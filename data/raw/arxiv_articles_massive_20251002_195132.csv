arxiv_id,title,authors,abstract,published,pdf_url,categories
1311.0716v1,Artificial Intelligence in Humans,['Michael Swan Laufer'],"In this paper, I put forward that in many instances, thinking mechanisms are
equivalent to artificial intelligence modules programmed into the human mind.",2013-10-30T14:19:49Z,http://arxiv.org/pdf/1311.0716v1,['cs.AI']
1903.04442v1,Physics Enhanced Artificial Intelligence,"[""Patrick O'Driscoll"", 'Jaehoon Lee', 'Bo Fu']","We propose that intelligently combining models from the domains of Artificial
Intelligence or Machine Learning with Physical and Expert models will yield a
more ""trustworthy"" model than any one model from a single domain, given a
complex and narrow enough problem. Based on mean-variance portfolio theory and
bias-variance trade-off analysis, we prove combining models from various
domains produces a model that has lower risk, increasing user trust. We call
such combined models - physics enhanced artificial intelligence (PEAI), and
suggest use cases for PEAI.",2019-03-11T17:03:19Z,http://arxiv.org/pdf/1903.04442v1,"['cs.AI', 'cs.LG']"
1606.08514v4,Towards Verified Artificial Intelligence,"['Sanjit A. Seshia', 'Dorsa Sadigh', 'S. Shankar Sastry']","Verified artificial intelligence (AI) is the goal of designing AI-based
systems that that have strong, ideally provable, assurances of correctness with
respect to mathematically-specified requirements. This paper considers Verified
AI from a formal methods perspective. We describe five challenges for achieving
Verified AI, and five corresponding principles for addressing these challenges.",2016-06-27T23:51:04Z,http://arxiv.org/pdf/1606.08514v4,['cs.AI']
1812.04814v1,Linking Artificial Intelligence Principles,"['Yi Zeng', 'Enmeng Lu', 'Cunqing Huangfu']","Artificial Intelligence principles define social and ethical considerations
to develop future AI. They come from research institutes, government
organizations and industries. All versions of AI principles are with different
considerations covering different perspectives and making different emphasis.
None of them can be considered as complete and can cover the rest AI principle
proposals. Here we introduce LAIP, an effort and platform for linking and
analyzing different Artificial Intelligence Principles. We want to explicitly
establish the common topics and links among AI Principles proposed by different
organizations and investigate on their uniqueness. Based on these efforts, for
the long-term future of AI, instead of directly adopting any of the AI
principles, we argue for the necessity of incorporating various AI Principles
into a comprehensive framework and focusing on how they can interact and
complete each other.",2018-12-12T05:43:57Z,http://arxiv.org/pdf/1812.04814v1,"['cs.AI', 'cs.CY']"
2407.16314v1,Capital as Artificial Intelligence,"['Cesare Carissimo', 'Marcin Korecki']","We gather many perspectives on Capital and synthesize their commonalities. We
provide a characterization of Capital as a historical agential system and
propose a model of Capital using tools from computer science. Our model
consists of propositions which, if satisfied by a specific grounding,
constitute a valid model of Capital. We clarify the manners in which Capital
can evolve. We claim that, when its evolution is driven by quantitative
optimization processes, Capital can possess qualities of Artificial
Intelligence. We find that Capital may not uniquely represent meaning, in the
same way that optimization is not intentionally meaningful. We find that
Artificial Intelligences like modern day Large Language Models are a part of
Capital. We link our readers to a web-interface where they can interact with a
part of Capital.",2024-07-23T09:05:33Z,http://arxiv.org/pdf/2407.16314v1,"['cs.CY', 'econ.TH']"
2001.00627v1,Artificial Intelligence in Surgery,"['Xiao-Yun Zhou', 'Yao Guo', 'Mali Shen', 'Guang-Zhong Yang']","Artificial Intelligence (AI) is gradually changing the practice of surgery
with the advanced technological development of imaging, navigation and robotic
intervention. In this article, the recent successful and influential
applications of AI in surgery are reviewed from pre-operative planning and
intra-operative guidance to the integration of surgical robots. We end with
summarizing the current state, emerging trends and major challenges in the
future development of AI in surgery.",2019-12-23T12:39:04Z,http://arxiv.org/pdf/2001.00627v1,"['physics.med-ph', 'cs.AI', 'eess.IV']"
1908.10345v1,Artificial Intelligence Approaches,"['Yingjie Hu', 'Wenwen Li', 'Dawn Wright', 'Orhun Aydin', 'Daniel Wilson', 'Omar Maher', 'Mansour Raad']","Artificial Intelligence (AI) has received tremendous attention from academia,
industry, and the general public in recent years. The integration of geography
and AI, or GeoAI, provides novel approaches for addressing a variety of
problems in the natural environment and our human society. This entry briefly
reviews the recent development of AI with a focus on machine learning and deep
learning approaches. We discuss the integration of AI with geography and
particularly geographic information science, and present a number of GeoAI
applications and possible future directions.",2019-08-27T17:36:27Z,http://arxiv.org/pdf/1908.10345v1,['cs.AI']
2212.11854v4,Data-Centric Artificial Intelligence,"['Johannes Jakubik', 'Michael Vössing', 'Niklas Kühl', 'Jannis Walk', 'Gerhard Satzger']","Data-centric artificial intelligence (data-centric AI) represents an emerging
paradigm emphasizing that the systematic design and engineering of data is
essential for building effective and efficient AI-based systems. The objective
of this article is to introduce practitioners and researchers from the field of
Information Systems (IS) to data-centric AI. We define relevant terms, provide
key characteristics to contrast the data-centric paradigm to the model-centric
one, and introduce a framework for data-centric AI. We distinguish data-centric
AI from related concepts and discuss its longer-term implications for the IS
community.",2022-12-22T16:41:03Z,http://arxiv.org/pdf/2212.11854v4,['cs.AI']
2202.09859v1,Cooperative Artificial Intelligence,['Tobias Baumann'],"In the future, artificial learning agents are likely to become increasingly
widespread in our society. They will interact with both other learning agents
and humans in a variety of complex settings including social dilemmas. We argue
that there is a need for research on the intersection between game theory and
artificial intelligence, with the goal of achieving cooperative artificial
intelligence that can navigate social dilemmas well. We consider the problem of
how an external agent can promote cooperation between artificial learners by
distributing additional rewards and punishments based on observing the actions
of the learners. We propose a rule for automatically learning how to create the
right incentives by considering the anticipated parameter updates of each
agent. Using this learning rule leads to cooperation with high social welfare
in matrix games in which the agents would otherwise learn to defect with high
probability. We show that the resulting cooperative outcome is stable in
certain games even if the planning agent is turned off after a given number of
episodes, while other games require ongoing intervention to maintain mutual
cooperation. Finally, we reflect on what the goals of multi-agent reinforcement
learning should be in the first place, and discuss the necessary building
blocks towards the goal of building cooperative AI.",2022-02-20T16:50:37Z,http://arxiv.org/pdf/2202.09859v1,"['cs.AI', 'cs.GT', 'cs.MA']"
1802.04451v2,Blockchain and Artificial Intelligence,"['Tshilidzi Marwala', 'Bo Xing']","It is undeniable that artificial intelligence (AI) and blockchain concepts
are spreading at a phenomenal rate. Both technologies have distinct degree of
technological complexity and multi-dimensional business implications. However,
a common misunderstanding about blockchain concept, in particular, is that
blockchain is decentralized and is not controlled by anyone. But the underlying
development of a blockchain system is still attributed to a cluster of core
developers. Take smart contract as an example, it is essentially a collection
of codes (or functions) and data (or states) that are programmed and deployed
on a blockchain (say, Ethereum) by different human programmers. It is thus,
unfortunately, less likely to be free of loopholes and flaws. In this article,
through a brief overview about how artificial intelligence could be used to
deliver bug-free smart contract so as to achieve the goal of blockchain 2.0, we
to emphasize that the blockchain implementation can be assisted or enhanced via
various AI techniques. The alliance of AI and blockchain is expected to create
numerous possibilities.",2018-02-13T03:10:59Z,http://arxiv.org/pdf/1802.04451v2,['cs.AI']
2502.05244v1,Probabilistic Artificial Intelligence,"['Andreas Krause', 'Jonas Hübotter']","Artificial intelligence commonly refers to the science and engineering of
artificial systems that can carry out tasks generally associated with requiring
aspects of human intelligence, such as playing games, translating languages,
and driving cars. In recent years, there have been exciting advances in
learning-based, data-driven approaches towards AI, and machine learning and
deep learning have enabled computer systems to perceive the world in
unprecedented ways. Reinforcement learning has enabled breakthroughs in complex
games such as Go and challenging robotics tasks such as quadrupedal locomotion.
  A key aspect of intelligence is to not only make predictions, but reason
about the uncertainty in these predictions, and to consider this uncertainty
when making decisions. This is what this manuscript on ""Probabilistic
Artificial Intelligence"" is about. The first part covers probabilistic
approaches to machine learning. We discuss the differentiation between
""epistemic"" uncertainty due to lack of data and ""aleatoric"" uncertainty, which
is irreducible and stems, e.g., from noisy observations and outcomes. We
discuss concrete approaches towards probabilistic inference and modern
approaches to efficient approximate inference.
  The second part of the manuscript is about taking uncertainty into account in
sequential decision tasks. We consider active learning and Bayesian
optimization -- approaches that collect data by proposing experiments that are
informative for reducing the epistemic uncertainty. We then consider
reinforcement learning and modern deep RL approaches that use neural network
function approximation. We close by discussing modern approaches in model-based
RL, which harness epistemic and aleatoric uncertainty to guide exploration,
while also reasoning about safety.",2025-02-07T14:29:07Z,http://arxiv.org/pdf/2502.05244v1,"['cs.AI', 'cs.LG']"
1712.03779v1,Artificial Intelligence and Statistics,"['Bin Yu', 'Karl Kumbier']","Artificial intelligence (AI) is intrinsically data-driven. It calls for the
application of statistical concepts through human-machine collaboration during
generation of data, development of algorithms, and evaluation of results. This
paper discusses how such human-machine collaboration can be approached through
the statistical concepts of population, question of interest,
representativeness of training data, and scrutiny of results (PQRS). The PQRS
workflow provides a conceptual framework for integrating statistical ideas with
human input into AI products and research. These ideas include experimental
design principles of randomization and local control as well as the principle
of stability to gain reproducibility and interpretability of algorithms and
data results. We discuss the use of these principles in the contexts of
self-driving cars, automated medical diagnoses, and examples from the authors'
collaborative research.",2017-12-08T02:18:43Z,http://arxiv.org/pdf/1712.03779v1,"['stat.ML', 'cs.AI']"
1908.02150v3,Industrial Artificial Intelligence,"['Jay Lee', 'Jaskaran Singh', 'Moslem Azamfar']","Artificial Intelligence (AI) is a cognitive science to enables human to
explore many intelligent ways to model our sensing and reasoning processes.
Industrial AI is a systematic discipline to enable engineers to systematically
develop and deploy AI algorithms with repeating and consistent successes. In
this paper, the key enablers for this transformative technology along with
their significant advantages are discussed. In addition, this research explains
Lighthouse Factories as an emerging status applying to the top manufacturers
that have implemented Industrial AI in their manufacturing ecosystem and gained
significant financial benefits. It is believed that this research will work as
a guideline and roadmap for researchers and industries towards the real-world
implementation of Industrial AI.",2019-08-04T05:19:43Z,http://arxiv.org/pdf/1908.02150v3,['cs.CY']
2006.12362v1,Artificial intelligence in space,"['George Anthony Gal', 'Cristiana Santos', 'Lucien Rapp', 'Réeka Markovich', 'Leendert van der Torre']","In the next coming years, space activities are expected to undergo a radical
transformation with the emergence of new satellite systems or new services
which will incorporate the contributions of artificial intelligence and machine
learning defined as covering a wide range of innovations from autonomous
objects with their own decision-making power to increasingly sophisticated
services exploiting very large volumes of information from space. This chapter
identifies some of the legal and ethical challenges linked to its use. These
legal and ethical challenges call for solutions which the international
treaties in force are not sufficient to determine and implement. For this
reason, a legal methodology must be developed that makes it possible to link
intelligent systems and services to a system of rules applicable thereto. It
discusses existing legal AI-based tools amenable for making space law
actionable, interoperable and machine readable for future compliance tools.",2020-06-22T16:00:44Z,http://arxiv.org/pdf/2006.12362v1,"['cs.CY', 'cs.AI']"
2101.06573v1,Understanding in Artificial Intelligence,"['Stefan Maetschke', 'David Martinez Iraola', 'Pieter Barnard', 'Elaheh ShafieiBavani', 'Peter Zhong', 'Ying Xu', 'Antonio Jimeno Yepes']","Current Artificial Intelligence (AI) methods, most based on deep learning,
have facilitated progress in several fields, including computer vision and
natural language understanding. The progress of these AI methods is measured
using benchmarks designed to solve challenging tasks, such as visual question
answering. A question remains of how much understanding is leveraged by these
methods and how appropriate are the current benchmarks to measure understanding
capabilities. To answer these questions, we have analysed existing benchmarks
and their understanding capabilities, defined by a set of understanding
capabilities, and current research streams. We show how progress has been made
in benchmark development to measure understanding capabilities of AI methods
and we review as well how current methods develop understanding capabilities.",2021-01-17T02:29:50Z,http://arxiv.org/pdf/2101.06573v1,['cs.AI']
2301.10823v3,Reflective Artificial Intelligence,"['Peter R. Lewis', 'Stefan Sarkadi']","Artificial Intelligence (AI) is about making computers that do the sorts of
things that minds can do, and as we progress towards this goal, we tend to
increasingly delegate human tasks to machines. However, AI systems usually do
these tasks with an unusual imbalance of insight and understanding: new, deeper
insights are present, yet many important qualities that a human mind would have
previously brought to the activity are utterly absent. Therefore, it is crucial
to ask which features of minds have we replicated, which are missing, and if
that matters. One core feature that humans bring to tasks, when dealing with
the ambiguity, emergent knowledge, and social context presented by the world,
is reflection. Yet this capability is utterly missing from current mainstream
AI. In this paper we ask what reflective AI might look like. Then, drawing on
notions of reflection in complex systems, cognitive science, and agents, we
sketch an architecture for reflective AI agents, and highlight ways forward.",2023-01-25T20:50:26Z,http://arxiv.org/pdf/2301.10823v3,['cs.AI']
2308.02435v1,Designing Fiduciary Artificial Intelligence,"['Sebastian Benthall', 'David Shekman']","A fiduciary is a trusted agent that has the legal duty to act with loyalty
and care towards a principal that employs them. When fiduciary organizations
interact with users through a digital interface, or otherwise automate their
operations with artificial intelligence, they will need to design these AI
systems to be compliant with their duties. This article synthesizes recent work
in computer science and law to develop a procedure for designing and auditing
Fiduciary AI. The designer of a Fiduciary AI should understand the context of
the system, identify its principals, and assess the best interests of those
principals. Then the designer must be loyal with respect to those interests,
and careful in an contextually appropriate way. We connect the steps in this
procedure to dimensions of Trustworthy AI, such as privacy and alignment.
Fiduciary AI is a promising means to address the incompleteness of data
subject's consent when interacting with complex technical systems.",2023-07-27T15:35:32Z,http://arxiv.org/pdf/2308.02435v1,"['cs.CY', 'cs.AI']"
2504.15125v3,Contemplative Artificial Intelligence,"['Ruben Laukkonen', 'Fionn Inglis', 'Shamil Chandaria', 'Lars Sandved-Smith', 'Edmundo Lopez-Sola', 'Jakob Hohwy', 'Jonathan Gold', 'Adam Elwood']","As artificial intelligence (AI) improves, traditional alignment strategies
may falter in the face of unpredictable self-improvement, hidden subgoals, and
the sheer complexity of intelligent systems. Inspired by contemplative wisdom
traditions, we show how four axiomatic principles can instil a resilient Wise
World Model in AI systems. First, mindfulness enables self-monitoring and
recalibration of emergent subgoals. Second, emptiness forestalls dogmatic goal
fixation and relaxes rigid priors. Third, non-duality dissolves adversarial
self-other boundaries. Fourth, boundless care motivates the universal reduction
of suffering. We find that prompting AI to reflect on these principles improves
performance on the AILuminate Benchmark (d=.96) and boosts cooperation and
joint-reward on the Prisoner's Dilemma task (d=7+). We offer detailed
implementation strategies at the level of architectures, constitutions, and
reinforcement on chain-of-thought. For future systems, active inference may
offer the self-organizing and dynamic coupling capabilities needed to enact
Contemplative AI in embodied agents.",2025-04-21T14:20:49Z,http://arxiv.org/pdf/2504.15125v3,['cs.AI']
1701.03868v1,Minimally Naturalistic Artificial Intelligence,['Steven Stenberg Hansen'],"The rapid advancement of machine learning techniques has re-energized
research into general artificial intelligence. While the idea of
domain-agnostic meta-learning is appealing, this emerging field must come to
terms with its relationship to human cognition and the statistics and structure
of the tasks humans perform. The position of this article is that only by
aligning our agents' abilities and environments with those of humans do we
stand a chance at developing general artificial intelligence (GAI). A broad
reading of the famous 'No Free Lunch' theorem is that there is no universally
optimal inductive bias or, equivalently, bias-free learning is impossible. This
follows from the fact that there are an infinite number of ways to extrapolate
data, any of which might be the one used by the data generating environment; an
inductive bias prefers some of these extrapolations to others, which lowers
performance in environments using these adversarial extrapolations. We may
posit that the optimal GAI is the one that maximally exploits the statistics of
its environment to create its inductive bias; accepting the fact that this
agent is guaranteed to be extremely sub-optimal for some alternative
environments. This trade-off appears benign when thinking about the environment
as being the physical universe, as performance on any fictive universe is
obviously irrelevant. But, we should expect a sharper inductive bias if we
further constrain our environment. Indeed, we implicitly do so by defining GAI
in terms of accomplishing that humans consider useful. One common version of
this is need the for 'common-sense reasoning', which implicitly appeals to the
statistics of physical universe as perceived by humans.",2017-01-14T01:57:31Z,http://arxiv.org/pdf/1701.03868v1,['cs.AI']
2202.07446v1,Relational Artificial Intelligence,['Virginia Dignum'],"The impact of Artificial Intelligence does not depend only on fundamental
research and technological developments, but for a large part on how these
systems are introduced into society and used in everyday situations. Even
though AI is traditionally associated with rational decision making,
understanding and shaping the societal impact of AI in all its facets requires
a relational perspective. A rational approach to AI, where computational
algorithms drive decision making independent of human intervention, insights
and emotions, has shown to result in bias and exclusion, laying bare societal
vulnerabilities and insecurities. A relational approach, that focus on the
relational nature of things, is needed to deal with the ethical, legal,
societal, cultural, and environmental implications of AI. A relational approach
to AI recognises that objective and rational reasoning cannot does not always
result in the 'right' way to proceed because what is 'right' depends on the
dynamics of the situation in which the decision is taken, and that rather than
solving ethical problems the focus of design and use of AI must be on asking
the ethical question. In this position paper, I start with a general discussion
of current conceptualisations of AI followed by an overview of existing
approaches to governance and responsible development and use of AI. Then, I
reflect over what should be the bases of a social paradigm for AI and how this
should be embedded in relational, feminist and non-Western philosophies, in
particular the Ubuntu philosophy.",2022-02-04T15:29:57Z,http://arxiv.org/pdf/2202.07446v1,"['cs.CY', 'cs.AI']"
1411.1373v9,Ethical Artificial Intelligence,['Bill Hibbard'],"This book-length article combines several peer reviewed papers and new
material to analyze the issues of ethical artificial intelligence (AI). The
behavior of future AI systems can be described by mathematical equations, which
are adapted to analyze possible unintended AI behaviors and ways that AI
designs can avoid them. This article makes the case for utility-maximizing
agents and for avoiding infinite sets in agent definitions. It shows how to
avoid agent self-delusion using model-based utility functions and how to avoid
agents that corrupt their reward generators (sometimes called ""perverse
instantiation"") using utility functions that evaluate outcomes at one point in
time from the perspective of humans at a different point in time. It argues
that agents can avoid unintended instrumental actions (sometimes called ""basic
AI drives"" or ""instrumental goals"") by accurately learning human values. This
article defines a self-modeling agent framework and shows how it can avoid
problems of resource limits, being predicted by other agents, and inconsistency
between the agent's utility function and its definition (one version of this
problem is sometimes called ""motivated value selection""). This article also
discusses how future AI will differ from current AI, the politics of AI, and
the ultimate use of AI to help understand the nature of the universe and our
place in it.",2014-11-05T19:40:02Z,http://arxiv.org/pdf/1411.1373v9,['cs.AI']
2203.03715v1,Needs and Artificial Intelligence,"['Soheil Human', 'Ryan Watkins']","Throughout their history, homo sapiens have used technologies to better
satisfy their needs. The relation between needs and technology is so
fundamental that the US National Research Council defined the distinguishing
characteristic of technology as its goal ""to make modifications in the world to
meet human needs"". Artificial intelligence (AI) is one of the most promising
emerging technologies of our time. Similar to other technologies, AI is
expected ""to meet [human] needs"". In this article, we reflect on the
relationship between needs and AI, and call for the realisation of needs-aware
AI systems. We argue that re-thinking needs for, through, and by AI can be a
very useful means towards the development of realistic approaches for
Sustainable, Human-centric, Accountable, Lawful, and Ethical (HALE) AI systems.
We discuss some of the most critical gaps, barriers, enablers, and drivers of
co-creating future AI-based socio-technical systems in which [human] needs are
well considered and met. Finally, we provide an overview of potential threats
and HALE considerations that should be carefully taken into account, and call
for joint, immediate, and interdisciplinary efforts and collaborations.",2022-02-18T15:16:22Z,http://arxiv.org/pdf/2203.03715v1,"['cs.CY', 'cs.AI']"
2309.06029v1,Artificially Intelligent Opinion Polling,"['Roberto Cerina', 'Raymond Duch']","We seek to democratise public-opinion research by providing practitioners
with a general methodology to make representative inference from cheap,
high-frequency, highly unrepresentative samples. We focus specifically on
samples which are readily available in moderate sizes. To this end, we provide
two major contributions: 1) we introduce a general sample-selection process
which we name online selection, and show it is a special-case of selection on
the dependent variable. We improve MrP for severely biased samples by
introducing a bias-correction term in the style of King and Zeng to the
logistic-regression framework. We show this bias-corrected model outperforms
traditional MrP under online selection, and achieves performance similar to
random-sampling in a vast array of scenarios; 2) we present a protocol to use
Large Language Models (LLMs) to extract structured, survey-like data from
social-media. We provide a prompt-style that can be easily adapted to a variety
of survey designs. We show that LLMs agree with human raters with respect to
the demographic, socio-economic and political characteristics of these online
users. The end-to-end implementation takes unrepresentative, unsrtuctured
social media data as inputs, and produces timely high-quality area-level
estimates as outputs. This is Artificially Intelligent Opinion Polling. We show
that our AI polling estimates of the 2020 election are highly accurate, on-par
with estimates produced by state-level polling aggregators such as
FiveThirtyEight, or from MrP models fit to extremely expensive high-quality
samples.",2023-09-12T08:03:02Z,http://arxiv.org/pdf/2309.06029v1,['stat.ME']
2508.16658v1,Ethics of Artificial Intelligence,['Vincent C. Müller'],"Artificial intelligence (AI) is a digital technology that will be of major
importance for the development of humanity in the near future. AI has raised
fundamental questions about what we should do with such systems, what the
systems themselves should do, what risks they involve and how we can control
these. - After the background to the field (1), this article introduces the
main debates (2), first on ethical issues that arise with AI systems as
objects, i.e. tools made and used by humans; here, the main sections are
privacy (2.1), manipulation (2.2), opacity (2.3), bias (2.4), autonomy &
responsibility (2.6) and the singularity (2.7). Then we look at AI systems as
subjects, i.e. when ethics is for the AI systems themselves in machine ethics
(2.8.) and artificial moral agency (2.9). Finally we look at future
developments and the concept of AI (3). For each section within these themes,
we provide a general explanation of the ethical issues, we outline existing
positions and arguments, then we analyse how this plays out with current
technologies and finally what policy consequences may be drawn.",2025-08-20T10:22:19Z,http://arxiv.org/pdf/2508.16658v1,['cs.CY']
1811.06526v3,Artificial Intelligence for Interstellar Travel,"['Andreas M. Hein', 'Stephen Baxter']","The large distances involved in interstellar travel require a high degree of
spacecraft autonomy, realized by artificial intelligence. The breadth of tasks
artificial intelligence could perform on such spacecraft involves maintenance,
data collection, designing and constructing an infrastructure using in-situ
resources. Despite its importance, existing publications on artificial
intelligence and interstellar travel are limited to cursory descriptions where
little detail is given about the nature of the artificial intelligence. This
article explores the role of artificial intelligence for interstellar travel by
compiling use cases, exploring capabilities, and proposing typologies, system
and mission architectures. Estimations for the required intelligence level for
specific types of interstellar probes are given, along with potential system
and mission architectures, covering those proposed in the literature but also
presenting novel ones. Finally, a generic design for interstellar probes with
an AI payload is proposed. Given current levels of increase in computational
power, a spacecraft with a similar computational power as the human brain would
have a mass from dozens to hundreds of tons in a 2050-2060 timeframe. Given
that the advent of the first interstellar missions and artificial general
intelligence are estimated to be by the mid-21st century, a more in-depth
exploration of the relationship between the two should be attempted, focusing
on neglected areas such as protecting the artificial intelligence payload from
radiation in interstellar space and the role of artificial intelligence in
self-replication.",2018-11-15T18:49:16Z,http://arxiv.org/pdf/1811.06526v3,"['physics.pop-ph', 'physics.space-ph']"
1610.07862v2,Intelligence in Artificial Intelligence,['Shoumen Palit Austin Datta'],"The elusive quest for intelligence in artificial intelligence prompts us to
consider that instituting human-level intelligence in systems may be (still) in
the realm of utopia. In about a quarter century, we have witnessed the winter
of AI (1990) being transformed and transported to the zenith of tabloid fodder
about AI (2015). The discussion at hand is about the elements that constitute
the canonical idea of intelligence. The delivery of intelligence as a
pay-per-use-service, popping out of an app or from a shrink-wrapped software
defined point solution, is in contrast to the bio-inspired view of intelligence
as an outcome, perhaps formed from a tapestry of events, cross-pollinated by
instances, each with its own microcosm of experiences and learning, which may
not be discrete all-or-none functions but continuous, over space and time. The
enterprise world may not require, aspire or desire such an engaged solution to
improve its services for enabling digital transformation through the deployment
of digital twins, for example. One might ask whether the ""work-flow on
steroids"" version of decision support may suffice for intelligence? Are we
harking back to the era of rule based expert systems? The image conjured by the
publicity machines offers deep solutions with human-level AI and preposterous
claims about capturing the ""brain in a box"" by 2020. Even emulating insects may
be difficult in terms of real progress. Perhaps we can try to focus on worms
(Caenorhabditis elegans) which may be better suited for what business needs to
quench its thirst for so-called intelligence in AI.",2016-10-24T02:15:46Z,http://arxiv.org/pdf/1610.07862v2,['cs.AI']
2012.06034v1,Artificial Intelligence & Cooperation,"['Elisa Bertino', 'Finale Doshi-Velez', 'Maria Gini', 'Daniel Lopresti', 'David Parkes']","The rise of Artificial Intelligence (AI) will bring with it an
ever-increasing willingness to cede decision-making to machines. But rather
than just giving machines the power to make decisions that affect us, we need
ways to work cooperatively with AI systems. There is a vital need for research
in ""AI and Cooperation"" that seeks to understand the ways in which systems of
AIs and systems of AIs with people can engender cooperative behavior. Trust in
AI is also key: trust that is intrinsic and trust that can only be earned over
time. Here we use the term ""AI"" in its broadest sense, as employed by the
recent 20-Year Community Roadmap for AI Research (Gil and Selman, 2019),
including but certainly not limited to, recent advances in deep learning.
  With success, cooperation between humans and AIs can build society just as
human-human cooperation has. Whether coming from an intrinsic willingness to be
helpful, or driven through self-interest, human societies have grown strong and
the human species has found success through cooperation. We cooperate ""in the
small"" -- as family units, with neighbors, with co-workers, with strangers --
and ""in the large"" as a global community that seeks cooperative outcomes around
questions of commerce, climate change, and disarmament. Cooperation has evolved
in nature also, in cells and among animals. While many cases involving
cooperation between humans and AIs will be asymmetric, with the human
ultimately in control, AI systems are growing so complex that, even today, it
is impossible for the human to fully comprehend their reasoning,
recommendations, and actions when functioning simply as passive observers.",2020-12-10T23:54:31Z,http://arxiv.org/pdf/2012.06034v1,"['cs.CY', 'cs.AI']"
2212.03412v1,Artificial Intelligence Security Competition (AISC),"['Yinpeng Dong', 'Peng Chen', 'Senyou Deng', 'Lianji L', 'Yi Sun', 'Hanyu Zhao', 'Jiaxing Li', 'Yunteng Tan', 'Xinyu Liu', 'Yangyi Dong', 'Enhui Xu', 'Jincai Xu', 'Shu Xu', 'Xuelin Fu', 'Changfeng Sun', 'Haoliang Han', 'Xuchong Zhang', 'Shen Chen', 'Zhimin Sun', 'Junyi Cao', 'Taiping Yao', 'Shouhong Ding', 'Yu Wu', 'Jian Lin', 'Tianpeng Wu', 'Ye Wang', 'Yu Fu', 'Lin Feng', 'Kangkang Gao', 'Zeyu Liu', 'Yuanzhe Pang', 'Chengqi Duan', 'Huipeng Zhou', 'Yajie Wang', 'Yuhang Zhao', 'Shangbo Wu', 'Haoran Lyu', 'Zhiyu Lin', 'Yifei Gao', 'Shuang Li', 'Haonan Wang', 'Jitao Sang', 'Chen Ma', 'Junhao Zheng', 'Yijia Li', 'Chao Shen', 'Chenhao Lin', 'Zhichao Cui', 'Guoshuai Liu', 'Huafeng Shi', 'Kun Hu', 'Mengxin Zhang']","The security of artificial intelligence (AI) is an important research area
towards safe, reliable, and trustworthy AI systems. To accelerate the research
on AI security, the Artificial Intelligence Security Competition (AISC) was
organized by the Zhongguancun Laboratory, China Industrial Control Systems
Cyber Emergency Response Team, Institute for Artificial Intelligence, Tsinghua
University, and RealAI as part of the Zhongguancun International Frontier
Technology Innovation Competition (https://www.zgc-aisc.com/en). The
competition consists of three tracks, including Deepfake Security Competition,
Autonomous Driving Security Competition, and Face Recognition Security
Competition. This report will introduce the competition rules of these three
tracks and the solutions of top-ranking teams in each track.",2022-12-07T02:45:27Z,http://arxiv.org/pdf/2212.03412v1,"['cs.CR', 'cs.AI', 'cs.CV', 'cs.LG']"
2304.02924v1,The Governance of Physical Artificial Intelligence,"['Yingbo Li', 'Anamaria-Beatrice Spulber', 'Yucong Duan']","Physical artificial intelligence can prove to be one of the most important
challenges of the artificial intelligence. The governance of physical
artificial intelligence would define its responsible intelligent application in
the society.",2023-04-06T08:26:38Z,http://arxiv.org/pdf/2304.02924v1,['cs.AI']
1703.06597v1,Artificial Intelligence and Economic Theories,"['Tshilidzi Marwala', 'Evan Hurwitz']","The advent of artificial intelligence has changed many disciplines such as
engineering, social science and economics. Artificial intelligence is a
computational technique which is inspired by natural intelligence such as the
swarming of birds, the working of the brain and the pathfinding of the ants.
These techniques have impact on economic theories. This book studies the impact
of artificial intelligence on economic theories, a subject that has not been
extensively studied. The theories that are considered are: demand and supply,
asymmetrical information, pricing, rational choice, rational expectation, game
theory, efficient market hypotheses, mechanism design, prospect, bounded
rationality, portfolio theory, rational counterfactual and causality. The
benefit of this book is that it evaluates existing theories of economics and
update them based on the developments in artificial intelligence field.",2017-03-20T04:47:14Z,http://arxiv.org/pdf/1703.06597v1,['cs.AI']
2203.08890v1,The Mathematics of Artificial Intelligence,['Gitta Kutyniok'],"We currently witness the spectacular success of artificial intelligence in
both science and public life. However, the development of a rigorous
mathematical foundation is still at an early stage. In this survey article,
which is based on an invited lecture at the International Congress of
Mathematicians 2022, we will in particular focus on the current ""workhorse"" of
artificial intelligence, namely deep neural networks. We will present the main
theoretical directions along with several exemplary results and discuss key
open problems.",2022-03-16T19:04:53Z,http://arxiv.org/pdf/2203.08890v1,"['cs.LG', 'math.HO', 'stat.ML', 'Primary 68T07, Secondary 41A25, 42C15, 35C20, 65D18']"
1704.08716v1,Artificial Intelligence Based Malware Analysis,"['Avi Pfeffer', 'Brian Ruttenberg', 'Lee Kellogg', 'Michael Howard', 'Catherine Call', ""Alison O'Connor"", 'Glenn Takata', 'Scott Neal Reilly', 'Terry Patten', 'Jason Taylor', 'Robert Hall', 'Arun Lakhotia', 'Craig Miles', 'Dan Scofield', 'Jared Frank']","Artificial intelligence methods have often been applied to perform specific
functions or tasks in the cyber-defense realm. However, as adversary methods
become more complex and difficult to divine, piecemeal efforts to understand
cyber-attacks, and malware-based attacks in particular, are not providing
sufficient means for malware analysts to understand the past, present and
future characteristics of malware.
  In this paper, we present the Malware Analysis and Attributed using Genetic
Information (MAAGI) system. The underlying idea behind the MAAGI system is that
there are strong similarities between malware behavior and biological organism
behavior, and applying biologically inspired methods to corpora of malware can
help analysts better understand the ecosystem of malware attacks. Due to the
sophistication of the malware and the analysis, the MAAGI system relies heavily
on artificial intelligence techniques to provide this capability. It has
already yielded promising results over its development life, and will hopefully
inspire more integration between the artificial intelligence and cyber--defense
communities.",2017-04-27T18:53:37Z,http://arxiv.org/pdf/1704.08716v1,"['cs.CR', 'cs.AI']"
1901.05406v1,Artificial Intelligence for Social Good,"['Gregory D. Hager', 'Ann Drobnis', 'Fei Fang', 'Rayid Ghani', 'Amy Greenwald', 'Terah Lyons', 'David C. Parkes', 'Jason Schultz', 'Suchi Saria', 'Stephen F. Smith', 'Milind Tambe']","The Computing Community Consortium (CCC), along with the White House Office
of Science and Technology Policy (OSTP), and the Association for the
Advancement of Artificial Intelligence (AAAI), co-sponsored a public workshop
on Artificial Intelligence for Social Good on June 7th, 2016 in Washington, DC.
This was one of five workshops that OSTP co-sponsored and held around the
country to spur public dialogue on artificial intelligence, machine learning,
and to identify challenges and opportunities related to AI. In the AI for
Social Good workshop, the successful deployments and the potential use of AI in
various topics that are essential for social good were discussed, including but
not limited to urban computing, health, environmental sustainability, and
public welfare. This report highlights each of these as well as a number of
crosscutting issues.",2019-01-16T17:42:43Z,http://arxiv.org/pdf/1901.05406v1,['cs.CY']
2309.00135v1,Construction Grammar and Artificial Intelligence,"['Katrien Beuls', 'Paul Van Eecke']","In this chapter, we argue that it is highly beneficial for the contemporary
construction grammarian to have a thorough understanding of the strong
relationship between the research fields of construction grammar and artificial
intelligence. We start by unravelling the historical links between the two
fields, showing that their relationship is rooted in a common attitude towards
human communication and language. We then discuss the first direction of
influence, focussing in particular on how insights and techniques from the
field of artificial intelligence play an important role in operationalising,
validating and scaling constructionist approaches to language. We then proceed
to the second direction of influence, highlighting the relevance of
construction grammar insights and analyses to the artificial intelligence
endeavour of building truly intelligent agents. We support our case with a
variety of illustrative examples and conclude that the further elaboration of
this relationship will play a key role in shaping the future of the field of
construction grammar.",2023-08-31T21:15:06Z,http://arxiv.org/pdf/2309.00135v1,"['cs.AI', 'cs.CL']"
2412.00330v1,Ethics and Artificial Intelligence Adoption,"['Martim Veiga', 'Carlos J. Costa']","In recent years, we have witnessed a marked development and growth in
Artificial Intelligence. The growth of the data volume generated by sensors and
machines, combined with the information flow resulting from the user actions on
the Internet, with high investments of the governments and the companies in
this area, provided the practice and developed the algorithms of the Artificial
Intelligence However, the people, in general, started to feel a particular fear
regarding the security and privacy of their data and the theme of the
Artificial Intelligence Ethics began to be discussed more regularly. The
investigation aim of this work is to understand the possibility of adopting
Artificial Intelligence nowadays in our society, having, as a mandatory
assumption, Ethics and respect towards data and people's privacy. With that
purpose in mind, a model has been created, mainly supported by the theories
that were used to create the model. The suggested model has been tested and
validated through Structural equation modeling based on data taken back from
the respondents' answers to the questionnaire online: 237 answers, mainly from
the Investigation Technologies area. The results obtained enabled the
validation of seven of the nine investigation hypotheses of the proposed model.
It was impossible to confirm any association between the Social Influence
construct and the variables of Behavioral Intention and the Use of Artificial
Intelligence. The aim of this work was accomplished once the investigation
theme was validated and proved that it is possible to adopt Artificial
Intelligence in our society, using the Attitude Towards Ethical Behavioral
construct as the mainstay of the model.",2024-11-30T03:08:15Z,http://arxiv.org/pdf/2412.00330v1,['cs.CY']
1703.10098v1,Rational Choice and Artificial Intelligence,['Tshilidzi Marwala'],"The theory of rational choice assumes that when people make decisions they do
so in order to maximize their utility. In order to achieve this goal they ought
to use all the information available and consider all the choices available to
choose an optimal choice. This paper investigates what happens when decisions
are made by artificially intelligent machines in the market rather than human
beings. Firstly, the expectations of the future are more consistent if they are
made by an artificially intelligent machine and the decisions are more rational
and thus marketplace becomes more rational.",2017-03-29T15:30:40Z,http://arxiv.org/pdf/1703.10098v1,"['cs.AI', 'q-fin.GN']"
2302.01570v1,Witgenstein's influence on artificial intelligence,"['Piero Molino', 'Jacopo Tagliabue']","We examine how much of the contemporary progress in artificial intelligence
(and, specifically, in natural language processing), can be, more or less
directly, traced back to the seminal work and ideas of the Austrian-British
philosopher Ludwig Wittgenstein, with particular focus on his late views.
Discussing Wittgenstein's original theses will give us the chance to survey the
state of artificial intelligence, and comment on both its strengths and
weaknesses. A similar text appeared first in Spanish as a chapter of CENTENARIO
DEL SILENCIO (2021), a book celebrating 100 years since the publication of the
Tractatus.",2023-02-03T06:47:20Z,http://arxiv.org/pdf/2302.01570v1,"['cs.AI', 'cs.CL']"
1801.05667v1,"Innateness, AlphaZero, and Artificial Intelligence",['Gary Marcus'],"The concept of innateness is rarely discussed in the context of artificial
intelligence. When it is discussed, or hinted at, it is often the context of
trying to reduce the amount of innate machinery in a given system. In this
paper, I consider as a test case a recent series of papers by Silver et al
(Silver et al., 2017a) on AlphaGo and its successors that have been presented
as an argument that a ""even in the most challenging of domains: it is possible
to train to superhuman level, without human examples or guidance"", ""starting
tabula rasa.""
  I argue that these claims are overstated, for multiple reasons. I close by
arguing that artificial intelligence needs greater attention to innateness, and
I point to some proposals about what that innateness might look like.",2018-01-17T14:05:21Z,http://arxiv.org/pdf/1801.05667v1,"['cs.AI', '97R40', 'I.2.0; I.2.6']"
2406.18620v1,Documentation Practices of Artificial Intelligence,"['Stefan Arnold', 'Dilara Yesilbas', 'Rene Gröbner', 'Dominik Riedelbauch', 'Maik Horn', 'Sven Weinzierl']","Artificial Intelligence (AI) faces persistent challenges in terms of
transparency and accountability, which requires rigorous documentation. Through
a literature review on documentation practices, we provide an overview of
prevailing trends, persistent issues, and the multifaceted interplay of factors
influencing the documentation. Our examination of key characteristics such as
scope, target audiences, support for multimodality, and level of automation,
highlights a dynamic evolution in documentation practices, underscored by a
shift towards a more holistic, engaging, and automated documentation.",2024-06-26T08:33:52Z,http://arxiv.org/pdf/2406.18620v1,"['cs.DL', 'cs.AI']"
2101.04255v6,Quantum Mathematics in Artificial Intelligence,"['Dominic Widdows', 'Kirsty Kitto', 'Trevor Cohen']","In the decade since 2010, successes in artificial intelligence have been at
the forefront of computer science and technology, and vector space models have
solidified a position at the forefront of artificial intelligence. At the same
time, quantum computers have become much more powerful, and announcements of
major advances are frequently in the news.
  The mathematical techniques underlying both these areas have more in common
than is sometimes realized. Vector spaces took a position at the axiomatic
heart of quantum mechanics in the 1930s, and this adoption was a key motivation
for the derivation of logic and probability from the linear geometry of vector
spaces. Quantum interactions between particles are modelled using the tensor
product, which is also used to express objects and operations in artificial
neural networks.
  This paper describes some of these common mathematical areas, including
examples of how they are used in artificial intelligence (AI), particularly in
automated reasoning and natural language processing (NLP). Techniques discussed
include vector spaces, scalar products, subspaces and implication, orthogonal
projection and negation, dual vectors, density matrices, positive operators,
and tensor products. Application areas include information retrieval,
categorization and implication, modelling word-senses and disambiguation,
inference in knowledge bases, and semantic composition.
  Some of these approaches can potentially be implemented on quantum hardware.
Many of the practical steps in this implementation are in early stages, and
some are already realized. Explaining some of the common mathematical tools can
help researchers in both AI and quantum computing further exploit these
overlaps, recognizing and exploring new directions along the way.",2021-01-12T01:35:56Z,http://arxiv.org/pdf/2101.04255v6,"['cs.AI', 'cs.CL', 'cs.IR']"
2209.11618v2,Artificial Intelligence and Advanced Materials,['Cefe López'],"Artificial intelligence is gaining strength and materials science can both
contribute to and profit from it. In a simultaneous progress race, new
materials, systems and processes can be devised and optimized thanks to machine
learning techniques and such progress can be turned into in-novative computing
platforms. Future materials scientists will profit from understanding how
machine learning can boost the conception of advanced materials. This review
covers aspects of computation from the fundamentals to directions taken and
repercussions produced by compu-tation to account for the origins, procedures
and applications of artificial intelligence. Machine learning and its methods
are reviewed to provide basic knowledge on its implementation and its
potential. The materials and systems used to implement artificial intelligence
with electric charges are finding serious competition from other information
carrying and processing agents. The impact these techniques are having on the
inception of new advanced materials is so deep that a new paradigm is
developing where implicit knowledge is being mined to conceive materi-als and
systems for functions instead of finding applications to found materials. How
far this trend can be carried is hard to fathom as exemplified by the power to
discover unheard of mate-rials or physical laws buried in data.",2022-09-23T14:39:59Z,http://arxiv.org/pdf/2209.11618v2,['cond-mat.mtrl-sci']
1509.01213v1,Impact of Artificial Intelligence on Economic Theory,['Tshilidzi Marwala'],"Artificial intelligence has impacted many aspects of human life. This paper
studies the impact of artificial intelligence on economic theory. In particular
we study the impact of artificial intelligence on the theory of bounded
rationality, efficient market hypothesis and prospect theory.",2015-07-01T16:26:21Z,http://arxiv.org/pdf/1509.01213v1,['q-fin.GN']
1701.07769v1,Ethical Considerations in Artificial Intelligence Courses,"['Emanuelle Burton', 'Judy Goldsmith', 'Sven Koenig', 'Benjamin Kuipers', 'Nicholas Mattei', 'Toby Walsh']","The recent surge in interest in ethics in artificial intelligence may leave
many educators wondering how to address moral, ethical, and philosophical
issues in their AI courses. As instructors we want to develop curriculum that
not only prepares students to be artificial intelligence practitioners, but
also to understand the moral, ethical, and philosophical impacts that
artificial intelligence will have on society. In this article we provide
practical case studies and links to resources for use by AI educators. We also
provide concrete suggestions on how to integrate AI ethics into a general
artificial intelligence course and how to teach a stand-alone artificial
intelligence ethics course.",2017-01-26T16:52:22Z,http://arxiv.org/pdf/1701.07769v1,"['cs.AI', 'cs.CY', 'cs.GL', 'K.3.2; K.4.1; K.7.m']"
1210.1568v1,A Definition of Artificial Intelligence,['Dimiter Dobrev'],"In this paper we offer a formal definition of Artificial Intelligence and
this directly gives us an algorithm for construction of this object. Really,
this algorithm is useless due to the combinatory explosion.
  The main innovation in our definition is that it does not include the
knowledge as a part of the intelligence. So according to our definition a newly
born baby also is an Intellect. Here we differs with Turing's definition which
suggests that an Intellect is a person with knowledge gained through the years.",2012-10-03T20:46:10Z,http://arxiv.org/pdf/1210.1568v1,['cs.AI']
1608.08196v1,Smart Policies for Artificial Intelligence,"['Miles Brundage', 'Joanna Bryson']","We argue that there already exists de facto artificial intelligence policy -
a patchwork of policies impacting the field of AI's development in myriad ways.
The key question related to AI policy, then, is not whether AI should be
governed at all, but how it is currently being governed, and how that
governance might become more informed, integrated, effective, and anticipatory.
We describe the main components of de facto AI policy and make some
recommendations for how AI policy can be improved, drawing on lessons from
other scientific and technological domains.",2016-08-29T19:50:30Z,http://arxiv.org/pdf/1608.08196v1,['cs.CY']
1803.06563v1,Viewpoint: Artificial Intelligence and Labour,['Spyridon Samothrakis'],"The welfare of modern societies has been intrinsically linked to wage labour.
With some exceptions, the modern human has to sell her labour-power to be able
reproduce biologically and socially. Thus, a lingering fear of technological
unemployment features predominately as a theme among Artificial Intelligence
researchers. In this short paper we show that, if past trends are anything to
go by, this fear is irrational. On the contrary, we argue that the main problem
humanity will be facing is the normalisation of extremely long working hours.",2018-03-17T20:08:49Z,http://arxiv.org/pdf/1803.06563v1,"['cs.CY', 'cs.AI']"
2107.03912v1,Artificial intelligence across company borders,"['Olga Fink', 'Torbjørn Netland', 'Stefan Feuerriegel']","Artificial intelligence (AI) has become a valued technology in many
companies. At the same time, a substantial potential for utilizing AI
\emph{across} company borders has remained largely untapped. An inhibiting
factor concerns disclosure of data to external parties, which raises legitimate
concerns about intellectual property rights, privacy issues, and cybersecurity
risks. Combining federated learning with domain adaptation can provide a
solution to this problem by enabling effective cross-company AI without data
disclosure. In this Viewpoint, we discuss the use, value, and implications of
this approach in a cross-company setting.",2021-06-21T11:56:41Z,http://arxiv.org/pdf/2107.03912v1,['cs.CY']
1707.08476v1,Guidelines for Artificial Intelligence Containment,"['James Babcock', 'Janos Kramar', 'Roman V. Yampolskiy']","With almost daily improvements in capabilities of artificial intelligence it
is more important than ever to develop safety software for use by the AI
research community. Building on our previous work on AI Containment Problem we
propose a number of guidelines which should help AI safety researchers to
develop reliable sandboxing software for intelligent programs of all levels.
Such safety container software will make it possible to study and analyze
intelligent artificial agent while maintaining certain level of safety against
information leakage, social engineering attacks and cyberattacks from within
the container.",2017-07-24T18:33:18Z,http://arxiv.org/pdf/1707.08476v1,"['cs.AI', 'cs.CR']"
2202.05947v1,Artificial Intelligence and Auction Design,"['Martino Banchio', 'Andrzej Skrzypacz']","Motivated by online advertising auctions, we study auction design in repeated
auctions played by simple Artificial Intelligence algorithms (Q-learning). We
find that first-price auctions with no additional feedback lead to
tacit-collusive outcomes (bids lower than values), while second-price auctions
do not. We show that the difference is driven by the incentive in first-price
auctions to outbid opponents by just one bid increment. This facilitates
re-coordination on low bids after a phase of experimentation. We also show that
providing information about lowest bid to win, as introduced by Google at the
time of switch to first-price auctions, increases competitiveness of auctions.",2022-02-12T00:54:40Z,http://arxiv.org/pdf/2202.05947v1,"['econ.TH', 'cs.AI', 'cs.GT']"
1802.07782v1,Artificial Intelligence and Legal Liability,['John Kingston'],"A recent issue of a popular computing journal asked which laws would apply if
a self-driving car killed a pedestrian. This paper considers the question of
legal liability for artificially intelligent computer systems. It discusses
whether criminal liability could ever apply; to whom it might apply; and, under
civil law, whether an AI program is a product that is subject to product design
legislation or a service to which the tort of negligence applies. The issue of
sales warranties is also considered. A discussion of some of the practical
limitations that AI systems are subject to is also included.",2018-02-21T20:11:28Z,http://arxiv.org/pdf/1802.07782v1,"['cs.AI', 'cs.CY']"
1806.04915v1,The IQ of Artificial Intelligence,['Dimiter Dobrev'],"All it takes to identify the computer programs which are Artificial
Intelligence is to give them a test and award AI to those that pass the test.
Let us say that the scores they earn at the test will be called IQ. We cannot
pinpoint a minimum IQ threshold that a program has to cover in order to be AI,
however, we will choose a certain value. Thus, our definition for AI will be
any program the IQ of which is above the chosen value. While this idea has
already been implemented in [3], here we will revisit this construct in order
to introduce certain improvements.",2018-06-13T09:29:42Z,http://arxiv.org/pdf/1806.04915v1,['cs.AI']
2407.17048v3,Artificial intelligence and financial crises,"['Jon Danielsson', 'Andreas Uthemann']","The rapid adoption of artificial intelligence (AI) poses new and poorly
understood threats to financial stability. We use a game-theoretic model to
analyse the stability impact of AI, finding that it amplifies existing
financial system vulnerabilities - leverage, liquidity stress and opacity -
through superior information processing, common data, speed and strategic
complementarities. The consequence is crises become faster and more severe,
where the likelihood of a crisis is directly affected by how effectively the
authorities engage with AI. In response, we propose that the financial
authorities develop their own AI systems and expertise, establish direct
AI-to-AI communication, implement automated crisis facilities and monitor AI
use.",2024-07-24T07:15:21Z,http://arxiv.org/pdf/2407.17048v3,"['econ.GN', 'q-fin.EC']"
1904.08796v1,Artificial Intelligence for Pediatric Ophthalmology,"['Julia E. Reid', 'Eric Eaton']","PURPOSE OF REVIEW: Despite the impressive results of recent artificial
intelligence (AI) applications to general ophthalmology, comparatively less
progress has been made toward solving problems in pediatric ophthalmology using
similar techniques. This article discusses the unique needs of pediatric
ophthalmology patients and how AI techniques can address these challenges,
surveys recent applications of AI to pediatric ophthalmology, and discusses
future directions in the field.
  RECENT FINDINGS: The most significant advances involve the automated
detection of retinopathy of prematurity (ROP), yielding results that rival
experts. Machine learning (ML) has also been successfully applied to the
classification of pediatric cataracts, prediction of post-operative
complications following cataract surgery, detection of strabismus and
refractive error, prediction of future high myopia, and diagnosis of reading
disability via eye tracking. In addition, ML techniques have been used for the
study of visual development, vessel segmentation in pediatric fundus images,
and ophthalmic image synthesis.
  SUMMARY: AI applications could significantly benefit clinical care for
pediatric ophthalmology patients by optimizing disease detection and grading,
broadening access to care, furthering scientific discovery, and improving
clinical efficiency. These methods need to match or surpass physician
performance in clinical trials before deployment with patients. Due to
widespread use of closed-access data sets and software implementations, it is
difficult to directly compare the performance of these approaches, and
reproducibility is poor. Open-access data sets and software implementations
could alleviate these issues, and encourage further AI applications to
pediatric ophthalmology.
  KEYWORDS: pediatric ophthalmology, machine learning, artificial intelligence,
deep learning",2019-04-06T01:47:47Z,http://arxiv.org/pdf/1904.08796v1,"['physics.med-ph', 'cs.CV', 'cs.LG', 'eess.IV']"
1907.04659v3,Artificial Intelligence: A Child's Play,['Ravi Kashyap'],"We discuss the objectives of any endeavor in creating artificial
intelligence, AI, and provide a possible alternative. Intelligence might be an
unintended consequence of curiosity left to roam free, best exemplified by a
frolicking infant. This suggests that our attempts at AI could have been
misguided. What we actually need to strive for can be termed artificial
curiosity, AC, and intelligence happens as a consequence of those efforts. For
this unintentional yet welcome aftereffect to set in a foundational list of
guiding principles needs to be present. We start with the intuition for this
line of reasoning and formalize it with a series of definitions, assumptions,
ingredients, models and iterative improvements that will be necessary to make
the incubation of intelligence a reality. Our discussion provides conceptual
modifications to the Turing Test and to Searle's Chinese room argument. We
discuss the future implications for society as AI becomes an integral part of
life.
  We provide a road-map for creating intelligence with the technical parts
relegated to the appendix so that the article is accessible to a wide audience.
The central techniques in our formal approach to creating intelligence draw
upon tools and concepts widely used in physics, cognitive science, psychology,
evolutionary biology, statistics, linguistics, communication systems, pattern
recognition, marketing, economics, finance, information science and
computational theory highlighting that solutions for creating artificial
intelligence have to transcend the artificial barriers between various fields
and be highly multi-disciplinary.",2019-07-01T04:46:07Z,http://arxiv.org/pdf/1907.04659v3,"['cs.AI', '68Q32 Computational learning theory, 68T05 Learning & adaptive\n  systems, 97R40 Artificial intelligence, 91E10 Cognitive psychology, 60J60\n  Diffusion processes', 'I.2.0; I.2.6; I.2.8; F.4.3; G.3']"
2011.04105v1,Evolution of Artificial Intelligent Plane,['Puneet Kumar'],"With the growth of the internet, it is becoming hard to manage, configure and
monitor networks. Recent trends to control and operate them is artificial
intelligence based automation to minimize human intervention. Albeit this
concept has been introduced since a decade with several different names, but
the underlying goal remains the same, which is to make network intelligent
enough to assemble, reassemble if configuration changes, and detect a problem
on its own and fix it. As a result, in addition to Data Plane, Control Plane
and Management Plane, a new plane called Artificial Intelligence (AI) Plane is
introduced. Our main objective is to analyze all major AI plane techniques,
frameworks and algorithms proposed in various types of networks. We propose a
comprehensive and network independent framework to cover all aspects of AI
plane, in particular we provide a systematically means of comparison. In
conjunction to make AI plane understand simpler, this framework highlights
relevant challenges and design considerations for future research. To the best
of our knowledge this is the first survey report which represents a complete
comparison of AI planes with their investigation issues in several types of
networks.",2020-11-08T23:33:12Z,http://arxiv.org/pdf/2011.04105v1,"['cs.AI', 'cs.NI']"
2211.13069v1,Cultural Incongruencies in Artificial Intelligence,"['Vinodkumar Prabhakaran', 'Rida Qadri', 'Ben Hutchinson']","Artificial intelligence (AI) systems attempt to imitate human behavior. How
well they do this imitation is often used to assess their utility and to
attribute human-like (or artificial) intelligence to them. However, most work
on AI refers to and relies on human intelligence without accounting for the
fact that human behavior is inherently shaped by the cultural contexts they are
embedded in, the values and beliefs they hold, and the social practices they
follow. Additionally, since AI technologies are mostly conceived and developed
in just a handful of countries, they embed the cultural values and practices of
these countries. Similarly, the data that is used to train the models also
fails to equitably represent global cultural diversity. Problems therefore
arise when these technologies interact with globally diverse societies and
cultures, with different values and interpretive practices. In this position
paper, we describe a set of cultural dependencies and incongruencies in the
context of AI-based language and vision technologies, and reflect on the
possibilities of and potential strategies towards addressing these
incongruencies.",2022-11-19T18:45:02Z,http://arxiv.org/pdf/2211.13069v1,"['cs.CY', 'cs.AI']"
2405.19522v1,Artificial Intelligence Index Report 2024,"['Nestor Maslej', 'Loredana Fattorini', 'Raymond Perrault', 'Vanessa Parli', 'Anka Reuel', 'Erik Brynjolfsson', 'John Etchemendy', 'Katrina Ligett', 'Terah Lyons', 'James Manyika', 'Juan Carlos Niebles', 'Yoav Shoham', 'Russell Wald', 'Jack Clark']","The 2024 Index is our most comprehensive to date and arrives at an important
moment when AI's influence on society has never been more pronounced. This
year, we have broadened our scope to more extensively cover essential trends
such as technical advancements in AI, public perceptions of the technology, and
the geopolitical dynamics surrounding its development. Featuring more original
data than ever before, this edition introduces new estimates on AI training
costs, detailed analyses of the responsible AI landscape, and an entirely new
chapter dedicated to AI's impact on science and medicine. The AI Index report
tracks, collates, distills, and visualizes data related to artificial
intelligence (AI). Our mission is to provide unbiased, rigorously vetted,
broadly sourced data in order for policymakers, researchers, executives,
journalists, and the general public to develop a more thorough and nuanced
understanding of the complex field of AI. The AI Index is recognized globally
as one of the most credible and authoritative sources for data and insights on
artificial intelligence. Previous editions have been cited in major newspapers,
including the The New York Times, Bloomberg, and The Guardian, have amassed
hundreds of academic citations, and been referenced by high-level policymakers
in the United States, the United Kingdom, and the European Union, among other
places. This year's edition surpasses all previous ones in size, scale, and
scope, reflecting the growing significance that AI is coming to hold in all of
our lives.",2024-05-29T20:59:57Z,http://arxiv.org/pdf/2405.19522v1,['cs.AI']
1304.3429v1,Probability Judgement in Artificial Intelligence,['Glenn Shafer'],"This paper is concerned with two theories of probability judgment: the
Bayesian theory and the theory of belief functions. It illustrates these
theories with some simple examples and discusses some of the issues that arise
when we try to implement them in expert systems. The Bayesian theory is well
known; its main ideas go back to the work of Thomas Bayes (1702-1761). The
theory of belief functions, often called the Dempster-Shafer theory in the
artificial intelligence community, is less well known, but it has even older
antecedents; belief-function arguments appear in the work of George Hooper
(16401723) and James Bernoulli (1654-1705). For elementary expositions of the
theory of belief functions, see Shafer (1976, 1985).",2013-03-27T19:56:37Z,http://arxiv.org/pdf/1304.3429v1,['cs.AI']
1812.02953v1,Building Ethics into Artificial Intelligence,"['Han Yu', 'Zhiqi Shen', 'Chunyan Miao', 'Cyril Leung', 'Victor R. Lesser', 'Qiang Yang']","As artificial intelligence (AI) systems become increasingly ubiquitous, the
topic of AI governance for ethical decision-making by AI has captured public
imagination. Within the AI research community, this topic remains less familiar
to many researchers. In this paper, we complement existing surveys, which
largely focused on the psychological, social and legal discussions of the
topic, with an analysis of recent advances in technical solutions for AI
governance. By reviewing publications in leading AI conferences including AAAI,
AAMAS, ECAI and IJCAI, we propose a taxonomy which divides the field into four
areas: 1) exploring ethical dilemmas; 2) individual ethical decision
frameworks; 3) collective ethical decision frameworks; and 4) ethics in
human-AI interactions. We highlight the intuitions and key techniques used in
each approach, and discuss promising future research directions towards
successful integration of ethical AI systems into human societies.",2018-12-07T09:18:01Z,http://arxiv.org/pdf/1812.02953v1,['cs.AI']
2101.02991v1,Artificial Intelligence enabled Smart Learning,"['Faisal Khan', 'Debdeep Bose']","Artificial Intelligence (AI) is a discipline of computer science that deals
with machine intelligence. It is essential to bring AI into the context of
learning because it helps in analysing the enormous amounts of data that is
collected from individual students, teachers and academic staff. The major
priorities of implementing AI in education are making innovative use of
existing digital technologies for learning, and teaching practices that
significantly improve traditional educational methods. The main problem with
traditional learning is that it cannot be suited to every student in class.
Some students may grasp the concepts well, while some may have difficulties in
understanding them and some may be more auditory or visual learners. The World
Bank report on education has indicated that the learning gap created by this
problem causes many students to drop out (World Development Report, 2018).
Personalised learning has been able to solve this grave problem.",2021-01-08T12:49:33Z,http://arxiv.org/pdf/2101.02991v1,['cs.AI']
1504.05696v2,Ascribing Consciousness to Artificial Intelligence,['Murray Shanahan'],"This paper critically assesses the anti-functionalist stance on consciousness
adopted by certain advocates of integrated information theory (IIT), a
corollary of which is that human-level artificial intelligence implemented on
conventional computing hardware is necessarily not conscious. The critique
draws on variations of a well-known gradual neuronal replacement thought
experiment, as well as bringing out tensions in IIT's treatment of
self-knowledge. The aim, though, is neither to reject IIT outright nor to
champion functionalism in particular. Rather, it is suggested that both ideas
have something to offer a scientific understanding of consciousness, as long as
they are not dressed up as solutions to illusory metaphysical problems. As for
human-level AI, we must await its development before we can decide whether or
not to ascribe consciousness to it.",2015-04-22T08:50:16Z,http://arxiv.org/pdf/1504.05696v2,['cs.AI']
2206.00225v1,Can Artificial Intelligence Transform DevOps?,"['Mamdouh Alenezi', 'Mohammad Zarour', 'Mohammad Akour']","DevOps and Artificial Intelligence (AI) are interconnected with each other.
DevOps is a business-driven approach to providing quickly delivered quality
software, and AI is the technology that can be used in the system to enhance
its functionality. So, DevOps teams can use AI to test, code, release, monitor,
and improve the system. Through AI, the automation process delivered by DevOps
could be improved efficiently. This study aims to explore how AI can transform
DevOps. The research is useful in terms of facilitating software developers and
businesses to assess the importance of AI in DevOps. The study has practical
implications as it elaborates on how AI transforms DevOps and in what way it
can support businesses in their business.",2022-06-01T04:21:39Z,http://arxiv.org/pdf/2206.00225v1,['cs.SE']
2303.12350v2,Artificial Intelligence and Dual Contract,['Qian Qi'],"This paper explores the capacity of artificial intelligence (AI) algorithms
to autonomously design incentive-compatible contracts in dual-principal-agent
settings, a relatively unexplored aspect of algorithmic mechanism design. We
develop a dynamic model where two principals, each equipped with independent
Q-learning algorithms, interact with a single agent. Our findings reveal that
the strategic behavior of AI principals (cooperation vs. competition) hinges
crucially on the alignment of their profits. Notably, greater profit alignment
fosters collusive strategies, yielding higher principal profits at the expense
of agent incentives. This emergent behavior persists across varying degrees of
principal heterogeneity, multiple principals, and environments with
uncertainty. Our study underscores the potential of AI for contract automation
while raising critical concerns regarding strategic manipulation and the
emergence of unintended collusion in AI-driven systems, particularly in the
context of the broader AI alignment problem.",2023-03-22T07:31:44Z,http://arxiv.org/pdf/2303.12350v2,"['cs.AI', 'cs.CY', 'econ.GN', 'q-fin.EC']"
2308.07457v1,Artificial Intelligence for Smart Transportation,"['Michael Wilbur', 'Amutheezan Sivagnanam', 'Afiya Ayman', 'Samitha Samaranayeke', 'Abhishek Dubey', 'Aron Laszka']","There are more than 7,000 public transit agencies in the U.S. (and many more
private agencies), and together, they are responsible for serving 60 billion
passenger miles each year. A well-functioning transit system fosters the growth
and expansion of businesses, distributes social and economic benefits, and
links the capabilities of community members, thereby enhancing what they can
accomplish as a society. Since affordable public transit services are the
backbones of many communities, this work investigates ways in which Artificial
Intelligence (AI) can improve efficiency and increase utilization from the
perspective of transit agencies. This book chapter discusses the primary
requirements, objectives, and challenges related to the design of AI-driven
smart transportation systems. We focus on three major topics. First, we discuss
data sources and data. Second, we provide an overview of how AI can aid
decision-making with a focus on transportation. Lastly, we discuss
computational problems in the transportation domain and AI approaches to these
problems.",2023-08-14T21:01:00Z,http://arxiv.org/pdf/2308.07457v1,['cs.AI']
2310.03715v1,Artificial Intelligence Index Report 2023,"['Nestor Maslej', 'Loredana Fattorini', 'Erik Brynjolfsson', 'John Etchemendy', 'Katrina Ligett', 'Terah Lyons', 'James Manyika', 'Helen Ngo', 'Juan Carlos Niebles', 'Vanessa Parli', 'Yoav Shoham', 'Russell Wald', 'Jack Clark', 'Raymond Perrault']","Welcome to the sixth edition of the AI Index Report. This year, the report
introduces more original data than any previous edition, including a new
chapter on AI public opinion, a more thorough technical performance chapter,
original analysis about large language and multimodal models, detailed trends
in global AI legislation records, a study of the environmental impact of AI
systems, and more. The AI Index Report tracks, collates, distills, and
visualizes data related to artificial intelligence. Our mission is to provide
unbiased, rigorously vetted, broadly sourced data in order for policymakers,
researchers, executives, journalists, and the general public to develop a more
thorough and nuanced understanding of the complex field of AI. The report aims
to be the world's most credible and authoritative source for data and insights
about AI.",2023-10-05T17:37:58Z,http://arxiv.org/pdf/2310.03715v1,"['cs.AI', 'cs.CY']"
2411.09131v1,Artificial Intelligence for Quantum Computing,"['Yuri Alexeev', 'Marwa H. Farag', 'Taylor L. Patti', 'Mark E. Wolf', 'Natalia Ares', 'Alán Aspuru-Guzik', 'Simon C. Benjamin', 'Zhenyu Cai', 'Zohim Chandani', 'Federico Fedele', 'Nicholas Harrigan', 'Jin-Sung Kim', 'Elica Kyoseva', 'Justin G. Lietz', 'Tom Lubowe', 'Alexander McCaskey', 'Roger G. Melko', 'Kouhei Nakaji', 'Alberto Peruzzo', 'Sam Stanwyck', 'Norm M. Tubman', 'Hanrui Wang', 'Timothy Costa']","Artificial intelligence (AI) advancements over the past few years have had an
unprecedented and revolutionary impact across everyday application areas. Its
significance also extends to technical challenges within science and
engineering, including the nascent field of quantum computing (QC). The
counterintuitive nature and high-dimensional mathematics of QC make it a prime
candidate for AI's data-driven learning capabilities, and in fact, many of QC's
biggest scaling challenges may ultimately rest on developments in AI. However,
bringing leading techniques from AI to QC requires drawing on disparate
expertise from arguably two of the most advanced and esoteric areas of computer
science. Here we aim to encourage this cross-pollination by reviewing how
state-of-the-art AI techniques are already advancing challenges across the
hardware and software stack needed to develop useful QC - from device design to
applications. We then close by examining its future opportunities and obstacles
in this space.",2024-11-14T02:11:16Z,http://arxiv.org/pdf/2411.09131v1,['quant-ph']
2411.13717v2,Hardware Accelerators for Artificial Intelligence,"['S M Mojahidul Ahsan', 'Anurag Dhungel', 'Mrittika Chowdhury', 'Md Sakib Hasan', 'Tamzidul Hoque']","In this chapter, we aim to explore an in-depth exploration of the specialized
hardware accelerators designed to enhance Artificial Intelligence (AI)
applications, focusing on their necessity, development, and impact on the field
of AI. It covers the transition from traditional computing systems to advanced
AI-specific hardware, addressing the growing demands of AI algorithms and the
inefficiencies of conventional architectures. The discussion extends to various
types of accelerators, including GPUs, FPGAs, and ASICs, and their roles in
optimizing AI workloads. Additionally, it touches on the challenges and
considerations in designing and implementing these accelerators, along with
future prospects in the evolution of AI hardware. This comprehensive overview
aims to equip readers with a clear understanding of the current landscape and
future directions in AI hardware development, making it accessible to both
experts and newcomers to the field.",2024-11-20T21:33:21Z,http://arxiv.org/pdf/2411.13717v2,"['cs.AR', 'cs.ET']"
2501.10465v1,The Mathematics of Artificial Intelligence,['Gabriel Peyré'],"This overview article highlights the critical role of mathematics in
artificial intelligence (AI), emphasizing that mathematics provides tools to
better understand and enhance AI systems. Conversely, AI raises new problems
and drives the development of new mathematics at the intersection of various
fields. This article focuses on the application of analytical and probabilistic
tools to model neural network architectures and better understand their
optimization. Statistical questions (particularly the generalization capacity
of these networks) are intentionally set aside, though they are of crucial
importance. We also shed light on the evolution of ideas that have enabled
significant advances in AI through architectures tailored to specific tasks,
each echoing distinct mathematical techniques. The goal is to encourage more
mathematicians to take an interest in and contribute to this exciting field.",2025-01-15T15:00:23Z,http://arxiv.org/pdf/2501.10465v1,"['math.OC', 'cs.AI']"
2504.07139v2,Artificial Intelligence Index Report 2025,"['Nestor Maslej', 'Loredana Fattorini', 'Raymond Perrault', 'Yolanda Gil', 'Vanessa Parli', 'Njenga Kariuki', 'Emily Capstick', 'Anka Reuel', 'Erik Brynjolfsson', 'John Etchemendy', 'Katrina Ligett', 'Terah Lyons', 'James Manyika', 'Juan Carlos Niebles', 'Yoav Shoham', 'Russell Wald', 'Tobi Walsh', 'Armin Hamrah', 'Lapo Santarlasci', 'Julia Betts Lotufo', 'Alexandra Rome', 'Andrew Shi', 'Sukrut Oak']","Welcome to the eighth edition of the AI Index report. The 2025 Index is our
most comprehensive to date and arrives at an important moment, as AI's
influence across society, the economy, and global governance continues to
intensify. New in this year's report are in-depth analyses of the evolving
landscape of AI hardware, novel estimates of inference costs, and new analyses
of AI publication and patenting trends. We also introduce fresh data on
corporate adoption of responsible AI practices, along with expanded coverage of
AI's growing role in science and medicine. Since its founding in 2017 as an
offshoot of the One Hundred Year Study of Artificial Intelligence, the AI Index
has been committed to equipping policymakers, journalists, executives,
researchers, and the public with accurate, rigorously validated, and globally
sourced data. Our mission has always been to help these stakeholders make
better-informed decisions about the development and deployment of AI. In a
world where AI is discussed everywhere - from boardrooms to kitchen tables -
this mission has never been more essential. The AI Index continues to lead in
tracking and interpreting the most critical trends shaping the field - from the
shifting geopolitical landscape and the rapid evolution of underlying
technologies, to AI's expanding role in business, policymaking, and public
life. Longitudinal tracking remains at the heart of our mission. In a domain
advancing at breakneck speed, the Index provides essential context - helping us
understand where AI stands today, how it got here, and where it may be headed
next. Recognized globally as one of the most authoritative resources on
artificial intelligence, the AI Index has been cited in major media outlets
such as The New York Times, Bloomberg, and The Guardian; referenced in hundreds
of academic papers; and used by policymakers and government agencies around the
world.",2025-04-08T02:01:37Z,http://arxiv.org/pdf/2504.07139v2,['cs.AI']
2106.15306v1,Artificial Intelligence in Minimally Invasive Interventional Treatment,['Daniel Ruijters'],"Minimally invasive image guided treatment procedures often employ advanced
image processing algorithms. The recent developments of artificial intelligence
algorithms harbor potential to further enhance this domain. In this article we
explore several application areas within the minimally invasive treatment space
and discuss the deployment of artificial intelligence within these areas.",2021-06-08T14:57:25Z,http://arxiv.org/pdf/2106.15306v1,"['cs.CV', 'cs.GR', 'cs.LG', 'eess.IV', 'I.2.1; I.2.10; I.4.9']"
2205.00322v2,Artificial Intelligence and Medicine: A literature review,['Chottiwatt Jittprasong'],"In practically every industry today, artificial intelligence is one of the
most effective ways for machines to assist humans. Since its inception, a large
number of researchers throughout the globe have been pioneering the application
of artificial intelligence in medicine. Although artificial intelligence may
seem to be a 21st-century concept, Alan Turing pioneered the first foundation
concept in the 1940s. Artificial intelligence in medicine has a huge variety of
applications that researchers are continually exploring. The tremendous
increase in computer and human resources has hastened progress in the 21st
century, and it will continue to do so for many years to come. This review of
the literature will highlight the emerging field of artificial intelligence in
medicine and its current level of development.",2022-04-30T18:39:00Z,http://arxiv.org/pdf/2205.00322v2,"['q-bio.QM', 'cs.AI', 'I.2']"
1009.4964v1,Text Classification using Artificial Intelligence,['S. M. Kamruzzaman'],"Text classification is the process of classifying documents into predefined
categories based on their content. It is the automated assignment of natural
language texts to predefined categories. Text classification is the primary
requirement of text retrieval systems, which retrieve texts in response to a
user query, and text understanding systems, which transform text in some way
such as producing summaries, answering questions or extracting data. Existing
supervised learning algorithms for classifying text need sufficient documents
to learn accurately. This paper presents a new algorithm for text
classification using artificial intelligence technique that requires fewer
documents for training. Instead of using words, word relation i.e. association
rules from these words is used to derive feature set from pre-classified text
documents. The concept of na\""ive Bayes classifier is then used on derived
features and finally only a single concept of genetic algorithm has been added
for final classification. A system based on the proposed algorithm has been
implemented and tested. The experimental results show that the proposed system
works as a successful text classifier.",2010-09-25T01:08:27Z,http://arxiv.org/pdf/1009.4964v1,['cs.IR']
2108.03793v1,Toward Human-Level Artificial Intelligence,['Deokgun Park'],"In this paper, we present our research on programming human-level artificial
intelligence (HLAI), including 1) a definition of HLAI, 2) an environment to
develop and test HLAI, and 3) a cognitive architecture for HLAI. The term AI is
used in a broad meaning, and HLAI is not clearly defined. I claim that the
essence of Human-Level Intelligence to be the capability to learn from others'
experiences via language. The key is that the event described by language has
the same effect as if the agent experiences it firsthand for the update of the
behavior policy. To develop and test models with such a capability, we are
developing a simulated environment called SEDRo. There is a 3D Home, and a
mother character takes care of the baby (the learning agent) and teaches
languages. The environment provides comparable experiences to that of a human
baby from birth to one year. Finally, I propose a cognitive architecture of
HLAI called Modulated Heterarchical Prediction Memory (mHPM). In mHPM, there
are three components: a universal module that learns to predict the next vector
given the sequence of vector signals, a heterarchical network of those modules,
and a reward-based modulation of learning. mHPM models the workings of the
neocortex but the innate auxiliary units such hippocampus, reward system,
instincts, and amygdala play critical roles, too.",2021-08-09T03:39:39Z,http://arxiv.org/pdf/2108.03793v1,['cs.AI']
2202.09292v1,System Safety and Artificial Intelligence,['Roel I. J. Dobbe'],"This chapter formulates seven lessons for preventing harm in artificial
intelligence (AI) systems based on insights from the field of system safety for
software-based automation in safety-critical domains. New applications of AI
across societal domains and public organizations and infrastructures come with
new hazards, which lead to new forms of harm, both grave and pernicious. The
text addresses the lack of consensus for diagnosing and eliminating new AI
system hazards. For decades, the field of system safety has dealt with
accidents and harm in safety-critical systems governed by varying degrees of
software-based automation and decision-making. This field embraces the core
assumption of systems and control that AI systems cannot be safeguarded by
technical design choices on the model or algorithm alone, instead requiring an
end-to-end hazard analysis and design frame that includes the context of use,
impacted stakeholders and the formal and informal institutional environment in
which the system operates. Safety and other values are then inherently
socio-technical and emergent system properties that require design and control
measures to instantiate these across the technical, social and institutional
components of a system. This chapter honors system safety pioneer Nancy
Leveson, by situating her core lessons for today's AI system safety challenges.
For every lesson, concrete tools are offered for rethinking and reorganizing
the safety management of AI systems, both in design and governance. This
history tells us that effective AI safety management requires transdisciplinary
approaches and a shared language that allows involvement of all levels of
society.",2022-02-18T16:37:54Z,http://arxiv.org/pdf/2202.09292v1,"['eess.SY', 'cs.AI', 'cs.CY', 'cs.LG', 'cs.SE', 'cs.SY']"
2011.10672v3,Artificial Intelligence Governance for Businesses,"['Johannes Schneider', 'Rene Abraham', 'Christian Meske', 'Jan vom Brocke']","Artificial Intelligence (AI) governance regulates the exercise of authority
and control over the management of AI. It aims at leveraging AI through
effective use of data and minimization of AI-related cost and risk. While
topics such as AI governance and AI ethics are thoroughly discussed on a
theoretical, philosophical, societal and regulatory level, there is limited
work on AI governance targeted to companies and corporations. This work views
AI products as systems, where key functionality is delivered by machine
learning (ML) models leveraging (training) data. We derive a conceptual
framework by synthesizing literature on AI and related fields such as ML. Our
framework decomposes AI governance into governance of data, (ML) models and
(AI) systems along four dimensions. It relates to existing IT and data
governance frameworks and practices. It can be adopted by practitioners and
academics alike. For practitioners the synthesis of mainly research papers, but
also practitioner publications and publications of regulatory bodies provides a
valuable starting point to implement AI governance, while for academics the
paper highlights a number of areas of AI governance that deserve more
attention.",2020-11-20T22:31:37Z,http://arxiv.org/pdf/2011.10672v3,['cs.AI']
2012.05410v1,Artificial Intelligence at the Edge,"['Elisa Bertino', 'Sujata Banerjee']","The Internet of Things (IoT) and edge computing applications aim to support a
variety of societal needs, including the global pandemic situation that the
entire world is currently experiencing and responses to natural disasters.
  The need for real-time interactive applications such as immersive video
conferencing, augmented/virtual reality, and autonomous vehicles, in education,
healthcare, disaster recovery and other domains, has never been higher. At the
same time, there have been recent technological breakthroughs in highly
relevant fields such as artificial intelligence (AI)/machine learning (ML),
advanced communication systems (5G and beyond), privacy-preserving
computations, and hardware accelerators. 5G mobile communication networks
increase communication capacity, reduce transmission latency and error, and
save energy -- capabilities that are essential for new applications. The
envisioned future 6G technology will integrate many more technologies,
including for example visible light communication, to support groundbreaking
applications, such as holographic communications and high precision
manufacturing. Many of these applications require computations and analytics
close to application end-points: that is, at the edge of the network, rather
than in a centralized cloud. AI techniques applied at the edge have tremendous
potential both to power new applications and to need more efficient operation
of edge infrastructure. However, it is critical to understand where to deploy
AI systems within complex ecosystems consisting of advanced applications and
the specific real-time requirements towards AI systems.",2020-12-10T02:08:47Z,http://arxiv.org/pdf/2012.05410v1,"['cs.CY', 'cs.AI']"
2102.03406v2,Symbolic Behaviour in Artificial Intelligence,"['Adam Santoro', 'Andrew Lampinen', 'Kory Mathewson', 'Timothy Lillicrap', 'David Raposo']","The ability to use symbols is the pinnacle of human intelligence, but has yet
to be fully replicated in machines. Here we argue that the path towards
symbolically fluent artificial intelligence (AI) begins with a reinterpretation
of what symbols are, how they come to exist, and how a system behaves when it
uses them. We begin by offering an interpretation of symbols as entities whose
meaning is established by convention. But crucially, something is a symbol only
for those who demonstrably and actively participate in this convention. We then
outline how this interpretation thematically unifies the behavioural traits
humans exhibit when they use symbols. This motivates our proposal that the
field place a greater emphasis on symbolic behaviour rather than particular
computational mechanisms inspired by more restrictive interpretations of
symbols. Finally, we suggest that AI research explore social and cultural
engagement as a tool to develop the cognitive machinery necessary for symbolic
behaviour to emerge. This approach will allow for AI to interpret something as
symbolic on its own rather than simply manipulate things that are only symbols
to human onlookers, and thus will ultimately lead to AI with more human-like
symbolic fluency.",2021-02-05T20:07:14Z,http://arxiv.org/pdf/2102.03406v2,"['cs.AI', 'cs.LG']"
2106.11022v1,Hard Choices in Artificial Intelligence,"['Roel Dobbe', 'Thomas Krendl Gilbert', 'Yonatan Mintz']","As AI systems are integrated into high stakes social domains, researchers now
examine how to design and operate them in a safe and ethical manner. However,
the criteria for identifying and diagnosing safety risks in complex social
contexts remain unclear and contested. In this paper, we examine the vagueness
in debates about the safety and ethical behavior of AI systems. We show how
this vagueness cannot be resolved through mathematical formalism alone, instead
requiring deliberation about the politics of development as well as the context
of deployment. Drawing from a new sociotechnical lexicon, we redefine vagueness
in terms of distinct design challenges at key stages in AI system development.
The resulting framework of Hard Choices in Artificial Intelligence (HCAI)
empowers developers by 1) identifying points of overlap between design
decisions and major sociotechnical challenges; 2) motivating the creation of
stakeholder feedback channels so that safety issues can be exhaustively
addressed. As such, HCAI contributes to a timely debate about the status of AI
development in democratic societies, arguing that deliberation should be the
goal of AI Safety, not just the procedure by which it is ensured.",2021-06-10T09:49:34Z,http://arxiv.org/pdf/2106.11022v1,"['cs.CY', 'cs.AI', 'cs.SY', 'eess.SY', 'I.2; K.4']"
2211.00065v1,Artificial Intelligence and Arms Control,"['Paul Scharre', 'Megan Lamberth']","Potential advancements in artificial intelligence (AI) could have profound
implications for how countries research and develop weapons systems, and how
militaries deploy those systems on the battlefield. The idea of AI-enabled
military systems has motivated some activists to call for restrictions or bans
on some weapon systems, while others have argued that AI may be too diffuse to
control. This paper argues that while a ban on all military applications of AI
is likely infeasible, there may be specific cases where arms control is
possible. Throughout history, the international community has attempted to ban
or regulate weapons or military systems for a variety of reasons. This paper
analyzes both successes and failures and offers several criteria that seem to
influence why arms control works in some cases and not others. We argue that
success or failure depends on the desirability (i.e., a weapon's military value
versus its perceived horribleness) and feasibility (i.e., sociopolitical
factors that influence its success) of arms control. Based on these criteria,
and the historical record of past attempts at arms control, we analyze the
potential for AI arms control in the future and offer recommendations for what
policymakers can do today.",2022-10-22T16:09:41Z,http://arxiv.org/pdf/2211.00065v1,"['cs.CY', 'cs.AI']"
2403.08425v3,Specification Overfitting in Artificial Intelligence,"['Benjamin Roth', 'Pedro Henrique Luz de Araujo', 'Yuxi Xia', 'Saskia Kaltenbrunner', 'Christoph Korab']","Machine learning (ML) and artificial intelligence (AI) approaches are often
criticized for their inherent bias and for their lack of control,
accountability, and transparency. Consequently, regulatory bodies struggle with
containing this technology's potential negative side effects. High-level
requirements such as fairness and robustness need to be formalized into
concrete specification metrics, imperfect proxies that capture isolated aspects
of the underlying requirements. Given possible trade-offs between different
metrics and their vulnerability to over-optimization, integrating specification
metrics in system development processes is not trivial. This paper defines
specification overfitting, a scenario where systems focus excessively on
specified metrics to the detriment of high-level requirements and task
performance. We present an extensive literature survey to categorize how
researchers propose, measure, and optimize specification metrics in several AI
fields (e.g., natural language processing, computer vision, reinforcement
learning). Using a keyword-based search on papers from major AI conferences and
journals between 2018 and mid-2023, we identify and analyze 74 papers that
propose or optimize specification metrics. We find that although most papers
implicitly address specification overfitting (e.g., by reporting more than one
specification metric), they rarely discuss which role specification metrics
should play in system development or explicitly define the scope and
assumptions behind metric formulations.",2024-03-13T11:20:34Z,http://arxiv.org/pdf/2403.08425v3,['cs.AI']
2502.10434v1,Agency in Artificial Intelligence Systems,['Parashar Das'],"There is a general concern that present developments in artificial
intelligence (AI) research will lead to sentient AI systems, and these may pose
an existential threat to humanity. But why cannot sentient AI systems benefit
humanity instead? This paper endeavours to put this question in a tractable
manner. I ask whether a putative AI system will develop an altruistic or a
malicious disposition towards our society, or what would be the nature of its
agency? Given that AI systems are being developed into formidable problem
solvers, we can reasonably expect these systems to preferentially take on
conscious aspects of human problem solving. I identify the relevant phenomenal
aspects of agency in human problem solving. The functional aspects of conscious
agency can be monitored using tools provided by functionalist theories of
consciousness. A recent expert report (Butlin et al. 2023) has identified
functionalist indicators of agency based on these theories. I show how to use
the Integrated Information Theory (IIT) of consciousness, to monitor the
phenomenal nature of this agency. If we are able to monitor the agency of AI
systems as they develop, then we can dissuade them from becoming a menace to
society while encouraging them to be an aid.",2025-02-09T02:21:14Z,http://arxiv.org/pdf/2502.10434v1,"['cs.AI', 'cs.CY']"
1912.06485v3,Blockchain Intelligence: When Blockchain Meets Artificial Intelligence,"['Zibin Zheng', 'Hong-Ning Dai', 'Jiajing Wu']","Blockchain is gaining extensive attention due to its provision of secure and
decentralized resource sharing manner. However, the incumbent blockchain
systems also suffer from a number of challenges in operational maintenance,
quality assurance of smart contracts and malicious behaviour detection of
blockchain data. The recent advances in artificial intelligence bring the
opportunities in overcoming the above challenges. The integration of blockchain
with artificial intelligence can be beneficial to enhance current blockchain
systems. This article presents an introduction of the convergence of blockchain
and artificial intelligence (namely blockchain intelligence). This article also
gives a case study to further demonstrate the feasibility of blockchain
intelligence and point out the future directions.",2019-12-11T02:56:45Z,http://arxiv.org/pdf/1912.06485v3,"['cs.CR', 'cs.AI', 'cs.DC', 'cs.SE']"
2202.06869v3,CLAS12 Track Reconstruction with Artificial Intelligence,"['Gagik Gavalian', 'Polykarpos Thomadakis', 'Angelos Angelopoulos', 'Nikos Chrisochoides', 'Raffaella De Vita', 'Veronique Ziegler']","In this article we describe the implementation of Artificial Intelligence
models in track reconstruction software for the CLAS12 detector at Jefferson
Lab. The Artificial Intelligence based approach resulted in improved track
reconstruction efficiency in high luminosity experimental conditions. The track
reconstruction efficiency increased by $10-12\%$ for single particle, and
statistics in multi-particle physics reactions increased by $15\%-35\%$
depending on the number of particles in the reaction. The implementation of
artificial intelligence in the workflow also resulted in a speedup of the
tracking by $35\%$.",2022-02-14T16:56:51Z,http://arxiv.org/pdf/2202.06869v3,"['physics.data-an', 'nucl-ex']"
1901.11184v1,Human-Centered Artificial Intelligence and Machine Learning,['Mark O. Riedl'],"Humans are increasingly coming into contact with artificial intelligence and
machine learning systems. Human-centered artificial intelligence is a
perspective on AI and ML that algorithms must be designed with awareness that
they are part of a larger system consisting of humans. We lay forth an argument
that human-centered artificial intelligence can be broken down into two
aspects: (1) AI systems that understand humans from a sociocultural
perspective, and (2) AI systems that help humans understand them. We further
argue that issues of social responsibility such as fairness, accountability,
interpretability, and transparency.",2019-01-31T02:47:16Z,http://arxiv.org/pdf/1901.11184v1,['cs.AI']
2111.11295v1,"Artificial Intelligence Technology analysis using Artificial
  Intelligence patent through Deep Learning model and vector space model","['Yongmin Yoo', 'Dongjin Lim', 'Kyungsun Kim']","Thanks to rapid development of artificial intelligence technology in recent
years, the current artificial intelligence technology is contributing to many
part of society. Education, environment, medical care, military, tourism,
economy, politics, etc. are having a very large impact on society as a whole.
For example, in the field of education, there is an artificial intelligence
tutoring system that automatically assigns tutors based on student's level. In
the field of economics, there are quantitative investment methods that
automatically analyze large amounts of data to find investment laws to create
investment models or predict changes in financial markets. As such, artificial
intelligence technology is being used in various fields. So, it is very
important to know exactly what factors have an important influence on each
field of artificial intelligence technology and how the relationship between
each field is connected. Therefore, it is necessary to analyze artificial
intelligence technology in each field. In this paper, we analyze patent
documents related to artificial intelligence technology. We propose a method
for keyword analysis within factors using artificial intelligence patent data
sets for artificial intelligence technology analysis. This is a model that
relies on feature engineering based on deep learning model named KeyBERT, and
using vector space model. A case study of collecting and analyzing artificial
intelligence patent data was conducted to show how the proposed model can be
applied to real world problems.",2021-11-08T00:10:49Z,http://arxiv.org/pdf/2111.11295v1,"['cs.IR', 'cs.AI', 'cs.LG']"
0412215v1,Quantization of Games: Towards Quantum Artificial Intelligence,"['Katarzyna Miakisz', 'Edward W. Piotrowski', 'Jan Sladkowski']","On grounds of the discussed material, we reason about possible future
development of quantum game theory and its impact on information processing and
the emerging information society. The idea of quantum artificial intelligence
is explained.",2004-12-30T14:20:22Z,http://arxiv.org/pdf/quant-ph/0412215v1,['quant-ph']
2101.09163v6,The Next Decade of Telecommunications Artificial Intelligence,"['Ye Ouyang', 'Lilei Wang', 'Aidong Yang', 'Maulik Shah', 'David Belanger', 'Tongqing Gao', 'Leping Wei', 'Yaqin Zhang']","It has been an exciting journey since the mobile communications and
artificial intelligence were conceived 37 years and 64 years ago. While both
fields evolved independently and profoundly changed communications and
computing industries, the rapid convergence of 5G and deep learning is
beginning to significantly transform the core communication infrastructure,
network management and vertical applications. The paper first outlines the
individual roadmaps of mobile communications and artificial intelligence in the
early stage, with a concentration to review the era from 3G to 5G when AI and
mobile communications started to converge. With regard to telecommunications
artificial intelligence, the paper further introduces in detail the progress of
artificial intelligence in the ecosystem of mobile communications. The paper
then summarizes the classifications of AI in telecom ecosystems along with its
evolution paths specified by various international telecommunications
standardization bodies. Towards the next decade, the paper forecasts the
prospective roadmap of telecommunications artificial intelligence. In line with
3GPP and ITU-R timeline of 5G & 6G, the paper further explores the network
intelligence following 3GPP and ORAN routes respectively, experience and
intention driven network management and operation, network AI signalling
system, intelligent middle-office based BSS, intelligent customer experience
management and policy control driven by BSS and OSS convergence, evolution from
SLA to ELA, and intelligent private network for verticals. The paper is
concluded with the vision that AI will reshape the future B5G or 6G landscape
and we need pivot our R&D, standardizations, and ecosystem to fully take the
unprecedented opportunities.",2021-01-19T07:33:44Z,http://arxiv.org/pdf/2101.09163v6,"['cs.NI', 'cs.AI']"
2305.08112v1,Quantum Operation of Affective Artificial Intelligence,['V. I. Yukalov'],"The review analyzes the fundamental principles which Artificial Intelligence
should be based on in order to imitate the realistic process of taking
decisions by humans experiencing emotions. Two approaches are compared, one
based on quantum theory and the other employing classical terms. Both these
approaches have a number of similarities, being principally probabilistic. The
analogies between quantum measurements under intrinsic noise and affective
decision making are elucidated. It is shown that cognitive processes have many
features that are formally similar to quantum measurements. This, however, in
no way means that for the imitation of human decision making Affective
Artificial Intelligence has necessarily to rely on the functioning of quantum
systems. Appreciating the common features between quantum measurements and
decision making helps for the formulation of an axiomatic approach employing
only classical notions. Artificial Intelligence, following this approach,
operates similarly to humans, by taking into account the utility of the
considered alternatives as well as their emotional attractiveness. Affective
Artificial Intelligence, whose operation takes account of the cognition-emotion
duality, avoids numerous behavioural paradoxes of traditional decision making.
A society of intelligent agents, interacting through the repeated multistep
exchange of information, forms a network accomplishing dynamic decision making.
The considered intelligent networks can characterize the operation of either a
human society of affective decision makers, or the brain composed of neurons,
or a typical probabilistic network of an artificial intelligence.",2023-05-14T09:40:13Z,http://arxiv.org/pdf/2305.08112v1,"['cs.AI', 'q-bio.NC', 'quant-ph']"
0811.1711v1,Artificial Intelligence Techniques for Steam Generator Modelling,"['Sarah Wright', 'Tshilidzi Marwala']","This paper investigates the use of different Artificial Intelligence methods
to predict the values of several continuous variables from a Steam Generator.
The objective was to determine how the different artificial intelligence
methods performed in making predictions on the given dataset. The artificial
intelligence methods evaluated were Neural Networks, Support Vector Machines,
and Adaptive Neuro-Fuzzy Inference Systems. The types of neural networks
investigated were Multi-Layer Perceptions, and Radial Basis Function. Bayesian
and committee techniques were applied to these neural networks. Each of the AI
methods considered was simulated in Matlab. The results of the simulations
showed that all the AI methods were capable of predicting the Steam Generator
data reasonably accurately. However, the Adaptive Neuro-Fuzzy Inference system
out performed the other methods in terms of accuracy and ease of
implementation, while still achieving a fast execution time as well as a
reasonable training time.",2008-11-11T14:09:36Z,http://arxiv.org/pdf/0811.1711v1,['cs.AI']
1410.1054v1,Experimental Realization of Quantum Artificial Intelligence,"['Li Zhaokai', 'Liu Xiaomei', 'Xu Nanyang', 'Du jiangfeng']","Machines are possible to have some artificial intelligence like human beings
owing to particular algorithms or software. Such machines could learn knowledge
from what people taught them and do works according to the knowledge. In
practical learning cases, the data is often extremely complicated and large,
thus classical learning machines often need huge computational resources.
Quantum machine learning algorithm, on the other hand, could be exponentially
faster than classical machines using quantum parallelism. Here, we demonstrate
a quantum machine learning algorithm on a four-qubit NMR test bench to solve an
optical character recognition problem, also known as the handwriting
recognition. The quantum machine learns standard character fonts and then
recognize handwritten characters from a set with two candidates. To our best
knowledge, this is the first artificial intelligence realized on a quantum
processor. Due to the widespreading importance of artificial intelligence and
its tremendous consuming of computational resources, quantum speedup would be
extremely attractive against the challenges from the Big Data.",2014-10-04T15:55:56Z,http://arxiv.org/pdf/1410.1054v1,['quant-ph']
2407.10305v1,Elements Of Legislation For Artificial Intelligence Systems,['Anna Romanova'],"The significant part of the operational context for autonomous company
management systems is the regulatory and legal environment in which
corporations operate. In order to create a dedicated operational context for
autonomous artificial intelligence systems, the wording of local regulatory
documents can be simultaneously presented in two versions: for use by people
and for use by autonomous systems. In this case, the artificial intelligence
system will get a well-defined operational context that allows such a system to
perform functions within the required standards. Local regulations that provide
basis for the joint work of individuals and autonomous artificial intelligence
systems can form the grounds for the relevant legislation governing the
development and implementation of autonomous systems.",2024-05-05T11:01:31Z,http://arxiv.org/pdf/2407.10305v1,['cs.CY']
2404.15633v3,Artificial Intelligence for Multi-Unit Auction design,"['Peyman Khezr', 'Kendall Taylor']","Understanding bidding behavior in multi-unit auctions remains an ongoing
challenge for researchers. Despite their widespread use, theoretical insights
into the bidding behavior, revenue ranking, and efficiency of commonly used
multi-unit auctions are limited. This paper utilizes artificial intelligence,
specifically reinforcement learning, as a model free learning approach to
simulate bidding in three prominent multi-unit auctions employed in practice.
We introduce six algorithms that are suitable for learning and bidding in
multi-unit auctions and compare them using an illustrative example. This paper
underscores the significance of using artificial intelligence in auction
design, particularly in enhancing the design of multi-unit auctions.",2024-04-24T03:51:26Z,http://arxiv.org/pdf/2404.15633v3,"['cs.GT', 'cs.AI', 'econ.TH']"
1510.02867v3,Artificial Intelligence and Asymmetric Information Theory,"['Tshilidzi Marwala', 'Evan Hurwitz']","When human agents come together to make decisions, it is often the case that
one human agent has more information than the other. This phenomenon is called
information asymmetry and this distorts the market. Often if one human agent
intends to manipulate a decision in its favor the human agent can signal wrong
or right information. Alternatively, one human agent can screen for information
to reduce the impact of asymmetric information on decisions. With the advent of
artificial intelligence, signaling and screening have been made easier. This
paper studies the impact of artificial intelligence on the theory of asymmetric
information. It is surmised that artificial intelligent agents reduce the
degree of information asymmetry and thus the market where these agents are
deployed become more efficient. It is also postulated that the more artificial
intelligent agents there are deployed in the market the less is the volume of
trades in the market. This is because for many trades to happen the asymmetry
of information on goods and services to be traded should exist, creating a
sense of arbitrage.",2015-10-10T03:07:10Z,http://arxiv.org/pdf/1510.02867v3,['cs.AI']
1710.08191v1,Human-in-the-loop Artificial Intelligence,['Fabio Massimo Zanzotto'],"Little by little, newspapers are revealing the bright future that Artificial
Intelligence (AI) is building. Intelligent machines will help everywhere.
However, this bright future has a dark side: a dramatic job market contraction
before its unpredictable transformation. Hence, in a near future, large numbers
of job seekers will need financial support while catching up with these novel
unpredictable jobs. This possible job market crisis has an antidote inside. In
fact, the rise of AI is sustained by the biggest knowledge theft of the recent
years. Learning AI machines are extracting knowledge from unaware skilled or
unskilled workers by analyzing their interactions. By passionately doing their
jobs, these workers are digging their own graves.
  In this paper, we propose Human-in-the-loop Artificial Intelligence (HIT-AI)
as a fairer paradigm for Artificial Intelligence systems. HIT-AI will reward
aware and unaware knowledge producers with a different scheme: decisions of AI
systems generating revenues will repay the legitimate owners of the knowledge
used for taking those decisions. As modern Robin Hoods, HIT-AI researchers
should fight for a fairer Artificial Intelligence that gives back what it
steals.",2017-10-23T10:37:50Z,http://arxiv.org/pdf/1710.08191v1,"['cs.AI', 'I.2; I.2.6']"
1701.07103v1,Artificial Intelligence Approaches To UCAV Autonomy,"['Amir Husain', 'Bruce Porter']","This paper covers a number of approaches that leverage Artificial
Intelligence algorithms and techniques to aid Unmanned Combat Aerial Vehicle
(UCAV) autonomy. An analysis of current approaches to autonomous control is
provided followed by an exploration of how these techniques can be extended and
enriched with AI techniques including Artificial Neural Networks (ANN),
Ensembling and Reinforcement Learning (RL) to evolve control strategies for
UCAVs.",2017-01-24T23:11:15Z,http://arxiv.org/pdf/1701.07103v1,"['cs.AI', 'cs.RO']"
2105.05330v2,Neuro-Symbolic Artificial Intelligence: Current Trends,"['Md Kamruzzaman Sarker', 'Lu Zhou', 'Aaron Eberhart', 'Pascal Hitzler']","Neuro-Symbolic Artificial Intelligence -- the combination of symbolic methods
with methods that are based on artificial neural networks -- has a
long-standing history. In this article, we provide a structured overview of
current trends, by means of categorizing recent publications from key
conferences. The article is meant to serve as a convenient starting point for
research on the general topic.",2021-05-11T20:11:57Z,http://arxiv.org/pdf/2105.05330v2,"['cs.AI', 'cs.LG']"
2404.02611v3,X-SHIELD: Regularization for eXplainable Artificial Intelligence,"['Iván Sevillano-García', 'Julián Luengo', 'Francisco Herrera']","As artificial intelligence systems become integral across domains, the demand
for explainability grows, the called eXplainable artificial intelligence (XAI).
Existing efforts primarily focus on generating and evaluating explanations for
black-box models while a critical gap in directly enhancing models remains
through these evaluations. It is important to consider the potential of this
explanation process to improve model quality with a feedback on training as
well. XAI may be used to improve model performance while boosting its
explainability. Under this view, this paper introduces Transformation -
Selective Hidden Input Evaluation for Learning Dynamics (T-SHIELD), a
regularization family designed to improve model quality by hiding features of
input, forcing the model to generalize without those features. Within this
family, we propose the XAI - SHIELD(X-SHIELD), a regularization for explainable
artificial intelligence, which uses explanations to select specific features to
hide. In contrast to conventional approaches, X-SHIELD regularization
seamlessly integrates into the objective function enhancing model
explainability while also improving performance. Experimental validation on
benchmark datasets underscores X-SHIELD's effectiveness in improving
performance and overall explainability. The improvement is validated through
experiments comparing models with and without the X-SHIELD regularization, with
further analysis exploring the rationale behind its design choices. This
establishes X-SHIELD regularization as a promising pathway for developing
reliable artificial intelligence regularization.",2024-04-03T09:56:38Z,http://arxiv.org/pdf/2404.02611v3,"['cs.AI', 'I.2.6']"
1602.07259v1,Philosophical Fictionalism and Problem of Artificial Intelligence,['Sergey B. Kulikov'],"The artificial intelligence received broad interpretation as a literary
image. This approach did not have unambiguous refering to the scopes of logical
studies and mathematical investigations. An author applied methods peculiar to
the semiotic approach, offered by Boris Uspensky and Yury Lotman. In addition,
the article presented the criticism of modern versions of educational
technologies, which led to the unconditional expectations for possibilities of
information and telecommunication technologies. Methodological culture's
growth, which was described on the base of semiotics and functional approach to
word formation of new meanings for the description of the studied subjects,
provided the development of pupils' thought. As a result, the research opened
new prospects on understanding of artificial intelligence within educational
practice.",2016-02-23T18:32:41Z,http://arxiv.org/pdf/1602.07259v1,"['cs.OH', '00A30']"
1912.11945v1,On the Morality of Artificial Intelligence,"['Alexandra Luccioni', 'Yoshua Bengio']","Much of the existing research on the social and ethical impact of Artificial
Intelligence has been focused on defining ethical principles and guidelines
surrounding Machine Learning (ML) and other Artificial Intelligence (AI)
algorithms [IEEE, 2017, Jobin et al., 2019]. While this is extremely useful for
helping define the appropriate social norms of AI, we believe that it is
equally important to discuss both the potential and risks of ML and to inspire
the community to use ML for beneficial objectives. In the present article,
which is specifically aimed at ML practitioners, we thus focus more on the
latter, carrying out an overview of existing high-level ethical frameworks and
guidelines, but above all proposing both conceptual and practical principles
and guidelines for ML research and deployment, insisting on concrete actions
that can be taken by practitioners to pursue a more ethical and moral practice
of ML aimed at using AI for social good.",2019-12-26T23:06:54Z,http://arxiv.org/pdf/1912.11945v1,"['cs.CY', 'cs.AI']"
2001.01818v1,Artificial Intelligence for Social Good: A Survey,"['Zheyuan Ryan Shi', 'Claire Wang', 'Fei Fang']","Artificial intelligence for social good (AI4SG) is a research theme that aims
to use and advance artificial intelligence to address societal issues and
improve the well-being of the world. AI4SG has received lots of attention from
the research community in the past decade with several successful applications.
Building on the most comprehensive collection of the AI4SG literature to date
with over 1000 contributed papers, we provide a detailed account and analysis
of the work under the theme in the following ways. (1) We quantitatively
analyze the distribution and trend of the AI4SG literature in terms of
application domains and AI techniques used. (2) We propose three conceptual
methods to systematically group the existing literature and analyze the eight
AI4SG application domains in a unified framework. (3) We distill five research
topics that represent the common challenges in AI4SG across various application
domains. (4) We discuss five issues that, we hope, can shed light on the future
development of the AI4SG research.",2020-01-07T00:16:28Z,http://arxiv.org/pdf/2001.01818v1,"['cs.CY', 'cs.AI']"
2011.00111v2,Photonics for artificial intelligence and neuromorphic computing,"['Bhavin J. Shastri', 'Alexander N. Tait', 'Thomas Ferreira de Lima', 'Wolfram H. P. Pernice', 'Harish Bhaskaran', 'C. David Wright', 'Paul R. Prucnal']","Research in photonic computing has flourished due to the proliferation of
optoelectronic components on photonic integration platforms. Photonic
integrated circuits have enabled ultrafast artificial neural networks,
providing a framework for a new class of information processing machines.
Algorithms running on such hardware have the potential to address the growing
demand for machine learning and artificial intelligence, in areas such as
medical diagnosis, telecommunications, and high-performance and scientific
computing. In parallel, the development of neuromorphic electronics has
highlighted challenges in that domain, in particular, related to processor
latency. Neuromorphic photonics offers sub-nanosecond latencies, providing a
complementary opportunity to extend the domain of artificial intelligence.
Here, we review recent advances in integrated photonic neuromorphic systems,
discuss current and future challenges, and outline the advances in science and
technology needed to meet those challenges.",2020-10-30T21:41:44Z,http://arxiv.org/pdf/2011.00111v2,"['physics.optics', 'cs.NE', 'physics.app-ph']"
2003.00260v1,On Safety Assessment of Artificial Intelligence,"['Jens Braband', 'Hendrik Schäbe']","In this paper we discuss how systems with Artificial Intelligence (AI) can
undergo safety assessment. This is relevant, if AI is used in safety related
applications. Taking a deeper look into AI models, we show, that many models of
artificial intelligence, in particular machine learning, are statistical
models. Safety assessment would then have t o concentrate on the model that is
used in AI, besides the normal assessment procedure. Part of the budget of
dangerous random failures for the relevant safety integrity level needs to be
used for the probabilistic faulty behavior of the AI system. We demonstrate our
thoughts with a simple example and propose a research challenge that may be
decisive for the use of AI in safety related systems.",2020-02-29T14:05:28Z,http://arxiv.org/pdf/2003.00260v1,"['cs.AI', 'stat.ML']"
2012.10232v1,Artificial Intelligence ordered 3D vertex importance,"['Iva Vasic', 'Bata Vasic', 'Zorica Nikolic']","Ranking vertices of multidimensional networks is crucial in many areas of
research, including selecting and determining the importance of decisions. Some
decisions are significantly more important than others, and their weight
categorization is also imortant. This paper defines a completely new method for
determining the weight decisions using artificial intelligence for importance
ranking of three-dimensional network vertices, improving the existing Ordered
Statistics Vertex Extraction and Tracking Algorithm (OSVETA) based on
modulation of quantized indices (QIM) and error correction codes. The technique
we propose in this paper offers significant improvements the efficiency of
determination the importance of network vertices in relation to statistical
OSVETA criteria, replacing heuristic methods with methods of precise prediction
of modern neural networks. The new artificial intelligence technique enables a
significantly better definition of the 3D meshes and a better assessment of
their topological features. The new method contributions result in a greater
precision in defining stable vertices, significantly reducing the probability
of deleting mesh vertices.",2020-12-17T06:54:59Z,http://arxiv.org/pdf/2012.10232v1,['cs.AI']
2102.03061v1,Applications of Artificial Intelligence in Particle Radiotherapy,"['Chao Wu', 'Dan Nguyen', 'Jan Schuemann', 'Andrea Mairani', 'Yuehu Pu', 'Steve Jiang']","Radiotherapy, due to its technology-intensive nature and reliance on digital
data and human-machine interactions, is particularly suited to benefit from
artificial intelligence (AI) to improve the accuracy and efficiency of its
clinical workflow. Recently, various artificial intelligence (AI) methods have
been successfully developed to exploit the benefit of the inherent physical
properties of particle therapy. Many reviews about AI applications in
radiotherapy have already been published, but none were specifically dedicated
to particle therapy. In this article, we present a comprehensive review of the
recent published works on AI applications in particle therapy, which can be
classified into particle therapy treatment planning, adaptive particle therapy,
range and dose verification and other applications in particle therapy.
Although promising results reported in these works demonstrate how AI-based
methods can help exploit the intrinsic physic advantages of particle therapy,
challenges remained to be address before AI applications in particle therapy
enjoy widespread implementation in clinical practice.",2021-02-05T08:54:38Z,http://arxiv.org/pdf/2102.03061v1,['physics.med-ph']
2105.09484v1,Federated Artificial Intelligence for Unified Credit Assessment,"['Minh-Duc Hoang', 'Linh Le', 'Anh-Tuan Nguyen', 'Trang Le', 'Hoang D. Nguyen']","With the rapid adoption of Internet technologies, digital footprints have
become ubiquitous and versatile to revolutionise the financial industry in
digital transformation. This paper takes initiatives to investigate a new
paradigm of the unified credit assessment with the use of federated artificial
intelligence. We conceptualised digital human representation which consists of
social, contextual, financial and technological dimensions to assess the
commercial creditworthiness and social reputation of both banked and unbanked
individuals. A federated artificial intelligence platform is proposed with a
comprehensive set of system design for efficient and effective credit scoring.
The study considerably contributes to the cumulative development of financial
intelligence and social computing. It also provides a number of implications
for academic bodies, practitioners, and developers of financial technologies.",2021-05-20T03:05:42Z,http://arxiv.org/pdf/2105.09484v1,['cs.AI']
2312.12936v1,Concept-based Explainable Artificial Intelligence: A Survey,"['Eleonora Poeta', 'Gabriele Ciravegna', 'Eliana Pastor', 'Tania Cerquitelli', 'Elena Baralis']","The field of explainable artificial intelligence emerged in response to the
growing need for more transparent and reliable models. However, using raw
features to provide explanations has been disputed in several works lately,
advocating for more user-understandable explanations. To address this issue, a
wide range of papers proposing Concept-based eXplainable Artificial
Intelligence (C-XAI) methods have arisen in recent years. Nevertheless, a
unified categorization and precise field definition are still missing. This
paper fills the gap by offering a thorough review of C-XAI approaches. We
define and identify different concepts and explanation types. We provide a
taxonomy identifying nine categories and propose guidelines for selecting a
suitable category based on the development context. Additionally, we report
common evaluation strategies including metrics, human evaluations and dataset
employed, aiming to assist the development of future methods. We believe this
survey will serve researchers, practitioners, and domain experts in
comprehending and advancing this innovative field.",2023-12-20T11:27:21Z,http://arxiv.org/pdf/2312.12936v1,"['cs.AI', 'cs.HC']"
2401.06148v1,Artificial Intelligence for Digital and Computational Pathology,"['Andrew H. Song', 'Guillaume Jaume', 'Drew F. K. Williamson', 'Ming Y. Lu', 'Anurag Vaidya', 'Tiffany R. Miller', 'Faisal Mahmood']","Advances in digitizing tissue slides and the fast-paced progress in
artificial intelligence, including deep learning, have boosted the field of
computational pathology. This field holds tremendous potential to automate
clinical diagnosis, predict patient prognosis and response to therapy, and
discover new morphological biomarkers from tissue images. Some of these
artificial intelligence-based systems are now getting approved to assist
clinical diagnosis; however, technical barriers remain for their widespread
clinical adoption and integration as a research tool. This Review consolidates
recent methodological advances in computational pathology for predicting
clinical end points in whole-slide images and highlights how these developments
enable the automation of clinical practice and the discovery of new biomarkers.
We then provide future perspectives as the field expands into a broader range
of clinical and research tasks with increasingly diverse modalities of clinical
data.",2023-12-13T00:22:52Z,http://arxiv.org/pdf/2401.06148v1,"['eess.IV', 'cs.AI', 'cs.CV', 'q-bio.QM']"
2402.15011v2,A Conversational Brain-Artificial Intelligence Interface,"['Anja Meunier', 'Michal Robert Žák', 'Lucas Munz', 'Sofiya Garkot', 'Manuel Eder', 'Jiachen Xu', 'Moritz Grosse-Wentrup']","We introduce Brain-Artificial Intelligence Interfaces (BAIs) as a new class
of Brain-Computer Interfaces (BCIs). Unlike conventional BCIs, which rely on
intact cognitive capabilities, BAIs leverage the power of artificial
intelligence to replace parts of the neuro-cognitive processing pipeline. BAIs
allow users to accomplish complex tasks by providing high-level intentions,
while a pre-trained AI agent determines low-level details. This approach
enlarges the target audience of BCIs to individuals with cognitive impairments,
a population often excluded from the benefits of conventional BCIs. We present
the general concept of BAIs and illustrate the potential of this new approach
with a Conversational BAI based on EEG. In particular, we show in an experiment
with simulated phone conversations that the Conversational BAI enables complex
communication without the need to generate language. Our work thus
demonstrates, for the first time, the ability of a speech neuroprosthesis to
enable fluent communication in realistic scenarios with non-invasive
technologies.",2024-02-22T23:11:12Z,http://arxiv.org/pdf/2402.15011v2,"['cs.HC', 'cs.AI', 'eess.SP']"
2408.14811v1,Brain-inspired Artificial Intelligence: A Comprehensive Review,"['Jing Ren', 'Feng Xia']","Current artificial intelligence (AI) models often focus on enhancing
performance through meticulous parameter tuning and optimization techniques.
However, the fundamental design principles behind these models receive
comparatively less attention, which can limit our understanding of their
potential and constraints. This comprehensive review explores the diverse
design inspirations that have shaped modern AI models, i.e., brain-inspired
artificial intelligence (BIAI). We present a classification framework that
categorizes BIAI approaches into physical structure-inspired and human
behavior-inspired models. We also examine the real-world applications where
different BIAI models excel, highlighting their practical benefits and
deployment challenges. By delving into these areas, we provide new insights and
propose future research directions to drive innovation and address current gaps
in the field. This review offers researchers and practitioners a comprehensive
overview of the BIAI landscape, helping them harness its potential and expedite
advancements in AI development.",2024-08-27T06:49:50Z,http://arxiv.org/pdf/2408.14811v1,['cs.AI']
1911.01156v2,"AAAI FSS-19: Artificial Intelligence in Government and Public Sector
  Proceedings","['Frank Stein', 'Alun Preece']","Proceedings of the AAAI Fall Symposium on Artificial Intelligence in
Government and Public Sector, Arlington, Virginia, USA, November 7-8, 2019",2019-11-04T12:26:51Z,http://arxiv.org/pdf/1911.01156v2,['cs.AI']
2112.05614v1,"AAAI FSS-21: Artificial Intelligence in Government and Public Sector
  Proceedings","['Mihai Boicu', 'Erik Blasch', 'Alun Preece']","Proceedings of the AAAI Fall Symposium on Artificial Intelligence in
Government and Public Sector, Washington, DC, USA, November 4-6, 2021",2021-12-10T15:48:31Z,http://arxiv.org/pdf/2112.05614v1,['cs.AI']
0705.3360v1,The Road to Quantum Artificial Intelligence,['Kyriakos N. Sgarbas'],"This paper overviews the basic principles and recent advances in the emerging
field of Quantum Computation (QC), highlighting its potential application to
Artificial Intelligence (AI). The paper provides a very brief introduction to
basic QC issues like quantum registers, quantum gates and quantum algorithms
and then it presents references, ideas and research guidelines on how QC can be
used to deal with some basic AI problems, such as search and pattern matching,
as soon as quantum computers become widely available.",2007-05-23T12:31:47Z,http://arxiv.org/pdf/0705.3360v1,['cs.AI']
1907.07771v1,Classification Schemas for Artificial Intelligence Failures,"['Peter J. Scott', 'Roman V. Yampolskiy']","In this paper we examine historical failures of artificial intelligence (AI)
and propose a classification scheme for categorizing future failures. By doing
so we hope that (a) the responses to future failures can be improved through
applying a systematic classification that can be used to simplify the choice of
response and (b) future failures can be reduced through augmenting development
lifecycles with targeted risk assessments.",2019-07-15T16:05:44Z,http://arxiv.org/pdf/1907.07771v1,['cs.CY']
2305.12728v1,Diversity and Inclusion in Artificial Intelligence,"['Didar Zowghi', 'Francesca da Rimini']","To date, there has been little concrete practical advice about how to ensure
that diversity and inclusion considerations should be embedded within both
specific Artificial Intelligence (AI) systems and the larger global AI
ecosystem. In this chapter, we present a clear definition of diversity and
inclusion in AI, one which positions this concept within an evolving and
holistic ecosystem. We use this definition and conceptual framing to present a
set of practical guidelines primarily aimed at AI technologists, data
scientists and project leaders.",2023-05-22T05:33:34Z,http://arxiv.org/pdf/2305.12728v1,"['cs.AI', 'cs.SE']"
1806.10518v2,Autonomous Wireless Systems with Artificial Intelligence,['Haris Gacanin'],"This paper discusses technology and opportunities to embrace artificial
intelligence (AI) in the design of autonomous wireless systems. We aim to
provide readers with motivation and general AI methodology of autonomous agents
in the context of self-organization in real time by unifying knowledge
management with sensing, reasoning and active learning. We highlight
differences between training-based methods for matching problems and
training-free methods for environment-specific problems. Finally, we
conceptually introduce the functions of an autonomous agent with knowledge
management.",2018-06-27T15:02:08Z,http://arxiv.org/pdf/1806.10518v2,"['cs.NI', 'cs.AI']"
2111.02001v1,Certifiable Artificial Intelligence Through Data Fusion,"['Erik Blasch', 'Junchi Bin', 'Zheng Liu']","This paper reviews and proposes concerns in adopting, fielding, and
maintaining artificial intelligence (AI) systems. While the AI community has
made rapid progress, there are challenges in certifying AI systems. Using
procedures from design and operational test and evaluation, there are
opportunities towards determining performance bounds to manage expectations of
intended use. A notional use case is presented with image data fusion to
support AI object recognition certifiability considering precision versus
distance.",2021-11-03T03:34:19Z,http://arxiv.org/pdf/2111.02001v1,"['cs.AI', 'eess.IV']"
2111.09437v1,Sustainable Artificial Intelligence through Continual Learning,"['Andrea Cossu', 'Marta Ziosi', 'Vincenzo Lomonaco']","The increasing attention on Artificial Intelligence (AI) regulation has led
to the definition of a set of ethical principles grouped into the Sustainable
AI framework. In this article, we identify Continual Learning, an active area
of AI research, as a promising approach towards the design of systems compliant
with the Sustainable AI principles. While Sustainable AI outlines general
desiderata for ethical applications, Continual Learning provides means to put
such desiderata into practice.",2021-11-17T22:43:13Z,http://arxiv.org/pdf/2111.09437v1,"['cs.AI', 'cs.LG']"
2204.05579v1,Enriching Artificial Intelligence Explanations with Knowledge Fragments,"['Jože M. Rožanec', 'Elena Trajkova', 'Inna Novalija', 'Patrik Zajec', 'Klemen Kenda', 'Blaž Fortuna', 'Dunja Mladenić']","Artificial Intelligence models are increasingly used in manufacturing to
inform decision-making. Responsible decision-making requires accurate forecasts
and an understanding of the models' behavior. Furthermore, the insights into
models' rationale can be enriched with domain knowledge. This research builds
explanations considering feature rankings for a particular forecast, enriching
them with media news entries, datasets' metadata, and entries from the Google
Knowledge Graph. We compare two approaches (embeddings-based and
semantic-based) on a real-world use case regarding demand forecasting.",2022-04-12T07:19:30Z,http://arxiv.org/pdf/2204.05579v1,['cs.AI']
2307.13705v1,Control and Monitoring of Artificial Intelligence Algorithms,"['Carlos Mario Braga Ortuño', 'Blanca Martinez Donoso', 'Belén Muñiz Villanueva']","This paper elucidates the importance of governing an artificial intelligence
model post-deployment and overseeing potential fluctuations in the distribution
of present data in contrast to the training data. The concepts of data drift
and concept drift are explicated, along with their respective foundational
distributions. Furthermore, a range of metrics is introduced, which can be
utilized to scrutinize the model's performance concerning potential temporal
variations.",2023-07-24T10:16:11Z,http://arxiv.org/pdf/2307.13705v1,"['cs.LG', 'cs.AI', '62-01', 'G.3']"
2405.13462v1,Blockchain and Artificial Intelligence: Synergies and Conflicts,"['Leon Witt', 'Armando Teles Fortes', 'Kentaroh Toyoda', 'Wojciech Samek', 'Dan Li']","Blockchain technology and Artificial Intelligence (AI) have emerged as
transformative forces in their respective domains. This paper explores
synergies and challenges between these two technologies. Our research analyses
the biggest projects combining blockchain and AI, based on market
capitalization, and derives a novel framework to categorize contemporary and
future use cases. Despite the theoretical compatibility, current real-world
applications combining blockchain and AI remain in their infancy.",2024-05-22T09:04:52Z,http://arxiv.org/pdf/2405.13462v1,"['cs.AI', 'cs.CY', 'cs.DC']"
2505.17882v1,Formalizing Embeddedness Failures in Universal Artificial Intelligence,"['Cole Wyeth', 'Marcus Hutter']","We rigorously discuss the commonly asserted failures of the AIXI
reinforcement learning agent as a model of embedded agency. We attempt to
formalize these failure modes and prove that they occur within the framework of
universal artificial intelligence, focusing on a variant of AIXI that models
the joint action/percept history as drawn from the universal distribution. We
also evaluate the progress that has been made towards a successful theory of
embedded agency based on variants of the AIXI agent.",2025-05-23T13:31:28Z,http://arxiv.org/pdf/2505.17882v1,['cs.AI']
2506.14576v1,SoK: Privacy-Enhancing Technologies in Artificial Intelligence,['Nouha Oualha'],"As artificial intelligence (AI) continues to permeate various sectors,
safeguarding personal and sensitive data has become increasingly crucial. To
address these concerns, privacy-enhancing technologies (PETs) have emerged as a
suite of digital tools that enable data collection and processing while
preserving privacy. This paper explores the current landscape of data privacy
in the context of AI, reviews the integration of PETs within AI systems, and
assesses both their achievements and the challenges that remain.",2025-06-17T14:32:01Z,http://arxiv.org/pdf/2506.14576v1,['cs.CR']
2507.17020v1,Ethics through the Facets of Artificial Intelligence,['Flavio Soares Correa da Silva'],"Artificial Intelligence (AI) has received unprecedented attention in recent
years, raising ethical concerns about the development and use of AI technology.
In the present article, we advocate that these concerns stem from a blurred
understanding of AI, how it can be used, and how it has been interpreted in
society. We explore the concept of AI based on three descriptive facets and
consider ethical issues related to each facet. Finally, we propose a framework
for the ethical assessment of the use of AI.",2025-07-22T21:21:37Z,http://arxiv.org/pdf/2507.17020v1,['cs.CY']
1706.01040v1,Brain Intelligence: Go Beyond Artificial Intelligence,"['Huimin Lu', 'Yujie Li', 'Min Chen', 'Hyoungseop Kim', 'Seiichi Serikawa']","Artificial intelligence (AI) is an important technology that supports daily
social life and economic activities. It contributes greatly to the sustainable
growth of Japan's economy and solves various social problems. In recent years,
AI has attracted attention as a key for growth in developed countries such as
Europe and the United States and developing countries such as China and India.
The attention has been focused mainly on developing new artificial intelligence
information communication technology (ICT) and robot technology (RT). Although
recently developed AI technology certainly excels in extracting certain
patterns, there are many limitations. Most ICT models are overly dependent on
big data, lack a self-idea function, and are complicated. In this paper, rather
than merely developing next-generation artificial intelligence technology, we
aim to develop a new concept of general-purpose intelligence cognition
technology called Beyond AI. Specifically, we plan to develop an intelligent
learning model called Brain Intelligence (BI) that generates new ideas about
events without having experienced them by using artificial life with an imagine
function. We will also conduct demonstrations of the developed BI intelligence
learning model on automatic driving, precision medical care, and industrial
robots.",2017-06-04T08:16:03Z,http://arxiv.org/pdf/1706.01040v1,['cs.CV']
1709.01547v2,Knowledge Transfer Between Artificial Intelligence Systems,"['Ivan Y. Tyukin', 'Alexander N. Gorban', 'Konstantin Sofeikov', 'Ilya Romanenko']","We consider the fundamental question: how a legacy ""student"" Artificial
Intelligent (AI) system could learn from a legacy ""teacher"" AI system or a
human expert without complete re-training and, most importantly, without
requiring significant computational resources. Here ""learning"" is understood as
an ability of one system to mimic responses of the other and vice-versa. We
call such learning an Artificial Intelligence knowledge transfer. We show that
if internal variables of the ""student"" Artificial Intelligent system have the
structure of an $n$-dimensional topological vector space and $n$ is
sufficiently high then, with probability close to one, the required knowledge
transfer can be implemented by simple cascades of linear functionals. In
particular, for $n$ sufficiently large, with probability close to one, the
""student"" system can successfully and non-iteratively learn $k\ll n$ new
examples from the ""teacher"" (or correct the same number of mistakes) at the
cost of two additional inner products. The concept is illustrated with an
example of knowledge transfer from a pre-trained convolutional neural network
to a simple linear classifier with HOG features.",2017-09-05T18:38:07Z,http://arxiv.org/pdf/1709.01547v2,"['cs.AI', '68T05, 68T30']"
2111.00992v1,"Artificial Intelligence, Surveillance, and Big Data","['David Karpa', 'Torben Klarl', 'Michael Rochlitz']","The most important resource to improve technologies in the field of
artificial intelligence is data. Two types of policies are crucial in this
respect: privacy and data-sharing regulations, and the use of surveillance
technologies for policing. Both types of policies vary substantially across
countries and political regimes. In this chapter, we examine how authoritarian
and democratic political institutions can influence the quality of research in
artificial intelligence, and the availability of large-scale datasets to
improve and train deep learning algorithms. We focus mainly on the Chinese
case, and find that -- ceteris paribus -- authoritarian political institutions
continue to have a negative effect on innovation. They can, however, have a
positive effect on research in deep learning, via the availability of
large-scale datasets that have been obtained through government surveillance.
We propose a research agenda to study which of the two effects might dominate
in a race for leadership in artificial intelligence between countries with
different political institutions, such as the United States and China.",2021-11-01T14:57:13Z,http://arxiv.org/pdf/2111.00992v1,"['econ.GN', 'q-fin.EC']"
2404.03499v1,Comprehensible Artificial Intelligence on Knowledge Graphs: A survey,"['Simon Schramm', 'Christoph Wehner', 'Ute Schmid']","Artificial Intelligence applications gradually move outside the safe walls of
research labs and invade our daily lives. This is also true for Machine
Learning methods on Knowledge Graphs, which has led to a steady increase in
their application since the beginning of the 21st century. However, in many
applications, users require an explanation of the Artificial Intelligences
decision. This led to increased demand for Comprehensible Artificial
Intelligence. Knowledge Graphs epitomize fertile soil for Comprehensible
Artificial Intelligence, due to their ability to display connected data, i.e.
knowledge, in a human- as well as machine-readable way. This survey gives a
short history to Comprehensible Artificial Intelligence on Knowledge Graphs.
Furthermore, we contribute by arguing that the concept Explainable Artificial
Intelligence is overloaded and overlapping with Interpretable Machine Learning.
By introducing the parent concept Comprehensible Artificial Intelligence, we
provide a clear-cut distinction of both concepts while accounting for their
similarities. Thus, we provide in this survey a case for Comprehensible
Artificial Intelligence on Knowledge Graphs consisting of Interpretable Machine
Learning on Knowledge Graphs and Explainable Artificial Intelligence on
Knowledge Graphs. This leads to the introduction of a novel taxonomy for
Comprehensible Artificial Intelligence on Knowledge Graphs. In addition, a
comprehensive overview of the research on Comprehensible Artificial
Intelligence on Knowledge Graphs is presented and put into the context of the
taxonomy. Finally, research gaps in the field of Comprehensible Artificial
Intelligence on Knowledge Graphs are identified for future research.",2024-04-04T14:57:32Z,http://arxiv.org/pdf/2404.03499v1,['cs.AI']
2108.04770v1,"Examining correlation between trust and transparency with explainable
  artificial intelligence",['Arnav Kartikeya'],"Trust between humans and artificial intelligence(AI) is an issue which has
implications in many fields of human computer interaction. The current issue
with artificial intelligence is a lack of transparency into its decision
making, and literature shows that increasing transparency increases trust.
Explainable artificial intelligence has the ability to increase transparency of
AI, which could potentially increase trust for humans. This paper attempts to
use the task of predicting yelp review star ratings with assistance from an
explainable and non explainable artificial intelligence to see if trust is
increased with increased transparency. Results show that for these tasks,
explainable artificial intelligence provided significant increase in trust as a
measure of influence.",2021-08-10T16:24:30Z,http://arxiv.org/pdf/2108.04770v1,['cs.HC']
2105.06564v2,"Physical Artificial Intelligence: The Concept Expansion of
  Next-Generation Artificial Intelligence","['Yingbo Li', 'Yucong Duan', 'Anamaria-Beatrice Spulber', 'Haoyang Che', 'Zakaria Maamar', 'Zhao Li', 'Chen Yang', 'Yu lei']","Artificial Intelligence has been a growth catalyst to our society and is
cosidered across all idustries as a fundamental technology. However, its
development has been limited to the signal processing domain that relies on the
generated and collected data from other sensors. In recent research, concepts
of Digital Artificial Intelligence and Physicial Artifical Intelligence have
emerged and this can be considered a big step in the theoretical development of
Artifical Intelligence. In this paper we explore the concept of Physicial
Artifical Intelligence and propose two subdomains: Integrated Physicial
Artifical Intelligence and Distributed Physicial Artifical Intelligence. The
paper will also examine the trend and governance of Physicial Artifical
Intelligence.",2021-05-13T21:46:46Z,http://arxiv.org/pdf/2105.06564v2,['cs.AI']
1705.00594v2,A System for Accessible Artificial Intelligence,"['Randal S. Olson', 'Moshe Sipper', 'William La Cava', 'Sharon Tartarone', 'Steven Vitale', 'Weixuan Fu', 'Patryk Orzechowski', 'Ryan J. Urbanowicz', 'John H. Holmes', 'Jason H. Moore']","While artificial intelligence (AI) has become widespread, many commercial AI
systems are not yet accessible to individual researchers nor the general public
due to the deep knowledge of the systems required to use them. We believe that
AI has matured to the point where it should be an accessible technology for
everyone. We present an ongoing project whose ultimate goal is to deliver an
open source, user-friendly AI system that is specialized for machine learning
analysis of complex data in the biomedical and health care domains. We discuss
how genetic programming can aid in this endeavor, and highlight specific
examples where genetic programming has automated machine learning analyses in
previous projects.",2017-05-01T17:11:48Z,http://arxiv.org/pdf/1705.00594v2,"['cs.AI', 'cs.HC', 'cs.NE']"
1811.08792v2,Artificial Intelligence-Defined 5G Radio Access Networks,"['Miao Yao', 'Munawwar Sohul', 'Vuk Marojevic', 'Jeffrey H. Reed']","Massive multiple-input multiple-output antenna systems, millimeter wave
communications, and ultra-dense networks have been widely perceived as the
three key enablers that facilitate the development and deployment of 5G
systems. This article discusses the intelligent agent in 5G base station which
combines sensing, learning, understanding and optimizing to facilitate these
enablers. We present a flexible, rapidly deployable, and cross-layer artificial
intelligence (AI)-based framework to enable the imminent and future demands on
5G and beyond infrastructure. We present example AI-enabled 5G use cases that
accommodate important 5G-specific capabilities and discuss the value of AI for
enabling beyond 5G network evolution.",2018-11-21T15:44:10Z,http://arxiv.org/pdf/1811.08792v2,"['eess.SP', 'cs.AI']"
2006.00093v4,Explainable Artificial Intelligence: a Systematic Review,"['Giulia Vilone', 'Luca Longo']","Explainable Artificial Intelligence (XAI) has experienced a significant
growth over the last few years. This is due to the widespread application of
machine learning, particularly deep learning, that has led to the development
of highly accurate models but lack explainability and interpretability. A
plethora of methods to tackle this problem have been proposed, developed and
tested. This systematic review contributes to the body of knowledge by
clustering these methods with a hierarchical classification system with four
main clusters: review articles, theories and notions, methods and their
evaluation. It also summarises the state-of-the-art in XAI and recommends
future research directions.",2020-05-29T21:41:12Z,http://arxiv.org/pdf/2006.00093v4,"['cs.AI', 'cs.LG', 'I.2.0; I.2.6; I.2.m']"
1809.07842v1,Bias Amplification in Artificial Intelligence Systems,['Kirsten Lloyd'],"As Artificial Intelligence (AI) technologies proliferate, concern has
centered around the long-term dangers of job loss or threats of machines
causing harm to humans. All of this concern, however, detracts from the more
pertinent and already existing threats posed by AI today: its ability to
amplify bias found in training datasets, and swiftly impact marginalized
populations at scale. Government and public sector institutions have a
responsibility to citizens to establish a dialogue with technology developers
and release thoughtful policy around data standards to ensure diverse
representation in datasets to prevent bias amplification and ensure that AI
systems are built with inclusion in mind.",2018-09-20T20:29:56Z,http://arxiv.org/pdf/1809.07842v1,['cs.AI']
2010.14376v1,The DigitalTwin from an Artificial Intelligence Perspective,"['Oliver Niggemann', 'Alexander Diedrich', 'Christian Kuehnert', 'Erik Pfannstiel', 'Joshua Schraven']","Services for Cyber-Physical Systems based on Artificial Intelligence and
Machine Learning require a virtual representation of the physical. To reduce
modeling efforts and to synchronize results, for each system, a common and
unique virtual representation used by all services during the whole system
life-cycle is needed, i.e. a DigitalTwin. In this paper such a DigitalTwin,
namely the AI reference model AITwin, is defined. This reference model is
verified by using a running example from process industry and by analyzing the
work done in recent projects.",2020-10-27T15:40:36Z,http://arxiv.org/pdf/2010.14376v1,['cs.AI']
2011.13464v1,Meta-learning in natural and artificial intelligence,['Jane X. Wang'],"Meta-learning, or learning to learn, has gained renewed interest in recent
years within the artificial intelligence community. However, meta-learning is
incredibly prevalent within nature, has deep roots in cognitive science and
psychology, and is currently studied in various forms within neuroscience. The
aim of this review is to recast previous lines of research in the study of
biological intelligence within the lens of meta-learning, placing these works
into a common framework. More recent points of interaction between AI and
neuroscience will be discussed, as well as interesting new directions that
arise under this perspective.",2020-11-26T20:21:39Z,http://arxiv.org/pdf/2011.13464v1,['cs.AI']
2305.05092v1,Artificial Intelligence in 3GPP 5G-Advanced: A Survey,['Xingqin Lin'],"Industries worldwide are being transformed by artificial intelligence (AI),
and the telecom industry is no different. Standardization is critical for
industry alignment to achieve widespread adoption of AI in telecom. The 3rd
generation partnership project (3GPP) Release 18 is the first release of
5G-Advanced, which includes a diverse set of study and work items dedicated to
AI. This article provides a holistic overview of the state of the art in the
3GPP work on AI in 5G-Advanced, by presenting the various 3GPP Release-18
activities on AI as an organic whole, explaining in detail the design aspects,
and sharing various design rationales influencing standardization.",2023-05-08T23:32:23Z,http://arxiv.org/pdf/2305.05092v1,"['cs.NI', 'cs.AI']"
1902.02441v1,Artificial Intelligence for Prosthetics - challenge solutions,"['Łukasz Kidziński', 'Carmichael Ong', 'Sharada Prasanna Mohanty', 'Jennifer Hicks', 'Sean F. Carroll', 'Bo Zhou', 'Hongsheng Zeng', 'Fan Wang', 'Rongzhong Lian', 'Hao Tian', 'Wojciech Jaśkowski', 'Garrett Andersen', 'Odd Rune Lykkebø', 'Nihat Engin Toklu', 'Pranav Shyam', 'Rupesh Kumar Srivastava', 'Sergey Kolesnikov', 'Oleksii Hrinchuk', 'Anton Pechenko', 'Mattias Ljungström', 'Zhen Wang', 'Xu Hu', 'Zehong Hu', 'Minghui Qiu', 'Jun Huang', 'Aleksei Shpilman', 'Ivan Sosin', 'Oleg Svidchenko', 'Aleksandra Malysheva', 'Daniel Kudenko', 'Lance Rane', 'Aditya Bhatt', 'Zhengfei Wang', 'Penghui Qi', 'Zeyang Yu', 'Peng Peng', 'Quan Yuan', 'Wenxin Li', 'Yunsheng Tian', 'Ruihan Yang', 'Pingchuan Ma', 'Shauharda Khadka', 'Somdeb Majumdar', 'Zach Dwiel', 'Yinyin Liu', 'Evren Tumer', 'Jeremy Watson', 'Marcel Salathé', 'Sergey Levine', 'Scott Delp']","In the NeurIPS 2018 Artificial Intelligence for Prosthetics challenge,
participants were tasked with building a controller for a musculoskeletal model
with a goal of matching a given time-varying velocity vector. Top participants
were invited to describe their algorithms. In this work, we describe the
challenge and present thirteen solutions that used deep reinforcement learning
approaches. Many solutions use similar relaxations and heuristics, such as
reward shaping, frame skipping, discretization of the action space, symmetry,
and policy blending. However, each team implemented different modifications of
the known algorithms by, for example, dividing the task into subtasks, learning
low-level control, or by incorporating expert knowledge and using imitation
learning.",2019-02-07T01:17:17Z,http://arxiv.org/pdf/1902.02441v1,"['cs.LG', 'cs.RO', 'stat.ML']"
1906.05270v1,Artificial Intelligence Enabled Material Behavior Prediction,"['Timothy Hanlon', 'Johan Reimann', 'Monica A. Soare', 'Anjali Singhal', 'James Grande', 'Marc Edgar', 'Kareem S. Aggour', 'Joseph Vinciquerra']","Artificial Intelligence and Machine Learning algorithms have considerable
potential to influence the prediction of material properties. Additive
materials have a unique property prediction challenge in the form of surface
roughness effects on fatigue behavior of structural components. Traditional
approaches using finite element methods to calculate stress risers associated
with additively built surfaces have been challenging due to the computational
resources required, often taking over a day to calculate a single sample
prediction. To address this performance challenge, Deep Learning has been
employed to enable low cycle fatigue life prediction in additive materials in a
matter of seconds.",2019-06-12T17:52:30Z,http://arxiv.org/pdf/1906.05270v1,"['cs.LG', 'physics.app-ph']"
2007.00523v2,Drug discovery with explainable artificial intelligence,"['José Jiménez-Luna', 'Francesca Grisoni', 'Gisbert Schneider']","Deep learning bears promise for drug discovery, including advanced image
analysis, prediction of molecular structure and function, and automated
generation of innovative chemical entities with bespoke properties. Despite the
growing number of successful prospective applications, the underlying
mathematical models often remain elusive to interpretation by the human mind.
There is a demand for 'explainable' deep learning methods to address the need
for a new narrative of the machine language of the molecular sciences. This
review summarizes the most prominent algorithmic concepts of explainable
artificial intelligence, and dares a forecast of the future opportunities,
potential applications, and remaining challenges.",2020-07-01T14:36:23Z,http://arxiv.org/pdf/2007.00523v2,"['cs.AI', 'cs.LG', 'stat.ML']"
2208.09500v2,Causality-Inspired Taxonomy for Explainable Artificial Intelligence,"['Pedro C. Neto', 'Tiago Gonçalves', 'João Ribeiro Pinto', 'Wilson Silva', 'Ana F. Sequeira', 'Arun Ross', 'Jaime S. Cardoso']","As two sides of the same coin, causality and explainable artificial
intelligence (xAI) were initially proposed and developed with different goals.
However, the latter can only be complete when seen through the lens of the
causality framework. As such, we propose a novel causality-inspired framework
for xAI that creates an environment for the development of xAI approaches. To
show its applicability, biometrics was used as case study. For this, we have
analysed 81 research papers on a myriad of biometric modalities and different
tasks. We have categorised each of these methods according to our novel xAI
Ladder and discussed the future directions of the field.",2022-08-19T18:26:35Z,http://arxiv.org/pdf/2208.09500v2,['cs.CV']
2301.04751v1,Artificial Intelligence Generated Coins for Size Comparison,['Gerald Artner'],"Authors of scientific articles use coins in photographs as a size reference
for objects. For this purpose, coins are placed next to objects when taking the
photo. In this letter we propose a novel method that uses artificial
intelligence (AI) generated images of coins to provide a size reference in
photos. The newest generation is able to quickly generate realistic
high-quality images from textual descriptions. With the proposed method no
physical coin is required while taking photos. Coins can be added to photos
that contain none. Furthermore, we show how the coin motif can be matched to
the object.",2023-01-11T23:10:38Z,http://arxiv.org/pdf/2301.04751v1,['cs.CV']
2302.07081v2,Integrating Artificial Intelligence and Humanities in Healthcare,['Zohaib Tariq'],"Artificial Intelligence (AI) and Medical Humanities have become two of the
most crucial and rapidly growing fields in the current world. AI has made
substantial advancements in recent years, enabling the development of
algorithms and systems that can perform tasks traditionally done by humans.
Medical Humanities, on the other hand, is the intersection of medical sciences,
humanities, and the social sciences, and deals with the cultural, historical,
philosophical, ethical, and social aspects of health, illness, and medicine.
The integration of AI and Medical Humanities can offer innovative solutions to
some of the pressing issues in the medical field.",2023-02-13T10:48:48Z,http://arxiv.org/pdf/2302.07081v2,['cs.CY']
2308.02558v1,The Paradigm Shifts in Artificial Intelligence,['Vasant Dhar'],"Kuhn's framework of scientific progress (Kuhn, 1962) provides a useful
framing of the paradigm shifts that have occurred in Artificial Intelligence
over the last 60 years. The framework is also useful in understanding what is
arguably a new paradigm shift in AI, signaled by the emergence of large
pre-trained systems such as GPT-3, on which conversational agents such as
ChatGPT are based. Such systems make intelligence a commoditized general
purpose technology that is configurable to applications. In this paper, I
summarize the forces that led to the rise and fall of each paradigm, and
discuss the pressing issues and risks associated with the current paradigm
shift in AI.",2023-08-02T19:38:24Z,http://arxiv.org/pdf/2308.02558v1,"['cs.AI', 'I.2.0']"
2308.10921v1,Artificial intelligence-driven antimicrobial peptide discovery,"['Paulina Szymczak', 'Ewa Szczurek']","Antimicrobial peptides (AMPs) emerge as promising agents against
antimicrobial resistance, providing an alternative to conventional antibiotics.
Artificial intelligence (AI) revolutionized AMP discovery through both
discrimination and generation approaches. The discriminators aid the
identification of promising candidates by predicting key peptide properties
such as activity and toxicity, while the generators learn the distribution over
peptides and enable sampling novel AMP candidates, either de novo, or as
analogues of a prototype peptide. Moreover, the controlled generation of AMPs
with desired properties is achieved by discriminator-guided filtering,
positive-only learning, latent space sampling, as well as conditional and
optimized generation. Here we review recent achievements in AI-driven AMP
discovery, highlighting the most exciting directions.",2023-08-21T14:02:14Z,http://arxiv.org/pdf/2308.10921v1,"['q-bio.BM', 'cs.LG']"
2308.16377v1,Science Communications for Explainable Artificial Intelligence,"['Simon Hudson', 'Matija Franklin']","Artificial Intelligence (AI) has a communication problem. XAI methods have
been used to make AI more understandable and helped resolve some of the
transparency issues that inhibit AI's broader usability. However, user
evaluation studies reveal that the often numerical explanations provided by XAI
methods have not always been effective for many types of users of AI systems.
This article aims to adapt the major communications models from Science
Communications into a framework for practitioners to understand, influence, and
integrate the context of audiences both for their communications supporting AI
literacy in the public and in designing XAI systems that are more adaptive to
different users.",2023-08-31T00:39:33Z,http://arxiv.org/pdf/2308.16377v1,['cs.HC']
2311.09255v1,Artificial intelligence and the skill premium,"['David E. Bloom', 'Klaus Prettner', 'Jamel Saadaoui', 'Mario Veruete']","What will likely be the effect of the emergence of ChatGPT and other forms of
artificial intelligence (AI) on the skill premium? To address this question, we
develop a nested constant elasticity of substitution production function that
distinguishes between industrial robots and AI. Industrial robots predominantly
substitute for low-skill workers, whereas AI mainly helps to perform the tasks
of high-skill workers. We show that AI reduces the skill premium as long as it
is more substitutable for high-skill workers than low-skill workers are for
high-skill workers.",2023-11-14T20:16:55Z,http://arxiv.org/pdf/2311.09255v1,"['econ.TH', 'cs.AI', '34C60 (Primary)']"
2312.05481v12,Artificial Intelligence in the Knowledge Economy,"['Enrique Ide', 'Eduard Talamas']","Artificial Intelligence (AI) can transform the knowledge economy by
automating non-codifiable work. To analyze this transformation, we incorporate
AI into an economy where humans form hierarchical organizations: Less
knowledgeable individuals become ""workers"" doing routine work, while others
become ""solvers"" handling exceptions. We model AI as a technology that converts
computational resources into ""AI agents"" that operate autonomously (as
co-workers and solvers/co-pilots) or non-autonomously (solely as co-pilots).
Autonomous AI primarily benefits the most knowledgeable individuals;
non-autonomous AI benefits the least knowledgeable. However, output is higher
with autonomous AI. These findings reconcile contradictory empirical evidence
and reveal tradeoffs when regulating AI autonomy.",2023-12-09T06:59:55Z,http://arxiv.org/pdf/2312.05481v12,['econ.TH']
2402.13272v1,Spontaneous Theory of Mind for Artificial Intelligence,"['Nikolos Gurney', 'David V. Pynadath', 'Volkan Ustun']","Existing approaches to Theory of Mind (ToM) in Artificial Intelligence (AI)
overemphasize prompted, or cue-based, ToM, which may limit our collective
ability to develop Artificial Social Intelligence (ASI). Drawing from research
in computer science, cognitive science, and related disciplines, we contrast
prompted ToM with what we call spontaneous ToM -- reasoning about others'
mental states that is grounded in unintentional, possibly uncontrollable
cognitive functions. We argue for a principled approach to studying and
developing AI ToM and suggest that a robust, or general, ASI will respond to
prompts \textit{and} spontaneously engage in social reasoning.",2024-02-16T22:41:13Z,http://arxiv.org/pdf/2402.13272v1,"['cs.AI', 'cs.HC']"
2408.04609v1,Criticizing Ethics According to Artificial Intelligence,['Irina Spiegel'],"This article presents a critique of ethics in the context of artificial
intelligence (AI). It argues for the need to question established patterns of
thought and traditional authorities, including core concepts such as autonomy,
morality, and ethics. These concepts are increasingly inadequate to deal with
the complexities introduced by emerging AI and autonomous agents. This critique
has several key components: clarifying conceptual ambiguities, honestly
addressing epistemic issues, and thoroughly exploring fundamental normative
problems. The ultimate goal is to reevaluate and possibly redefine some
traditional ethical concepts to better address the challenges posed by AI.",2024-08-08T17:28:24Z,http://arxiv.org/pdf/2408.04609v1,['cs.CY']
2408.10726v1,Quantum Artificial Intelligence: A Brief Survey,"['Matthias Klusch', 'Jörg Lässig', 'Daniel Müssig', 'Antonio Macaluso', 'Frank K. Wilhelm']","Quantum Artificial Intelligence (QAI) is the intersection of quantum
computing and AI, a technological synergy with expected significant benefits
for both. In this paper, we provide a brief overview of what has been achieved
in QAI so far and point to some open questions for future research. In
particular, we summarize some major key findings on the feasability and the
potential of using quantum computing for solving computationally hard problems
in various subfields of AI, and vice versa, the leveraging of AI methods for
building and operating quantum computing devices.",2024-08-20T10:55:17Z,http://arxiv.org/pdf/2408.10726v1,"['quant-ph', 'cs.AI']"
2409.15903v1,Five questions and answers about artificial intelligence,"['Alberto Prieto', 'Beatriz Prieto']","Rapid advances in Artificial Intelligence (AI) are generating much
controversy in society, often without scientific basis. As occurred the
development of other emerging technologies, such as the introduction of
electricity in the early 20th century, AI causes both fascination and fear.
Following the advice of the philosopher R.W. Emerson's: advice the knowledge is
the antidote to fear; this paper seeks to contribute to the dissemination of
knowledge about AI. To this end, it reflects on the following questions: the
origins of AI, its possible future evolution, its ability to show feelings, the
associated threats and dangers, and the concept of AI singularity.",2024-09-24T09:19:55Z,http://arxiv.org/pdf/2409.15903v1,['cs.AI']
2507.05587v1,Towards Measurement Theory for Artificial Intelligence,['Elija Perrier'],"We motivate and outline a programme for a formal theory of measurement of
artificial intelligence. We argue that formalising measurement for AI will
allow researchers, practitioners, and regulators to: (i) make comparisons
between systems and the evaluation methods applied to them; (ii) connect
frontier AI evaluations with established quantitative risk analysis techniques
drawn from engineering and safety science; and (iii) foreground how what counts
as AI capability is contingent upon the measurement operations and scales we
elect to use. We sketch a layered measurement stack, distinguish direct from
indirect observables, and signpost how these ingredients provide a pathway
toward a unified, calibratable taxonomy of AI phenomena.",2025-07-08T01:52:37Z,http://arxiv.org/pdf/2507.05587v1,['cs.AI']
2508.11694v1,Music and Artificial Intelligence: Artistic Trends,"['Jordi Pons', 'Zack Zukowski', 'Julian D. Parker', 'CJ Carr', 'Josiah Taylor', 'Zach Evans']","We study how musicians use artificial intelligence (AI) across formats like
singles, albums, performances, installations, voices, ballets, operas, or
soundtracks. We collect 337 music artworks and categorize them based on AI
usage: AI composition, co-composition, sound design, lyrics generation, and
translation. We find that AI is employed as a co-creative tool, as an artistic
medium, and in live performances and installations. Innovative uses of AI
include exploring uncanny aesthetics, multilingual and multigenre song
releases, and new formats such as online installations. This research provides
a comprehensive overview of current AI music practices, offering insights into
emerging artistic trends and the challenges faced by AI musicians.",2025-08-12T18:12:02Z,http://arxiv.org/pdf/2508.11694v1,"['cs.CY', 'cs.SD', 'eess.AS']"
2509.14907v1,Artificial Intelligence and Market Entrant Game Developers,"['Seonbin Jo', 'Woo-Sung Jung', 'Jisung Yoon', 'Hyunuk Kim']","Artificial Intelligence (AI) is increasingly being used for generating
digital assets, such as programming codes and images. Games composed of various
digital assets are thus expected to be influenced significantly by AI.
Leveraging public data and AI disclosure statements of games, this paper shows
that relatively more independent developers entered the market when generative
AI became more publicly accessible, but their purposes of using AI are similar
with non-independent developers. Game features associated with AI hint nuanced
impacts of AI on independent developers.",2025-09-18T12:35:19Z,http://arxiv.org/pdf/2509.14907v1,['cs.CY']
1202.6153v1,One Decade of Universal Artificial Intelligence,['Marcus Hutter'],"The first decade of this century has seen the nascency of the first
mathematical theory of general artificial intelligence. This theory of
Universal Artificial Intelligence (UAI) has made significant contributions to
many theoretical, philosophical, and practical AI questions. In a series of
papers culminating in book (Hutter, 2005), an exciting sound and complete
mathematical model for a super intelligent agent (AIXI) has been developed and
rigorously analyzed. While nowadays most AI researchers avoid discussing
intelligence, the award-winning PhD thesis (Legg, 2008) provided the
philosophical embedding and investigated the UAI-based universal measure of
rational intelligence, which is formal, objective and non-anthropocentric.
Recently, effective approximations of AIXI have been derived and experimentally
investigated in JAIR paper (Veness et al. 2011). This practical breakthrough
has resulted in some impressive applications, finally muting earlier critique
that UAI is only a theory. For the first time, without providing any domain
knowledge, the same agent is able to self-adapt to a diverse range of
interactive environments. For instance, AIXI is able to learn from scratch to
play TicTacToe, Pacman, Kuhn Poker, and other games by trial and error, without
even providing the rules of the games.
  These achievements give new hope that the grand goal of Artificial General
Intelligence is not elusive.
  This article provides an informal overview of UAI in context. It attempts to
gently introduce a very theoretical, formal, and mathematical subject, and
discusses philosophical and technical ingredients, traits of intelligence, some
social questions, and the past and future of UAI.",2012-02-28T09:19:32Z,http://arxiv.org/pdf/1202.6153v1,['cs.AI']
1810.02688v2,Wikistat 2.0: Educational Resources for Artificial Intelligence,"['Philippe Besse', 'Brendan Guillouet', 'Béatrice Laurent']","Big data, data science, deep learning, artificial intelligence are the key
words of intense hype related with a job market in full evolution, that impose
to adapt the contents of our university professional trainings. Which
artificial intelligence is mostly concerned by the job offers? Which
methodologies and technologies should be favored in the training programs?
Which objectives, tools and educational resources do we needed to put in place
to meet these pressing needs? We answer these questions in describing the
contents and operational resources in the Data Science orientation of the
specialty Applied Mathematics at INSA Toulouse. We focus on basic mathematics
training (Optimization, Probability, Statistics), associated with the practical
implementation of the most performing statistical learning algorithms, with the
most appropriate technologies and on real examples. Considering the huge
volatility of the technologies, it is imperative to train students in
seft-training, this will be their technological watch tool when they will be in
professional activity. This explains the structuring of the educational site
github.com/wikistat into a set of tutorials. Finally, to motivate the thorough
practice of these tutorials, a serious game is organized each year in the form
of a prediction contest between students of Master degrees in Applied
Mathematics for IA.",2018-09-28T08:27:59Z,http://arxiv.org/pdf/1810.02688v2,"['cs.CY', 'cs.AI', 'math.ST', 'stat.ML', 'stat.TH']"
2101.03613v1,Explainable Artificial Intelligence (XAI): An Engineering Perspective,"['F. Hussain', 'R. Hussain', 'E. Hossain']","The remarkable advancements in Deep Learning (DL) algorithms have fueled
enthusiasm for using Artificial Intelligence (AI) technologies in almost every
domain; however, the opaqueness of these algorithms put a question mark on
their applications in safety-critical systems. In this regard, the
`explainability' dimension is not only essential to both explain the inner
workings of black-box algorithms, but it also adds accountability and
transparency dimensions that are of prime importance for regulators, consumers,
and service providers. eXplainable Artificial Intelligence (XAI) is the set of
techniques and methods to convert the so-called black-box AI algorithms to
white-box algorithms, where the results achieved by these algorithms and the
variables, parameters, and steps taken by the algorithm to reach the obtained
results, are transparent and explainable. To complement the existing literature
on XAI, in this paper, we take an `engineering' approach to illustrate the
concepts of XAI. We discuss the stakeholders in XAI and describe the
mathematical contours of XAI from engineering perspective. Then we take the
autonomous car as a use-case and discuss the applications of XAI for its
different components such as object detection, perception, control, action
decision, and so on. This work is an exploratory study to identify new avenues
of research in the field of XAI.",2021-01-10T19:49:12Z,http://arxiv.org/pdf/2101.03613v1,"['cs.LG', 'cs.AI']"
2101.09429v1,Explainable Artificial Intelligence Approaches: A Survey,"['Sheikh Rabiul Islam', 'William Eberle', 'Sheikh Khaled Ghafoor', 'Mohiuddin Ahmed']","The lack of explainability of a decision from an Artificial Intelligence (AI)
based ""black box"" system/model, despite its superiority in many real-world
applications, is a key stumbling block for adopting AI in many high stakes
applications of different domain or industry. While many popular Explainable
Artificial Intelligence (XAI) methods or approaches are available to facilitate
a human-friendly explanation of the decision, each has its own merits and
demerits, with a plethora of open challenges. We demonstrate popular XAI
methods with a mutual case study/task (i.e., credit default prediction),
analyze for competitive advantages from multiple perspectives (e.g., local,
global), provide meaningful insight on quantifying explainability, and
recommend paths towards responsible or human-centered AI using XAI as a medium.
Practitioners can use this work as a catalog to understand, compare, and
correlate competitive advantages of popular XAI methods. In addition, this
survey elicits future research directions towards responsible or human-centric
AI systems, which is crucial to adopt AI in high stakes applications.",2021-01-23T06:15:34Z,http://arxiv.org/pdf/2101.09429v1,"['cs.AI', 'cs.LG']"
1809.04797v1,Focus Group on Artificial Intelligence for Health,"['Marcel Salathé', 'Thomas Wiegand', 'Markus Wenzel']","Artificial Intelligence (AI) - the phenomenon of machines being able to solve
problems that require human intelligence - has in the past decade seen an
enormous rise of interest due to significant advances in effectiveness and use.
The health sector, one of the most important sectors for societies and
economies worldwide, is particularly interesting for AI applications, given the
ongoing digitalisation of all types of health information. The potential for AI
assistance in the health domain is immense, because AI can support medical
decision making at reduced costs, everywhere. However, due to the complexity of
AI algorithms, it is difficult to distinguish good from bad AI-based solutions
and to understand their strengths and weaknesses, which is crucial for
clarifying responsibilities and for building trust. For this reason, the
International Telecommunication Union (ITU) has established a new Focus Group
on ""Artificial Intelligence for Health"" (FG-AI4H) in partnership with the World
Health Organization (WHO). Health and care services are usually the
responsibility of a government - even when provided through private insurance
systems - and thus under the responsibility of WHO/ITU member states. FG-AI4H
will identify opportunities for international standardization, which will
foster the application of AI to health issues on a global scale. In particular,
it will establish a standardized assessment framework with open benchmarks for
the evaluation of AI-based methods for health, such as AI-based diagnosis,
triage or treatment decisions.",2018-09-13T06:46:34Z,http://arxiv.org/pdf/1809.04797v1,"['cs.AI', 'cs.CY']"
1912.00747v3,The Transformative Potential of Artificial Intelligence,"['Ross Gruetzemacher', 'Jess Whittlestone']","The terms 'human-level artificial intelligence' and 'artificial general
intelligence' are widely used to refer to the possibility of advanced
artificial intelligence (AI) with potentially extreme impacts on society. These
terms are poorly defined and do not necessarily indicate what is most important
with respect to future societal impacts. We suggest that the term
'transformative AI' is a helpful alternative, reflecting the possibility that
advanced AI systems could have very large impacts on society without reaching
human-level cognitive abilities. To be most useful, however, more analysis of
what it means for AI to be 'transformative' is needed. In this paper, we
propose three different levels on which AI might be said to be transformative,
associated with different levels of societal change. We suggest that these
distinctions would improve conversations between policy makers and decision
makers concerning the mid- to long-term impacts of advances in AI. Further, we
feel this would have a positive effect on strategic foresight efforts involving
advanced AI, which we expect to illuminate paths to alternative futures. We
conclude with a discussion of the benefits of our new framework and by
highlighting directions for future work in this area.",2019-11-27T09:37:58Z,http://arxiv.org/pdf/1912.00747v3,"['cs.CY', 'cs.AI']"
1912.06796v1,Artificial Intelligence Techniques for Security Vulnerability Prevention,['Steve Kommrusch'],"Computer security has been a concern for decades and artificial intelligence
techniques have been applied to the area for nearly as long. Most of the
techniques are being applied to the detection of attacks to running systems,
but recent improvements in machine learning (for example, in natural language
processing) have enabled the opportunity to process software and specifications
to detect vulnerabilities in a system before it is deployed. This paper
presents a survey of artificial intelligence techniques (including machine
learning) to detect or repair security vulnerabilities before product
introduction. In the surveyed papers, techniques are presented for using NLP to
analyze requirements documents for security standard completeness, performing
neural fuzz testing of software, generating exploits to detect risk, and more.
We categorize current techniques into 3 groups: vulnerability detection,
vulnerability repair, and specification analysis. Generally, while AI
techniques have become quite useful in this area, we show that AI techniques
still tend to be limited in scope, providing a collection of tools which can
augment but not replace careful system development to reduce vulnerability
risks.",2019-12-14T07:01:44Z,http://arxiv.org/pdf/1912.06796v1,['cs.CR']
2008.12629v1,Optical oxygen sensing with artificial intelligence,"['Umberto Michelucci', 'Michael Baumgartner', 'Francesca Venturini']","Luminescence-based sensors for measuring oxygen concentration are widely used
both in industry and research due to the practical advantages and sensitivity
of this type of sensing. The measuring principle is the luminescence quenching
by oxygen molecules, which results in a change of the luminescence decay time
and intensity. In the classical approach, this change is related to an oxygen
concentration using the Stern-Volmer equation. This equation, which in most of
the cases is non-linear, is parametrized through device-specific constants.
Therefore, to determine these parameters every sensor needs to be precisely
calibrated at one or more known concentrations. This work explores an entirely
new artificial intelligence approach and demonstrates the feasibility of oxygen
sensing through machine learning. The specifically developed neural network
learns very efficiently to relate the input quantities to the oxygen
concentration. The results show a mean deviation of the predicted from the
measured concentration of 0.5 percent air, comparable to many commercial and
low-cost sensors. Since the network was trained using synthetically generated
data, the accuracy of the model predictions is limited by the ability of the
generated data to describe the measured data, opening up future possibilities
for significant improvement by using a large number of experimental
measurements for training. The approach described in this work demonstrates the
applicability of artificial intelligence to sensing of sensors.",2020-07-27T20:59:38Z,http://arxiv.org/pdf/2008.12629v1,"['eess.SP', 'cs.LG']"
2204.05146v1,Artificial Intelligence Enabled Spectral Reconfigurable Fiber Laser,"['Yanli Zhang', 'Shanshan Wang', 'Mingzhu She', 'Weili Zhang']","The combinations of artificial intelligence and lasers provide powerful ways
to form smart light sources with ground-breaking functions. Here, a Raman fiber
laser (RFL) with reconfigurable and programmable spectra in an ultra-wide
bandwidth is developed based on spectral-spatial manipulation of light in
multimode fiber (MMF). The proposed fiber laser uses nonlinear gain from
cascaded stimulated Raman scattering, random distributed feedback from Rayleigh
scattering, and point feedback from an MMF-based smart spectral filter. Through
wavefront shaping controlled by a genetic algorithm, light of selective
wavelength(s) can be focused in the MMF, forming the filter that, together with
the active part of the laser, actively shape the output spectrum with a high
degree of freedom. We achieved arbitrary spectral shaping of the cascaded RFL
(e.g., continuously tunable single-wavelength and multi-wavelength laser with
customizable linewidth, mode separation, and power distribution) from the 1st-
to the 3rd-order Stokes emission by adjusting the pump power and
auto-optimization of the smart filter. Our research uses
artificial-intelligence controlled light manipulation in a fiber platform with
multi-eigenmodes and nonlinear gain, mapping the spatial control into the
spectral domain as well as extending the linear control of light in MMF to
active light emission, which is of great significance for applications in
optical communication, sensing, and spectroscopy.",2022-04-11T14:27:01Z,http://arxiv.org/pdf/2204.05146v1,"['physics.optics', 'cs.SY', 'eess.SY', 'physics.app-ph']"
2208.12120v1,Towards Benchmarking Explainable Artificial Intelligence Methods,['Lars Holmberg'],"The currently dominating artificial intelligence and machine learning
technology, neural networks, builds on inductive statistical learning. Neural
networks of today are information processing systems void of understanding and
reasoning capabilities, consequently, they cannot explain promoted decisions in
a humanly valid form. In this work, we revisit and use fundamental philosophy
of science theories as an analytical lens with the goal of revealing, what can
be expected, and more importantly, not expected, from methods that aim to
explain decisions promoted by a neural network. By conducting a case study we
investigate a selection of explainability method's performance over two mundane
domains, animals and headgear. Through our study, we lay bare that the
usefulness of these methods relies on human domain knowledge and our ability to
understand, generalise and reason. The explainability methods can be useful
when the goal is to gain further insights into a trained neural network's
strengths and weaknesses. If our aim instead is to use these explainability
methods to promote actionable decisions or build trust in ML-models they need
to be less ambiguous than they are today. In this work, we conclude from our
study, that benchmarking explainability methods, is a central quest towards
trustworthy artificial intelligence and machine learning.",2022-08-25T14:28:30Z,http://arxiv.org/pdf/2208.12120v1,"['cs.AI', 'cs.LG', 'I.2.6; I.2.4']"
2310.13192v3,The Opaque Law of Artificial Intelligence,['Vincenzo Calderonio'],"The purpose of this paper is to analyse the opacity of algorithms,
contextualized in the open debate on responsibility for artificial intelligence
causation; with an experimental approach by which, applying the proposed
conversational methodology of the Turing Test, we expect to evaluate the
performance of one of the best existing NLP model of generative AI (Chat-GPT)
to see how far it can go right now and how the shape of a legal regulation of
it could be. The analysis of the problem will be supported by a comment of
Italian classical law categories such as causality, intent and fault to
understand the problem of the usage of AI, focusing in particular on the
human-machine interaction. On the computer science side, for a technical point
of view of the logic used to craft these algorithms, in the second chapter will
be proposed a practical interrogation of Chat-GPT aimed at finding some
critical points of the functioning of AI. The end of the paper will concentrate
on some existing legal solutions which can be applied to the problem, plus a
brief description of the approach proposed by EU Artificial Intelligence act.",2023-10-19T23:02:46Z,http://arxiv.org/pdf/2310.13192v3,"['cs.AI', 'F.0; I.2; J.4; K.4; K.5']"
2402.18784v2,Brain-inspired and Self-based Artificial Intelligence,"['Yi Zeng', 'Feifei Zhao', 'Yuxuan Zhao', 'Dongcheng Zhao', 'Enmeng Lu', 'Qian Zhang', 'Yuwei Wang', 'Hui Feng', 'Zhuoya Zhao', 'Jihang Wang', 'Qingqun Kong', 'Yinqian Sun', 'Yang Li', 'Guobin Shen', 'Bing Han', 'Yiting Dong', 'Wenxuan Pan', 'Xiang He', 'Aorigele Bao', 'Jin Wang']","The question ""Can machines think?"" and the Turing Test to assess whether
machines could achieve human-level intelligence is one of the roots of AI. With
the philosophical argument ""I think, therefore I am"", this paper challenge the
idea of a ""thinking machine"" supported by current AIs since there is no sense
of self in them. Current artificial intelligence is only seemingly intelligent
information processing and does not truly understand or be subjectively aware
of oneself and perceive the world with the self as human intelligence does. In
this paper, we introduce a Brain-inspired and Self-based Artificial
Intelligence (BriSe AI) paradigm. This BriSe AI paradigm is dedicated to
coordinating various cognitive functions and learning strategies in a
self-organized manner to build human-level AI models and robotic applications.
Specifically, BriSe AI emphasizes the crucial role of the Self in shaping the
future AI, rooted with a practical hierarchical Self framework, including
Perception and Learning, Bodily Self, Autonomous Self, Social Self, and
Conceptual Self. The hierarchical framework of the Self highlights self-based
environment perception, self-bodily modeling, autonomous interaction with the
environment, social interaction and collaboration with others, and even more
abstract understanding of the Self. Furthermore, the positive mutual promotion
and support among multiple levels of Self, as well as between Self and
learning, enhance the BriSe AI's conscious understanding of information and
flexible adaptation to complex environments, serving as a driving force
propelling BriSe AI towards real Artificial General Intelligence.",2024-02-29T01:15:17Z,http://arxiv.org/pdf/2402.18784v2,"['cs.AI', 'q-bio.NC']"
2408.04999v1,MathPartner: An Artificial Intelligence Cloud Service,"['Gennadi Malaschonok', 'Alexandr Seliverstov']","In a broad sense, artificial intelligence is a service to find a solution to
complex intellectual problems. In this sense, the MathPartner service provides
artificial intelligence that allows us to formulate questions and receive
answers to questions formulated in a mathematical language. For mathematicians
and physicists today, such a language is \LaTeX. The MathPartner service uses a
dialect of \LaTeX, which is called Mathpar. The service is a cloud-based
computer algebra system and provides users with the opportunity to solve many
mathematical problems. In this publication, we focus only on a small class of
extremum problems, which are widely applied in economics, management,
logistics, and in many engineering fields. In particular, we consider the
shortest path problem and discuss an algorithm that is based on the tropical
mathematics. The ability to work with many types of classical and tropical
algebras, which are freely available to users, is an important distinguishing
feature of this intelligent tool for symbolic-numerical calculations. We also
consider the use of the simplex algorithm for solving optimization problems.",2024-08-09T11:19:01Z,http://arxiv.org/pdf/2408.04999v1,"['cs.SC', '68T01', 'F.4.1; F.2.2']"
2410.19998v1,Artificial Intelligence of Things: A Survey,"['Shakhrul Iman Siam', 'Hyunho Ahn', 'Li Liu', 'Samiul Alam', 'Hui Shen', 'Zhichao Cao', 'Ness Shroff', 'Bhaskar Krishnamachari', 'Mani Srivastava', 'Mi Zhang']","The integration of the Internet of Things (IoT) and modern Artificial
Intelligence (AI) has given rise to a new paradigm known as the Artificial
Intelligence of Things (AIoT). In this survey, we provide a systematic and
comprehensive review of AIoT research. We examine AIoT literature related to
sensing, computing, and networking & communication, which form the three key
components of AIoT. In addition to advancements in these areas, we review
domain-specific AIoT systems that are designed for various important
application domains. We have also created an accompanying GitHub repository,
where we compile the papers included in this survey:
https://github.com/AIoT-MLSys-Lab/AIoT-Survey. This repository will be actively
maintained and updated with new research as it becomes available. As both IoT
and AI become increasingly critical to our society, we believe AIoT is emerging
as an essential research field at the intersection of IoT and modern AI. We
hope this survey will serve as a valuable resource for those engaged in AIoT
research and act as a catalyst for future explorations to bridge gaps and drive
advancements in this exciting field.",2024-10-25T22:45:58Z,http://arxiv.org/pdf/2410.19998v1,"['cs.NI', 'cs.AI']"
2304.13269v4,Games for Artificial Intelligence Research: A Review and Perspectives,"['Chengpeng Hu', 'Yunlong Zhao', 'Ziqi Wang', 'Haocheng Du', 'Jialin Liu']","Games have been the perfect test-beds for artificial intelligence research
for the characteristics that widely exist in real-world scenarios. Learning and
optimisation, decision making in dynamic and uncertain environments, game
theory, planning and scheduling, design and education are common research areas
shared between games and real-world problems. Numerous open-source games or
game-based environments have been implemented for studying artificial
intelligence. In addition to single- or multi-player, collaborative or
adversarial games, there has also been growing interest in implementing
platforms for creative design in recent years. Those platforms provide ideal
benchmarks for exploring and comparing artificial intelligence ideas and
techniques. This paper reviews the games and game-based platforms for
artificial intelligence research, provides guidance on matching particular
types of artificial intelligence with suitable games for testing and matching
particular needs in games with suitable artificial intelligence techniques,
discusses the research trend induced by the evolution of those games and
platforms, and gives an outlook.",2023-04-26T03:42:31Z,http://arxiv.org/pdf/2304.13269v4,['cs.AI']
1810.06018v1,"AAAI FSS-18: Artificial Intelligence in Government and Public Sector
  Proceedings","['Frank Stein', 'Alun Preece', 'Mihai Boicu']","Proceedings of the AAAI Fall Symposium on Artificial Intelligence in
Government and Public Sector, Arlington, Virginia, USA, October 18-20, 2018",2018-10-14T11:40:30Z,http://arxiv.org/pdf/1810.06018v1,['cs.AI']
2011.04527v2,"AAAI FSS-20: Artificial Intelligence in Government and Public Sector
  Proceedings","['Frank Stein', 'Alun Preece']","Proceedings of the AAAI Fall Symposium on Artificial Intelligence in
Government and Public Sector, Washington, DC, USA, November 13-14, 2020",2020-11-09T16:08:42Z,http://arxiv.org/pdf/2011.04527v2,['cs.AI']
1301.6359v2,Subjective Reality and Strong Artificial Intelligence,['Alexander Serov'],"The main prospective aim of modern research related to Artificial
Intelligence is the creation of technical systems that implement the idea of
Strong Intelligence. According our point of view the path to the development of
such systems comes through the research in the field related to perceptions.
Here we formulate the model of the perception of external world which may be
used for the description of perceptual activity of intelligent beings. We
consider a number of issues related to the development of the set of patterns
which will be used by the intelligent system when interacting with environment.
The key idea of the presented perception model is the idea of subjective
reality. The principle of the relativity of perceived world is formulated. It
is shown that this principle is the immediate consequence of the idea of
subjective reality. In this paper we show how the methodology of subjective
reality may be used for the creation of different types of Strong AI systems.",2013-01-27T14:29:04Z,http://arxiv.org/pdf/1301.6359v2,['cs.AI']
1409.0813v2,Friendly Artificial Intelligence: the Physics Challenge,['Max Tegmark'],"Relentless progress in artificial intelligence (AI) is increasingly raising
concerns that machines will replace humans on the job market, and perhaps
altogether. Eliezer Yudkowski and others have explored the possibility that a
promising future for humankind could be guaranteed by a superintelligent
""Friendly AI"", designed to safeguard humanity and its values. I argue that,
from a physics perspective where everything is simply an arrangement of
elementary particles, this might be even harder than it appears. Indeed, it may
require thinking rigorously about the meaning of life: What is ""meaning"" in a
particle arrangement? What is ""life""? What is the ultimate ethical imperative,
i.e., how should we strive to rearrange the particles of our Universe and shape
its future? If we fail to answer the last question rigorously, this future is
unlikely to contain humans.",2014-09-02T18:20:28Z,http://arxiv.org/pdf/1409.0813v2,"['cs.CY', 'cs.AI']"
1606.00652v1,Death and Suicide in Universal Artificial Intelligence,"['Jarryd Martin', 'Tom Everitt', 'Marcus Hutter']","Reinforcement learning (RL) is a general paradigm for studying intelligent
behaviour, with applications ranging from artificial intelligence to psychology
and economics. AIXI is a universal solution to the RL problem; it can learn any
computable environment. A technical subtlety of AIXI is that it is defined
using a mixture over semimeasures that need not sum to 1, rather than over
proper probability measures. In this work we argue that the shortfall of a
semimeasure can naturally be interpreted as the agent's estimate of the
probability of its death. We formally define death for generally intelligent
agents like AIXI, and prove a number of related theorems about their behaviour.
Notable discoveries include that agent behaviour can change radically under
positive linear transformations of the reward signal (from suicidal to
dogmatically self-preserving), and that the agent's posterior belief that it
will survive increases over time.",2016-06-02T12:48:39Z,http://arxiv.org/pdf/1606.00652v1,"['cs.AI', 'I.2.0; I.2.6']"
1706.03021v1,Ethical Artificial Intelligence - An Open Question,"['Alice Pavaloiu', 'Utku Kose']","Artificial Intelligence (AI) is an effective science which employs strong
enough approaches, methods, and techniques to solve unsolvable real world based
problems. Because of its unstoppable rise towards the future, there are also
some discussions about its ethics and safety. Shaping an AI friendly
environment for people and a people friendly environment for AI can be a
possible answer for finding a shared context of values for both humans and
robots. In this context, objective of this paper is to address the ethical
issues of AI and explore the moral dilemmas that arise from ethical algorithms,
from pre set or acquired values. In addition, the paper will also focus on the
subject of AI safety. As general, the paper will briefly analyze the concerns
and potential solutions to solving the ethical issues presented and increase
readers awareness on AI safety as another related research interest.",2017-05-16T20:57:36Z,http://arxiv.org/pdf/1706.03021v1,"['cs.AI', 'cs.CY']"
1803.09992v1,Applications of Artificial Intelligence to Network Security,['Alberto Perez Veiga'],"Attacks to networks are becoming more complex and sophisticated every day.
Beyond the so-called script-kiddies and hacking newbies, there is a myriad of
professional attackers seeking to make serious profits infiltrating in
corporate networks. Either hostile governments, big corporations or mafias are
constantly increasing their resources and skills in cybercrime in order to spy,
steal or cause damage more effectively. traditional approaches to Network
Security seem to start hitting their limits and it is being recognized the need
for a smarter approach to threat detections. This paper provides an
introduction on the need for evolution of Cyber Security techniques and how
Artificial Intelligence could be of application to help solving some of the
problems. It provides also, a high-level overview of some state of the art AI
Network Security techniques, to finish analysing what is the foreseeable future
of the application of AI to Network Security.",2018-03-27T09:54:30Z,http://arxiv.org/pdf/1803.09992v1,"['cs.CR', 'cs.AI', 'cs.CY']"
1812.11509v2,AIR5: Five Pillars of Artificial Intelligence Research,"['Yew-Soon Ong', 'Abhishek Gupta']","In this article, we provide and overview of what we consider to be some of
the most pressing research questions facing the fields of artificial
intelligence (AI) and computational intelligence (CI); with the latter focusing
on algorithms that are inspired by various natural phenomena. We demarcate
these questions using five unique Rs - namely, (i) rationalizability, (ii)
resilience, (iii) reproducibility, (iv) realism, and (v) responsibility.
Notably, just as air serves as the basic element of biological life, the term
AIR5 - cumulatively referring to the five aforementioned Rs - is introduced
herein to mark some of the basic elements of artificial life (supporting the
sustained growth of AI and CI). A brief summary of each of the Rs is presented,
highlighting their relevance as pillars of future research in this arena.",2018-12-30T11:00:48Z,http://arxiv.org/pdf/1812.11509v2,['cs.AI']
2107.03721v4,Demystifying the Draft EU Artificial Intelligence Act,"['Michael Veale', 'Frederik Zuiderveen Borgesius']","In April 2021, the European Commission proposed a Regulation on Artificial
Intelligence, known as the AI Act. We present an overview of the Act and
analyse its implications, drawing on scholarship ranging from the study of
contemporary AI practices to the structure of EU product safety regimes over
the last four decades. Aspects of the AI Act, such as different rules for
different risk-levels of AI, make sense. But we also find that some provisions
of the Draft AI Act have surprising legal implications, whilst others may be
largely ineffective at achieving their stated goals. Several overarching
aspects, including the enforcement regime and the risks of maximum
harmonisation pre-empting legitimate national AI policy, engender significant
concern. These issues should be addressed as a priority in the legislative
process.",2021-07-08T10:04:07Z,http://arxiv.org/pdf/2107.03721v4,"['cs.CY', 'cs.AI', 'K.5.0; K.5.1']"
2107.06747v1,Artificial Intelligence in PET: an Industry Perspective,"['Arkadiusz Sitek', 'Sangtae Ahn', 'Evren Asma', 'Adam Chandler', 'Alvin Ihsani', 'Sven Prevrhal', 'Arman Rahmim', 'Babak Saboury', 'Kris Thielemans']","Artificial intelligence (AI) has significant potential to positively impact
and advance medical imaging, including positron emission tomography (PET)
imaging applications. AI has the ability to enhance and optimize all aspects of
the PET imaging chain from patient scheduling, patient setup, protocoling, data
acquisition, detector signal processing, reconstruction, image processing and
interpretation. AI poses industry-specific challenges which will need to be
addressed and overcome to maximize the future potentials of AI in PET. This
paper provides an overview of these industry-specific challenges for the
development, standardization, commercialization, and clinical adoption of AI,
and explores the potential enhancements to PET imaging brought on by AI in the
near future. In particular, the combination of on-demand image reconstruction,
AI, and custom designed data processing workflows may open new possibilities
for innovation which would positively impact the industry and ultimately
patients.",2021-07-14T14:47:24Z,http://arxiv.org/pdf/2107.06747v1,"['cs.CV', 'cs.AI']"
2107.13454v1,Artificial Intelligence in Healthcare: Lost In Translation?,"['Vince I. Madai', 'David C. Higgins']","Artificial intelligence (AI) in healthcare is a potentially revolutionary
tool to achieve improved healthcare outcomes while reducing overall health
costs. While many exploratory results hit the headlines in recent years there
are only few certified and even fewer clinically validated products available
in the clinical setting. This is a clear indication of failing translation due
to shortcomings of the current approach to AI in healthcare. In this work, we
highlight the major areas, where we observe current challenges for translation
in AI in healthcare, namely precision medicine, reproducible science, data
issues and algorithms, causality, and product development. For each field, we
outline possible solutions for these challenges. Our work will lead to improved
translation of AI in healthcare products into the clinical setting",2021-07-28T16:10:40Z,http://arxiv.org/pdf/2107.13454v1,['cs.AI']
2001.07038v4,Measuring Diversity of Artificial Intelligence Conferences,"['Ana Freire', 'Lorenzo Porcaro', 'Emilia Gómez']","The lack of diversity of the Artificial Intelligence (AI) field is nowadays a
concern, and several initiatives such as funding schemes and mentoring programs
have been designed to overcome it. However, there is no indication on how these
initiatives actually impact AI diversity in the short and long term. This work
studies the concept of diversity in this particular context and proposes a
small set of diversity indicators (i.e. indexes) of AI scientific events. These
indicators are designed to quantify the diversity of the AI field and monitor
its evolution. We consider diversity in terms of gender, geographical location
and business (understood as the presence of academia versus industry). We
compute these indicators for the different communities of a conference:
authors, keynote speakers and organizing committee. From these components we
compute a summarized diversity indicator for each AI event. We evaluate the
proposed indexes for a set of recent major AI conferences and we discuss their
values and limitations.",2020-01-20T10:09:50Z,http://arxiv.org/pdf/2001.07038v4,"['cs.DL', 'cs.AI', 'cs.CY']"
2104.13180v1,Controlling earthquake-like instabilities using artificial intelligence,"['Efthymios Papachristos', 'Ioannis Stefanou']","Earthquakes are lethal and costly. This study aims at avoiding these
catastrophic events by the application of injection policies retrieved through
reinforcement learning. With the rapid growth of artificial intelligence,
prediction-control problems are all the more tackled by function approximation
models that learn how to control a specific task, even for systems with
unmodeled/unknown dynamics and important uncertainties. Here, we show for the
first time the possibility of controlling earthquake-like instabilities using
state-of-the-art deep reinforcement learning techniques. The controller is
trained using a reduced model of the physical system, i.e, the spring-slider
model, which embodies the main dynamics of the physical problem for a given
earthquake magnitude. Its robustness to unmodeled dynamics is explored through
a parametric study. Our study is a first step towards minimizing seismicity in
industrial projects (geothermal energy, hydrocarbons production, CO2
sequestration) while, in a second step for inspiring techniques for natural
earthquakes control and prevention.",2021-04-27T13:39:58Z,http://arxiv.org/pdf/2104.13180v1,"['physics.geo-ph', 'cs.AI']"
1907.03848v1,Artificial Intelligence Governance and Ethics: Global Perspectives,"['Angela Daly', 'Thilo Hagendorff', 'Li Hui', 'Monique Mann', 'Vidushi Marda', 'Ben Wagner', 'Wei Wang', 'Saskia Witteborn']","Artificial intelligence (AI) is a technology which is increasingly being
utilised in society and the economy worldwide, and its implementation is
planned to become more prevalent in coming years. AI is increasingly being
embedded in our lives, supplementing our pervasive use of digital technologies.
But this is being accompanied by disquiet over problematic and dangerous
implementations of AI, or indeed, even AI itself deciding to do dangerous and
problematic actions, especially in fields such as the military, medicine and
criminal justice. These developments have led to concerns about whether and how
AI systems adhere, and will adhere to ethical standards. These concerns have
stimulated a global conversation on AI ethics, and have resulted in various
actors from different countries and sectors issuing ethics and governance
initiatives and guidelines for AI. Such developments form the basis for our
research in this report, combining our international and interdisciplinary
expertise to give an insight into what is happening in Australia, China,
Europe, India and the US.",2019-06-28T07:42:48Z,http://arxiv.org/pdf/1907.03848v1,"['cs.CY', 'cs.AI', 'cs.LG']"
1909.12063v1,Artificial Intelligence BlockCloud (AIBC) Technical Whitepaper,['Qi Deng'],"The AIBC is an Artificial Intelligence and blockchain technology based
large-scale decentralized ecosystem that allows system-wide low-cost sharing of
computing and storage resources. The AIBC consists of four layers: a
fundamental layer, a resource layer, an application layer, and an ecosystem
layer. The AIBC implements a two-consensus scheme to enforce upper-layer
economic policies and achieve fundamental layer performance and robustness: the
DPoEV incentive consensus on the application and resource layers, and the DABFT
distributed consensus on the fundamental layer. The DABFT uses deep learning
techniques to predict and select the most suitable BFT algorithm in order to
achieve the best balance of performance, robustness, and security. The DPoEV
uses the knowledge map algorithm to accurately assess the economic value of
digital assets.",2019-09-26T12:49:50Z,http://arxiv.org/pdf/1909.12063v1,"['cs.AI', 'cs.LG', 'q-fin.ST', 'stat.ML']"
2002.04087v2,"Human-Centered Artificial Intelligence: Reliable, Safe & Trustworthy",['Ben Shneiderman'],"Well-designed technologies that offer high levels of human control and high
levels of computer automation can increase human performance, leading to wider
adoption. The Human-Centered Artificial Intelligence (HCAI) framework clarifies
how to (1) design for high levels of human control and high levels of computer
automation so as to increase human performance, (2) understand the situations
in which full human control or full computer control are necessary, and (3)
avoid the dangers of excessive human control or excessive computer control. The
methods of HCAI are more likely to produce designs that are Reliable, Safe &
Trustworthy (RST). Achieving these goals will dramatically increase human
performance, while supporting human self-efficacy, mastery, creativity, and
responsibility.",2020-02-10T21:02:48Z,http://arxiv.org/pdf/2002.04087v2,"['cs.HC', 'cs.AI', 'H.5.0']"
2209.12618v1,Survey on Applications of Neurosymbolic Artificial Intelligence,"['Djallel Bouneffouf', 'Charu C. Aggarwal']","In recent years, the Neurosymbolic framework has attracted a lot of attention
in various applications, from recommender systems and information retrieval to
healthcare and finance. This success is due to its stellar performance combined
with attractive properties, such as learning and reasoning. The new emerging
Neurosymbolic field is currently experiencing a renaissance, as novel
frameworks and algorithms motivated by various practical applications are being
introduced, building on top of the classical neural and reasoning problem
setting. This article aims to provide a comprehensive review of significant
recent developments in real-world applications of Neurosymbolic Artificial
Intelligence. Specifically, we introduce a taxonomy of common Neurosymbolic
applications and summarize the state-of-the-art for each of those domains.
Furthermore, we identify important current trends and provide new perspectives
pertaining to the future of this burgeoning field.",2022-09-08T18:18:41Z,http://arxiv.org/pdf/2209.12618v1,"['cs.AI', 'cs.SC']"
2305.11897v2,Critical Appraisal of Artificial Intelligence-Mediated Communication,['Dara Tafazoli'],"Over the last two decades, technology use in language learning and teaching
has significantly advanced and is now referred to as Computer-Assisted Language
Learning (CALL). Recently, the integration of Artificial Intelligence (AI) into
CALL has brought about a significant shift in the traditional approach to
language education both inside and outside the classroom. In line with this
book's scope, I explore the advantages and disadvantages of AI-mediated
communication in language education. I begin with a brief review of AI in
education. I then introduce the ICALL and give a critical appraisal of the
potential of AI-powered automatic speech recognition (ASR), Machine Translation
(MT), Intelligent Tutoring Systems (ITSs), AI-powered chatbots, and Extended
Reality (XR). In conclusion, I argue that it is crucial for language teachers
to engage in CALL teacher education and professional development to keep up
with the ever-evolving technology landscape and improve their teaching
effectiveness.",2023-05-15T02:35:40Z,http://arxiv.org/pdf/2305.11897v2,"['cs.HC', 'cs.AI']"
2008.07341v1,"Data, Power and Bias in Artificial Intelligence","['Susan Leavy', ""Barry O'Sullivan"", 'Eugenia Siapera']","Artificial Intelligence has the potential to exacerbate societal bias and set
back decades of advances in equal rights and civil liberty. Data used to train
machine learning algorithms may capture social injustices, inequality or
discriminatory attitudes that may be learned and perpetuated in society.
Attempts to address this issue are rapidly emerging from different perspectives
involving technical solutions, social justice and data governance measures.
While each of these approaches are essential to the development of a
comprehensive solution, often discourse associated with each seems disparate.
This paper reviews ongoing work to ensure data justice, fairness and bias
mitigation in AI systems from different domains exploring the interrelated
dynamics of each and examining whether the inevitability of bias in AI training
data may in fact be used for social good. We highlight the complexity
associated with defining policies for dealing with bias. We also consider
technical challenges in addressing issues of societal bias.",2020-07-28T16:17:40Z,http://arxiv.org/pdf/2008.07341v1,['cs.CY']
2105.10866v1,Towards Artificial Intelligence Enabled Financial Crime Detection,['Zeinab Rouhollahi'],"Recently, financial institutes have been dealing with an increase in
financial crimes. In this context, financial services firms started to improve
their vigilance and use new technologies and approaches to identify and predict
financial fraud and crime possibilities. This task is challenging as
institutions need to upgrade their data and analytics capabilities to enable
new technologies such as Artificial Intelligence (AI) to predict and detect
financial crimes. In this paper, we put a step towards AI-enabled financial
crime detection in general and money laundering detection in particular to
address this challenge. We study and analyse the recent works done in financial
crime detection and present a novel model to detect money laundering cases with
minimum human intervention needs.",2021-05-23T06:57:25Z,http://arxiv.org/pdf/2105.10866v1,"['cs.LG', 'cs.IR', 'q-fin.ST']"
2110.02007v3,Empowering Local Communities Using Artificial Intelligence,"['Yen-Chia Hsu', ""Ting-Hao 'Kenneth' Huang"", 'Himanshu Verma', 'Andrea Mauri', 'Illah Nourbakhsh', 'Alessandro Bozzon']","Artificial Intelligence (AI) is increasingly used to analyze large amounts of
data in various practices, such as object recognition. We are specifically
interested in using AI-powered systems to engage local communities in
developing plans or solutions for pressing societal and environmental concerns.
Such local contexts often involve multiple stakeholders with different and even
contradictory agendas, resulting in mismatched expectations of these systems'
behaviors and desired outcomes. There is a need to investigate if AI models and
pipelines can work as expected in different contexts through co-creation and
field deployment. Based on case studies in co-creating AI-powered systems with
local people, we explain challenges that require more attention and provide
viable paths to bridge AI research with citizen needs. We advocate for
developing new collaboration approaches and mindsets that are needed to
co-create AI-powered systems in multi-stakeholder contexts to address local
concerns.",2021-10-05T12:51:11Z,http://arxiv.org/pdf/2110.02007v3,"['cs.AI', 'cs.HC']"
2112.09325v2,Dilemma of the Artificial Intelligence Regulatory Landscape,"['Weiyue Wu', 'Shaoshan Liu']","As a startup company in the autonomous driving space, we have undergone four
years of painful experiences dealing with a broad spectrum of regulatory
requirements. Compared to the software industry norm, which spends 13% of their
overall budget on compliances, we were forced to spend 42% of our budget on
compliances. Our situation is not alone and, in a way, reflects the dilemma of
the artificial intelligence (AI) regulatory landscape. The root cause is the
lack of AI expertise in the legislative and executive branches, leading to a
lack of standardization for the industry to follow. In this article, we share
our first-hand experiences and advocate for the establishment of an FDA-like
agency to regulate AI properly.",2021-12-17T05:10:31Z,http://arxiv.org/pdf/2112.09325v2,"['cs.CY', 'cs.AI']"
2201.08789v1,AiTLAS: Artificial Intelligence Toolbox for Earth Observation,"['Ivica Dimitrovski', 'Ivan Kitanovski', 'Panče Panov', 'Nikola Simidjievski', 'Dragi Kocev']","The AiTLAS toolbox (Artificial Intelligence Toolbox for Earth Observation)
includes state-of-the-art machine learning methods for exploratory and
predictive analysis of satellite imagery as well as repository of AI-ready
Earth Observation (EO) datasets. It can be easily applied for a variety of
Earth Observation tasks, such as land use and cover classification, crop type
prediction, localization of specific objects (semantic segmentation), etc. The
main goal of AiTLAS is to facilitate better usability and adoption of novel AI
methods (and models) by EO experts, while offering easy access and standardized
format of EO datasets to AI experts which further allows benchmarking of
various existing and novel AI methods tailored for EO data.",2022-01-21T17:10:14Z,http://arxiv.org/pdf/2201.08789v1,['cs.CV']
2206.11187v1,Automated Compliance Blueprint Optimization with Artificial Intelligence,"['Abdulhamid Adebayo', 'Daby Sow', 'Muhammed Fatih Bulut']","For highly regulated industries such as banking and healthcare, one of the
major hindrances to the adoption of cloud computing is compliance with
regulatory standards. This is a complex problem due to many regulatory and
technical specification (techspec) documents that the companies need to comply
with. The critical problem is to establish the mapping between techspecs and
regulation controls so that from day one, companies can comply with regulations
with minimal effort. We demonstrate the practicality of an approach to
automatically analyze regulatory standards using Artificial Intelligence (AI)
techniques. We present early results to identify the mapping between techspecs
and regulation controls, and discuss challenges that must be overcome for this
solution to be fully practical.",2022-06-22T15:59:16Z,http://arxiv.org/pdf/2206.11187v1,"['cs.AI', 'cs.CR']"
2210.05103v1,Leveraging Artificial Intelligence on Binary Code Comprehension,['Yifan Zhang'],"Understanding binary code is an essential but complex software engineering
task for reverse engineering, malware analysis, and compiler optimization.
Unlike source code, binary code has limited semantic information, which makes
it challenging for human comprehension. At the same time, compiling source to
binary code, or transpiling among different programming languages (PLs) can
provide a way to introduce external knowledge into binary comprehension. We
propose to develop Artificial Intelligence (AI) models that aid human
comprehension of binary code. Specifically, we propose to incorporate domain
knowledge from large corpora of source code (e.g., variable names, comments) to
build AI models that capture a generalizable representation of binary code.
Lastly, we will investigate metrics to assess the performance of models that
apply to binary code by using human studies of comprehension.",2022-10-11T02:39:29Z,http://arxiv.org/pdf/2210.05103v1,"['cs.SE', 'cs.AI']"
2301.05864v1,Recent advances in artificial intelligence for retrosynthesis,"['Zipeng Zhong', 'Jie Song', 'Zunlei Feng', 'Tiantao Liu', 'Lingxiang Jia', 'Shaolun Yao', 'Tingjun Hou', 'Mingli Song']","Retrosynthesis is the cornerstone of organic chemistry, providing chemists in
material and drug manufacturing access to poorly available and brand-new
molecules. Conventional rule-based or expert-based computer-aided synthesis has
obvious limitations, such as high labor costs and limited search space. In
recent years, dramatic breakthroughs driven by artificial intelligence have
revolutionized retrosynthesis. Here we aim to present a comprehensive review of
recent advances in AI-based retrosynthesis. For single-step and multi-step
retrosynthesis both, we first list their goal and provide a thorough taxonomy
of existing methods. Afterwards, we analyze these methods in terms of their
mechanism and performance, and introduce popular evaluation metrics for them,
in which we also provide a detailed comparison among representative methods on
several public datasets. In the next part we introduce popular databases and
established platforms for retrosynthesis. Finally, this review concludes with a
discussion about promising research directions in this field.",2023-01-14T09:29:39Z,http://arxiv.org/pdf/2301.05864v1,"['cs.LG', 'physics.chem-ph', 'q-bio.BM']"
2303.12732v1,Unfinished Architectures: A Perspective from Artificial Intelligence,"['Elena Merino-Gómez', 'Pedro Reviriego', 'Fernando Moral']","Unfinished buildings are a constant throughout the history of architecture
and have given rise to intense debates on the opportuneness of their
completion, in addition to offering alibis for theorizing about the
compositional possibilities in coherence with the finished parts. The
development of Artificial Intelligence (AI) opens new avenues for the proposal
of possibilities for the completion of unfinished architectures. Specifically,
with the recent appearance of tools such as DALL-E, capable of completing
images guided by a textual description, it is possible to count on the help of
AI for architectural design tasks. In this article we explore the use of these
new AI tools for the completion of unfinished facades of historical temples and
analyse the still germinal stadium in the field of architectural graphic
composition.",2023-03-03T13:05:10Z,http://arxiv.org/pdf/2303.12732v1,"['cs.CV', 'cs.AI']"
2306.01495v1,Accelerating science with human-aware artificial intelligence,"['Jamshid Sourati', 'James Evans']","Artificial intelligence (AI) models trained on published scientific findings
have been used to invent valuable materials and targeted therapies, but they
typically ignore the human scientists who continually alter the landscape of
discovery. Here we show that incorporating the distribution of human expertise
by training unsupervised models on simulated inferences cognitively accessible
to experts dramatically improves (up to 400%) AI prediction of future
discoveries beyond those focused on research content alone, especially when
relevant literature is sparse. These models succeed by predicting human
predictions and the scientists who will make them. By tuning human-aware AI to
avoid the crowd, we can generate scientifically promising ""alien"" hypotheses
unlikely to be imagined or pursued without intervention until the distant
future, which hold promise to punctuate scientific advance beyond questions
currently pursued. Accelerating human discovery or probing its blind spots,
human-aware AI enables us to move toward and beyond the contemporary scientific
frontier.",2023-06-02T12:43:23Z,http://arxiv.org/pdf/2306.01495v1,"['cs.AI', 'cs.SI']"
2310.20474v1,Critical Role of Artificially Intelligent Conversational Chatbot,"['Seraj A. M. Mostafa', 'Md Z. Islam', 'Mohammad Z. Islam', 'Fairose Jeehan', 'Saujanna Jafreen', 'Raihan U. Islam']","Artificially intelligent chatbot, such as ChatGPT, represents a recent and
powerful advancement in the AI domain. Users prefer them for obtaining quick
and precise answers, avoiding the usual hassle of clicking through multiple
links in traditional searches. ChatGPT's conversational approach makes it
comfortable and accessible for finding answers quickly and in an organized
manner. However, it is important to note that these chatbots have limitations,
especially in terms of providing accurate answers as well as ethical concerns.
In this study, we explore various scenarios involving ChatGPT's ethical
implications within academic contexts, its limitations, and the potential
misuse by specific user groups. To address these challenges, we propose
architectural solutions aimed at preventing inappropriate use and promoting
responsible AI interactions.",2023-10-31T14:08:07Z,http://arxiv.org/pdf/2310.20474v1,['cs.AI']
2403.08802v4,Governance of Generative Artificial Intelligence for Companies,"['Johannes Schneider', 'Pauline Kuss', 'Rene Abraham', 'Christian Meske']","Generative Artificial Intelligence (GenAI), specifically large language
models(LLMs) like ChatGPT, has swiftly entered organizations without adequate
governance, posing both opportunities and risks. Despite extensive debates on
GenAI's transformative nature and regulatory measures, limited research
addresses organizational governance, encompassing technical and business
perspectives. Although numerous frameworks for governance of AI exist, it is
not clear to what extent they apply to GenAI. Our review paper fills this gap
by surveying recent works with the purpose of better understanding fundamental
characteristics of GenAI and adjusting prior frameworks specifically towards
GenAI governance within companies. To do so, it extends Nickerson's framework
development processes to include prior conceptualizations. Our framework
outlines the scope, objectives, and governance mechanisms tailored to harness
business opportunities as well as mitigate risks associated with GenAI
integration. Our research contributes a focused approach to GenAI governance,
offering practical insights for companies navigating the challenges of GenAI
adoption and highlighting research gaps.",2024-02-05T14:20:19Z,http://arxiv.org/pdf/2403.08802v4,"['cs.AI', 'cs.CY', 'cs.LG', 'I.2.m']"
2406.10653v1,Justice in Healthcare Artificial Intelligence in Africa,"['Aloysius Ochasi', 'Abdoul Jalil Djiberou Mahamadou', 'Russ B. Altman']","There is an ongoing debate on balancing the benefits and risks of artificial
intelligence (AI) as AI is becoming critical to improving healthcare delivery
and patient outcomes. Such improvements are essential in resource-constrained
settings where millions lack access to adequate healthcare services, such as in
Africa. AI in such a context can potentially improve the effectiveness,
efficiency, and accessibility of healthcare services. Nevertheless, the
development and use of AI-driven healthcare systems raise numerous ethical,
legal, and socio-economic issues. Justice is a major concern in AI that has
implications for amplifying social inequities. This paper discusses these
implications and related justice concepts such as solidarity, Common Good,
sustainability, AI bias, and fairness. For Africa to effectively benefit from
AI, these principles should align with the local context while balancing the
risks. Compared to mainstream ethical debates on justice, this perspective
offers context-specific considerations for equitable healthcare AI development
in Africa.",2024-06-15T14:47:03Z,http://arxiv.org/pdf/2406.10653v1,"['cs.CY', 'cs.AI', 'I.2.0']"
2007.14206v1,Machine Learning Potential Repository,['Atsuto Seko'],"This paper introduces a machine learning potential repository that includes
Pareto optimal machine learning potentials. It also shows the systematic
development of accurate and fast machine learning potentials for a wide range
of elemental systems. As a result, many Pareto optimal machine learning
potentials are available in the repository from a website. Therefore, the
repository will help many scientists to perform accurate and fast atomistic
simulations.",2020-07-27T14:30:23Z,http://arxiv.org/pdf/2007.14206v1,"['physics.comp-ph', 'cond-mat.mtrl-sci', 'physics.chem-ph', 'physics.data-an']"
2201.09345v2,Machine Learning Symmetry,['Shailesh Lal'],"We review recent work in machine learning aspects of conformal field theory
and Lie algebra representation theory using neural networks.",2022-01-23T19:09:22Z,http://arxiv.org/pdf/2201.09345v2,"['hep-th', 'math-ph', 'math.MP', 'stat.ML']"
1807.01477v2,Diversity in Machine Learning,"['Zhiqiang Gong', 'Ping Zhong', 'Weidong Hu']","Machine learning methods have achieved good performance and been widely
applied in various real-world applications. They can learn the model adaptively
and be better fit for special requirements of different tasks. Generally, a
good machine learning system is composed of plentiful training data, a good
model training process, and an accurate inference. Many factors can affect the
performance of the machine learning process, among which the diversity of the
machine learning process is an important one. The diversity can help each
procedure to guarantee a total good machine learning: diversity of the training
data ensures that the training data can provide more discriminative information
for the model, diversity of the learned model (diversity in parameters of each
model or diversity among different base models) makes each parameter/model
capture unique or complement information and the diversity in inference can
provide multiple choices each of which corresponds to a specific plausible
local optimal result. Even though the diversity plays an important role in
machine learning process, there is no systematical analysis of the
diversification in machine learning system. In this paper, we systematically
summarize the methods to make data diversification, model diversification, and
inference diversification in the machine learning process, respectively. In
addition, the typical applications where the diversity technology improved the
machine learning performance have been surveyed, including the remote sensing
imaging tasks, machine translation, camera relocalization, image segmentation,
object detection, topic modeling, and others. Finally, we discuss some
challenges of the diversity technology in machine learning and point out some
directions in future work.",2018-07-04T08:25:17Z,http://arxiv.org/pdf/1807.01477v2,['cs.CV']
1903.06334v2,Machine Learning Risk Models,"['Zura Kakushadze', 'Willie Yu']","We give an explicit algorithm and source code for constructing risk models
based on machine learning techniques. The resultant covariance matrices are not
factor models. Based on empirical backtests, we compare the performance of
these machine learning risk models to other constructions, including
statistical risk models, risk models based on fundamental industry
classifications, and also those utilizing multilevel clustering based industry
classifications.",2019-03-15T02:47:21Z,http://arxiv.org/pdf/1903.06334v2,"['q-fin.PM', 'q-fin.RM']"
2107.01238v1,Solving Machine Learning Problems,"['Sunny Tran', 'Pranav Krishna', 'Ishan Pakuwal', 'Prabhakar Kafle', 'Nikhil Singh', 'Jayson Lynch', 'Iddo Drori']","Can a machine learn Machine Learning? This work trains a machine learning
model to solve machine learning problems from a University undergraduate level
course. We generate a new training set of questions and answers consisting of
course exercises, homework, and quiz questions from MIT's 6.036 Introduction to
Machine Learning course and train a machine learning model to answer these
questions. Our system demonstrates an overall accuracy of 96% for open-response
questions and 97% for multiple-choice questions, compared with MIT students'
average of 93%, achieving grade A performance in the course, all in real-time.
Questions cover all 12 topics taught in the course, excluding coding questions
or questions with images. Topics include: (i) basic machine learning
principles; (ii) perceptrons; (iii) feature extraction and selection; (iv)
logistic regression; (v) regression; (vi) neural networks; (vii) advanced
neural networks; (viii) convolutional neural networks; (ix) recurrent neural
networks; (x) state machines and MDPs; (xi) reinforcement learning; and (xii)
decision trees. Our system uses Transformer models within an encoder-decoder
architecture with graph and tree representations. An important aspect of our
approach is a data-augmentation scheme for generating new example problems. We
also train a machine learning model to generate problem hints. Thus, our system
automatically generates new questions across topics, answers both open-response
questions and multiple-choice questions, classifies problems, and generates
problem hints, pushing the envelope of AI for STEM education.",2021-07-02T18:52:50Z,http://arxiv.org/pdf/2107.01238v1,['cs.LG']
2110.12773v1,Scientific Machine Learning Benchmarks,"['Jeyan Thiyagalingam', 'Mallikarjun Shankar', 'Geoffrey Fox', 'Tony Hey']","The breakthrough in Deep Learning neural networks has transformed the use of
AI and machine learning technologies for the analysis of very large
experimental datasets. These datasets are typically generated by large-scale
experimental facilities at national laboratories. In the context of science,
scientific machine learning focuses on training machines to identify patterns,
trends, and anomalies to extract meaningful scientific insights from such
datasets. With a new generation of experimental facilities, the rate of data
generation and the scale of data volumes will increasingly require the use of
more automated data analysis. At present, identifying the most appropriate
machine learning algorithm for the analysis of any given scientific dataset is
still a challenge for scientists. This is due to many different machine
learning frameworks, computer architectures, and machine learning models.
Historically, for modelling and simulation on HPC systems such problems have
been addressed through benchmarking computer applications, algorithms, and
architectures. Extending such a benchmarking approach and identifying metrics
for the application of machine learning methods to scientific datasets is a new
challenge for both scientists and computer scientists. In this paper, we
describe our approach to the development of scientific machine learning
benchmarks and review other approaches to benchmarking scientific machine
learning.",2021-10-25T10:05:11Z,http://arxiv.org/pdf/2110.12773v1,"['cs.LG', 'physics.comp-ph', 'I.2']"
2206.00423v2,Open-environment Machine Learning,['Zhi-Hua Zhou'],"Conventional machine learning studies generally assume close-environment
scenarios where important factors of the learning process hold invariant. With
the great success of machine learning, nowadays, more and more practical tasks,
particularly those involving open-environment scenarios where important factors
are subject to change, called open-environment machine learning (Open ML) in
this article, are present to the community. Evidently it is a grand challenge
for machine learning turning from close environment to open environment. It
becomes even more challenging since, in various big data tasks, data are
usually accumulated with time, like streams, while it is hard to train the
machine learning model after collecting all data as in conventional studies.
This article briefly introduces some advances in this line of research,
focusing on techniques concerning emerging new classes, decremental/incremental
features, changing data distributions, varied learning objectives, and
discusses some theoretical issues.",2022-06-01T11:57:56Z,http://arxiv.org/pdf/2206.00423v2,['cs.LG']
1601.03642v1,Creativity in Machine Learning,['Martin Thoma'],"Recent machine learning techniques can be modified to produce creative
results. Those results did not exist before; it is not a trivial combination of
the data which was fed into the machine learning system. The obtained results
come in multiple forms: As images, as text and as audio.
  This paper gives a high level overview of how they are created and gives some
examples. It is meant to be a summary of the current work and give people who
are new to machine learning some starting points.",2016-01-12T23:28:07Z,http://arxiv.org/pdf/1601.03642v1,"['cs.CV', 'cs.LG']"
1611.09347v2,Quantum Machine Learning,"['Jacob Biamonte', 'Peter Wittek', 'Nicola Pancotti', 'Patrick Rebentrost', 'Nathan Wiebe', 'Seth Lloyd']","Fuelled by increasing computer power and algorithmic advances, machine
learning techniques have become powerful tools for finding patterns in data.
Since quantum systems produce counter-intuitive patterns believed not to be
efficiently produced by classical systems, it is reasonable to postulate that
quantum computers may outperform classical computers on machine learning tasks.
The field of quantum machine learning explores how to devise and implement
concrete quantum software that offers such advantages. Recent work has made
clear that the hardware and software challenges are still considerable but has
also opened paths towards solutions.",2016-11-28T20:59:46Z,http://arxiv.org/pdf/1611.09347v2,"['quant-ph', 'cond-mat.str-el', 'stat.ML']"
2003.00656v5,Machine Learning Portfolio Allocation,"['Michael Pinelis', 'David Ruppert']","We find economically and statistically significant gains when using machine
learning for portfolio allocation between the market index and risk-free asset.
Optimal portfolio rules for time-varying expected returns and volatility are
implemented with two Random Forest models. One model is employed in forecasting
the sign probabilities of the excess return with payout yields. The second is
used to construct an optimized volatility estimate. Reward-risk timing with
machine learning provides substantial improvements over the buy-and-hold in
utility, risk-adjusted returns, and maximum drawdowns. This paper presents a
new theoretical basis and unifying framework for machine learning applied to
both return- and volatility-timing.",2020-03-02T04:45:16Z,http://arxiv.org/pdf/2003.00656v5,"['q-fin.PM', 'q-fin.GN', 'q-fin.PR', 'q-fin.RM', 'q-fin.ST']"
2203.08056v1,Machine Learning and Cosmology,"['Cora Dvorkin', 'Siddharth Mishra-Sharma', 'Brian Nord', 'V. Ashley Villar', 'Camille Avestruz', 'Keith Bechtol', 'Aleksandra Ćiprijanović', 'Andrew J. Connolly', 'Lehman H. Garrison', 'Gautham Narayan', 'Francisco Villaescusa-Navarro']","Methods based on machine learning have recently made substantial inroads in
many corners of cosmology. Through this process, new computational tools, new
perspectives on data collection, model development, analysis, and discovery, as
well as new communities and educational pathways have emerged. Despite rapid
progress, substantial potential at the intersection of cosmology and machine
learning remains untapped. In this white paper, we summarize current and
ongoing developments relating to the application of machine learning within
cosmology and provide a set of recommendations aimed at maximizing the
scientific impact of these burgeoning tools over the coming decade through both
technical development as well as the fostering of emerging communities.",2022-03-15T16:50:46Z,http://arxiv.org/pdf/2203.08056v1,"['hep-ph', 'astro-ph.CO', 'astro-ph.IM', 'cs.LG', 'stat.ML']"
1903.09731v3,Expert-Augmented Machine Learning,"['E. D. Gennatas', 'J. H. Friedman', 'L. H. Ungar', 'R. Pirracchio', 'E. Eaton', 'L. Reichman', 'Y. Interian', 'C. B. Simone', 'A. Auerbach', 'E. Delgado', 'M. J. Van der Laan', 'T. D. Solberg', 'G. Valdes']","Machine Learning is proving invaluable across disciplines. However, its
success is often limited by the quality and quantity of available data, while
its adoption by the level of trust that models afford users. Human vs. machine
performance is commonly compared empirically to decide whether a certain task
should be performed by a computer or an expert. In reality, the optimal
learning strategy may involve combining the complementary strengths of man and
machine. Here we present Expert-Augmented Machine Learning (EAML), an automated
method that guides the extraction of expert knowledge and its integration into
machine-learned models. We use a large dataset of intensive care patient data
to predict mortality and show that we can extract expert knowledge using an
online platform, help reveal hidden confounders, improve generalizability on a
different population and learn using less data. EAML presents a novel framework
for high performance and dependable machine learning in critical applications.",2019-03-22T23:32:22Z,http://arxiv.org/pdf/1903.09731v3,"['stat.ML', 'cs.AI']"
1610.08251v1,Quantum-enhanced machine learning,"['Vedran Dunjko', 'Jacob M. Taylor', 'Hans J. Briegel']","The emerging field of quantum machine learning has the potential to
substantially aid in the problems and scope of artificial intelligence. This is
only enhanced by recent successes in the field of classical machine learning.
In this work we propose an approach for the systematic treatment of machine
learning, from the perspective of quantum information. Our approach is general
and covers all three main branches of machine learning: supervised,
unsupervised and reinforcement learning. While quantum improvements in
supervised and unsupervised learning have been reported, reinforcement learning
has received much less attention. Within our approach, we tackle the problem of
quantum enhancements in reinforcement learning as well, and propose a
systematic scheme for providing improvements. As an example, we show that
quadratic improvements in learning efficiency, and exponential improvements in
performance over limited time periods, can be obtained for a broad class of
learning problems.",2016-10-26T09:35:11Z,http://arxiv.org/pdf/1610.08251v1,"['quant-ph', 'cs.AI', 'cs.LG']"
2102.00753v2,Quantum Fair Machine Learning,['Elija Perrier'],"In this paper, we inaugurate the field of quantum fair machine learning. We
undertake a comparative analysis of differences and similarities between
classical and quantum fair machine learning algorithms, specifying how the
unique features of quantum computation alter measures, metrics and remediation
strategies when quantum algorithms are subject to fairness constraints. We
present the first results in quantum fair machine learning by demonstrating the
use of Grover's search algorithm to satisfy statistical parity constraints
imposed on quantum algorithms. We provide lower-bounds on iterations needed to
achieve such statistical parity within $\epsilon$-tolerance. We extend
canonical Lipschitz-conditioned individual fairness criteria to the quantum
setting using quantum metrics. We examine the consequences for typical measures
of fairness in machine learning context when quantum information processing and
quantum data are involved. Finally, we propose open questions and research
programmes for this new field of interest to researchers in computer science,
ethics and quantum computation.",2021-02-01T10:36:46Z,http://arxiv.org/pdf/2102.00753v2,"['cs.LG', 'quant-ph']"
2507.17931v1,Quantum Machine Learning Playground,"['Pascal Debus', 'Sebastian Issel', 'Kilian Tscharke']","This article introduces an innovative interactive visualization tool designed
to demystify quantum machine learning (QML) algorithms. Our work is inspired by
the success of classical machine learning visualization tools, such as
TensorFlow Playground, and aims to bridge the gap in visualization resources
specifically for the field of QML. The article includes a comprehensive
overview of relevant visualization metaphors from both quantum computing and
classical machine learning, the development of an algorithm visualization
concept, and the design of a concrete implementation as an interactive web
application. By combining common visualization metaphors for the so-called data
re-uploading universal quantum classifier as a representative QML model, this
article aims to lower the entry barrier to quantum computing and encourage
further innovation in the field. The accompanying interactive application is a
proposal for the first version of a quantum machine learning playground for
learning and exploring QML models.",2025-07-23T21:08:29Z,http://arxiv.org/pdf/2507.17931v1,"['quant-ph', 'cs.GR', 'cs.LG']"
1202.6548v2,mlpy: Machine Learning Python,"['Davide Albanese', 'Roberto Visintainer', 'Stefano Merler', 'Samantha Riccadonna', 'Giuseppe Jurman', 'Cesare Furlanello']","mlpy is a Python Open Source Machine Learning library built on top of
NumPy/SciPy and the GNU Scientific Libraries. mlpy provides a wide range of
state-of-the-art machine learning methods for supervised and unsupervised
problems and it is aimed at finding a reasonable compromise among modularity,
maintainability, reproducibility, usability and efficiency. mlpy is
multiplatform, it works with Python 2 and 3 and it is distributed under GPL3 at
the website http://mlpy.fbk.eu.",2012-02-29T13:49:10Z,http://arxiv.org/pdf/1202.6548v2,"['cs.MS', 'cs.LG', 'stat.ML']"
1911.10500v2,Causality for Machine Learning,['Bernhard Schölkopf'],"Graphical causal inference as pioneered by Judea Pearl arose from research on
artificial intelligence (AI), and for a long time had little connection to the
field of machine learning.
  This article discusses where links have been and should be established,
introducing key concepts along the way. It argues that the hard open problems
of machine learning and AI are intrinsically related to causality, and explains
how the field is beginning to understand them.",2019-11-24T11:04:56Z,http://arxiv.org/pdf/1911.10500v2,"['cs.LG', 'cs.AI', 'stat.ML', 'I.2, I.5, K.4', 'I.2; I.5; K.4']"
2001.00030v1,Quantum Adversarial Machine Learning,"['Sirui Lu', 'Lu-Ming Duan', 'Dong-Ling Deng']","Adversarial machine learning is an emerging field that focuses on studying
vulnerabilities of machine learning approaches in adversarial settings and
developing techniques accordingly to make learning robust to adversarial
manipulations. It plays a vital role in various machine learning applications
and has attracted tremendous attention across different communities recently.
In this paper, we explore different adversarial scenarios in the context of
quantum machine learning. We find that, similar to traditional classifiers
based on classical neural networks, quantum learning systems are likewise
vulnerable to crafted adversarial examples, independent of whether the input
data is classical or quantum. In particular, we find that a quantum classifier
that achieves nearly the state-of-the-art accuracy can be conclusively deceived
by adversarial examples obtained via adding imperceptible perturbations to the
original legitimate samples. This is explicitly demonstrated with quantum
adversarial learning in different scenarios, including classifying real-life
images (e.g., handwritten digit images in the dataset MNIST), learning phases
of matter (such as, ferromagnetic/paramagnetic orders and symmetry protected
topological phases), and classifying quantum data. Furthermore, we show that
based on the information of the adversarial examples at hand, practical defense
strategies can be designed to fight against a number of different attacks. Our
results uncover the notable vulnerability of quantum machine learning systems
to adversarial perturbations, which not only reveals a novel perspective in
bridging machine learning and quantum physics in theory but also provides
valuable guidance for practical applications of quantum classifiers based on
both near-term and future quantum technologies.",2019-12-31T19:00:12Z,http://arxiv.org/pdf/2001.00030v1,"['quant-ph', 'cond-mat.dis-nn', 'cond-mat.str-el', 'cs.CV']"
2410.23724v1,Argumentation and Machine Learning,"['Antonio Rago', 'Kristijonas Čyras', 'Jack Mumford', 'Oana Cocarascu']","This chapter provides an overview of research works that present approaches
with some degree of cross-fertilisation between Computational Argumentation and
Machine Learning. Our review of the literature identified two broad themes
representing the purpose of the interaction between these two areas:
argumentation for machine learning and machine learning for argumentation.
Across these two themes, we systematically evaluate the spectrum of works
across various dimensions, including the type of learning and the form of
argumentation framework used. Further, we identify three types of interaction
between these two areas: synergistic approaches, where the Argumentation and
Machine Learning components are tightly integrated; segmented approaches, where
the two are interleaved such that the outputs of one are the inputs of the
other; and approximated approaches, where one component shadows the other at a
chosen level of detail. We draw conclusions about the suitability of certain
forms of Argumentation for supporting certain types of Machine Learning, and
vice versa, with clear patterns emerging from the review. Whilst the reviewed
works provide inspiration for successfully combining the two fields of
research, we also identify and discuss limitations and challenges that ought to
be addressed in order to ensure that they remain a fruitful pairing as AI
advances.",2024-10-31T08:19:58Z,http://arxiv.org/pdf/2410.23724v1,"['cs.AI', 'F.4.1; I.2.4']"
1106.4509v1,Machine Learning Markets,['Amos Storkey'],"Prediction markets show considerable promise for developing flexible
mechanisms for machine learning. Here, machine learning markets for
multivariate systems are defined, and a utility-based framework is established
for their analysis. This differs from the usual approach of defining static
betting functions. It is shown that such markets can implement model
combination methods used in machine learning, such as product of expert and
mixture of expert approaches as equilibrium pricing models, by varying agent
utility functions. They can also implement models composed of local potentials,
and message passing methods. Prediction markets also allow for more flexible
combinations, by combining multiple different utility functions. Conversely,
the market mechanisms implement inference in the relevant probabilistic models.
This means that market mechanism can be utilized for implementing parallelized
model building and inference for probabilistic modelling.",2011-06-22T17:12:42Z,http://arxiv.org/pdf/1106.4509v1,"['cs.AI', 'cs.MA', 'cs.NE', 'q-fin.TR', 'stat.ML']"
1904.02773v1,Adaptive Sequential Machine Learning,"['Craig Wilson', 'Yuheng Bu', 'Venugopal Veeravalli']","A framework previously introduced in [3] for solving a sequence of stochastic
optimization problems with bounded changes in the minimizers is extended and
applied to machine learning problems such as regression and classification. The
stochastic optimization problems arising in these machine learning problems is
solved using algorithms such as stochastic gradient descent (SGD). A method
based on estimates of the change in the minimizers and properties of the
optimization algorithm is introduced for adaptively selecting the number of
samples at each time step to ensure that the excess risk, i.e., the expected
gap between the loss achieved by the approximate minimizer produced by the
optimization algorithm and the exact minimizer, does not exceed a target level.
A bound is developed to show that the estimate of the change in the minimizers
is non-trivial provided that the excess risk is small enough. Extensions
relevant to the machine learning setting are considered, including a cost-based
approach to select the number of samples with a cost budget over a fixed
horizon, and an approach to applying cross-validation for model selection.
Finally, experiments with synthetic and real data are used to validate the
algorithms.",2019-04-04T20:03:46Z,http://arxiv.org/pdf/1904.02773v1,"['cs.LG', 'stat.ML']"
2111.03731v1,Frugal Machine Learning,"['Mikhail Evchenko', 'Joaquin Vanschoren', 'Holger H. Hoos', 'Marc Schoenauer', 'Michèle Sebag']","Machine learning, already at the core of increasingly many systems and
applications, is set to become even more ubiquitous with the rapid rise of
wearable devices and the Internet of Things. In most machine learning
applications, the main focus is on the quality of the results achieved (e.g.,
prediction accuracy), and hence vast amounts of data are being collected,
requiring significant computational resources to build models. In many
scenarios, however, it is infeasible or impractical to set up large centralized
data repositories. In personal health, for instance, privacy issues may inhibit
the sharing of detailed personal data. In such cases, machine learning should
ideally be performed on wearable devices themselves, which raises major
computational limitations such as the battery capacity of smartwatches. This
paper thus investigates frugal learning, aimed to build the most accurate
possible models using the least amount of resources. A wide range of learning
algorithms is examined through a frugal lens, analyzing their accuracy/runtime
performance on a wide range of data sets. The most promising algorithms are
thereafter assessed in a real-world scenario by implementing them in a
smartwatch and letting them learn activity recognition models on the watch
itself.",2021-11-05T21:27:55Z,http://arxiv.org/pdf/2111.03731v1,"['cs.LG', 'eess.SP']"
2201.01289v2,Self-directed Machine Learning,"['Wenwu Zhu', 'Xin Wang', 'Pengtao Xie']","Conventional machine learning (ML) relies heavily on manual design from
machine learning experts to decide learning tasks, data, models, optimization
algorithms, and evaluation metrics, which is labor-intensive, time-consuming,
and cannot learn autonomously like humans. In education science, self-directed
learning, where human learners select learning tasks and materials on their own
without requiring hands-on guidance, has been shown to be more effective than
passive teacher-guided learning. Inspired by the concept of self-directed human
learning, we introduce the principal concept of Self-directed Machine Learning
(SDML) and propose a framework for SDML. Specifically, we design SDML as a
self-directed learning process guided by self-awareness, including internal
awareness and external awareness. Our proposed SDML process benefits from self
task selection, self data selection, self model selection, self optimization
strategy selection and self evaluation metric selection through self-awareness
without human guidance. Meanwhile, the learning performance of the SDML process
serves as feedback to further improve self-awareness. We propose a mathematical
formulation for SDML based on multi-level optimization. Furthermore, we present
case studies together with potential applications of SDML, followed by
discussing future research directions. We expect that SDML could enable
machines to conduct human-like self-directed learning and provide a new
perspective towards artificial general intelligence.",2022-01-04T18:32:06Z,http://arxiv.org/pdf/2201.01289v2,"['cs.LG', 'cs.AI']"
2206.03266v1,Machine Learning Sensors,"['Pete Warden', 'Matthew Stewart', 'Brian Plancher', 'Colby Banbury', 'Shvetank Prakash', 'Emma Chen', 'Zain Asgar', 'Sachin Katti', 'Vijay Janapa Reddi']","Machine learning sensors represent a paradigm shift for the future of
embedded machine learning applications. Current instantiations of embedded
machine learning (ML) suffer from complex integration, lack of modularity, and
privacy and security concerns from data movement. This article proposes a more
data-centric paradigm for embedding sensor intelligence on edge devices to
combat these challenges. Our vision for ""sensor 2.0"" entails segregating sensor
input data and ML processing from the wider system at the hardware level and
providing a thin interface that mimics traditional sensors in functionality.
This separation leads to a modular and easy-to-use ML sensor device. We discuss
challenges presented by the standard approach of building ML processing into
the software stack of the controlling microprocessor on an embedded system and
how the modularity of ML sensors alleviates these problems. ML sensors increase
privacy and accuracy while making it easier for system builders to integrate ML
into their products as a simple component. We provide examples of prospective
ML sensors and an illustrative datasheet as a demonstration and hope that this
will build a dialogue to progress us towards sensor 2.0.",2022-06-07T13:22:13Z,http://arxiv.org/pdf/2206.03266v1,"['cs.LG', 'cs.AR', 'eess.SP']"
2310.08215v1,Trustworthy Machine Learning,"['Bálint Mucsányi', 'Michael Kirchhof', 'Elisa Nguyen', 'Alexander Rubinstein', 'Seong Joon Oh']","As machine learning technology gets applied to actual products and solutions,
new challenges have emerged. Models unexpectedly fail to generalize to small
changes in the distribution, tend to be confident on novel data they have never
seen, or cannot communicate the rationale behind their decisions effectively
with the end users. Collectively, we face a trustworthiness issue with the
current machine learning technology. This textbook on Trustworthy Machine
Learning (TML) covers a theoretical and technical background of four key topics
in TML: Out-of-Distribution Generalization, Explainability, Uncertainty
Quantification, and Evaluation of Trustworthiness. We discuss important
classical and contemporary research papers of the aforementioned fields and
uncover and connect their underlying intuitions. The book evolved from the
homonymous course at the University of T\""ubingen, first offered in the Winter
Semester of 2022/23. It is meant to be a stand-alone product accompanied by
code snippets and various pointers to further sources on topics of TML. The
dedicated website of the book is https://trustworthyml.io/.",2023-10-12T11:04:17Z,http://arxiv.org/pdf/2310.08215v1,"['cs.LG', 'cs.AI', 'I.2.0']"
2404.19032v2,Fermionic Machine Learning,"['Jérémie Gince', 'Jean-Michel Pagé', 'Marco Armenta', 'Ayana Sarkar', 'Stefanos Kourtis']","We introduce fermionic machine learning (FermiML), a machine learning
framework based on fermionic quantum computation. FermiML models are expressed
in terms of parameterized matchgate circuits, a restricted class of quantum
circuits that map exactly to systems of free Majorana fermions. The FermiML
framework allows for building fermionic counterparts of any quantum machine
learning (QML) model based on parameterized quantum circuits, including models
that produce highly entangled quantum states. Importantly, matchgate circuits
are efficiently simulable classically, thus rendering FermiML a flexible
framework for utility benchmarks of QML methods on large real-world datasets.
We initiate the exploration of FermiML by benchmarking it against unrestricted
PQCs in the context of classification with random quantum kernels. Through
experiments on standard datasets (Digits and Wisconsin Breast Cancer), we
demonstrate that FermiML kernels are on-par with unrestricted PQC kernels in
classification tasks using support-vector machines. Furthermore, we find that
FermiML kernels outperform their unrestricted candidates on multi-class
classification, including on datasets with several tens of relevant features.
We thus show how FermiML enables us to explore regimes previously inaccessible
to QML methods.",2024-04-29T18:16:52Z,http://arxiv.org/pdf/2404.19032v2,"['quant-ph', 'cond-mat.dis-nn']"
2405.10198v2,Comprehensive Causal Machine Learning,"['Michael Lechner', 'Jana Mareckova']","Uncovering causal effects in multiple treatment setting at various levels of
granularity provides substantial value to decision makers. Comprehensive
machine learning approaches to causal effect estimation allow to use a single
causal machine learning approach for estimation and inference of causal mean
effects for all levels of granularity. Focusing on selection-on-observables,
this paper compares three such approaches, the modified causal forest (mcf),
the generalized random forest (grf), and double machine learning (dml). It also
compares the theoretical properties of the approaches and provides proven
theoretical guarantees for the mcf. The findings indicate that dml-based
methods excel for average treatment effects at the population level (ATE) and
group level (GATE) with few groups, when selection into treatment is not too
strong. However, for finer causal heterogeneity, explicitly outcome-centred
forest-based approaches are superior. The mcf has three additional benefits:
(i) It is the most robust estimator in cases when dml-based approaches
underperform because of substantial selection into treatment; (ii) it is the
best estimator for GATEs when the number of groups gets larger; and (iii), it
is the only estimator that is internally consistent, in the sense that
low-dimensional causal ATEs and GATEs are obtained as aggregates of
finer-grained causal parameters.",2024-05-16T15:39:09Z,http://arxiv.org/pdf/2405.10198v2,['econ.EM']
2506.12292v1,Quantum Machine Learning,['Muhammad Usman'],"The meteoric rise of artificial intelligence in recent years has seen machine
learning methods become ubiquitous in modern science, technology, and industry.
Concurrently, the emergence of programmable quantum computers, coupled with the
expectation that large-scale fault-tolerant machines will follow in the near to
medium-term future, has led to much speculation about the prospect of quantum
machine learning (QML), namely machine learning (ML) solutions which take
advantage of quantum properties to outperform their classical counterparts.
Indeed, QML is widely considered as one of the front-running use cases for
quantum computing. In recent years, research in QML has gained significant
global momentum. In this chapter, we introduce the fundamentals of QML and
provide a brief overview of the recent progress and future trends in the field
of QML. We highlight key opportunities for achieving quantum advantage in ML
tasks, as well as describe some open challenges currently facing the field of
QML. Specifically in the context of cybersecurity, we introduce the potential
for QML in defence and security-sensitive applications, where it has been
predicted that the seamless integration of quantum computing into ML will
herald the development of robust and reliable QML systems, resilient against
sophisticated threats arising from data manipulation and poisoning.",2025-06-14T00:58:54Z,http://arxiv.org/pdf/2506.12292v1,['quant-ph']
2205.00210v1,Software Testing for Machine Learning,"['Dusica Marijan', 'Arnaud Gotlieb']","Machine learning has become prevalent across a wide variety of applications.
Unfortunately, machine learning has also shown to be susceptible to deception,
leading to errors, and even fatal failures. This circumstance calls into
question the widespread use of machine learning, especially in safety-critical
applications, unless we are able to assure its correctness and trustworthiness
properties. Software verification and testing are established technique for
assuring such properties, for example by detecting errors. However, software
testing challenges for machine learning are vast and profuse - yet critical to
address. This summary talk discusses the current state-of-the-art of software
testing for machine learning. More specifically, it discusses six key challenge
areas for software testing of machine learning systems, examines current
approaches to these challenges and highlights their limitations. The paper
provides a research agenda with elaborated directions for making progress
toward advancing the state-of-the-art on testing of machine learning.",2022-04-30T08:47:10Z,http://arxiv.org/pdf/2205.00210v1,"['cs.SE', 'cs.AI', 'cs.LG']"
2101.08928v1,Machine Learning Percolation Model,"['Shu Cheng', 'Fei He', 'Huai Zhang', 'Ka-Di Zhu', 'Yaolin Shi']","Recent advances in machine learning have become increasingly popular in the
applications of phase transitions and critical phenomena. By machine learning
approaches, we try to identify the physical characteristics in the
two-dimensional percolation model. To achieve this, we adopt Monte Carlo
simulation to generate dataset at first, and then we employ several approaches
to analyze the dataset. Four kinds of convolutional neural networks (CNNs), one
variational autoencoder (VAE), one convolutional VAE (cVAE), one principal
component analysis (PCA), and one $k$-means are used for identifying order
parameter, the permeability, and the critical transition point. The former
three kinds of CNNs can simulate the two order parameters and the permeability
with high accuracy, and good extrapolating performance. The former two kinds of
CNNs have high anti-noise ability. To validate the robustness of the former
three kinds of CNNs, we also use the VAE and the cVAE to generate new
percolating configurations to add perturbations into the raw configurations. We
find that there is no difference by using the raw or the perturbed
configurations to identify the physical characteristics, under the prerequisite
of corresponding labels. In the case of lacking labels, we use unsupervised
learning to detect the physical characteristics. The PCA, a classical
unsupervised learning, performs well when identifying the permeability but
fails to deduce order parameter. Hence, we apply the fourth kinds of CNNs with
different preset thresholds, and identify a new order parameter and the
critical transition point. Our findings indicate that the effectiveness of
machine learning still needs to be evaluated in the applications of phase
transitions and critical phenomena.",2021-01-22T03:24:52Z,http://arxiv.org/pdf/2101.08928v1,['cond-mat.dis-nn']
1109.0325v1,Quantum adiabatic machine learning,"['Kristen L. Pudenz', 'Daniel A. Lidar']","We develop an approach to machine learning and anomaly detection via quantum
adiabatic evolution. In the training phase we identify an optimal set of weak
classifiers, to form a single strong classifier. In the testing phase we
adiabatically evolve one or more strong classifiers on a superposition of
inputs in order to find certain anomalous elements in the classification space.
Both the training and testing phases are executed via quantum adiabatic
evolution. We apply and illustrate this approach in detail to the problem of
software verification and validation.",2011-09-01T23:10:31Z,http://arxiv.org/pdf/1109.0325v1,"['quant-ph', 'cs.LG']"
1206.4656v1,Machine Learning that Matters,['Kiri Wagstaff'],"Much of current machine learning (ML) research has lost its connection to
problems of import to the larger world of science and society. From this
perspective, there exist glaring limitations in the data sets we investigate,
the metrics we employ for evaluation, and the degree to which results are
communicated back to their originating domains. What changes are needed to how
we conduct research to increase the impact that ML has? We present six Impact
Challenges to explicitly focus the field?s energy and attention, and we discuss
existing obstacles that must be addressed. We aim to inspire ongoing discussion
and focus on ML that matters.",2012-06-18T15:26:13Z,http://arxiv.org/pdf/1206.4656v1,"['cs.LG', 'cs.AI', 'stat.ML']"
2202.09480v1,Reciprocity in Machine Learning,"['Mukund Sundararajan', 'Walid Krichene']","Machine learning is pervasive. It powers recommender systems such as Spotify,
Instagram and YouTube, and health-care systems via models that predict sleep
patterns, or the risk of disease. Individuals contribute data to these models
and benefit from them. Are these contributions (outflows of influence) and
benefits (inflows of influence) reciprocal? We propose measures of outflows,
inflows and reciprocity building on previously proposed measures of training
data influence. Our initial theoretical and empirical results indicate that
under certain distributional assumptions, some classes of models are
approximately reciprocal. We conclude with several open directions.",2022-02-19T00:25:03Z,http://arxiv.org/pdf/2202.09480v1,"['cs.LG', 'cs.AI', 'econ.GN', 'q-fin.EC']"
2011.08958v1,Machine-Learning Number Fields,"['Yang-Hui He', 'Kyu-Hwan Lee', 'Thomas Oliver']","We show that standard machine-learning algorithms may be trained to predict
certain invariants of algebraic number fields to high accuracy. A random-forest
classifier that is trained on finitely many Dedekind zeta coefficients is able
to distinguish between real quadratic fields with class number 1 and 2, to 0.96
precision. Furthermore, the classifier is able to extrapolate to fields with
discriminant outside the range of the training data. When trained on the
coefficients of defining polynomials for Galois extensions of degrees 2, 6, and
8, a logistic regression classifier can distinguish between Galois groups and
predict the ranks of unit groups with precision >0.97.",2020-11-17T21:40:40Z,http://arxiv.org/pdf/2011.08958v1,"['math.NT', 'hep-th', 'stat.ML']"
2003.05095v1,Machine Learning Treasury Yields,"['Zura Kakushadze', 'Willie Yu']","We give explicit algorithms and source code for extracting factors underlying
Treasury yields using (unsupervised) machine learning (ML) techniques, such as
nonnegative matrix factorization (NMF) and (statistically deterministic)
clustering. NMF is a popular ML algorithm (used in computer vision,
bioinformatics/computational biology, document classification, etc.), but is
often misconstrued and misused. We discuss how to properly apply NMF to
Treasury yields. We analyze the factors based on NMF and clustering and their
interpretation. We discuss their implications for forecasting Treasury yields
in the context of out-of-sample ML stability issues.",2020-03-11T03:15:18Z,http://arxiv.org/pdf/2003.05095v1,"['stat.ME', 'q-fin.CP', 'q-fin.PR']"
2310.11340v1,Contextualized Machine Learning,"['Benjamin Lengerich', 'Caleb N. Ellington', 'Andrea Rubbi', 'Manolis Kellis', 'Eric P. Xing']","We examine Contextualized Machine Learning (ML), a paradigm for learning
heterogeneous and context-dependent effects. Contextualized ML estimates
heterogeneous functions by applying deep learning to the meta-relationship
between contextual information and context-specific parametric models. This is
a form of varying-coefficient modeling that unifies existing frameworks
including cluster analysis and cohort modeling by introducing two reusable
concepts: a context encoder which translates sample context into model
parameters, and sample-specific model which operates on sample predictors. We
review the process of developing contextualized models, nonparametric inference
from contextualized models, and identifiability conditions of contextualized
models. Finally, we present the open-source PyTorch package ContextualizedML.",2023-10-17T15:23:00Z,http://arxiv.org/pdf/2310.11340v1,"['stat.ML', 'cs.LG']"
2407.00183v2,Top-philic Machine Learning,"['Rahool Kumar Barman', 'Sumit Biswas']","In this article, we review the application of modern machine-learning (ML)
techniques to boost the search for processes involving the top quarks at the
LHC. We revisit the formalism of Convolutional Neural Networks (CNNs), Graph
Neural Networks (GNNs), and Attention Mechanisms. Based on recent studies, we
explore their applications in designing improved top taggers, top
reconstruction, and event classification tasks. We also examine the ML-based
likelihood-free inference approach and generative unfolding models, focusing on
their applications to scenarios involving top quarks.",2024-06-28T18:38:30Z,http://arxiv.org/pdf/2407.00183v2,"['hep-ph', 'hep-ex']"
2509.20370v1,Philosophy-informed Machine Learning,['MZ Naser'],"Philosophy-informed machine learning (PhIML) directly infuses core ideas from
analytic philosophy into ML model architectures, objectives, and evaluation
protocols. Therefore, PhIML promises new capabilities through models that
respect philosophical concepts and values by design. From this lens, this paper
reviews conceptual foundations to demonstrate philosophical gains and
alignment. In addition, we present case studies on how ML users/designers can
adopt PhIML as an agnostic post-hoc tool or intrinsically build it into ML
model architectures. Finally, this paper sheds light on open technical barriers
alongside philosophical, practical, and governance challenges and outlines a
research roadmap toward safe, philosophy-aware, and ethically responsible
PhIML.",2025-09-18T21:51:21Z,http://arxiv.org/pdf/2509.20370v1,"['cs.AI', 'cs.CY', 'cs.LG']"
1609.09060v2,Machine Learning Topological States,"['Dong-Ling Deng', 'Xiaopeng Li', 'S. Das Sarma']","Artificial neural networks and machine learning have now reached a new era
after several decades of improvement where applications are to explode in many
fields of science, industry, and technology. Here, we use artificial neural
networks to study an intriguing phenomenon in quantum physics--- the
topological phases of matter. We find that certain topological states, either
symmetry-protected or with intrinsic topological order, can be represented with
classical artificial neural networks. This is demonstrated by using three
concrete spin systems, the one-dimensional (1D) symmetry-protected topological
cluster state and the 2D and 3D toric code states with intrinsic topological
orders. For all three cases we show rigorously that the topological ground
states can be represented by short-range neural networks in an \textit{exact}
and \textit{efficient} fashion---the required number of hidden neurons is as
small as the number of physical spins and the number of parameters scales only
\textit{linearly} with the system size. For the 2D toric-code model, we find
that the proposed short-range neural networks can describe the excited states
with abelain anyons and their nontrivial mutual statistics as well. In
addition, by using reinforcement learning we show that neural networks are
capable of finding the topological ground states of non-integrable Hamiltonians
with strong interactions and studying their topological phase transitions. Our
results demonstrate explicitly the exceptional power of neural networks in
describing topological quantum states, and at the same time provide valuable
guidance to machine learning of topological phases in generic lattice models.",2016-09-28T19:59:56Z,http://arxiv.org/pdf/1609.09060v2,"['cond-mat.dis-nn', 'cond-mat.stat-mech', 'cond-mat.str-el', 'quant-ph']"
1511.07883v1,Machine Learning Exciton Dynamics,"['Florian Häse', 'Stéphanie Valleau', 'Edward Pyzer-Knapp', 'Alán Aspuru-Guzik']","Obtaining the exciton dynamics of large photosynthetic complexes by using
mixed quantum mechanics/molecular mechanics (QM/MM) is computationally
demanding. We propose a machine learning technique, multi-layer perceptrons, as
a tool to reduce the time required to compute excited state energies. With this
approach we predict time-dependent density functional theory (TDDFT) excited
state energies of bacteriochlorophylls in the Fenna-Matthews-Olson (FMO)
complex. Additionally we compute spectral densities and exciton populations
from the predictions. Different methods to determine multi-layer perceptron
training sets are introduced, leading to several initial data selections. In
addition, we compute spectral densities and exciton populations. Once
multi-layer perceptrons are trained, predicting excited state energies was
found to be significantly faster than the corresponding QM/MM calculations. We
showed that multi-layer perceptrons can successfully reproduce the energies of
QM/MM calculations to a high degree of accuracy with prediction errors
contained within 0.01 eV (0.5%). Spectral densities and exciton dynamics are
also in agreement with the TDDFT results. The acceleration and accurate
prediction of dynamics strongly encourage the combination of machine learning
techniques with ab-initio methods.",2015-11-24T21:01:01Z,http://arxiv.org/pdf/1511.07883v1,"['physics.chem-ph', 'physics.comp-ph']"
2012.15816v1,Fairness in Machine Learning,"['Luca Oneto', 'Silvia Chiappa']","Machine learning based systems are reaching society at large and in many
aspects of everyday life. This phenomenon has been accompanied by concerns
about the ethical issues that may arise from the adoption of these
technologies. ML fairness is a recently established area of machine learning
that studies how to ensure that biases in the data and model inaccuracies do
not lead to models that treat individuals unfavorably on the basis of
characteristics such as e.g. race, gender, disabilities, and sexual or
political orientation. In this manuscript, we discuss some of the limitations
present in the current reasoning about fairness and in methods that deal with
it, and describe some work done by the authors to address them. More
specifically, we show how causal Bayesian networks can play an important role
to reason about and deal with fairness, especially in complex unfairness
scenarios. We describe how optimal transport theory can be used to develop
methods that impose constraints on the full shapes of distributions
corresponding to different sensitive attributes, overcoming the limitation of
most approaches that approximate fairness desiderata by imposing constraints on
the lower order moments or other functions of those distributions. We present a
unified framework that encompasses methods that can deal with different
settings and fairness criteria, and that enjoys strong theoretical guarantees.
We introduce an approach to learn fair representations that can generalize to
unseen tasks. Finally, we describe a technique that accounts for legal
restrictions about the use of sensitive attributes.",2020-12-31T18:38:58Z,http://arxiv.org/pdf/2012.15816v1,"['cs.LG', 'cs.CY', 'stat.ML']"
2303.05911v2,Lifelong Machine Learning Potentials,"['Marco Eckhoff', 'Markus Reiher']","Machine learning potentials (MLPs) trained on accurate quantum chemical data
can retain the high accuracy, while inflicting little computational demands. On
the downside, they need to be trained for each individual system. In recent
years, a vast number of MLPs has been trained from scratch because learning
additional data typically requires to train again on all data to not forget
previously acquired knowledge. Additionally, most common structural descriptors
of MLPs cannot represent efficiently a large number of different chemical
elements. In this work, we tackle these problems by introducing
element-embracing atom-centered symmetry functions (eeACSFs) which combine
structural properties and element information from the periodic table. These
eeACSFs are a key for our development of a lifelong machine learning potential
(lMLP). Uncertainty quantification can be exploited to transgress a fixed,
pre-trained MLP to arrive at a continuously adapting lMLP, because a predefined
level of accuracy can be ensured. To extend the applicability of an lMLP to new
systems, we apply continual learning strategies to enable autonomous and
on-the-fly training on a continuous stream of new data. For the training of
deep neural networks, we propose the continual resilient (CoRe) optimizer and
incremental learning strategies relying on rehearsal of data, regularization of
parameters, and the architecture of the model.",2023-03-10T13:38:36Z,http://arxiv.org/pdf/2303.05911v2,"['cs.LG', 'cond-mat.dis-nn', 'physics.chem-ph', 'physics.comp-ph']"
2009.14596v1,Machine Learning and Computational Mathematics,['Weinan E'],"Neural network-based machine learning is capable of approximating functions
in very high dimension with unprecedented efficiency and accuracy. This has
opened up many exciting new possibilities, not just in traditional areas of
artificial intelligence, but also in scientific computing and computational
science. At the same time, machine learning has also acquired the reputation of
being a set of ""black box"" type of tricks, without fundamental principles. This
has been a real obstacle for making further progress in machine learning. In
this article, we try to address the following two very important questions: (1)
How machine learning has already impacted and will further impact computational
mathematics, scientific computing and computational science? (2) How
computational mathematics, particularly numerical analysis, {can} impact
machine learning? We describe some of the most important progress that has been
made on these issues. Our hope is to put things into a perspective that will
help to integrate machine learning with computational mathematics.",2020-09-23T23:16:46Z,http://arxiv.org/pdf/2009.14596v1,"['math.NA', 'cs.LG', 'cs.NA', 'stat.ML', '68T07, 46E15, 26B35, 26B40']"
2104.05314v2,Machine learning and deep learning,"['Christian Janiesch', 'Patrick Zschech', 'Kai Heinrich']","Today, intelligent systems that offer artificial intelligence capabilities
often rely on machine learning. Machine learning describes the capacity of
systems to learn from problem-specific training data to automate the process of
analytical model building and solve associated tasks. Deep learning is a
machine learning concept based on artificial neural networks. For many
applications, deep learning models outperform shallow machine learning models
and traditional data analysis approaches. In this article, we summarize the
fundamentals of machine learning and deep learning to generate a broader
understanding of the methodical underpinning of current intelligent systems. In
particular, we provide a conceptual distinction between relevant terms and
concepts, explain the process of automated analytical model building through
machine learning and deep learning, and discuss the challenges that arise when
implementing such intelligent systems in the field of electronic markets and
networked business. These naturally go beyond technological aspects and
highlight issues in human-machine interaction and artificial intelligence
servitization.",2021-04-12T09:54:12Z,http://arxiv.org/pdf/2104.05314v2,['cs.AI']
1301.1575v1,BigDB: Automatic Machine Learning Optimizer,"['Anna Pyayt', 'Michael Gubanov']","In this short vision paper, we introduce a machine learning optimizer for
data management and describe its architecture and main functionality.",2013-01-06T04:03:29Z,http://arxiv.org/pdf/1301.1575v1,['cs.DB']
1808.00033v3,Techniques for Interpretable Machine Learning,"['Mengnan Du', 'Ninghao Liu', 'Xia Hu']","Interpretable machine learning tackles the important problem that humans
cannot understand the behaviors of complex machine learning models and how
these models arrive at a particular decision. Although many approaches have
been proposed, a comprehensive understanding of the achievements and challenges
is still lacking. We provide a survey covering existing techniques to increase
the interpretability of machine learning models. We also discuss crucial issues
that the community should consider in future work such as designing
user-friendly explanations and developing comprehensive evaluation metrics to
further push forward the area of interpretable machine learning.",2018-07-31T19:14:39Z,http://arxiv.org/pdf/1808.00033v3,"['cs.LG', 'cs.AI', 'stat.ML']"
2007.07981v1,Differential Replication in Machine Learning,"['Irene Unceta', 'Jordi Nin', 'Oriol Pujol']","When deployed in the wild, machine learning models are usually confronted
with data and requirements that constantly vary, either because of changes in
the generating distribution or because external constraints change the
environment where the model operates. To survive in such an ecosystem, machine
learning models need to adapt to new conditions by evolving over time. The idea
of model adaptability has been studied from different perspectives. In this
paper, we propose a solution based on reusing the knowledge acquired by the
already deployed machine learning models and leveraging it to train future
generations. This is the idea behind differential replication of machine
learning models.",2020-07-15T20:26:49Z,http://arxiv.org/pdf/2007.07981v1,"['cs.LG', 'stat.ML', 'cs.LG, stat.ML']"
2201.06921v1,Can Machine Learning be Moral?,"['Miguel Sicart', 'Irina Shklovski', 'Mirabelle Jones']","The ethics of Machine Learning has become an unavoidable topic in the AI
Community. The deployment of machine learning systems in multiple social
contexts has resulted in a closer ethical scrutiny of the design, development,
and application of these systems. The AI/ML community has come to terms with
the imperative to think about the ethical implications of machine learning, not
only as a product but also as a practice (Birhane, 2021; Shen et al. 2021). The
critical question that is troubling many debates is what can constitute an
ethically accountable machine learning system. In this paper we explore
possibilities for ethical evaluation of machine learning methodologies. We
scrutinize techniques, methods and technical practices in machine learning from
a relational ethics perspective, taking into consideration how machine learning
systems are part of the world and how they relate to different forms of agency.
Taking a page from Phil Agre (1997) we use the notion of a critical technical
practice as a means of analysis of machine learning approaches. Our radical
proposal is that supervised learning appears to be the only machine learning
method that is ethically defensible.",2021-12-13T07:20:50Z,http://arxiv.org/pdf/2201.06921v1,"['cs.CY', 'cs.HC']"
1708.06992v2,Econométrie et Machine Learning,"['Arthur Charpentier', 'Emmanuel Flachaire', 'Antoine Ly']","Econometrics and machine learning seem to have one common goal: to construct
a predictive model, for a variable of interest, using explanatory variables (or
features). However, these two fields developed in parallel, thus creating two
different cultures, to paraphrase Breiman (2001). The first was to build
probabilistic models to describe economic phenomena. The second uses algorithms
that will learn from their mistakes, with the aim, most often to classify
(sounds, images, etc.). Recently, however, learning models have proven to be
more effective than traditional econometric techniques (with a price to pay
less explanatory power), and above all, they manage to manage much larger data.
In this context, it becomes necessary for econometricians to understand what
these two cultures are, what opposes them and especially what brings them
closer together, in order to appropriate tools developed by the statistical
learning community to integrate them into Econometric models.",2017-07-26T21:12:42Z,http://arxiv.org/pdf/1708.06992v2,"['stat.OT', 'econ.EM']"
1808.05787v1,Machine Learning Configuration Interaction,['J. P. Coe'],"We propose the concept of machine learning configuration interaction (MLCI)
whereby an artificial neural network is trained on-the-fly to predict important
new configurations in an iterative selected configuration interaction
procedure. We demonstrate that the neural network can discriminate between
important and unimportant configurations, that it has not been trained on, much
better than by chance. MLCI is then used to find compact wavefunctions for
carbon monoxide at both stretched and equilibrium geometries. We also consider
the multireference problem of the water molecule with elongated bonds. Results
are contrasted with those from other ways of selecting configurations:
first-order perturbation, random selection and Monte Carlo configuration
interaction. Compared with these other serial calculations, this prototype MLCI
is competitive in its accuracy, converges in significantly fewer iterations
than the stochastic approaches, and requires less time for the higher-accuracy
computations.",2018-08-17T08:10:36Z,http://arxiv.org/pdf/1808.05787v1,"['physics.chem-ph', 'physics.comp-ph', 'quant-ph']"
1903.01879v2,Copying Machine Learning Classifiers,"['Irene Unceta', 'Jordi Nin', 'Oriol Pujol']","We study model-agnostic copies of machine learning classifiers. We develop
the theory behind the problem of copying, highlighting its differences with
that of learning, and propose a framework to copy the functionality of any
classifier using no prior knowledge of its parameters or training data
distribution. We identify the different sources of loss and provide guidelines
on how best to generate synthetic sets for the copying process. We further
introduce a set of metrics to evaluate copies in practice. We validate our
framework through extensive experiments using data from a series of well-known
problems. We demonstrate the value of copies in use cases where desiderata such
as interpretability, fairness or productivization constrains need to be
addressed. Results show that copies can be exploited to enhance existing
solutions and improve them adding new features and characteristics.",2019-03-05T15:03:37Z,http://arxiv.org/pdf/1903.01879v2,"['cs.LG', 'stat.ML']"
2004.03865v1,Manipulation-Proof Machine Learning,"['Daniel Björkegren', 'Joshua E. Blumenstock', 'Samsun Knight']","An increasing number of decisions are guided by machine learning algorithms.
In many settings, from consumer credit to criminal justice, those decisions are
made by applying an estimator to data on an individual's observed behavior. But
when consequential decisions are encoded in rules, individuals may
strategically alter their behavior to achieve desired outcomes. This paper
develops a new class of estimator that is stable under manipulation, even when
the decision rule is fully transparent. We explicitly model the costs of
manipulating different behaviors, and identify decision rules that are stable
in equilibrium. Through a large field experiment in Kenya, we show that
decision rules estimated with our strategy-robust method outperform those based
on standard supervised learning approaches.",2020-04-08T08:04:01Z,http://arxiv.org/pdf/2004.03865v1,"['econ.TH', 'cs.LG', 'econ.EM']"
2006.00123v1,Machine Learning Fund Categorizations,"['Dhagash Mehta', 'Dhruv Desai', 'Jithin Pradeep']","Given the surge in popularity of mutual funds (including exchange-traded
funds (ETFs)) as a diversified financial investment, a vast variety of mutual
funds from various investment management firms and diversification strategies
have become available in the market. Identifying similar mutual funds among
such a wide landscape of mutual funds has become more important than ever
because of many applications ranging from sales and marketing to portfolio
replication, portfolio diversification and tax loss harvesting. The current
best method is data-vendor provided categorization which usually relies on
curation by human experts with the help of available data. In this work, we
establish that an industry wide well-regarded categorization system is
learnable using machine learning and largely reproducible, and in turn
constructing a truly data-driven categorization. We discuss the intellectual
challenges in learning this man-made system, our results and their
implications.",2020-05-29T23:26:14Z,http://arxiv.org/pdf/2006.00123v1,"['q-fin.ST', 'cs.LG', 'q-fin.CP', 'stat.ML']"
2002.04640v1,Debugging Machine Learning Pipelines,"['Raoni Lourenço', 'Juliana Freire', 'Dennis Shasha']","Machine learning tasks entail the use of complex computational pipelines to
reach quantitative and qualitative conclusions. If some of the activities in a
pipeline produce erroneous or uninformative outputs, the pipeline may fail or
produce incorrect results. Inferring the root cause of failures and unexpected
behavior is challenging, usually requiring much human thought, and is both
time-consuming and error-prone. We propose a new approach that makes use of
iteration and provenance to automatically infer the root causes and derive
succinct explanations of failures. Through a detailed experimental evaluation,
we assess the cost, precision, and recall of our approach compared to the state
of the art. Our source code and experimental data will be available for
reproducibility and enhancement.",2020-02-11T19:13:12Z,http://arxiv.org/pdf/2002.04640v1,"['cs.LG', 'cs.DB', 'stat.ML']"
1806.03121v3,Machine Learning CICY Threefolds,"['Kieran Bull', 'Yang-Hui He', 'Vishnu Jejjala', 'Challenger Mishra']","The latest techniques from Neural Networks and Support Vector Machines (SVM)
are used to investigate geometric properties of Complete Intersection
Calabi-Yau (CICY) threefolds, a class of manifolds that facilitate string model
building. An advanced neural network classifier and SVM are employed to (1)
learn Hodge numbers and report a remarkable improvement over previous efforts,
(2) query for favourability, and (3) predict discrete symmetries, a highly
imbalanced problem to which both Synthetic Minority Oversampling Technique
(SMOTE) and permutations of the CICY matrix are used to decrease the class
imbalance and improve performance. In each case study, we employ a genetic
algorithm to optimise the hyperparameters of the neural network. We demonstrate
that our approach provides quick diagnostic tools capable of shortlisting
quasi-realistic string models based on compactification over smooth CICYs and
further supports the paradigm that classes of problems in algebraic geometry
can be machine learned.",2018-06-08T12:40:04Z,http://arxiv.org/pdf/1806.03121v3,"['hep-th', 'hep-ph', 'math.AG', 'stat.ML']"
2008.13492v3,Wireless for Machine Learning,"['Henrik Hellström', 'José Mairton B. da Silva Jr', 'Mohammad Mohammadi Amiri', 'Mingzhe Chen', 'Viktoria Fodor', 'H. Vincent Poor', 'Carlo Fischione']","As data generation increasingly takes place on devices without a wired
connection, machine learning (ML) related traffic will be ubiquitous in
wireless networks. Many studies have shown that traditional wireless protocols
are highly inefficient or unsustainable to support ML, which creates the need
for new wireless communication methods. In this survey, we give an exhaustive
review of the state-of-the-art wireless methods that are specifically designed
to support ML services over distributed datasets. Currently, there are two
clear themes within the literature, analog over-the-air computation and digital
radio resource management optimized for ML. This survey gives a comprehensive
introduction to these methods, reviews the most important works, highlights
open problems, and discusses application scenarios.",2020-08-31T11:09:49Z,http://arxiv.org/pdf/2008.13492v3,"['eess.SP', 'cs.LG']"
2111.14514v1,Naive Automated Machine Learning,"['Felix Mohr', 'Marcel Wever']","An essential task of Automated Machine Learning (AutoML) is the problem of
automatically finding the pipeline with the best generalization performance on
a given dataset. This problem has been addressed with sophisticated black-box
optimization techniques such as Bayesian Optimization, Grammar-Based Genetic
Algorithms, and tree search algorithms. Most of the current approaches are
motivated by the assumption that optimizing the components of a pipeline in
isolation may yield sub-optimal results. We present Naive AutoML, an approach
that does precisely this: It optimizes the different algorithms of a
pre-defined pipeline scheme in isolation. The finally returned pipeline is
obtained by just taking the best algorithm of each slot. The isolated
optimization leads to substantially reduced search spaces, and, surprisingly,
this approach yields comparable and sometimes even better performance than
current state-of-the-art optimizers.",2021-11-29T13:12:54Z,http://arxiv.org/pdf/2111.14514v1,['cs.LG']
2112.08440v5,Climate-Invariant Machine Learning,"['Tom Beucler', 'Pierre Gentine', 'Janni Yuval', 'Ankitesh Gupta', 'Liran Peng', 'Jerry Lin', 'Sungduk Yu', 'Stephan Rasp', 'Fiaz Ahmed', ""Paul A. O'Gorman"", 'J. David Neelin', 'Nicholas J. Lutsko', 'Michael Pritchard']","Projecting climate change is a generalization problem: we extrapolate the
recent past using physical models across past, present, and future climates.
Current climate models require representations of processes that occur at
scales smaller than model grid size, which have been the main source of model
projection uncertainty. Recent machine learning (ML) algorithms hold promise to
improve such process representations, but tend to extrapolate poorly to climate
regimes they were not trained on. To get the best of the physical and
statistical worlds, we propose a new framework - termed ""climate-invariant"" ML
- incorporating knowledge of climate processes into ML algorithms, and show
that it can maintain high offline accuracy across a wide range of climate
conditions and configurations in three distinct atmospheric models. Our results
suggest that explicitly incorporating physical knowledge into data-driven
models of Earth system processes can improve their consistency, data
efficiency, and generalizability across climate regimes.",2021-12-14T07:02:57Z,http://arxiv.org/pdf/2112.08440v5,"['cs.LG', 'physics.ao-ph', 'physics.comp-ph']"
2206.00885v1,Coordinated Double Machine Learning,"['Nitai Fingerhut', 'Matteo Sesia', 'Yaniv Romano']","Double machine learning is a statistical method for leveraging complex
black-box models to construct approximately unbiased treatment effect estimates
given observational data with high-dimensional covariates, under the assumption
of a partially linear model. The idea is to first fit on a subset of the
samples two non-linear predictive models, one for the continuous outcome of
interest and one for the observed treatment, and then to estimate a linear
coefficient for the treatment using the remaining samples through a simple
orthogonalized regression. While this methodology is flexible and can
accommodate arbitrary predictive models, typically trained independently of one
another, this paper argues that a carefully coordinated learning algorithm for
deep neural networks may reduce the estimation bias. The improved empirical
performance of the proposed method is demonstrated through numerical
experiments on both simulated and real data.",2022-06-02T05:56:21Z,http://arxiv.org/pdf/2206.00885v1,"['stat.ML', 'cs.LG', 'stat.ME']"
2306.04734v1,Machine-Learning Kronecker Coefficients,['Kyu-Hwan Lee'],"The Kronecker coefficients are the decomposition multiplicities of the tensor
product of two irreducible representations of the symmetric group. Unlike the
Littlewood--Richardson coefficients, which are the analogues for the general
linear group, there is no known combinatorial description of the Kronecker
coefficients, and it is an NP-hard problem to decide whether a given Kronecker
coefficient is zero or not. In this paper, we show that standard
machine-learning algorithms such as Nearest Neighbors, Convolutional Neural
Networks and Gradient Boosting Decision Trees may be trained to predict whether
a given Kronecker coefficient is zero or not. Our results show that a trained
machine can efficiently perform this binary classification with high accuracy
($\approx 0.98$).",2023-06-07T19:10:44Z,http://arxiv.org/pdf/2306.04734v1,"['math.RT', 'math.CO', 'stat.ML']"
2412.11526v3,Probabilities-Informed Machine Learning,['Mohsen Rashki'],"Machine learning (ML) has emerged as a powerful tool for tackling complex
regression and classification tasks, yet its success often hinges on the
quality of training data. This study introduces an ML paradigm inspired by
domain knowledge of the structure of output function, akin to physics-informed
ML, but rooted in probabilistic principles rather than physical laws. The
proposed approach integrates the probabilistic structure of the target variable
(such as its cumulative distribution function) into the training process. This
probabilistic information is obtained from historical data or estimated using
structural reliability methods during experimental design. By embedding
domain-specific probabilistic insights into the learning process, the technique
enhances model accuracy and mitigates risks of overfitting and underfitting.
Applications in regression, image denoising, and classification demonstrate the
approach's effectiveness in addressing real-world problems.",2024-12-16T08:01:22Z,http://arxiv.org/pdf/2412.11526v3,"['cs.LG', 'math.PR']"
2507.10363v1,Machine-Learning to Trust,['Ran Spiegler'],"Can players sustain long-run trust when their equilibrium beliefs are shaped
by machine-learning methods that penalize complexity? I study a game in which
an infinite sequence of agents with one-period recall decides whether to place
trust in their immediate successor. The cost of trusting is state-dependent.
Each player's best response is based on a belief about others' behavior, which
is a coarse fit of the true population strategy with respect to a partition of
relevant contingencies. In equilibrium, this partition minimizes the sum of the
mean squared prediction error and a complexity penalty proportional to its
size. Relative to symmetric mixed-strategy Nash equilibrium, this solution
concept significantly narrows the scope for trust.",2025-07-14T15:03:50Z,http://arxiv.org/pdf/2507.10363v1,['econ.TH']
1802.05688v4,Simulation assisted machine learning,"['Timo M. Deist', 'Andrew Patti', 'Zhaoqi Wang', 'David Krane', 'Taylor Sorenson', 'David Craft']","Motivation: In a predictive modeling setting, if sufficient details of the
system behavior are known, one can build and use a simulation for making
predictions. When sufficient system details are not known, one typically turns
to machine learning, which builds a black-box model of the system using a large
dataset of input sample features and outputs. We consider a setting which is
between these two extremes: some details of the system mechanics are known but
not enough for creating simulations that can be used to make high quality
predictions. In this context we propose using approximate simulations to build
a kernel for use in kernelized machine learning methods, such as support vector
machines. The results of multiple simulations (under various uncertainty
scenarios) are used to compute similarity measures between every pair of
samples: sample pairs are given a high similarity score if they behave
similarly under a wide range of simulation parameters. These similarity values,
rather than the original high dimensional feature data, are used to build the
kernel.
  Results: We demonstrate and explore the simulation based kernel (SimKern)
concept using four synthetic complex systems--three biologically inspired
models and one network flow optimization model. We show that, when the number
of training samples is small compared to the number of features, the SimKern
approach dominates over no-prior-knowledge methods. This approach should be
applicable in all disciplines where predictive models are sought and
informative yet approximate simulations are available.
  Availability: The Python SimKern software, the demonstration models (in
MATLAB, R), and the datasets are available at
https://github.com/davidcraft/SimKern.",2018-02-15T18:04:34Z,http://arxiv.org/pdf/1802.05688v4,"['stat.ML', 'cs.LG', 'q-bio.QM']"
2409.18397v2,Scientific Machine Learning Seismology,['Tomohisa Okazaki'],"Scientific machine learning (SciML) is an interdisciplinary research field
that integrates machine learning, particularly deep learning, with physics
theory to understand and predict complex natural phenomena. By incorporating
physical knowledge, SciML reduces the dependency on observational data, which
is often limited in the natural sciences. In this article, the fundamental
concepts of SciML, its applications in seismology, and prospects are described.
Specifically, two popular methods are mainly discussed: physics-informed neural
networks (PINNs) and neural operators (NOs). PINNs can address both forward and
inverse problems by incorporating governing laws into the loss functions. The
use of PINNs is expanding into areas such as simultaneous solutions of
differential equations, inference in underdetermined systems, and
regularization based on physics. These research directions would broaden the
scope of deep learning in natural sciences. NOs are models designed for
operator learning, which deals with relationships between infinite-dimensional
spaces. NOs show promise in modeling the time evolution of complex systems
based on observational or simulation data. Since large amounts of data are
often required, combining NOs with physics-informed learning holds significant
potential. Finally, SciML is considered from a broader perspective beyond deep
learning: statistical (or mathematical) frameworks that integrate observational
data with physical principles to model natural phenomena. In seismology,
mathematically rigorous Bayesian statistics has been developed over the past
decades, whereas more flexible and scalable deep learning has only emerged
recently. Both approaches can be considered as part of SciML in a broad sense.
Theoretical and practical insights in both directions would advance SciML
methodologies and thereby deepen our understanding of earthquake phenomena.",2024-09-27T02:27:42Z,http://arxiv.org/pdf/2409.18397v2,"['physics.geo-ph', 'cs.LG', 'physics.comp-ph']"
1803.09103v1,Machine Learning and Applied Linguistics,['Sowmya Vajjala'],"This entry introduces the topic of machine learning and provides an overview
of its relevance for applied linguistics and language learning. The discussion
will focus on giving an introduction to the methods and applications of machine
learning in applied linguistics, and will provide references for further study.",2018-03-24T13:08:56Z,http://arxiv.org/pdf/1803.09103v1,['cs.CL']
2112.02309v2,Machine Learning in Nuclear Physics,"['Amber Boehnlein', 'Markus Diefenthaler', 'Cristiano Fanelli', 'Morten Hjorth-Jensen', 'Tanja Horn', 'Michelle P. Kuchera', 'Dean Lee', 'Witold Nazarewicz', 'Kostas Orginos', 'Peter Ostroumov', 'Long-Gang Pang', 'Alan Poon', 'Nobuo Sato', 'Malachi Schram', 'Alexander Scheinker', 'Michael S. Smith', 'Xin-Nian Wang', 'Veronique Ziegler']","Advances in machine learning methods provide tools that have broad
applicability in scientific research. These techniques are being applied across
the diversity of nuclear physics research topics, leading to advances that will
facilitate scientific discoveries and societal applications.
  This Review gives a snapshot of nuclear physics research which has been
transformed by machine learning techniques.",2021-12-04T11:26:00Z,http://arxiv.org/pdf/2112.02309v2,"['nucl-th', 'cs.LG', 'hep-ex', 'nucl-ex']"
1905.11075v3,Machine Learning for Fluid Mechanics,"['Steven Brunton', 'Bernd Noack', 'Petros Koumoutsakos']","The field of fluid mechanics is rapidly advancing, driven by unprecedented
volumes of data from field measurements, experiments and large-scale
simulations at multiple spatiotemporal scales. Machine learning offers a wealth
of techniques to extract information from data that could be translated into
knowledge about the underlying fluid mechanics. Moreover, machine learning
algorithms can augment domain knowledge and automate tasks related to flow
control and optimization. This article presents an overview of past history,
current developments, and emerging opportunities of machine learning for fluid
mechanics. It outlines fundamental machine learning methodologies and discusses
their uses for understanding, modeling, optimizing, and controlling fluid
flows. The strengths and limitations of these methods are addressed from the
perspective of scientific inquiry that considers data as an inherent part of
modeling, experimentation, and simulation. Machine learning provides a powerful
information processing framework that can enrich, and possibly even transform,
current lines of fluid mechanics research and industrial applications.",2019-05-27T09:26:17Z,http://arxiv.org/pdf/1905.11075v3,"['physics.flu-dyn', 'cs.LG', 'stat.ML']"
1909.01866v1,Understanding Bias in Machine Learning,"['Jindong Gu', 'Daniela Oelke']","Bias is known to be an impediment to fair decisions in many domains such as
human resources, the public sector, health care etc. Recently, hope has been
expressed that the use of machine learning methods for taking such decisions
would diminish or even resolve the problem. At the same time, machine learning
experts warn that machine learning models can be biased as well. In this
article, our goal is to explain the issue of bias in machine learning from a
technical perspective and to illustrate the impact that biased data can have on
a machine learning model. To reach such a goal, we develop interactive plots to
visualizing the bias learned from synthetic data.",2019-09-02T20:36:19Z,http://arxiv.org/pdf/1909.01866v1,"['cs.LG', 'stat.ML']"
2205.08824v1,Automating In-Network Machine Learning,"['Changgang Zheng', 'Mingyuan Zang', 'Xinpeng Hong', 'Riyad Bensoussane', 'Shay Vargaftik', 'Yaniv Ben-Itzhak', 'Noa Zilberman']","Using programmable network devices to aid in-network machine learning has
been the focus of significant research. However, most of the research was of a
limited scope, providing a proof of concept or describing a closed-source
algorithm. To date, no general solution has been provided for mapping machine
learning algorithms to programmable network devices. In this paper, we present
Planter, an open-source, modular framework for mapping trained machine learning
models to programmable devices. Planter supports a wide range of machine
learning models, multiple targets and can be easily extended. The evaluation of
Planter compares different mapping approaches, and demonstrates the
feasibility, performance, and resource efficiency for applications such as
anomaly detection, financial transactions, and quality of experience.
  The results show that Planter-based in-network machine learning algorithms
can run at line rate, have a negligible effect on latency, coexist with
standard switching functionality, and have no or minor accuracy trade-offs.",2022-05-18T09:42:22Z,http://arxiv.org/pdf/2205.08824v1,"['cs.NI', 'cs.LG']"
2407.19890v1,Quantum Dynamics of Machine Learning,"['Peng Wang', 'Maimaitiniyazi Maimaitiabudula']","The quantum dynamic equation (QDE) of machine learning is obtained based on
Schr\""odinger equation and potential energy equivalence relationship. Through
Wick rotation, the relationship between quantum dynamics and thermodynamics is
also established in this paper. This equation reformulates the iterative
process of machine learning into a time-dependent partial differential equation
with a clear mathematical structure, offering a theoretical framework for
investigating machine learning iterations through quantum and mathematical
theories. Within this framework, the fundamental iterative process, the
diffusion model, and the Softmax and Sigmoid functions are examined, validating
the proposed quantum dynamics equations. This approach not only presents a
rigorous theoretical foundation for machine learning but also holds promise for
supporting the implementation of machine learning algorithms on quantum
computers.",2024-07-07T16:30:46Z,http://arxiv.org/pdf/2407.19890v1,"['quant-ph', 'cs.LG']"
1803.05252v2,Algebraic Machine Learning,"['Fernando Martin-Maroto', 'Gonzalo G. de Polavieja']","Machine learning algorithms use error function minimization to fit a large
set of parameters in a preexisting model. However, error minimization
eventually leads to a memorization of the training dataset, losing the ability
to generalize to other datasets. To achieve generalization something else is
needed, for example a regularization method or stopping the training when error
in a validation dataset is minimal. Here we propose a different approach to
learning and generalization that is parameter-free, fully discrete and that
does not use function minimization. We use the training data to find an
algebraic representation with minimal size and maximal freedom, explicitly
expressed as a product of irreducible components. This algebraic representation
is shown to directly generalize, giving high accuracy in test data, more so the
smaller the representation. We prove that the number of generalizing
representations can be very large and the algebra only needs to find one. We
also derive and test a relationship between compression and error rate. We give
results for a simple problem solved step by step, hand-written character
recognition, and the Queens Completion problem as an example of unsupervised
learning. As an alternative to statistical learning, algebraic learning may
offer advantages in combining bottom-up and top-down information, formal
concept derivation from data and large-scale parallelization.",2018-03-14T13:09:35Z,http://arxiv.org/pdf/1803.05252v2,"['cs.LG', 'cs.DM', 'math.AC', 'math.RA']"
2010.07067v2,Machine Learning Force Fields,"['Oliver T. Unke', 'Stefan Chmiela', 'Huziel E. Sauceda', 'Michael Gastegger', 'Igor Poltavsky', 'Kristof T. Schütt', 'Alexandre Tkatchenko', 'Klaus-Robert Müller']","In recent years, the use of Machine Learning (ML) in computational chemistry
has enabled numerous advances previously out of reach due to the computational
complexity of traditional electronic-structure methods. One of the most
promising applications is the construction of ML-based force fields (FFs), with
the aim to narrow the gap between the accuracy of ab initio methods and the
efficiency of classical FFs. The key idea is to learn the statistical relation
between chemical structure and potential energy without relying on a
preconceived notion of fixed chemical bonds or knowledge about the relevant
interactions. Such universal ML approximations are in principle only limited by
the quality and quantity of the reference data used to train them. This review
gives an overview of applications of ML-FFs and the chemical insights that can
be obtained from them. The core concepts underlying ML-FFs are described in
detail and a step-by-step guide for constructing and testing them from scratch
is given. The text concludes with a discussion of the challenges that remain to
be overcome by the next generation of ML-FFs.",2020-10-14T13:14:14Z,http://arxiv.org/pdf/2010.07067v2,"['physics.chem-ph', 'stat.ML']"
2007.14870v2,Decoding machine learning benchmarks,"['Lucas F. F. Cardoso', 'Vitor C. A. Santos', 'Regiane S. K. Francês', 'Ricardo B. C. Prudêncio', 'Ronnie C. O. Alves']","Despite the availability of benchmark machine learning (ML) repositories
(e.g., UCI, OpenML), there is no standard evaluation strategy yet capable of
pointing out which is the best set of datasets to serve as gold standard to
test different ML algorithms. In recent studies, Item Response Theory (IRT) has
emerged as a new approach to elucidate what should be a good ML benchmark. This
work applied IRT to explore the well-known OpenML-CC18 benchmark to identify
how suitable it is on the evaluation of classifiers. Several classifiers
ranging from classical to ensembles ones were evaluated using IRT models, which
could simultaneously estimate dataset difficulty and classifiers' ability. The
Glicko-2 rating system was applied on the top of IRT to summarize the innate
ability and aptitude of classifiers. It was observed that not all datasets from
OpenML-CC18 are really useful to evaluate classifiers. Most datasets evaluated
in this work (84%) contain easy instances in general (e.g., around 10% of
difficult instances only). Also, 80% of the instances in half of this benchmark
are very discriminating ones, which can be of great use for pairwise algorithm
comparison, but not useful to push classifiers abilities. This paper presents
this new evaluation methodology based on IRT as well as the tool decodIRT,
developed to guide IRT estimation over ML benchmarks.",2020-07-29T14:39:41Z,http://arxiv.org/pdf/2007.14870v2,"['cs.LG', 'stat.ML', 'I.2.6']"
2109.10870v1,SoK: Machine Learning Governance,"['Varun Chandrasekaran', 'Hengrui Jia', 'Anvith Thudi', 'Adelin Travers', 'Mohammad Yaghini', 'Nicolas Papernot']","The application of machine learning (ML) in computer systems introduces not
only many benefits but also risks to society. In this paper, we develop the
concept of ML governance to balance such benefits and risks, with the aim of
achieving responsible applications of ML. Our approach first systematizes
research towards ascertaining ownership of data and models, thus fostering a
notion of identity specific to ML systems. Building on this foundation, we use
identities to hold principals accountable for failures of ML systems through
both attribution and auditing. To increase trust in ML systems, we then survey
techniques for developing assurance, i.e., confidence that the system meets its
security requirements and does not exhibit certain known failures. This leads
us to highlight the need for techniques that allow a model owner to manage the
life cycle of their system, e.g., to patch or retire their ML system. Put
altogether, our systematization of knowledge standardizes the interactions
between principals involved in the deployment of ML throughout its life cycle.
We highlight opportunities for future work, e.g., to formalize the resulting
game between ML principals.",2021-09-20T17:56:22Z,http://arxiv.org/pdf/2109.10870v1,"['cs.CR', 'cs.LG', 'cs.SE']"
2211.14142v2,Machine learning cosmic inflation,"['Ahana Kamerkar', 'Savvas Nesseris', 'Lucas Pinol']","We present a machine-learning approach, based on the genetic algorithms (GA),
that can be used to reconstruct the inflationary potential directly from
cosmological data. We create a pipeline consisting of the GA, a primordial code
and a Boltzmann code used to calculate the theoretical predictions, and Cosmic
Microwave Background (CMB) data. As a proof of concept, we apply our
methodology to the Planck CMB data and explore the functional space of
single-field inflationary potentials in a non-parametric, yet analytical way.
We show that the algorithm easily improves upon the vanilla model of quadratic
inflation and proposes slow-roll potentials better suited to the data, while we
confirm the robustness of the Starobinsky inflation model (and other
small-field models). Moreover, using unbinned CMB data, we perform a first
concrete application of the GA by searching for oscillatory features in the
potential in an agnostic way, and find very significant improvements upon the
best featureless potentials, $\Delta \chi^2 < -20$. These encouraging
preliminary results motivate the search for resonant features in the primordial
power spectrum with a multimodal distribution of frequencies. We stress that
our pipeline is modular and can easily be extended to other CMB data sets and
inflationary scenarios, like multifield inflation or theories with higher-order
derivatives.",2022-11-25T14:42:55Z,http://arxiv.org/pdf/2211.14142v2,"['astro-ph.CO', 'gr-qc', 'hep-ph']"
2409.02668v2,Introduction to Machine Learning,['Laurent Younes'],"This book introduces the mathematical foundations and techniques that lead to
the development and analysis of many of the algorithms that are used in machine
learning. It starts with an introductory chapter that describes notation used
throughout the book and serve at a reminder of basic concepts in calculus,
linear algebra and probability and also introduces some measure theoretic
terminology, which can be used as a reading guide for the sections that use
these tools. The introductory chapters also provide background material on
matrix analysis and optimization. The latter chapter provides theoretical
support to many algorithms that are used in the book, including stochastic
gradient descent, proximal methods, etc. After discussing basic concepts for
statistical prediction, the book includes an introduction to reproducing kernel
theory and Hilbert space techniques, which are used in many places, before
addressing the description of various algorithms for supervised statistical
learning, including linear methods, support vector machines, decision trees,
boosting, or neural networks. The subject then switches to generative methods,
starting with a chapter that presents sampling methods and an introduction to
the theory of Markov chains. The following chapter describe the theory of
graphical models, an introduction to variational methods for models with latent
variables, and to deep-learning based generative models. The next chapters
focus on unsupervised learning methods, for clustering, factor analysis and
manifold learning. The final chapter of the book is theory-oriented and
discusses concentration inequalities and generalization bounds.",2024-09-04T12:51:41Z,http://arxiv.org/pdf/2409.02668v2,"['stat.ML', 'cs.LG']"
2411.00093v3,Machine Learning Electroweakino Production,"['Rafał Masełek', 'Mihoko M. Nojiri', 'Kazuki Sakurai']","The system of light electroweakinos and heavy squarks gives rise to one of
the most challenging signatures to detect at the LHC. It consists of missing
transverse energy recoiled against a few hadronic jets originating either from
QCD radiation or squark decays. The analysis generally suffers from the large
irreducible Z + jets $(Z \to \nu \bar \nu)$ background. In this study, we
explore Machine Learning (ML) methods for efficient signal/background
discrimination. Our best attempt uses both reconstructed (jets, missing
transverse energy, etc.) and low-level (particle-flow) objects. We find that
the discrimination performance improves as the pT threshold for soft particles
is lowered from 10 GeV to 1 GeV, at the expense of larger systematic
uncertainty. In many cases, the ML method provides a factor two enhancement in
$S/\sqrt{(S + B)}$ from a simple kinematical selection. The sensitivity on the
squark-elecroweakino mass plane is derived with this method, assuming the Run-3
and HL-LHC luminosities. Moreover, we investigate the relations between input
features and the network's classification performance to reveal the physical
information used in the background/signal discrimination process.",2024-10-31T18:00:01Z,http://arxiv.org/pdf/2411.00093v3,"['hep-ph', 'hep-ex']"
2111.11537v1,Machine Learning for Mars Exploration,['Ali Momennasab'],"Risk to human astronauts and interplanetary distance causing slow and limited
communication drives scientists to pursue an autonomous approach to exploring
distant planets, such as Mars. A portion of exploration of Mars has been
conducted through the autonomous collection and analysis of Martian data by
spacecraft such as the Mars rovers and the Mars Express Orbiter. The autonomy
used on these Mars exploration spacecraft and on Earth to analyze data
collected by these vehicles mainly consist of machine learning, a field of
artificial intelligence where algorithms collect data and self-improve with the
data. Additional applications of machine learning techniques for Mars
exploration have potential to resolve communication limitations and human risks
of interplanetary exploration. In addition, analyzing Mars data with machine
learning has the potential to provide a greater understanding of Mars in
numerous domains such as its climate, atmosphere, and potential future
habitation. To explore further utilizations of machine learning techniques for
Mars exploration, this paper will first summarize the general features and
phenomena of Mars to provide a general overview of the planet, elaborate upon
uncertainties of Mars that would be beneficial to explore and understand,
summarize every current or previous usage of machine learning techniques in the
exploration of Mars, explore implementations of machine learning that will be
utilized in future Mars exploration missions, and explore machine learning
techniques used in Earthly domains to provide solutions to the previously
described uncertainties of Mars.",2021-11-22T21:11:42Z,http://arxiv.org/pdf/2111.11537v1,"['astro-ph.EP', 'astro-ph.IM', 'cs.LG']"
1805.03441v1,Machine Learning in Compiler Optimisation,"['Zheng Wang', ""Michael O'Boyle""]","In the last decade, machine learning based compilation has moved from an an
obscure research niche to a mainstream activity. In this article, we describe
the relationship between machine learning and compiler optimisation and
introduce the main concepts of features, models, training and deployment. We
then provide a comprehensive survey and provide a road map for the wide variety
of different research areas. We conclude with a discussion on open issues in
the area and potential research directions. This paper provides both an
accessible introduction to the fast moving area of machine learning based
compilation and a detailed bibliography of its main achievements.",2018-05-09T10:04:28Z,http://arxiv.org/pdf/1805.03441v1,"['cs.PL', 'cs.DC', 'cs.LG', 'cs.SE']"
1812.10422v1,Machine Learning in Official Statistics,"['Martin Beck', 'Florian Dumpert', 'Joerg Feuerhake']","In the first half of 2018, the Federal Statistical Office of Germany
(Destatis) carried out a ""Proof of Concept Machine Learning"" as part of its
Digital Agenda. A major component of this was surveys on the use of machine
learning methods in official statistics, which were conducted at selected
national and international statistical institutions and among the divisions of
Destatis. It was of particular interest to find out in which statistical areas
and for which tasks machine learning is used and which methods are applied.
This paper is intended to make the results of the surveys publicly accessible.",2018-12-13T11:02:01Z,http://arxiv.org/pdf/1812.10422v1,"['cs.CY', 'cs.LG', 'stat.ML']"
2102.05639v1,Energy-Harvesting Distributed Machine Learning,"['Basak Guler', 'Aylin Yener']","This paper provides a first study of utilizing energy harvesting for
sustainable machine learning in distributed networks. We consider a distributed
learning setup in which a machine learning model is trained over a large number
of devices that can harvest energy from the ambient environment, and develop a
practical learning framework with theoretical convergence guarantees. We
demonstrate through numerical experiments that the proposed framework can
significantly outperform energy-agnostic benchmarks. Our framework is scalable,
requires only local estimation of the energy statistics, and can be applied to
a wide range of distributed training settings, including machine learning in
wireless networks, edge computing, and mobile internet of things.",2021-02-10T18:53:51Z,http://arxiv.org/pdf/2102.05639v1,"['cs.LG', 'cs.IT', 'math.IT', 'stat.ML']"
1805.05052v17,Machine Learning: The Basics,['Alexander Jung'],"Machine learning (ML) has become a commodity in our every-day lives. We
routinely ask ML empowered smartphones to suggest lovely food places or to
guide us through a strange place. ML methods have also become standard tools in
many fields of science and engineering. A plethora of ML applications transform
human lives at unprecedented pace and scale. This book portrays ML as the
combination of three basic components: data, model and loss. ML methods combine
these three components within computationally efficient implementations of the
basic scientific principle ""trial and error"". This principle consists of the
continuous adaptation of a hypothesis about a phenomenon that generates data.
ML methods use a hypothesis to compute predictions for future events. We
believe that thinking about ML as combinations of three components given by
data, model, and loss helps to navigate the steadily growing offer for
ready-to-use ML methods. Our three-component picture of ML allows a unified
treatment of a wide range of concepts and techniques which seem quite unrelated
at first sight. The regularization effect of early stopping in iterative
methods is due to the shrinking of the effective hypothesis space.
Privacy-preserving ML is obtained by particular choices for the features of
data points. Explainable ML methods are characterized by particular choices for
the hypothesis space. To make good use of ML tools it is instrumental to
understand its underlying principles at different levels of detail. On a lower
level, this tutorial helps ML engineers to choose suitable methods for the
application at hand. The book also offers a higher-level view on the
implementation of ML methods which is typically required to manage a team of ML
engineers and data scientists.",2018-05-14T08:08:33Z,http://arxiv.org/pdf/1805.05052v17,"['cs.LG', 'stat.ML', '97K80, 65Fxx', 'A.1; I.2; I.5; G.3; G.1']"
2107.08148v1,Declarative Machine Learning Systems,"['Piero Molino', 'Christopher Ré']","In the last years machine learning (ML) has moved from a academic endeavor to
a pervasive technology adopted in almost every aspect of computing. ML-powered
products are now embedded in our digital lives: from recommendations of what to
watch, to divining our search intent, to powering virtual assistants in
consumer and enterprise settings. Recent successes in applying ML in natural
sciences revealed that ML can be used to tackle some of the hardest real-world
problems humanity faces today. For these reasons ML has become central in the
strategy of tech companies and has gathered even more attention from academia
than ever before. Despite these successes, what we have witnessed so far is
just the beginning. Right now the people training and using ML models are
expert developers working within large organizations, but we believe the next
wave of ML systems will allow a larger amount of people, potentially without
coding skills, to perform the same tasks. These new ML systems will not require
users to fully understand all the details of how models are trained and
utilized for obtaining predictions. Declarative interfaces are well suited for
this goal, by hiding complexity and favouring separation of interests, and can
lead to increased productivity. We worked on such abstract interfaces by
developing two declarative ML systems, Overton and Ludwig, that require users
to declare only their data schema (names and types of inputs) and tasks rather
then writing low level ML code. In this article we will describe how ML systems
are currently structured, highlight important factors for their success and
adoption, what are the issues current ML systems are facing and how the systems
we developed addressed them. Finally we will talk about learnings from the
development of ML systems throughout the years and how we believe the next
generation of ML systems will look like.",2021-07-16T23:57:57Z,http://arxiv.org/pdf/2107.08148v1,"['cs.LG', 'cs.AI', 'cs.SE']"
2010.10981v1,Amnesiac Machine Learning,"['Laura Graves', 'Vineel Nagisetty', 'Vijay Ganesh']","The Right to be Forgotten is part of the recently enacted General Data
Protection Regulation (GDPR) law that affects any data holder that has data on
European Union residents. It gives EU residents the ability to request deletion
of their personal data, including training records used to train machine
learning models. Unfortunately, Deep Neural Network models are vulnerable to
information leaking attacks such as model inversion attacks which extract class
information from a trained model and membership inference attacks which
determine the presence of an example in a model's training data. If a malicious
party can mount an attack and learn private information that was meant to be
removed, then it implies that the model owner has not properly protected their
user's rights and their models may not be compliant with the GDPR law. In this
paper, we present two efficient methods that address this question of how a
model owner or data holder may delete personal data from models in such a way
that they may not be vulnerable to model inversion and membership inference
attacks while maintaining model efficacy. We start by presenting a real-world
threat model that shows that simply removing training data is insufficient to
protect users. We follow that up with two data removal methods, namely
Unlearning and Amnesiac Unlearning, that enable model owners to protect
themselves against such attacks while being compliant with regulations. We
provide extensive empirical analysis that show that these methods are indeed
efficient, safe to apply, effectively remove learned information about
sensitive data from trained models while maintaining model efficacy.",2020-10-21T13:14:17Z,http://arxiv.org/pdf/2010.10981v1,"['cs.LG', 'cs.AI', 'cs.CR']"
1901.03415v2,Context Aware Machine Learning,['Yun Zeng'],"We propose a principle for exploring context in machine learning models.
Starting with a simple assumption that each observation may or may not depend
on its context, a conditional probability distribution is decomposed into two
parts: context-free and context-sensitive. Then by employing the log-linear
word production model for relating random variables to their embedding space
representation and making use of the convexity of natural exponential function,
we show that the embedding of an observation can also be decomposed into a
weighted sum of two vectors, representing its context-free and
context-sensitive parts, respectively. This simple treatment of context
provides a unified view of many existing deep learning models, leading to
revisions of these models able to achieve significant performance boost.
Specifically, our upgraded version of a recent sentence embedding model not
only outperforms the original one by a large margin, but also leads to a new,
principled approach for compositing the embeddings of bag-of-words features, as
well as a new architecture for modeling attention in deep neural networks. More
surprisingly, our new principle provides a novel understanding of the gates and
equations defined by the long short term memory model, which also leads to a
new model that is able to converge significantly faster and achieve much lower
prediction errors. Furthermore, our principle also inspires a new type of
generic neural network layer that better resembles real biological neurons than
the traditional linear mapping plus nonlinear activation based architecture.
Its multi-layer extension provides a new principle for deep neural networks
which subsumes residual network (ResNet) as its special case, and its extension
to convolutional neutral network model accounts for irrelevant input (e.g.,
background in an image) in addition to filtering.",2019-01-10T22:12:24Z,http://arxiv.org/pdf/1901.03415v2,"['cs.LG', 'stat.ML']"
2007.13086v3,Anonymizing Machine Learning Models,"['Abigail Goldsteen', 'Gilad Ezov', 'Ron Shmelkin', 'Micha Moffie', 'Ariel Farkash']","There is a known tension between the need to analyze personal data to drive
business and privacy concerns. Many data protection regulations, including the
EU General Data Protection Regulation (GDPR) and the California Consumer
Protection Act (CCPA), set out strict restrictions and obligations on the
collection and processing of personal data. Moreover, machine learning models
themselves can be used to derive personal information, as demonstrated by
recent membership and attribute inference attacks. Anonymized data, however, is
exempt from the obligations set out in these regulations. It is therefore
desirable to be able to create models that are anonymized, thus also exempting
them from those obligations, in addition to providing better protection against
attacks.
  Learning on anonymized data typically results in significant degradation in
accuracy. In this work, we propose a method that is able to achieve better
model accuracy by using the knowledge encoded within the trained model, and
guiding our anonymization process to minimize the impact on the model's
accuracy, a process we call accuracy-guided anonymization. We demonstrate that
by focusing on the model's accuracy rather than generic information loss
measures, our method outperforms state of the art k-anonymity methods in terms
of the achieved utility, in particular with high values of k and large numbers
of quasi-identifiers.
  We also demonstrate that our approach has a similar, and sometimes even
better ability to prevent membership inference attacks as approaches based on
differential privacy, while averting some of their drawbacks such as
complexity, performance overhead and model-specific implementations. This makes
model-guided anonymization a legitimate substitute for such methods and a
practical approach to creating privacy-preserving models.",2020-07-26T09:29:03Z,http://arxiv.org/pdf/2007.13086v3,"['cs.CR', 'cs.LG', 'I.2.6; K.6.5']"
1712.07143v2,Machine Learning for Vehicular Networks,"['Hao Ye', 'Le Liang', 'Geoffrey Ye Li', 'JoonBeom Kim', 'Lu Lu', 'May Wu']","The emerging vehicular networks are expected to make everyday vehicular
operation safer, greener, and more efficient, and pave the path to autonomous
driving in the advent of the fifth generation (5G) cellular system. Machine
learning, as a major branch of artificial intelligence, has been recently
applied to wireless networks to provide a data-driven approach to solve
traditionally challenging problems. In this article, we review recent advances
in applying machine learning in vehicular networks and attempt to bring more
attention to this emerging area. After a brief overview of the major concept of
machine learning, we present some application examples of machine learning in
solving problems arising in vehicular networks. We finally discuss and
highlight several open issues that warrant further research.",2017-12-19T19:03:41Z,http://arxiv.org/pdf/1712.07143v2,"['cs.IT', 'math.IT']"
1712.09208v1,Machine Learning Cosmic Expansion History,"['Deng Wang', 'Wei Zhang']","We use the machine learning techniques, for the first time, to study the
background evolution of the universe in light of 30 cosmic chronometers. From 7
machine learning algorithms, using the principle of mean squared error
minimization on testing set, we find that Bayesian ridge regression is the
optimal method to extract the information from cosmic chronometers. By use of a
power-law polynomial expansion, we obtain the first Hubble constant estimation
$H_0=65.95^{+6.98}_{-6.36}$ km s$^{-1}$ Mpc$^{-1}$ from machine learning. From
the view of machine learning, we may rule out a large number of cosmological
models, the number of physical parameters of which containing $H_0$ is larger
than 3. Very importantly and interestingly, we find that the parameter spaces
of 3 specific cosmological models can all be clearly compressed by considering
both their explanation and generalization abilities.",2017-12-26T08:37:39Z,http://arxiv.org/pdf/1712.09208v1,"['astro-ph.CO', 'astro-ph.HE', 'gr-qc']"
2006.05604v1,Machine Learning and Control Theory,"['Alain Bensoussan', 'Yiqun Li', 'Dinh Phan Cao Nguyen', 'Minh-Binh Tran', 'Sheung Chi Phillip Yam', 'Xiang Zhou']","We survey in this article the connections between Machine Learning and
Control Theory. Control Theory provide useful concepts and tools for Machine
Learning. Conversely Machine Learning can be used to solve large control
problems. In the first part of the paper, we develop the connections between
reinforcement learning and Markov Decision Processes, which are discrete time
control problems. In the second part, we review the concept of supervised
learning and the relation with static optimization. Deep learning which extends
supervised learning, can be viewed as a control problem. In the third part, we
present the links between stochastic gradient descent and mean-field theory.
Conversely, in the fourth and fifth parts, we review machine learning
approaches to stochastic control problems, and focus on the deterministic case,
to explain, more easily, the numerical algorithms.",2020-06-10T01:47:34Z,http://arxiv.org/pdf/2006.05604v1,"['cs.LG', 'math.OC', 'stat.ML']"
1802.05351v3,Stealing Hyperparameters in Machine Learning,"['Binghui Wang', 'Neil Zhenqiang Gong']","Hyperparameters are critical in machine learning, as different
hyperparameters often result in models with significantly different
performance. Hyperparameters may be deemed confidential because of their
commercial value and the confidentiality of the proprietary algorithms that the
learner uses to learn them. In this work, we propose attacks on stealing the
hyperparameters that are learned by a learner. We call our attacks
hyperparameter stealing attacks. Our attacks are applicable to a variety of
popular machine learning algorithms such as ridge regression, logistic
regression, support vector machine, and neural network. We evaluate the
effectiveness of our attacks both theoretically and empirically. For instance,
we evaluate our attacks on Amazon Machine Learning. Our results demonstrate
that our attacks can accurately steal hyperparameters. We also study
countermeasures. Our results highlight the need for new defenses against our
hyperparameter stealing attacks for certain machine learning algorithms.",2018-02-14T22:58:31Z,http://arxiv.org/pdf/1802.05351v3,"['cs.CR', 'cs.LG', 'stat.ML']"
1807.04162v3,TherML: Thermodynamics of Machine Learning,"['Alexander A. Alemi', 'Ian Fischer']","In this work we offer a framework for reasoning about a wide class of
existing objectives in machine learning. We develop a formal correspondence
between this work and thermodynamics and discuss its implications.",2018-07-11T14:39:17Z,http://arxiv.org/pdf/1807.04162v3,"['cs.LG', 'cond-mat.stat-mech', 'stat.ML']"
1907.08908v1,Techniques for Automated Machine Learning,"['Yi-Wei Chen', 'Qingquan Song', 'Xia Hu']","Automated machine learning (AutoML) aims to find optimal machine learning
solutions automatically given a machine learning problem. It could release the
burden of data scientists from the multifarious manual tuning process and
enable the access of domain experts to the off-the-shelf machine learning
solutions without extensive experience. In this paper, we review the current
developments of AutoML in terms of three categories, automated feature
engineering (AutoFE), automated model and hyperparameter learning (AutoMHL),
and automated deep learning (AutoDL). State-of-the-art techniques adopted in
the three categories are presented, including Bayesian optimization,
reinforcement learning, evolutionary algorithm, and gradient-based approaches.
We summarize popular AutoML frameworks and conclude with current open
challenges of AutoML.",2019-07-21T04:03:36Z,http://arxiv.org/pdf/1907.08908v1,"['cs.LG', 'cs.AI', 'stat.ML']"
1910.08605v2,Machine learning Calabi-Yau metrics,"['Anthony Ashmore', 'Yang-Hui He', 'Burt Ovrut']","We apply machine learning to the problem of finding numerical Calabi-Yau
metrics. Building on Donaldson's algorithm for calculating balanced metrics on
K\""ahler manifolds, we combine conventional curve fitting and machine-learning
techniques to numerically approximate Ricci-flat metrics. We show that machine
learning is able to predict the Calabi-Yau metric and quantities associated
with it, such as its determinant, having seen only a small sample of training
data. Using this in conjunction with a straightforward curve fitting routine,
we demonstrate that it is possible to find highly accurate numerical metrics
much more quickly than by using Donaldson's algorithm alone, with our new
machine-learning algorithm decreasing the time required by between one and two
orders of magnitude.",2019-10-18T19:53:34Z,http://arxiv.org/pdf/1910.08605v2,"['hep-th', 'math.AG', 'stat.ML']"
2007.01503v1,Mathematical Perspective of Machine Learning,['Yarema Boryshchak'],"We take a closer look at some theoretical challenges of Machine Learning as a
function approximation, gradient descent as the default optimization algorithm,
limitations of fixed length and width networks and a different approach to RNNs
from a mathematical perspective.",2020-07-03T05:26:02Z,http://arxiv.org/pdf/2007.01503v1,"['cs.LG', 'stat.ML', '68T07']"
1805.03362v3,Attractor Reconstruction by Machine Learning,"['Zhixin Lu', 'Brian R. Hunt', 'Edward Ott']","A machine-learning approach called ""reservoir computing"" has been used
successfully for short-term prediction and attractor reconstruction of chaotic
dynamical systems from time series data. We present a theoretical framework
that describes conditions under which reservoir computing can create an
empirical model capable of skillful short-term forecasts and accurate long-term
ergodic behavior. We illustrate this theory through numerical experiments. We
also argue that the theory applies to certain other machine learning methods
for time series prediction.",2018-05-09T03:44:13Z,http://arxiv.org/pdf/1805.03362v3,['nlin.CD']
2202.02414v2,OMLT: Optimization & Machine Learning Toolkit,"['Francesco Ceccon', 'Jordan Jalving', 'Joshua Haddad', 'Alexander Thebelt', 'Calvin Tsay', 'Carl D. Laird', 'Ruth Misener']","The optimization and machine learning toolkit (OMLT) is an open-source
software package incorporating neural network and gradient-boosted tree
surrogate models, which have been trained using machine learning, into larger
optimization problems. We discuss the advances in optimization technology that
made OMLT possible and show how OMLT seamlessly integrates with the algebraic
modeling language Pyomo. We demonstrate how to use OMLT for solving
decision-making problems in both computer science and engineering.",2022-02-04T22:23:45Z,http://arxiv.org/pdf/2202.02414v2,"['stat.ML', 'cs.AI', 'cs.LG', 'math.OC']"
1502.02127v2,Hyperparameter Search in Machine Learning,"['Marc Claesen', 'Bart De Moor']","We introduce the hyperparameter search problem in the field of machine
learning and discuss its main challenges from an optimization perspective.
Machine learning methods attempt to build models that capture some element of
interest based on given data. Most common learning algorithms feature a set of
hyperparameters that must be determined before training commences. The choice
of hyperparameters can significantly affect the resulting model's performance,
but determining good values can be complex; hence a disciplined, theoretically
sound search strategy is essential.",2015-02-07T11:46:22Z,http://arxiv.org/pdf/1502.02127v2,"['cs.LG', 'stat.ML', 'G.1.6; I.2.6; I.2.8; I.5']"
2106.07032v1,Category Theory in Machine Learning,"['Dan Shiebler', 'Bruno Gavranović', 'Paul Wilson']","Over the past two decades machine learning has permeated almost every realm
of technology. At the same time, many researchers have begun using category
theory as a unifying language, facilitating communication between different
scientific disciplines. It is therefore unsurprising that there is a burgeoning
interest in applying category theory to machine learning. We aim to document
the motivations, goals and common themes across these applications. We touch on
gradient-based learning, probability, and equivariant learning.",2021-06-13T15:58:13Z,http://arxiv.org/pdf/2106.07032v1,['cs.LG']
2111.02508v1,AlphaD3M: Machine Learning Pipeline Synthesis,"['Iddo Drori', 'Yamuna Krishnamurthy', 'Remi Rampin', 'Raoni de Paula Lourenco', 'Jorge Piazentin Ono', 'Kyunghyun Cho', 'Claudio Silva', 'Juliana Freire']","We introduce AlphaD3M, an automatic machine learning (AutoML) system based on
meta reinforcement learning using sequence models with self play. AlphaD3M is
based on edit operations performed over machine learning pipeline primitives
providing explainability. We compare AlphaD3M with state-of-the-art AutoML
systems: Autosklearn, Autostacker, and TPOT, on OpenML datasets. AlphaD3M
achieves competitive performance while being an order of magnitude faster,
reducing computation time from hours to minutes, and is explainable by design.",2021-11-03T20:18:48Z,http://arxiv.org/pdf/2111.02508v1,['cs.LG']
2412.20588v2,Kryptonite-N: Machine Learning Strikes Back,"['Albus Li', 'Nathan Bailey', 'Will Sumerfield', 'Kira Kim']","Quinn et al propose challenge datasets in their work called ``Kryptonite-N"".
These datasets aim to counter the universal function approximation argument of
machine learning, breaking the notation that machine learning can ``approximate
any continuous function"" \cite{original_paper}. Our work refutes this claim and
shows that universal function approximations can be applied successfully; the
Kryptonite datasets are constructed predictably, allowing logistic regression
with sufficient polynomial expansion and L1 regularization to solve for any
dimension N.",2024-12-29T21:23:09Z,http://arxiv.org/pdf/2412.20588v2,"['cs.LG', 'cs.AI']"
2009.10050v2,Measuring justice in machine learning,['Alan Lundgard'],"How can we build more just machine learning systems? To answer this question,
we need to know both what justice is and how to tell whether one system is more
or less just than another. That is, we need both a definition and a measure of
justice. Theories of distributive justice hold that justice can be measured (in
part) in terms of the fair distribution of benefits and burdens across people
in society. Recently, the field known as fair machine learning has turned to
John Rawls's theory of distributive justice for inspiration and
operationalization. However, philosophers known as capability theorists have
long argued that Rawls's theory uses the wrong measure of justice, thereby
encoding biases against people with disabilities. If these theorists are right,
is it possible to operationalize Rawls's theory in machine learning systems
without also encoding its biases? In this paper, I draw on examples from fair
machine learning to suggest that the answer to this question is no: the
capability theorists' arguments against Rawls's theory carry over into machine
learning systems. But capability theorists don't only argue that Rawls's theory
uses the wrong measure, they also offer an alternative measure. Which measure
of justice is right? And has fair machine learning been using the wrong one?",2020-09-21T17:46:11Z,http://arxiv.org/pdf/2009.10050v2,"['cs.CY', 'I.2.0; K.4.1; J.1.0']"
2507.23455v1,Machine learning and machine learned prediction in chest X-ray images,"['Shereiff Garrett', 'Abhinav Adhikari', 'Sarina Gautam', 'DaShawn Marquis Morris', 'Chandra Mani Adhikari']","Machine learning and artificial intelligence are fast-growing fields of
research in which data is used to train algorithms, learn patterns, and make
predictions. This approach helps to solve seemingly intricate problems with
significant accuracy without explicit programming by recognizing complex
relationships in data. Taking an example of 5824 chest X-ray images, we
implement two machine learning algorithms, namely, a baseline convolutional
neural network (CNN) and a DenseNet-121, and present our analysis in making
machine-learned predictions in predicting patients with ailments. Both baseline
CNN and DenseNet-121 perform very well in the binary classification problem
presented in this work. Gradient-weighted class activation mapping shows that
DenseNet-121 correctly focuses on essential parts of the input chest X-ray
images in its decision-making more than the baseline CNN.",2025-07-31T11:31:25Z,http://arxiv.org/pdf/2507.23455v1,"['cs.CV', 'cs.AI', 'cs.LG']"
2102.12712v1,Machine Learning for Scientific Discovery,"['Shraddha Surana', 'Yogesh Wadadekar', 'Divya Oberoi']","Machine Learning algorithms are good tools for both classification and
prediction purposes. These algorithms can further be used for scientific
discoveries from the enormous data being collected in our era. We present ways
of discovering and understanding astronomical phenomena by applying machine
learning algorithms to data collected with radio telescopes. We discuss the use
of supervised machine learning algorithms to predict the free parameters of
star formation histories and also better understand the relations between the
different input and output parameters. We made use of Deep Learning to capture
the non-linearity in the parameters. Our models are able to predict with low
error rates and give the advantage of predicting in real time once the model
has been trained. The other class of machine learning algorithms viz.
unsupervised learning can prove to be very useful in finding patterns in the
data. We explore how we use such unsupervised techniques on solar radio data to
identify patterns and variations, and also link such findings to theories,
which help to better understand the nature of the system being studied. We
highlight the challenges faced in terms of data size, availability, features,
processing ability and importantly, the interpretability of results. As our
ability to capture and store data increases, increased use of machine learning
to understand the underlying physics in the information captured seems
inevitable.",2021-02-25T07:22:33Z,http://arxiv.org/pdf/2102.12712v1,['astro-ph.IM']
2301.13724v2,Towards fully covariant machine learning,"['Soledad Villar', 'David W. Hogg', 'Weichi Yao', 'George A. Kevrekidis', 'Bernhard Schölkopf']","Any representation of data involves arbitrary investigator choices. Because
those choices are external to the data-generating process, each choice leads to
an exact symmetry, corresponding to the group of transformations that takes one
possible representation to another. These are the passive symmetries; they
include coordinate freedom, gauge symmetry, and units covariance, all of which
have led to important results in physics. In machine learning, the most visible
passive symmetry is the relabeling or permutation symmetry of graphs. Our goal
is to understand the implications for machine learning of the many passive
symmetries in play. We discuss dos and don'ts for machine learning practice if
passive symmetries are to be respected. We discuss links to causal modeling,
and argue that the implementation of passive symmetries is particularly
valuable when the goal of the learning problem is to generalize out of sample.
This paper is conceptual: It translates among the languages of physics,
mathematics, and machine-learning. We believe that consideration and
implementation of passive symmetries might help machine learning in the same
ways that it transformed physics in the twentieth century.",2023-01-31T16:01:12Z,http://arxiv.org/pdf/2301.13724v2,"['stat.ML', 'astro-ph.IM', 'cs.LG', 'math-ph', 'math.MP', 'physics.data-an']"
2306.00061v2,Shadows of quantum machine learning,"['Sofiene Jerbi', 'Casper Gyurik', 'Simon C. Marshall', 'Riccardo Molteni', 'Vedran Dunjko']","Quantum machine learning is often highlighted as one of the most promising
practical applications for which quantum computers could provide a
computational advantage. However, a major obstacle to the widespread use of
quantum machine learning models in practice is that these models, even once
trained, still require access to a quantum computer in order to be evaluated on
new data. To solve this issue, we introduce a new class of quantum models where
quantum resources are only required during training, while the deployment of
the trained model is classical. Specifically, the training phase of our models
ends with the generation of a 'shadow model' from which the classical
deployment becomes possible. We prove that: i) this class of models is
universal for classically-deployed quantum machine learning; ii) it does have
restricted learning capacities compared to 'fully quantum' models, but
nonetheless iii) it achieves a provable learning advantage over fully classical
learners, contingent on widely-believed assumptions in complexity theory. These
results provide compelling evidence that quantum machine learning can confer
learning advantages across a substantially broader range of scenarios, where
quantum computers are exclusively employed during the training phase. By
enabling classical deployment, our approach facilitates the implementation of
quantum machine learning models in various practical contexts.",2023-05-31T18:00:02Z,http://arxiv.org/pdf/2306.00061v2,"['quant-ph', 'cs.AI', 'cs.LG', 'stat.ML']"
1303.2739v1,Machine Learning for Bioclimatic Modelling,['Maumita Bhattacharya'],"Many machine learning (ML) approaches are widely used to generate bioclimatic
models for prediction of geographic range of organism as a function of climate.
Applications such as prediction of range shift in organism, range of invasive
species influenced by climate change are important parameters in understanding
the impact of climate change. However, success of machine learning-based
approaches depends on a number of factors. While it can be safely said that no
particular ML technique can be effective in all applications and success of a
technique is predominantly dependent on the application or the type of the
problem, it is useful to understand their behavior to ensure informed choice of
techniques. This paper presents a comprehensive review of machine
learning-based bioclimatic model generation and analyses the factors
influencing success of such models. Considering the wide use of statistical
techniques, in our discussion we also include conventional statistical
techniques used in bioclimatic modelling.",2013-03-12T01:13:44Z,http://arxiv.org/pdf/1303.2739v1,"['cs.LG', 'stat.AP', '97R30']"
1607.01224v1,Machine Learning for Antimicrobial Resistance,"['John W. Santerre', 'James J. Davis', 'Fangfang Xia', 'Rick Stevens']","Biological datasets amenable to applied machine learning are more available
today than ever before, yet they lack adequate representation in the
Data-for-Good community. Here we present a work in progress case study
performing analysis on antimicrobial resistance (AMR) using standard ensemble
machine learning techniques and note the successes and pitfalls such work
entails. Broadly, applied machine learning (AML) techniques are well suited to
AMR, with classification accuracies ranging from mid-90% to low- 80% depending
on sample size. Additionally, these techniques prove successful at identifying
gene regions known to be associated with the AMR phenotype. We believe that the
extensive amount of biological data available, the plethora of problems
presented, and the global impact of such work merits the consideration of the
Data- for-Good community.",2016-07-05T12:42:01Z,http://arxiv.org/pdf/1607.01224v1,"['stat.ML', 'q-bio.QM']"
1708.00909v4,Machine learning for neural decoding,"['Joshua I. Glaser', 'Ari S. Benjamin', 'Raeed H. Chowdhury', 'Matthew G. Perich', 'Lee E. Miller', 'Konrad P. Kording']","Despite rapid advances in machine learning tools, the majority of neural
decoding approaches still use traditional methods. Modern machine learning
tools, which are versatile and easy to use, have the potential to significantly
improve decoding performance. This tutorial describes how to effectively apply
these algorithms for typical decoding problems. We provide descriptions, best
practices, and code for applying common machine learning methods, including
neural networks and gradient boosting. We also provide detailed comparisons of
the performance of various methods at the task of decoding spiking activity in
motor cortex, somatosensory cortex, and hippocampus. Modern methods,
particularly neural networks and ensembles, significantly outperform
traditional approaches, such as Wiener and Kalman filters. Improving the
performance of neural decoding algorithms allows neuroscientists to better
understand the information contained in a neural population and can help
advance engineering applications such as brain machine interfaces.",2017-08-02T19:53:22Z,http://arxiv.org/pdf/1708.00909v4,"['q-bio.NC', 'cs.LG', 'stat.ML']"
2101.00755v1,Machine Learning for Robotic Manipulation,['Quan Vuong'],"The past decade has witnessed the tremendous successes of machine learning
techniques in the supervised learning paradigm, where there is a clear
demarcation between training and testing. In the supervised learning paradigm,
learning is inherently passive, seeking to distill human-provided supervision
in large-scale datasets into high capacity models. Following these successes,
machine learning researchers have looked beyond this paradigm and became
interested in tasks that are more dynamic. To them, robotics serve as an
excellent test-bed, for the challenges of robotics break many of the
assumptions that made supervised learning successful. Out of the many different
areas within robotics, robotic manipulation has become a favorite area for
researchers to demonstrate new algorithms because of the vast numbers of
possible applications and its highly dynamical and complex nature. This
document surveys recent robotics conferences and identifies the major trends
with which machine learning techniques have been applied to the challenges of
robotic manipulation.",2021-01-04T03:42:07Z,http://arxiv.org/pdf/2101.00755v1,['cs.RO']
1911.02792v1,Machine learning for molecular simulation,"['Frank Noé', 'Alexandre Tkatchenko', 'Klaus-Robert Müller', 'Cecilia Clementi']","Machine learning (ML) is transforming all areas of science. The complex and
time-consuming calculations in molecular simulations are particularly suitable
for a machine learning revolution and have already been profoundly impacted by
the application of existing ML methods. Here we review recent ML methods for
molecular simulation, with particular focus on (deep) neural networks for the
prediction of quantum-mechanical energies and forces, coarse-grained molecular
dynamics, the extraction of free energy surfaces and kinetics and generative
network approaches to sample molecular equilibrium structures and compute
thermodynamics. To explain these methods and illustrate open methodological
problems, we review some important principles of molecular physics and describe
how they can be incorporated into machine learning structures. Finally, we
identify and describe a list of open challenges for the interface between ML
and molecular simulation.",2019-11-07T08:14:18Z,http://arxiv.org/pdf/1911.02792v1,"['physics.chem-ph', 'cs.LG', 'physics.comp-ph', 'quant-ph']"
2002.05648v3,Politics of Adversarial Machine Learning,"['Kendra Albert', 'Jonathon Penney', 'Bruce Schneier', 'Ram Shankar Siva Kumar']","In addition to their security properties, adversarial machine-learning
attacks and defenses have political dimensions. They enable or foreclose
certain options for both the subjects of the machine learning systems and for
those who deploy them, creating risks for civil liberties and human rights. In
this paper, we draw on insights from science and technology studies,
anthropology, and human rights literature, to inform how defenses against
adversarial attacks can be used to suppress dissent and limit attempts to
investigate machine learning systems. To make this concrete, we use real-world
examples of how attacks such as perturbation, model inversion, or membership
inference can be used for socially desirable ends. Although the predictions of
this analysis may seem dire, there is hope. Efforts to address human rights
concerns in the commercial spyware industry provide guidance for similar
measures to ensure ML systems serve democratic, not authoritarian ends",2020-02-01T01:15:39Z,http://arxiv.org/pdf/2002.05648v3,"['cs.CY', 'cs.CR', 'cs.LG', 'stat.ML']"
1806.10920v1,Machine Learning for Mathematical Software,['M. England'],"While there has been some discussion on how Symbolic Computation could be
used for AI there is little literature on applications in the other direction.
However, recent results for quantifier elimination suggest that, given enough
example problems, there is scope for machine learning tools like Support Vector
Machines to improve the performance of Computer Algebra Systems. We survey the
authors own work and similar applications for other mathematical software.
  It may seem that the inherently probabilistic nature of machine learning
tools would invalidate the exact results prized by mathematical software.
However, algorithms and implementations often come with a range of choices
which have no effect on the mathematical correctness of the end result but a
great effect on the resources required to find it, and thus here, machine
learning can have a significant impact.",2018-06-28T12:35:47Z,http://arxiv.org/pdf/1806.10920v1,"['cs.SC', '68T05, 68W30', 'I.2.6; I.1.0']"
2003.11040v2,Machine Learning for Quantum Matter,['Juan Carrasquilla'],"Quantum matter, the research field studying phases of matter whose properties
are intrinsically quantum mechanical, draws from areas as diverse as hard
condensed matter physics, materials science, statistical mechanics, quantum
information, quantum gravity, and large-scale numerical simulations. Recently,
researchers interested quantum matter and strongly correlated quantum systems
have turned their attention to the algorithms underlying modern machine
learning with an eye on making progress in their fields. Here we provide a
short review on the recent development and adaptation of machine learning ideas
for the purpose advancing research in quantum matter, including ideas ranging
from algorithms that recognize conventional and topological states of matter in
synthetic an experimental data, to representations of quantum states in terms
of neural networks and their applications to the simulation and control of
quantum systems. We discuss the outlook for future developments in areas at the
intersection between machine learning and quantum many-body physics.",2020-03-24T18:00:30Z,http://arxiv.org/pdf/2003.11040v2,"['physics.comp-ph', 'cond-mat.str-el', 'quant-ph']"
2102.09449v2,Quantum field-theoretic machine learning,"['Dimitrios Bachtis', 'Gert Aarts', 'Biagio Lucini']","We derive machine learning algorithms from discretized Euclidean field
theories, making inference and learning possible within dynamics described by
quantum field theory. Specifically, we demonstrate that the $\phi^{4}$ scalar
field theory satisfies the Hammersley-Clifford theorem, therefore recasting it
as a machine learning algorithm within the mathematically rigorous framework of
Markov random fields. We illustrate the concepts by minimizing an asymmetric
distance between the probability distribution of the $\phi^{4}$ theory and that
of target distributions, by quantifying the overlap of statistical ensembles
between probability distributions and through reweighting to complex-valued
actions with longer-range interactions. Neural network architectures are
additionally derived from the $\phi^{4}$ theory which can be viewed as
generalizations of conventional neural networks and applications are presented.
We conclude by discussing how the proposal opens up a new research avenue, that
of developing a mathematical and computational framework of machine learning
within quantum field theory.",2021-02-18T16:12:51Z,http://arxiv.org/pdf/2102.09449v2,"['hep-lat', 'cond-mat.dis-nn', 'cond-mat.stat-mech', 'cs.LG', 'hep-th']"
2210.09084v1,Multi-Agent Automated Machine Learning,"['Zhaozhi Wang', 'Kefan Su', 'Jian Zhang', 'Huizhu Jia', 'Qixiang Ye', 'Xiaodong Xie', 'Zongqing Lu']","In this paper, we propose multi-agent automated machine learning (MA2ML) with
the aim to effectively handle joint optimization of modules in automated
machine learning (AutoML). MA2ML takes each machine learning module, such as
data augmentation (AUG), neural architecture search (NAS), or hyper-parameters
(HPO), as an agent and the final performance as the reward, to formulate a
multi-agent reinforcement learning problem. MA2ML explicitly assigns credit to
each agent according to its marginal contribution to enhance cooperation among
modules, and incorporates off-policy learning to improve search efficiency.
Theoretically, MA2ML guarantees monotonic improvement of joint optimization.
Extensive experiments show that MA2ML yields the state-of-the-art top-1
accuracy on ImageNet under constraints of computational cost, e.g.,
$79.7\%/80.5\%$ with FLOPs fewer than 600M/800M. Extensive ablation studies
verify the benefits of credit assignment and off-policy learning of MA2ML.",2022-10-17T13:32:59Z,http://arxiv.org/pdf/2210.09084v1,"['cs.LG', 'cs.CV']"
2302.10298v1,Quantum Machine Learning hyperparameter search,"['S. Consul-Pacareu', 'R. Montaño', 'Kevin Rodriguez-Fernandez', 'Àlex Corretgé', 'Esteve Vilella-Moreno', 'Daniel Casado-Faulí', 'Parfait Atchade-Adelomou']","This paper presents a quantum-based Fourier-regression approach for machine
learning hyperparameter optimization applied to a benchmark of models trained
on a dataset related to a forecast problem in the airline industry. Our
approach utilizes the Fourier series method to represent the hyperparameter
search space, which is then optimized using quantum algorithms to find the
optimal set of hyperparameters for a given machine learning model. Our study
evaluates the proposed method on a benchmark of models trained to predict a
forecast problem in the airline industry using a standard HyperParameter
Optimizer (HPO). The results show that our approach outperforms traditional
hyperparameter optimization methods in terms of accuracy and convergence speed
for the given search space. Our study provides a new direction for future
research in quantum-based machine learning hyperparameter optimization.",2023-02-20T20:41:31Z,http://arxiv.org/pdf/2302.10298v1,"['cs.LG', 'quant-ph']"
2306.15308v1,Machine learning in solar physics,"['A. Asensio Ramos', 'M. C. M. Cheung', 'I. Chifu', 'R. Gafeira']","The application of machine learning in solar physics has the potential to
greatly enhance our understanding of the complex processes that take place in
the atmosphere of the Sun. By using techniques such as deep learning, we are
now in the position to analyze large amounts of data from solar observations
and identify patterns and trends that may not have been apparent using
traditional methods. This can help us improve our understanding of explosive
events like solar flares, which can have a strong effect on the Earth
environment. Predicting hazardous events on Earth becomes crucial for our
technological society. Machine learning can also improve our understanding of
the inner workings of the sun itself by allowing us to go deeper into the data
and to propose more complex models to explain them. Additionally, the use of
machine learning can help to automate the analysis of solar data, reducing the
need for manual labor and increasing the efficiency of research in this field.",2023-06-27T08:55:20Z,http://arxiv.org/pdf/2306.15308v1,"['astro-ph.SR', 'astro-ph.IM', 'cs.CV']"
2402.01415v1,SMLP: Symbolic Machine Learning Prover,"['Franz Brauße', 'Zurab Khasidashvili', 'Konstantin Korovin']","Symbolic Machine Learning Prover (SMLP) is a tool and a library for system
exploration based on data samples obtained by simulating or executing the
system on a number of input vectors. SMLP aims at exploring the system based on
this data by taking a grey-box approach: SMLP combines statistical methods of
data exploration with building and exploring machine learning models in close
feedback loop with the system's response, and exploring these models by
combining probabilistic and formal methods. SMLP has been applied in industrial
setting at Intel for analyzing and optimizing hardware designs at the analog
level. SMLP is a general purpose tool and can be applied to systems that can be
sampled and modeled by machine learning models.",2024-02-02T13:53:29Z,http://arxiv.org/pdf/2402.01415v1,"['cs.LG', 'cs.AI', 'cs.LO', 'cs.SC', 'math.OC']"
2505.03861v1,Machine Learning: a Lecture Note,['Kyunghyun Cho'],"This lecture note is intended to prepare early-year master's and PhD students
in data science or a related discipline with foundational ideas in machine
learning. It starts with basic ideas in modern machine learning with
classification as a main target task. These basic ideas include loss
formulation, backpropagation, stochastic gradient descent, generalization,
model selection as well as fundamental blocks of artificial neural networks.
Based on these basic ideas, the lecture note explores in depth the probablistic
approach to unsupervised learning, covering directed latent variable models,
product of experts, generative adversarial networks and autoregressive models.
Finally, the note ends by covering a diverse set of further topics, such as
reinforcement learning, ensemble methods and meta-learning. After reading this
lecture note, a student should be ready to embark on studying and researching
more advanced topics in machine learning and more broadly artificial
intelligence.",2025-05-06T16:03:41Z,http://arxiv.org/pdf/2505.03861v1,"['cs.LG', 'stat.ML']"
1201.0490v4,Scikit-learn: Machine Learning in Python,"['Fabian Pedregosa', 'Gaël Varoquaux', 'Alexandre Gramfort', 'Vincent Michel', 'Bertrand Thirion', 'Olivier Grisel', 'Mathieu Blondel', 'Andreas Müller', 'Joel Nothman', 'Gilles Louppe', 'Peter Prettenhofer', 'Ron Weiss', 'Vincent Dubourg', 'Jake Vanderplas', 'Alexandre Passos', 'David Cournapeau', 'Matthieu Brucher', 'Matthieu Perrot', 'Édouard Duchesnay']","Scikit-learn is a Python module integrating a wide range of state-of-the-art
machine learning algorithms for medium-scale supervised and unsupervised
problems. This package focuses on bringing machine learning to non-specialists
using a general-purpose high-level language. Emphasis is put on ease of use,
performance, documentation, and API consistency. It has minimal dependencies
and is distributed under the simplified BSD license, encouraging its use in
both academic and commercial settings. Source code, binaries, and documentation
can be downloaded from http://scikit-learn.org.",2012-01-02T16:42:40Z,http://arxiv.org/pdf/1201.0490v4,"['cs.LG', 'cs.MS']"
1810.10731v3,Law and Adversarial Machine Learning,"['Ram Shankar Siva Kumar', ""David R. O'Brien"", 'Kendra Albert', 'Salome Vilojen']","When machine learning systems fail because of adversarial manipulation, how
should society expect the law to respond? Through scenarios grounded in
adversarial ML literature, we explore how some aspects of computer crime,
copyright, and tort law interface with perturbation, poisoning, model stealing
and model inversion attacks to show how some attacks are more likely to result
in liability than others. We end with a call for action to ML researchers to
invest in transparent benchmarks of attacks and defenses; architect ML systems
with forensics in mind and finally, think more about adversarial machine
learning in the context of civil liberties. The paper is targeted towards ML
researchers who have no legal background.",2018-10-25T06:17:34Z,http://arxiv.org/pdf/1810.10731v3,"['cs.LG', 'cs.CR', 'cs.CY', 'stat.ML']"
1912.02590v1,Machine Learning on sWeighted Data,"['Maxim Borisyak', 'Nikita Kazeev']","Data analysis in high energy physics has to deal with data samples produced
from different sources. One of the most widely used ways to unfold their
contributions is the sPlot technique. It uses the results of a maximum
likelihood fit to assign weights to events. Some weights produced by sPlot are
by design negative. Negative weights make it difficult to apply machine
learning methods. The loss function becomes unbounded. This leads to divergent
neural network training. In this paper we propose a mathematically rigorous way
to transform the weights obtained by sPlot into class probabilities conditioned
on observables, thus enabling to apply any machine learning algorithm
out-of-the-box.",2019-10-17T17:06:11Z,http://arxiv.org/pdf/1912.02590v1,"['hep-ex', 'cs.LG', 'physics.data-an', 'stat.ML']"
2305.16634v1,Machine Learning for Protein Engineering,"['Kadina E. Johnston', 'Clara Fannjiang', 'Bruce J. Wittmann', 'Brian L. Hie', 'Kevin K. Yang', 'Zachary Wu']","Directed evolution of proteins has been the most effective method for protein
engineering. However, a new paradigm is emerging, fusing the library generation
and screening approaches of traditional directed evolution with computation
through the training of machine learning models on protein sequence fitness
data. This chapter highlights successful applications of machine learning to
protein engineering and directed evolution, organized by the improvements that
have been made with respect to each step of the directed evolution cycle.
Additionally, we provide an outlook for the future based on the current
direction of the field, namely in the development of calibrated models and in
incorporating other modalities, such as protein structure.",2023-05-26T05:19:17Z,http://arxiv.org/pdf/2305.16634v1,['q-bio.BM']
1801.06566v1,Model Theory and Machine Learning,"['Hunter Chase', 'James Freitag']","About 25 years ago, it came to light that a single combinatorial property
determines both an important dividing line in model theory (NIP) and machine
learning (PAC-learnability). The following years saw a fruitful exchange of
ideas between PAC learning and the model theory of NIP structures. In this
article, we point out a new and similar connection between model theory and
machine learning, this time developing a correspondence between
\emph{stability} and learnability in various settings of \emph{online
learning.} In particular, this gives many new examples of mathematically
interesting classes which are learnable in the online setting.",2018-01-19T20:31:32Z,http://arxiv.org/pdf/1801.06566v1,"['math.LO', '03C95, 03C98, 03C45']"
2111.08507v1,Machine Learning for Genomic Data,['Akankshita Dash'],"This report explores the application of machine learning techniques on short
timeseries gene expression data. Although standard machine learning algorithms
work well on longer time-series', they often fail to find meaningful insights
from fewer timepoints. In this report, we explore model-based clustering
techniques. We combine popular unsupervised learning techniques like K-Means,
Gaussian Mixture Models, Bayesian Networks, Hidden Markov Models with the
well-known Expectation Maximization algorithm. K-Means and Gaussian Mixture
Models are fairly standard, while Hidden Markov Model and Bayesian Networks
clustering are more novel ideas that suit time-series gene expression data.",2021-11-15T14:34:20Z,http://arxiv.org/pdf/2111.08507v1,"['q-bio.GN', 'cs.LG', '62F15', 'G.3']"
2303.15794v2,Machine Learning for Observational Cosmology,"['Kana Moriwaki', 'Takahiro Nishimichi', 'Naoki Yoshida']","An array of large observational programs using ground-based and space-borne
telescopes is planned in the next decade. The forthcoming wide-field sky
surveys are expected to deliver a sheer volume of data exceeding an exabyte.
Processing the large amount of multiplex astronomical data is technically
challenging, and fully automated technologies based on machine learning and
artificial intelligence are urgently needed. Maximizing scientific returns from
the big data requires community-wide efforts. We summarize recent progress in
machine learning applications in observational cosmology. We also address
crucial issues in high-performance computing that are needed for the data
processing and statistical analysis.",2023-03-28T07:59:04Z,http://arxiv.org/pdf/2303.15794v2,"['astro-ph.IM', 'astro-ph.CO', 'astro-ph.GA', 'astro-ph.HE']"
2311.16172v1,Evolutionary Machine Learning and Games,"['Julian Togelius', 'Ahmed Khalifa', 'Sam Earle', 'Michael Cerny Green', 'Lisa Soros']","Evolutionary machine learning (EML) has been applied to games in multiple
ways, and for multiple different purposes. Importantly, AI research in games is
not only about playing games; it is also about generating game content,
modeling players, and many other applications. Many of these applications pose
interesting problems for EML. We will structure this chapter on EML for games
based on whether evolution is used to augment machine learning (ML) or ML is
used to augment evolution. For completeness, we also briefly discuss the usage
of ML and evolution separately in games.",2023-11-20T13:21:39Z,http://arxiv.org/pdf/2311.16172v1,"['cs.NE', 'cs.AI', 'cs.LG']"
2407.05520v1,A Theory of Machine Learning,"['Jinsook Kim', 'Jinho Kang']","We critically review three major theories of machine learning and provide a
new theory according to which machines learn a function when the machines
successfully compute it. We show that this theory challenges common assumptions
in the statistical and the computational learning theories, for it implies that
learning true probabilities is equivalent neither to obtaining a correct
calculation of the true probabilities nor to obtaining an almost-sure
convergence to them. We also briefly discuss some case studies from natural
language processing and macroeconomics from the perspective of the new theory.",2024-07-07T23:57:10Z,http://arxiv.org/pdf/2407.05520v1,"['cs.LG', 'stat.ML']"
1601.04126v1,Engineering Safety in Machine Learning,['Kush R. Varshney'],"Machine learning algorithms are increasingly influencing our decisions and
interacting with us in all parts of our daily lives. Therefore, just like for
power plants, highways, and myriad other engineered sociotechnical systems, we
must consider the safety of systems involving machine learning. In this paper,
we first discuss the definition of safety in terms of risk, epistemic
uncertainty, and the harm incurred by unwanted outcomes. Then we examine
dimensions, such as the choice of cost function and the appropriateness of
minimizing the empirical average training cost, along which certain real-world
applications may not be completely amenable to the foundational principle of
modern statistical machine learning: empirical risk minimization. In
particular, we note an emerging dichotomy of applications: ones in which safety
is important and risk minimization is not the complete story (we name these
Type A applications), and ones in which safety is not so critical and risk
minimization is sufficient (we name these Type B applications). Finally, we
discuss how four different strategies for achieving safety in engineering
(inherently safe design, safety reserves, safe fail, and procedural safeguards)
can be mapped to the machine learning context through interpretability and
causality of predictive models, objectives beyond expected prediction accuracy,
human involvement for labeling difficult or rare examples, and user experience
design of software.",2016-01-16T05:46:57Z,http://arxiv.org/pdf/1601.04126v1,"['stat.ML', 'cs.AI', 'cs.CY', 'cs.LG']"
1805.12153v3,Machine learning for bounce calculation,['Ryusuke Jinno'],"We study the possibility of using machine learning for the calculation of the
bounce action in quantum tunneling. Adopting supervised learning, we train
neural network to give the bounce action from a given potential. It is found
that, for one-dimensional tunneling, even a simple neural network performs at a
percent level.",2018-05-30T18:00:35Z,http://arxiv.org/pdf/1805.12153v3,"['hep-th', 'hep-ph']"
2001.11956v1,Documentation of Machine Learning Software,"['Yalda Hashemi', 'Maleknaz Nayebi', 'Giuliano Antoniol']","Machine Learning software documentation is different from most of the
documentations that were studied in software engineering research. Often, the
users of these documentations are not software experts. The increasing interest
in using data science and in particular, machine learning in different fields
attracted scientists and engineers with various levels of knowledge about
programming and software engineering. Our ultimate goal is automated generation
and adaptation of machine learning software documents for users with different
levels of expertise. We are interested in understanding the nature and triggers
of the problems and the impact of the users' levels of expertise in the process
of documentation evolution. We will investigate the Stack Overflow Q/As and
classify the documentation related Q/As within the machine learning domain to
understand the types and triggers of the problems as well as the potential
change requests to the documentation. We intend to use the results for building
on top of the state of the art techniques for automatic documentation
generation and extending on the adoption, summarization, and explanation of
software functionalities.",2020-01-30T00:01:28Z,http://arxiv.org/pdf/2001.11956v1,"['cs.SE', 'cs.LG']"
2207.02851v1,Tensor networks in machine learning,"['Richik Sengupta', 'Soumik Adhikary', 'Ivan Oseledets', 'Jacob Biamonte']","A tensor network is a type of decomposition used to express and approximate
large arrays of data. A given data-set, quantum state or higher dimensional
multi-linear map is factored and approximated by a composition of smaller
multi-linear maps. This is reminiscent to how a Boolean function might be
decomposed into a gate array: this represents a special case of tensor
decomposition, in which the tensor entries are replaced by 0, 1 and the
factorisation becomes exact. The collection of associated techniques are
called, tensor network methods: the subject developed independently in several
distinct fields of study, which have more recently become interrelated through
the language of tensor networks. The tantamount questions in the field relate
to expressability of tensor networks and the reduction of computational
overheads. A merger of tensor networks with machine learning is natural. On the
one hand, machine learning can aid in determining a factorization of a tensor
network approximating a data set. On the other hand, a given tensor network
structure can be viewed as a machine learning model. Herein the tensor network
parameters are adjusted to learn or classify a data-set. In this survey we
recover the basics of tensor networks and explain the ongoing effort to develop
the theory of tensor networks in machine learning.",2022-07-06T18:00:00Z,http://arxiv.org/pdf/2207.02851v1,"['quant-ph', 'cond-mat.dis-nn', 'cs.AI', 'cs.LG']"
1402.6013v1,Open science in machine learning,"['Joaquin Vanschoren', 'Mikio L. Braun', 'Cheng Soon Ong']","We present OpenML and mldata, open science platforms that provides easy
access to machine learning data, software and results to encourage further
study and application. They go beyond the more traditional repositories for
data sets and software packages in that they allow researchers to also easily
share the results they obtained in experiments and to compare their solutions
with those of others.",2014-02-24T23:12:42Z,http://arxiv.org/pdf/1402.6013v1,"['cs.LG', 'cs.DL']"
2110.12483v1,Machine Learning Line Bundle Connections,"['Anthony Ashmore', 'Rehan Deen', 'Yang-Hui He', 'Burt A. Ovrut']","We study the use of machine learning for finding numerical hermitian
Yang-Mills connections on line bundles over Calabi-Yau manifolds. Defining an
appropriate loss function and focusing on the examples of an elliptic curve, a
K3 surface and a quintic threefold, we show that neural networks can be trained
to give a close approximation to hermitian Yang-Mills connections.",2021-10-24T16:31:46Z,http://arxiv.org/pdf/2110.12483v1,['hep-th']
2203.06073v1,Machine Learning for Hilbert Series,['Edward Hirst'],"Hilbert series are a standard tool in algebraic geometry, and more recently
are finding many uses in theoretical physics. This summary reviews work
applying machine learning to databases of them; and was prepared for the
proceedings of the Nankai Symposium on Mathematical Dialogues, 2021.",2022-03-11T16:52:42Z,http://arxiv.org/pdf/2203.06073v1,"['hep-th', 'math.AG']"
2206.01749v1,Uncertainty Estimation in Machine Learning,['Valentin Arkov'],"Most machine learning techniques are based upon statistical learning theory,
often simplified for the sake of computing speed. This paper is focused on the
uncertainty aspect of mathematical modeling in machine learning. Regression
analysis is chosen to further investigate the evaluation aspect of uncertainty
in model coefficients and, more importantly, in the output feature value
predictions. A survey demonstrates major stages in the conventional least
squares approach to the creation of the regression model, along with its
uncertainty estimation. On the other hand, it is shown that in machine learning
the model complexity and severe nonlinearity become serious obstacles to
uncertainty evaluation. Furthermore, the process of machine model training
demands high computing power, not available at the level of personal computers.
This is why so-called pre-trained models are widely used in such areas of
machine learning as natural language processing. The latest example of a
pre-trained model is the Generative Pre-trained Transformer 3 with hundreds of
billions of parameters and a half-terabyte training dataset. Similarly,
mathematical models built from real data are growing in complexity which is
accompanied by the growing amount of training data. However, when machine
models and their predictions are used in decision-making, one needs to estimate
uncertainty and evaluate accompanying risks. This problem could be resolved
with non-parametric techniques at the expense of greater demand for computing
power, which can be offered by modern supercomputers available, including those
utilizing graphical and tensor processing units along with the conventional
central processors.",2022-06-03T16:11:11Z,http://arxiv.org/pdf/2206.01749v1,"['cs.LG', 'cs.AI', '60H99', 'I.2.6']"
2208.06680v3,Locating disparities in machine learning,"['Moritz von Zahn', 'Oliver Hinz', 'Stefan Feuerriegel']","Machine learning can provide predictions with disparate outcomes, in which
subgroups of the population (e.g., defined by age, gender, or other sensitive
attributes) are systematically disadvantaged. In order to comply with upcoming
legislation, practitioners need to locate such disparate outcomes. However,
previous literature typically detects disparities through statistical
procedures for when the sensitive attribute is specified a priori. This limits
applicability in real-world settings where datasets are high dimensional and,
on top of that, sensitive attributes may be unknown. As a remedy, we propose a
data-driven framework called Automatic Location of Disparities (ALD) which aims
at locating disparities in machine learning. ALD meets several demands from
industry: ALD (1) is applicable to arbitrary machine learning classifiers; (2)
operates on different definitions of disparities (e.g., statistical parity or
equalized odds); and (3) deals with both categorical and continuous predictors
even if disparities arise from complex and multi-way interactions known as
intersectionality (e. g., age above 60 and female). ALD produces interpretable
audit reports as output. We demonstrate the effectiveness of ALD based on both
synthetic and real-world datasets. As a result, we empower practitioners to
effectively locate and mitigate disparities in machine learning algorithms,
conduct algorithmic audits, and protect individuals from discrimination.",2022-08-13T16:39:51Z,http://arxiv.org/pdf/2208.06680v3,['cs.LG']
2402.19254v1,Machine learning for modular multiplication,"['Kristin Lauter', 'Cathy Yuanchen Li', 'Krystal Maughan', 'Rachel Newton', 'Megha Srivastava']","Motivated by cryptographic applications, we investigate two machine learning
approaches to modular multiplication: namely circular regression and a
sequence-to-sequence transformer model. The limited success of both methods
demonstrated in our results gives evidence for the hardness of tasks involving
modular multiplication upon which cryptosystems are based.",2024-02-29T15:26:03Z,http://arxiv.org/pdf/2402.19254v1,"['cs.LG', 'cs.CR']"
2209.06529v1,Data Privacy and Trustworthy Machine Learning,"['Martin Strobel', 'Reza Shokri']","The privacy risks of machine learning models is a major concern when training
them on sensitive and personal data. We discuss the tradeoffs between data
privacy and the remaining goals of trustworthy machine learning (notably,
fairness, robustness, and explainability).",2022-09-14T10:07:44Z,http://arxiv.org/pdf/2209.06529v1,"['cs.LG', 'cs.CR']"
1405.1304v1,Application of Machine Learning Techniques in Aquaculture,"['Akhlaqur Rahman', 'Sumaira Tasnim']","In this paper we present applications of different machine learning
algorithms in aquaculture. Machine learning algorithms learn models from
historical data. In aquaculture historical data are obtained from farm
practices, yields, and environmental data sources. Associations between these
different variables can be obtained by applying machine learning algorithms to
historical data. In this paper we present applications of different machine
learning algorithms in aquaculture applications.",2014-05-03T14:26:42Z,http://arxiv.org/pdf/1405.1304v1,"['cs.CE', 'cs.LG']"
2111.04439v1,Addressing Privacy Threats from Machine Learning,['Mary Anne Smart'],"Every year at NeurIPS, machine learning researchers gather and discuss
exciting applications of machine learning in areas such as public health,
disaster response, climate change, education, and more. However, many of these
same researchers are expressing growing concern about applications of machine
learning for surveillance (Nanayakkara et al., 2021). This paper presents a
brief overview of strategies for resisting these surveillance technologies and
calls for greater collaboration between machine learning and human-computer
interaction researchers to address the threats that these technologies pose.",2021-10-25T03:40:25Z,http://arxiv.org/pdf/2111.04439v1,"['cs.CY', 'cs.CR', 'cs.LG']"
2412.18979v1,Quantum memristors for neuromorphic quantum machine learning,['Lucas Lamata'],"Quantum machine learning may permit to realize more efficient machine
learning calculations with near-term quantum devices. Among the diverse quantum
machine learning paradigms which are currently being considered, quantum
memristors are promising as a way of combining, in the same quantum hardware, a
unitary evolution with the nonlinearity provided by the measurement and
feedforward. Thus, an efficient way of deploying neuromorphic quantum computing
for quantum machine learning may be enabled.",2024-12-25T20:21:24Z,http://arxiv.org/pdf/2412.18979v1,"['quant-ph', 'cs.NE']"
1311.5250v1,Attractor Control Using Machine Learning,"['Thomas Duriez', 'Vladimir Parezanovic', 'Bernd R. Noack', 'Laurent Cordier', 'Marc Segond', 'Markus Abel']","We propose a general strategy for feedback control design of complex
dynamical systems exploiting the nonlinear mechanisms in a systematic
unsupervised manner. These dynamical systems can have a state space of
arbitrary dimension with finite number of actuators (multiple inputs) and
sensors (multiple outputs). The control law maps outputs into inputs and is
optimized with respect to a cost function, containing physics via the dynamical
or statistical properties of the attractor to be controlled. Thus, we are
capable of exploiting nonlinear mechanisms, e.g. chaos or frequency cross-talk,
serving the control objective. This optimization is based on genetic
programming, a branch of machine learning. This machine learning control is
successfully applied to the stabilization of nonlinearly coupled oscillators
and maximization of Lyapunov exponent of a forced Lorenz system. We foresee
potential applications to most nonlinear multiple inputs/multiple outputs
control problems, particulary in experiments.",2013-11-20T22:30:23Z,http://arxiv.org/pdf/1311.5250v1,"['nlin.CD', 'physics.flu-dyn']"
1605.01735v1,Machine learning phases of matter,"['Juan Carrasquilla', 'Roger G. Melko']","Neural networks can be used to identify phases and phase transitions in
condensed matter systems via supervised machine learning. Readily programmable
through modern software libraries, we show that a standard feed-forward neural
network can be trained to detect multiple types of order parameter directly
from raw state configurations sampled with Monte Carlo. In addition, they can
detect highly non-trivial states such as Coulomb phases, and if modified to a
convolutional neural network, topological phases with no conventional order
parameter. We show that this classification occurs within the neural network
without knowledge of the Hamiltonian or even the general locality of
interactions. These results demonstrate the power of machine learning as a
basic research tool in the field of condensed matter and statistical physics.",2016-05-05T20:00:04Z,http://arxiv.org/pdf/1605.01735v1,['cond-mat.str-el']
1702.05774v1,Machine Learning Predicts Laboratory Earthquakes,"['Bertrand Rouet-Leduc', 'Claudia Hulbert', 'Nicholas Lubbers', 'Kipton Barros', 'Colin Humphreys', 'Paul A. Johnson']","Forecasting fault failure is a fundamental but elusive goal in earthquake
science. Here we show that by listening to the acoustic signal emitted by a
laboratory fault, machine learning can predict the time remaining before it
fails with great accuracy. These predictions are based solely on the
instantaneous physical characteristics of the acoustical signal, and do not
make use of its history. Surprisingly, machine learning identifies a signal
emitted from the fault zone previously thought to be low-amplitude noise that
enables failure forecasting throughout the laboratory quake cycle. We
hypothesize that applying this approach to continuous seismic data may lead to
significant advances in identifying currently unknown signals, in providing new
insights into fault physics, and in placing bounds on fault failure times.",2017-02-19T17:57:10Z,http://arxiv.org/pdf/1702.05774v1,['physics.geo-ph']
1803.08066v2,Jet Charge and Machine Learning,"['Katherine Fraser', 'Matthew D. Schwartz']","Modern machine learning techniques, such as convolutional, recurrent and
recursive neural networks, have shown promise for jet substructure at the Large
Hadron Collider. For example, they have demonstrated effectiveness at boosted
top or W boson identification or for quark/gluon discrimination. We explore
these methods for the purpose of classifying jets according to their electric
charge. We find that both neural networks that incorporate distance within the
jet as an input and boosted decision trees including radial distance
information can provide significant improvement in jet charge extraction over
current methods. Specifically, convolutional, recurrent, and recursive networks
can provide the largest improvement over traditional methods, in part by
effectively utilizing distance within the jet or clustering history. The
advantages of using a fixed-size input representation (as with the CNN) or a
small input representation (as with the RNN) suggest that both convolutional
and recurrent networks will be essential to the future of modern machine
learning at colliders.",2018-03-21T18:02:02Z,http://arxiv.org/pdf/1803.08066v2,"['hep-ph', 'stat.ML']"
1808.07069v1,Machine learning non-local correlations,"['Askery Canabarro', 'Samuraí Brito', 'Rafael Chaves']","The ability to witness non-local correlations lies at the core of
foundational aspects of quantum mechanics and its application in the processing
of information. Commonly, this is achieved via the violation of Bell
inequalities. Unfortunately, however, their systematic derivation quickly
becomes unfeasible as the scenario of interest grows in complexity. To cope
with that, we propose here a machine learning approach for the detection and
quantification of non-locality. It consists of an ensemble of multilayer
perceptrons blended with genetic algorithms achieving a high performance in a
number of relevant Bell scenarios. Our results offer a novel method and a
proof-of-principle for the relevance of machine learning for understanding
non-locality.",2018-08-21T18:03:36Z,http://arxiv.org/pdf/1808.07069v1,"['quant-ph', 'stat.ML']"
2006.03626v2,LGML: Logic Guided Machine Learning,"['Joseph Scott', 'Maysum Panju', 'Vijay Ganesh']","We introduce Logic Guided Machine Learning (LGML), a novel approach that
symbiotically combines machine learning (ML) and logic solvers with the goal of
learning mathematical functions from data. LGML consists of two phases, namely
a learning-phase and a logic-phase with a corrective feedback loop, such that,
the learning-phase learns symbolic expressions from input data, and the
logic-phase cross verifies the consistency of the learned expression with known
auxiliary truths. If inconsistent, the logic-phase feeds back ""counterexamples""
to the learning-phase. This process is repeated until the learned expression is
consistent with auxiliary truth. Using LGML, we were able to learn expressions
that correspond to the Pythagorean theorem and the sine function, with several
orders of magnitude improvements in data efficiency compared to an approach
based on an out-of-the-box multi-layered perceptron (MLP).",2020-06-05T18:42:08Z,http://arxiv.org/pdf/2006.03626v2,['cs.AI']
2108.07380v2,InfoGram and Admissible Machine Learning,['Subhadeep Mukhopadhyay'],"We have entered a new era of machine learning (ML), where the most accurate
algorithm with superior predictive power may not even be deployable, unless it
is admissible under the regulatory constraints. This has led to great interest
in developing fair, transparent and trustworthy ML methods. The purpose of this
article is to introduce a new information-theoretic learning framework
(admissible machine learning) and algorithmic risk-management tools (InfoGram,
L-features, ALFA-testing) that can guide an analyst to redesign off-the-shelf
ML methods to be regulatory compliant, while maintaining good prediction
accuracy. We have illustrated our approach using several real-data examples
from financial sectors, biomedical research, marketing campaigns, and the
criminal justice system.",2021-08-17T00:04:38Z,http://arxiv.org/pdf/2108.07380v2,"['stat.ML', 'cs.AI', 'cs.LG', 'econ.EM']"
1912.05665v2,Managing Machine Learning Workflow Components,"['Marcio Moreno', 'Vítor Lourenço', 'Sandro Rama Fiorini', 'Polyana Costa', 'Rafael Brandão', 'Daniel Civitarese', 'Renato Cerqueira']","Machine Learning Workflows (MLWfs) have become essential and a disruptive
approach in problem-solving over several industries. However, the development
process of MLWfs may be complicated, hard to achieve, time-consuming, and
error-prone. To handle this problem, in this paper, we introduce machine
learning workflow management (MLWfM) as a technique to aid the development and
reuse of MLWfs and their components through three aspects: representation,
execution, and creation. More precisely, we discuss our approach to structure
the MLWfs' components and their metadata to aid retrieval and reuse of
components in new MLWfs. Also, we consider the execution of these components
within a tool. The hybrid knowledge representation, called Hyperknowledge,
frames our methodology, supporting the three MLWfM's aspects. To validate our
approach, we show a practical use case in the Oil & Gas industry.",2019-12-10T00:44:06Z,http://arxiv.org/pdf/1912.05665v2,['cs.LG']
2001.10794v1,Software Logging for Machine Learning,"['Nathan Bosch', 'Jan Bosch']","System logs perform a critical function in software-intensive systems as logs
record the state of the system and significant events in the system at
important points in time. Unfortunately, log entries are typically created in
an ad-hoc, unstructured and uncoordinated fashion, limiting their usefulness
for analytics and machine learning. In this paper, we present the main
challenges of contemporary approaches to generating and storing system logs
data for large, complex, software-intensive systems based on an in-depth case
study at a world-leading telecommunications company. Second, we present a
systematic and structured approach for generating log data that does not suffer
from the aforementioned challenges and is optimized for use in machine
learning. Third, we provide validation of the approach based on expert
interviews that confirms that the approach addresses the identified challenges
and problems.",2020-01-24T13:44:08Z,http://arxiv.org/pdf/2001.10794v1,['cs.SE']
2104.12733v1,Invariant polynomials and machine learning,['Ward Haddadin'],"We present an application of invariant polynomials in machine learning. Using
the methods developed in previous work, we obtain two types of generators of
the Lorentz- and permutation-invariant polynomials in particle momenta; minimal
algebra generators and Hironaka decompositions. We discuss and prove some
approximation theorems to make use of these invariant generators in machine
learning algorithms in general and in neural networks specifically. By
implementing these generators in neural networks applied to regression tasks,
we test the improvements in performance under a wide range of hyperparameter
choices and find a reduction of the loss on training data and a significant
reduction of the loss on validation data. For a different approach on
quantifying the performance of these neural networks, we treat the problem from
a Bayesian inference perspective and employ nested sampling techniques to
perform model comparison. Beyond a certain network size, we find that networks
utilising Hironaka decompositions perform the best.",2021-04-26T17:24:29Z,http://arxiv.org/pdf/2104.12733v1,"['hep-ph', 'cs.LG', 'stat.ML']"
1909.06342v4,Explainable Machine Learning in Deployment,"['Umang Bhatt', 'Alice Xiang', 'Shubham Sharma', 'Adrian Weller', 'Ankur Taly', 'Yunhan Jia', 'Joydeep Ghosh', 'Ruchir Puri', 'José M. F. Moura', 'Peter Eckersley']","Explainable machine learning offers the potential to provide stakeholders
with insights into model behavior by using various methods such as feature
importance scores, counterfactual explanations, or influential training data.
Yet there is little understanding of how organizations use these methods in
practice. This study explores how organizations view and use explainability for
stakeholder consumption. We find that, currently, the majority of deployments
are not for end users affected by the model but rather for machine learning
engineers, who use explainability to debug the model itself. There is thus a
gap between explainability in practice and the goal of transparency, since
explanations primarily serve internal stakeholders rather than external ones.
Our study synthesizes the limitations of current explainability techniques that
hamper their use for end users. To facilitate end user interaction, we develop
a framework for establishing clear goals for explainability. We end by
discussing concerns raised regarding explainability.",2019-09-13T17:35:53Z,http://arxiv.org/pdf/1909.06342v4,"['cs.LG', 'cs.AI', 'cs.CY', 'cs.HC', 'stat.ML']"
2209.14991v3,Machine learning and invariant theory,"['Ben Blum-Smith', 'Soledad Villar']","Inspired by constraints from physical law, equivariant machine learning
restricts the learning to a hypothesis class where all the functions are
equivariant with respect to some group action. Irreducible representations or
invariant theory are typically used to parameterize the space of such
functions. In this article, we introduce the topic and explain a couple of
methods to explicitly parameterize equivariant functions that are being used in
machine learning applications. In particular, we explicate a general procedure,
attributed to Malgrange, to express all polynomial maps between linear spaces
that are equivariant under the action of a group $G$, given a characterization
of the invariant polynomials on a bigger space. The method also parametrizes
smooth equivariant maps in the case that $G$ is a compact Lie group.",2022-09-29T17:52:17Z,http://arxiv.org/pdf/2209.14991v3,"['stat.ML', 'cs.LG']"
2206.05985v2,Modeling the Machine Learning Multiverse,"['Samuel J. Bell', 'Onno P. Kampman', 'Jesse Dodge', 'Neil D. Lawrence']","Amid mounting concern about the reliability and credibility of machine
learning research, we present a principled framework for making robust and
generalizable claims: the multiverse analysis. Our framework builds upon the
multiverse analysis (Steegen et al., 2016) introduced in response to
psychology's own reproducibility crisis. To efficiently explore
high-dimensional and often continuous ML search spaces, we model the multiverse
with a Gaussian Process surrogate and apply Bayesian experimental design. Our
framework is designed to facilitate drawing robust scientific conclusions about
model performance, and thus our approach focuses on exploration rather than
conventional optimization. In the first of two case studies, we investigate
disputed claims about the relative merit of adaptive optimizers. Second, we
synthesize conflicting research on the effect of learning rate on the large
batch training generalization gap. For the machine learning community, the
multiverse analysis is a simple and effective technique for identifying robust
claims, for increasing transparency, and a step toward improved
reproducibility.",2022-06-13T09:11:48Z,http://arxiv.org/pdf/2206.05985v2,"['cs.LG', 'stat.ME']"
2210.00954v3,Machine Learning-Powered Course Allocation,"['Ermis Soumalias', 'Behnoosh Zamanlooy', 'Jakob Weissteiner', 'Sven Seuken']","We study the course allocation problem, where universities assign course
schedules to students. The current state-of-the-art mechanism, Course Match,
has one major shortcoming: students make significant mistakes when reporting
their preferences, which negatively affects welfare and fairness. To address
this issue, we introduce a new mechanism, Machine Learning-powered Course Match
(MLCM). At the core of MLCM is a machine learning-powered preference
elicitation module that iteratively asks personalized pairwise comparison
queries to alleviate students' reporting mistakes. Extensive computational
experiments, grounded in real-world data, demonstrate that MLCM, with only ten
comparison queries, significantly increases both average and minimum student
utility by 7%-11% and 17%-29%, respectively. Finally, we highlight MLCM's
robustness to changes in the environment and show how our design minimizes the
risk of upgrading to MLCM while making the upgrade process simple for
universities and seamless for their students.",2022-10-03T14:11:33Z,http://arxiv.org/pdf/2210.00954v3,"['cs.GT', 'cs.AI', 'cs.LG']"
2302.06716v3,Machine Learning Model Attribution Challenge,"['Elizabeth Merkhofer', 'Deepesh Chaudhari', 'Hyrum S. Anderson', 'Keith Manville', 'Lily Wong', 'João Gante']","We present the findings of the Machine Learning Model Attribution Challenge.
Fine-tuned machine learning models may derive from other trained models without
obvious attribution characteristics. In this challenge, participants identify
the publicly-available base models that underlie a set of anonymous, fine-tuned
large language models (LLMs) using only textual output of the models.
Contestants aim to correctly attribute the most fine-tuned models, with ties
broken in the favor of contestants whose solutions use fewer calls to the
fine-tuned models' API. The most successful approaches were manual, as
participants observed similarities between model outputs and developed
attribution heuristics based on public documentation of the base models, though
several teams also submitted automated, statistical solutions.",2023-02-13T22:05:27Z,http://arxiv.org/pdf/2302.06716v3,"['cs.LG', 'cs.CL', 'cs.CR']"
1512.02900v1,Advances in quantum machine learning,"['Jeremy Adcock', 'Euan Allen', 'Matthew Day', 'Stefan Frick', 'Janna Hinchliff', 'Mack Johnson', 'Sam Morley-Short', 'Sam Pallister', 'Alasdair Price', 'Stasja Stanisic']","Here we discuss advances in the field of quantum machine learning. The
following document offers a hybrid discussion; both reviewing the field as it
is currently, and suggesting directions for further research. We include both
algorithms and experimental implementations in the discussion. The field's
outlook is generally positive, showing significant promise. However, we believe
there are appreciable hurdles to overcome before one can claim that it is a
primary application of quantum computation.",2015-12-09T15:32:39Z,http://arxiv.org/pdf/1512.02900v1,['quant-ph']
2103.03122v1,Machine Learning using Stata/Python,['Giovanni Cerulli'],"We present two related Stata modules, r_ml_stata and c_ml_stata, for fitting
popular Machine Learning (ML) methods both in regression and classification
settings. Using the recent Stata/Python integration platform (sfi) of Stata 16,
these commands provide hyper-parameters' optimal tuning via K-fold
cross-validation using greed search. More specifically, they make use of the
Python Scikit-learn API to carry out both cross-validation and outcome/label
prediction.",2021-03-03T10:31:44Z,http://arxiv.org/pdf/2103.03122v1,"['stat.CO', 'cs.LG', 'cs.MS']"
2207.00108v1,Discrimination in machine learning algorithms,"['Roberta Pappadà', 'Francesco Pauli']","Machine learning algorithms are routinely used for business decisions that
may directly affect individuals, for example, because a credit scoring
algorithm refuses them a loan. It is then relevant from an ethical (and legal)
point of view to ensure that these algorithms do not discriminate based on
sensitive attributes (like sex or race), which may occur unwittingly and
unknowingly by the operator and the management. Statistical tools and methods
are then required to detect and eliminate such potential biases.",2022-06-30T21:35:42Z,http://arxiv.org/pdf/2207.00108v1,"['stat.ML', 'cs.CY', 'cs.LG']"
1909.08027v1,Machine Learning Potential Energy Surfaces,"['Oliver T. Unke', 'Markus Meuwly']","Machine Learning techniques can be used to represent high-dimensional
potential energy surfaces for reactive chemical systems. Two such methods are
based on a reproducing kernel Hilbert space representation or on deep neural
networks. They can achieve a sub-1 kcal/mol accuracy with respect to reference
data and can be used in studies of chemical dynamics. Their construction and a
few typical examples are briefly summarized in the present contribution.",2019-09-17T18:52:54Z,http://arxiv.org/pdf/1909.08027v1,['physics.chem-ph']
2205.11473v1,Rethinking Streaming Machine Learning Evaluation,"['Shreya Shankar', 'Bernease Herman', 'Aditya G. Parameswaran']","While most work on evaluating machine learning (ML) models focuses on
computing accuracy on batches of data, tracking accuracy alone in a streaming
setting (i.e., unbounded, timestamp-ordered datasets) fails to appropriately
identify when models are performing unexpectedly. In this position paper, we
discuss how the nature of streaming ML problems introduces new real-world
challenges (e.g., delayed arrival of labels) and recommend additional metrics
to assess streaming ML performance.",2022-05-23T17:21:43Z,http://arxiv.org/pdf/2205.11473v1,"['cs.LG', 'cs.AI', 'stat.ML']"
2311.02278v1,Machine learning's own Industrial Revolution,"['Yuan Luo', 'Song Han', 'Jingjing Liu']","Machine learning is expected to enable the next Industrial Revolution.
However, lacking standardized and automated assembly networks, ML faces
significant challenges to meet ever-growing enterprise demands and empower
broad industries. In the Perspective, we argue that ML needs to first complete
its own Industrial Revolution, elaborate on how to best achieve its goals, and
discuss new opportunities to enable rapid translation from ML's innovation
frontier to mass production and utilization.",2023-11-04T00:00:13Z,http://arxiv.org/pdf/2311.02278v1,['cs.LG']
2401.07929v1,Machine Learning Based Object Tracking,"['Md Rakibul Karim Akanda', 'Joshua Reynolds', 'Treylin Jackson', 'Milijah Gray']","Machine learning based object detection as well as tracking that object have
been performed in this paper. The authors were able to set a range of interest
(ROI) around an object using Open Computer Vision, better known as OpenCV. Next
a tracking algorithm has been used to maintain tracking on an object while
simultaneously operating two servo motors to keep the object centered in the
frame. Detailed procedure and code are included in this paper.",2024-01-15T19:46:05Z,http://arxiv.org/pdf/2401.07929v1,"['cs.CV', 'physics.app-ph']"
2506.00572v1,Machine-learning Growth at Risk,"['Tobias Adrian', 'Hongqi Chen', 'Max-Sebastian Dovì', 'Ji Hyung Lee']","We analyse growth vulnerabilities in the US using quantile partial
correlation regression, a selection-based machine-learning method that achieves
model selection consistency under time series. We find that downside risk is
primarily driven by financial, labour-market, and housing variables, with their
importance changing over time. Decomposing downside risk into its individual
components, we construct sector-specific indices that predict it, while
controlling for information from other sectors, thereby isolating the downside
risks emanating from each sector.",2025-05-31T14:06:53Z,http://arxiv.org/pdf/2506.00572v1,"['econ.GN', 'q-fin.EC']"
0611011v1,Hedging predictions in machine learning,"['Alexander Gammerman', 'Vladimir Vovk']","Recent advances in machine learning make it possible to design efficient
prediction algorithms for data sets with huge numbers of parameters. This paper
describes a new technique for ""hedging"" the predictions output by many such
algorithms, including support vector machines, kernel ridge regression, kernel
nearest neighbours, and by many other state-of-the-art methods. The hedged
predictions for the labels of new objects include quantitative measures of
their own accuracy and reliability. These measures are provably valid under the
assumption of randomness, traditional in machine learning: the objects and
their labels are assumed to be generated independently from the same
probability distribution. In particular, it becomes possible to control (up to
statistical fluctuations) the number of erroneous predictions by selecting a
suitable confidence level. Validity being achieved automatically, the remaining
goal of hedged prediction is efficiency: taking full account of the new
objects' features and other available information to produce as accurate
predictions as possible. This can be done successfully using the powerful
machinery of modern machine learning.",2006-11-02T18:44:49Z,http://arxiv.org/pdf/cs/0611011v1,['cs.LG']
1808.03794v1,Magnetic microstructure machine learning analysis,"['Lukas Exl', 'Johann Fischbacher', 'Alexander Kovacs', 'Harald Oezelt', 'Markus Gusenbauer', 'Kazuya Yokota', 'Tetsuya Shoji', 'Gino Hrkac', 'Thomas Schrefl']","We use a machine learning approach to identify the importance of
microstructure characteristics in causing magnetization reversal in ideally
structured large-grained Nd$_2$Fe$_{14}$B permanent magnets. The embedded
Stoner-Wohlfarth method is used as a reduced order model for determining local
switching field maps which guide the data-driven learning procedure. The
predictor model is a random forest classifier which we validate by comparing
with full micromagnetic simulations in the case of small granular test
structures. In the course of the machine learning microstructure analysis the
most important features explaining magnetization reversal were found to be the
misorientation and the position of the grain within the magnet. The lowest
switching fields occur near the top and bottom edges of the magnet. While the
dependence of the local switching field on the grain orientation is known from
theory, the influence of the position of the grain on the local coercive field
strength is less obvious. As a direct result of our findings of the machine
learning analysis we show that edge hardening via Dy-diffusion leads to higher
coercive fields.",2018-08-11T12:25:36Z,http://arxiv.org/pdf/1808.03794v1,"['cond-mat.mtrl-sci', 'physics.comp-ph', 'physics.data-an']"
1811.11668v1,Racial categories in machine learning,"['Sebastian Benthall', 'Bruce D. Haynes']","Controversies around race and machine learning have sparked debate among
computer scientists over how to design machine learning systems that guarantee
fairness. These debates rarely engage with how racial identity is embedded in
our social experience, making for sociological and psychological complexity.
This complexity challenges the paradigm of considering fairness to be a formal
property of supervised learning with respect to protected personal attributes.
Racial identity is not simply a personal subjective quality. For people labeled
""Black"" it is an ascribed political category that has consequences for social
differentiation embedded in systemic patterns of social inequality achieved
through both social and spatial segregation. In the United States, racial
classification can best be understood as a system of inherently unequal status
categories that places whites as the most privileged category while signifying
the Negro/black category as stigmatized. Social stigma is reinforced through
the unequal distribution of societal rewards and goods along racial lines that
is reinforced by state, corporate, and civic institutions and practices. This
creates a dilemma for society and designers: be blind to racial group
disparities and thereby reify racialized social inequality by no longer
measuring systemic inequality, or be conscious of racial categories in a way
that itself reifies race. We propose a third option. By preceding group
fairness interventions with unsupervised learning to dynamically detect
patterns of segregation, machine learning systems can mitigate the root cause
of social disparities, social segregation and stratification, without further
anchoring status categories of disadvantage.",2018-11-28T16:47:36Z,http://arxiv.org/pdf/1811.11668v1,"['cs.LG', 'stat.ML']"
2004.01496v2,Company classification using machine learning,"['Sven Husmann', 'Antoniya Shivarova', 'Rick Steinert']","The recent advancements in computational power and machine learning
algorithms have led to vast improvements in manifold areas of research.
Especially in finance, the application of machine learning enables both
researchers and practitioners to gain new insights into financial data and
well-studied areas such as company classification. In our paper, we demonstrate
that unsupervised machine learning algorithms can be used to visualize and
classify company data in an economically meaningful and effective way. In
particular, we implement the data-driven dimension reduction and visualization
tool t-distributed stochastic neighbor embedding (t-SNE) in combination with
spectral clustering. The resulting company groups can then be utilized by
experts in the field for empirical analysis and optimal decision making. By
providing an exemplary out-of-sample study within a portfolio optimization
framework, we show that the application of t-SNE and spectral clustering
improves the overall portfolio performance. Therefore, we introduce our
approach to the financial community as a valuable technique in the context of
data analysis and company classification.",2020-03-31T23:36:27Z,http://arxiv.org/pdf/2004.01496v2,"['q-fin.ST', 'cs.LG']"
2103.13358v1,Anticipating synchronization with machine learning,"['Huawei Fan', 'Ling-Wei Kong', 'Ying-Cheng Lai', 'Xingang Wang']","In applications of dynamical systems, situations can arise where it is
desired to predict the onset of synchronization as it can lead to
characteristic and significant changes in the system performance and behaviors,
for better or worse. In experimental and real settings, the system equations
are often unknown, raising the need to develop a prediction framework that is
model free and fully data driven. We contemplate that this challenging problem
can be addressed with machine learning. In particular, exploiting reservoir
computing or echo state networks, we devise a ""parameter-aware"" scheme to train
the neural machine using asynchronous time series, i.e., in the parameter
regime prior to the onset of synchronization. A properly trained machine will
possess the power to predict the synchronization transition in that, with a
given amount of parameter drift, whether the system would remain asynchronous
or exhibit synchronous dynamics can be accurately anticipated. We demonstrate
the machine-learning based framework using representative chaotic models and
small network systems that exhibit continuous (second-order) or abrupt
(first-order) transitions. A remarkable feature is that, for a network system
exhibiting an explosive (first-order) transition and a hysteresis loop in
synchronization, the machine learning scheme is capable of accurately
predicting these features, including the precise locations of the transition
points associated with the forward and backward transition paths.",2021-03-13T03:51:48Z,http://arxiv.org/pdf/2103.13358v1,"['nlin.AO', 'stat.ML']"
2011.14135v2,Exoplanet Detection using Machine Learning,"['Abhishek Malik', 'Benjamin P. Moster', 'Christian Obermeier']","We introduce a new machine learning based technique to detect exoplanets
using the transit method. Machine learning and deep learning techniques have
proven to be broadly applicable in various scientific research areas. We aim to
exploit some of these methods to improve the conventional algorithm based
approaches presently used in astrophysics to detect exoplanets. Using the
time-series analysis library TSFresh to analyse light curves, we extracted 789
features from each curve, which capture the information about the
characteristics of a light curve. We then used these features to train a
gradient boosting classifier using the machine learning tool lightgbm. This
approach was tested on simulated data, which showed that is more effective than
the conventional box least squares fitting (BLS) method. We further found that
our method produced comparable results to existing state-of-the-art deep
learning models, while being much more computationally efficient and without
needing folded and secondary views of the light curves. For Kepler data, the
method is able to predict a planet with an AUC of 0.948, so that 94.8 per cent
of the true planet signals are ranked higher than non-planet signals. The
resulting recall is 0.96, so that 96 per cent of real planets are classified as
planets. For the Transiting Exoplanet Survey Satellite (TESS) data, we found
our method can classify light curves with an accuracy of 0.98, and is able to
identify planets with a recall of 0.82 at a precision of 0.63.",2020-11-28T14:06:39Z,http://arxiv.org/pdf/2011.14135v2,"['astro-ph.EP', 'astro-ph.IM', 'cs.LG']"
1603.09035v1,Towards Geo-Distributed Machine Learning,"['Ignacio Cano', 'Markus Weimer', 'Dhruv Mahajan', 'Carlo Curino', 'Giovanni Matteo Fumarola']","Latency to end-users and regulatory requirements push large companies to
build data centers all around the world. The resulting data is ""born""
geographically distributed. On the other hand, many machine learning
applications require a global view of such data in order to achieve the best
results. These types of applications form a new class of learning problems,
which we call Geo-Distributed Machine Learning (GDML). Such applications need
to cope with: 1) scarce and expensive cross-data center bandwidth, and 2)
growing privacy concerns that are pushing for stricter data sovereignty
regulations. Current solutions to learning from geo-distributed data sources
revolve around the idea of first centralizing the data in one data center, and
then training locally. As machine learning algorithms are
communication-intensive, the cost of centralizing the data is thought to be
offset by the lower cost of intra-data center communication during training. In
this work, we show that the current centralized practice can be far from
optimal, and propose a system for doing geo-distributed training. Furthermore,
we argue that the geo-distributed approach is structurally more amenable to
dealing with regulatory constraints, as raw data never leaves the source data
center. Our empirical evaluation on three real datasets confirms the general
validity of our approach, and shows that GDML is not only possible but also
advisable in many scenarios.",2016-03-30T04:05:29Z,http://arxiv.org/pdf/1603.09035v1,"['cs.LG', 'cs.DC', 'stat.ML']"
1901.03678v1,Machine Learning Automation Toolbox (MLaut),"['Viktor Kazakov', 'Franz J. Király']","In this paper we present MLaut (Machine Learning AUtomation Toolbox) for the
python data science ecosystem. MLaut automates large-scale evaluation and
benchmarking of machine learning algorithms on a large number of datasets.
MLaut provides a high-level workflow interface to machine algorithm algorithms,
implements a local back-end to a database of dataset collections, trained
algorithms, and experimental results, and provides easy-to-use interfaces to
the scikit-learn and keras modelling libraries. Experiments are easy to set up
with default settings in a few lines of code, while remaining fully
customizable to the level of hyper-parameter tuning, pipeline composition, or
deep learning architecture.
  As a principal test case for MLaut, we conducted a large-scale supervised
classification study in order to benchmark the performance of a number of
machine learning algorithms - to our knowledge also the first larger-scale
study on standard supervised learning data sets to include deep learning
algorithms. While corroborating a number of previous findings in literature, we
found (within the limitations of our study) that deep neural networks do not
perform well on basic supervised learning, i.e., outside the more specialized,
image-, audio-, or text-based tasks.",2019-01-11T18:06:05Z,http://arxiv.org/pdf/1901.03678v1,"['cs.LG', 'cs.AI', 'stat.ML']"
2410.22854v2,Hyperparameter Optimization in Machine Learning,"['Luca Franceschi', 'Michele Donini', 'Valerio Perrone', 'Aaron Klein', 'Cédric Archambeau', 'Matthias Seeger', 'Massimiliano Pontil', 'Paolo Frasconi']","Hyperparameters are configuration variables controlling the behavior of
machine learning algorithms. They are ubiquitous in machine learning and
artificial intelligence and the choice of their values determines the
effectiveness of systems based on these technologies. Manual hyperparameter
search is often unsatisfactory and becomes infeasible when the number of
hyperparameters is large. Automating the search is an important step towards
advancing, streamlining, and systematizing machine learning, freeing
researchers and practitioners alike from the burden of finding a good set of
hyperparameters by trial and error. In this survey, we present a unified
treatment of hyperparameter optimization, providing the reader with examples,
insights into the state-of-the-art, and numerous links to further reading. We
cover the main families of techniques to automate hyperparameter search, often
referred to as hyperparameter optimization or tuning, including random and
quasi-random search, bandit-, model-, population-, and gradient-based
approaches. We further discuss extensions, including online, constrained, and
multi-objective formulations, touch upon connections with other fields such as
meta-learning and neural architecture search, and conclude with open questions
and future research directions.",2024-10-30T09:39:22Z,http://arxiv.org/pdf/2410.22854v2,"['stat.ML', 'cs.LG']"
2411.10744v1,Digital-Analog Quantum Machine Learning,['Lucas Lamata'],"Machine Learning algorithms are extensively used in an increasing number of
systems, applications, technologies, and products, both in industry and in
society as a whole. They enable computing devices to learn from previous
experience and therefore improve their performance in a certain context or
environment. In this way, many useful possibilities have been made accessible.
However, dealing with an increasing amount of data poses difficulties for
classical devices. Quantum systems may offer a way forward, possibly enabling
to scale up machine learning calculations in certain contexts. On the other
hand, quantum systems themselves are also hard to scale up, due to decoherence
and the fragility of quantum superpositions. In the short and mid term, it has
been evidenced that a quantum paradigm that combines evolution under large
analog blocks with discrete quantum gates, may be fruitful to achieve new
knowledge of classical and quantum systems with no need of having a
fault-tolerant quantum computer. In this Perspective, we review some recent
works that employ this digital-analog quantum paradigm to carry out efficient
machine learning calculations with current quantum devices.",2024-11-16T08:54:52Z,http://arxiv.org/pdf/2411.10744v1,"['quant-ph', 'cs.AI']"
2103.11249v1,SELM: Software Engineering of Machine Learning Models,"['Nafiseh Jafari', 'Mohammad Reza Besharati', 'Mohammad Izadi', 'Maryam Hourali']","One of the pillars of any machine learning model is its concepts. Using
software engineering, we can engineer these concepts and then develop and
expand them. In this article, we present a SELM framework for Software
Engineering of machine Learning Models. We then evaluate this framework through
a case study. Using the SELM framework, we can improve a machine learning
process efficiency and provide more accuracy in learning with less processing
hardware resources and a smaller training dataset. This issue highlights the
importance of an interdisciplinary approach to machine learning. Therefore, in
this article, we have provided interdisciplinary teams' proposals for machine
learning.",2021-03-20T21:43:24Z,http://arxiv.org/pdf/2103.11249v1,"['cs.SE', 'cs.AI']"
2306.14624v2,Insights From Insurance for Fair Machine Learning,"['Christian Fröhlich', 'Robert C. Williamson']","We argue that insurance can act as an analogon for the social situatedness of
machine learning systems, hence allowing machine learning scholars to take
insights from the rich and interdisciplinary insurance literature. Tracing the
interaction of uncertainty, fairness and responsibility in insurance provides a
fresh perspective on fairness in machine learning. We link insurance fairness
conceptions to their machine learning relatives, and use this bridge to
problematize fairness as calibration. In this process, we bring to the
forefront two themes that have been largely overlooked in the machine learning
literature: responsibility and aggregate-individual tensions.",2023-06-26T11:56:00Z,http://arxiv.org/pdf/2306.14624v2,"['cs.LG', 'cs.CY']"
2403.17381v1,Application-Driven Innovation in Machine Learning,"['David Rolnick', 'Alan Aspuru-Guzik', 'Sara Beery', 'Bistra Dilkina', 'Priya L. Donti', 'Marzyeh Ghassemi', 'Hannah Kerner', 'Claire Monteleoni', 'Esther Rolf', 'Milind Tambe', 'Adam White']","As applications of machine learning proliferate, innovative algorithms
inspired by specific real-world challenges have become increasingly important.
Such work offers the potential for significant impact not merely in domains of
application but also in machine learning itself. In this paper, we describe the
paradigm of application-driven research in machine learning, contrasting it
with the more standard paradigm of methods-driven research. We illustrate the
benefits of application-driven machine learning and how this approach can
productively synergize with methods-driven work. Despite these benefits, we
find that reviewing, hiring, and teaching practices in machine learning often
hold back application-driven innovation. We outline how these processes may be
improved.",2024-03-26T04:59:27Z,http://arxiv.org/pdf/2403.17381v1,"['cs.LG', 'cs.AI']"
2108.07915v1,Data Pricing in Machine Learning Pipelines,"['Zicun Cong', 'Xuan Luo', 'Pei Jian', 'Feida Zhu', 'Yong Zhang']","Machine learning is disruptive. At the same time, machine learning can only
succeed by collaboration among many parties in multiple steps naturally as
pipelines in an eco-system, such as collecting data for possible machine
learning applications, collaboratively training models by multiple parties and
delivering machine learning services to end users. Data is critical and
penetrating in the whole machine learning pipelines. As machine learning
pipelines involve many parties and, in order to be successful, have to form a
constructive and dynamic eco-system, marketplaces and data pricing are
fundamental in connecting and facilitating those many parties. In this article,
we survey the principles and the latest research development of data pricing in
machine learning pipelines. We start with a brief review of data marketplaces
and pricing desiderata. Then, we focus on pricing in three important steps in
machine learning pipelines. To understand pricing in the step of training data
collection, we review pricing raw data sets and data labels. We also
investigate pricing in the step of collaborative training of machine learning
models, and overview pricing machine learning models for end users in the step
of machine learning deployment. We also discuss a series of possible future
directions.",2021-08-18T00:57:06Z,http://arxiv.org/pdf/2108.07915v1,['cs.LG']
2103.00366v2,Confronting Machine Learning With Financial Research,"['Kristof Lommers', 'Ouns El Harzli', 'Jack Kim']","This study aims to examine the challenges and applications of machine
learning for financial research. Machine learning algorithms have been
developed for certain data environments which substantially differ from the one
we encounter in finance. Not only do difficulties arise due to some of the
idiosyncrasies of financial markets, there is a fundamental tension between the
underlying paradigm of machine learning and the research philosophy in
financial economics. Given the peculiar features of financial markets and the
empirical framework within social science, various adjustments have to be made
to the conventional machine learning methodology. We discuss some of the main
challenges of machine learning in finance and examine how these could be
accounted for. Despite some of the challenges, we argue that machine learning
could be unified with financial research to become a robust complement to the
econometrician's toolbox. Moreover, we discuss the various applications of
machine learning in the research process such as estimation, empirical
discovery, testing, causal inference and prediction.",2021-02-28T01:10:09Z,http://arxiv.org/pdf/2103.00366v2,"['q-fin.ST', 'cs.LG', 'econ.EM']"
1707.03184v1,A Survey on Resilient Machine Learning,"['Atul Kumar', 'Sameep Mehta']","Machine learning based system are increasingly being used for sensitive tasks
such as security surveillance, guiding autonomous vehicle, taking investment
decisions, detecting and blocking network intrusion and malware etc. However,
recent research has shown that machine learning models are venerable to attacks
by adversaries at all phases of machine learning (eg, training data collection,
training, operation). All model classes of machine learning systems can be
misled by providing carefully crafted inputs making them wrongly classify
inputs. Maliciously created input samples can affect the learning process of a
ML system by either slowing down the learning process, or affecting the
performance of the learned mode, or causing the system make error(s) only in
attacker's planned scenario. Because of these developments, understanding
security of machine learning algorithms and systems is emerging as an important
research area among computer security and machine learning researchers and
practitioners. We present a survey of this emerging area in machine learning.",2017-07-11T09:15:46Z,http://arxiv.org/pdf/1707.03184v1,"['cs.AI', 'cs.CR', 'cs.LG']"
2011.04328v1,Risk Assessment for Machine Learning Models,"['Paul Schwerdtner', 'Florens Greßner', 'Nikhil Kapoor', 'Felix Assion', 'René Sass', 'Wiebke Günther', 'Fabian Hüger', 'Peter Schlicht']","In this paper we propose a framework for assessing the risk associated with
deploying a machine learning model in a specified environment. For that we
carry over the risk definition from decision theory to machine learning. We
develop and implement a method that allows to define deployment scenarios, test
the machine learning model under the conditions specified in each scenario, and
estimate the damage associated with the output of the machine learning model
under test. Using the likelihood of each scenario together with the estimated
damage we define \emph{key risk indicators} of a machine learning model.
  The definition of scenarios and weighting by their likelihood allows for
standardized risk assessment in machine learning throughout multiple domains of
application. In particular, in our framework, the robustness of a machine
learning model to random input corruptions, distributional shifts caused by a
changing environment, and adversarial perturbations can be assessed.",2020-11-09T10:50:50Z,http://arxiv.org/pdf/2011.04328v1,"['cs.LG', 'cs.AI']"
2406.04344v3,"Verbalized Machine Learning: Revisiting Machine Learning with Language
  Models","['Tim Z. Xiao', 'Robert Bamler', 'Bernhard Schölkopf', 'Weiyang Liu']","Motivated by the progress made by large language models (LLMs), we introduce
the framework of verbalized machine learning (VML). In contrast to conventional
machine learning (ML) models that are typically optimized over a continuous
parameter space, VML constrains the parameter space to be human-interpretable
natural language. Such a constraint leads to a new perspective of function
approximation, where an LLM with a text prompt can be viewed as a function
parameterized by the text prompt. Guided by this perspective, we revisit
classical ML problems, such as regression and classification, and find that
these problems can be solved by an LLM-parameterized learner and optimizer. The
major advantages of VML include (1) easy encoding of inductive bias: prior
knowledge about the problem and hypothesis class can be encoded in natural
language and fed into the LLM-parameterized learner; (2) automatic model class
selection: the optimizer can automatically select a model class based on data
and verbalized prior knowledge, and it can update the model class during
training; and (3) interpretable learner updates: the LLM-parameterized
optimizer can provide explanations for why an update is performed. We
empirically verify the effectiveness of VML, and hope that VML can serve as a
stepping stone to stronger interpretability.",2024-06-06T17:59:56Z,http://arxiv.org/pdf/2406.04344v3,"['cs.LG', 'cs.CL', 'cs.CV']"
1905.03853v2,Genuinely Distributed Byzantine Machine Learning,"['El-Mahdi El-Mhamdi', 'Rachid Guerraoui', 'Arsany Guirguis', 'Lê Nguyên Hoang', 'Sébastien Rouault']","Machine Learning (ML) solutions are nowadays distributed, according to the
so-called server/worker architecture. One server holds the model parameters
while several workers train the model. Clearly, such architecture is prone to
various types of component failures, which can be all encompassed within the
spectrum of a Byzantine behavior. Several approaches have been proposed
recently to tolerate Byzantine workers. Yet all require trusting a central
parameter server. We initiate in this paper the study of the ``general''
Byzantine-resilient distributed machine learning problem where no individual
component is trusted.
  We show that this problem can be solved in an asynchronous system, despite
the presence of $\frac{1}{3}$ Byzantine parameter servers and $\frac{1}{3}$
Byzantine workers (which is optimal). We present a new algorithm, ByzSGD, which
solves the general Byzantine-resilient distributed machine learning problem by
relying on three major schemes. The first, Scatter/Gather, is a communication
scheme whose goal is to bound the maximum drift among models on correct
servers. The second, Distributed Median Contraction (DMC), leverages the
geometric properties of the median in high dimensional spaces to bring
parameters within the correct servers back close to each other, ensuring
learning convergence. The third, Minimum-Diameter Averaging (MDA), is a
statistically-robust gradient aggregation rule whose goal is to tolerate
Byzantine workers. MDA requires loose bound on the variance of non-Byzantine
gradient estimates, compared to existing alternatives (e.g., Krum).
Interestingly, ByzSGD ensures Byzantine resilience without adding communication
rounds (on a normal path), compared to vanilla non-Byzantine alternatives.
ByzSGD requires, however, a larger number of messages which, we show, can be
reduced if we assume synchrony.",2019-05-05T16:14:30Z,http://arxiv.org/pdf/1905.03853v2,"['cs.DC', 'cs.LG', 'stat.ML']"
1603.02021v1,Machine Learning for Protein Function,['Dan Ofer'],"Systematic identification of protein function is a key problem in current
biology. Most traditional methods fail to identify functionally equivalent
proteins if they lack similar sequences, structural data or extensive manual
annotations. In this thesis, I focused on feature engineering and machine
learning methods for identifying diverse classes of proteins that share
functional relatedness but little sequence or structural similarity, notably,
Neuropeptide Precursors (NPPs).
  I aim to identify functional protein classes solely using unannotated protein
primary sequences from any organism. This thesis focuses on feature
representations of whole protein sequences, sequence derived engineered
features, their extraction, frameworks for their usage by machine learning (ML)
models, and the application of ML models to biological tasks, focusing on high
level protein functions. I implemented the ideas of feature engineering to
develop a platform (called NeuroPID) that extracts meaningful features for
classification of overlooked NPPs. The platform allows mass discovery of new
NPs and NPPs. It was expanded as a webserver.
  I expanded our approach towards other challenging protein classes. This is
implemented as a novel bioinformatics toolkit called ProFET (Protein Feature
Engineering Toolkit). ProFET extracts hundreds of biophysical and sequence
derived attributes, allowing the application of machine learning methods to
proteins. ProFET was applied on many protein benchmark datasets with state of
the art performance. The success of ProFET applies to a wide range of
high-level functions such as metagenomic analysis, subcellular localization,
structure and unique functional properties (e.g. thermophiles, nucleic acid
binding).
  These methods and frameworks represent a valuable resource for using ML and
data science methods on proteins.",2016-03-07T12:04:10Z,http://arxiv.org/pdf/1603.02021v1,['q-bio.GN']
0701907v3,Kernel methods in machine learning,"['Thomas Hofmann', 'Bernhard Schölkopf', 'Alexander J. Smola']","We review machine learning methods employing positive definite kernels. These
methods formulate learning and estimation problems in a reproducing kernel
Hilbert space (RKHS) of functions defined on the data domain, expanded in terms
of a kernel. Working in linear spaces of function has the benefit of
facilitating the construction and analysis of learning algorithms while at the
same time allowing large classes of functions. The latter include nonlinear
functions as well as functions defined on nonvectorial data. We cover a wide
range of methods, ranging from binary classifiers to sophisticated methods for
estimation with structured data.",2007-01-31T03:42:40Z,http://arxiv.org/pdf/math/0701907v3,"['math.ST', 'math.PR', 'stat.TH', '30C40 (Primary) 68T05 (Secondary)']"
1103.1003v1,Teraflop-scale Incremental Machine Learning,['Eray Özkural'],"We propose a long-term memory design for artificial general intelligence
based on Solomonoff's incremental machine learning methods. We use R5RS Scheme
and its standard library with a few omissions as the reference machine. We
introduce a Levin Search variant based on Stochastic Context Free Grammar
together with four synergistic update algorithms that use the same grammar as a
guiding probability distribution of programs. The update algorithms include
adjusting production probabilities, re-using previous solutions, learning
programming idioms and discovery of frequent subprograms. Experiments with two
training sequences demonstrate that our approach to incremental learning is
effective.",2011-03-05T03:41:30Z,http://arxiv.org/pdf/1103.1003v1,['cs.AI']
1107.4340v1,Spectral approximations in machine learning,"['Darren Homrighausen', 'Daniel J. McDonald']","In many areas of machine learning, it becomes necessary to find the
eigenvector decompositions of large matrices. We discuss two methods for
reducing the computational burden of spectral decompositions: the more
venerable Nystom extension and a newly introduced algorithm based on random
projections. Previous work has centered on the ability to reconstruct the
original matrix. We argue that a more interesting and relevant comparison is
their relative performance in clustering and classification tasks using the
approximate eigenvectors as features. We demonstrate that performance is task
specific and depends on the rank of the approximation.",2011-07-21T18:44:51Z,http://arxiv.org/pdf/1107.4340v1,['stat.ML']
1404.1333v2,Understanding Machine-learned Density Functionals,"['Li Li', 'John C. Snyder', 'Isabelle M. Pelaschier', 'Jessica Huang', 'Uma-Naresh Niranjan', 'Paul Duncan', 'Matthias Rupp', 'Klaus-Robert Müller', 'Kieron Burke']","Kernel ridge regression is used to approximate the kinetic energy of
non-interacting fermions in a one-dimensional box as a functional of their
density. The properties of different kernels and methods of cross-validation
are explored, and highly accurate energies are achieved. Accurate {\em
constrained optimal densities} are found via a modified Euler-Lagrange
constrained minimization of the total energy. A projected gradient descent
algorithm is derived using local principal component analysis. Additionally, a
sparse grid representation of the density can be used without degrading the
performance of the methods. The implications for machine-learned density
functional approximations are discussed.",2014-04-04T18:20:23Z,http://arxiv.org/pdf/1404.1333v2,"['physics.chem-ph', 'cs.LG', 'physics.comp-ph', 'stat.ML']"
1708.06615v3,Exploring supersymmetry with machine learning,"['Jie Ren', 'Lei Wu', 'Jin Min Yang', 'Jun Zhao']","Investigation of well-motivated parameter space in the theories of Beyond the
Standard Model (BSM) plays an important role in new physics discoveries.
However, a large-scale exploration of models with multi-parameter or equivalent
solutions with a finite separation, such as supersymmetric models, is typically
a time-consuming and challenging task. In this paper, we propose a
self-exploration method, named Machine Learning Scan (MLS), to achieve an
efficient test of models. As a proof-of-concept, we apply MLS to investigate
the subspace of MSSM and CMSSM and find that such a method can reduce the
computational cost and may be helpful for accelerating the exploration of
supersymmetry.",2017-08-22T13:56:48Z,http://arxiv.org/pdf/1708.06615v3,['hep-ph']
1808.06492v1,Benchmarking Automatic Machine Learning Frameworks,"['Adithya Balaji', 'Alexander Allen']","AutoML serves as the bridge between varying levels of expertise when
designing machine learning systems and expedites the data science process. A
wide range of techniques is taken to address this, however there does not exist
an objective comparison of these techniques. We present a benchmark of current
open source AutoML solutions using open source datasets. We test auto-sklearn,
TPOT, auto_ml, and H2O's AutoML solution against a compiled set of regression
and classification datasets sourced from OpenML and find that auto-sklearn
performs the best across classification datasets and TPOT performs the best
across regression datasets.",2018-08-17T02:15:39Z,http://arxiv.org/pdf/1808.06492v1,"['cs.LG', 'cs.AI', 'stat.ML']"
2006.04747v2,Secure Byzantine-Robust Machine Learning,"['Lie He', 'Sai Praneeth Karimireddy', 'Martin Jaggi']","Increasingly machine learning systems are being deployed to edge servers and
devices (e.g. mobile phones) and trained in a collaborative manner. Such
distributed/federated/decentralized training raises a number of concerns about
the robustness, privacy, and security of the procedure. While extensive work
has been done in tackling with robustness, privacy, or security individually,
their combination has rarely been studied. In this paper, we propose a secure
two-server protocol that offers both input privacy and Byzantine-robustness. In
addition, this protocol is communication-efficient, fault-tolerant and enjoys
local differential privacy.",2020-06-08T16:55:15Z,http://arxiv.org/pdf/2006.04747v2,"['cs.LG', 'cs.CR', 'stat.ML']"
2101.01759v2,Machine Learning and Quantum Devices,['Florian Marquardt'],"These brief lecture notes cover the basics of neural networks and deep
learning as well as their applications in the quantum domain, for physicists
without prior knowledge. In the first part, we describe training using
backpropagation, image classification, convolutional networks and autoencoders.
The second part is about advanced techniques like reinforcement learning (for
discovering control strategies), recurrent neural networks (for analyzing time
traces), and Boltzmann machines (for learning probability distributions). In
the third lecture, we discuss first recent applications to quantum physics,
with an emphasis on quantum information processing machines. Finally, the
fourth lecture is devoted to the promise of using quantum effects to accelerate
machine learning.",2021-01-05T19:48:24Z,http://arxiv.org/pdf/2101.01759v2,['quant-ph']
1912.03354v1,Bilinear Models for Machine Learning,"['Tayssir Doghri', 'Leszek Szczecinski', 'Jacob Benesty', 'Amar Mitiche']","In this work we define and analyze the bilinear models which replace the
conventional linear operation used in many building blocks of machine learning
(ML). The main idea is to devise the ML algorithms which are adapted to the
objects they treat. In the case of monochromatic images, we show that the
bilinear operation exploits better the structure of the image than the
conventional linear operation which ignores the spatial relationship between
the pixels. This translates into significantly smaller number of parameters
required to yield the same performance. We show numerical examples of
classification in the MNIST data set.",2019-12-06T21:59:59Z,http://arxiv.org/pdf/1912.03354v1,['cs.CV']
1807.07260v1,Machine Learning Based Featureless Signalling,['Ismail Shakeel'],"Direct-sequence spread-spectrum (DSSS) is commonly used to mitigate the
effect of jamming and to operate under an adversary receiver's thermal noise
floor in order to avoid signal detection. Unfortunately, the discrete nature
and unique distribution of DSSS spreading sequences make it relatively easy to
detect the resulting transmitted signals. To overcome this issue, this paper
proposes a machine learning based scheme that generates featureless,
non-repetitive noise-like spread signals. The proposed scheme provides several
benefits over the standard DSSS system including the ability to generate
signals with low probabilities of detection/intercept, additional processing
gain and also an uncoordinated synchronisation method.",2018-07-19T06:59:33Z,http://arxiv.org/pdf/1807.07260v1,['eess.SP']
2209.01091v2,Machine Learning Post-Minkowskian Integrals,"['Ryusuke Jinno', 'Gregor Kälin', 'Zhengwen Liu', 'Henrique Rubira']","We study a neural network framework for the numerical evaluation of Feynman
loop integrals that are fundamental building blocks for perturbative
computations of physical observables in gauge and gravity theories. We show
that such a machine learning approach improves the convergence of the Monte
Carlo algorithm for high-precision evaluation of multi-dimensional integrals
compared to traditional algorithms. In particular, we use a neural network to
improve the importance sampling. For a set of representative integrals
appearing in the computation of the conservative dynamics for a compact binary
system in General Relativity, we perform a quantitative comparison between the
Monte Carlo integrators VEGAS and i-flow, an integrator based on neural network
sampling.",2022-09-02T14:44:21Z,http://arxiv.org/pdf/2209.01091v2,"['hep-th', 'gr-qc', 'hep-ph']"
2003.13339v1,Machine Learning String Standard Models,"['Rehan Deen', 'Yang-Hui He', 'Seung-Joo Lee', 'Andre Lukas']","We study machine learning of phenomenologically relevant properties of string
compactifications, which arise in the context of heterotic line bundle models.
Both supervised and unsupervised learning are considered. We find that, for a
fixed compactification manifold, relatively small neural networks are capable
of distinguishing consistent line bundle models with the correct gauge group
and the correct chiral asymmetry from random models without these properties.
The same distinction can also be achieved in the context of unsupervised
learning, using an auto-encoder. Learning non-topological properties,
specifically the number of Higgs multiplets, turns out to be more difficult,
but is possible using sizeable networks and feature-enhanced data sets.",2020-03-30T11:14:14Z,http://arxiv.org/pdf/2003.13339v1,"['hep-th', 'math.AG', 'stat.ML']"
2109.04298v1,Quantum Machine Learning for Finance,"['Marco Pistoia', 'Syed Farhan Ahmad', 'Akshay Ajagekar', 'Alexander Buts', 'Shouvanik Chakrabarti', 'Dylan Herman', 'Shaohan Hu', 'Andrew Jena', 'Pierre Minssen', 'Pradeep Niroula', 'Arthur Rattew', 'Yue Sun', 'Romina Yalovetzky']","Quantum computers are expected to surpass the computational capabilities of
classical computers during this decade, and achieve disruptive impact on
numerous industry sectors, particularly finance. In fact, finance is estimated
to be the first industry sector to benefit from Quantum Computing not only in
the medium and long terms, but even in the short term. This review paper
presents the state of the art of quantum algorithms for financial applications,
with particular focus to those use cases that can be solved via Machine
Learning.",2021-09-09T14:20:10Z,http://arxiv.org/pdf/2109.04298v1,"['quant-ph', 'cs.LG']"
2112.06350v2,Machine Learning Calabi-Yau Hypersurfaces,"['David S. Berman', 'Yang-Hui He', 'Edward Hirst']","We revisit the classic database of weighted-P4s which admit Calabi-Yau 3-fold
hypersurfaces equipped with a diverse set of tools from the machine-learning
toolbox. Unsupervised techniques identify an unanticipated almost linear
dependence of the topological data on the weights. This then allows us to
identify a previously unnoticed clustering in the Calabi-Yau data. Supervised
techniques are successful in predicting the topological parameters of the
hypersurface from its weights with an accuracy of R^2 > 95%. Supervised
learning also allows us to identify weighted-P4s which admit Calabi-Yau
hypersurfaces to 100% accuracy by making use of partitioning supported by the
clustering behaviour.",2021-12-12T23:17:31Z,http://arxiv.org/pdf/2112.06350v2,"['hep-th', 'math.AG', 'stat.ML']"
2203.04983v1,Modeling hadronization using machine learning,"['Phil Ilten', 'Tony Menzo', 'Ahmed Youssef', 'Jure Zupan']","We present the first steps in the development of a new class of hadronization
models utilizing machine learning techniques. We successfully implement,
validate, and train a conditional sliced-Wasserstein autoencoder to replicate
the Pythia generated kinematic distributions of first-hadron emissions, when
the Lund string model of hadronization implemented in Pythia is restricted to
the emissions of pions only. The trained models are then used to generate the
full hadronization chains, with an IR cutoff energy imposed externally. The
hadron multiplicities and cumulative kinematic distributions are shown to match
the Pythia generated ones. We also discuss possible future generalizations of
our results.",2022-03-09T19:00:02Z,http://arxiv.org/pdf/2203.04983v1,['hep-ph']
1807.07987v2,Deep Learning,"['Nicholas G. Polson', 'Vadim O. Sokolov']","Deep learning (DL) is a high dimensional data reduction technique for
constructing high-dimensional predictors in input-output models. DL is a form
of machine learning that uses hierarchical layers of latent features. In this
article, we review the state-of-the-art of deep learning from a modeling and
algorithmic perspective. We provide a list of successful areas of applications
in Artificial Intelligence (AI), Image Processing, Robotics and Automation.
Deep learning is predictive in its nature rather then inferential and can be
viewed as a black-box methodology for high-dimensional function estimation.",2018-07-20T18:20:34Z,http://arxiv.org/pdf/1807.07987v2,"['stat.ML', 'cs.LG']"
1806.01756v1,Concept-Oriented Deep Learning,['Daniel T Chang'],"Concepts are the foundation of human deep learning, understanding, and
knowledge integration and transfer. We propose concept-oriented deep learning
(CODL) which extends (machine) deep learning with concept representations and
conceptual understanding capability. CODL addresses some of the major
limitations of deep learning: interpretability, transferability, contextual
adaptation, and requirement for lots of labeled training data. We discuss the
major aspects of CODL including concept graph, concept representations, concept
exemplars, and concept representation learning systems supporting incremental
and continual learning.",2018-06-05T15:50:30Z,http://arxiv.org/pdf/1806.01756v1,['cs.AI']
1808.08618v2,Deep Learning: Computational Aspects,"['Nicholas Polson', 'Vadim Sokolov']","In this article we review computational aspects of Deep Learning (DL). Deep
learning uses network architectures consisting of hierarchical layers of latent
variables to construct predictors for high-dimensional input-output models.
Training a deep learning architecture is computationally intensive, and
efficient linear algebra libraries is the key for training and inference.
Stochastic gradient descent (SGD) optimization and batch sampling are used to
learn from massive data sets.",2018-08-26T20:26:11Z,http://arxiv.org/pdf/1808.08618v2,"['cs.LG', 'stat.CO', 'stat.ML']"
1710.05468v9,Generalization in Deep Learning,"['Kenji Kawaguchi', 'Leslie Pack Kaelbling', 'Yoshua Bengio']","This paper provides theoretical insights into why and how deep learning can
generalize well, despite its large capacity, complexity, possible algorithmic
instability, nonrobustness, and sharp minima, responding to an open question in
the literature. We also discuss approaches to provide non-vacuous
generalization guarantees for deep learning. Based on theoretical observations,
we propose new open problems and discuss the limitations of our results.",2017-10-16T02:21:24Z,http://arxiv.org/pdf/1710.05468v9,"['stat.ML', 'cs.AI', 'cs.LG', 'cs.NE']"
2006.03364v1,Structure preserving deep learning,"['Elena Celledoni', 'Matthias J. Ehrhardt', 'Christian Etmann', 'Robert I McLachlan', 'Brynjulf Owren', 'Carola-Bibiane Schönlieb', 'Ferdia Sherry']","Over the past few years, deep learning has risen to the foreground as a topic
of massive interest, mainly as a result of successes obtained in solving
large-scale image processing tasks. There are multiple challenging mathematical
problems involved in applying deep learning: most deep learning methods require
the solution of hard optimisation problems, and a good understanding of the
tradeoff between computational effort, amount of data and model complexity is
required to successfully design a deep learning approach for a given problem. A
large amount of progress made in deep learning has been based on heuristic
explorations, but there is a growing effort to mathematically understand the
structure in existing deep learning methods and to systematically design new
deep learning methods to preserve certain types of structure in deep learning.
In this article, we review a number of these directions: some deep neural
networks can be understood as discretisations of dynamical systems, neural
networks can be designed to have desirable properties such as invertibility or
group equivariance, and new algorithmic frameworks based on conformal
Hamiltonian systems and Riemannian manifolds to solve the optimisation problems
have been proposed. We conclude our review of each of these topics by
discussing some open problems that we consider to be interesting directions for
future research.",2020-06-05T10:59:09Z,http://arxiv.org/pdf/2006.03364v1,"['cs.LG', 'cs.NA', 'math.NA', 'stat.ML']"
1804.01653v2,Review of Deep Learning,"['Rong Zhang', 'Weiping Li', 'Tong Mo']","In recent years, China, the United States and other countries, Google and
other high-tech companies have increased investment in artificial intelligence.
Deep learning is one of the current artificial intelligence research's key
areas. This paper analyzes and summarizes the latest progress and future
research directions of deep learning. Firstly, three basic models of deep
learning are outlined, including multilayer perceptrons, convolutional neural
networks, and recurrent neural networks. On this basis, we further analyze the
emerging new models of convolution neural networks and recurrent neural
networks. This paper then summarizes deep learning's applications in many areas
of artificial intelligence, including speech processing, computer vision,
natural language processing and so on. Finally, this paper discusses the
existing problems of deep learning and gives the corresponding possible
solutions.",2018-04-05T02:23:59Z,http://arxiv.org/pdf/1804.01653v2,"['cs.LG', 'cs.CV', 'cs.NE', 'stat.ML']"
2006.10027v2,Deep Learning Meets SAR,"['Xiao Xiang Zhu', 'Sina Montazeri', 'Mohsin Ali', 'Yuansheng Hua', 'Yuanyuan Wang', 'Lichao Mou', 'Yilei Shi', 'Feng Xu', 'Richard Bamler']","Deep learning in remote sensing has become an international hype, but it is
mostly limited to the evaluation of optical data. Although deep learning has
been introduced in Synthetic Aperture Radar (SAR) data processing, despite
successful first attempts, its huge potential remains locked. In this paper, we
provide an introduction to the most relevant deep learning models and concepts,
point out possible pitfalls by analyzing special characteristics of SAR data,
review the state-of-the-art of deep learning applied to SAR in depth, summarize
available benchmarks, and recommend some important future research directions.
With this effort, we hope to stimulate more research in this interesting yet
under-exploited research field and to pave the way for use of deep learning in
big SAR data processing workflows.",2020-06-17T17:46:36Z,http://arxiv.org/pdf/2006.10027v2,"['eess.IV', 'cs.LG', 'stat.ML']"
1808.09772v2,Notes on Deep Learning for NLP,['Antoine J. -P. Tixier'],My notes on Deep Learning for NLP.,2018-08-29T12:58:45Z,http://arxiv.org/pdf/1808.09772v2,['cs.CL']
1602.06561v3,Deep Learning in Finance,"['J. B. Heaton', 'N. G. Polson', 'J. H. Witte']","We explore the use of deep learning hierarchical models for problems in
financial prediction and classification. Financial prediction problems -- such
as those presented in designing and pricing securities, constructing
portfolios, and risk management -- often involve large data sets with complex
data interactions that currently are difficult or impossible to specify in a
full economic model. Applying deep learning methods to these problems can
produce more useful results than standard methods in finance. In particular,
deep learning can detect and exploit interactions in the data that are, at
least currently, invisible to any existing financial economic theory.",2016-02-21T18:19:56Z,http://arxiv.org/pdf/1602.06561v3,['cs.LG']
1902.11122v5,Deep Learning in Cardiology,"['Paschalis Bizopoulos', 'Dimitrios Koutsouris']","The medical field is creating large amount of data that physicians are unable
to decipher and use efficiently. Moreover, rule-based expert systems are
inefficient in solving complicated medical tasks or for creating insights using
big data. Deep learning has emerged as a more accurate and effective technology
in a wide range of medical problems such as diagnosis, prediction and
intervention. Deep learning is a representation learning method that consists
of layers that transform the data non-linearly, thus, revealing hierarchical
relationships and structures. In this review we survey deep learning
application papers that use structured data, signal and imaging modalities from
cardiology. We discuss the advantages and limitations of applying deep learning
in cardiology that also apply in medicine in general, while proposing certain
directions as the most viable for clinical use.",2019-02-22T10:09:11Z,http://arxiv.org/pdf/1902.11122v5,"['cs.CV', 'cs.AI', 'cs.LG']"
1908.06315v4,Implicit Deep Learning,"['Laurent El Ghaoui', 'Fangda Gu', 'Bertrand Travacca', 'Armin Askari', 'Alicia Y. Tsai']","Implicit deep learning prediction rules generalize the recursive rules of
feedforward neural networks. Such rules are based on the solution of a
fixed-point equation involving a single vector of hidden features, which is
thus only implicitly defined. The implicit framework greatly simplifies the
notation of deep learning, and opens up many new possibilities, in terms of
novel architectures and algorithms, robustness analysis and design,
interpretability, sparsity, and network architecture optimization.",2019-08-17T15:36:37Z,http://arxiv.org/pdf/1908.06315v4,"['cs.LG', 'math.OC', 'stat.ML']"
1603.06430v5,Deep Learning in Bioinformatics,"['Seonwoo Min', 'Byunghan Lee', 'Sungroh Yoon']","In the era of big data, transformation of biomedical big data into valuable
knowledge has been one of the most important challenges in bioinformatics. Deep
learning has advanced rapidly since the early 2000s and now demonstrates
state-of-the-art performance in various fields. Accordingly, application of
deep learning in bioinformatics to gain insight from data has been emphasized
in both academia and industry. Here, we review deep learning in bioinformatics,
presenting examples of current research. To provide a useful and comprehensive
perspective, we categorize research both by the bioinformatics domain (i.e.,
omics, biomedical imaging, biomedical signal processing) and deep learning
architecture (i.e., deep neural networks, convolutional neural networks,
recurrent neural networks, emergent architectures) and present brief
descriptions of each study. Additionally, we discuss theoretical and practical
issues of deep learning in bioinformatics and suggest future research
directions. We believe that this review will provide valuable insights and
serve as a starting point for researchers to apply deep learning approaches in
their bioinformatics studies.",2016-03-21T13:55:02Z,http://arxiv.org/pdf/1603.06430v5,"['cs.LG', 'q-bio.GN']"
1805.04825v1,Deep Learning in Software Engineering,"['Xiaochen Li', 'He Jiang', 'Zhilei Ren', 'Ge Li', 'Jingxuan Zhang']","Recent years, deep learning is increasingly prevalent in the field of
Software Engineering (SE). However, many open issues still remain to be
investigated. How do researchers integrate deep learning into SE problems?
Which SE phases are facilitated by deep learning? Do practitioners benefit from
deep learning? The answers help practitioners and researchers develop practical
deep learning models for SE tasks. To answer these questions, we conduct a
bibliography analysis on 98 research papers in SE that use deep learning
techniques. We find that 41 SE tasks in all SE phases have been facilitated by
deep learning integrated solutions. In which, 84.7% papers only use standard
deep learning models and their variants to solve SE problems. The
practicability becomes a concern in utilizing deep learning techniques. How to
improve the effectiveness, efficiency, understandability, and testability of
deep learning based solutions may attract more SE researchers in the future.",2018-05-13T06:01:39Z,http://arxiv.org/pdf/1805.04825v1,['cs.SE']
2306.04469v1,Model-Based Deep Learning,"['Nir Shlezinger', 'Yonina C. Eldar']","Signal processing traditionally relies on classical statistical modeling
techniques. Such model-based methods utilize mathematical formulations that
represent the underlying physics, prior information and additional domain
knowledge. Simple classical models are useful but sensitive to inaccuracies and
may lead to poor performance when real systems display complex or dynamic
behavior. More recently, deep learning approaches that use deep neural networks
are becoming increasingly popular. Deep learning systems do not rely on
mathematical modeling, and learn their mapping from data, which allows them to
operate in complex environments. However, they lack the interpretability and
reliability of model-based methods, typically require large training sets to
obtain good performance, and tend to be computationally complex. Model-based
signal processing methods and data-centric deep learning each have their pros
and cons. These paradigms can be characterized as edges of a continuous
spectrum varying in specificity and parameterization. The methodologies that
lie in the middle ground of this spectrum, thus integrating model-based signal
processing with deep learning, are referred to as model-based deep learning,
and are the focus here. This monograph provides a tutorial style presentation
of model-based deep learning methodologies. These are families of algorithms
that combine principled mathematical models with data-driven systems to benefit
from the advantages of both approaches. Such model-based deep learning methods
exploit both partial domain knowledge, via mathematical structures designed for
specific problems, as well as learning from limited data. We accompany our
presentation with running examples, in super-resolution, dynamic systems, and
array processing. We show how they are expressed using the provided
characterization and specialized in each of the detailed methodologies.",2023-06-05T03:17:07Z,http://arxiv.org/pdf/2306.04469v1,['eess.SP']
1709.05871v1,IBM Deep Learning Service,"['Bishwaranjan Bhattacharjee', 'Scott Boag', 'Chandani Doshi', 'Parijat Dube', 'Ben Herta', 'Vatche Ishakian', 'K. R. Jayaram', 'Rania Khalaf', 'Avesh Krishna', 'Yu Bo Li', 'Vinod Muthusamy', 'Ruchir Puri', 'Yufei Ren', 'Florian Rosenberg', 'Seetharami R. Seelam', 'Yandong Wang', 'Jian Ming Zhang', 'Li Zhang']","Deep learning driven by large neural network models is overtaking traditional
machine learning methods for understanding unstructured and perceptual data
domains such as speech, text, and vision. At the same time, the
""as-a-Service""-based business model on the cloud is fundamentally transforming
the information technology industry. These two trends: deep learning, and
""as-a-service"" are colliding to give rise to a new business model for cognitive
application delivery: deep learning as a service in the cloud. In this paper,
we will discuss the details of the software architecture behind IBM's deep
learning as a service (DLaaS). DLaaS provides developers the flexibility to use
popular deep learning libraries such as Caffe, Torch and TensorFlow, in the
cloud in a scalable and resilient manner with minimal effort. The platform uses
a distribution and orchestration layer that facilitates learning from a large
amount of data in a reasonable amount of time across compute nodes. A resource
provisioning layer enables flexible job management on heterogeneous resources,
such as graphics processing units (GPUs) and central processing units (CPUs),
in an infrastructure as a service (IaaS) cloud.",2017-09-18T11:40:48Z,http://arxiv.org/pdf/1709.05871v1,['cs.DC']
2212.00911v1,Navigating causal deep learning,"['Jeroen Berrevoets', 'Krzysztof Kacprzyk', 'Zhaozhi Qian', 'Mihaela van der Schaar']","Causal deep learning (CDL) is a new and important research area in the larger
field of machine learning. With CDL, researchers aim to structure and encode
causal knowledge in the extremely flexible representation space of deep
learning models. Doing so will lead to more informed, robust, and general
predictions and inference -- which is important! However, CDL is still in its
infancy. For example, it is not clear how we ought to compare different methods
as they are so different in their output, the way they encode causal knowledge,
or even how they represent this knowledge. This is a living paper that
categorises methods in causal deep learning beyond Pearl's ladder of causation.
We refine the rungs in Pearl's ladder, while also adding a separate dimension
that categorises the parametric assumptions of both input and representation,
arriving at the map of causal deep learning. Our map covers machine learning
disciplines such as supervised learning, reinforcement learning, generative
modelling and beyond. Our paradigm is a tool which helps researchers to: find
benchmarks, compare methods, and most importantly: identify research gaps. With
this work we aim to structure the avalanche of papers being published on causal
deep learning. While papers on the topic are being published daily, our map
remains fixed. We open-source our map for others to use as they see fit:
perhaps to offer guidance in a related works section, or to better highlight
the contribution of their paper.",2022-12-01T23:44:23Z,http://arxiv.org/pdf/2212.00911v1,['cs.LG']
2104.05569v1,Deep Learning for IoT,['Tao Lin'],"Deep learning and other machine learning approaches are deployed to many
systems related to Internet of Things or IoT. However, it faces challenges that
adversaries can take loopholes to hack these systems through tampering history
data. This paper first presents overall points of adversarial machine learning.
Then, we illustrate traditional methods, such as Petri Net cannot solve this
new question efficiently. To help IoT data analysis more efficient, we propose
a retrieval method based on deep learning (recurrent neural network). Besides,
this paper presents a research on data retrieval solution to avoid hacking by
adversaries in the fields of adversary machine leaning. It further directs the
new approaches in terms of how to implementing this framework in IoT settings
based on adversarial deep learning.",2021-04-12T15:39:30Z,http://arxiv.org/pdf/2104.05569v1,"['cs.LG', 'cs.NI']"
2504.08489v1,Statistically guided deep learning,"['Michael Kohler', 'Adam Krzyzak']","We present a theoretically well-founded deep learning algorithm for
nonparametric regression. It uses over-parametrized deep neural networks with
logistic activation function, which are fitted to the given data via gradient
descent. We propose a special topology of these networks, a special random
initialization of the weights, and a data-dependent choice of the learning rate
and the number of gradient descent steps. We prove a theoretical bound on the
expected $L_2$ error of this estimate, and illustrate its finite sample size
performance by applying it to simulated data. Our results show that a
theoretical analysis of deep learning which takes into account simultaneously
optimization, generalization and approximation can result in a new deep
learning estimate which has an improved finite sample performance.",2025-04-11T12:36:06Z,http://arxiv.org/pdf/2504.08489v1,"['math.ST', 'cs.LG', 'stat.ML', 'stat.TH']"
1412.3489v2,Quantum Deep Learning,"['Nathan Wiebe', 'Ashish Kapoor', 'Krysta M. Svore']","In recent years, deep learning has had a profound impact on machine learning
and artificial intelligence. At the same time, algorithms for quantum computers
have been shown to efficiently solve some problems that are intractable on
conventional, classical computers. We show that quantum computing not only
reduces the time required to train a deep restricted Boltzmann machine, but
also provides a richer and more comprehensive framework for deep learning than
classical computing and leads to significant improvements in the optimization
of the underlying objective function. Our quantum methods also permit efficient
training of full Boltzmann machines and multi-layer, fully connected models and
do not have well known classical counterparts.",2014-12-10T23:05:16Z,http://arxiv.org/pdf/1412.3489v2,"['quant-ph', 'cs.LG', 'cs.NE']"
2302.12027v1,Forecasting with Deep Learning,['Gissel Velarde'],"This paper presents a method for time series forecasting with deep learning
and its assessment on two datasets. The method starts with data preparation,
followed by model training and evaluation. The final step is a visual
inspection. Experimental work demonstrates that a single time series can be
used to train deep learning networks if time series in a dataset contain
patterns that repeat even with a certain variation. However, for less
structured time series such as stock market closing prices, the networks
perform just like a baseline that repeats the last observed value. The
implementation of the method as well as the experiments are open-source.",2023-02-17T10:09:22Z,http://arxiv.org/pdf/2302.12027v1,"['cs.LG', 'cs.AI']"
2310.06251v1,Deep Learning: A Tutorial,"['Nick Polson', 'Vadim Sokolov']","Our goal is to provide a review of deep learning methods which provide
insight into structured high-dimensional data. Rather than using shallow
additive architectures common to most statistical models, deep learning uses
layers of semi-affine input transformations to provide a predictive rule.
Applying these layers of transformations leads to a set of attributes (or,
features) to which probabilistic statistical methods can be applied. Thus, the
best of both worlds can be achieved: scalable prediction rules fortified with
uncertainty quantification, where sparse regularization finds the features.",2023-10-10T01:55:22Z,http://arxiv.org/pdf/2310.06251v1,"['stat.ML', 'cs.LG']"
1810.11614v2,Deep learning for denoising,"['Siwei Yu', 'Jianwei Ma', 'Wenlong Wang']","Compared with traditional seismic noise attenuation algorithms that depend on
signal models and their corresponding prior assumptions, removing noise with a
deep neural network is trained based on a large training set, where the inputs
are the raw datasets and the corresponding outputs are the desired clean data.
After the completion of training, the deep learning method achieves adaptive
denoising with no requirements of (i) accurate modelings of the signal and
noise, or (ii) optimal parameters tuning. We call this intelligent denoising.
We use a convolutional neural network as the basic tool for deep learning. In
random and linear noise attenuation, the training set is generated with
artificially added noise. In the multiple attenuation step, the training set is
generated with acoustic wave equation. Stochastic gradient descent is used to
solve the optimal parameters for the convolutional neural network. The runtime
of deep learning on a graphics processing unit for denoising has the same order
as the $f-x$ deconvolution method. Synthetic and field results show the
potential applications of deep learning in automatic attenuation of random
noise (with unknown variance), linear noise, and multiples.",2018-10-27T07:39:09Z,http://arxiv.org/pdf/1810.11614v2,"['physics.geo-ph', 'cs.LG', 'eess.SP', '86A15']"
2003.03253v1,Introduction to deep learning,"['Lihi Shiloh-Perl', 'Raja Giryes']","Deep Learning (DL) has made a major impact on data science in the last
decade. This chapter introduces the basic concepts of this field. It includes
both the basic structures used to design deep neural networks and a brief
survey of some of its popular use cases.",2020-02-29T14:52:28Z,http://arxiv.org/pdf/2003.03253v1,['cs.LG']
2211.16350v4,"On ""Deep Learning"" Misconduct",['Juyang Weng'],"This is a theoretical paper, as a companion paper of the plenary talk for the
same conference ISAIC 2022. In contrast to the author's plenary talk in the
same conference, conscious learning (Weng, 2022b; Weng, 2022c) which develops a
single network for a life (many tasks), ""Deep Learning"" trains multiple
networks for each task. Although ""Deep Learning"" may use different learning
modes, including supervised, reinforcement and adversarial modes, almost all
""Deep Learning"" projects apparently suffer from the same misconduct, called
""data deletion"" and ""test on training data"". This paper establishes a theorem
that a simple method called Pure-Guess Nearest Neighbor (PGNN) reaches any
required errors on validation data set and test data set, including zero-error
requirements, through the same misconduct, as long as the test data set is in
the possession of the authors and both the amount of storage space and the time
of training are finite but unbounded. The misconduct violates well-known
protocols called transparency and cross-validation. The nature of the
misconduct is fatal, because in the absence of any disjoint test, ""Deep
Learning"" is clearly not generalizable.",2022-11-23T17:04:42Z,http://arxiv.org/pdf/2211.16350v4,"['cs.LG', 'I.3']"
2303.02186v2,Causal Deep Learning,"['Jeroen Berrevoets', 'Krzysztof Kacprzyk', 'Zhaozhi Qian', 'Mihaela van der Schaar']","Causality has the potential to truly transform the way we solve a large
number of real-world problems. Yet, so far, its potential largely remains to be
unlocked as causality often requires crucial assumptions which cannot be tested
in practice. To address this challenge, we propose a new way of thinking about
causality -- we call this causal deep learning. Our causal deep learning
framework spans three dimensions: (1) a structural dimension, which
incorporates partial yet testable causal knowledge rather than assuming either
complete or no causal knowledge among the variables of interest; (2) a
parametric dimension, which encompasses parametric forms that capture the type
of relationships among the variables of interest; and (3) a temporal dimension,
which captures exposure times or how the variables of interest interact
(possibly causally) over time. Causal deep learning enables us to make progress
on a variety of real-world problems by leveraging partial causal knowledge
(including independencies among variables) and quantitatively characterising
causal relationships among variables of interest (possibly over time). Our
framework clearly identifies which assumptions are testable and which ones are
not, such that the resulting solutions can be judiciously adopted in practice.
Using our formulation we can combine or chain together causal representations
to solve specific problems without losing track of which assumptions are
required to build these solutions, pushing real-world impact in healthcare,
economics and business, environmental sciences and education, through causal
deep learning.",2023-03-03T19:19:18Z,http://arxiv.org/pdf/2303.02186v2,"['cs.LG', 'cs.AI']"
2201.13380v1,Deep Learning Macroeconomics,['Rafael R. S. Guimaraes'],"Limited datasets and complex nonlinear relationships are among the challenges
that may emerge when applying econometrics to macroeconomic problems. This
research proposes deep learning as an approach to transfer learning in the
former case and to map relationships between variables in the latter case.
Although macroeconomists already apply transfer learning when assuming a given
a priori distribution in a Bayesian context, estimating a structural VAR with
signal restriction and calibrating parameters based on results observed in
other models, to name a few examples, advance in a more systematic transfer
learning strategy in applied macroeconomics is the innovation we are
introducing. We explore the proposed strategy empirically, showing that data
from different but related domains, a type of transfer learning, helps identify
the business cycle phases when there is no business cycle dating committee and
to quick estimate a economic-based output gap. Next, since deep learning
methods are a way of learning representations, those that are formed by the
composition of multiple non-linear transformations, to yield more abstract
representations, we apply deep learning for mapping low-frequency from
high-frequency variables. The results obtained show the suitability of deep
learning models applied to macroeconomic problems. First, models learned to
classify United States business cycles correctly. Then, applying transfer
learning, they were able to identify the business cycles of out-of-sample
Brazilian and European data. Along the same lines, the models learned to
estimate the output gap based on the U.S. data and obtained good performance
when faced with Brazilian data. Additionally, deep learning proved adequate for
mapping low-frequency variables from high-frequency data to interpolate,
distribute, and extrapolate time series by related series.",2022-01-31T17:43:43Z,http://arxiv.org/pdf/2201.13380v1,"['econ.EM', 'cs.LG']"
1705.05750v2,Holography as deep learning,"['Wen-Cong Gan', 'Fu-Wen Shu']","Quantum many-body problem with exponentially large degrees of freedom can be
reduced to a tractable computational form by neural network method \cite{CT}.
The power of deep neural network (DNN) based on deep learning is clarified by
mapping it to renormalization group (RG), which may shed lights on holographic
principle by identifying a sequence of RG transformations to the AdS geometry.
In this essay, we show that any network which reflects RG process has intrinsic
hyperbolic geometry, and discuss the structure of entanglement encoded in the
graph of DNN. We find the entanglement structure of deep neural network is of
Ryu-Takayanagi form. Based on these facts, we argue that the emergence of
holographic gravitational theory is related to deep learning process of the
quantum field theory.",2017-05-16T14:57:22Z,http://arxiv.org/pdf/1705.05750v2,"['gr-qc', 'hep-th', 'quant-ph']"
1803.06111v1,Vulnerability of Deep Learning,['Richard Kenway'],"The Renormalisation Group (RG) provides a framework in which it is possible
to assess whether a deep-learning network is sensitive to small changes in the
input data and hence prone to error, or susceptible to adversarial attack.
Distinct classification outputs are associated with different RG fixed points
and sensitivity to small changes in the input data is due to the presence of
relevant operators at a fixed point. A numerical scheme, based on Monte Carlo
RG ideas, is proposed for identifying the existence of relevant operators and
the corresponding directions of greatest sensitivity in the input data. Thus, a
trained deep-learning network may be tested for its robustness and, if it is
vulnerable to attack, dangerous perturbations of the input data identified.",2018-03-16T08:52:04Z,http://arxiv.org/pdf/1803.06111v1,"['stat.ML', 'cond-mat.dis-nn', 'cond-mat.stat-mech', 'cs.AI', 'cs.LG']"
2006.08256v5,Markov-Lipschitz Deep Learning,"['Stan Z. Li', 'Zelin Zang', 'Lirong Wu']","We propose a novel framework, called Markov-Lipschitz deep learning (MLDL),
to tackle geometric deterioration caused by collapse, twisting, or crossing in
vector-based neural network transformations for manifold-based representation
learning and manifold data generation. A prior constraint, called locally
isometric smoothness (LIS), is imposed across-layers and encoded into a Markov
random field (MRF)-Gibbs distribution. This leads to the best possible
solutions for local geometry preservation and robustness as measured by locally
geometric distortion and locally bi-Lipschitz continuity. Consequently, the
layer-wise vector transformations are enhanced into well-behaved,
LIS-constrained metric homeomorphisms. Extensive experiments, comparisons, and
ablation study demonstrate significant advantages of MLDL for manifold learning
and manifold data generation. MLDL is general enough to enhance any vector
transformation-based networks. The code is available at
https://github.com/westlake-cairi/Markov-Lipschitz-Deep-Learning.",2020-06-15T09:46:42Z,http://arxiv.org/pdf/2006.08256v5,"['cs.LG', 'stat.ML']"
2110.15829v5,Holistic Deep Learning,"['Dimitris Bertsimas', 'Kimberly Villalobos Carballo', 'Léonard Boussioux', 'Michael Lingzhi Li', 'Alex Paskov', 'Ivan Paskov']","This paper presents a novel holistic deep learning framework that
simultaneously addresses the challenges of vulnerability to input
perturbations, overparametrization, and performance instability from different
train-validation splits. The proposed framework holistically improves accuracy,
robustness, sparsity, and stability over standard deep learning models, as
demonstrated by extensive experiments on both tabular and image data sets. The
results are further validated by ablation experiments and SHAP value analysis,
which reveal the interactions and trade-offs between the different evaluation
metrics. To support practitioners applying our framework, we provide a
prescriptive approach that offers recommendations for selecting an appropriate
training loss function based on their specific objectives. All the code to
reproduce the results can be found at https://github.com/kimvc7/HDL.",2021-10-29T14:46:32Z,http://arxiv.org/pdf/2110.15829v5,"['cs.LG', 'cs.AI']"
2211.09639v2,Why Deep Learning Generalizes,['Benjamin L. Badger'],"Very large deep learning models trained using gradient descent are remarkably
resistant to memorization given their huge capacity, but are at the same time
capable of fitting large datasets of pure noise. Here methods are introduced by
which models may be trained to memorize datasets that normally are generalized.
We find that memorization is difficult relative to generalization, but that
adding noise makes memorization easier. Increasing the dataset size exaggerates
the characteristics of that dataset: model access to more training samples
makes overfitting easier for random data, but somewhat harder for natural
images. The bias of deep learning towards generalization is explored
theoretically, and we show that generalization results from a model's
parameters being attracted to points of maximal stability with respect to that
model's inputs during gradient descent.",2022-11-17T16:39:43Z,http://arxiv.org/pdf/2211.09639v2,['cs.LG']
2403.03385v1,Multi-modal Deep Learning,['Chen Yuhua'],"This article investigates deep learning methodologies for single-modality
clinical data analysis, as a crucial precursor to multi-modal medical research.
Building on Guo JingYuan's work, the study refines clinical data processing
through Compact Convolutional Transformer (CCT), Patch Up, and the innovative
CamCenterLoss technique, establishing a foundation for future multimodal
investigations. The proposed methodology demonstrates improved prediction
accuracy and at tentiveness to critically ill patients compared to Guo
JingYuan's ResNet and StageNet approaches. Novelty that using image-pretrained
vision transformer backbone to perform transfer learning time-series clinical
data.The study highlights the potential of CCT, Patch Up, and novel
CamCenterLoss in processing single modality clinical data within deep learning
frameworks, paving the way for future multimodal medical research and promoting
precision and personalized healthcare",2024-03-06T00:36:05Z,http://arxiv.org/pdf/2403.03385v1,"['eess.IV', 'cs.AI', 'cs.CV']"
2407.15339v3,Deep Learning for Economists,['Melissa Dell'],"Deep learning provides powerful methods to impute structured information from
large-scale, unstructured text and image datasets. For example, economists
might wish to detect the presence of economic activity in satellite images, or
to measure the topics or entities mentioned in social media, the congressional
record, or firm filings. This review introduces deep neural networks, covering
methods such as classifiers, regression models, generative AI, and embedding
models. Applications include classification, document digitization, record
linkage, and methods for data exploration in massive scale text and image
corpora. When suitable methods are used, deep learning models can be cheap to
tune and can scale affordably to problems involving millions or billions of
data points.. The review is accompanied by a companion website, EconDL, with
user-friendly demo notebooks, software resources, and a knowledge base that
provides technical details and additional applications.",2024-07-22T02:53:18Z,http://arxiv.org/pdf/2407.15339v3,"['econ.GN', 'cs.CL', 'cs.CV', 'q-fin.EC']"
2012.08405v3,Model-Based Deep Learning,"['Nir Shlezinger', 'Jay Whang', 'Yonina C. Eldar', 'Alexandros G. Dimakis']","Signal processing, communications, and control have traditionally relied on
classical statistical modeling techniques. Such model-based methods utilize
mathematical formulations that represent the underlying physics, prior
information and additional domain knowledge. Simple classical models are useful
but sensitive to inaccuracies and may lead to poor performance when real
systems display complex or dynamic behavior. On the other hand, purely
data-driven approaches that are model-agnostic are becoming increasingly
popular as datasets become abundant and the power of modern deep learning
pipelines increases. Deep neural networks (DNNs) use generic architectures
which learn to operate from data, and demonstrate excellent performance,
especially for supervised problems. However, DNNs typically require massive
amounts of data and immense computational resources, limiting their
applicability for some signal processing scenarios. We are interested in hybrid
techniques that combine principled mathematical models with data-driven systems
to benefit from the advantages of both approaches. Such model-based deep
learning methods exploit both partial domain knowledge, via mathematical
structures designed for specific problems, as well as learning from limited
data. In this article we survey the leading approaches for studying and
designing model-based deep learning systems. We divide hybrid
model-based/data-driven systems into categories based on their inference
mechanism. We provide a comprehensive review of the leading approaches for
combining model-based algorithms with deep learning in a systematic manner,
along with concrete guidelines and detailed signal processing oriented examples
from recent literature. Our aim is to facilitate the design and study of future
systems on the intersection of signal processing and machine learning that
incorporate the advantages of both domains.",2020-12-15T16:29:49Z,http://arxiv.org/pdf/2012.08405v3,"['eess.SP', 'cs.LG']"
2304.08457v2,Deep Learning Criminal Networks,"['Haroldo V. Ribeiro', 'Diego D. Lopes', 'Arthur A. B. Pessa', 'Alvaro F. Martins', 'Bruno R. da Cunha', 'Sebastian Goncalves', 'Ervin K. Lenzi', 'Quentin S. Hanley', 'Matjaz Perc']","Recent advances in deep learning methods have enabled researchers to develop
and apply algorithms for the analysis and modeling of complex networks. These
advances have sparked a surge of interest at the interface between network
science and machine learning. Despite this, the use of machine learning methods
to investigate criminal networks remains surprisingly scarce. Here, we explore
the potential of graph convolutional networks to learn patterns among networked
criminals and to predict various properties of criminal networks. Using
empirical data from political corruption, criminal police intelligence, and
criminal financial networks, we develop a series of deep learning models based
on the GraphSAGE framework that are able to recover missing criminal
partnerships, distinguish among types of associations, predict the amount of
money exchanged among criminal agents, and even anticipate partnerships and
recidivism of criminals during the growth dynamics of corruption networks, all
with impressive accuracy. Our deep learning models significantly outperform
previous shallow learning approaches and produce high-quality embeddings for
node and edge properties. Moreover, these models inherit all the advantages of
the GraphSAGE framework, including the generalization to unseen nodes and
scaling up to large graph structures.",2023-04-17T17:33:30Z,http://arxiv.org/pdf/2304.08457v2,"['physics.soc-ph', 'cs.SI', 'physics.data-an']"
2307.10991v2,Dense Sample Deep Learning,"['Stephen Josè Hanson', 'Vivek Yadav', 'Catherine Hanson']","Deep Learning (DL) , a variant of the neural network algorithms originally
proposed in the 1980s, has made surprising progress in Artificial Intelligence
(AI), ranging from language translation, protein folding, autonomous cars, and
more recently human-like language models (CHATbots), all that seemed
intractable until very recently. Despite the growing use of Deep Learning (DL)
networks, little is actually understood about the learning mechanisms and
representations that makes these networks effective across such a diverse range
of applications. Part of the answer must be the huge scale of the architecture
and of course the large scale of the data, since not much has changed since
1987. But the nature of deep learned representations remain largely unknown.
Unfortunately training sets with millions or billions of tokens have unknown
combinatorics and Networks with millions or billions of hidden units cannot
easily be visualized and their mechanisms cannot be easily revealed. In this
paper, we explore these questions with a large (1.24M weights; VGG) DL in a
novel high density sample task (5 unique tokens with at minimum 500 exemplars
per token) which allows us to more carefully follow the emergence of category
structure and feature construction. We use various visualization methods for
following the emergence of the classification and the development of the
coupling of feature detectors and structures that provide a type of graphical
bootstrapping, From these results we harvest some basic observations of the
learning dynamics of DL and propose a new theory of complex feature
construction based on our results.",2023-07-20T16:21:14Z,http://arxiv.org/pdf/2307.10991v2,"['cs.AI', 'q-bio.NC', 'stat.ML']"
1803.08993v1,Deep Learning Phase Segregation,"['Amir Barati Farimani', 'Joseph Gomes', 'Rishi Sharma', 'Franklin L. Lee', 'Vijay S. Pande']","Phase segregation, the process by which the components of a binary mixture
spontaneously separate, is a key process in the evolution and design of many
chemical, mechanical, and biological systems. In this work, we present a
data-driven approach for the learning, modeling, and prediction of phase
segregation. A direct mapping between an initially dispersed, immiscible binary
fluid and the equilibrium concentration field is learned by conditional
generative convolutional neural networks. Concentration field predictions by
the deep learning model conserve phase fraction, correctly predict phase
transition, and reproduce area, perimeter, and total free energy distributions
up to 98% accuracy.",2018-03-23T21:59:01Z,http://arxiv.org/pdf/1803.08993v1,"['cs.LG', 'physics.comp-ph', 'stat.ML']"
1909.02803v3,Personalization of Deep Learning,"['Johannes Schneider', 'Michail Vlachos']","We discuss training techniques, objectives and metrics toward personalization
of deep learning models. In machine learning, personalization addresses the
goal of a trained model to target a particular individual by optimizing one or
more performance metrics, while conforming to certain constraints. To
personalize, we investigate three methods of ``curriculum learning`` and two
approaches for data grouping, i.e., augmenting the data of an individual by
adding similar data identified with an auto-encoder. We show that both
``curriculuum learning'' and ``personalized'' data augmentation lead to
improved performance on data of an individual. Mostly, this comes at the cost
of reduced performance on a more general, broader dataset.",2019-09-06T10:17:25Z,http://arxiv.org/pdf/1909.02803v3,"['cs.LG', 'stat.ML']"
2305.15239v2,Deep Learning and Ethics,"['Travis LaCroix', 'Simon J. D. Prince']","This article appears as chapter 21 of Prince (2023, Understanding Deep
Learning); a complete draft of the textbook is available here:
http://udlbook.com. This chapter considers potential harms arising from the
design and use of AI systems. These include algorithmic bias, lack of
explainability, data privacy violations, militarization, fraud, and
environmental concerns. The aim is not to provide advice on being more ethical.
Instead, the goal is to express ideas and start conversations in key areas that
have received attention in philosophy, political science, and the broader
social sciences.",2023-05-24T15:24:19Z,http://arxiv.org/pdf/2305.15239v2,"['cs.AI', 'cs.CY', 'cs.LG']"
2109.05237v4,Physics-based Deep Learning,"['N. Thuerey', 'B. Holzschuh', 'P. Holl', 'G. Kohl', 'M. Lino', 'Q. Liu', 'P. Schnell', 'F. Trost']","This document is a hands-on, comprehensive guide to deep learning in the
realm of physical simulations. Rather than just theory, we emphasize practical
application: every concept is paired with interactive Jupyter notebooks to get
you up and running quickly. Beyond traditional supervised learning, we dive
into physical loss-constraints, differentiable simulations, diffusion-based
approaches for probabilistic generative AI, as well as reinforcement learning
and advanced neural network architectures. These foundations are paving the way
for the next generation of scientific foundation models. We are living in an
era of rapid transformation. These methods have the potential to redefine
what's possible in computational science.",2021-09-11T09:38:02Z,http://arxiv.org/pdf/2109.05237v4,"['cs.LG', 'physics.comp-ph']"
1611.03777v1,Tricks from Deep Learning,"['Atılım Güneş Baydin', 'Barak A. Pearlmutter', 'Jeffrey Mark Siskind']","The deep learning community has devised a diverse set of methods to make
gradient optimization, using large datasets, of large and highly complex models
with deeply cascaded nonlinearities, practical. Taken as a whole, these methods
constitute a breakthrough, allowing computational structures which are quite
wide, very deep, and with an enormous number and variety of free parameters to
be effectively optimized. The result now dominates much of practical machine
learning, with applications in machine translation, computer vision, and speech
recognition. Many of these methods, viewed through the lens of algorithmic
differentiation (AD), can be seen as either addressing issues with the gradient
itself, or finding ways of achieving increased efficiency using tricks that are
AD-related, but not provided by current AD systems.
  The goal of this paper is to explain not just those methods of most relevance
to AD, but also the technical constraints and mindset which led to their
discovery. After explaining this context, we present a ""laundry list"" of
methods developed by the deep learning community. Two of these are discussed in
further mathematical detail: a way to dramatically reduce the size of the tape
when performing reverse-mode AD on a (theoretically) time-reversible process
like an ODE integrator; and a new mathematical insight that allows for the
implementation of a stochastic Newton's method.",2016-11-10T17:57:19Z,http://arxiv.org/pdf/1611.03777v1,"['cs.LG', 'stat.ML']"
1805.04513v1,Laconic Deep Learning Computing,"['Sayeh Sharify', 'Mostafa Mahmoud', 'Alberto Delmas Lascorz', 'Milos Nikolic', 'Andreas Moshovos']","We motivate a method for transparently identifying ineffectual computations
in unmodified Deep Learning models and without affecting accuracy.
Specifically, we show that if we decompose multiplications down to the bit
level the amount of work performed during inference for image classification
models can be consistently reduced by two orders of magnitude. In the best case
studied of a sparse variant of AlexNet, this approach can ideally reduce
computation work by more than 500x. We present Laconic a hardware accelerator
that implements this approach to improve execution time, and energy efficiency
for inference with Deep Learning Networks. Laconic judiciously gives up some of
the work reduction potential to yield a low-cost, simple, and energy efficient
design that outperforms other state-of-the-art accelerators. For example, a
Laconic configuration that uses a weight memory interface with just 128 wires
outperforms a conventional accelerator with a 2K-wire weight memory interface
by 2.3x on average while being 2.13x more energy efficient on average. A
Laconic configuration that uses a 1K-wire weight memory interface, outperforms
the 2K-wire conventional accelerator by 15.4x and is 1.95x more energy
efficient. Laconic does not require but rewards advances in model design such
as a reduction in precision, the use of alternate numeric representations that
reduce the number of bits that are ""1"", or an increase in weight or activation
sparsity.",2018-05-10T18:14:08Z,http://arxiv.org/pdf/1805.04513v1,"['cs.NE', 'cs.AR', 'cs.LG']"
1912.13122v8,Towards Regulated Deep Learning,['Andrés García-Camino'],"Regulation of Multi-Agent Systems (MAS) and Declarative Electronic
Institutions (DEIs) was a multidisciplinary research topic of the past decade
involving (Physical and Software) Agents and Law since the beginning, but
recently evolved towards News-claimed Robot Lawyer since 2016. One of these
first proposals of restricting the behaviour of Software Agents was Electronic
Institutions. However, with the recent reformulation of Artificial Neural
Networks (ANNs) as Deep Learning (DL), Security, Privacy,Ethical and Legal
issues regarding the use of DL has raised concerns in the Artificial
Intelligence (AI) Community. Now that the Regulation of MAS is almost correctly
addressed, we propose the Regulation of Artificial Neural Networks as
Agent-based Training of a special type of regulated Artificial Neural Network
that we call Institutional Neural Network (INN).The main purpose of this paper
is to bring attention to Artificial Teaching (AT) and to give a tentative
answer showing a proof-of-concept implementation of Regulated Deep Learning
(RDL). This paper introduces the former concept and provide $I^*$, a language
previously used to model declaratively and extend Electronic Institutions, as a
means to regulate the execution of Artificial Neural Networks and their
interactions with Artificial Teachers (ATs)",2019-12-31T00:10:50Z,http://arxiv.org/pdf/1912.13122v8,"['cs.AI', 'cs.LG', 'cs.LO', 'cs.MA', 'cs.PL']"
2002.02664v1,Short sighted deep learning,"['Ellen de Melllo Koch', 'Anita de Mello Koch', 'Nicholas Kastanos', 'Ling Cheng']","A theory explaining how deep learning works is yet to be developed. Previous
work suggests that deep learning performs a coarse graining, similar in spirit
to the renormalization group (RG). This idea has been explored in the setting
of a local (nearest neighbor interactions) Ising spin lattice. We extend the
discussion to the setting of a long range spin lattice. Markov Chain Monte
Carlo (MCMC) simulations determine both the critical temperature and scaling
dimensions of the system. The model is used to train both a single RBM
(restricted Boltzmann machine) network, as well as a stacked RBM network.
Following earlier Ising model studies, the trained weights of a single layer
RBM network define a flow of lattice models. In contrast to results for nearest
neighbor Ising, the RBM flow for the long ranged model does not converge to the
correct values for the spin and energy scaling dimension. Further, correlation
functions between visible and hidden nodes exhibit key differences between the
stacked RBM and RG flows. The stacked RBM flow appears to move towards low
temperatures whereas the RG flow moves towards high temperature. This again
differs from results obtained for nearest neighbor Ising.",2020-02-07T08:33:07Z,http://arxiv.org/pdf/2002.02664v1,"['cs.LG', 'cond-mat.stat-mech', 'physics.comp-ph', 'stat.ML']"
2306.15065v1,Molecular geometric deep learning,"['Cong Shen', 'Jiawei Luo', 'Kelin Xia']","Geometric deep learning (GDL) has demonstrated huge power and enormous
potential in molecular data analysis. However, a great challenge still remains
for highly efficient molecular representations. Currently, covalent-bond-based
molecular graphs are the de facto standard for representing molecular topology
at the atomic level. Here we demonstrate, for the first time, that molecular
graphs constructed only from non-covalent bonds can achieve similar or even
better results than covalent-bond-based models in molecular property
prediction. This demonstrates the great potential of novel molecular
representations beyond the de facto standard of covalent-bond-based molecular
graphs. Based on the finding, we propose molecular geometric deep learning
(Mol-GDL). The essential idea is to incorporate a more general molecular
representation into GDL models. In our Mol-GDL, molecular topology is modeled
as a series of molecular graphs, each focusing on a different scale of atomic
interactions. In this way, both covalent interactions and non-covalent
interactions are incorporated into the molecular representation on an equal
footing. We systematically test Mol-GDL on fourteen commonly-used benchmark
datasets. The results show that our Mol-GDL can achieve a better performance
than state-of-the-art (SOTA) methods. Source code and data are available at
https://github.com/CS-BIO/Mol-GDL.",2023-06-22T14:25:08Z,http://arxiv.org/pdf/2306.15065v1,"['physics.comp-ph', 'cs.AI', 'cs.LG']"
1807.04739v1,When deep learning meets security,['Majd Latah'],"Deep learning is an emerging research field that has proven its effectiveness
towards deploying more efficient intelligent systems. Security, on the other
hand, is one of the most essential issues in modern communication systems.
Recently many papers have shown that using deep learning models can achieve
promising results when applied to the security domain. In this work, we provide
an overview for the recent studies that apply deep learning techniques to the
field of security.",2018-07-12T17:44:42Z,http://arxiv.org/pdf/1807.04739v1,"['cs.CR', 'cs.LG']"
2209.12014v1,Asset Pricing and Deep Learning,['Chen Zhang'],"Traditional machine learning methods have been widely studied in financial
innovation. My study focuses on the application of deep learning methods on
asset pricing. I investigate various deep learning methods for asset pricing,
especially for risk premia measurement. All models take the same set of
predictive signals (firm characteristics, systematic risks and macroeconomics).
I demonstrate high performance of all kinds of state-of-the-art (SOTA) deep
learning methods, and figure out that RNNs with memory mechanism and attention
have the best performance in terms of predictivity. Furthermore, I demonstrate
large economic gains to investors using deep learning forecasts. The results of
my comparative experiments highlight the importance of domain knowledge and
financial theory when designing deep learning models. I also show return
prediction tasks bring new challenges to deep learning. The time varying
distribution causes distribution shift problem, which is essential for
financial time series prediction. I demonstrate that deep learning methods can
improve asset risk premium measurement. Due to the booming deep learning
studies, they can constantly promote the study of underlying financial
mechanisms behind asset pricing. I also propose a promising research method
that learning from data and figuring out the underlying economic mechanisms
through explainable artificial intelligence (AI) methods. My findings not only
justify the value of deep learning in blooming fintech development, but also
highlight their prospects and advantages over traditional machine learning
methods.",2022-09-24T14:18:07Z,http://arxiv.org/pdf/2209.12014v1,"['q-fin.ST', 'cs.LG', 'q-fin.PR']"
1801.00631v1,Deep Learning: A Critical Appraisal,['Gary Marcus'],"Although deep learning has historical roots going back decades, neither the
term ""deep learning"" nor the approach was popular just over five years ago,
when the field was reignited by papers such as Krizhevsky, Sutskever and
Hinton's now classic (2012) deep network model of Imagenet. What has the field
discovered in the five subsequent years? Against a background of considerable
progress in areas such as speech recognition, image recognition, and game
playing, and considerable enthusiasm in the popular press, I present ten
concerns for deep learning, and suggest that deep learning must be supplemented
by other techniques if we are to reach artificial general intelligence.",2018-01-02T12:49:35Z,http://arxiv.org/pdf/1801.00631v1,"['cs.AI', 'cs.LG', 'stat.ML', '97R40', 'I.2.0; I.2.6']"
2105.11046v1,Deep learning in biomedical optics,"['Lei Tian', 'Brady Hunt', 'Muyinatu A. Lediju Bell', 'Ji Yi', 'Jason T. Smith', 'Marien Ochoa', 'Xavier Intes', 'Nicholas J. Durr']","This article reviews deep learning applications in biomedical optics with a
particular emphasis on image formation. The review is organized by imaging
domains within biomedical optics and includes microscopy, fluorescence lifetime
imaging, in vivo microscopy, widefield endoscopy, optical coherence tomography,
photoacoustic imaging, diffuse tomography, and functional optical brain
imaging. For each of these domains, we summarize how deep learning has been
applied and highlight methods by which deep learning can enable new
capabilities for optics in medicine. Challenges and opportunities to improve
translation and adoption of deep learning in biomedical optics are also
summarized.",2021-05-23T23:49:22Z,http://arxiv.org/pdf/2105.11046v1,"['physics.optics', 'physics.bio-ph']"
1705.03921v1,Why & When Deep Learning Works: Looking Inside Deep Learnings,['Ronny Ronen'],"The Intel Collaborative Research Institute for Computational Intelligence
(ICRI-CI) has been heavily supporting Machine Learning and Deep Learning
research from its foundation in 2012. We have asked six leading ICRI-CI Deep
Learning researchers to address the challenge of ""Why & When Deep Learning
works"", with the goal of looking inside Deep Learning, providing insights on
how deep networks function, and uncovering key observations on their
expressiveness, limitations, and potential. The output of this challenge
resulted in five papers that address different facets of deep learning. These
different facets include a high-level understating of why and when deep
networks work (and do not work), the impact of geometry on the expressiveness
of deep networks, and making deep networks interpretable.",2017-05-10T18:52:26Z,http://arxiv.org/pdf/1705.03921v1,['cs.LG']
1706.02714v3,Deep-Learning the Landscape,['Yang-Hui He'],"We propose a paradigm to deep-learn the ever-expanding databases which have
emerged in mathematical physics and particle phenomenology, as diverse as the
statistics of string vacua or combinatorial and algebraic geometry. As concrete
examples, we establish multi-layer neural networks as both classifiers and
predictors and train them with a host of available data ranging from Calabi-Yau
manifolds and vector bundles, to quiver representations for gauge theories. We
find that even a relatively simple neural network can learn many significant
quantities to astounding accuracy in a matter of minutes and can also predict
hithertofore unencountered results. This paradigm should prove a valuable tool
in various investigations in landscapes in physics as well as pure mathematics.",2017-06-08T18:01:02Z,http://arxiv.org/pdf/1706.02714v3,"['hep-th', 'hep-ph', 'math.AG', 'stat.ML']"
2106.11342v5,Dive into Deep Learning,"['Aston Zhang', 'Zachary C. Lipton', 'Mu Li', 'Alexander J. Smola']","This open-source book represents our attempt to make deep learning
approachable, teaching readers the concepts, the context, and the code. The
entire book is drafted in Jupyter notebooks, seamlessly integrating exposition
figures, math, and interactive examples with self-contained code. Our goal is
to offer a resource that could (i) be freely available for everyone; (ii) offer
sufficient technical depth to provide a starting point on the path to actually
becoming an applied machine learning scientist; (iii) include runnable code,
showing readers how to solve problems in practice; (iv) allow for rapid
updates, both by us and also by the community at large; (v) be complemented by
a forum for interactive discussion of technical details and to answer
questions.",2021-06-21T18:19:46Z,http://arxiv.org/pdf/2106.11342v5,"['cs.LG', 'cs.AI', 'cs.CL', 'cs.CV']"
2206.07609v1,Epistemic Deep Learning,"['Shireen Kudukkil Manchingal', 'Fabio Cuzzolin']","The belief function approach to uncertainty quantification as proposed in the
Demspter-Shafer theory of evidence is established upon the general mathematical
models for set-valued observations, called random sets. Set-valued predictions
are the most natural representations of uncertainty in machine learning. In
this paper, we introduce a concept called epistemic deep learning based on the
random-set interpretation of belief functions to model epistemic learning in
deep neural networks. We propose a novel random-set convolutional neural
network for classification that produces scores for sets of classes by learning
set-valued ground truth representations. We evaluate different formulations of
entropy and distance measures for belief functions as viable loss functions for
these random-set networks. We also discuss methods for evaluating the quality
of epistemic predictions and the performance of epistemic random-set neural
networks. We demonstrate through experiments that the epistemic approach
produces better performance results when compared to traditional approaches of
estimating uncertainty.",2022-06-15T15:39:52Z,http://arxiv.org/pdf/2206.07609v1,"['cs.LG', 'cs.NE', 'stat.ML']"
2212.04297v1,Approximations in Deep Learning,"['Etienne Dupuis', 'Silviu-Ioan Filip', 'Olivier Sentieys', 'David Novo', ""Ian O'Connor"", 'Alberto Bosio']","The design and implementation of Deep Learning (DL) models is currently
receiving a lot of attention from both industrials and academics. However, the
computational workload associated with DL is often out of reach for low-power
embedded devices and is still costly when run on datacenters. By relaxing the
need for fully precise operations, Approximate Computing (AxC) substantially
improves performance and energy efficiency. DL is extremely relevant in this
context, since playing with the accuracy needed to do adequate computations
will significantly enhance performance, while keeping the quality of results in
a user-constrained range. This chapter will explore how AxC can improve the
performance and energy efficiency of hardware accelerators in DL applications
during inference and training.",2022-12-08T14:39:01Z,http://arxiv.org/pdf/2212.04297v1,"['cs.AR', 'eess.SP']"
2301.04856v1,Multimodal Deep Learning,"['Cem Akkus', 'Luyang Chu', 'Vladana Djakovic', 'Steffen Jauch-Walser', 'Philipp Koch', 'Giacomo Loss', 'Christopher Marquardt', 'Marco Moldovan', 'Nadja Sauter', 'Maximilian Schneider', 'Rickmer Schulte', 'Karol Urbanczyk', 'Jann Goschenhofer', 'Christian Heumann', 'Rasmus Hvingelby', 'Daniel Schalk', 'Matthias Aßenmacher']","This book is the result of a seminar in which we reviewed multimodal
approaches and attempted to create a solid overview of the field, starting with
the current state-of-the-art approaches in the two subfields of Deep Learning
individually. Further, modeling frameworks are discussed where one modality is
transformed into the other, as well as models in which one modality is utilized
to enhance representation learning for the other. To conclude the second part,
architectures with a focus on handling both modalities simultaneously are
introduced. Finally, we also cover other modalities as well as general-purpose
multi-modal models, which are able to handle different tasks on different
modalities within one unified architecture. One interesting application
(Generative Art) eventually caps off this booklet.",2023-01-12T07:42:36Z,http://arxiv.org/pdf/2301.04856v1,"['cs.CL', 'cs.LG', 'stat.ML']"
2410.07081v3,JPEG Inspired Deep Learning,"['Ahmed H. Salamah', 'Kaixiang Zheng', 'Yiwen Liu', 'En-Hui Yang']","Although it is traditionally believed that lossy image compression, such as
JPEG compression, has a negative impact on the performance of deep neural
networks (DNNs), it is shown by recent works that well-crafted JPEG compression
can actually improve the performance of deep learning (DL). Inspired by this,
we propose JPEG-DL, a novel DL framework that prepends any underlying DNN
architecture with a trainable JPEG compression layer. To make the quantization
operation in JPEG compression trainable, a new differentiable soft quantizer is
employed at the JPEG layer, and then the quantization operation and underlying
DNN are jointly trained. Extensive experiments show that in comparison with the
standard DL, JPEG-DL delivers significant accuracy improvements across various
datasets and model architectures while enhancing robustness against adversarial
attacks. Particularly, on some fine-grained image classification datasets,
JPEG-DL can increase prediction accuracy by as much as 20.9%. Our code is
available on https://github.com/AhmedHussKhalifa/JPEG-Inspired-DL.git.",2024-10-09T17:23:54Z,http://arxiv.org/pdf/2410.07081v3,['cs.CV']
1612.05596v2,Neuromorphic Deep Learning Machines,"['Emre Neftci', 'Charles Augustine', 'Somnath Paul', 'Georgios Detorakis']","An ongoing challenge in neuromorphic computing is to devise general and
computationally efficient models of inference and learning which are compatible
with the spatial and temporal constraints of the brain. One increasingly
popular and successful approach is to take inspiration from inference and
learning algorithms used in deep neural networks. However, the workhorse of
deep learning, the gradient descent Back Propagation (BP) rule, often relies on
the immediate availability of network-wide information stored with
high-precision memory, and precise operations that are difficult to realize in
neuromorphic hardware. Remarkably, recent work showed that exact backpropagated
weights are not essential for learning deep representations. Random BP replaces
feedback weights with random ones and encourages the network to adjust its
feed-forward weights to learn pseudo-inverses of the (random) feedback weights.
Building on these results, we demonstrate an event-driven random BP (eRBP) rule
that uses an error-modulated synaptic plasticity for learning deep
representations in neuromorphic computing hardware. The rule requires only one
addition and two comparisons for each synaptic weight using a two-compartment
leaky Integrate & Fire (I&F) neuron, making it very suitable for implementation
in digital or mixed-signal neuromorphic hardware. Our results show that using
eRBP, deep representations are rapidly learned, achieving nearly identical
classification accuracies compared to artificial neural network simulations on
GPUs, while being robust to neural and synaptic state quantizations during
learning.",2016-12-16T19:06:35Z,http://arxiv.org/pdf/1612.05596v2,"['cs.NE', 'cs.AI']"
1705.04709v1,Deep Learning Microscopy,"['Yair Rivenson', 'Zoltan Gorocs', 'Harun Gunaydin', 'Yibo Zhang', 'Hongda Wang', 'Aydogan Ozcan']","We demonstrate that a deep neural network can significantly improve optical
microscopy, enhancing its spatial resolution over a large field-of-view and
depth-of-field. After its training, the only input to this network is an image
acquired using a regular optical microscope, without any changes to its design.
We blindly tested this deep learning approach using various tissue samples that
are imaged with low-resolution and wide-field systems, where the network
rapidly outputs an image with remarkably better resolution, matching the
performance of higher numerical aperture lenses, also significantly surpassing
their limited field-of-view and depth-of-field. These results are
transformative for various fields that use microscopy tools, including e.g.,
life sciences, where optical microscopy is considered as one of the most widely
used and deployed techniques. Beyond such applications, our presented approach
is broadly applicable to other imaging modalities, also spanning different
parts of the electromagnetic spectrum, and can be used to design computational
imagers that get better and better as they continue to image specimen and
establish new transformations among different modes of imaging.",2017-05-12T18:22:54Z,http://arxiv.org/pdf/1705.04709v1,"['cs.LG', 'cs.CV', 'physics.optics', '68T01, 68T05, 68U10, 62M45, 78M32, 92C50, 92C55, 94A08', 'I.2; I.2.1; I.2.6; I.2.10; I.3; I.3.3; I.4.3; I.4.4; I.4.9; J.3']"
1804.07045v2,Semantic Adversarial Deep Learning,"['Tommaso Dreossi', 'Somesh Jha', 'Sanjit A. Seshia']","Fueled by massive amounts of data, models produced by machine-learning (ML)
algorithms, especially deep neural networks, are being used in diverse domains
where trustworthiness is a concern, including automotive systems, finance,
health care, natural language processing, and malware detection. Of particular
concern is the use of ML algorithms in cyber-physical systems (CPS), such as
self-driving cars and aviation, where an adversary can cause serious
consequences. However, existing approaches to generating adversarial examples
and devising robust ML algorithms mostly ignore the semantics and context of
the overall system containing the ML component. For example, in an autonomous
vehicle using deep learning for perception, not every adversarial example for
the neural network might lead to a harmful consequence. Moreover, one may want
to prioritize the search for adversarial examples towards those that
significantly modify the desired semantics of the overall system. Along the
same lines, existing algorithms for constructing robust ML algorithms ignore
the specification of the overall system. In this paper, we argue that the
semantics and specification of the overall system has a crucial role to play in
this line of research. We present preliminary research results that support
this claim.",2018-04-19T09:15:58Z,http://arxiv.org/pdf/1804.07045v2,"['cs.LG', 'stat.ML']"
1811.07598v1,Self-Referenced Deep Learning,"['Xu Lan', 'Xiatian Zhu', 'Shaogang Gong']","Knowledge distillation is an effective approach to transferring knowledge
from a teacher neural network to a student target network for satisfying the
low-memory and fast running requirements in practice use. Whilst being able to
create stronger target networks compared to the vanilla non-teacher based
learning strategy, this scheme needs to train additionally a large teacher
model with expensive computational cost. In this work, we present a
Self-Referenced Deep Learning (SRDL) strategy. Unlike both vanilla optimisation
and existing knowledge distillation, SRDL distils the knowledge discovered by
the in-training target model back to itself to regularise the subsequent
learning procedure therefore eliminating the need for training a large teacher
model. SRDL improves the model generalisation performance compared to vanilla
learning and conventional knowledge distillation approaches with negligible
extra computational cost. Extensive evaluations show that a variety of deep
networks benefit from SRDL resulting in enhanced deployment performance on both
coarse-grained object categorisation tasks (CIFAR10, CIFAR100, Tiny ImageNet,
and ImageNet) and fine-grained person instance identification tasks
(Market-1501).",2018-11-19T10:41:17Z,http://arxiv.org/pdf/1811.07598v1,['cs.CV']
2009.01575v2,Deep Learning in Science,"['Stefano Bianchini', 'Moritz Müller', 'Pierre Pelletier']","Much of the recent success of Artificial Intelligence (AI) has been spurred
on by impressive achievements within a broader family of machine learning
methods, commonly referred to as Deep Learning (DL). This paper provides
insights on the diffusion and impact of DL in science. Through a Natural
Language Processing (NLP) approach on the arXiv.org publication corpus, we
delineate the emerging DL technology and identify a list of relevant search
terms. These search terms allow us to retrieve DL-related publications from Web
of Science across all sciences. Based on that sample, we document the DL
diffusion process in the scientific system. We find i) an exponential growth in
the adoption of DL as a research tool across all sciences and all over the
world, ii) regional differentiation in DL application domains, and iii) a
transition from interdisciplinary DL applications to disciplinary research
within application domains. In a second step, we investigate how the adoption
of DL methods affects scientific development. Therefore, we empirically assess
how DL adoption relates to re-combinatorial novelty and scientific impact in
the health sciences. We find that DL adoption is negatively correlated with
re-combinatorial novelty, but positively correlated with expectation as well as
variance of citation performance. Our findings suggest that DL does not (yet?)
work as an autopilot to navigate complex knowledge landscapes and overthrow
their structure. However, the 'DL principle' qualifies for its versatility as
the nucleus of a general scientific method that advances science in a
measurable way.",2020-09-03T10:41:29Z,http://arxiv.org/pdf/2009.01575v2,"['cs.CY', 'econ.EM']"
1709.01779v2,Deep learning from crowds,"['Filipe Rodrigues', 'Francisco Pereira']","Over the last few years, deep learning has revolutionized the field of
machine learning by dramatically improving the state-of-the-art in various
domains. However, as the size of supervised artificial neural networks grows,
typically so does the need for larger labeled datasets. Recently, crowdsourcing
has established itself as an efficient and cost-effective solution for labeling
large sets of data in a scalable manner, but it often requires aggregating
labels from multiple noisy contributors with different levels of expertise. In
this paper, we address the problem of learning deep neural networks from
crowds. We begin by describing an EM algorithm for jointly learning the
parameters of the network and the reliabilities of the annotators. Then, a
novel general-purpose crowd layer is proposed, which allows us to train deep
neural networks end-to-end, directly from the noisy labels of multiple
annotators, using only backpropagation. We empirically show that the proposed
approach is able to internally capture the reliability and biases of different
annotators and achieve new state-of-the-art results for various crowdsourced
datasets across different settings, namely classification, regression and
sequence labeling.",2017-09-06T11:41:19Z,http://arxiv.org/pdf/1709.01779v2,"['stat.ML', 'cs.CV', 'cs.HC', 'cs.LG']"
2302.11529v2,Modular Deep Learning,"['Jonas Pfeiffer', 'Sebastian Ruder', 'Ivan Vulić', 'Edoardo Maria Ponti']","Transfer learning has recently become the dominant paradigm of machine
learning. Pre-trained models fine-tuned for downstream tasks achieve better
performance with fewer labelled examples. Nonetheless, it remains unclear how
to develop models that specialise towards multiple tasks without incurring
negative interference and that generalise systematically to non-identically
distributed tasks. Modular deep learning has emerged as a promising solution to
these challenges. In this framework, units of computation are often implemented
as autonomous parameter-efficient modules. Information is conditionally routed
to a subset of modules and subsequently aggregated. These properties enable
positive transfer and systematic generalisation by separating computation from
routing and updating modules locally. We offer a survey of modular
architectures, providing a unified view over several threads of research that
evolved independently in the scientific literature. Moreover, we explore
various additional purposes of modularity, including scaling language models,
causal inference, programme induction, and planning in reinforcement learning.
Finally, we report various concrete applications where modularity has been
successfully deployed such as cross-lingual and cross-modal knowledge transfer.
Related talks and projects to this survey, are available at
https://www.modulardeeplearning.com/.",2023-02-22T18:11:25Z,http://arxiv.org/pdf/2302.11529v2,['cs.LG']
2307.12187v1,Monadic Deep Learning,"['Bo Yang', 'Zhihao Zhang Kirisame Marisa', 'Kai Shi']","The Java and Scala community has built a very successful big data ecosystem.
However, most of neural networks running on it are modeled in dynamically typed
programming languages. These dynamically typed deep learning frameworks treat
neural networks as differentiable expressions that contain many trainable
variable, and perform automatic differentiation on those expressions when
training them.
  Until 2019, none of the learning frameworks in statically typed languages
provided the expressive power of traditional frameworks. Their users are not
able to use custom algorithms unless creating plenty of boilerplate code for
hard-coded back-propagation.
  We solved this problem in DeepLearning.scala 2. Our contributions are:
  1. We discovered a novel approach to perform automatic differentiation in
reverse mode for statically typed functions that contain multiple trainable
variable, and can interoperate freely with the metalanguage.
  2. We designed a set of monads and monad transformers, which allow users to
create monadic expressions that represent dynamic neural networks.
  3. Along with these monads, we provide some applicative functors, to perform
multiple calculations in parallel.
  With these features, users of DeepLearning.scala were able to create complex
neural networks in an intuitive and concise way, and still maintain type
safety.",2023-07-23T00:17:37Z,http://arxiv.org/pdf/2307.12187v1,"['cs.PL', 'cs.AI', 'cs.LG']"
2405.08901v2,Preheating with deep learning,"['Jong-Hyun Yoon', 'Simon Cléry', 'Mathieu Gross', 'Yann Mambrini']","We apply deep learning techniques to the late-time turbulent regime in a
post-inflationary model where a real scalar inflaton field and the standard
model Higgs doublet interact with renormalizable couplings between them. After
inflation, the inflaton decays into the Higgs through a trilinear coupling and
the Higgs field subsequently thermalizes with gauge bosons via its $SU(2)\times
U(1)$ gauge interaction. Depending on the strength of the trilinear interaction
and the Higgs self-coupling, the effective mass squared of Higgs can become
negative, leading to the tachyonic production of Higgs particles. These
produced Higgs particles would then share their energy with gauge bosons,
potentially indicating thermalization. Since the model entails different
non-perturbative effects, it is necessary to resort to numerical and
semi-classical techniques. However, simulations require significant costs in
terms of time and computational resources depending on the model used.
Particularly, when $SU(2)$ gauge interactions are introduced, this becomes
evident as the gauge field redistributes particle energies through rescattering
processes, leading to an abundance of UV modes that disrupt simulation
stability. This necessitates very small lattice spacings, resulting in
exceedingly long simulation runtimes. Furthermore, the late-time behavior of
preheating dynamics exhibits a universal form by wave kinetic theory.
Therefore, we analyze patterns in the flow of particle numbers and predict
future behavior using CNN-LSTM (Convolutional Neural Network combined with Long
Short-Term Memory) time series analysis. In this way, we can reduce our
dependence on simulations by orders of magnitude in terms of time and
computational resources.",2024-05-14T18:30:02Z,http://arxiv.org/pdf/2405.08901v2,"['hep-ph', 'astro-ph.CO']"
2501.14152v1,Multimodal Prescriptive Deep Learning,"['Dimitris Bertsimas', 'Lisa Everest', 'Vasiliki Stoumpou']","We introduce a multimodal deep learning framework, Prescriptive Neural
Networks (PNNs), that combines ideas from optimization and machine learning,
and is, to the best of our knowledge, the first prescriptive method to handle
multimodal data. The PNN is a feedforward neural network trained on embeddings
to output an outcome-optimizing prescription. In two real-world multimodal
datasets, we demonstrate that PNNs prescribe treatments that are able to
significantly improve estimated outcomes in transcatheter aortic valve
replacement (TAVR) procedures by reducing estimated postoperative complication
rates by 32% and in liver trauma injuries by reducing estimated mortality rates
by over 40%. In four real-world, unimodal tabular datasets, we demonstrate that
PNNs outperform or perform comparably to other well-known, state-of-the-art
prescriptive models; importantly, on tabular datasets, we also recover
interpretability through knowledge distillation, fitting interpretable Optimal
Classification Tree models onto the PNN prescriptions as classification
targets, which is critical for many real-world applications. Finally, we
demonstrate that our multimodal PNN models achieve stability across randomized
data splits comparable to other prescriptive methods and produce realistic
prescriptions across the different datasets.",2025-01-24T00:37:28Z,http://arxiv.org/pdf/2501.14152v1,"['cs.LG', 'stat.ML']"
1710.10784v1,How deep learning works --The geometry of deep learning,"['Xiao Dong', 'Jiasong Wu', 'Ling Zhou']","Why and how that deep learning works well on different tasks remains a
mystery from a theoretical perspective. In this paper we draw a geometric
picture of the deep learning system by finding its analogies with two existing
geometric structures, the geometry of quantum computations and the geometry of
the diffeomorphic template matching. In this framework, we give the geometric
structures of different deep learning systems including convolutional neural
networks, residual networks, recursive neural networks, recurrent neural
networks and the equilibrium prapagation framework. We can also analysis the
relationship between the geometrical structures and their performance of
different networks in an algorithmic level so that the geometric framework may
guide the design of the structures and algorithms of deep learning systems.",2017-10-30T06:42:23Z,http://arxiv.org/pdf/1710.10784v1,"['cs.LG', 'stat.ML']"
1709.01953v2,Implicit Regularization in Deep Learning,['Behnam Neyshabur'],"In an attempt to better understand generalization in deep learning, we study
several possible explanations. We show that implicit regularization induced by
the optimization method is playing a key role in generalization and success of
deep learning models. Motivated by this view, we study how different complexity
measures can ensure generalization and explain how optimization algorithms can
implicitly regularize complexity measures. We empirically investigate the
ability of these measures to explain different observed phenomena in deep
learning. We further study the invariances in neural networks, suggest
complexity measures and optimization algorithms that have similar invariances
to those in neural networks and evaluate them on a number of learning tasks.",2017-09-06T18:12:04Z,http://arxiv.org/pdf/1709.01953v2,['cs.LG']
2107.02584v2,Deep learning for bioimage analysis,"['Adrien Hallou', 'Hannah Yevick', 'Bianca Dumitrascu', 'Virginie Uhlmann']","Deep learning has transformed the way large and complex image datasets can be
processed, reshaping what is possible in bioimage analysis. As the complexity
and size of bioimage data continues to grow, this new analysis paradigm is
becoming increasingly ubiquitous. In this Review, we begin by introducing the
concepts needed for beginners to understand deep learning. We then review how
deep learning has impacted bioimage analysis and explore the open-source
resources available to integrate it into a research project. Finally, we
discuss the future of deep learning applied to cell and developmental biology.
We analyse how state-of-the-art methodologies have the potential to transform
our understanding of biological systems through new image-based analysis and
modelling that integrate multimodal inputs in space and time.",2021-07-06T12:53:45Z,http://arxiv.org/pdf/2107.02584v2,"['q-bio.QM', 'physics.bio-ph', 'I.2.1; I.4.3; I.4.4; I.4.6; I.4.8']"
1802.04647v1,Deep Learning with Apache SystemML,"['Niketan Pansare', 'Michael Dusenberry', 'Nakul Jindal', 'Matthias Boehm', 'Berthold Reinwald', 'Prithviraj Sen']","Enterprises operate large data lakes using Hadoop and Spark frameworks that
(1) run a plethora of tools to automate powerful data
preparation/transformation pipelines, (2) run on shared, large clusters to (3)
perform many different analytics tasks ranging from model preparation,
building, evaluation, and tuning for both machine learning and deep learning.
Developing machine/deep learning models on data in such shared environments is
challenging. Apache SystemML provides a unified framework for implementing
machine learning and deep learning algorithms in a variety of shared deployment
scenarios. SystemML's novel compilation approach automatically generates
runtime execution plans for machine/deep learning algorithms that are composed
of single-node and distributed runtime operations depending on data and cluster
characteristics such as data size, data sparsity, cluster size, and memory
configurations, while still exploiting the capabilities of the underlying big
data frameworks.",2018-02-08T23:54:37Z,http://arxiv.org/pdf/1802.04647v1,"['cs.LG', 'cs.DC']"
1807.04950v1,Deep Learning in the Wild,"['Thilo Stadelmann', 'Mohammadreza Amirian', 'Ismail Arabaci', 'Marek Arnold', 'Gilbert François Duivesteijn', 'Ismail Elezi', 'Melanie Geiger', 'Stefan Lörwald', 'Benjamin Bruno Meier', 'Katharina Rombach', 'Lukas Tuggener']","Deep learning with neural networks is applied by an increasing number of
people outside of classic research environments, due to the vast success of the
methodology on a wide range of machine perception tasks. While this interest is
fueled by beautiful success stories, practical work in deep learning on novel
tasks without existing baselines remains challenging. This paper explores the
specific challenges arising in the realm of real world tasks, based on case
studies from research \& development in conjunction with industry, and extracts
lessons learned from them. It thus fills a gap between the publication of
latest algorithmic and methodical developments, and the usually omitted
nitty-gritty of how to make them work. Specifically, we give insight into deep
learning projects on face matching, print media monitoring, industrial quality
control, music scanning, strategy game playing, and automated machine learning,
thereby providing best practices for deep learning in practice.",2018-07-13T07:22:45Z,http://arxiv.org/pdf/1807.04950v1,"['cs.LG', 'cs.AI', 'cs.CV', 'stat.ML']"
2205.05764v1,Deep Learning and Synthetic Media,['Raphaël Millière'],"Deep learning algorithms are rapidly changing the way in which audiovisual
media can be produced. Synthetic audiovisual media generated with deep learning
- often subsumed colloquially under the label ""deepfakes"" - have a number of
impressive characteristics; they are increasingly trivial to produce, and can
be indistinguishable from real sounds and images recorded with a sensor. Much
attention has been dedicated to ethical concerns raised by this technological
development. Here, I focus instead on a set of issues related to the notion of
synthetic audiovisual media, its place within a broader taxonomy of audiovisual
media, and how deep learning techniques differ from more traditional approaches
to media synthesis. After reviewing important etiological features of deep
learning pipelines for media manipulation and generation, I argue that
""deepfakes"" and related synthetic media produced with such pipelines do not
merely offer incremental improvements over previous methods, but challenge
traditional taxonomical distinctions, and pave the way for genuinely novel
kinds of audiovisual media.",2022-05-11T20:28:09Z,http://arxiv.org/pdf/2205.05764v1,"['cs.LG', 'cs.SD', 'eess.AS']"
2401.02321v1,Deep Learning for Optical Tweezers,"['Antonio Ciarlo', 'David Bronte Ciriza', 'Martin Selin', 'Onofrio M. Maragò', 'Antonio Sasso', 'Giuseppe Pesce', 'Giovanni Volpe', 'Mattias Goksör']","Optical tweezers exploit light--matter interactions to trap particles ranging
from single atoms to micrometer-sized eukaryotic cells. For this reason,
optical tweezers are a ubiquitous tool in physics, biology, and nanotechnology.
Recently, the use of deep learning has started to enhance optical tweezers by
improving their design, calibration, and real-time control as well as the
tracking and analysis of the trapped objects, often outperforming classical
methods thanks to the higher computational speed and versatility of deep
learning. Here, we review how deep learning has already remarkably improved
optical tweezers, while exploring the exciting, new future possibilities
enabled by this dynamic synergy. Furthermore, we offer guidelines on
integrating deep learning with optical trapping and optical manipulation in a
reliable and trustworthy way.",2024-01-04T15:41:46Z,http://arxiv.org/pdf/2401.02321v1,"['physics.optics', 'physics.ins-det', '78-02']"
2302.00150v1,Multi-Grade Deep Learning,['Yuesheng Xu'],"The current deep learning model is of a single-grade, that is, it learns a
deep neural network by solving a single nonconvex optimization problem. When
the layer number of the neural network is large, it is computationally
challenging to carry out such a task efficiently. Inspired by the human
education process which arranges learning in grades, we propose a multi-grade
learning model: We successively solve a number of optimization problems of
small sizes, which are organized in grades, to learn a shallow neural network
for each grade. Specifically, the current grade is to learn the leftover from
the previous grade. In each of the grades, we learn a shallow neural network
stacked on the top of the neural network, learned in the previous grades, which
remains unchanged in training of the current and future grades. By dividing the
task of learning a deep neural network into learning several shallow neural
networks, one can alleviate the severity of the nonconvexity of the original
optimization problem of a large size. When all grades of the learning are
completed, the final neural network learned is a stair-shape neural network,
which is the superposition of networks learned from all grades. Such a model
enables us to learn a deep neural network much more effectively and
efficiently. Moreover, multi-grade learning naturally leads to adaptive
learning. We prove that in the context of function approximation if the neural
network generated by a new grade is nontrivial, the optimal error of the grade
is strictly reduced from the optimal error of the previous grade. Furthermore,
we provide several proof-of-concept numerical examples which demonstrate that
the proposed multi-grade model outperforms significantly the traditional
single-grade model and is much more robust than the traditional model.",2023-02-01T00:09:56Z,http://arxiv.org/pdf/2302.00150v1,['cs.LG']
2302.09656v5,Credal Bayesian Deep Learning,"['Michele Caprio', 'Souradeep Dutta', 'Kuk Jin Jang', 'Vivian Lin', 'Radoslav Ivanov', 'Oleg Sokolsky', 'Insup Lee']","Uncertainty quantification and robustness to distribution shifts are
important goals in machine learning and artificial intelligence. Although
Bayesian Neural Networks (BNNs) allow for uncertainty in the predictions to be
assessed, different sources of predictive uncertainty cannot be distinguished
properly. We present Credal Bayesian Deep Learning (CBDL). Heuristically, CBDL
allows to train an (uncountably) infinite ensemble of BNNs, using only finitely
many elements. This is possible thanks to prior and likelihood finitely
generated credal sets (FGCSs), a concept from the imprecise probability
literature. Intuitively, convex combinations of a finite collection of
prior-likelihood pairs are able to represent infinitely many such pairs. After
training, CBDL outputs a set of posteriors on the parameters of the neural
network. At inference time, such posterior set is used to derive a set of
predictive distributions that is in turn utilized to distinguish between
(predictive) aleatoric and epistemic uncertainties, and to quantify them. The
predictive set also produces either (i) a collection of outputs enjoying
desirable probabilistic guarantees, or (ii) the single output that is deemed
the best, that is, the one having the highest predictive lower probability --
another imprecise-probabilistic concept. CBDL is more robust than single BNNs
to prior and likelihood misspecification, and to distribution shift. We show
that CBDL is better at quantifying and disentangling different types of
(predictive) uncertainties than single BNNs and ensemble of BNNs. In addition,
we apply CBDL to two case studies to demonstrate its downstream tasks
capabilities: one, for motion prediction in autonomous driving scenarios, and
two, to model blood glucose and insulin dynamics for artificial pancreas
control. We show that CBDL performs better when compared to an ensemble of BNNs
baseline.",2023-02-19T19:03:26Z,http://arxiv.org/pdf/2302.09656v5,"['cs.LG', 'stat.ML', 'Primary: 68T37, Secondary: 68T05, 68W25']"
1807.03523v1,DLOPT: Deep Learning Optimization Library,"['Andrés Camero', 'Jamal Toutouh', 'Enrique Alba']","Deep learning hyper-parameter optimization is a tough task. Finding an
appropriate network configuration is a key to success, however most of the
times this labor is roughly done. In this work we introduce a novel library to
tackle this problem, the Deep Learning Optimization Library: DLOPT. We briefly
describe its architecture and present a set of use examples. This is an open
source project developed under the GNU GPL v3 license and it is freely
available at https://github.com/acamero/dlopt",2018-07-10T08:34:25Z,http://arxiv.org/pdf/1807.03523v1,"['cs.LG', 'cs.NE', 'stat.ML']"
1809.03559v1,Deep Learning Towards Mobile Applications,"['Ji Wang', 'Bokai Cao', 'Philip S. Yu', 'Lichao Sun', 'Weidong Bao', 'Xiaomin Zhu']","Recent years have witnessed an explosive growth of mobile devices. Mobile
devices are permeating every aspect of our daily lives. With the increasing
usage of mobile devices and intelligent applications, there is a soaring demand
for mobile applications with machine learning services. Inspired by the
tremendous success achieved by deep learning in many machine learning tasks, it
becomes a natural trend to push deep learning towards mobile applications.
However, there exist many challenges to realize deep learning in mobile
applications, including the contradiction between the miniature nature of
mobile devices and the resource requirement of deep neural networks, the
privacy and security concerns about individuals' data, and so on. To resolve
these challenges, during the past few years, great leaps have been made in this
area. In this paper, we provide an overview of the current challenges and
representative achievements about pushing deep learning on mobile devices from
three aspects: training with mobile data, efficient inference on mobile
devices, and applications of mobile deep learning. The former two aspects cover
the primary tasks of deep learning. Then, we go through our two recent
applications that apply the data collected by mobile devices to inferring mood
disturbance and user identification. Finally, we conclude this paper with the
discussion of the future of this area.",2018-09-10T19:28:57Z,http://arxiv.org/pdf/1809.03559v1,"['cs.LG', 'cs.AI', 'cs.DC']"
2005.06068v1,Deep Learning for Wireless Communications,"['Tugba Erpek', ""Timothy J. O'Shea"", 'Yalin E. Sagduyu', 'Yi Shi', 'T. Charles Clancy']","Existing communication systems exhibit inherent limitations in translating
theory to practice when handling the complexity of optimization for emerging
wireless applications with high degrees of freedom. Deep learning has a strong
potential to overcome this challenge via data-driven solutions and improve the
performance of wireless systems in utilizing limited spectrum resources. In
this chapter, we first describe how deep learning is used to design an
end-to-end communication system using autoencoders. This flexible design
effectively captures channel impairments and optimizes transmitter and receiver
operations jointly in single-antenna, multiple-antenna, and multiuser
communications. Next, we present the benefits of deep learning in spectrum
situation awareness ranging from channel modeling and estimation to signal
detection and classification tasks. Deep learning improves the performance when
the model-based methods fail. Finally, we discuss how deep learning applies to
wireless communication security. In this context, adversarial machine learning
provides novel means to launch and defend against wireless attacks. These
applications demonstrate the power of deep learning in providing novel means to
design, optimize, adapt, and secure wireless communications.",2020-05-12T21:58:44Z,http://arxiv.org/pdf/2005.06068v1,"['cs.NI', 'cs.LG']"
2508.02723v1,Mathematical Foundations of Geometric Deep Learning,"['Haitz Sáez de Ocáriz Borde', 'Michael Bronstein']","We review the key mathematical concepts necessary for studying Geometric Deep
Learning.",2025-08-01T06:02:39Z,http://arxiv.org/pdf/2508.02723v1,"['cs.LG', 'cs.AI']"
1904.05391v5,Deep Learning without Weight Transport,"['Mohamed Akrout', 'Collin Wilson', 'Peter C. Humphreys', 'Timothy Lillicrap', 'Douglas Tweed']","Current algorithms for deep learning probably cannot run in the brain because
they rely on weight transport, where forward-path neurons transmit their
synaptic weights to a feedback path, in a way that is likely impossible
biologically. An algorithm called feedback alignment achieves deep learning
without weight transport by using random feedback weights, but it performs
poorly on hard visual-recognition tasks. Here we describe two mechanisms - a
neural circuit called a weight mirror and a modification of an algorithm
proposed by Kolen and Pollack in 1994 - both of which let the feedback path
learn appropriate synaptic weights quickly and accurately even in large
networks, without weight transport or complex wiring.Tested on the ImageNet
visual-recognition task, these mechanisms outperform both feedback alignment
and the newer sign-symmetry method, and nearly match backprop, the standard
algorithm of deep learning, which uses weight transport.",2019-04-10T18:55:59Z,http://arxiv.org/pdf/1904.05391v5,"['cs.LG', 'stat.ML']"
1907.02994v2,Deep learning in ultrasound imaging,"['Ruud JG van Sloun', 'Regev Cohen', 'Yonina C Eldar']","We consider deep learning strategies in ultrasound systems, from the
front-end to advanced applications. Our goal is to provide the reader with a
broad understanding of the possible impact of deep learning methodologies on
many aspects of ultrasound imaging. In particular, we discuss methods that lie
at the interface of signal acquisition and machine learning, exploiting both
data structure (e.g. sparsity in some domain) and data dimensionality (big
data) already at the raw radio-frequency channel stage. As some examples, we
outline efficient and effective deep learning solutions for adaptive
beamforming and adaptive spectral Doppler through artificial agents, learn
compressive encodings for color Doppler, and provide a framework for structured
signal recovery by learning fast approximations of iterative minimization
problems, with applications to clutter suppression and super-resolution
ultrasound. These emerging technologies may have considerable impact on
ultrasound imaging, showing promise across key components in the receive
processing chain.",2019-07-05T18:39:49Z,http://arxiv.org/pdf/1907.02994v2,"['eess.SP', 'cs.LG', 'eess.IV']"
2102.01194v2,A Statistician Teaches Deep Learning,"['G. Jogesh Babu', 'David Banks', 'Hyunsoon Cho', 'David Han', 'Hailin Sang', 'Shouyi Wang']","Deep learning (DL) has gained much attention and become increasingly popular
in modern data science. Computer scientists led the way in developing deep
learning techniques, so the ideas and perspectives can seem alien to
statisticians. Nonetheless, it is important that statisticians become involved
-- many of our students need this expertise for their careers. In this paper,
developed as part of a program on DL held at the Statistical and Applied
Mathematical Sciences Institute, we address this culture gap and provide tips
on how to teach deep learning to statistics graduate students. After some
background, we list ways in which DL and statistical perspectives differ,
provide a recommended syllabus that evolved from teaching two iterations of a
DL graduate course, offer examples of suggested homework assignments, give an
annotated list of teaching resources, and discuss DL in the context of two
research areas.",2021-01-29T04:59:43Z,http://arxiv.org/pdf/2102.01194v2,"['stat.ML', 'cs.CY', 'cs.LG']"
2405.18281v2,MODL: Multilearner Online Deep Learning,"['Antonios Valkanas', 'Boris N. Oreshkin', 'Mark Coates']","Online deep learning tackles the challenge of learning from data streams by
balancing two competing goals: fast learning and deep learning. However,
existing research primarily emphasizes deep learning solutions, which are more
adept at handling the ``deep'' aspect than the ``fast'' aspect of online
learning. In this work, we introduce an alternative paradigm through a hybrid
multilearner approach. We begin by developing a fast online logistic regression
learner, which operates without relying on backpropagation. It leverages
closed-form recursive updates of model parameters, efficiently addressing the
fast learning component of the online learning challenge. This approach is
further integrated with a cascaded multilearner design, where shallow and deep
learners are co-trained in a cooperative, synergistic manner to solve the
online learning problem. We demonstrate that this approach achieves
state-of-the-art performance on standard online learning datasets. We make our
code available: https://github.com/AntonValk/MODL",2024-05-28T15:34:33Z,http://arxiv.org/pdf/2405.18281v2,"['cs.LG', 'cs.AI']"
1905.13390v1,Vehicle Detection in Deep Learning,['Yao Xiao'],"Computer vision is developing rapidly with the support of deep learning
techniques. This thesis proposes an advanced vehicle-detection model based on
an improvement to classical convolutional neural networks. The advanced model
was applied against a vehicle detection benchmark and was built to detect
on-road objects. First, we propose a high-level architecture for our advanced
model, which utilizes different state-of-the-art deep learning techniques.
Then, we utilize the residual neural networks and region proposal network to
achieve competitive performance according to the vehicle detection benchmark.
Lastly, we describe the developing trend of vehicle detection techniques and
the future direction of research.",2019-05-29T00:33:28Z,http://arxiv.org/pdf/1905.13390v1,['cs.CV']
2005.02636v2,Deep Learning and AdS/QCD,"['Tetsuya Akutagawa', 'Koji Hashimoto', 'Takayuki Sumimoto']","We propose a deep learning method to build an AdS/QCD model from the data of
hadron spectra. A major problem of generic AdS/QCD models is that a large
ambiguity is allowed for the bulk gravity metric with which QCD observables are
holographically calculated. We adopt the experimentally measured spectra of
$\rho$ and $a_2$ mesons as training data, and perform a supervised machine
learning which determines concretely a bulk metric and a dilaton profile of an
AdS/QCD model. Our deep learning (DL) architecture is based on the AdS/DL
correspondence (arXiv:1802.08313) where the deep neural network is identified
with the emergent bulk spacetime.",2020-05-06T07:48:00Z,http://arxiv.org/pdf/2005.02636v2,"['hep-th', 'cond-mat.dis-nn', 'hep-ph']"
1904.10345v1,Deep Learning for Survival Outcomes,['Jon Arni Steingrimsson'],"This manuscripts develops a new class of deep learning algorithms for
outcomes that are potentially censored. To account for censoring, the
unobservable loss function used in the absence of censoring is replaced by a
censoring unbiased transformation. The resulting class of algorithms can be
used to estimate both survival probabilities and restricted mean survival. We
show how the deep learning algorithms can be implemented using software for
uncensored data using a form of response transformation. Simulations and
analysis of the Netherlands 70 Gene Signature Data show strong performance of
the proposed algorithms.",2019-04-23T14:08:38Z,http://arxiv.org/pdf/1904.10345v1,['stat.ME']
2407.18384v3,Mathematical theory of deep learning,"['Philipp Petersen', 'Jakob Zech']","This book provides an introduction to the mathematical analysis of deep
learning. It covers fundamental results in approximation theory, optimization
theory, and statistical learning theory, which are the three main pillars of
deep neural network theory. Serving as a guide for students and researchers in
mathematics and related fields, the book aims to equip readers with
foundational knowledge on the topic. It prioritizes simplicity over generality,
and presents rigorous yet accessible results to help build an understanding of
the essential mathematical concepts underpinning deep learning.",2024-07-25T20:37:12Z,http://arxiv.org/pdf/2407.18384v3,"['cs.LG', 'math.HO']"
1805.10451v2,Geometric Understanding of Deep Learning,"['Na Lei', 'Zhongxuan Luo', 'Shing-Tung Yau', 'David Xianfeng Gu']","Deep learning is the mainstream technique for many machine learning tasks,
including image recognition, machine translation, speech recognition, and so
on. It has outperformed conventional methods in various fields and achieved
great successes. Unfortunately, the understanding on how it works remains
unclear. It has the central importance to lay down the theoretic foundation for
deep learning.
  In this work, we give a geometric view to understand deep learning: we show
that the fundamental principle attributing to the success is the manifold
structure in data, namely natural high dimensional data concentrates close to a
low-dimensional manifold, deep learning learns the manifold and the probability
distribution on it.
  We further introduce the concepts of rectified linear complexity for deep
neural network measuring its learning capability, rectified linear complexity
of an embedding manifold describing the difficulty to be learned. Then we show
for any deep neural network with fixed architecture, there exists a manifold
that cannot be learned by the network. Finally, we propose to apply optimal
mass transportation theory to control the probability distribution in the
latent space.",2018-05-26T09:15:53Z,http://arxiv.org/pdf/1805.10451v2,"['cs.LG', 'stat.ML']"
1903.01458v1,Deep Learning for Cognitive Neuroscience,"['Katherine R. Storrs', 'Nikolaus Kriegeskorte']","Neural network models can now recognise images, understand text, translate
languages, and play many human games at human or superhuman levels. These
systems are highly abstracted, but are inspired by biological brains and use
only biologically plausible computations. In the coming years, neural networks
are likely to become less reliant on learning from massive labelled datasets,
and more robust and generalisable in their task performance. From their
successes and failures, we can learn about the computational requirements of
the different tasks at which brains excel. Deep learning also provides the
tools for testing cognitive theories. In order to test a theory, we need to
realise the proposed information-processing system at scale, so as to be able
to assess its feasibility and emergent behaviours. Deep learning allows us to
scale up from principles and circuit models to end-to-end trainable models
capable of performing complex tasks. There are many levels at which cognitive
neuroscientists can use deep learning in their work, from inspiring theories to
serving as full computational models. Ongoing advances in deep learning bring
us closer to understanding how cognition and perception may be implemented in
the brain -- the grand challenge at the core of cognitive neuroscience.",2019-03-04T14:34:52Z,http://arxiv.org/pdf/1903.01458v1,"['q-bio.NC', 'cs.LG']"
2001.05266v1,Deep Learning for MIR Tutorial,"['Alexander Schindler', 'Thomas Lidy', 'Sebastian Böck']","Deep Learning has become state of the art in visual computing and
continuously emerges into the Music Information Retrieval (MIR) and audio
retrieval domain. In order to bring attention to this topic we propose an
introductory tutorial on deep learning for MIR. Besides a general introduction
to neural networks, the proposed tutorial covers a wide range of MIR relevant
deep learning approaches. \textbf{Convolutional Neural Networks} are currently
a de-facto standard for deep learning based audio retrieval. \textbf{Recurrent
Neural Networks} have proven to be effective in onset detection tasks such as
beat or audio-event detection. \textbf{Siamese Networks} have been shown
effective in learning audio representations and distance functions specific for
music similarity retrieval. We will incorporate both academic and industrial
points of view into the tutorial. Accompanying the tutorial, we will create a
Github repository for the content presented at the tutorial as well as
references to state of the art work and literature for further reading. This
repository will remain public after the conference.",2020-01-15T12:23:17Z,http://arxiv.org/pdf/2001.05266v1,"['cs.IR', 'cs.LG', 'cs.SD', 'eess.AS']"
1701.04503v1,Deep Learning for Computational Chemistry,"['Garrett B. Goh', 'Nathan O. Hodas', 'Abhinav Vishnu']","The rise and fall of artificial neural networks is well documented in the
scientific literature of both computer science and computational chemistry. Yet
almost two decades later, we are now seeing a resurgence of interest in deep
learning, a machine learning algorithm based on multilayer neural networks.
Within the last few years, we have seen the transformative impact of deep
learning in many domains, particularly in speech recognition and computer
vision, to the extent that the majority of expert practitioners in those field
are now regularly eschewing prior established models in favor of deep learning
models. In this review, we provide an introductory overview into the theory of
deep neural networks and their unique properties that distinguish them from
traditional machine learning algorithms used in cheminformatics. By providing
an overview of the variety of emerging applications of deep neural networks, we
highlight its ubiquity and broad applicability to a wide range of challenges in
the field, including QSAR, virtual screening, protein structure prediction,
quantum chemistry, materials design and property prediction. In reviewing the
performance of deep neural networks, we observed a consistent outperformance
against non-neural networks state-of-the-art models across disparate research
topics, and deep neural network based models often exceeded the ""glass ceiling""
expectations of their respective tasks. Coupled with the maturity of
GPU-accelerated computing for training deep neural networks and the exponential
growth of chemical data on which to train these networks on, we anticipate that
deep learning algorithms will be a valuable tool for computational chemistry.",2017-01-17T01:15:14Z,http://arxiv.org/pdf/1701.04503v1,"['stat.ML', 'cs.AI', 'cs.CE', 'cs.LG', 'physics.chem-ph']"
1709.05929v1,Institutionally Distributed Deep Learning Networks,"['Ken Chang', 'Niranjan Balachandar', 'Carson K Lam', 'Darvin Yi', 'James M Brown', 'Andrew Beers', 'Bruce R Rosen', 'Daniel L Rubin', 'Jayashree Kalpathy-Cramer']","Deep learning has become a promising approach for automated medical
diagnoses. When medical data samples are limited, collaboration among multiple
institutions is necessary to achieve high algorithm performance. However,
sharing patient data often has limitations due to technical, legal, or ethical
concerns. In such cases, sharing a deep learning model is a more attractive
alternative. The best method of performing such a task is unclear, however. In
this study, we simulate the dissemination of learning deep learning network
models across four institutions using various heuristics and compare the
results with a deep learning model trained on centrally hosted patient data.
The heuristics investigated include ensembling single institution models,
single weight transfer, and cyclical weight transfer. We evaluated these
approaches for image classification in three independent image collections
(retinal fundus photos, mammography, and ImageNet). We find that cyclical
weight transfer resulted in a performance (testing accuracy = 77.3%) that was
closest to that of centrally hosted patient data (testing accuracy = 78.7%). We
also found that there is an improvement in the performance of cyclical weight
transfer heuristic with high frequency of weight transfer.",2017-09-10T15:36:17Z,http://arxiv.org/pdf/1709.05929v1,"['cs.CV', 'cs.LG', 'physics.med-ph']"
2105.09266v5,Copyright in Generative Deep Learning,"['Giorgio Franceschelli', 'Mirco Musolesi']","Machine-generated artworks are now part of the contemporary art scene: they
are attracting significant investments and they are presented in exhibitions
together with those created by human artists. These artworks are mainly based
on generative deep learning techniques, which have seen a formidable
development and remarkable refinement in the very recent years. Given the
inherent characteristics of these techniques, a series of novel legal problems
arise. In this article, we consider a set of key questions in the area of
generative deep learning for the arts, including the following: is it possible
to use copyrighted works as training set for generative models? How do we
legally store their copies in order to perform the training process? Who (if
someone) will own the copyright on the generated data? We try to answer these
questions considering the law in force in both the United States of America and
the European Union, and potential future alternatives. We then extend our
analysis to code generation, which is an emerging area of generative deep
learning. Finally, we also formulate a set of practical guidelines for artists
and developers working on deep learning generated art, as well as some policy
suggestions for policymakers.",2021-05-19T17:22:47Z,http://arxiv.org/pdf/2105.09266v5,"['cs.CY', 'cs.AI', 'cs.LG']"
2106.14085v1,Deep Learning Partial Least Squares,"['Nicholas Polson', 'Vadim Sokolov', 'Jianeng Xu']","High dimensional data reduction techniques are provided by using partial
least squares within deep learning. Our framework provides a nonlinear
extension of PLS together with a disciplined approach to feature selection and
architecture design in deep learning. This leads to a statistical
interpretation of deep learning that is tailor made for predictive problems. We
can use the tools of PLS, such as scree-plot, bi-plot to provide model
diagnostics. Posterior predictive uncertainty is available using MCMC methods
at the last layer. Thus we achieve the best of both worlds: scalability and
fast predictive rule construction together with uncertainty quantification. Our
key construct is to employ deep learning within PLS by predicting the output
scores as a deep learner of the input scores. As with PLS our X-scores are
constructed using SVD and applied to both regression and classification
problems and are fast and scalable. Following Frank and Friedman 1993, we
provide a Bayesian shrinkage interpretation of our nonlinear predictor. We
introduce a variety of new partial least squares models: PLS-ReLU,
PLS-Autoencoder, PLS-Trees and PLS-GP. To illustrate our methodology, we use
simulated examples and the analysis of preferences of orange juice and
predicting wine quality as a function of input characteristics. We also
illustrate Brillinger's estimation procedure to provide the feature selection
and data dimension reduction. Finally, we conclude with directions for future
research.",2021-06-26T20:22:54Z,http://arxiv.org/pdf/2106.14085v1,['stat.ME']
2203.05874v1,Deep Learning for Wireless Dynamics,"['Heunchul Lee', 'Jaeseong Jeong', 'Zhao Wang']","This paper aims to predict radio channel variations over time by deep
learning from channel observations without knowledge of the underlying channel
dynamics. In next-generation wideband cellular systems, multicarrier
transmission for higher data rate leads to the high-resolution predicting
problem. By leveraging recent advances of deep learning in high-resolution
image processing, we propose a purely data-driven deep learning (DL) approach
to predicting high-resolution temporal evolution of wideband radio channels. In
order to investigate the effect of architectural design choices, we develop and
study three deep learning prediction models, namely, baseline, image
completion, and next-frame prediction models using UNet. Numerical results show
that the proposed DL approach achieves a 52% lower prediction error than the
traditional approach based on the Kalman filter (KF) in mean absolute errors.
To quantify impact of channel aging and prediction on precoding performance, we
also evaluate the performance degradation due to outdated and predicted channel
state information (CSI) compared to perfect CSI. Our simulations show that the
proposed DL approach can reduce the performance loss due to channel aging by
71% through adapting precoding vector to changes in radio channel while the
traditional KF approach only shows a 27% reduction.",2022-03-11T12:21:05Z,http://arxiv.org/pdf/2203.05874v1,"['cs.IT', 'math.IT']"
2408.05629v2,Quantum-secure multiparty deep learning,"['Kfir Sulimany', 'Sri Krishna Vadlamani', 'Ryan Hamerly', 'Prahlad Iyengar', 'Dirk Englund']","Secure multiparty computation enables the joint evaluation of multivariate
functions across distributed users while ensuring the privacy of their local
inputs. This field has become increasingly urgent due to the exploding demand
for computationally intensive deep learning inference. These computations are
typically offloaded to cloud computing servers, leading to vulnerabilities that
can compromise the security of the clients' data. To solve this problem, we
introduce a linear algebra engine that leverages the quantum nature of light
for information-theoretically secure multiparty computation using only
conventional telecommunication components. We apply this linear algebra engine
to deep learning and derive rigorous upper bounds on the information leakage of
both the deep neural network weights and the client's data via the Holevo and
the Cram\'er-Rao bounds, respectively. Applied to the MNIST classification
task, we obtain test accuracies exceeding $96\%$ while leaking less than $0.1$
bits per weight symbol and $0.01$ bits per data symbol. This weight leakage is
an order of magnitude below the minimum bit precision required for accurate
deep learning using state-of-the-art quantization techniques. Our work lays the
foundation for practical quantum-secure computation and unlocks secure cloud
deep learning as a field.",2024-08-10T20:48:40Z,http://arxiv.org/pdf/2408.05629v2,"['quant-ph', 'cs.AI', 'cs.IT', 'cs.LG', 'math.IT', 'physics.optics']"
2502.18300v3,Bayesian Computation in Deep Learning,"['Wenlong Chen', 'Bolian Li', 'Ruqi Zhang', 'Yingzhen Li']","This review paper is intended for the 2nd edition of the Handbook of Markov
chain Monte Carlo. We provide an introduction to approximate inference
techniques as Bayesian computation methods applied to deep learning models. We
organize the chapter by presenting popular computational methods for Bayesian
neural networks and deep generative models, explaining their unique challenges
in posterior inference as well as the solutions.",2025-02-25T15:39:33Z,http://arxiv.org/pdf/2502.18300v3,"['cs.LG', 'stat.ML']"
1512.06927v4,A C++ library for Multimodal Deep Learning,['Jian Jin'],"MDL, Multimodal Deep Learning Library, is a deep learning framework that
supports multiple models, and this document explains its philosophy and
functionality. MDL runs on Linux, Mac, and Unix platforms. It depends on
OpenCV.",2015-12-22T01:27:23Z,http://arxiv.org/pdf/1512.06927v4,['cs.LG']
1711.03577v1,What Really is Deep Learning Doing?,['Chuyu Xiong'],"Deep learning has achieved a great success in many areas, from computer
vision to natural language processing, to game playing, and much more. Yet,
what deep learning is really doing is still an open question. There are a lot
of works in this direction. For example, [5] tried to explain deep learning by
group renormalization, and [6] tried to explain deep learning from the view of
functional approximation. In order to address this very crucial question, here
we see deep learning from perspective of mechanical learning and learning
machine (see [1], [2]). From this particular angle, we can see deep learning
much better and answer with confidence: What deep learning is really doing? why
it works well, how it works, and how much data is necessary for learning. We
also will discuss advantages and disadvantages of deep learning at the end of
this work.",2017-11-06T23:00:13Z,http://arxiv.org/pdf/1711.03577v1,"['cs.LG', 'cs.NE']"
2009.08328v7,Review: Deep Learning in Electron Microscopy,['Jeffrey M. Ede'],"Deep learning is transforming most areas of science and technology, including
electron microscopy. This review paper offers a practical perspective aimed at
developers with limited familiarity. For context, we review popular
applications of deep learning in electron microscopy. Afterwards, we discuss
hardware and software needed to get started with deep learning and interface
with electron microscopes. We then review neural network components, popular
architectures, and their optimization. Finally, we discuss future directions of
deep learning in electron microscopy.",2020-09-17T14:23:55Z,http://arxiv.org/pdf/2009.08328v7,"['eess.IV', 'cond-mat.mtrl-sci', 'cs.CV', 'cs.LG']"
1801.07883v2,Deep Learning for Sentiment Analysis : A Survey,"['Lei Zhang', 'Shuai Wang', 'Bing Liu']","Deep learning has emerged as a powerful machine learning technique that
learns multiple layers of representations or features of the data and produces
state-of-the-art prediction results. Along with the success of deep learning in
many other application domains, deep learning is also popularly used in
sentiment analysis in recent years. This paper first gives an overview of deep
learning and then provides a comprehensive survey of its current applications
in sentiment analysis.",2018-01-24T07:32:29Z,http://arxiv.org/pdf/1801.07883v2,"['cs.CL', 'cs.IR', 'cs.LG', 'stat.ML']"
1608.00316v1,Density functionals from deep learning,['Jeffrey M. McMahon'],"Density-functional theory is a formally exact description of a many-body
quantum system in terms of its density; in practice, however, approximations to
the universal density functional are required. In this work, a model based on
deep learning is developed to approximate this functional. Deep learning allows
computational models that are capable of naturally discovering intricate
structure in large and/or high-dimensional data sets, with multiple levels of
abstraction. As no assumptions are made as to the form of this structure, this
approach is much more powerful and flexible than traditional approaches. As an
example application, the model is shown to perform well on approximating the
kinetic-energy density functional for noninteracting electrons. The model is
analyzed in detail, and its advantages over conventional machine learning are
discussed.",2016-08-01T04:28:32Z,http://arxiv.org/pdf/1608.00316v1,"['physics.comp-ph', 'physics.chem-ph']"
1706.00473v4,Deep Learning: A Bayesian Perspective,"['Nicholas Polson', 'Vadim Sokolov']","Deep learning is a form of machine learning for nonlinear high dimensional
pattern matching and prediction. By taking a Bayesian probabilistic
perspective, we provide a number of insights into more efficient algorithms for
optimisation and hyper-parameter tuning. Traditional high-dimensional data
reduction techniques, such as principal component analysis (PCA), partial least
squares (PLS), reduced rank regression (RRR), projection pursuit regression
(PPR) are all shown to be shallow learners. Their deep learning counterparts
exploit multiple deep layers of data reduction which provide predictive
performance gains. Stochastic gradient descent (SGD) training optimisation and
Dropout (DO) regularization provide estimation and variable selection. Bayesian
regularization is central to finding weights and connections in networks to
optimize the predictive bias-variance trade-off. To illustrate our methodology,
we provide an analysis of international bookings on Airbnb. Finally, we
conclude with directions for future research.",2017-06-01T19:50:37Z,http://arxiv.org/pdf/1706.00473v4,"['stat.ML', 'cs.LG', 'stat.ME']"
1706.09077v1,Super-Resolution via Deep Learning,['Khizar Hayat'],"The recent phenomenal interest in convolutional neural networks (CNNs) must
have made it inevitable for the super-resolution (SR) community to explore its
potential. The response has been immense and in the last three years, since the
advent of the pioneering work, there appeared too many works not to warrant a
comprehensive survey. This paper surveys the SR literature in the context of
deep learning. We focus on the three important aspects of multimedia - namely
image, video and multi-dimensions, especially depth maps. In each case, first
relevant benchmarks are introduced in the form of datasets and state of the art
SR methods, excluding deep learning. Next is a detailed analysis of the
individual works, each including a short description of the method and a
critique of the results with special reference to the benchmarking done. This
is followed by minimum overall benchmarking in the form of comparison on some
common dataset, while relying on the results reported in various works.",2017-06-28T00:02:18Z,http://arxiv.org/pdf/1706.09077v1,['cs.CV']
1712.00912v2,Deep Learning Diffuse Optical Tomography,"['Jaejun Yoo', 'Sohail Sabir', 'Duchang Heo', 'Kee Hyun Kim', 'Abdul Wahab', 'Yoonseok Choi', 'Seul-I Lee', 'Eun Young Chae', 'Hak Hee Kim', 'Young Min Bae', 'Young-wook Choi', 'Seungryong Cho', 'Jong Chul Ye']","Diffuse optical tomography (DOT) has been investigated as an alternative
imaging modality for breast cancer detection thanks to its excellent contrast
to hemoglobin oxidization level. However, due to the complicated non-linear
photon scattering physics and ill-posedness, the conventional reconstruction
algorithms are sensitive to imaging parameters such as boundary conditions. To
address this, here we propose a novel deep learning approach that learns
non-linear photon scattering physics and obtains an accurate three dimensional
(3D) distribution of optical anomalies. In contrast to the traditional
black-box deep learning approaches, our deep network is designed to invert the
Lippman-Schwinger integral equation using the recent mathematical theory of
deep convolutional framelets. As an example of clinical relevance, we applied
the method to our prototype DOT system. We show that our deep neural network,
trained with only simulation data, can accurately recover the location of
anomalies within biomimetic phantoms and live animals without the use of an
exogenous contrast agent.",2017-12-04T05:47:10Z,http://arxiv.org/pdf/1712.00912v2,"['cs.CV', 'cs.AI', 'cs.LG', 'stat.ML']"
1908.09963v2,Deep Learning-Based Average Consensus,"['Masako Kishida', 'Masaki Ogura', 'Yuichi Yoshida', 'Tadashi Wadayama']","In this study, we analyzed the problem of accelerating the linear average
consensus algorithm for complex networks. We propose a data-driven approach to
tuning the weights of temporal (i.e., time-varying) networks using deep
learning techniques. Given a finite-time window, the proposed approach first
unfolds the linear average consensus protocol to obtain a feedforward
signal-flow graph, which is regarded as a neural network. The edge weights of
the obtained neural network are then trained using standard deep learning
techniques to minimize consensus error over a given finite-time window. Through
this training process, we obtain a set of optimized time-varying weights, which
yield faster consensus for a complex network. We also demonstrate that the
proposed approach can be extended for infinite-time window problems. Numerical
experiments revealed that our approach can achieve a significantly smaller
consensus error compared to baseline strategies.",2019-08-27T00:20:48Z,http://arxiv.org/pdf/1908.09963v2,['math.OC']
2104.02395v3,Ensemble deep learning: A review,"['M. A. Ganaie', 'Minghui Hu', 'A. K. Malik', 'M. Tanveer', 'P. N. Suganthan']","Ensemble learning combines several individual models to obtain better
generalization performance. Currently, deep learning architectures are showing
better performance compared to the shallow or traditional models. Deep ensemble
learning models combine the advantages of both the deep learning models as well
as the ensemble learning such that the final model has better generalization
performance. This paper reviews the state-of-art deep ensemble models and hence
serves as an extensive summary for the researchers. The ensemble models are
broadly categorised into bagging, boosting, stacking, negative correlation
based deep ensemble models, explicit/implicit ensembles,
homogeneous/heterogeneous ensemble, decision fusion strategies based deep
ensemble models. Applications of deep ensemble models in different domains are
also briefly discussed. Finally, we conclude this paper with some potential
future research directions.",2021-04-06T09:56:29Z,http://arxiv.org/pdf/2104.02395v3,"['cs.LG', 'cs.AI', 'cs.CV']"
1802.05383v1,Deep Learning Based Speech Beamforming,"['Kaizhi Qian', 'Yang Zhang', 'Shiyu Chang', 'Xuesong Yang', 'Dinei Florencio', 'Mark Hasegawa-Johnson']","Multi-channel speech enhancement with ad-hoc sensors has been a challenging
task. Speech model guided beamforming algorithms are able to recover natural
sounding speech, but the speech models tend to be oversimplified or the
inference would otherwise be too complicated. On the other hand, deep learning
based enhancement approaches are able to learn complicated speech distributions
and perform efficient inference, but they are unable to deal with variable
number of input channels. Also, deep learning approaches introduce a lot of
errors, particularly in the presence of unseen noise types and settings. We
have therefore proposed an enhancement framework called DEEPBEAM, which
combines the two complementary classes of algorithms. DEEPBEAM introduces a
beamforming filter to produce natural sounding speech, but the filter
coefficients are determined with the help of a monaural speech enhancement
neural network. Experiments on synthetic and real-world data show that DEEPBEAM
is able to produce clean, dry and natural sounding speech, and is robust
against unseen noise.",2018-02-15T02:00:54Z,http://arxiv.org/pdf/1802.05383v1,"['cs.CL', 'cs.AI', 'cs.SD', 'eess.AS', 'eess.SP']"
1909.02730v1,Deep Learning for Spectrum Sensing,"['Jiabao Gao', 'Xuemei Yi', 'Caijun Zhong', 'Xiaoming Chen', 'Zhaoyang Zhang']","In cognitive radio systems, the ability to accurately detect primary user's
signal is essential to secondary user in order to utilize idle licensed
spectrum. Conventional energy detector is a good choice for blind signal
detection, while it suffers from the well-known SNR-wall due to noise
uncertainty. In this letter, we firstly propose a deep learning based signal
detector which exploits the underlying structural information of the modulated
signals, and is shown to achieve the state of the art detection performance,
requiring no prior knowledge about channel state information or background
noise. In addition, the impacts of modulation scheme and sample length on
performance are investigated. Finally, a deep learning based cooperative
detection system is proposed, which is shown to provide substantial performance
gain over conventional cooperative sensing methods.",2019-09-06T06:18:23Z,http://arxiv.org/pdf/1909.02730v1,"['cs.IT', 'eess.SP', 'math.IT']"
2002.12790v1,Entanglement-based quantum deep learning,"['Zhenwei Yang', 'Xiangdong Zhang']","Classical deep learning algorithms have aroused great interest in both
academia and industry for their utility in image recognition, language
translation, decision-making problems and more. In this work, we have provided
a quantum deep learning scheme based on multi-qubit entanglement states,
including computation and training of neural network in full quantum process.
In the course of training, efficient calculation of the distance between
unknown unit vector and known unit vector has been realized by proper
measurement based on the Greenberger-Horne-Zeilinger entanglement states. An
exponential speedup over classical algorithms has been demonstrated. In the
process of computation, quantum scheme corresponding to multi-layer feedforward
neural network has been provided. We have shown the utility of our scheme using
Iris dataset. The extensibility of the present scheme to different types of
model has also been analyzed",2020-02-27T09:14:00Z,http://arxiv.org/pdf/2002.12790v1,"['quant-ph', 'physics.optics']"
2302.08002v2,Deep Learning Enhanced Realized GARCH,"['Chen Liu', 'Chao Wang', 'Minh-Ngoc Tran', 'Robert Kohn']","We propose a new approach to volatility modeling by combining deep learning
(LSTM) and realized volatility measures. This LSTM-enhanced realized GARCH
framework incorporates and distills modeling advances from financial
econometrics, high frequency trading data and deep learning. Bayesian inference
via the Sequential Monte Carlo method is employed for statistical inference and
forecasting. The new framework can jointly model the returns and realized
volatility measures, has an excellent in-sample fit and superior predictive
performance compared to several benchmark models, while being able to adapt
well to the stylized facts in volatility. The performance of the new framework
is tested using a wide range of metrics, from marginal likelihood, volatility
forecasting, to tail risk forecasting and option pricing. We report on a
comprehensive empirical study using 31 widely traded stock indices over a time
period that includes COVID-19 pandemic.",2023-02-16T00:20:43Z,http://arxiv.org/pdf/2302.08002v2,"['econ.EM', 'cs.LG', 'q-fin.CP']"
2403.11958v1,Language Evolution with Deep Learning,"['Mathieu Rita', 'Paul Michel', 'Rahma Chaabouni', 'Olivier Pietquin', 'Emmanuel Dupoux', 'Florian Strub']","Computational modeling plays an essential role in the study of language
emergence. It aims to simulate the conditions and learning processes that could
trigger the emergence of a structured language within a simulated controlled
environment. Several methods have been used to investigate the origin of our
language, including agent-based systems, Bayesian agents, genetic algorithms,
and rule-based systems. This chapter explores another class of computational
models that have recently revolutionized the field of machine learning: deep
learning models. The chapter introduces the basic concepts of deep and
reinforcement learning methods and summarizes their helpfulness for simulating
language emergence. It also discusses the key findings, limitations, and recent
attempts to build realistic simulations. This chapter targets linguists and
cognitive scientists seeking an introduction to deep learning as a tool to
investigate language evolution.",2024-03-18T16:52:54Z,http://arxiv.org/pdf/2403.11958v1,"['cs.CL', 'cs.MA']"
2506.02796v1,Deep Learning Enhanced Multivariate GARCH,"['Haoyuan Wang', 'Chen Liu', 'Minh-Ngoc Tran', 'Chao Wang']","This paper introduces a novel multivariate volatility modeling framework,
named Long Short-Term Memory enhanced BEKK (LSTM-BEKK), that integrates deep
learning into multivariate GARCH processes. By combining the flexibility of
recurrent neural networks with the econometric structure of BEKK models, our
approach is designed to better capture nonlinear, dynamic, and high-dimensional
dependence structures in financial return data. The proposed model addresses
key limitations of traditional multivariate GARCH-based methods, particularly
in capturing persistent volatility clustering and asymmetric co-movement across
assets. Leveraging the data-driven nature of LSTMs, the framework adapts
effectively to time-varying market conditions, offering improved robustness and
forecasting performance. Empirical results across multiple equity markets
confirm that the LSTM-BEKK model achieves superior performance in terms of
out-of-sample portfolio risk forecast, while maintaining the interpretability
from the BEKK models. These findings highlight the potential of hybrid
econometric-deep learning models in advancing financial risk management and
multivariate volatility forecasting.",2025-06-03T12:22:57Z,http://arxiv.org/pdf/2506.02796v1,"['q-fin.CP', 'cs.AI', 'econ.EM']"
1708.07408v1,Quantum fields as deep learning,['Jae-Weon Lee'],"In this essay we conjecture that quantum fields such as the Higgs field is
related to a restricted Boltzmann machine for deep neural networks. An
accelerating Rindler observer in a flat spacetime sees the quantum fields
having a thermal distribution from the quantum entanglement, and a
renormalization group process for the thermal fields on a lattice is similar to
a deep learning algorithm.
  This correspondence can be generalized for the KMS states of quantum fields
in a curved spacetime like a black hole.",2017-08-18T17:43:30Z,http://arxiv.org/pdf/1708.07408v1,"['physics.gen-ph', 'hep-th']"
1812.06369v2,Provable limitations of deep learning,"['Emmanuel Abbe', 'Colin Sandon']","As the success of deep learning reaches more grounds, one would like to also
envision the potential limits of deep learning. This paper gives a first set of
results proving that certain deep learning algorithms fail at learning certain
efficiently learnable functions. The results put forward a notion of
cross-predictability that characterizes when such failures take place. Parity
functions provide an extreme example with a cross-predictability that decays
exponentially, while a mere super-polynomial decay of the cross-predictability
is shown to be sufficient to obtain failures. Examples in community detection
and arithmetic learning are also discussed.
  Recall that it is known that the class of neural networks (NNs) with
polynomial network size can express any function that can be implemented in
polynomial time, and that their sample complexity scales polynomially with the
network size. The challenge is with the optimization error (the ERM is
NP-hard), and the success behind deep learning is to train deep NNs with
descent algorithms. The failures shown in this paper apply to training
poly-size NNs on function distributions of low cross-predictability with a
descent algorithm that is either run with limited memory per sample or that is
initialized and run with enough randomness. We further claim that such types of
constraints are necessary to obtain failures, in that exact SGD with careful
non-random initialization can be shown to learn parities. The
cross-predictability in our results plays a similar role the statistical
dimension in statistical query (SQ) algorithms, with distinctions explained in
the paper. The proof techniques are based on exhibiting algorithmic constraints
that imply a statistical indistinguishability between the algorithm's output on
the test model v.s.\ a null model, using information measures to bound the
total variation distance.",2018-12-16T00:10:08Z,http://arxiv.org/pdf/1812.06369v2,"['cs.LG', 'cs.CC', 'cs.IT', 'math.IT', 'stat.ML']"
2009.05426v4,Semantic Relations and Deep Learning,"['Vivi Nastase', 'Stan Szpakowicz']","The second edition of ""Semantic Relations Between Nominals"" by Vivi Nastase,
Stan Szpakowicz, Preslav Nakov and Diarmuid \'O S\'eaghdha has been published
in April 2021 by Morgan & Claypool
(www.morganclaypoolpublishers.com/catalog_Orig/product_info.php?products_id=1627).
A new Chapter 5 of the book, by Vivi Nastase and Stan Szpakowicz, discusses
relation classification/extraction in the deep-learning paradigm which arose
after the first edition appeared. This is Chapter 5, made public by the kind
permission of Morgan & Claypool.",2020-09-11T13:21:28Z,http://arxiv.org/pdf/2009.05426v4,"['cs.CL', 'I.2.7; H.3.3']"
2202.12348v1,Bayesian Deep Learning for Graphs,['Federico Errica'],"The adaptive processing of structured data is a long-standing research topic
in machine learning that investigates how to automatically learn a mapping from
a structured input to outputs of various nature. Recently, there has been an
increasing interest in the adaptive processing of graphs, which led to the
development of different neural network-based methodologies. In this thesis, we
take a different route and develop a Bayesian Deep Learning framework for graph
learning. The dissertation begins with a review of the principles over which
most of the methods in the field are built, followed by a study on graph
classification reproducibility issues. We then proceed to bridge the basic
ideas of deep learning for graphs with the Bayesian world, by building our deep
architectures in an incremental fashion. This framework allows us to consider
graphs with discrete and continuous edge features, producing unsupervised
embeddings rich enough to reach the state of the art on several classification
tasks. Our approach is also amenable to a Bayesian nonparametric extension that
automatizes the choice of almost all model's hyper-parameters. Two real-world
applications demonstrate the efficacy of deep learning for graphs. The first
concerns the prediction of information-theoretic quantities for molecular
simulations with supervised neural models. After that, we exploit our Bayesian
models to solve a malware-classification task while being robust to
intra-procedural code obfuscation techniques. We conclude the dissertation with
an attempt to blend the best of the neural and Bayesian worlds together. The
resulting hybrid model is able to predict multimodal distributions conditioned
on input graphs, with the consequent ability to model stochasticity and
uncertainty better than most works. Overall, we aim to provide a Bayesian
perspective into the articulated research field of deep learning for graphs.",2022-02-24T20:18:41Z,http://arxiv.org/pdf/2202.12348v1,"['cs.LG', 'cs.AI', 'stat.ML']"
1501.03084v1,Deep Learning with Nonparametric Clustering,['Gang Chen'],"Clustering is an essential problem in machine learning and data mining. One
vital factor that impacts clustering performance is how to learn or design the
data representation (or features). Fortunately, recent advances in deep
learning can learn unsupervised features effectively, and have yielded state of
the art performance in many classification problems, such as character
recognition, object recognition and document categorization. However, little
attention has been paid to the potential of deep learning for unsupervised
clustering problems. In this paper, we propose a deep belief network with
nonparametric clustering. As an unsupervised method, our model first leverages
the advantages of deep learning for feature representation and dimension
reduction. Then, it performs nonparametric clustering under a maximum margin
framework -- a discriminative clustering model and can be trained online
efficiently in the code space. Lastly model parameters are refined in the deep
belief network. Thus, this model can learn features for clustering and infer
model complexity in an unified framework. The experimental results show the
advantage of our approach over competitive baselines.",2015-01-13T17:26:26Z,http://arxiv.org/pdf/1501.03084v1,"['cs.LG', '68T10', 'I.2.6']"
1809.10410v1,Image Reconstruction Using Deep Learning,"['Po-Yu Liu', 'Edmund Y. Lam']","This paper proposes a deep learning architecture that attains statistically
significant improvements over traditional algorithms in Poisson image denoising
espically when the noise is strong. Poisson noise commonly occurs in low-light
and photon- limited settings, where the noise can be most accurately modeled by
the Poission distribution. Poisson noise traditionally prevails only in
specific fields such as astronomical imaging. However, with the booming market
of surveillance cameras, which commonly operate in low-light environments, or
mobile phones, which produce noisy night scene pictures due to lower-grade
sensors, the necessity for an advanced Poisson image denoising algorithm has
increased. Deep learning has achieved amazing breakthroughs in other imaging
problems, such image segmentation and recognition, and this paper proposes a
deep learning denoising network that outperforms traditional algorithms in
Poisson denoising especially when the noise is strong. The architecture
incorporates a hybrid of convolutional and deconvolutional layers along with
symmetric connections. The denoising network achieved statistically significant
0.38dB, 0.68dB, and 1.04dB average PSNR gains over benchmark traditional
algorithms in experiments with image peak values 4, 2, and 1. The denoising
network can also operate with shorter computational time while still
outperforming the benchmark algorithm by tuning the reconstruction stride
sizes.",2018-09-27T08:58:38Z,http://arxiv.org/pdf/1809.10410v1,['cs.CV']
2005.06540v1,Deep Learning for Political Science,"['Kakia Chatsiou', 'Slava Jankin Mikhaylov']","Political science, and social science in general, have traditionally been
using computational methods to study areas such as voting behavior, policy
making, international conflict, and international development. More recently,
increasingly available quantities of data are being combined with improved
algorithms and affordable computational resources to predict, learn, and
discover new insights from data that is large in volume and variety. New
developments in the areas of machine learning, deep learning, natural language
processing (NLP), and, more generally, artificial intelligence (AI) are opening
up new opportunities for testing theories and evaluating the impact of
interventions and programs in a more dynamic and effective way. Applications
using large volumes of structured and unstructured data are becoming common in
government and industry, and increasingly also in social science research. This
chapter offers an introduction to such methods drawing examples from political
science. Focusing on the areas where the strengths of the methods coincide with
challenges in these fields, the chapter first presents an introduction to AI
and its core technology - machine learning, with its rapidly developing
subfield of deep learning. The discussion of deep neural networks is
illustrated with the NLP tasks that are relevant to political science. The
latest advances in deep learning methods for NLP are also reviewed, together
with their potential for improving information extraction and pattern
recognition from political science texts.",2020-05-13T19:14:37Z,http://arxiv.org/pdf/2005.06540v1,"['cs.CL', 'cs.LG']"
2202.14005v2,"Deep, Deep Learning with BART","['Moritz Blumenthal', 'Guanxiong Luo', 'Martin Schilling', 'H. Christian M. Holme', 'Martin Uecker']","Purpose: To develop a deep-learning-based image reconstruction framework for
reproducible research in MRI.
  Methods: The BART toolbox offers a rich set of implementations of calibration
and reconstruction algorithms for parallel imaging and compressed sensing. In
this work, BART was extended by a non-linear operator framework that provides
automatic differentiation to allow computation of gradients. Existing
MRI-specific operators of BART, such as the non-uniform fast Fourier transform,
are directly integrated into this framework and are complemented by common
building blocks used in neural networks. To evaluate the use of the framework
for advanced deep-learning-based reconstruction, two state-of-the-art unrolled
reconstruction networks, namely the Variational Network [1] and MoDL [2], were
implemented.
  Results: State-of-the-art deep image-reconstruction networks can be
constructed and trained using BART's gradient based optimization algorithms.
The BART implementation achieves a similar performance in terms of training
time and reconstruction quality compared to the original implementations based
on TensorFlow.
  Conclusion: By integrating non-linear operators and neural networks into
BART, we provide a general framework for deep-learning-based reconstruction in
MRI.",2022-02-28T18:23:41Z,http://arxiv.org/pdf/2202.14005v2,"['cs.CV', 'eess.SP']"
1910.14215v2,Multivariate Uncertainty in Deep Learning,"['Rebecca L. Russell', 'Christopher Reale']","Deep learning has the potential to dramatically impact navigation and
tracking state estimation problems critical to autonomous vehicles and
robotics. Measurement uncertainties in state estimation systems based on Kalman
and other Bayes filters are typically assumed to be a fixed covariance matrix.
This assumption is risky, particularly for ""black box"" deep learning models, in
which uncertainty can vary dramatically and unexpectedly. Accurate
quantification of multivariate uncertainty will allow for the full potential of
deep learning to be used more safely and reliably in these applications. We
show how to model multivariate uncertainty for regression problems with neural
networks, incorporating both aleatoric and epistemic sources of heteroscedastic
uncertainty. We train a deep uncertainty covariance matrix model in two ways:
directly using a multivariate Gaussian density loss function, and indirectly
using end-to-end training through a Kalman filter. We experimentally show in a
visual tracking problem the large impact that accurate multivariate uncertainty
quantification can have on Kalman filter performance for both in-domain and
out-of-domain evaluation data. We additionally show in a challenging visual
odometry problem how end-to-end filter training can allow uncertainty
predictions to compensate for filter weaknesses.",2019-10-31T02:25:16Z,http://arxiv.org/pdf/1910.14215v2,"['cs.LG', 'cs.NE', 'cs.RO', 'stat.ML']"
2012.04115v2,Generalization bounds for deep learning,"['Guillermo Valle-Pérez', 'Ard A. Louis']","Generalization in deep learning has been the topic of much recent theoretical
and empirical research. Here we introduce desiderata for techniques that
predict generalization errors for deep learning models in supervised learning.
Such predictions should 1) scale correctly with data complexity; 2) scale
correctly with training set size; 3) capture differences between architectures;
4) capture differences between optimization algorithms; 5) be quantitatively
not too far from the true error (in particular, be non-vacuous); 6) be
efficiently computable; and 7) be rigorous. We focus on generalization error
upper bounds, and introduce a categorisation of bounds depending on assumptions
on the algorithm and data. We review a wide range of existing approaches, from
classical VC dimension to recent PAC-Bayesian bounds, commenting on how well
they perform against the desiderata.
  We next use a function-based picture to derive a marginal-likelihood
PAC-Bayesian bound. This bound is, by one definition, optimal up to a
multiplicative constant in the asymptotic limit of large training sets, as long
as the learning curve follows a power law, which is typically found in practice
for deep learning problems. Extensive empirical analysis demonstrates that our
marginal-likelihood PAC-Bayes bound fulfills desiderata 1-3 and 5. The results
for 6 and 7 are promising, but not yet fully conclusive, while only desideratum
4 is currently beyond the scope of our bound. Finally, we comment on why this
function-based bound performs significantly better than current parameter-based
PAC-Bayes bounds.",2020-12-07T23:45:09Z,http://arxiv.org/pdf/2012.04115v2,"['stat.ML', 'cs.AI', 'cs.LG', 'cs.NE']"
2211.14395v1,Deep Learning Training Procedure Augmentations,['Cristian Simionescu'],"Recent advances in Deep Learning have greatly improved performance on various
tasks such as object detection, image segmentation, sentiment analysis. The
focus of most research directions up until very recently has been on beating
state-of-the-art results. This has materialized in the utilization of bigger
and bigger models and techniques which help the training procedure to extract
more predictive power out of a given dataset. While this has lead to great
results, many of which with real-world applications, other relevant aspects of
deep learning have remained neglected and unknown. In this work, we will
present several novel deep learning training techniques which, while capable of
offering significant performance gains they also reveal several interesting
analysis results regarding convergence speed, optimization landscape
smoothness, and adversarial robustness. The methods presented in this work are
the following:
  $\bullet$ Perfect Ordering Approximation; a generalized model agnostic
curriculum learning approach. The results show the effectiveness of the
technique for improving training time as well as offer some new insight into
the training process of deep networks.
  $\bullet$ Cascading Sum Augmentation; an extension of mixup capable of
utilizing more data points for linear interpolation by leveraging a smoother
optimization landscape. This can be used for computer vision tasks in order to
improve both prediction performance as well as improve passive model
robustness.",2022-11-25T22:31:11Z,http://arxiv.org/pdf/2211.14395v1,"['cs.CV', 'cs.AI', 'cs.LG']"
2504.05355v2,Deep Learning for Double Auction,"['Jiayin Liu', 'Chenglong Zhang']","Auctions are important mechanisms extensively implemented in various markets,
e.g., search engines' keyword auctions, antique auctions, etc. Finding an
optimal auction mechanism is extremely difficult due to the constraints of
imperfect information, incentive compatibility (IC), and individual rationality
(IR). In addition to the traditional economic methods, some recently attempted
to find the optimal (single) auction using deep learning methods. Unlike those
attempts focusing on single auctions, we develop deep learning methods for
double auctions, where imperfect information exists on both the demand and
supply sides. The previous attempts on single auction cannot directly apply to
our contexts and those attempts additionally suffer from limited
generalizability, inefficiency in ensuring the constraints, and learning
fluctuations. We innovate in designing deep learning models for solving the
more complex problem and additionally addressing the previous models' three
limitations. Specifically, we achieve generalizability by leveraging a
transformer-based architecture to model market participants as sequences for
varying market sizes; we utilize the numerical features of the constraints and
pre-treat them for a higher learning efficiency; we develop a
gradient-conflict-elimination scheme to address the problem of learning
fluctuation. Extensive experimental evaluations demonstrate the superiority of
our approach to classical and machine learning baselines.",2025-04-07T08:56:32Z,http://arxiv.org/pdf/2504.05355v2,"['cs.LG', 'cs.GT', 'econ.TH']"
2507.13399v1,Selective Embedding for Deep Learning,"['Mert Sehri', 'Zehui Hua', 'Francisco de Assis Boldt', 'Patrick Dumond']","Deep learning has revolutionized many industries by enabling models to
automatically learn complex patterns from raw data, reducing dependence on
manual feature engineering. However, deep learning algorithms are sensitive to
input data, and performance often deteriorates under nonstationary conditions
and across dissimilar domains, especially when using time-domain data.
Conventional single-channel or parallel multi-source data loading strategies
either limit generalization or increase computational costs. This study
introduces selective embedding, a novel data loading strategy, which alternates
short segments of data from multiple sources within a single input channel.
Drawing inspiration from cognitive psychology, selective embedding mimics
human-like information processing to reduce model overfitting, enhance
generalization, and improve computational efficiency. Validation is conducted
using six time-domain datasets, demonstrating that the proposed method
consistently achieves high classification accuracy across various deep learning
architectures while significantly reducing training times. The approach proves
particularly effective for complex systems with multiple data sources, offering
a scalable and resource-efficient solution for real-world applications in
healthcare, heavy machinery, marine, railway, and agriculture, where robustness
and adaptability are critical.",2025-07-16T15:45:01Z,http://arxiv.org/pdf/2507.13399v1,['cs.LG']
1805.08355v1,Opening the black box of deep learning,"['Dian Lei', 'Xiaoxiao Chen', 'Jianfei Zhao']","The great success of deep learning shows that its technology contains
profound truth, and understanding its internal mechanism not only has important
implications for the development of its technology and effective application in
various fields, but also provides meaningful insights into the understanding of
human brain mechanism. At present, most of the theoretical research on deep
learning is based on mathematics. This dissertation proposes that the neural
network of deep learning is a physical system, examines deep learning from
three different perspectives: microscopic, macroscopic, and physical world
views, answers multiple theoretical puzzles in deep learning by using physics
principles. For example, from the perspective of quantum mechanics and
statistical physics, this dissertation presents the calculation methods for
convolution calculation, pooling, normalization, and Restricted Boltzmann
Machine, as well as the selection of cost functions, explains why deep learning
must be deep, what characteristics are learned in deep learning, why
Convolutional Neural Networks do not have to be trained layer by layer, and the
limitations of deep learning, etc., and proposes the theoretical direction and
basis for the further development of deep learning now and in the future. The
brilliance of physics flashes in deep learning, we try to establish the deep
learning technology based on the scientific theory of physics.",2018-05-22T02:12:33Z,http://arxiv.org/pdf/1805.08355v1,"['cs.LG', 'stat.ML']"
1711.11008v1,Security Risks in Deep Learning Implementations,"['Qixue Xiao', 'Kang Li', 'Deyue Zhang', 'Weilin Xu']","Advance in deep learning algorithms overshadows their security risk in
software implementations. This paper discloses a set of vulnerabilities in
popular deep learning frameworks including Caffe, TensorFlow, and Torch.
Contrast to the small code size of deep learning models, these deep learning
frameworks are complex and contain heavy dependencies on numerous open source
packages. This paper considers the risks caused by these vulnerabilities by
studying their impact on common deep learning applications such as voice
recognition and image classifications. By exploiting these framework
implementations, attackers can launch denial-of-service attacks that crash or
hang a deep learning application, or control-flow hijacking attacks that cause
either system compromise or recognition evasions. The goal of this paper is to
draw attention on the software implementations and call for the community
effort to improve the security of deep learning frameworks.",2017-11-29T18:33:27Z,http://arxiv.org/pdf/1711.11008v1,['cs.CR']
1908.08843v2,Fairness in Deep Learning: A Computational Perspective,"['Mengnan Du', 'Fan Yang', 'Na Zou', 'Xia Hu']","Deep learning is increasingly being used in high-stake decision making
applications that affect individual lives. However, deep learning models might
exhibit algorithmic discrimination behaviors with respect to protected groups,
potentially posing negative impacts on individuals and society. Therefore,
fairness in deep learning has attracted tremendous attention recently. We
provide a review covering recent progresses to tackle algorithmic fairness
problems of deep learning from the computational perspective. Specifically, we
show that interpretability can serve as a useful ingredient to diagnose the
reasons that lead to algorithmic discrimination. We also discuss fairness
mitigation approaches categorized according to three stages of deep learning
life-cycle, aiming to push forward the area of fairness in deep learning and
build genuinely fair and reliable deep learning systems.",2019-08-23T14:38:07Z,http://arxiv.org/pdf/1908.08843v2,"['cs.LG', 'cs.AI', 'cs.CY', 'stat.ML']"
2103.09177v1,Deep learning: a statistical viewpoint,"['Peter L. Bartlett', 'Andrea Montanari', 'Alexander Rakhlin']","The remarkable practical success of deep learning has revealed some major
surprises from a theoretical perspective. In particular, simple gradient
methods easily find near-optimal solutions to non-convex optimization problems,
and despite giving a near-perfect fit to training data without any explicit
effort to control model complexity, these methods exhibit excellent predictive
accuracy. We conjecture that specific principles underlie these phenomena: that
overparametrization allows gradient methods to find interpolating solutions,
that these methods implicitly impose regularization, and that
overparametrization leads to benign overfitting. We survey recent theoretical
progress that provides examples illustrating these principles in simpler
settings. We first review classical uniform convergence results and why they
fall short of explaining aspects of the behavior of deep learning methods. We
give examples of implicit regularization in simple settings, where gradient
methods lead to minimal norm functions that perfectly fit the training data.
Then we review prediction methods that exhibit benign overfitting, focusing on
regression problems with quadratic loss. For these methods, we can decompose
the prediction rule into a simple component that is useful for prediction and a
spiky component that is useful for overfitting but, in a favorable setting,
does not harm prediction accuracy. We focus specifically on the linear regime
for neural networks, where the network can be approximated by a linear model.
In this regime, we demonstrate the success of gradient flow, and we consider
benign overfitting with two-layer networks, giving an exact asymptotic analysis
that precisely demonstrates the impact of overparametrization. We conclude by
highlighting the key challenges that arise in extending these insights to
realistic deep learning settings.",2021-03-16T16:26:36Z,http://arxiv.org/pdf/2103.09177v1,"['math.ST', 'cs.LG', 'stat.ML', 'stat.TH']"
1306.0543v2,Predicting Parameters in Deep Learning,"['Misha Denil', 'Babak Shakibi', 'Laurent Dinh', ""Marc'Aurelio Ranzato"", 'Nando de Freitas']","We demonstrate that there is significant redundancy in the parameterization
of several deep learning models. Given only a few weight values for each
feature it is possible to accurately predict the remaining values. Moreover, we
show that not only can the parameter values be predicted, but many of them need
not be learned at all. We train several different architectures by learning
only a small number of weights and predicting the rest. In the best case we are
able to predict more than 95% of the weights of a network without any drop in
accuracy.",2013-06-03T19:16:26Z,http://arxiv.org/pdf/1306.0543v2,"['cs.LG', 'cs.NE', 'stat.ML']"
1705.10342v1,Deep Learning for Ontology Reasoning,"['Patrick Hohenecker', 'Thomas Lukasiewicz']","In this work, we present a novel approach to ontology reasoning that is based
on deep learning rather than logic-based formal reasoning. To this end, we
introduce a new model for statistical relational learning that is built upon
deep recursive neural networks, and give experimental evidence that it can
easily compete with, or even outperform, existing logic-based reasoners on the
task of ontology reasoning. More precisely, we compared our implemented system
with one of the best logic-based ontology reasoners at present, RDFox, on a
number of large standard benchmark datasets, and found that our system attained
high reasoning quality, while being up to two orders of magnitude faster.",2017-05-29T18:17:52Z,http://arxiv.org/pdf/1705.10342v1,"['cs.AI', 'cs.LG']"
1808.01174v3,Generalization Error in Deep Learning,"['Daniel Jakubovitz', 'Raja Giryes', 'Miguel R. D. Rodrigues']","Deep learning models have lately shown great performance in various fields
such as computer vision, speech recognition, speech translation, and natural
language processing. However, alongside their state-of-the-art performance, it
is still generally unclear what is the source of their generalization ability.
Thus, an important question is what makes deep neural networks able to
generalize well from the training set to new data. In this article, we provide
an overview of the existing theory and bounds for the characterization of the
generalization error of deep neural networks, combining both classical and more
recent theoretical and empirical results.",2018-08-03T12:57:12Z,http://arxiv.org/pdf/1808.01174v3,"['cs.LG', 'cs.AI', 'stat.ML']"
1812.01478v1,Matrix Factorization via Deep Learning,"['Duc Minh Nguyen', 'Evaggelia Tsiligianni', 'Nikos Deligiannis']","Matrix completion is one of the key problems in signal processing and machine
learning. In recent years, deep-learning-based models have achieved
state-of-the-art results in matrix completion. Nevertheless, they suffer from
two drawbacks: (i) they can not be extended easily to rows or columns unseen
during training; and (ii) their results are often degraded in case discrete
predictions are required. This paper addresses these two drawbacks by
presenting a deep matrix factorization model and a generic method to allow
joint training of the factorization model and the discretization operator.
Experiments on a real movie rating dataset show the efficacy of the proposed
models.",2018-12-04T15:15:23Z,http://arxiv.org/pdf/1812.01478v1,"['cs.LG', 'stat.ML']"
1908.07017v1,Optical deep learning nano-profilometry,"['Jinlong Zhu', 'Yanan Liu', 'Sanyogita Purandare', 'Jian-Ming Jin', 'Shiyuan Liu', 'Lynford L. Goddard']","Determining the dimensions of nanostructures is critical to ensuring the
maximum performance of many geometry-sensitive nanoscale functional devices.
However, accurate metrology at the nanoscale is difficult using optics-based
methods due to the diffraction limit. In this article, we propose an optical
nano-profilometry framework with convolutional neural networks, which can
retrieve deep sub-wavelength geometrical profiles of nanostructures from their
optical images or scattering spectra. The generality, efficiency, and accuracy
of the proposed framework are validated by performing two different
measurements on three distinct nanostructures. We believe this work may
catalyze more explorations of optics-based nano-metrology with deep learning.",2019-07-24T20:15:08Z,http://arxiv.org/pdf/1908.07017v1,"['physics.app-ph', 'physics.optics', '83C50, 78A45, 78A46']"
2006.02734v2,Robust Sampling in Deep Learning,"['Aurora Cobo Aguilera', 'Antonio Artés-Rodríguez', 'Fernando Pérez-Cruz', 'Pablo Martínez Olmos']","Deep learning requires regularization mechanisms to reduce overfitting and
improve generalization. We address this problem by a new regularization method
based on distributional robust optimization. The key idea is to modify the
contribution from each sample for tightening the empirical risk bound. During
the stochastic training, the selection of samples is done according to their
accuracy in such a way that the worst performed samples are the ones that
contribute the most in the optimization. We study different scenarios and show
the ones where it can make the convergence faster or increase the accuracy.",2020-06-04T09:46:52Z,http://arxiv.org/pdf/2006.02734v2,"['cs.LG', 'stat.ML']"
1910.06789v1,Deep learning for Aerosol Forecasting,"['Caleb Hoyne', 'S. Karthik Mukkavilli', 'David Meger']","Reanalysis datasets combining numerical physics models and limited
observations to generate a synthesised estimate of variables in an Earth
system, are prone to biases against ground truth. Biases identified with the
NASA Modern-Era Retrospective Analysis for Research and Applications, Version 2
(MERRA-2) aerosol optical depth (AOD) dataset, against the Aerosol Robotic
Network (AERONET) ground measurements in previous studies, motivated the
development of a deep learning based AOD prediction model globally. This study
combines a convolutional neural network (CNN) with MERRA-2, tested against all
AERONET sites. The new hybrid CNN-based model provides better estimates
validated versus AERONET ground truth, than only using MERRA-2 reanalysis.",2019-10-14T17:35:08Z,http://arxiv.org/pdf/1910.06789v1,"['cs.LG', 'cs.CV', 'physics.ao-ph', 'physics.data-an', 'stat.ML']"
2002.11835v1,Tensor Decompositions in Deep Learning,"['Davide Bacciu', 'Danilo P. Mandic']","The paper surveys the topic of tensor decompositions in modern machine
learning applications. It focuses on three active research topics of
significant relevance for the community. After a brief review of consolidated
works on multi-way data analysis, we consider the use of tensor decompositions
in compressing the parameter space of deep learning models. Lastly, we discuss
how tensor methods can be leveraged to yield richer adaptive representations of
complex data, including structured information. The paper concludes with a
discussion on interesting open research challenges.",2020-02-26T23:07:19Z,http://arxiv.org/pdf/2002.11835v1,"['cs.LG', 'stat.ML']"
1806.07908v1,Como funciona o Deep Learning,"['Moacir Antonelli Ponti', 'Gabriel B. Paranhos da Costa']","Deep Learning methods are currently the state-of-the-art in many problems
which can be tackled via machine learning, in particular classification
problems. However there is still lack of understanding on how those methods
work, why they work and what are the limitations involved in using them. In
this chapter we will describe in detail the transition from shallow to deep
networks, include examples of code on how to implement them, as well as the
main issues one faces when training a deep network. Afterwards, we introduce
some theoretical background behind the use of deep models, and discuss their
limitations.",2018-06-20T18:04:09Z,http://arxiv.org/pdf/1806.07908v1,"['cs.LG', 'cs.CV', 'stat.ML']"
2201.01869v1,Earthquake Nowcasting with Deep Learning,"['Geoffrey Fox', 'John Rundle', 'Andrea Donnellan', 'Bo Feng']","We review previous approaches to nowcasting earthquakes and introduce new
approaches based on deep learning using three distinct models based on
recurrent neural networks and transformers. We discuss different choices for
observables and measures presenting promising initial results for a region of
Southern California from 1950-2020. Earthquake activity is predicted as a
function of 0.1-degree spatial bins for time periods varying from two weeks to
four years. The overall quality is measured by the Nash Sutcliffe Efficiency
comparing the deviation of nowcast and observation with the variance over time
in each spatial region. The software is available as open-source together with
the preprocessed data from the USGS.",2021-12-18T16:55:59Z,http://arxiv.org/pdf/2201.01869v1,"['physics.geo-ph', 'cs.LG']"
2303.15464v1,Mathematical Challenges in Deep Learning,"['Vahid Partovi Nia', 'Guojun Zhang', 'Ivan Kobyzev', 'Michael R. Metel', 'Xinlin Li', 'Ke Sun', 'Sobhan Hemati', 'Masoud Asgharian', 'Linglong Kong', 'Wulong Liu', 'Boxing Chen']","Deep models are dominating the artificial intelligence (AI) industry since
the ImageNet challenge in 2012. The size of deep models is increasing ever
since, which brings new challenges to this field with applications in cell
phones, personal computers, autonomous cars, and wireless base stations. Here
we list a set of problems, ranging from training, inference, generalization
bound, and optimization with some formalism to communicate these challenges
with mathematicians, statisticians, and theoretical computer scientists. This
is a subjective view of the research questions in deep learning that benefits
the tech industry in long run.",2023-03-24T20:12:27Z,http://arxiv.org/pdf/2303.15464v1,"['cs.LG', 'cs.AI', 'math.ST', 'stat.ML', 'stat.TH']"
1605.01369v2,Accelerating Deep Learning with Shrinkage and Recall,"['Shuai Zheng', 'Abhinav Vishnu', 'Chris Ding']","Deep Learning is a very powerful machine learning model. Deep Learning trains
a large number of parameters for multiple layers and is very slow when data is
in large scale and the architecture size is large. Inspired from the shrinking
technique used in accelerating computation of Support Vector Machines (SVM)
algorithm and screening technique used in LASSO, we propose a shrinking Deep
Learning with recall (sDLr) approach to speed up deep learning computation. We
experiment shrinking Deep Learning with recall (sDLr) using Deep Neural Network
(DNN), Deep Belief Network (DBN) and Convolution Neural Network (CNN) on 4 data
sets. Results show that the speedup using shrinking Deep Learning with recall
(sDLr) can reach more than 2.0 while still giving competitive classification
performance.",2016-05-04T18:17:37Z,http://arxiv.org/pdf/1605.01369v2,"['cs.LG', 'cs.CV', 'cs.NE']"
1908.10206v1,The many faces of deep learning,['Raul Vicente'],"Deep learning has sparked a network of mutual interactions between different
disciplines and AI. Naturally, each discipline focuses and interprets the
workings of deep learning in different ways. This diversity of perspectives on
deep learning, from neuroscience to statistical physics, is a rich source of
inspiration that fuels novel developments in the theory and applications of
machine learning. In this perspective, we collect and synthesize different
intuitions scattered across several communities as for how deep learning works.
In particular, we will briefly discuss the different perspectives that
disciplines across mathematics, physics, computation, and neuroscience take on
how deep learning does its tricks. Our discussion on each perspective is
necessarily shallow due to the multiple views that had to be covered. The
deepness in this case should come from putting all these faces of deep learning
together in the reader's mind, so that one can look at the same problem from
different angles.",2019-08-25T12:04:49Z,http://arxiv.org/pdf/1908.10206v1,"['cs.LG', 'physics.data-an', 'q-bio.NC', 'stat.ML']"
1807.08169v1,Recent Advances in Deep Learning: An Overview,"['Matiur Rahman Minar', 'Jibon Naher']","Deep Learning is one of the newest trends in Machine Learning and Artificial
Intelligence research. It is also one of the most popular scientific research
trends now-a-days. Deep learning methods have brought revolutionary advances in
computer vision and machine learning. Every now and then, new and new deep
learning techniques are being born, outperforming state-of-the-art machine
learning and even existing deep learning techniques. In recent years, the world
has seen many major breakthroughs in this field. Since deep learning is
evolving at a huge speed, its kind of hard to keep track of the regular
advances especially for new researchers. In this paper, we are going to briefly
discuss about recent advances in Deep Learning for past few years.",2018-07-21T15:40:10Z,http://arxiv.org/pdf/1807.08169v1,"['cs.LG', 'cs.AI', 'stat.ML']"
2010.05125v2,Learning Task-aware Robust Deep Learning Systems,"['Keji Han', 'Yun Li', 'Xianzhong Long', 'Yao Ge']","Many works demonstrate that deep learning system is vulnerable to adversarial
attack. A deep learning system consists of two parts: the deep learning task
and the deep model. Nowadays, most existing works investigate the impact of the
deep model on robustness of deep learning systems, ignoring the impact of the
learning task. In this paper, we adopt the binary and interval label encoding
strategy to redefine the classification task and design corresponding loss to
improve robustness of the deep learning system. Our method can be viewed as
improving the robustness of deep learning systems from both the learning task
and deep model. Experimental results demonstrate that our learning task-aware
method is much more robust than traditional classification while retaining the
accuracy.",2020-10-11T01:06:49Z,http://arxiv.org/pdf/2010.05125v2,"['cs.LG', 'cs.AI', 'stat.ML']"
2204.01942v1,Fault-Tolerant Deep Learning: A Hierarchical Perspective,"['Cheng Liu', 'Zhen Gao', 'Siting Liu', 'Xuefei Ning', 'Huawei Li', 'Xiaowei Li']","With the rapid advancements of deep learning in the past decade, it can be
foreseen that deep learning will be continuously deployed in more and more
safety-critical applications such as autonomous driving and robotics. In this
context, reliability turns out to be critical to the deployment of deep
learning in these applications and gradually becomes a first-class citizen
among the major design metrics like performance and energy efficiency.
Nevertheless, the back-box deep learning models combined with the diverse
underlying hardware faults make resilient deep learning extremely challenging.
In this special session, we conduct a comprehensive survey of fault-tolerant
deep learning design approaches with a hierarchical perspective and investigate
these approaches from model layer, architecture layer, circuit layer, and cross
layer respectively.",2022-04-05T02:31:18Z,http://arxiv.org/pdf/2204.01942v1,"['cs.AR', 'cs.AI', 'cs.LG', 'B.2.3; B.8.1']"
2210.05866v1,Deep Learning for Iris Recognition: A Survey,"['Kien Nguyen', 'Hugo Proença', 'Fernando Alonso-Fernandez']","In this survey, we provide a comprehensive review of more than 200 papers,
technical reports, and GitHub repositories published over the last 10 years on
the recent developments of deep learning techniques for iris recognition,
covering broad topics on algorithm designs, open-source tools, open challenges,
and emerging research. First, we conduct a comprehensive analysis of deep
learning techniques developed for two main sub-tasks in iris biometrics:
segmentation and recognition. Second, we focus on deep learning techniques for
the robustness of iris recognition systems against presentation attacks and via
human-machine pairing. Third, we delve deep into deep learning techniques for
forensic application, especially in post-mortem iris recognition. Fourth, we
review open-source resources and tools in deep learning techniques for iris
recognition. Finally, we highlight the technical challenges, emerging research
trends, and outlook for the future of deep learning in iris recognition.",2022-10-12T01:58:09Z,http://arxiv.org/pdf/2210.05866v1,"['cs.CV', 'cs.AI']"
1312.5355v1,Generative NeuroEvolution for Deep Learning,"['Phillip Verbancsics', 'Josh Harguess']","An important goal for the machine learning (ML) community is to create
approaches that can learn solutions with human-level capability. One domain
where humans have held a significant advantage is visual processing. A
significant approach to addressing this gap has been machine learning
approaches that are inspired from the natural systems, such as artificial
neural networks (ANNs), evolutionary computation (EC), and generative and
developmental systems (GDS). Research into deep learning has demonstrated that
such architectures can achieve performance competitive with humans on some
visual tasks; however, these systems have been primarily trained through
supervised and unsupervised learning algorithms. Alternatively, research is
showing that evolution may have a significant role in the development of visual
systems. Thus this paper investigates the role neuro-evolution (NE) can take in
deep learning. In particular, the Hypercube-based NeuroEvolution of Augmenting
Topologies is a NE approach that can effectively learn large neural structures
by training an indirect encoding that compresses the ANN weight pattern as a
function of geometry. The results show that HyperNEAT struggles with performing
image classification by itself, but can be effective in training a feature
extractor that other ML approaches can learn from. Thus NeuroEvolution combined
with other ML methods provides an intriguing area of research that can
replicate the processes in nature.",2013-12-18T22:14:31Z,http://arxiv.org/pdf/1312.5355v1,"['cs.NE', 'cs.CV']"
1507.04761v1,Deep Learning and Music Adversaries,"['Corey Kereliuk', 'Bob L. Sturm', 'Jan Larsen']","An adversary is essentially an algorithm intent on making a classification
system perform in some particular way given an input, e.g., increase the
probability of a false negative. Recent work builds adversaries for deep
learning systems applied to image object recognition, which exploits the
parameters of the system to find the minimal perturbation of the input image
such that the network misclassifies it with high confidence. We adapt this
approach to construct and deploy an adversary of deep learning systems applied
to music content analysis. In our case, however, the input to the systems is
magnitude spectral frames, which requires special care in order to produce
valid input audio signals from network-derived perturbations. For two different
train-test partitionings of two benchmark datasets, and two different deep
architectures, we find that this adversary is very effective in defeating the
resulting systems. We find the convolutional networks are more robust, however,
compared with systems based on a majority vote over individually classified
audio frames. Furthermore, we integrate the adversary into the training of new
deep systems, but do not find that this improves their resilience against the
same adversary.",2015-07-16T20:24:18Z,http://arxiv.org/pdf/1507.04761v1,"['cs.LG', 'cs.NE', 'cs.SD']"
1702.00523v1,Deep Learning the Indus Script,"['Satish Palaniappan', 'Ronojoy Adhikari']","Standardized corpora of undeciphered scripts, a necessary starting point for
computational epigraphy, requires laborious human effort for their preparation
from raw archaeological records. Automating this process through machine
learning algorithms can be of significant aid to epigraphical research. Here,
we take the first steps in this direction and present a deep learning pipeline
that takes as input images of the undeciphered Indus script, as found in
archaeological artifacts, and returns as output a string of graphemes, suitable
for inclusion in a standard corpus. The image is first decomposed into regions
using Selective Search and these regions are classified as containing textual
and/or graphical information using a convolutional neural network. Regions
classified as potentially containing text are hierarchically merged and trimmed
to remove non-textual information. The remaining textual part of the image is
segmented using standard image processing techniques to isolate individual
graphemes. This set is finally passed to a second convolutional neural network
to classify the graphemes, based on a standard corpus. The classifier can
identify the presence or absence of the most frequent Indus grapheme, the ""jar""
sign, with an accuracy of 92%. Our results demonstrate the great potential of
deep learning approaches in computational epigraphy and, more generally, in the
digital humanities.",2017-02-02T01:56:22Z,http://arxiv.org/pdf/1702.00523v1,"['cs.CV', 'cs.CL', 'cs.LG', 'I.5.4; I.2.10; I.2.6']"
1803.00149v1,Deep Learning for Causal Inference,['Vikas Ramachandra'],"In this paper, we propose deep learning techniques for econometrics,
specifically for causal inference and for estimating individual as well as
average treatment effects. The contribution of this paper is twofold: 1. For
generalized neighbor matching to estimate individual and average treatment
effects, we analyze the use of autoencoders for dimensionality reduction while
maintaining the local neighborhood structure among the data points in the
embedding space. This deep learning based technique is shown to perform better
than simple k nearest neighbor matching for estimating treatment effects,
especially when the data points have several features/covariates but reside in
a low dimensional manifold in high dimensional space. We also observe better
performance than manifold learning methods for neighbor matching. 2. Propensity
score matching is one specific and popular way to perform matching in order to
estimate average and individual treatment effects. We propose the use of deep
neural networks (DNNs) for propensity score matching, and present a network
called PropensityNet for this. This is a generalization of the logistic
regression technique traditionally used to estimate propensity scores and we
show empirically that DNNs perform better than logistic regression at
propensity score matching. Code for both methods will be made available shortly
on Github at: https://github.com/vikas84bf",2018-03-01T01:01:16Z,http://arxiv.org/pdf/1803.00149v1,"['econ.EM', 'cs.LG', 'stat.ML']"
1707.07980v1,Deep Learning Based MIMO Communications,"[""Timothy J. O'Shea"", 'Tugba Erpek', 'T. Charles Clancy']","We introduce a novel physical layer scheme for single user Multiple-Input
Multiple-Output (MIMO) communications based on unsupervised deep learning using
an autoencoder. This method extends prior work on the joint optimization of
physical layer representation and encoding and decoding processes as a single
end-to-end task by expanding transmitter and receivers to the multi-antenna
case. We introduce a widely used domain appropriate wireless channel impairment
model (Rayleigh fading channel), into the autoencoder optimization problem in
order to directly learn a system which optimizes for it. We considered both
spatial diversity and spatial multiplexing techniques in our implementation.
Our deep learning-based approach demonstrates significant potential for
learning schemes which approach and exceed the performance of the methods which
are widely used in existing wireless MIMO systems. We discuss how the proposed
scheme can be easily adapted for open-loop and closed-loop operation in spatial
diversity and multiplexing modes and extended use with only compact binary
channel state information (CSI) as feedback.",2017-07-25T13:28:27Z,http://arxiv.org/pdf/1707.07980v1,"['cs.IT', 'math.IT']"
1809.01604v1,Merging datasets through deep learning,"['Kavitha Srinivas', 'Abraham Gale', 'Julian Dolby']","Merging datasets is a key operation for data analytics. A frequent
requirement for merging is joining across columns that have different surface
forms for the same entity (e.g., the name of a person might be represented as
""Douglas Adams"" or ""Adams, Douglas""). Similarly, ontology alignment can require
recognizing distinct surface forms of the same entity, especially when
ontologies are independently developed. However, data management systems are
currently limited to performing merges based on string equality, or at best
using string similarity. We propose an approach to performing merges based on
deep learning models. Our approach depends on (a) creating a deep learning
model that maps surface forms of an entity into a set of vectors such that
alternate forms for the same entity are closest in vector space, (b) indexing
these vectors using a nearest neighbors algorithm to find the forms that can be
potentially joined together. To build these models, we had to adapt techniques
from metric learning due to the characteristics of the data; specifically we
describe novel sample selection techniques and loss functions that work for
this problem. To evaluate our approach, we used Wikidata as ground truth and
built models from datasets with approximately 1.1M people's names (200K
identities) and 130K company names (70K identities). We developed models that
allow for joins with precision@1 of .75-.81 and recall of .74-.81. We make the
models available for aligning people or companies across multiple datasets.",2018-09-05T16:19:26Z,http://arxiv.org/pdf/1809.01604v1,"['cs.LG', 'cs.AI', 'stat.ML']"
1809.10536v1,Deep Learning and Holographic QCD,"['Koji Hashimoto', 'Sotaro Sugishita', 'Akinori Tanaka', 'Akio Tomiya']","We apply the relation between deep learning (DL) and the AdS/CFT
correspondence to a holographic model of QCD. Using a lattice QCD data of the
chiral condensate at a finite temperature as our training data, the deep
learning procedure holographically determines an emergent bulk metric as neural
network weights. The emergent bulk metric is found to have both a black hole
horizon and a finite-height IR wall, so shares both the confining and
deconfining phases, signaling the cross-over thermal phase transition of QCD.
In fact, a quark antiquark potential holographically calculated by the emergent
bulk metric turns out to possess both the linear confining part and the Debye
screening part, as is often observed in lattice QCD. From this we argue the
discrepancy between the chiral symmetry breaking and the quark confinement in
the holographic QCD. The DL method is shown to provide a novel data-driven
holographic modeling of QCD, and sheds light on the mechanism of emergence of
the bulk geometries in the AdS/CFT correspondence.",2018-09-27T14:19:54Z,http://arxiv.org/pdf/1809.10536v1,"['hep-th', 'hep-lat', 'hep-ph']"
1904.11643v1,Bayesian Generative Active Deep Learning,"['Toan Tran', 'Thanh-Toan Do', 'Ian Reid', 'Gustavo Carneiro']","Deep learning models have demonstrated outstanding performance in several
problems, but their training process tends to require immense amounts of
computational and human resources for training and labeling, constraining the
types of problems that can be tackled. Therefore, the design of effective
training methods that require small labeled training sets is an important
research direction that will allow a more effective use of resources.Among
current approaches designed to address this issue, two are particularly
interesting: data augmentation and active learning. Data augmentation achieves
this goal by artificially generating new training points, while active learning
relies on the selection of the ""most informative"" subset of unlabeled training
samples to be labelled by an oracle. Although successful in practice, data
augmentation can waste computational resources because it indiscriminately
generates samples that are not guaranteed to be informative, and active
learning selects a small subset of informative samples (from a large
un-annotated set) that may be insufficient for the training process. In this
paper, we propose a Bayesian generative active deep learning approach that
combines active learning with data augmentation -- we provide theoretical and
empirical evidence (MNIST, CIFAR-$\{10,100\}$, and SVHN) that our approach has
more efficient training and better classification results than data
augmentation and active learning.",2019-04-26T01:55:04Z,http://arxiv.org/pdf/1904.11643v1,"['cs.LG', 'stat.ML']"
1503.01445v1,Toxicity Prediction using Deep Learning,"['Thomas Unterthiner', 'Andreas Mayr', 'Günter Klambauer', 'Sepp Hochreiter']","Everyday we are exposed to various chemicals via food additives, cleaning and
cosmetic products and medicines -- and some of them might be toxic. However
testing the toxicity of all existing compounds by biological experiments is
neither financially nor logistically feasible. Therefore the government
agencies NIH, EPA and FDA launched the Tox21 Data Challenge within the
""Toxicology in the 21st Century"" (Tox21) initiative. The goal of this challenge
was to assess the performance of computational methods in predicting the
toxicity of chemical compounds. State of the art toxicity prediction methods
build upon specifically-designed chemical descriptors developed over decades.
Though Deep Learning is new to the field and was never applied to toxicity
prediction before, it clearly outperformed all other participating methods. In
this application paper we show that deep nets automatically learn features
resembling well-established toxicophores. In total, our Deep Learning approach
won both of the panel-challenges (nuclear receptors and stress response) as
well as the overall Grand Challenge, and thereby sets a new standard in tox
prediction.",2015-03-04T20:18:55Z,http://arxiv.org/pdf/1503.01445v1,"['stat.ML', 'cs.LG', 'cs.NE', 'q-bio.BM']"
2012.07439v1,Graphs for deep learning representations,['Carlos Lassance'],"In recent years, Deep Learning methods have achieved state of the art
performance in a vast range of machine learning tasks, including image
classification and multilingual automatic text translation. These architectures
are trained to solve machine learning tasks in an end-to-end fashion. In order
to reach top-tier performance, these architectures often require a very large
number of trainable parameters. There are multiple undesirable consequences,
and in order to tackle these issues, it is desired to be able to open the black
boxes of deep learning architectures. Problematically, doing so is difficult
due to the high dimensionality of representations and the stochasticity of the
training process. In this thesis, we investigate these architectures by
introducing a graph formalism based on the recent advances in Graph Signal
Processing (GSP). Namely, we use graphs to represent the latent spaces of deep
neural networks. We showcase that this graph formalism allows us to answer
various questions including: ensuring generalization abilities, reducing the
amount of arbitrary choices in the design of the learning process, improving
robustness to small perturbations added to the inputs, and reducing
computational complexity",2020-12-14T11:51:23Z,http://arxiv.org/pdf/2012.07439v1,['cs.LG']
2109.11431v1,Deep Learning for Ultrasound Beamforming,"['Ruud JG van Sloun', 'Jong Chul Ye', 'Yonina C Eldar']","Diagnostic imaging plays a critical role in healthcare, serving as a
fundamental asset for timely diagnosis, disease staging and management as well
as for treatment choice, planning, guidance, and follow-up. Among the
diagnostic imaging options, ultrasound imaging is uniquely positioned, being a
highly cost-effective modality that offers the clinician an unmatched and
invaluable level of interaction, enabled by its real-time nature. Ultrasound
probes are becoming increasingly compact and portable, with the market demand
for low-cost pocket-sized and (in-body) miniaturized devices expanding. At the
same time, there is a strong trend towards 3D imaging and the use of
high-frame-rate imaging schemes; both accompanied by dramatically increasing
data rates that pose a heavy burden on the probe-system communication and
subsequent image reconstruction algorithms.
  With the demand for high-quality image reconstruction and signal extraction
from less (e.g unfocused or parallel) transmissions that facilitate fast
imaging, and a push towards compact probes, modern ultrasound imaging leans
heavily on innovations in powerful digital receive channel processing.
Beamforming, the process of mapping received ultrasound echoes to the spatial
image domain, naturally lies at the heart of the ultrasound image formation
chain. In this chapter on Deep Learning for Ultrasound Beamforming, we discuss
why and when deep learning methods can play a compelling role in the digital
beamforming pipeline, and then show how these data-driven systems can be
leveraged for improved ultrasound image reconstruction.",2021-09-23T15:15:21Z,http://arxiv.org/pdf/2109.11431v1,"['eess.SP', 'cs.AI', 'eess.IV']"
2111.14088v1,Multicriteria interpretability driven Deep Learning,['Marco Repetto'],"Deep Learning methods are renowned for their performances, yet their lack of
interpretability prevents them from high-stakes contexts. Recent model agnostic
methods address this problem by providing post-hoc interpretability methods by
reverse-engineering the model's inner workings. However, in many regulated
fields, interpretability should be kept in mind from the start, which means
that post-hoc methods are valid only as a sanity check after model training.
Interpretability from the start, in an abstract setting, means posing a set of
soft constraints on the model's behavior by injecting knowledge and
annihilating possible biases. We propose a Multicriteria technique that allows
to control the feature effects on the model's outcome by injecting knowledge in
the objective function. We then extend the technique by including a non-linear
knowledge function to account for more complex effects and local lack of
knowledge. The result is a Deep Learning model that embodies interpretability
from the start and aligns with the recent regulations. A practical empirical
example based on credit risk, suggests that our approach creates performant yet
robust models capable of overcoming biases derived from data scarcity.",2021-11-28T09:41:13Z,http://arxiv.org/pdf/2111.14088v1,"['cs.LG', 'cs.AI']"
2211.04686v3,Directional Privacy for Deep Learning,"['Pedro Faustini', 'Natasha Fernandes', 'Shakila Tonni', 'Annabelle McIver', 'Mark Dras']","Differentially Private Stochastic Gradient Descent (DP-SGD) is a key method
for applying privacy in the training of deep learning models. It applies
isotropic Gaussian noise to gradients during training, which can perturb these
gradients in any direction, damaging utility. Metric DP, however, can provide
alternative mechanisms based on arbitrary metrics that might be more suitable
for preserving utility. In this paper, we apply \textit{directional privacy},
via a mechanism based on the von Mises-Fisher (VMF) distribution, to perturb
gradients in terms of \textit{angular distance} so that gradient direction is
broadly preserved. We show that this provides both $\epsilon$-DP and $\epsilon
d$-privacy for deep learning training, rather than the $(\epsilon,
\delta)$-privacy of the Gaussian mechanism. Experiments on key datasets then
indicate that the VMF mechanism can outperform the Gaussian in the
utility-privacy trade-off. In particular, our experiments provide a direct
empirical comparison of privacy between the two approaches in terms of their
ability to defend against reconstruction and membership inference.",2022-11-09T05:18:08Z,http://arxiv.org/pdf/2211.04686v3,"['cs.LG', 'cs.CR']"
2302.05745v2,Verifying Generalization in Deep Learning,"['Guy Amir', 'Osher Maayan', 'Tom Zelazny', 'Guy Katz', 'Michael Schapira']","Deep neural networks (DNNs) are the workhorses of deep learning, which
constitutes the state of the art in numerous application domains. However,
DNN-based decision rules are notoriously prone to poor generalization, i.e.,
may prove inadequate on inputs not encountered during training. This limitation
poses a significant obstacle to employing deep learning for mission-critical
tasks, and also in real-world environments that exhibit high variability. We
propose a novel, verification-driven methodology for identifying DNN-based
decision rules that generalize well to new input domains. Our approach
quantifies generalization to an input domain by the extent to which decisions
reached by independently trained DNNs are in agreement for inputs in this
domain. We show how, by harnessing the power of DNN verification, our approach
can be efficiently and effectively realized. We evaluate our verification-based
approach on three deep reinforcement learning (DRL) benchmarks, including a
system for Internet congestion control. Our results establish the usefulness of
our approach. More broadly, our work puts forth a novel objective for formal
verification, with the potential for mitigating the risks associated with
deploying DNN-based systems in the wild.",2023-02-11T17:08:15Z,http://arxiv.org/pdf/2302.05745v2,"['cs.LG', 'cs.LO']"
2103.05127v2,Model Complexity of Deep Learning: A Survey,"['Xia Hu', 'Lingyang Chu', 'Jian Pei', 'Weiqing Liu', 'Jiang Bian']","Model complexity is a fundamental problem in deep learning. In this paper we
conduct a systematic overview of the latest studies on model complexity in deep
learning. Model complexity of deep learning can be categorized into expressive
capacity and effective model complexity. We review the existing studies on
those two categories along four important factors, including model framework,
model size, optimization process and data complexity. We also discuss the
applications of deep learning model complexity including understanding model
generalization, model optimization, and model selection and design. We conclude
by proposing several interesting future directions.",2021-03-08T22:39:32Z,http://arxiv.org/pdf/2103.05127v2,"['cs.LG', 'cs.AI']"
2011.13726v2,AdS/Deep-Learning made easy: simple examples,"['Mugeon Song', 'Maverick S. H. Oh', 'Yongjun Ahn', 'Keun-Young Kim']","Deep learning has been widely and actively used in various research areas.
Recently, in the gauge/gravity duality, a new deep learning technique so-called
the AdS/Deep-Learning (DL) has been proposed [1, 2]. The goal of this paper is
to describe the essence of the AdS/DL in the simplest possible setups, for
those who want to apply it to the subject of emergent spacetime as a neural
network. For prototypical examples, we choose simple classical mechanics
problems. This method is a little different from standard deep learning
techniques in the sense that not only do we have the right final answers but
also obtain a physical understanding of learning parameters.",2020-11-27T13:23:18Z,http://arxiv.org/pdf/2011.13726v2,"['physics.class-ph', 'cs.LG', 'hep-th']"
1906.08986v2,Database Meets Deep Learning: Challenges and Opportunities,"['Wei Wang', 'Meihui Zhang', 'Gang Chen', 'H. V. Jagadish', 'Beng Chin Ooi', 'Kian-Lee Tan']","Deep learning has recently become very popular on account of its incredible
success in many complex data-driven applications, such as image classification
and speech recognition. The database community has worked on data-driven
applications for many years, and therefore should be playing a lead role in
supporting this new wave. However, databases and deep learning are different in
terms of both techniques and applications. In this paper, we discuss research
problems at the intersection of the two fields. In particular, we discuss
possible improvements for deep learning systems from a database perspective,
and analyze database applications that may benefit from deep learning
techniques.",2019-06-21T07:26:31Z,http://arxiv.org/pdf/1906.08986v2,"['cs.DB', 'cs.DC', 'cs.LG']"
2007.09637v1,Survey on Deep Learning-based Kuzushiji Recognition,"['Kazuya Ueki', 'Tomoka Kojima']","Owing to the overwhelming accuracy of the deep learning method demonstrated
at the 2012 image classification competition, deep learning has been
successfully applied to a variety of other tasks. The high-precision detection
and recognition of Kuzushiji, a Japanese cursive script used for transcribing
historical documents, has been made possible through the use of deep learning.
In recent years, competitions on Kuzushiji recognition have been held, and many
researchers have proposed various recognition methods. This study examines
recent research trends, current problems, and future prospects in Kuzushiji
recognition using deep learning.",2020-07-19T09:46:46Z,http://arxiv.org/pdf/2007.09637v1,['cs.CV']
1312.5548v1,My First Deep Learning System of 1991 + Deep Learning Timeline 1962-2013,['Jürgen Schmidhuber'],"Deep Learning has attracted significant attention in recent years. Here I
present a brief overview of my first Deep Learner of 1991, and its historic
context, with a timeline of Deep Learning highlights.",2013-12-19T13:45:45Z,http://arxiv.org/pdf/1312.5548v1,['cs.NE']
1602.00172v2,Deep Learning For Smile Recognition,['Patrick O. Glauner'],"Inspired by recent successes of deep learning in computer vision, we propose
a novel application of deep convolutional neural networks to facial expression
recognition, in particular smile recognition. A smile recognition test accuracy
of 99.45% is achieved for the Denver Intensity of Spontaneous Facial Action
(DISFA) database, significantly outperforming existing approaches based on
hand-crafted features with accuracies ranging from 65.55% to 79.67%. The
novelty of this approach includes a comprehensive model selection of the
architecture parameters, allowing to find an appropriate architecture for each
expression such as smile. This is feasible because all experiments were run on
a Tesla K40c GPU, allowing a speedup of factor 10 over traditional computations
on a CPU.",2016-01-30T23:59:04Z,http://arxiv.org/pdf/1602.00172v2,"['cs.CV', 'cs.LG', 'cs.NE']"
1605.06921v1,Generative Choreography using Deep Learning,"['Luka Crnkovic-Friis', 'Louise Crnkovic-Friis']","Recent advances in deep learning have enabled the extraction of high-level
features from raw sensor data which has opened up new possibilities in many
different fields, including computer generated choreography. In this paper we
present a system chor-rnn for generating novel choreographic material in the
nuanced choreographic language and style of an individual choreographer. It
also shows promising results in producing a higher level compositional
cohesion, rather than just generating sequences of movement. At the core of
chor-rnn is a deep recurrent neural network trained on raw motion capture data
and that can generate new dance sequences for a solo dancer. Chor-rnn can be
used for collaborative human-machine choreography or as a creative catalyst,
serving as inspiration for a choreographer.",2016-05-23T07:36:49Z,http://arxiv.org/pdf/1605.06921v1,"['cs.AI', 'cs.LG', 'cs.MM', 'cs.NE']"
1705.08665v4,Bayesian Compression for Deep Learning,"['Christos Louizos', 'Karen Ullrich', 'Max Welling']","Compression and computational efficiency in deep learning have become a
problem of great significance. In this work, we argue that the most principled
and effective way to attack this problem is by adopting a Bayesian point of
view, where through sparsity inducing priors we prune large parts of the
network. We introduce two novelties in this paper: 1) we use hierarchical
priors to prune nodes instead of individual weights, and 2) we use the
posterior uncertainties to determine the optimal fixed point precision to
encode the weights. Both factors significantly contribute to achieving the
state of the art in terms of compression rates, while still staying competitive
with methods designed to optimize for speed or energy efficiency.",2017-05-24T09:07:01Z,http://arxiv.org/pdf/1705.08665v4,"['stat.ML', 'cs.LG']"
1708.04439v2,Extractive Summarization using Deep Learning,"['Sukriti Verma', 'Vagisha Nidhi']","This paper proposes a text summarization approach for factual reports using a
deep learning model. This approach consists of three phases: feature
extraction, feature enhancement, and summary generation, which work together to
assimilate core information and generate a coherent, understandable summary. We
are exploring various features to improve the set of sentences selected for the
summary, and are using a Restricted Boltzmann Machine to enhance and abstract
those features to improve resultant accuracy without losing any important
information. The sentences are scored based on those enhanced features and an
extractive summary is constructed. Experimentation carried out on several
articles demonstrates the effectiveness of the proposed approach. Source code
available at: https://github.com/vagisha-nidhi/TextSummarizer",2017-08-15T09:08:50Z,http://arxiv.org/pdf/1708.04439v2,"['cs.CL', 'cs.IR', 'cs.LG']"
1803.10768v1,Unreasonable Effectivness of Deep Learning,['Finn Macleod'],"We show how well known rules of back propagation arise from a weighted
combination of finite automata. By redefining a finite automata as a predictor
we combine the set of all $k$-state finite automata using a weighted majority
algorithm. This aggregated prediction algorithm can be simplified using
symmetry, and we prove the equivalence of an algorithm that does this. We
demonstrate that this algorithm is equivalent to a form of a back propagation
acting in a completely connected $k$-node neural network. Thus the use of the
weighted majority algorithm allows a bound on the general performance of deep
learning approaches to prediction via known results from online statistics. The
presented framework opens more detailed questions about network topology; it is
a bridge to the well studied techniques of semigroup theory and applying these
techniques to answer what specific network topologies are capable of
predicting. This informs both the design of artificial networks and the
exploration of neuroscience models.",2018-03-28T14:29:30Z,http://arxiv.org/pdf/1803.10768v1,"['cs.LG', 'stat.ML']"
1808.05527v3,Deep Learning for Energy Markets,"['Michael Polson', 'Vadim Sokolov']","Deep Learning is applied to energy markets to predict extreme loads observed
in energy grids. Forecasting energy loads and prices is challenging due to
sharp peaks and troughs that arise due to supply and demand fluctuations from
intraday system constraints. We propose deep spatio-temporal models and extreme
value theory (EVT) to capture theses effects and in particular the tail
behavior of load spikes. Deep LSTM architectures with ReLU and $\tanh$
activation functions can model trends and temporal dependencies while EVT
captures highly volatile load spikes above a pre-specified threshold. To
illustrate our methodology, we use hourly price and demand data from 4719 nodes
of the PJM interconnection, and we construct a deep predictor. We show that
DL-EVT outperforms traditional Fourier time series methods, both in-and
out-of-sample, by capturing the observed nonlinearities in prices. Finally, we
conclude with directions for future research.",2018-08-16T15:01:01Z,http://arxiv.org/pdf/1808.05527v3,"['stat.ML', 'cs.LG', 'q-fin.ST']"
1810.05893v4,Deep Learning-Based Channel Estimation,"['Mehran Soltani', 'Vahid Pourahmadi', 'Ali Mirzaei', 'Hamid Sheikhzadeh']","In this paper, we present a deep learning (DL) algorithm for channel
estimation in communication systems. We consider the time-frequency response of
a fast fading communication channel as a two-dimensional image. The aim is to
find the unknown values of the channel response using some known values at the
pilot locations. To this end, a general pipeline using deep image processing
techniques, image super-resolution (SR) and image restoration (IR) is proposed.
This scheme considers the pilot values, altogether, as a low-resolution image
and uses an SR network cascaded with a denoising IR network to estimate the
channel. Moreover, an implementation of the proposed pipeline is presented. The
estimation error shows that the presented algorithm is comparable to the
minimum mean square error (MMSE) with full knowledge of the channel statistics
and it is better than ALMMSE (an approximation to linear MMSE). The results
confirm that this pipeline can be used efficiently in channel estimation.",2018-10-13T17:08:52Z,http://arxiv.org/pdf/1810.05893v4,"['cs.IT', 'cs.LG', 'eess.SP', 'math.IT', 'stat.ML']"
2006.09590v2,Deep Learning with Functional Inputs,"['Barinder Thind', 'Kevin Multani', 'Jiguo Cao']","We present a methodology for integrating functional data into deep densely
connected feed-forward neural networks. The model is defined for scalar
responses with multiple functional and scalar covariates. A by-product of the
method is a set of dynamic functional weights that can be visualized during the
optimization process. This visualization leads to greater interpretability of
the relationship between the covariates and the response relative to
conventional neural networks. The model is shown to perform well in a number of
contexts including prediction of new data and recovery of the true underlying
functional weights; these results were confirmed through real applications and
simulation studies. A forthcoming R package is developed on top of a popular
deep learning library (Keras) allowing for general use of the approach.",2020-06-17T01:23:00Z,http://arxiv.org/pdf/2006.09590v2,"['stat.ML', 'cs.LG', 'stat.ME']"
2005.13665v3,Deep Learning for Portfolio Optimization,"['Zihao Zhang', 'Stefan Zohren', 'Stephen Roberts']","We adopt deep learning models to directly optimise the portfolio Sharpe
ratio. The framework we present circumvents the requirements for forecasting
expected returns and allows us to directly optimise portfolio weights by
updating model parameters. Instead of selecting individual assets, we trade
Exchange-Traded Funds (ETFs) of market indices to form a portfolio. Indices of
different asset classes show robust correlations and trading them substantially
reduces the spectrum of available assets to choose from. We compare our method
with a wide range of algorithms with results showing that our model obtains the
best performance over the testing period, from 2011 to the end of April 2020,
including the financial instabilities of the first quarter of 2020. A
sensitivity analysis is included to understand the relevance of input features
and we further study the performance of our approach under different cost rates
and different risk levels via volatility scaling.",2020-05-27T21:28:43Z,http://arxiv.org/pdf/2005.13665v3,"['q-fin.PM', 'cs.LG', 'q-fin.CP']"
1701.02620v2,Deep Learning for Logo Recognition,"['Simone Bianco', 'Marco Buzzelli', 'Davide Mazzini', 'Raimondo Schettini']","In this paper we propose a method for logo recognition using deep learning.
Our recognition pipeline is composed of a logo region proposal followed by a
Convolutional Neural Network (CNN) specifically trained for logo
classification, even if they are not precisely localized. Experiments are
carried out on the FlickrLogos-32 database, and we evaluate the effect on
recognition performance of synthetic versus real data augmentation, and image
pre-processing. Moreover, we systematically investigate the benefits of
different training choices such as class-balancing, sample-weighting and
explicit modeling the background class (i.e. no-logo regions). Experimental
results confirm the feasibility of the proposed method, that outperforms the
methods in the state of the art.",2017-01-10T14:51:39Z,http://arxiv.org/pdf/1701.02620v2,['cs.CV']
1807.03162v2,Deep Learning Based Sphere Decoding,"['Mostafa Mohammadkarimi', 'Mehrtash Mehrabi', 'Masoud Ardakani', 'Yindi Jing']","In this paper, a deep learning (DL)-based sphere decoding algorithm is
proposed, where the radius of the decoding hypersphere is learned by a deep
neural network (DNN). The performance achieved by the proposed algorithm is
very close to the optimal maximum likelihood decoding (MLD) over a wide range
of signal-to-noise ratios (SNRs), while the computational complexity, compared
to existing sphere decoding variants, is significantly reduced. This
improvement is attributed to DNN's ability of intelligently learning the radius
of the hypersphere used in decoding. The expected complexity of the proposed
DL-based algorithm is analytically derived and compared with existing ones. It
is shown that the number of lattice points inside the decoding hypersphere
drastically reduces in the DL-based algorithm in both the average and
worst-case senses. The effectiveness of the proposed algorithm is shown through
simulation for high-dimensional multiple-input multiple-output (MIMO) systems,
using high-order modulations.",2018-07-06T03:18:35Z,http://arxiv.org/pdf/1807.03162v2,"['eess.SP', 'cs.LG']"
1910.04918v3,Deep Learning for Prostate Pathology,"['Okyaz Eminaga', 'Yuri Tolkach', 'Christian Kunder', 'Mahmood Abbas', 'Ryan Han', 'Rosalie Nolley', 'Axel Semjonow', 'Martin Boegemann', 'Sebastian Huss', 'Andreas Loening', 'Robert West', 'Geoffrey Sonn', 'Richard Fan', 'Olaf Bettendorf', 'James Brook', 'Daniel Rubin']","The current study detects different morphologies related to prostate
pathology using deep learning models; these models were evaluated on 2,121
hematoxylin and eosin (H&E) stain histology images captured using bright field
microscopy, which spanned a variety of image qualities, origins (whole slide,
tissue micro array, whole mount, Internet), scanning machines, timestamps, H&E
staining protocols, and institutions. For case usage, these models were applied
for the annotation tasks in clinician-oriented pathology reports for
prostatectomy specimens. The true positive rate (TPR) for slides with prostate
cancer was 99.7% by a false positive rate of 0.785%. The F1-scores of Gleason
patterns reported in pathology reports ranged from 0.795 to 1.0 at the case
level. TPR was 93.6% for the cribriform morphology and 72.6% for the ductal
morphology. The correlation between the ground truth and the prediction for the
relative tumor volume was 0.987 n. Our models cover the major components of
prostate pathology and successfully accomplish the annotation tasks.",2019-10-11T00:10:59Z,http://arxiv.org/pdf/1910.04918v3,"['q-bio.TO', 'cs.CV', 'cs.LG', 'eess.IV']"
1910.10231v1,Deep Learning at the Edge,"['Sahar Voghoei', 'Navid Hashemi Tonekaboni', 'Jason G. Wallace', 'Hamid R. Arabnia']","The ever-increasing number of Internet of Things (IoT) devices has created a
new computing paradigm, called edge computing, where most of the computations
are performed at the edge devices, rather than on centralized servers. An edge
device is an electronic device that provides connections to service providers
and other edge devices; typically, such devices have limited resources. Since
edge devices are resource-constrained, the task of launching algorithms,
methods, and applications onto edge devices is considered to be a significant
challenge. In this paper, we discuss one of the most widely used machine
learning methods, namely, Deep Learning (DL) and offer a short survey on the
recent approaches used to map DL onto the edge computing paradigm. We also
provide relevant discussions about selected applications that would greatly
benefit from DL at the edge.",2019-10-22T21:08:09Z,http://arxiv.org/pdf/1910.10231v1,"['cs.LG', 'cs.NE']"
1910.12582v1,Engineering Reliable Deep Learning Systems,"['P. Santhanam', 'Eitan Farchi', 'Victor Pankratius']","Recent progress in artificial intelligence (AI) using deep learning
techniques has triggered its wide-scale use across a broad range of
applications. These systems can already perform tasks such as natural language
processing of voice and text, visual recognition, question-answering,
recommendations and decision support. However, at the current level of
maturity, the use of an AI component in mission-critical or safety-critical
applications can have unexpected consequences. Consequently, serious concerns
about reliability, repeatability, trust, and maintainability of AI applications
remain. As AI becomes pervasive despite its shortcomings, more systematic ways
of approaching AI software development and certification are needed. These
fundamental aspects establish the need for a discipline on ""AI Engineering"".
This paper presents the current perspective of relevant AI engineering concepts
and some key challenges that need to be overcome to make significant progress
in this important area.",2019-10-14T15:13:45Z,http://arxiv.org/pdf/1910.12582v1,['cs.CY']
1902.03620v2,Deep learning detection of transients,['Iftach Sadeh'],"The next generation of observatories will facilitate the discovery of new
types of astrophysical transients. The detection of such phenomena, whose
characteristics are presently poorly constrained, will hinge on the ability to
perform blind searches. We present a new algorithm for this purpose, based on
deep learning. We incorporate two approaches, utilising anomaly detection and
classification techniques. The first is model-independent, avoiding the use of
background modelling and instrument simulations. The second method enables
targeted searches, relying on generic spectral and temporal patterns as input.
We compare our methodology with the existing approach to serendipitous
detection of gamma-ray transients. The algorithm is shown to be more robust,
especially for non-trivial spectral features. We use our framework to derive
the detection prospects of low-luminosity gamma-ray bursts with the upcoming
Cherenkov Telescope Array. Our method is an unbiased, completely data-driven
approach for multiwavelength and multi-messenger transient detection.",2019-02-10T15:22:15Z,http://arxiv.org/pdf/1902.03620v2,"['astro-ph.HE', 'astro-ph.IM']"
2008.10293v1,Bosch Deep Learning Hardware Benchmark,"['Armin Runge', 'Thomas Wenzel', 'Dimitrios Bariamis', 'Benedikt Sebastian Staffler', 'Lucas Rego Drumond', 'Michael Pfeiffer']","The widespread use of Deep Learning (DL) applications in science and industry
has created a large demand for efficient inference systems. This has resulted
in a rapid increase of available Hardware Accelerators (HWAs) making comparison
challenging and laborious. To address this, several DL hardware benchmarks have
been proposed aiming at a comprehensive comparison for many models, tasks, and
hardware platforms. Here, we present our DL hardware benchmark which has been
specifically developed for inference on embedded HWAs and tasks required for
autonomous driving. In addition to previous benchmarks, we propose a new
granularity level to evaluate common submodules of DL models, a twofold
benchmark procedure that accounts for hardware and model optimizations done by
HWA manufacturers, and an extended set of performance indicators that can help
to identify a mismatch between a HWA and the DL models used in our benchmark.",2020-08-24T09:50:24Z,http://arxiv.org/pdf/2008.10293v1,"['cs.LG', 'cs.AI', 'cs.CV', 'stat.ML']"
2201.09199v1,Deep Learning on Attributed Sequences,['Zhongfang Zhuang'],"Recent research in feature learning has been extended to sequence data, where
each instance consists of a sequence of heterogeneous items with a variable
length. However, in many real-world applications, the data exists in the form
of attributed sequences, which is composed of a set of fixed-size attributes
and variable-length sequences with dependencies between them. In the attributed
sequence context, feature learning remains challenging due to the dependencies
between sequences and their associated attributes. In this dissertation, we
focus on analyzing and building deep learning models for four new problems on
attributed sequences. Our extensive experiments on real-world datasets
demonstrate that the proposed solutions significantly improve the performance
of each task over the state-of-the-art methods on attributed sequences.",2022-01-23T06:54:31Z,http://arxiv.org/pdf/2201.09199v1,"['cs.LG', 'cs.AI']"
2203.00567v2,Descriptellation: Deep Learned Constellation Descriptors,"['Chunwei Xing', 'Xinyu Sun', 'Andrei Cramariuc', 'Samuel Gull', 'Jen Jen Chung', 'Cesar Cadena', 'Roland Siegwart', 'Florian Tschopp']","Current descriptors for global localization often struggle under vast
viewpoint or appearance changes. One possible improvement is the addition of
topological information on semantic objects. However, handcrafted topological
descriptors are hard to tune and not robust to environmental noise, drastic
perspective changes, object occlusion or misdetections. To solve this problem,
we formulate a learning-based approach by modelling semantically meaningful
object constellations as graphs and using Deep Graph Convolution Networks to
map a constellation to a descriptor. We demonstrate the effectiveness of our
Deep Learned Constellation Descriptor (Descriptellation) on two real-world
datasets. Although Descriptellation is trained on randomly generated simulation
datasets, it shows good generalization abilities on real-world datasets.
Descriptellation also outperforms state-of-the-art and handcrafted
constellation descriptors for global localization, and is robust to different
types of noise. The code is publicly available at
https://github.com/ethz-asl/Descriptellation.",2022-03-01T15:43:01Z,http://arxiv.org/pdf/2203.00567v2,"['cs.RO', 'cs.CV']"
2204.08157v1,Deep Learning Coherent Diffractive Imaging,"['Dillan J. Chang', ""Colum M. O'Leary"", 'Cong Su', 'Salman Kahn', 'Alex Zettl', 'Jim Ciston', 'Peter Ercius', 'Jianwei Miao']","We report the development of deep learning coherent electron diffractive
imaging at sub-angstrom resolution using convolutional neural networks (CNNs)
trained with only simulated data. We experimentally demonstrate this method by
applying the trained CNNs to directly recover the phase images from electron
diffraction patterns of twisted hexagonal boron nitride, monolayer graphene and
a Au nanoparticle with comparable quality to those reconstructed by a
conventional ptychographic method. Fourier ring correlation between the CNN and
ptychographic images indicates the achievement of a spatial resolution in the
range of 0.70 and 0.55 angstrom (depending on different resolution criteria).
The ability to replace iterative algorithms with CNNs and perform real-time
imaging from coherent diffraction patterns is expected to find broad
applications in the physical and biological sciences.",2022-04-18T04:05:41Z,http://arxiv.org/pdf/2204.08157v1,['cond-mat.mtrl-sci']
2208.09325v1,Deep Learning for Choice Modeling,"['Zhongze Cai', 'Hanzhao Wang', 'Kalyan Talluri', 'Xiaocheng Li']","Choice modeling has been a central topic in the study of individual
preference or utility across many fields including economics, marketing,
operations research, and psychology. While the vast majority of the literature
on choice models has been devoted to the analytical properties that lead to
managerial and policy-making insights, the existing methods to learn a choice
model from empirical data are often either computationally intractable or
sample inefficient. In this paper, we develop deep learning-based choice models
under two settings of choice modeling: (i) feature-free and (ii) feature-based.
Our model captures both the intrinsic utility for each candidate choice and the
effect that the assortment has on the choice probability. Synthetic and real
data experiments demonstrate the performances of proposed models in terms of
the recovery of the existing choice models, sample complexity, assortment
effect, architecture design, and model interpretation.",2022-08-19T13:10:17Z,http://arxiv.org/pdf/2208.09325v1,"['stat.ML', 'cs.LG', 'econ.EM']"
2210.04323v1,Deep Learning Inference Frameworks Benchmark,['Pierrick Pochelu'],"Deep learning (DL) has been widely adopted those last years but they are
computing-intensive method. Therefore, scientists proposed diverse optimization
to accelerate their predictions for end-user applications. However, no single
inference framework currently dominates in terms of performance. This paper
takes a holistic approach to conduct an empirical comparison and analysis of
four representative DL inference frameworks. First, given a selection of
CPU-GPU configurations, we show that for a specific DL framework, different
configurations of its settings may have a significant impact on the prediction
speed, memory, and computing power. Second, to the best of our knowledge, this
study is the first to identify the opportunities for accelerating the ensemble
of co-localized models in the same GPU. This measurement study provides an
in-depth empirical comparison and analysis of four representative DL frameworks
and offers practical guidance for service providers to deploy and deliver DL
predictions.",2022-10-09T19:16:53Z,http://arxiv.org/pdf/2210.04323v1,"['cs.LG', 'cs.PF']"
2401.03639v1,Deep Learning for Visual Neuroprosthesis,"['Peter Beech', 'Shanshan Jia', 'Zhaofei Yu', 'Jian K. Liu']","The visual pathway involves complex networks of cells and regions which
contribute to the encoding and processing of visual information. While some
aspects of visual perception are understood, there are still many unanswered
questions regarding the exact mechanisms of visual encoding and the
organization of visual information along the pathway. This chapter discusses
the importance of visual perception and the challenges associated with
understanding how visual information is encoded and represented in the brain.
Furthermore, this chapter introduces the concept of neuroprostheses: devices
designed to enhance or replace bodily functions, and highlights the importance
of constructing computational models of the visual pathway in the
implementation of such devices. A number of such models, employing the use of
deep learning models, are outlined, and their value to understanding visual
coding and natural vision is discussed.",2024-01-08T02:53:22Z,http://arxiv.org/pdf/2401.03639v1,"['q-bio.NC', 'cs.AI', 'cs.CV', 'cs.LG']"
2403.03353v3,Hypothesis Spaces for Deep Learning,"['Rui Wang', 'Yuesheng Xu', 'Mingsong Yan']","This paper introduces a hypothesis space for deep learning based on deep
neural networks (DNNs). By treating a DNN as a function of two variables - the
input variable and the parameter variable - we consider the set of DNNs where
the parameter variable belongs to a space of weight matrices and biases
determined by a prescribed depth and layer widths. To construct a Banach space
of functions of the input variable, we take the weak* closure of the linear
span of this DNN set. We prove that the resulting Banach space is a reproducing
kernel Banach space (RKBS) and explicitly construct its reproducing kernel.
Furthermore, we investigate two learning models - regularized learning and the
minimum norm interpolation (MNI) problem - within the RKBS framework by
establishing representer theorems. These theorems reveal that the solutions to
these learning problems can be expressed as a finite sum of kernel expansions
based on training data.",2024-03-05T22:42:29Z,http://arxiv.org/pdf/2403.03353v3,"['stat.ML', 'cs.LG', 'math.FA']"
2405.16339v2,BOLD: Boolean Logic Deep Learning,"['Van Minh Nguyen', 'Cristian Ocampo', 'Aymen Askri', 'Louis Leconte', 'Ba-Hien Tran']","Deep learning is computationally intensive, with significant efforts focused
on reducing arithmetic complexity, particularly regarding energy consumption
dominated by data movement. While existing literature emphasizes inference,
training is considerably more resource-intensive. This paper proposes a novel
mathematical principle by introducing the notion of Boolean variation such that
neurons made of Boolean weights and inputs can be trained -- for the first time
-- efficiently in Boolean domain using Boolean logic instead of gradient
descent and real arithmetic. We explore its convergence, conduct extensively
experimental benchmarking, and provide consistent complexity evaluation by
considering chip architecture, memory hierarchy, dataflow, and arithmetic
precision. Our approach achieves baseline full-precision accuracy in ImageNet
classification and surpasses state-of-the-art results in semantic segmentation,
with notable performance in image super-resolution, and natural language
understanding with transformer-based models. Moreover, it significantly reduces
energy consumption during both training and inference.",2024-05-25T19:50:23Z,http://arxiv.org/pdf/2405.16339v2,"['stat.ML', 'cs.LG']"
2405.20594v1,Deep Learning without Weight Symmetry,"['Li Ji-An', 'Marcus K. Benna']","Backpropagation (BP), a foundational algorithm for training artificial neural
networks, predominates in contemporary deep learning. Although highly
successful, it is often considered biologically implausible. A significant
limitation arises from the need for precise symmetry between connections in the
backward and forward pathways to backpropagate gradient signals accurately,
which is not observed in biological brains. Researchers have proposed several
algorithms to alleviate this symmetry constraint, such as feedback alignment
and direct feedback alignment. However, their divergence from backpropagation
dynamics presents challenges, particularly in deeper networks and convolutional
layers. Here we introduce the Product Feedback Alignment (PFA) algorithm. Our
findings demonstrate that PFA closely approximates BP and achieves comparable
performance in deep convolutional networks while avoiding explicit weight
symmetry. Our results offer a novel solution to the longstanding weight
symmetry problem, leading to more biologically plausible learning in deep
convolutional networks compared to earlier methods.",2024-05-31T03:11:19Z,http://arxiv.org/pdf/2405.20594v1,"['cs.LG', 'cs.AI', 'q-bio.NC']"
2406.04104v1,Symplectic Methods in Deep Learning,"['Sofya Maslovskaya', 'Sina Ober-Blöbaum']","Deep learning is widely used in tasks including image recognition and
generation, in learning dynamical systems from data and many more. It is
important to construct learning architectures with theoretical guarantees to
permit safety in the applications. There has been considerable progress in this
direction lately. In particular, symplectic networks were shown to have the non
vanishing gradient property, essential for numerical stability. On the other
hand, architectures based on higher order numerical methods were shown to be
efficient in many tasks where the learned function has an underlying dynamical
structure. In this work we construct symplectic networks based on higher order
explicit methods with non vanishing gradient property and test their efficiency
on various examples.",2024-06-06T14:20:55Z,http://arxiv.org/pdf/2406.04104v1,"['math.NA', 'cs.NA', 'math.OC']"
2507.03438v1,Deep Learning and Model Independence,['Martin King'],"The lack of evidence in favor of any new physics models means that the search
for new physics beyond the Standard Model (BSM) is wide open, with no direction
clearly more promising than any other. This marks a turn towards what can be
called `model-independent' methods-strategies that reduce the influence of
modelling assumptions by performing minimally-biased precision measurements,
using effective field theories, or using Deep Learning methods (DL). In this
paper, I present the novel and promising uses of DL as a primary tool in high
energy physics research, highlighting the use of autoencoder networks and
unsupervised learning methods. I advocate for the importance and usefulness of
the concept of model independence and propose a definition that recognizes that
independence of models is not absolute, but comes in degrees.",2025-07-04T09:53:36Z,http://arxiv.org/pdf/2507.03438v1,"['physics.hist-ph', 'hep-ph']"
1409.3358v1,Building Program Vector Representations for Deep Learning,"['Lili Mou', 'Ge Li', 'Yuxuan Liu', 'Hao Peng', 'Zhi Jin', 'Yan Xu', 'Lu Zhang']","Deep learning has made significant breakthroughs in various fields of
artificial intelligence. Advantages of deep learning include the ability to
capture highly complicated features, weak involvement of human engineering,
etc. However, it is still virtually impossible to use deep learning to analyze
programs since deep architectures cannot be trained effectively with pure back
propagation. In this pioneering paper, we propose the ""coding criterion"" to
build program vector representations, which are the premise of deep learning
for program analysis. Our representation learning approach directly makes deep
learning a reality in this new field. We evaluate the learned vector
representations both qualitatively and quantitatively. We conclude, based on
the experiments, the coding criterion is successful in building program
representations. To evaluate whether deep learning is beneficial for program
analysis, we feed the representations to deep neural networks, and achieve
higher accuracy in the program classification task than ""shallow"" methods, such
as logistic regression and the support vector machine. This result confirms the
feasibility of deep learning to analyze programs. It also gives primary
evidence of its success in this new field. We believe deep learning will become
an outstanding technique for program analysis in the near future.",2014-09-11T08:44:28Z,http://arxiv.org/pdf/1409.3358v1,"['cs.SE', 'cs.LG', 'cs.NE']"
1904.05526v2,A Selective Overview of Deep Learning,"['Jianqing Fan', 'Cong Ma', 'Yiqiao Zhong']","Deep learning has arguably achieved tremendous success in recent years. In
simple words, deep learning uses the composition of many nonlinear functions to
model the complex dependency between input features and labels. While neural
networks have a long history, recent advances have greatly improved their
performance in computer vision, natural language processing, etc. From the
statistical and scientific perspective, it is natural to ask: What is deep
learning? What are the new characteristics of deep learning, compared with
classical methods? What are the theoretical foundations of deep learning? To
answer these questions, we introduce common neural network models (e.g.,
convolutional neural nets, recurrent neural nets, generative adversarial nets)
and training techniques (e.g., stochastic gradient descent, dropout, batch
normalization) from a statistical point of view. Along the way, we highlight
new characteristics of deep learning (including depth and over-parametrization)
and explain their practical and theoretical benefits. We also sample recent
results on theories of deep learning, many of which are only suggestive. While
a complete understanding of deep learning remains elusive, we hope that our
perspectives and discussions serve as a stimulus for new statistical research.",2019-04-10T17:53:15Z,http://arxiv.org/pdf/1904.05526v2,"['stat.ML', 'cs.LG', 'math.ST', 'stat.ME', 'stat.TH']"
1603.07846v1,Deep Learning At Scale and At Ease,"['Wei Wang', 'Gang Chen', 'Haibo Chen', 'Tien Tuan Anh Dinh', 'Jinyang Gao', 'Beng Chin Ooi', 'Kian-Lee Tan', 'Sheng Wang']","Recently, deep learning techniques have enjoyed success in various multimedia
applications, such as image classification and multi-modal data analysis. Large
deep learning models are developed for learning rich representations of complex
data. There are two challenges to overcome before deep learning can be widely
adopted in multimedia and other applications. One is usability, namely the
implementation of different models and training algorithms must be done by
non-experts without much effort especially when the model is large and complex.
The other is scalability, that is the deep learning system must be able to
provision for a huge demand of computing resources for training large models
with massive datasets. To address these two challenges, in this paper, we
design a distributed deep learning platform called SINGA which has an intuitive
programming model based on the common layer abstraction of deep learning
models. Good scalability is achieved through flexible distributed training
architecture and specific optimization techniques. SINGA runs on GPUs as well
as on CPUs, and we show that it outperforms many other state-of-the-art deep
learning systems. Our experience with developing and training deep learning
models for real-life multimedia applications in SINGA shows that the platform
is both usable and scalable.",2016-03-25T08:46:02Z,http://arxiv.org/pdf/1603.07846v1,"['cs.LG', 'cs.DC']"
1710.03959v1,Deep learning in remote sensing: a review,"['Xiao Xiang Zhu', 'Devis Tuia', 'Lichao Mou', 'Gui-Song Xia', 'Liangpei Zhang', 'Feng Xu', 'Friedrich Fraundorfer']","Standing at the paradigm shift towards data-intensive science, machine
learning techniques are becoming increasingly important. In particular, as a
major breakthrough in the field, deep learning has proven as an extremely
powerful tool in many fields. Shall we embrace deep learning as the key to all?
Or, should we resist a 'black-box' solution? There are controversial opinions
in the remote sensing community. In this article, we analyze the challenges of
using deep learning for remote sensing data analysis, review the recent
advances, and provide resources to make deep learning in remote sensing
ridiculously simple to start with. More importantly, we advocate remote sensing
scientists to bring their expertise into deep learning, and use it as an
implicit general model to tackle unprecedented large-scale influential
challenges, such as climate change and urbanization.",2017-10-11T08:35:05Z,http://arxiv.org/pdf/1710.03959v1,"['cs.CV', 'eess.IV']"
1805.01890v2,RMDL: Random Multimodel Deep Learning for Classification,"['Kamran Kowsari', 'Mojtaba Heidarysafa', 'Donald E. Brown', 'Kiana Jafari Meimandi', 'Laura E. Barnes']","The continually increasing number of complex datasets each year necessitates
ever improving machine learning methods for robust and accurate categorization
of these data. This paper introduces Random Multimodel Deep Learning (RMDL): a
new ensemble, deep learning approach for classification. Deep learning models
have achieved state-of-the-art results across many domains. RMDL solves the
problem of finding the best deep learning structure and architecture while
simultaneously improving robustness and accuracy through ensembles of deep
learning architectures. RDML can accept as input a variety data to include
text, video, images, and symbolic. This paper describes RMDL and shows test
results for image and text data including MNIST, CIFAR-10, WOS, Reuters, IMDB,
and 20newsgroup. These test results show that RDML produces consistently better
performance than standard methods over a broad range of data types and
classification problems.",2018-05-03T19:36:43Z,http://arxiv.org/pdf/1805.01890v2,"['cs.LG', 'cs.AI', 'cs.CV', 'cs.NE', 'stat.ML']"
1808.05077v1,Exploiting Deep Learning for Persian Sentiment Analysis,"['Kia Dashtipour', 'Mandar Gogate', 'Ahsan Adeel', 'Cosimo Ieracitano', 'Hadi Larijani', 'Amir Hussain']","The rise of social media is enabling people to freely express their opinions
about products and services. The aim of sentiment analysis is to automatically
determine subject's sentiment (e.g., positive, negative, or neutral) towards a
particular aspect such as topic, product, movie, news etc. Deep learning has
recently emerged as a powerful machine learning technique to tackle a growing
demand of accurate sentiment analysis. However, limited work has been conducted
to apply deep learning algorithms to languages other than English, such as
Persian. In this work, two deep learning models (deep autoencoders and deep
convolutional neural networks (CNNs)) are developed and applied to a novel
Persian movie reviews dataset. The proposed deep learning models are analyzed
and compared with the state-of-the-art shallow multilayer perceptron (MLP)
based machine learning model. Simulation results demonstrate the enhanced
performance of deep learning over state-of-the-art MLP.",2018-08-15T13:46:54Z,http://arxiv.org/pdf/1808.05077v1,"['cs.CL', 'I.2.7; I.5.0']"
9705270v1,Neural Networks,"['Heinz Horner', 'Reimer Kuehn']","We review the theory of neural networks, as it has emerged in the last ten
years or so within the physics community, emphasizing questions of biological
relevance over those of importance in mathematical statistics and machine
learning theory.",1997-05-27T12:16:43Z,http://arxiv.org/pdf/cond-mat/9705270v1,"['cond-mat.dis-nn', 'q-bio']"
2106.13594v1,Bayesian Neural Networks: Essentials,['Daniel T. Chang'],"Bayesian neural networks utilize probabilistic layers that capture
uncertainty over weights and activations, and are trained using Bayesian
inference. Since these probabilistic layers are designed to be drop-in
replacement of their deterministic counter parts, Bayesian neural networks
provide a direct and natural way to extend conventional deep neural networks to
support probabilistic deep learning. However, it is nontrivial to understand,
design and train Bayesian neural networks due to their complexities. We discuss
the essentials of Bayesian neural networks including duality (deep neural
networks, probabilistic models), approximate Bayesian inference, Bayesian
priors, Bayesian posteriors, and deep variational learning. We use TensorFlow
Probability APIs and code examples for illustration. The main problem with
Bayesian neural networks is that the architecture of deep neural networks makes
it quite redundant, and costly, to account for uncertainty for a large number
of successive layers. Hybrid Bayesian neural networks, which use few
probabilistic layers judicially positioned in the networks, provide a practical
solution.",2021-06-22T13:54:17Z,http://arxiv.org/pdf/2106.13594v1,"['cs.LG', 'cs.AI']"
1907.11569v4,Making Neural Networks FAIR,"['Anna Nguyen', 'Tobias Weller', 'Michael Färber', 'York Sure-Vetter']","Research on neural networks has gained significant momentum over the past few
years. Because training is a resource-intensive process and training data
cannot always be made available to everyone, there has been a trend to reuse
pre-trained neural networks. As such, neural networks themselves have become
research data. In this paper, we first present the neural network ontology
FAIRnets Ontology, an ontology to make existing neural network models findable,
accessible, interoperable, and reusable according to the FAIR principles. Our
ontology allows us to model neural networks on a meta-level in a structured
way, including the representation of all network layers and their
characteristics. Secondly, we have modeled over 18,400 neural networks from
GitHub based on this ontology, which we provide to the public as a knowledge
graph called FAIRnets, ready to be used for recommending suitable neural
networks to data scientists.",2019-07-26T13:30:02Z,http://arxiv.org/pdf/1907.11569v4,"['cs.LG', 'stat.ML']"
2002.10078v3,On Hiding Neural Networks Inside Neural Networks,"['Chuan Guo', 'Ruihan Wu', 'Kilian Q. Weinberger']","Modern neural networks often contain significantly more parameters than the
size of their training data. We show that this excess capacity provides an
opportunity for embedding secret machine learning models within a trained
neural network. Our novel framework hides the existence of a secret neural
network with arbitrary desired functionality within a carrier network. We prove
theoretically that the secret network's detection is computationally infeasible
and demonstrate empirically that the carrier network does not compromise the
secret network's disguise. Our paper introduces a previously unknown
steganographic technique that can be exploited by adversaries if left
unchecked.",2020-02-24T05:18:29Z,http://arxiv.org/pdf/2002.10078v3,"['cs.LG', 'stat.ML']"
2304.05133v2,Lecture Notes: Neural Network Architectures,['Evelyn Herberg'],"These lecture notes provide an overview of Neural Network architectures from
a mathematical point of view. Especially, Machine Learning with Neural Networks
is seen as an optimization problem. Covered are an introduction to Neural
Networks and the following architectures: Feedforward Neural Network,
Convolutional Neural Network, ResNet, and Recurrent Neural Network.",2023-04-11T10:54:36Z,http://arxiv.org/pdf/2304.05133v2,"['cs.LG', 'math.OC', '68T07']"
1908.08926v1,Efficient Deep Neural Networks,['Bichen Wu'],"The success of deep neural networks (DNNs) is attributable to three factors:
increased compute capacity, more complex models, and more data. These factors,
however, are not always present, especially for edge applications such as
autonomous driving, augmented reality, and internet-of-things. Training DNNs
requires a large amount of data, which is difficult to obtain. Edge devices
such as mobile phones have limited compute capacity, and therefore, require
specialized and efficient DNNs. However, due to the enormous design space and
prohibitive training costs, designing efficient DNNs for different target
devices is challenging. So the question is, with limited data, compute
capacity, and model complexity, can we still successfully apply deep neural
networks?
  This dissertation focuses on the above problems and improving the efficiency
of deep neural networks at four levels. Model efficiency: we designed neural
networks for various computer vision tasks and achieved more than 10x faster
speed and lower energy. Data efficiency: we developed an advanced tool that
enables 6.2x faster annotation of a LiDAR point cloud. We also leveraged domain
adaptation to utilize simulated data, bypassing the need for real data.
Hardware efficiency: we co-designed neural networks and hardware accelerators
and achieved 11.6x faster inference. Design efficiency: the process of finding
the optimal neural networks is time-consuming. Our automated neural
architecture search algorithms discovered, using 421x lower computational cost
than previous search methods, models with state-of-the-art accuracy and
efficiency.",2019-08-20T23:26:04Z,http://arxiv.org/pdf/1908.08926v1,['cs.CV']
2104.07106v1,On quantum neural networks,['Alexandr A. Ezhov'],"The early definition of a quantum neural network as a new field that combines
the classical neurocomputing with quantum computing was rather vague and
satisfactory in the 2000s. The widespread in 2020 modern definition of a
quantum neural network as a model or machine learning algorithm that combines
the functions of quantum computing with artificial neural networks deprives
quantum neural networks of their fundamental importance. We argue that the
concept of a quantum neural network should be defined in terms of its most
general function as a tool for representing the amplitude of an arbitrary
quantum process. Our reasoning is based on the use of the Feynman path integral
formulation in quantum mechanics. This approach has been used in many works to
investigate the main problem of quantum cosmology, such as the origin of the
Universe. In fact, the question of whether our Universe is a quantum computer
was posed by Seth Lloyd, who gave the answer is yes, but we argue that the
universe can be thought of as a quantum neural network.",2021-04-12T18:30:30Z,http://arxiv.org/pdf/2104.07106v1,['quant-ph']
2207.01578v2,Quantum Neural Network Compression,"['Zhirui Hu', 'Peiyan Dong', 'Zhepeng Wang', 'Youzuo Lin', 'Yanzhi Wang', 'Weiwen Jiang']","Model compression, such as pruning and quantization, has been widely applied
to optimize neural networks on resource-limited classical devices. Recently,
there are growing interest in variational quantum circuits (VQC), that is, a
type of neural network on quantum computers (a.k.a., quantum neural networks).
It is well known that the near-term quantum devices have high noise and limited
resources (i.e., quantum bits, qubits); yet, how to compress quantum neural
networks has not been thoroughly studied. One might think it is straightforward
to apply the classical compression techniques to quantum scenarios. However,
this paper reveals that there exist differences between the compression of
quantum and classical neural networks. Based on our observations, we claim that
the compilation/traspilation has to be involved in the compression process. On
top of this, we propose the very first systematical framework, namely CompVQC,
to compress quantum neural networks (QNNs).In CompVQC, the key component is a
novel compression algorithm, which is based on the alternating direction method
of multipliers (ADMM) approach. Experiments demonstrate the advantage of the
CompVQC, reducing the circuit depth (almost over 2.5 %) with a negligible
accuracy drop (<1%), which outperforms other competitors. Another promising
truth is our CompVQC can indeed promote the robustness of the QNN on the
near-term noisy quantum devices.",2022-07-04T16:57:46Z,http://arxiv.org/pdf/2207.01578v2,"['quant-ph', 'cs.AI']"
1801.07710v2,Bayesian Neural Networks,"['Vikram Mullachery', 'Aniruddh Khera', 'Amir Husain']","This paper describes and discusses Bayesian Neural Network (BNN). The paper
showcases a few different applications of them for classification and
regression problems. BNNs are comprised of a Probabilistic Model and a Neural
Network. The intent of such a design is to combine the strengths of Neural
Networks and Stochastic modeling. Neural Networks exhibit continuous function
approximator capabilities. Stochastic models allow direct specification of a
model with known interaction between parameters to generate data. During the
prediction phase, stochastic models generate a complete posterior distribution
and produce probabilistic guarantees on the predictions. Thus BNNs are a unique
combination of neural network and stochastic models with the stochastic model
forming the core of this integration. BNNs can then produce probabilistic
guarantees on it's predictions and also generate the distribution of parameters
that it has learnt from the observations. That means, in the parameter space,
one can deduce the nature and shape of the neural network's learnt parameters.
These two characteristics makes them highly attractive to theoreticians as well
as practitioners. Recently there has been a lot of activity in this area, with
the advent of numerous probabilistic programming libraries such as: PyMC3,
Edward, Stan etc. Further this area is rapidly gaining ground as a standard
machine learning approach for numerous problems",2018-01-23T20:52:44Z,http://arxiv.org/pdf/1801.07710v2,"['cs.LG', 'cs.AI', 'stat.ML']"
2105.03388v2,Hierarchical Graph Neural Networks,['Stanislav Sobolevsky'],"Over the recent years, Graph Neural Networks have become increasingly popular
in network analytic and beyond. With that, their architecture noticeable
diverges from the classical multi-layered hierarchical organization of the
traditional neural networks. At the same time, many conventional approaches in
network science efficiently utilize the hierarchical approaches to account for
the hierarchical organization of the networks, and recent works emphasize their
critical importance. This paper aims to connect the dots between the
traditional Neural Network and the Graph Neural Network architectures as well
as the network science approaches, harnessing the power of the hierarchical
network organization. A Hierarchical Graph Neural Network architecture is
proposed, supplementing the original input network layer with the hierarchy of
auxiliary network layers and organizing the computational scheme updating the
node features through both - horizontal network connections within each layer
as well as the vertical connection between the layers. It enables simultaneous
learning of the individual node features along with the aggregated network
features at variable resolution and uses them to improve the convergence and
stability of the individual node feature learning. The proposed Hierarchical
Graph Neural network architecture is successfully evaluated on the network
embedding and modeling as well as network classification, node labeling, and
community tasks and demonstrates increased efficiency in those.",2021-05-07T16:47:18Z,http://arxiv.org/pdf/2105.03388v2,"['cs.LG', 'cs.AI', 'math.CO', 'physics.data-an', '68T07, 05C85']"
2206.05562v1,Parameter Convex Neural Networks,"['Jingcheng Zhou', 'Wei Wei', 'Xing Li', 'Bowen Pang', 'Zhiming Zheng']","Deep learning utilizing deep neural networks (DNNs) has achieved a lot of
success recently in many important areas such as computer vision, natural
language processing, and recommendation systems. The lack of convexity for DNNs
has been seen as a major disadvantage of many optimization methods, such as
stochastic gradient descent, which greatly reduces the genelization of neural
network applications. We realize that the convexity make sense in the neural
network and propose the exponential multilayer neural network (EMLP), a class
of parameter convex neural network (PCNN) which is convex with regard to the
parameters of the neural network under some conditions that can be realized.
Besides, we propose the convexity metric for the two-layer EGCN and test the
accuracy when the convexity metric changes. For late experiments, we use the
same architecture to make the exponential graph convolutional network (EGCN)
and do the experiment on the graph classificaion dataset in which our model
EGCN performs better than the graph convolutional network (GCN) and the graph
attention network (GAT).",2022-06-11T16:44:59Z,http://arxiv.org/pdf/2206.05562v1,"['cs.LG', 'cs.AI']"
1209.4855v1,The Future of Neural Networks,"['Sachin Lakra', 'T. V. Prasad', 'G. Ramakrishna']","The paper describes some recent developments in neural networks and discusses
the applicability of neural networks in the development of a machine that
mimics the human brain. The paper mentions a new architecture, the pulsed
neural network that is being considered as the next generation of neural
networks. The paper also explores the use of memristors in the development of a
brain-like computer called the MoNETA. A new model, multi/infinite dimensional
neural networks, are a recent development in the area of advanced neural
networks. The paper concludes that the need of neural networks in the
development of human-like technology is essential and may be non-expendable for
it.",2012-09-20T14:14:59Z,http://arxiv.org/pdf/1209.4855v1,['cs.NE']
1810.10627v2,Streaming Graph Neural Networks,"['Yao Ma', 'Ziyi Guo', 'Zhaochun Ren', 'Eric Zhao', 'Jiliang Tang', 'Dawei Yin']","Graphs are essential representations of many real-world data such as social
networks. Recent years have witnessed the increasing efforts made to extend the
neural network models to graph-structured data. These methods, which are
usually known as the graph neural networks, have been applied to advance many
graphs related tasks such as reasoning dynamics of the physical system, graph
classification, and node classification. Most of the existing graph neural
network models have been designed for static graphs, while many real-world
graphs are inherently dynamic. For example, social networks are naturally
evolving as new users joining and new relations being created. Current graph
neural network models cannot utilize the dynamic information in dynamic graphs.
However, the dynamic information has been proven to enhance the performance of
many graph analytic tasks such as community detection and link prediction.
Hence, it is necessary to design dedicated graph neural networks for dynamic
graphs. In this paper, we propose DGNN, a new {\bf D}ynamic {\bf G}raph {\bf
N}eural {\bf N}etwork model, which can model the dynamic information as the
graph evolving. In particular, the proposed framework can keep updating node
information by capturing the sequential information of edges (interactions),
the time intervals between edges and information propagation coherently.
Experimental results on various dynamic graphs demonstrate the effectiveness of
the proposed framework.",2018-10-24T21:20:05Z,http://arxiv.org/pdf/1810.10627v2,"['cs.LG', 'stat.ML']"
2310.10013v1,Riemannian Residual Neural Networks,"['Isay Katsman', 'Eric Ming Chen', 'Sidhanth Holalkere', 'Anna Asch', 'Aaron Lou', 'Ser-Nam Lim', 'Christopher De Sa']","Recent methods in geometric deep learning have introduced various neural
networks to operate over data that lie on Riemannian manifolds. Such networks
are often necessary to learn well over graphs with a hierarchical structure or
to learn over manifold-valued data encountered in the natural sciences. These
networks are often inspired by and directly generalize standard Euclidean
neural networks. However, extending Euclidean networks is difficult and has
only been done for a select few manifolds. In this work, we examine the
residual neural network (ResNet) and show how to extend this construction to
general Riemannian manifolds in a geometrically principled manner. Originally
introduced to help solve the vanishing gradient problem, ResNets have become
ubiquitous in machine learning due to their beneficial learning properties,
excellent empirical results, and easy-to-incorporate nature when building
varied neural networks. We find that our Riemannian ResNets mirror these
desirable properties: when compared to existing manifold neural networks
designed to learn over hyperbolic space and the manifold of symmetric positive
definite matrices, we outperform both kinds of networks in terms of relevant
testing metrics and training dynamics.",2023-10-16T02:12:32Z,http://arxiv.org/pdf/2310.10013v1,"['stat.ML', 'cs.LG']"
2405.03725v2,Deep Oscillatory Neural Network,"['Nurani Rajagopal Rohan', 'Vigneswaran C', 'Sayan Ghosh', 'Kishore Rajendran', 'Gaurav A', 'V Srinivasa Chakravarthy']","We propose a novel, brain-inspired deep neural network model known as the
Deep Oscillatory Neural Network (DONN). Deep neural networks like the Recurrent
Neural Networks indeed possess sequence processing capabilities but the
internal states of the network are not designed to exhibit brain-like
oscillatory activity. With this motivation, the DONN is designed to have
oscillatory internal dynamics. Neurons of the DONN are either nonlinear neural
oscillators or traditional neurons with sigmoidal or ReLU activation. The
neural oscillator used in the model is the Hopf oscillator, with the dynamics
described in the complex domain. Input can be presented to the neural
oscillator in three possible modes. The sigmoid and ReLU neurons also use
complex-valued extensions. All the weight stages are also complex-valued.
Training follows the general principle of weight change by minimizing the
output error and therefore has an overall resemblance to complex
backpropagation. A generalization of DONN to convolutional networks known as
the Oscillatory Convolutional Neural Network is also proposed. The two proposed
oscillatory networks are applied to a variety of benchmark problems in signal
and image/video processing. The performance of the proposed models is either
comparable or superior to published results on the same data sets.",2024-05-06T06:17:16Z,http://arxiv.org/pdf/2405.03725v2,"['cs.NE', 'cs.AI', 'cs.LG']"
2412.14695v2,Lorentzian Residual Neural Networks,"['Neil He', 'Menglin Yang', 'Rex Ying']","Hyperbolic neural networks have emerged as a powerful tool for modeling
hierarchical data structures prevalent in real-world datasets. Notably,
residual connections, which facilitate the direct flow of information across
layers, have been instrumental in the success of deep neural networks. However,
current methods for constructing hyperbolic residual networks suffer from
limitations such as increased model complexity, numerical instability, and
errors due to multiple mappings to and from the tangent space. To address these
limitations, we introduce LResNet, a novel Lorentzian residual neural network
based on the weighted Lorentzian centroid in the Lorentz model of hyperbolic
geometry. Our method enables the efficient integration of residual connections
in Lorentz hyperbolic neural networks while preserving their hierarchical
representation capabilities. We demonstrate that our method can theoretically
derive previous methods while offering improved stability, efficiency, and
effectiveness. Extensive experiments on both graph and vision tasks showcase
the superior performance and robustness of our method compared to
state-of-the-art Euclidean and hyperbolic alternatives. Our findings highlight
the potential of LResNet for building more expressive neural networks in
hyperbolic embedding space as a generally applicable method to multiple
architectures, including CNNs, GNNs, and graph Transformers.",2024-12-19T09:56:01Z,http://arxiv.org/pdf/2412.14695v2,['cs.LG']
1609.07152v3,Input Convex Neural Networks,"['Brandon Amos', 'Lei Xu', 'J. Zico Kolter']","This paper presents the input convex neural network architecture. These are
scalar-valued (potentially deep) neural networks with constraints on the
network parameters such that the output of the network is a convex function of
(some of) the inputs. The networks allow for efficient inference via
optimization over some inputs to the network given others, and can be applied
to settings including structured prediction, data imputation, reinforcement
learning, and others. In this paper we lay the basic groundwork for these
models, proposing methods for inference, optimization and learning, and analyze
their representational power. We show that many existing neural network
architectures can be made input-convex with a minor modification, and develop
specialized optimization algorithms tailored to this setting. Finally, we
highlight the performance of the methods on multi-label prediction, image
completion, and reinforcement learning problems, where we show improvement over
the existing state of the art in many cases.",2016-09-22T20:10:57Z,http://arxiv.org/pdf/1609.07152v3,"['cs.LG', 'math.OC']"
1711.00449v2,Attacking Binarized Neural Networks,"['Angus Galloway', 'Graham W. Taylor', 'Medhat Moussa']","Neural networks with low-precision weights and activations offer compelling
efficiency advantages over their full-precision equivalents. The two most
frequently discussed benefits of quantization are reduced memory consumption,
and a faster forward pass when implemented with efficient bitwise operations.
We propose a third benefit of very low-precision neural networks: improved
robustness against some adversarial attacks, and in the worst case, performance
that is on par with full-precision models. We focus on the very low-precision
case where weights and activations are both quantized to $\pm$1, and note that
stochastically quantizing weights in just one layer can sharply reduce the
impact of iterative attacks. We observe that non-scaled binary neural networks
exhibit a similar effect to the original defensive distillation procedure that
led to gradient masking, and a false notion of security. We address this by
conducting both black-box and white-box experiments with binary models that do
not artificially mask gradients.",2017-11-01T17:28:26Z,http://arxiv.org/pdf/1711.00449v2,"['cs.LG', 'stat.ML']"
1908.05164v3,Unconstrained Monotonic Neural Networks,"['Antoine Wehenkel', 'Gilles Louppe']","Monotonic neural networks have recently been proposed as a way to define
invertible transformations. These transformations can be combined into powerful
autoregressive flows that have been shown to be universal approximators of
continuous probability distributions. Architectures that ensure monotonicity
typically enforce constraints on weights and activation functions, which
enables invertibility but leads to a cap on the expressiveness of the resulting
transformations. In this work, we propose the Unconstrained Monotonic Neural
Network (UMNN) architecture based on the insight that a function is monotonic
as long as its derivative is strictly positive. In particular, this latter
condition can be enforced with a free-form neural network whose only constraint
is the positiveness of its output. We evaluate our new invertible building
block within a new autoregressive flow (UMNN-MAF) and demonstrate its
effectiveness on density estimation experiments. We also illustrate the ability
of UMNNs to improve variational inference.",2019-08-14T15:11:31Z,http://arxiv.org/pdf/1908.05164v3,"['cs.LG', 'cs.NE', 'stat.ML']"
2006.06629v1,Growing Artificial Neural Networks,"['John Mixter', 'Ali Akoglu']","Pruning is a legitimate method for reducing the size of a neural network to
fit in low SWaP hardware, but the networks must be trained and pruned offline.
We propose an algorithm, Artificial Neurogenesis (ANG), that grows rather than
prunes the network and enables neural networks to be trained and executed in
low SWaP embedded hardware. ANG accomplishes this by using the training data to
determine critical connections between layers before the actual training takes
place. Our experiments use a modified LeNet-5 as a baseline neural network that
achieves a test accuracy of 98.74% using a total of 61,160 weights. An ANG
grown network achieves a test accuracy of 98.80% with only 21,211 weights.",2020-06-11T17:25:51Z,http://arxiv.org/pdf/2006.06629v1,"['cs.NE', 'cs.LG']"
1809.03368v1,Probabilistic Binary Neural Networks,"['Jorn W. T. Peters', 'Max Welling']","Low bit-width weights and activations are an effective way of combating the
increasing need for both memory and compute power of Deep Neural Networks. In
this work, we present a probabilistic training method for Neural Network with
both binary weights and activations, called BLRNet. By embracing stochasticity
during training, we circumvent the need to approximate the gradient of
non-differentiable functions such as sign(), while still obtaining a fully
Binary Neural Network at test time. Moreover, it allows for anytime ensemble
predictions for improved performance and uncertainty estimates by sampling from
the weight distribution. Since all operations in a layer of the BLRNet operate
on random variables, we introduce stochastic versions of Batch Normalization
and max pooling, which transfer well to a deterministic network at test time.
We evaluate the BLRNet on multiple standardized benchmarks.",2018-09-10T14:51:08Z,http://arxiv.org/pdf/1809.03368v1,"['cs.LG', 'stat.ML']"
1907.00262v1,Dissecting Pruned Neural Networks,"['Jonathan Frankle', 'David Bau']","Pruning is a standard technique for removing unnecessary structure from a
neural network to reduce its storage footprint, computational demands, or
energy consumption. Pruning can reduce the parameter-counts of many
state-of-the-art neural networks by an order of magnitude without compromising
accuracy, meaning these networks contain a vast amount of unnecessary
structure. In this paper, we study the relationship between pruning and
interpretability. Namely, we consider the effect of removing unnecessary
structure on the number of hidden units that learn disentangled representations
of human-recognizable concepts as identified by network dissection. We aim to
evaluate how the interpretability of pruned neural networks changes as they are
compressed. We find that pruning has no detrimental effect on this measure of
interpretability until so few parameters remain that accuracy beings to drop.
Resnet-50 models trained on ImageNet maintain the same number of interpretable
concepts and units until more than 90% of parameters have been pruned.",2019-06-29T19:27:57Z,http://arxiv.org/pdf/1907.00262v1,"['cs.LG', 'cs.CV', 'cs.NE', 'stat.ML']"
1910.03879v2,Dissecting Deep Neural Networks,"['Haakon Robinson', 'Adil Rasheed', 'Omer San']","In exchange for large quantities of data and processing power, deep neural
networks have yielded models that provide state of the art predication
capabilities in many fields. However, a lack of strong guarantees on their
behaviour have raised concerns over their use in safety-critical applications.
A first step to understanding these networks is to develop alternate
representations that allow for further analysis. It has been shown that neural
networks with piecewise affine activation functions are themselves piecewise
affine, with their domains consisting of a vast number of linear regions. So
far, the research on this topic has focused on counting the number of linear
regions, rather than obtaining explicit piecewise affine representations. This
work presents a novel algorithm that can compute the piecewise affine form of
any fully connected neural network with rectified linear unit activations.",2019-10-09T10:05:23Z,http://arxiv.org/pdf/1910.03879v2,"['cs.LG', 'cs.NE', 'stat.ML']"
2002.02815v1,Switchable Precision Neural Networks,"['Luis Guerra', 'Bohan Zhuang', 'Ian Reid', 'Tom Drummond']","Instantaneous and on demand accuracy-efficiency trade-off has been recently
explored in the context of neural networks slimming. In this paper, we propose
a flexible quantization strategy, termed Switchable Precision neural Networks
(SP-Nets), to train a shared network capable of operating at multiple
quantization levels. At runtime, the network can adjust its precision on the
fly according to instant memory, latency, power consumption and accuracy
demands. For example, by constraining the network weights to 1-bit with
switchable precision activations, our shared network spans from BinaryConnect
to Binarized Neural Network, allowing to perform dot-products using only
summations or bit operations. In addition, a self-distillation scheme is
proposed to increase the performance of the quantized switches. We tested our
approach with three different quantizers and demonstrate the performance of
SP-Nets against independently trained quantized models in classification
accuracy for Tiny ImageNet and ImageNet datasets using ResNet-18 and MobileNet
architectures.",2020-02-07T14:43:44Z,http://arxiv.org/pdf/2002.02815v1,['cs.CV']
2010.11189v2,Quantum Deformed Neural Networks,"['Roberto Bondesan', 'Max Welling']","We develop a new quantum neural network layer designed to run efficiently on
a quantum computer but that can be simulated on a classical computer when
restricted in the way it entangles input states. We first ask how a classical
neural network architecture, both fully connected or convolutional, can be
executed on a quantum computer using quantum phase estimation. We then deform
the classical layer into a quantum design which entangles activations and
weights into quantum superpositions. While the full model would need the
exponential speedups delivered by a quantum computer, a restricted class of
designs represent interesting new classical network layers that still use
quantum features. We show that these quantum deformed neural networks can be
trained and executed on normal data such as images, and even classically
deliver modest improvements over standard architectures.",2020-10-21T09:46:12Z,http://arxiv.org/pdf/2010.11189v2,"['quant-ph', 'cs.LG']"
2209.03416v5,Bispectral Neural Networks,"['Sophia Sanborn', 'Christian Shewmake', 'Bruno Olshausen', 'Christopher Hillar']","We present a neural network architecture, Bispectral Neural Networks (BNNs)
for learning representations that are invariant to the actions of compact
commutative groups on the space over which a signal is defined. The model
incorporates the ansatz of the bispectrum, an analytically defined group
invariant that is complete -- that is, it preserves all signal structure while
removing only the variation due to group actions. Here, we demonstrate that
BNNs are able to simultaneously learn groups, their irreducible
representations, and corresponding equivariant and complete-invariant maps
purely from the symmetries implicit in data. Further, we demonstrate that the
completeness property endows these networks with strong invariance-based
adversarial robustness. This work establishes Bispectral Neural Networks as a
powerful computational primitive for robust invariant representation learning",2022-09-07T18:34:48Z,http://arxiv.org/pdf/2209.03416v5,['cs.LG']
2012.06800v1,Delay Differential Neural Networks,"['Srinivas Anumasa', 'P. K. Srijith']","Neural ordinary differential equations (NODEs) treat computation of
intermediate feature vectors as trajectories of ordinary differential equation
parameterized by a neural network. In this paper, we propose a novel model,
delay differential neural networks (DDNN), inspired by delay differential
equations (DDEs). The proposed model considers the derivative of the hidden
feature vector as a function of the current feature vector and past feature
vectors (history). The function is modelled as a neural network and
consequently, it leads to continuous depth alternatives to many recent ResNet
variants. We propose two different DDNN architectures, depending on the way
current and past feature vectors are considered. For training DDNNs, we provide
a memory-efficient adjoint method for computing gradients and back-propagate
through the network. DDNN improves the data efficiency of NODE by further
reducing the number of parameters without affecting the generalization
performance. Experiments conducted on synthetic and real-world image
classification datasets such as Cifar10 and Cifar100 show the effectiveness of
the proposed models.",2020-12-12T12:20:54Z,http://arxiv.org/pdf/2012.06800v1,"['cs.LG', 'cs.CV', 'cs.NE']"
2102.10472v3,Learning Neural Network Subspaces,"['Mitchell Wortsman', 'Maxwell Horton', 'Carlos Guestrin', 'Ali Farhadi', 'Mohammad Rastegari']","Recent observations have advanced our understanding of the neural network
optimization landscape, revealing the existence of (1) paths of high accuracy
containing diverse solutions and (2) wider minima offering improved
performance. Previous methods observing diverse paths require multiple training
runs. In contrast we aim to leverage both property (1) and (2) with a single
method and in a single training run. With a similar computational cost as
training one model, we learn lines, curves, and simplexes of high-accuracy
neural networks. These neural network subspaces contain diverse solutions that
can be ensembled, approaching the ensemble performance of independently trained
networks without the training cost. Moreover, using the subspace midpoint
boosts accuracy, calibration, and robustness to label noise, outperforming
Stochastic Weight Averaging.",2021-02-20T23:26:58Z,http://arxiv.org/pdf/2102.10472v3,"['cs.LG', 'cs.CV']"
2106.13834v2,Ladder Polynomial Neural Networks,"['Li-Ping Liu', 'Ruiyuan Gu', 'Xiaozhe Hu']","Polynomial functions have plenty of useful analytical properties, but they
are rarely used as learning models because their function class is considered
to be restricted. This work shows that when trained properly polynomial
functions can be strong learning models. Particularly this work constructs
polynomial feedforward neural networks using the product activation, a new
activation function constructed from multiplications. The new neural network is
a polynomial function and provides accurate control of its polynomial order. It
can be trained by standard training techniques such as batch normalization and
dropout. This new feedforward network covers several previous polynomial models
as special cases. Compared with common feedforward neural networks, the
polynomial feedforward network has closed-form calculations of a few
interesting quantities, which are very useful in Bayesian learning. In a series
of regression and classification tasks in the empirical study, the proposed
model outperforms previous polynomial models.",2021-06-25T18:16:48Z,http://arxiv.org/pdf/2106.13834v2,"['cs.LG', 'cs.NE']"
2210.02113v3,Optimization-Informed Neural Networks,"['Dawen Wu', 'Abdel Lisser']","Solving constrained nonlinear optimization problems (CNLPs) is a longstanding
problem that arises in various fields, e.g., economics, computer science, and
engineering. We propose optimization-informed neural networks (OINN), a deep
learning approach to solve CNLPs. By neurodynamic optimization methods, a CNLP
is first reformulated as an initial value problem (IVP) involving an ordinary
differential equation (ODE) system. A neural network model is then used as an
approximate solution for this IVP, with the endpoint being the prediction to
the CNLP. We propose a novel training algorithm that directs the model to hold
the best prediction during training. In a nutshell, OINN transforms a CNLP into
a neural network training problem. By doing so, we can solve CNLPs based on
deep learning infrastructure only, without using standard optimization solvers
or numerical integration solvers. The effectiveness of the proposed approach is
demonstrated through a collection of classical problems, e.g., variational
inequalities, nonlinear complementary problems, and standard CNLPs.",2022-10-05T09:28:55Z,http://arxiv.org/pdf/2210.02113v3,"['math.OC', 'cs.LG', 'cs.NA', 'math.NA']"
2211.14632v1,Why Neural Networks Work,"['Sayandev Mukherjee', 'Bernardo A. Huberman']","We argue that many properties of fully-connected feedforward neural networks
(FCNNs), also called multi-layer perceptrons (MLPs), are explainable from the
analysis of a single pair of operations, namely a random projection into a
higher-dimensional space than the input, followed by a sparsification
operation. For convenience, we call this pair of successive operations
expand-and-sparsify following the terminology of Dasgupta. We show how
expand-and-sparsify can explain the observed phenomena that have been discussed
in the literature, such as the so-called Lottery Ticket Hypothesis, the
surprisingly good performance of randomly-initialized untrained neural
networks, the efficacy of Dropout in training and most importantly, the
mysterious generalization ability of overparameterized models, first
highlighted by Zhang et al. and subsequently identified even in non-neural
network models by Belkin et al.",2022-11-26T18:15:17Z,http://arxiv.org/pdf/2211.14632v1,"['cs.LG', 'cs.CY', 'cs.NE', 'stat.ML']"
2307.04526v3,Self-Expanding Neural Networks,"['Rupert Mitchell', 'Robin Menzenbach', 'Kristian Kersting', 'Martin Mundt']","The results of training a neural network are heavily dependent on the
architecture chosen; and even a modification of only its size, however small,
typically involves restarting the training process. In contrast to this, we
begin training with a small architecture, only increase its capacity as
necessary for the problem, and avoid interfering with previous optimization
while doing so. We thereby introduce a natural gradient based approach which
intuitively expands both the width and depth of a neural network when this is
likely to substantially reduce the hypothetical converged training loss. We
prove an upper bound on the ``rate'' at which neurons are added, and a
computationally cheap lower bound on the expansion score. We illustrate the
benefits of such Self-Expanding Neural Networks with full connectivity and
convolutions in both classification and regression problems, including those
where the appropriate architecture size is substantially uncertain a priori.",2023-07-10T12:49:59Z,http://arxiv.org/pdf/2307.04526v3,"['cs.LG', 'I.2.6']"
2402.13144v3,Neural Network Diffusion,"['Kai Wang', 'Dongwen Tang', 'Boya Zeng', 'Yida Yin', 'Zhaopan Xu', 'Yukun Zhou', 'Zelin Zang', 'Trevor Darrell', 'Zhuang Liu', 'Yang You']","Diffusion models have achieved remarkable success in image and video
generation. In this work, we demonstrate that diffusion models can also
\textit{generate high-performing neural network parameters}. Our approach is
simple, utilizing an autoencoder and a diffusion model. The autoencoder
extracts latent representations of a subset of the trained neural network
parameters. Next, a diffusion model is trained to synthesize these latent
representations from random noise. This model then generates new
representations, which are passed through the autoencoder's decoder to produce
new subsets of high-performing network parameters. Across various architectures
and datasets, our approach consistently generates models with comparable or
improved performance over trained networks, with minimal additional cost.
Notably, we empirically find that the generated models are not memorizing the
trained ones. Our results encourage more exploration into the versatile use of
diffusion models. Our code is available
\href{https://github.com/NUS-HPC-AI-Lab/Neural-Network-Diffusion}{here}.",2024-02-20T16:59:03Z,http://arxiv.org/pdf/2402.13144v3,"['cs.LG', 'cs.CV']"
2508.14101v1,Implicit Hypergraph Neural Network,"['Akash Choudhuri', 'Yongjian Zhong', 'Bijaya Adhikari']","Hypergraphs offer a generalized framework for capturing high-order
relationships between entities and have been widely applied in various domains,
including healthcare, social networks, and bioinformatics. Hypergraph neural
networks, which rely on message-passing between nodes over hyperedges to learn
latent representations, have emerged as the method of choice for predictive
tasks in many of these domains. These approaches typically perform only a small
number of message-passing rounds to learn the representations, which they then
utilize for predictions. The small number of message-passing rounds comes at a
cost, as the representations only capture local information and forego
long-range high-order dependencies. However, as we demonstrate, blindly
increasing the message-passing rounds to capture long-range dependency also
degrades the performance of hyper-graph neural networks.
  Recent works have demonstrated that implicit graph neural networks capture
long-range dependencies in standard graphs while maintaining performance.
Despite their popularity, prior work has not studied long-range dependency
issues on hypergraph neural networks. Here, we first demonstrate that existing
hypergraph neural networks lose predictive power when aggregating more
information to capture long-range dependency. We then propose Implicit
Hypergraph Neural Network (IHNN), a novel framework that jointly learns
fixed-point representations for both nodes and hyperedges in an end-to-end
manner to alleviate this issue. Leveraging implicit differentiation, we
introduce a tractable projected gradient descent approach to train the model
efficiently. Extensive experiments on real-world hypergraphs for node
classification demonstrate that IHNN outperforms the closest prior works in
most settings, establishing a new state-of-the-art in hypergraph learning.",2025-08-16T16:58:59Z,http://arxiv.org/pdf/2508.14101v1,"['cs.LG', 'cs.AI']"
1705.08557v1,Grounded Recurrent Neural Networks,"['Ankit Vani', 'Yacine Jernite', 'David Sontag']","In this work, we present the Grounded Recurrent Neural Network (GRNN), a
recurrent neural network architecture for multi-label prediction which
explicitly ties labels to specific dimensions of the recurrent hidden state (we
call this process ""grounding""). The approach is particularly well-suited for
extracting large numbers of concepts from text. We apply the new model to
address an important problem in healthcare of understanding what medical
concepts are discussed in clinical text. Using a publicly available dataset
derived from Intensive Care Units, we learn to label a patient's diagnoses and
procedures from their discharge summary. Our evaluation shows a clear advantage
to using our proposed architecture over a variety of strong baselines.",2017-05-23T23:17:49Z,http://arxiv.org/pdf/1705.08557v1,"['stat.ML', 'cs.CL', 'cs.LG', 'cs.NE']"
1706.07966v1,Irregular Convolutional Neural Networks,"['Jiabin Ma', 'Wei Wang', 'Liang Wang']","Convolutional kernels are basic and vital components of deep Convolutional
Neural Networks (CNN). In this paper, we equip convolutional kernels with shape
attributes to generate the deep Irregular Convolutional Neural Networks (ICNN).
Compared to traditional CNN applying regular convolutional kernels like
${3\times3}$, our approach trains irregular kernel shapes to better fit the
geometric variations of input features. In other words, shapes are learnable
parameters in addition to weights. The kernel shapes and weights are learned
simultaneously during end-to-end training with the standard back-propagation
algorithm. Experiments for semantic segmentation are implemented to validate
the effectiveness of our proposed ICNN.",2017-06-24T14:19:41Z,http://arxiv.org/pdf/1706.07966v1,['cs.CV']
1712.05245v2,Pointwise Convolutional Neural Networks,"['Binh-Son Hua', 'Minh-Khoi Tran', 'Sai-Kit Yeung']","Deep learning with 3D data such as reconstructed point clouds and CAD models
has received great research interests recently. However, the capability of
using point clouds with convolutional neural network has been so far not fully
explored. In this paper, we present a convolutional neural network for semantic
segmentation and object recognition with 3D point clouds. At the core of our
network is pointwise convolution, a new convolution operator that can be
applied at each point of a point cloud. Our fully convolutional network design,
while being surprisingly simple to implement, can yield competitive accuracy in
both semantic segmentation and object recognition task.",2017-12-14T14:25:52Z,http://arxiv.org/pdf/1712.05245v2,"['cs.CV', 'cs.LG']"
1805.06082v2,Optical Neural Networks,"['Grant Fennessy', 'Yevgeniy Vorobeychik']","We develop a novel optical neural network (ONN) framework which introduces a
degree of scalar invariance to image classification estima- tion. Taking a hint
from the human eye, which has higher resolution near the center of the retina,
images are broken out into multiple levels of varying zoom based on a focal
point. Each level is passed through an identical convolutional neural network
(CNN) in a Siamese fashion, and the results are recombined to produce a high
accuracy estimate of the object class. ONNs act as a wrapper around existing
CNNs, and can thus be applied to many existing algorithms to produce notable
accuracy improvements without having to change the underlying architecture.",2018-05-16T01:12:11Z,http://arxiv.org/pdf/1805.06082v2,['cs.CV']
1904.03955v2,Kervolutional Neural Networks,"['Chen Wang', 'Jianfei Yang', 'Lihua Xie', 'Junsong Yuan']","Convolutional neural networks (CNNs) have enabled the state-of-the-art
performance in many computer vision tasks. However, little effort has been
devoted to establishing convolution in non-linear space. Existing works mainly
leverage on the activation layers, which can only provide point-wise
non-linearity. To solve this problem, a new operation, kervolution (kernel
convolution), is introduced to approximate complex behaviors of human
perception systems leveraging on the kernel trick. It generalizes convolution,
enhances the model capacity, and captures higher order interactions of
features, via patch-wise kernel functions, but without introducing additional
parameters. Extensive experiments show that kervolutional neural networks (KNN)
achieve higher accuracy and faster convergence than baseline CNN.",2019-04-08T11:10:51Z,http://arxiv.org/pdf/1904.03955v2,['cs.CV']
1904.07785v1,Graph Wavelet Neural Network,"['Bingbing Xu', 'Huawei Shen', 'Qi Cao', 'Yunqi Qiu', 'Xueqi Cheng']","We present graph wavelet neural network (GWNN), a novel graph convolutional
neural network (CNN), leveraging graph wavelet transform to address the
shortcomings of previous spectral graph CNN methods that depend on graph
Fourier transform. Different from graph Fourier transform, graph wavelet
transform can be obtained via a fast algorithm without requiring matrix
eigendecomposition with high computational cost. Moreover, graph wavelets are
sparse and localized in vertex domain, offering high efficiency and good
interpretability for graph convolution. The proposed GWNN significantly
outperforms previous spectral graph CNNs in the task of graph-based
semi-supervised classification on three benchmark datasets: Cora, Citeseer and
Pubmed.",2019-04-12T08:20:08Z,http://arxiv.org/pdf/1904.07785v1,"['cs.LG', 'stat.ML']"
1909.13334v2,Symplectic Recurrent Neural Networks,"['Zhengdao Chen', 'Jianyu Zhang', 'Martin Arjovsky', 'Léon Bottou']","We propose Symplectic Recurrent Neural Networks (SRNNs) as learning
algorithms that capture the dynamics of physical systems from observed
trajectories. An SRNN models the Hamiltonian function of the system by a neural
network and furthermore leverages symplectic integration, multiple-step
training and initial state optimization to address the challenging numerical
issues associated with Hamiltonian systems. We show that SRNNs succeed reliably
on complex and noisy Hamiltonian systems. We also show how to augment the SRNN
integration scheme in order to handle stiff dynamical systems such as bouncing
billiards.",2019-09-29T18:04:07Z,http://arxiv.org/pdf/1909.13334v2,"['cs.LG', 'stat.ML']"
2011.05062v2,Quantum Spike Neural Network,"['Yanhu Chen', 'Hongxiang Guo', 'Cen Wang', 'Xiong Gao', 'Jian Wu']","Utilizing quantum computers to deploy artificial neural networks (ANNs) will
bring the potential of significant advancements in both speed and scale. In
this paper, we propose a kind of quantum spike neural networks (SNNs) as well
as comprehensively evaluate and give a detailed mathematical proof for the
quantum SNNs, including its successful probability, calculation accuracy, and
algorithm complexity. The proof shows the quantum SNNs' computational
complexity that is log-polynomial in the data dimension. Furthermore, we
provide a method to improve quantum SNNs' minimum successful probability to
nearly 100%. Finally, we present the good performance of quantum SNNs for
solving pattern recognition from the real-world.",2020-11-10T11:58:05Z,http://arxiv.org/pdf/2011.05062v2,['quant-ph']
1801.05731v1,In-network Neural Networks,"['Giuseppe Siracusano', 'Roberto Bifulco']","We present N2Net, a system that implements binary neural networks using
commodity switching chips deployed in network switches and routers. Our system
shows that these devices can run simple neural network models, whose input is
encoded in the network packets' header, at packet processing speeds (billions
of packets per second). Furthermore, our experience highlights that switching
chips could support even more complex models, provided that some minor and
cheap modifications to the chip's design are applied. We believe N2Net provides
an interesting building block for future end-to-end networked systems.",2018-01-17T16:17:28Z,http://arxiv.org/pdf/1801.05731v1,"['cs.DC', 'cs.AR', 'cs.LG']"
1906.01563v3,Hamiltonian Neural Networks,"['Sam Greydanus', 'Misko Dzamba', 'Jason Yosinski']","Even though neural networks enjoy widespread use, they still struggle to
learn the basic laws of physics. How might we endow them with better inductive
biases? In this paper, we draw inspiration from Hamiltonian mechanics to train
models that learn and respect exact conservation laws in an unsupervised
manner. We evaluate our models on problems where conservation of energy is
important, including the two-body problem and pixel observations of a pendulum.
Our model trains faster and generalizes better than a regular neural network.
An interesting side effect is that our model is perfectly reversible in time.",2019-06-04T16:27:55Z,http://arxiv.org/pdf/1906.01563v3,['cs.NE']
2110.02585v1,Simplicial Convolutional Neural Networks,"['Maosheng Yang', 'Elvin Isufi', 'Geert Leus']","Graphs can model networked data by representing them as nodes and their
pairwise relationships as edges. Recently, signal processing and neural
networks have been extended to process and learn from data on graphs, with
achievements in tasks like graph signal reconstruction, graph or node
classifications, and link prediction. However, these methods are only suitable
for data defined on the nodes of a graph. In this paper, we propose a
simplicial convolutional neural network (SCNN) architecture to learn from data
defined on simplices, e.g., nodes, edges, triangles, etc. We study the SCNN
permutation and orientation equivariance, complexity, and spectral analysis.
Finally, we test the SCNN performance for imputing citations on a coauthorship
complex.",2021-10-06T08:52:55Z,http://arxiv.org/pdf/2110.02585v1,"['cs.LG', 'eess.SP']"
2204.09973v2,Merging of neural networks,"['Martin Pašen', 'Vladimír Boža']","We propose a simple scheme for merging two neural networks trained with
different starting initialization into a single one with the same size as the
original ones. We do this by carefully selecting channels from each input
network. Our procedure might be used as a finalization step after one tries
multiple starting seeds to avoid an unlucky one. We also show that training two
networks and merging them leads to better performance than training a single
network for an extended period of time.
  Availability: https://github.com/fmfi-compbio/neural-network-merging",2022-04-21T08:52:54Z,http://arxiv.org/pdf/2204.09973v2,['cs.LG']
2301.02987v1,Neural network models,['Plamen Dimitrov'],"This work presents the current collection of mathematical models related to
neural networks and proposes a new family of such with extended structure and
dynamics in order to attain a selection of cognitive capabilities. It starts by
providing a basic background to the morphology and physiology of the biological
and the foundations and advances of the artificial neural networks. The first
part then continues with a survey of all current mathematical models and some
of their derived properties. In the second part, a new family of models is
formulated, compared with the rest, and developed analytically and numerically.
Finally, important additional aspects and any limitations to deal with in the
future are discussed.",2023-01-08T05:52:13Z,http://arxiv.org/pdf/2301.02987v1,"['cs.NE', 'math.DS', '37N25 (Primary) 92B20, 68T07 (Secondary)']"
2405.06409v1,Visualizing Neural Network Imagination,"['Nevan Wichers', 'Victor Tao', 'Riccardo Volpato', 'Fazl Barez']","In certain situations, neural networks will represent environment states in
their hidden activations. Our goal is to visualize what environment states the
networks are representing. We experiment with a recurrent neural network (RNN)
architecture with a decoder network at the end. After training, we apply the
decoder to the intermediate representations of the network to visualize what
they represent. We define a quantitative interpretability metric and use it to
demonstrate that hidden states can be highly interpretable on a simple task. We
also develop autoencoder and adversarial techniques and show that benefit
interpretability.",2024-05-10T11:43:35Z,http://arxiv.org/pdf/2405.06409v1,"['cs.LG', 'cs.AI']"
2409.02052v1,Robust Fourier Neural Networks,"['Halyun Jeong', 'Jihun Han']","Fourier embedding has shown great promise in removing spectral bias during
neural network training. However, it can still suffer from high generalization
errors, especially when the labels or measurements are noisy. We demonstrate
that introducing a simple diagonal layer after the Fourier embedding layer
makes the network more robust to measurement noise, effectively prompting it to
learn sparse Fourier features. We provide theoretical justifications for this
Fourier feature learning, leveraging recent developments in diagonal networks
and implicit regularization in neural networks. Under certain conditions, our
proposed approach can also learn functions that are noisy mixtures of nonlinear
functions of Fourier features. Numerical experiments validate the effectiveness
of our proposed architecture, supporting our theory.",2024-09-03T16:56:41Z,http://arxiv.org/pdf/2409.02052v1,"['cs.LG', '65T40, 62J02, 68T07']"
2504.07923v1,Trading Graph Neural Network,['Xian Wu'],"This paper proposes a new algorithm -- Trading Graph Neural Network (TGNN)
that can structurally estimate the impact of asset features, dealer features
and relationship features on asset prices in trading networks. It combines the
strength of the traditional simulated method of moments (SMM) and recent
machine learning techniques -- Graph Neural Network (GNN). It outperforms
existing reduced-form methods with network centrality measures in prediction
accuracy. The method can be used on networks with any structure, allowing for
heterogeneity among both traders and assets.",2025-04-10T17:40:31Z,http://arxiv.org/pdf/2504.07923v1,"['q-fin.TR', 'cs.LG', 'econ.GN', 'q-fin.EC', 'q-fin.PR']"
0005038v1,Quantum Cellular Neural Networks,"['Geza Toth', 'Craig S. Lent', 'P. Douglas Tougaw', 'Yuriy Brazhnik', 'Weiwen Weng', 'Wolfgang Porod', 'Ruey-Wen Liu', 'Yih-Fang Huang']","We have previously proposed a way of using coupled quantum dots to construct
digital computing elements - quantum-dot cellular automata (QCA). Here we
consider a different approach to using coupled quantum-dot cells in an
architecture which, rather that reproducing Boolean logic, uses a physical
near-neighbor connectivity to construct an analog Cellular Neural Network
(CNN).",2000-05-02T05:35:35Z,http://arxiv.org/pdf/cond-mat/0005038v1,"['cond-mat.mes-hall', 'cond-mat.str-el']"
0601129v1,Instantaneously Trained Neural Networks,['Abhilash Ponnath'],"This paper presents a review of instantaneously trained neural networks
(ITNNs). These networks trade learning time for size and, in the basic model, a
new hidden node is created for each training sample. Various versions of the
corner-classification family of ITNNs, which have found applications in
artificial intelligence (AI), are described. Implementation issues are also
considered.",2006-01-30T22:02:47Z,http://arxiv.org/pdf/cs/0601129v1,"['cs.NE', 'cs.AI']"
1602.07776v4,Recurrent Neural Network Grammars,"['Chris Dyer', 'Adhiguna Kuncoro', 'Miguel Ballesteros', 'Noah A. Smith']","We introduce recurrent neural network grammars, probabilistic models of
sentences with explicit phrase structure. We explain efficient inference
procedures that allow application to both parsing and language modeling.
Experiments show that they provide better parsing in English than any single
previously published supervised generative model and better language modeling
than state-of-the-art sequential RNNs in English and Chinese.",2016-02-25T02:42:58Z,http://arxiv.org/pdf/1602.07776v4,"['cs.CL', 'cs.NE']"
1604.05753v1,Sketching and Neural Networks,"['Amit Daniely', 'Nevena Lazic', 'Yoram Singer', 'Kunal Talwar']","High-dimensional sparse data present computational and statistical challenges
for supervised learning. We propose compact linear sketches for reducing the
dimensionality of the input, followed by a single layer neural network. We show
that any sparse polynomial function can be computed, on nearly all sparse
binary vectors, by a single layer neural network that takes a compact sketch of
the vector as input. Consequently, when a set of sparse binary vectors is
approximately separable using a sparse polynomial, there exists a single-layer
neural network that takes a short sketch as input and correctly classifies
nearly all the points. Previous work has proposed using sketches to reduce
dimensionality while preserving the hypothesis class. However, the sketch size
has an exponential dependence on the degree in the case of polynomial
classifiers. In stark contrast, our approach of using improper learning, using
a larger hypothesis class allows the sketch size to have a logarithmic
dependence on the degree. Even in the linear case, our approach allows us to
improve on the pesky $O({1}/{{\gamma}^2})$ dependence of random projections, on
the margin $\gamma$. We empirically show that our approach leads to more
compact neural networks than related methods such as feature hashing at equal
or better performance.",2016-04-19T21:22:29Z,http://arxiv.org/pdf/1604.05753v1,"['cs.LG', 'cs.AI']"
1605.09081v1,Understanding Convolutional Neural Networks,['Jayanth Koushik'],"Convoulutional Neural Networks (CNNs) exhibit extraordinary performance on a
variety of machine learning tasks. However, their mathematical properties and
behavior are quite poorly understood. There is some work, in the form of a
framework, for analyzing the operations that they perform. The goal of this
project is to present key results from this theory, and provide intuition for
why CNNs work.",2016-05-30T00:50:39Z,http://arxiv.org/pdf/1605.09081v1,['stat.OT']
1611.02145v1,Crowdsourcing in Computer Vision,"['Adriana Kovashka', 'Olga Russakovsky', 'Li Fei-Fei', 'Kristen Grauman']","Computer vision systems require large amounts of manually annotated data to
properly learn challenging visual concepts. Crowdsourcing platforms offer an
inexpensive method to capture human knowledge and understanding, for a vast
number of visual perception tasks. In this survey, we describe the types of
annotations computer vision researchers have collected using crowdsourcing, and
how they have ensured that this data is of high quality while annotation effort
is minimized. We begin by discussing data collection on both classic (e.g.,
object recognition) and recent (e.g., visual story-telling) vision tasks. We
then summarize key design decisions for creating effective data collection
interfaces and workflows, and present strategies for intelligently selecting
the most important data instances to annotate. Finally, we conclude with some
thoughts on the future of crowdsourcing in computer vision.",2016-11-07T16:11:19Z,http://arxiv.org/pdf/1611.02145v1,"['cs.CV', 'cs.HC']"
2301.02211v1,Teaching Computer Vision for Ecology,"['Elijah Cole', 'Suzanne Stathatos', 'Björn Lütjens', 'Tarun Sharma', 'Justin Kay', 'Jason Parham', 'Benjamin Kellenberger', 'Sara Beery']","Computer vision can accelerate ecology research by automating the analysis of
raw imagery from sensors like camera traps, drones, and satellites. However,
computer vision is an emerging discipline that is rarely taught to ecologists.
This work discusses our experience teaching a diverse group of ecologists to
prototype and evaluate computer vision systems in the context of an intensive
hands-on summer workshop. We explain the workshop structure, discuss common
challenges, and propose best practices. This document is intended for computer
scientists who teach computer vision across disciplines, but it may also be
useful to ecologists or other domain experts who are learning to use computer
vision themselves.",2023-01-05T18:30:17Z,http://arxiv.org/pdf/2301.02211v1,"['cs.CY', 'cs.CV']"
1707.07210v1,Inspiring Computer Vision System Solutions,"['Julian Zilly', 'Amit Boyarski', 'Micael Carvalho', 'Amir Atapour Abarghouei', 'Konstantinos Amplianitis', 'Aleksandr Krasnov', 'Massimiliano Mancini', 'Hernán Gonzalez', 'Riccardo Spezialetti', 'Carlos Sampedro Pérez', 'Hao Li']","The ""digital Michelangelo project"" was a seminal computer vision project in
the early 2000's that pushed the capabilities of acquisition systems and
involved multiple people from diverse fields, many of whom are now leaders in
industry and academia. Reviewing this project with modern eyes provides us with
the opportunity to reflect on several issues, relevant now as then to the field
of computer vision and research in general, that go beyond the technical
aspects of the work.
  This article was written in the context of a reading group competition at the
week-long International Computer Vision Summer School 2017 (ICVSS) on Sicily,
Italy. To deepen the participants understanding of computer vision and to
foster a sense of community, various reading groups were tasked to highlight
important lessons which may be learned from provided literature, going beyond
the contents of the paper. This report is the winning entry of this guided
discourse (Fig. 1). The authors closely examined the origins, fruits and most
importantly lessons about research in general which may be distilled from the
""digital Michelangelo project"". Discussions leading to this report were held
within the group as well as with Hao Li, the group mentor.",2017-07-22T20:20:57Z,http://arxiv.org/pdf/1707.07210v1,"['cs.CV', 'cs.CY']"
2212.05153v4,Algorithmic progress in computer vision,"['Ege Erdil', 'Tamay Besiroglu']","We investigate algorithmic progress in image classification on ImageNet,
perhaps the most well-known test bed for computer vision. We estimate a model,
informed by work on neural scaling laws, and infer a decomposition of progress
into the scaling of compute, data, and algorithms. Using Shapley values to
attribute performance improvements, we find that algorithmic improvements have
been roughly as important as the scaling of compute for progress computer
vision. Our estimates indicate that algorithmic innovations mostly take the
form of compute-augmenting algorithmic advances (which enable researchers to
get better performance from less compute), not data-augmenting algorithmic
advances. We find that compute-augmenting algorithmic advances are made at a
pace more than twice as fast as the rate usually associated with Moore's law.
In particular, we estimate that compute-augmenting innovations halve compute
requirements every nine months (95\% confidence interval: 4 to 25 months).",2022-12-10T00:18:05Z,http://arxiv.org/pdf/2212.05153v4,"['cs.CV', 'cs.LG']"
1701.06859v1,Sparse models for Computer Vision,['Laurent Perrinet'],"The representation of images in the brain is known to be sparse. That is, as
neural activity is recorded in a visual area ---for instance the primary visual
cortex of primates--- only a few neurons are active at a given time with
respect to the whole population. It is believed that such a property reflects
the efficient match of the representation with the statistics of natural
scenes. Applying such a paradigm to computer vision therefore seems a promising
approach towards more biomimetic algorithms. Herein, we will describe a
biologically-inspired approach to this problem. First, we will describe an
unsupervised learning paradigm which is particularly adapted to the efficient
coding of image patches. Then, we will outline a complete multi-scale framework
---SparseLets--- implementing a biologically inspired sparse representation of
natural images. Finally, we will propose novel methods for integrating prior
information into these algorithms and provide some preliminary experimental
results. We will conclude by giving some perspective on applying such
algorithms to computer vision. More specifically, we will propose that
bio-inspired approaches may be applied to computer vision using predictive
coding schemes, sparse models being one simple and efficient instance of such
schemes.",2017-01-24T13:20:11Z,http://arxiv.org/pdf/1701.06859v1,"['cs.CV', 'q-bio.NC']"
2301.01161v1,Procedural Humans for Computer Vision,"['Charlie Hewitt', 'Tadas Baltrušaitis', 'Erroll Wood', 'Lohit Petikam', 'Louis Florentin', 'Hanz Cuevas Velasquez']","Recent work has shown the benefits of synthetic data for use in computer
vision, with applications ranging from autonomous driving to face landmark
detection and reconstruction. There are a number of benefits of using synthetic
data from privacy preservation and bias elimination to quality and feasibility
of annotation. Generating human-centered synthetic data is a particular
challenge in terms of realism and domain-gap, though recent work has shown that
effective machine learning models can be trained using synthetic face data
alone. We show that this can be extended to include the full body by building
on the pipeline of Wood et al. to generate synthetic images of humans in their
entirety, with ground-truth annotations for computer vision applications.
  In this report we describe how we construct a parametric model of the face
and body, including articulated hands; our rendering pipeline to generate
realistic images of humans based on this body model; an approach for training
DNNs to regress a dense set of landmarks covering the entire body; and a method
for fitting our body model to dense landmarks predicted from multiple views.",2023-01-03T15:44:48Z,http://arxiv.org/pdf/2301.01161v1,"['cs.CV', 'cs.GR']"
1310.0319v3,Second Croatian Computer Vision Workshop (CCVW 2013),"['Sven Lončarić', 'Siniša Šegvić']","Proceedings of the Second Croatian Computer Vision Workshop (CCVW 2013,
http://www.fer.unizg.hr/crv/ccvw2013) held September 19, 2013, in Zagreb,
Croatia. Workshop was organized by the Center of Excellence for Computer Vision
of the University of Zagreb.",2013-10-01T14:26:29Z,http://arxiv.org/pdf/1310.0319v3,['cs.CV']
1701.04674v1,Human perception in computer vision,['Ron Dekel'],"Computer vision has made remarkable progress in recent years. Deep neural
network (DNN) models optimized to identify objects in images exhibit
unprecedented task-trained accuracy and, remarkably, some generalization
ability: new visual problems can now be solved more easily based on previous
learning. Biological vision (learned in life and through evolution) is also
accurate and general-purpose. Is it possible that these different learning
regimes converge to similar problem-dependent optimal computations? We
therefore asked whether the human system-level computation of visual perception
has DNN correlates and considered several anecdotal test cases. We found that
perceptual sensitivity to image changes has DNN mid-computation correlates,
while sensitivity to segmentation, crowding and shape has DNN end-computation
correlates. Our results quantify the applicability of using DNN computation to
estimate perceptual loss, and are consistent with the fascinating theoretical
view that properties of human perception are a consequence of
architecture-independent visual learning.",2017-01-17T14:00:30Z,http://arxiv.org/pdf/1701.04674v1,"['cs.CV', 'q-bio.NC']"
1910.12539v1,Virtual Piano using Computer Vision,"['Seongjae Kang', 'Jaeyoon Kim', 'Sung-eui Yoon']","In this research, Piano performances have been analyzed only based on visual
information. Computer vision algorithms, e.g., Hough transform and binary
thresholding, have been applied to find where the keyboard and specific keys
are located. At the same time, Convolutional Neural Networks(CNNs) has been
also utilized to find whether specific keys are pressed or not, and how much
intensity the keys are pressed only based on visual information. Especially for
detecting intensity, a new method of utilizing spatial, temporal CNNs model is
devised. Early fusion technique is especially applied in temporal CNNs
architecture to analyze hand movement. We also make a new dataset for training
each model. Especially when finding an intensity of a pressed key, both of
video frames and their optical flow images are used to train models to find
effectiveness.",2019-10-28T10:36:30Z,http://arxiv.org/pdf/1910.12539v1,['cs.CV']
2308.13558v1,Federated Learning for Computer Vision,"['Yassine Himeur', 'Iraklis Varlamis', 'Hamza Kheddar', 'Abbes Amira', 'Shadi Atalla', 'Yashbir Singh', 'Faycal Bensaali', 'Wathiq Mansoor']","Computer Vision (CV) is playing a significant role in transforming society by
utilizing machine learning (ML) tools for a wide range of tasks. However, the
need for large-scale datasets to train ML models creates challenges for
centralized ML algorithms. The massive computation loads required for
processing and the potential privacy risks associated with storing and
processing data on central cloud servers put these algorithms under severe
strain. To address these issues, federated learning (FL) has emerged as a
promising solution, allowing privacy preservation by training models locally
and exchanging them to improve overall performance. Additionally, the
computational load is distributed across multiple clients, reducing the burden
on central servers. This paper presents, to the best of the authors' knowledge,
the first review discussing recent advancements of FL in CV applications,
comparing them to conventional centralized training paradigms. It provides an
overview of current FL applications in various CV tasks, emphasizing the
advantages of FL and the challenges of implementing it in CV. To facilitate
this, the paper proposes a taxonomy of FL techniques in CV, outlining their
applications and security threats. It also discusses privacy concerns related
to implementing blockchain in FL schemes for CV tasks and summarizes existing
privacy preservation methods. Moving on, the paper identifies open research
challenges and potential future research directions to further exploit the
potential of FL and blockchain in CV applications.",2023-08-24T16:05:14Z,http://arxiv.org/pdf/2308.13558v1,['cs.CV']
2112.03111v1,Ethics and Creativity in Computer Vision,"['Negar Rostamzadeh', 'Emily Denton', 'Linda Petrini']","This paper offers a retrospective of what we learnt from organizing the
workshop *Ethical Considerations in Creative applications of Computer Vision*
at CVPR 2021 conference and, prior to that, a series of workshops on *Computer
Vision for Fashion, Art and Design* at ECCV 2018, ICCV 2019, and CVPR 2020. We
hope this reflection will bring artists and machine learning researchers into
conversation around the ethical and social dimensions of creative applications
of computer vision.",2021-12-06T15:23:08Z,http://arxiv.org/pdf/2112.03111v1,"['cs.CV', 'cs.CY', 'cs.LG']"
1907.09233v1,Adapting Computer Vision Algorithms for Omnidirectional Video,['Hannes Fassold'],"Omnidirectional (360{\deg}) video has got quite popular because it provides a
highly immersive viewing experience. For computer vision algorithms, it poses
several challenges, like the special (equirectangular) projection commonly
employed and the huge image size. In this work, we give a high-level overview
of these challenges and outline strategies how to adapt computer vision
algorithm for the specifics of omnidirectional video.",2019-07-22T11:12:35Z,http://arxiv.org/pdf/1907.09233v1,['cs.CV']
1910.13796v1,Deep Learning vs. Traditional Computer Vision,"[""Niall O' Mahony"", 'Sean Campbell', 'Anderson Carvalho', 'Suman Harapanahalli', 'Gustavo Velasco-Hernandez', 'Lenka Krpalkova', 'Daniel Riordan', 'Joseph Walsh']","Deep Learning has pushed the limits of what was possible in the domain of
Digital Image Processing. However, that is not to say that the traditional
computer vision techniques which had been undergoing progressive development in
years prior to the rise of DL have become obsolete. This paper will analyse the
benefits and drawbacks of each approach. The aim of this paper is to promote a
discussion on whether knowledge of classical computer vision techniques should
be maintained. The paper will also explore how the two sides of computer vision
can be combined. Several recent hybrid methodologies are reviewed which have
demonstrated the ability to improve computer vision performance and to tackle
problems not suited to Deep Learning. For example, combining traditional
computer vision techniques with Deep Learning has been popular in emerging
domains such as Panoramic Vision and 3D vision for which Deep Learning models
have not yet been fully optimised",2019-10-30T12:25:10Z,http://arxiv.org/pdf/1910.13796v1,"['cs.CV', 'cs.LG']"
2306.05135v1,Does Image Anonymization Impact Computer Vision Training?,"['Håkon Hukkelås', 'Frank Lindseth']","Image anonymization is widely adapted in practice to comply with privacy
regulations in many regions. However, anonymization often degrades the quality
of the data, reducing its utility for computer vision development. In this
paper, we investigate the impact of image anonymization for training computer
vision models on key computer vision tasks (detection, instance segmentation,
and pose estimation). Specifically, we benchmark the recognition drop on common
detection datasets, where we evaluate both traditional and realistic
anonymization for faces and full bodies. Our comprehensive experiments reflect
that traditional image anonymization substantially impacts final model
performance, particularly when anonymizing the full body. Furthermore, we find
that realistic anonymization can mitigate this decrease in performance, where
our experiments reflect a minimal performance drop for face anonymization. Our
study demonstrates that realistic anonymization can enable privacy-preserving
computer vision development with minimal performance degradation across a range
of important computer vision benchmarks.",2023-06-08T12:02:03Z,http://arxiv.org/pdf/2306.05135v1,"['cs.CV', 'cs.AI']"
2302.08242v1,Tuning computer vision models with task rewards,"['André Susano Pinto', 'Alexander Kolesnikov', 'Yuge Shi', 'Lucas Beyer', 'Xiaohua Zhai']","Misalignment between model predictions and intended usage can be detrimental
for the deployment of computer vision models. The issue is exacerbated when the
task involves complex structured outputs, as it becomes harder to design
procedures which address this misalignment. In natural language processing,
this is often addressed using reinforcement learning techniques that align
models with a task reward. We adopt this approach and show its surprising
effectiveness across multiple computer vision tasks, such as object detection,
panoptic segmentation, colorization and image captioning. We believe this
approach has the potential to be widely useful for better aligning models with
a diverse range of computer vision tasks.",2023-02-16T11:49:48Z,http://arxiv.org/pdf/2302.08242v1,['cs.CV']
1705.04402v3,Negative Results in Computer Vision: A Perspective,['Ali Borji'],"A negative result is when the outcome of an experiment or a model is not what
is expected or when a hypothesis does not hold. Despite being often overlooked
in the scientific community, negative results are results and they carry value.
While this topic has been extensively discussed in other fields such as social
sciences and biosciences, less attention has been paid to it in the computer
vision community. The unique characteristics of computer vision, particularly
its experimental aspect, call for a special treatment of this matter. In this
paper, I will address what makes negative results important, how they should be
disseminated and incentivized, and what lessons can be learned from cognitive
vision research in this regard. Further, I will discuss issues such as computer
vision and human vision interaction, experimental design and statistical
hypothesis testing, explanatory versus predictive modeling, performance
evaluation, model comparison, as well as computer vision research culture.",2017-05-11T23:39:18Z,http://arxiv.org/pdf/1705.04402v3,['cs.CV']
1905.12887v2,Does computer vision matter for action?,"['Brady Zhou', 'Philipp Krähenbühl', 'Vladlen Koltun']","Computer vision produces representations of scene content. Much computer
vision research is predicated on the assumption that these intermediate
representations are useful for action. Recent work at the intersection of
machine learning and robotics calls this assumption into question by training
sensorimotor systems directly for the task at hand, from pixels to actions,
with no explicit intermediate representations. Thus the central question of our
work: Does computer vision matter for action? We probe this question and its
offshoots via immersive simulation, which allows us to conduct controlled
reproducible experiments at scale. We instrument immersive three-dimensional
environments to simulate challenges such as urban driving, off-road trail
traversal, and battle. Our main finding is that computer vision does matter.
Models equipped with intermediate representations train faster, achieve higher
task performance, and generalize better to previously unseen environments. A
video that summarizes the work and illustrates the results can be found at
https://youtu.be/4MfWa2yZ0Jc",2019-05-30T07:18:33Z,http://arxiv.org/pdf/1905.12887v2,"['cs.CV', 'cs.AI', 'cs.LG', 'cs.RO']"
2408.11448v1,Lookism: The overlooked bias in computer vision,"['Aditya Gulati', 'Bruno Lepri', 'Nuria Oliver']","In recent years, there have been significant advancements in computer vision
which have led to the widespread deployment of image recognition and generation
systems in socially relevant applications, from hiring to security screening.
However, the prevalence of biases within these systems has raised significant
ethical and social concerns. The most extensively studied biases in this
context are related to gender, race and age. Yet, other biases are equally
pervasive and harmful, such as lookism, i.e., the preferential treatment of
individuals based on their physical appearance. Lookism remains under-explored
in computer vision but can have profound implications not only by perpetuating
harmful societal stereotypes but also by undermining the fairness and
inclusivity of AI technologies. Thus, this paper advocates for the systematic
study of lookism as a critical bias in computer vision models. Through a
comprehensive review of existing literature, we identify three areas of
intersection between lookism and computer vision. We illustrate them by means
of examples and a user study. We call for an interdisciplinary approach to
address lookism, urging researchers, developers, and policymakers to prioritize
the development of equitable computer vision systems that respect and reflect
the diversity of human appearances.",2024-08-21T09:07:20Z,http://arxiv.org/pdf/2408.11448v1,"['cs.CV', 'cs.AI', 'cs.CY', 'I.2.0; I.4.0; K.4.2']"
2506.11140v3,Autonomous Computer Vision Development with Agentic AI,"['Jin Kim', 'Muhammad Wahi-Anwa', 'Sangyun Park', 'Shawn Shin', 'John M. Hoffman', 'Matthew S. Brown']","Agentic Artificial Intelligence (AI) systems leveraging Large Language Models
(LLMs) exhibit significant potential for complex reasoning, planning, and tool
utilization. We demonstrate that a specialized computer vision system can be
built autonomously from a natural language prompt using Agentic AI methods.
This involved extending SimpleMind (SM), an open-source Cognitive AI
environment with configurable tools for medical image analysis, with an
LLM-based agent, implemented using OpenManus, to automate the planning (tool
configuration) for a particular computer vision task. We provide a
proof-of-concept demonstration that an agentic system can interpret a computer
vision task prompt, plan a corresponding SimpleMind workflow by decomposing the
task and configuring appropriate tools. From the user input prompt, ""provide sm
(SimpleMind) config for lungs, heart, and ribs segmentation for cxr (chest
x-ray)""), the agent LLM was able to generate the plan (tool configuration file
in YAML format), and execute SM-Learn (training) and SM-Think (inference)
scripts autonomously. The computer vision agent automatically configured,
trained, and tested itself on 50 chest x-ray images, achieving mean dice scores
of 0.96, 0.82, 0.83, for lungs, heart, and ribs, respectively. This work shows
the potential for autonomous planning and tool configuration that has
traditionally been performed by a data scientist in the development of computer
vision applications.",2025-06-11T02:21:19Z,http://arxiv.org/pdf/2506.11140v3,"['cs.CV', 'cs.AI', 'cs.MA']"
1904.07714v1,"Low-Power Computer Vision: Status, Challenges, Opportunities","['Sergei Alyamkin', 'Matthew Ardi', 'Alexander C. Berg', 'Achille Brighton', 'Bo Chen', 'Yiran Chen', 'Hsin-Pai Cheng', 'Zichen Fan', 'Chen Feng', 'Bo Fu', 'Kent Gauen', 'Abhinav Goel', 'Alexander Goncharenko', 'Xuyang Guo', 'Soonhoi Ha', 'Andrew Howard', 'Xiao Hu', 'Yuanjun Huang', 'Donghyun Kang', 'Jaeyoun Kim', 'Jong Gook Ko', 'Alexander Kondratyev', 'Junhyeok Lee', 'Seungjae Lee', 'Suwoong Lee', 'Zichao Li', 'Zhiyu Liang', 'Juzheng Liu', 'Xin Liu', 'Yang Lu', 'Yung-Hsiang Lu', 'Deeptanshu Malik', 'Hong Hanh Nguyen', 'Eunbyung Park', 'Denis Repin', 'Liang Shen', 'Tao Sheng', 'Fei Sun', 'David Svitov', 'George K. Thiruvathukal', 'Baiwu Zhang', 'Jingchi Zhang', 'Xiaopeng Zhang', 'Shaojie Zhuo']","Computer vision has achieved impressive progress in recent years. Meanwhile,
mobile phones have become the primary computing platforms for millions of
people. In addition to mobile phones, many autonomous systems rely on visual
data for making decisions and some of these systems have limited energy (such
as unmanned aerial vehicles also called drones and mobile robots). These
systems rely on batteries and energy efficiency is critical. This article
serves two main purposes: (1) Examine the state-of-the-art for low-power
solutions to detect objects in images. Since 2015, the IEEE Annual
International Low-Power Image Recognition Challenge (LPIRC) has been held to
identify the most energy-efficient computer vision solutions. This article
summarizes 2018 winners' solutions. (2) Suggest directions for research as well
as opportunities for low-power computer vision.",2019-04-15T17:48:48Z,http://arxiv.org/pdf/1904.07714v1,"['cs.CV', 'cs.AI', 'cs.PF']"
2204.03643v1,Total Variation Optimization Layers for Computer Vision,"['Raymond A. Yeh', 'Yuan-Ting Hu', 'Zhongzheng Ren', 'Alexander G. Schwing']","Optimization within a layer of a deep-net has emerged as a new direction for
deep-net layer design. However, there are two main challenges when applying
these layers to computer vision tasks: (a) which optimization problem within a
layer is useful?; (b) how to ensure that computation within a layer remains
efficient? To study question (a), in this work, we propose total variation (TV)
minimization as a layer for computer vision. Motivated by the success of total
variation in image processing, we hypothesize that TV as a layer provides
useful inductive bias for deep-nets too. We study this hypothesis on five
computer vision tasks: image classification, weakly supervised object
localization, edge-preserving smoothing, edge detection, and image denoising,
improving over existing baselines. To achieve these results we had to address
question (b): we developed a GPU-based projected-Newton method which is
$37\times$ faster than existing solutions.",2022-04-07T17:59:27Z,http://arxiv.org/pdf/2204.03643v1,['cs.CV']
2302.08054v1,Spectral 3D Computer Vision -- A Review,"['Yajie Sun', 'Ali Zia', 'Vivien Rolland', 'Charissa Yu', 'Jun Zhou']","Spectral 3D computer vision examines both the geometric and spectral
properties of objects. It provides a deeper understanding of an object's
physical properties by providing information from narrow bands in various
regions of the electromagnetic spectrum. Mapping the spectral information onto
the 3D model reveals changes in the spectra-structure space or enhances 3D
representations with properties such as reflectance, chromatic aberration, and
varying defocus blur. This emerging paradigm advances traditional computer
vision and opens new avenues of research in 3D structure, depth estimation,
motion analysis, and more. It has found applications in areas such as smart
agriculture, environment monitoring, building inspection, geological
exploration, and digital cultural heritage records. This survey offers a
comprehensive overview of spectral 3D computer vision, including a unified
taxonomy of methods, key application areas, and future challenges and
prospects.",2023-02-16T03:29:40Z,http://arxiv.org/pdf/2302.08054v1,"['cs.CV', 'cs.AI']"
2507.18660v1,Fuzzy Theory in Computer Vision: A Review,"['Adilet Yerkin', 'Ayan Igali', 'Elnara Kadyrgali', 'Maksat Shagyrov', 'Malika Ziyada', 'Muragul Muratbekova', 'Pakizar Shamoi']","Computer vision applications are omnipresent nowadays. The current paper
explores the use of fuzzy logic in computer vision, stressing its role in
handling uncertainty, noise, and imprecision in image data. Fuzzy logic is able
to model gradual transitions and human-like reasoning and provides a promising
approach to computer vision. Fuzzy approaches offer a way to improve object
recognition, image segmentation, and feature extraction by providing more
adaptable and interpretable solutions compared to traditional methods. We
discuss key fuzzy techniques, including fuzzy clustering, fuzzy inference
systems, type-2 fuzzy sets, and fuzzy rule-based decision-making. The paper
also discusses various applications, including medical imaging, autonomous
systems, and industrial inspection. Additionally, we explore the integration of
fuzzy logic with deep learning models such as convolutional neural networks
(CNNs) to enhance performance in complex vision tasks. Finally, we examine
emerging trends such as hybrid fuzzy-deep learning models and explainable AI.",2025-07-23T15:23:09Z,http://arxiv.org/pdf/2507.18660v1,['cs.CV']
2406.00447v1,DroneVis: Versatile Computer Vision Library for Drones,"['Ahmed Heakl', 'Fatma Youssef', 'Victor Parque', 'Walid Gomaa']","This paper introduces DroneVis, a novel library designed to automate computer
vision algorithms on Parrot drones. DroneVis offers a versatile set of features
and provides a diverse range of computer vision tasks along with a variety of
models to choose from. Implemented in Python, the library adheres to
high-quality code standards, facilitating effortless customization and feature
expansion according to user requirements. In addition, comprehensive
documentation is provided, encompassing usage guidelines and illustrative use
cases. Our documentation, code, and examples are available in
https://github.com/ahmedheakl/drone-vis.",2024-06-01T14:06:46Z,http://arxiv.org/pdf/2406.00447v1,"['cs.CV', 'cs.AI', 'cs.CY', 'cs.LG', 'cs.RO']"
1705.04352v3,Reconfiguring the Imaging Pipeline for Computer Vision,"['Mark Buckler', 'Suren Jayasuriya', 'Adrian Sampson']","Advancements in deep learning have ignited an explosion of research on
efficient hardware for embedded computer vision. Hardware vision acceleration,
however, does not address the cost of capturing and processing the image data
that feeds these algorithms. We examine the role of the image signal processing
(ISP) pipeline in computer vision to identify opportunities to reduce
computation and save energy. The key insight is that imaging pipelines should
be designed to be configurable: to switch between a traditional photography
mode and a low-power vision mode that produces lower-quality image data
suitable only for computer vision. We use eight computer vision algorithms and
a reversible pipeline simulation tool to study the imaging system's impact on
vision performance. For both CNN-based and classical vision algorithms, we
observe that only two ISP stages, demosaicing and gamma compression, are
critical for task performance. We propose a new image sensor design that can
compensate for skipping these stages. The sensor design features an adjustable
resolution and tunable analog-to-digital converters (ADCs). Our proposed
imaging system's vision mode disables the ISP entirely and configures the
sensor to produce subsampled, lower-precision image data. This vision mode can
save ~75% of the average energy of a baseline photography mode while having
only a small impact on vision task accuracy.",2017-05-11T18:57:01Z,http://arxiv.org/pdf/1705.04352v3,['cs.CV']
2010.01177v4,Global Adaptive Filtering Layer for Computer Vision,"['Viktor Shipitsin', 'Iaroslav Bespalov', 'Dmitry V. Dylov']","We devise a universal adaptive neural layer to ""learn"" optimal frequency
filter for each image together with the weights of the base neural network that
performs some computer vision task. The proposed approach takes the source
image in the spatial domain, automatically selects the best frequencies from
the frequency domain, and transmits the inverse-transform image to the main
neural network. Remarkably, such a simple add-on layer dramatically improves
the performance of the main network regardless of its design. We observe that
the light networks gain a noticeable boost in the performance metrics; whereas,
the training of the heavy ones converges faster when our adaptive layer is
allowed to ""learn"" alongside the main architecture. We validate the idea in
four classical computer vision tasks: classification, segmentation, denoising,
and erasing, considering popular natural and medical data benchmarks.",2020-10-02T19:43:49Z,http://arxiv.org/pdf/2010.01177v4,"['eess.IV', 'cs.CV']"
1906.02337v1,MNIST-C: A Robustness Benchmark for Computer Vision,"['Norman Mu', 'Justin Gilmer']","We introduce the MNIST-C dataset, a comprehensive suite of 15 corruptions
applied to the MNIST test set, for benchmarking out-of-distribution robustness
in computer vision. Through several experiments and visualizations we
demonstrate that our corruptions significantly degrade performance of
state-of-the-art computer vision models while preserving the semantic content
of the test images. In contrast to the popular notion of adversarial
robustness, our model-agnostic corruptions do not seek worst-case performance
but are instead designed to be broad and diverse, capturing multiple failure
modes of modern models. In fact, we find that several previously published
adversarial defenses significantly degrade robustness as measured by MNIST-C.
We hope that our benchmark serves as a useful tool for future work in designing
systems that are able to learn robust feature representations that capture the
underlying semantics of the input.",2019-06-05T22:23:43Z,http://arxiv.org/pdf/1906.02337v1,"['cs.CV', 'cs.LG']"
2111.07624v1,Attention Mechanisms in Computer Vision: A Survey,"['Meng-Hao Guo', 'Tian-Xing Xu', 'Jiang-Jiang Liu', 'Zheng-Ning Liu', 'Peng-Tao Jiang', 'Tai-Jiang Mu', 'Song-Hai Zhang', 'Ralph R. Martin', 'Ming-Ming Cheng', 'Shi-Min Hu']","Humans can naturally and effectively find salient regions in complex scenes.
Motivated by this observation, attention mechanisms were introduced into
computer vision with the aim of imitating this aspect of the human visual
system. Such an attention mechanism can be regarded as a dynamic weight
adjustment process based on features of the input image. Attention mechanisms
have achieved great success in many visual tasks, including image
classification, object detection, semantic segmentation, video understanding,
image generation, 3D vision, multi-modal tasks and self-supervised learning. In
this survey, we provide a comprehensive review of various attention mechanisms
in computer vision and categorize them according to approach, such as channel
attention, spatial attention, temporal attention and branch attention; a
related repository https://github.com/MenghaoGuo/Awesome-Vision-Attentions is
dedicated to collecting related work. We also suggest future directions for
attention mechanism research.",2021-11-15T09:18:40Z,http://arxiv.org/pdf/2111.07624v1,['cs.CV']
1107.2875v1,A Hilbert Scheme in Computer Vision,"['Chris Aholt', 'Bernd Sturmfels', 'Rekha Thomas']","Multiview geometry is the study of two-dimensional images of
three-dimensional scenes, a foundational subject in computer vision. We
determine a universal Groebner basis for the multiview ideal of n generic
cameras. As the cameras move, the multiview varieties vary in a family of
dimension 11n-15. This family is the distinguished component of a multigraded
Hilbert scheme with a unique Borel-fixed point. We present a combinatorial
study of ideals lying on that Hilbert scheme.",2011-07-14T17:36:59Z,http://arxiv.org/pdf/1107.2875v1,"['math.AG', 'cs.CV', '14N, 14Q, 68']"
1707.09332v6,Two Hilbert schemes in computer vision,"['Max Lieblich', 'Lucas Van Meter']","We study multiview moduli problems that arise in computer vision. We show
that these moduli spaces are always smooth and irreducible, in both the
calibrated and uncalibrated cases, for any number of views. We also show that
these moduli spaces always admit open immersions into Hilbert schemes for more
than two views, extending and refining work of Aholt-Sturmfels-Thomas. We use
these moduli spaces to study and extend the classical twisted pair covering of
the essential variety.",2017-07-28T17:13:22Z,http://arxiv.org/pdf/1707.09332v6,"['math.AG', 'cs.CV']"
2008.00813v1,Kinematics of motion tracking using computer vision,['José L. Escalona'],"This paper describes the kinematics of the motion tracking of a rigid body
using video recording. The novelty of the paper is on the adaptation of the
methods and nomenclature used in Computer Vision to those used in Multibody
System Dynamics. That way, the equations presented here can be used, for
example, for inverse-dynamics multibody simulations driven by the motion
tracking of selected bodies. This paper also adapts the well-known Zhang
calibration method to the presented nomenclature.",2020-07-19T18:02:13Z,http://arxiv.org/pdf/2008.00813v1,"['cs.CV', 'eess.IV']"
2406.13008v1,ClaudesLens: Uncertainty Quantification in Computer Vision Models,"['Mohamad Al Shaar', 'Nils Ekström', 'Gustav Gille', 'Reza Rezvan', 'Ivan Wely']","In a world where more decisions are made using artificial intelligence, it is
of utmost importance to ensure these decisions are well-grounded. Neural
networks are the modern building blocks for artificial intelligence. Modern
neural network-based computer vision models are often used for object
classification tasks. Correctly classifying objects with \textit{certainty} has
become of great importance in recent times. However, quantifying the inherent
\textit{uncertainty} of the output from neural networks is a challenging task.
Here we show a possible method to quantify and evaluate the uncertainty of the
output of different computer vision models based on Shannon entropy. By adding
perturbation of different levels, on different parts, ranging from the input to
the parameters of the network, one introduces entropy to the system. By
quantifying and evaluating the perturbed models on the proposed PI and PSI
metrics, we can conclude that our theoretical framework can grant insight into
the uncertainty of predictions of computer vision models. We believe that this
theoretical framework can be applied to different applications for neural
networks. We believe that Shannon entropy may eventually have a bigger role in
the SOTA (State-of-the-art) methods to quantify uncertainty in artificial
intelligence. One day we might be able to apply Shannon entropy to our neural
systems.",2024-06-18T18:58:54Z,http://arxiv.org/pdf/2406.13008v1,"['cs.CV', 'cs.AI']"
2411.18224v2,KANs for Computer Vision: An Experimental Study,"['Karthik Mohan', 'Hanxiao Wang', 'Xiatian Zhu']","This paper presents an experimental study of Kolmogorov-Arnold Networks
(KANs) applied to computer vision tasks, particularly image classification.
KANs introduce learnable activation functions on edges, offering flexible
non-linear transformations compared to traditional pre-fixed activation
functions with specific neural work like Multi-Layer Perceptrons (MLPs) and
Convolutional Neural Networks (CNNs). While KANs have shown promise mostly in
simplified or small-scale datasets, their effectiveness for more complex
real-world tasks such as computer vision tasks remains less explored. To fill
this gap, this experimental study aims to provide extended observations and
insights into the strengths and limitations of KANs. We reveal that although
KANs can perform well in specific vision tasks, they face significant
challenges, including increased hyperparameter sensitivity and higher
computational costs. These limitations suggest that KANs require architectural
adaptations, such as integration with other architectures, to be practical for
large-scale vision problems. This study focuses on empirical findings rather
than proposing new methods, aiming to inform future research on optimizing
KANs, in particular computer vision applications or alike.",2024-11-27T10:59:28Z,http://arxiv.org/pdf/2411.18224v2,['cs.CV']
1709.00069v1,Learning Inference Models for Computer Vision,['Varun Jampani'],"Computer vision can be understood as the ability to perform inference on
image data. Breakthroughs in computer vision technology are often marked by
advances in inference techniques. This thesis proposes novel inference schemes
and demonstrates applications in computer vision. We propose inference
techniques for both generative and discriminative vision models. The use of
generative models in vision is often hampered by the difficulty of posterior
inference. We propose techniques for improving inference in MCMC sampling and
message-passing inference. Our inference strategy is to learn separate
discriminative models that assist Bayesian inference in a generative model.
Experiments on a range of generative models show that the proposed techniques
accelerate the inference process and/or converge to better solutions. A main
complication in the design of discriminative models is the inclusion of prior
knowledge. We concentrate on CNN models and propose a generalization of
standard spatial convolutions to bilateral convolutions. We generalize the
existing use of bilateral filters and then propose new neural network
architectures with learnable bilateral filters, which we call `Bilateral Neural
Networks'. Experiments demonstrate the use of the bilateral networks on a wide
range of image and video tasks and datasets. In summary, we propose techniques
for better inference in several vision models ranging from inverse graphics to
freely parameterized neural networks. In generative models, our inference
techniques alleviate some of the crucial hurdles in Bayesian posterior
inference, paving new ways for the use of model based machine learning in
vision. In discriminative CNN models, the proposed filter generalizations aid
in the design of new neural network architectures that can handle sparse
high-dimensional data as well as provide a way to incorporate prior knowledge
into CNNs.",2017-08-31T20:33:06Z,http://arxiv.org/pdf/1709.00069v1,['cs.CV']
2309.00035v1,FACET: Fairness in Computer Vision Evaluation Benchmark,"['Laura Gustafson', 'Chloe Rolland', 'Nikhila Ravi', 'Quentin Duval', 'Aaron Adcock', 'Cheng-Yang Fu', 'Melissa Hall', 'Candace Ross']","Computer vision models have known performance disparities across attributes
such as gender and skin tone. This means during tasks such as classification
and detection, model performance differs for certain classes based on the
demographics of the people in the image. These disparities have been shown to
exist, but until now there has not been a unified approach to measure these
differences for common use-cases of computer vision models. We present a new
benchmark named FACET (FAirness in Computer Vision EvaluaTion), a large,
publicly available evaluation set of 32k images for some of the most common
vision tasks - image classification, object detection and segmentation. For
every image in FACET, we hired expert reviewers to manually annotate
person-related attributes such as perceived skin tone and hair type, manually
draw bounding boxes and label fine-grained person-related classes such as disk
jockey or guitarist. In addition, we use FACET to benchmark state-of-the-art
vision models and present a deeper understanding of potential performance
disparities and challenges across sensitive demographic attributes. With the
exhaustive annotations collected, we probe models using single demographics
attributes as well as multiple attributes using an intersectional approach
(e.g. hair color and perceived skin tone). Our results show that
classification, detection, segmentation, and visual grounding models exhibit
performance disparities across demographic attributes and intersections of
attributes. These harms suggest that not all people represented in datasets
receive fair and equitable treatment in these vision tasks. We hope current and
future results using our benchmark will contribute to fairer, more robust
vision models. FACET is available publicly at https://facet.metademolab.com/",2023-08-31T17:59:48Z,http://arxiv.org/pdf/2309.00035v1,"['cs.CV', 'cs.AI']"
1708.00069v1,Learning Robust Representations for Computer Vision,"['Peng Zheng', 'Aleksandr Y. Aravkin', 'Karthikeyan Natesan Ramamurthy', 'Jayaraman Jayaraman Thiagarajan']","Unsupervised learning techniques in computer vision often require learning
latent representations, such as low-dimensional linear and non-linear
subspaces. Noise and outliers in the data can frustrate these approaches by
obscuring the latent spaces.
  Our main goal is deeper understanding and new development of robust
approaches for representation learning. We provide a new interpretation for
existing robust approaches and present two specific contributions: a new robust
PCA approach, which can separate foreground features from dynamic background,
and a novel robust spectral clustering method, that can cluster facial images
with high accuracy. Both contributions show superior performance to standard
methods on real-world test sets.",2017-07-31T20:50:01Z,http://arxiv.org/pdf/1708.00069v1,"['stat.ML', 'cs.CV', 'cs.LG']"
1811.02234v1,Semantic bottleneck for computer vision tasks,"['Maxime Bucher', 'Stéphane Herbin', 'Frédéric Jurie']","This paper introduces a novel method for the representation of images that is
semantic by nature, addressing the question of computation intelligibility in
computer vision tasks. More specifically, our proposition is to introduce what
we call a semantic bottleneck in the processing pipeline, which is a crossing
point in which the representation of the image is entirely expressed with
natural language , while retaining the efficiency of numerical representations.
We show that our approach is able to generate semantic representations that
give state-of-the-art results on semantic content-based image retrieval and
also perform very well on image classification tasks. Intelligibility is
evaluated through user centered experiments for failure detection.",2018-11-06T09:01:02Z,http://arxiv.org/pdf/1811.02234v1,"['cs.CV', 'cs.AI', 'cs.LG', 'cs.NE']"
2004.03120v2,Ranking Computer Vision Service Issues using Emotion,"['Maheswaree K Curumsing', 'Alex Cummaudo', 'Ulrike Maria Graetsch', 'Scott Barnett', 'Rajesh Vasa']","Software developers are increasingly using machine learning APIs to implement
'intelligent' features. Studies show that incorporating machine learning into
an application increases technical debt, creates data dependencies, and
introduces uncertainty due to non-deterministic behaviour. However, we know
very little about the emotional state of software developers who deal with such
issues. In this paper, we do a landscape analysis of emotion found in 1,245
Stack Overflow posts about computer vision APIs. We investigate the application
of an existing emotion classifier EmoTxt and manually verify our results. We
found that the emotion profile varies for different question categories.",2020-04-07T04:27:17Z,http://arxiv.org/pdf/2004.03120v2,['cs.SE']
2004.08708v1,Adaptive Attention Span in Computer Vision,"['Jerrod Parker', 'Shakti Kumar', 'Joe Roussy']","Recent developments in Transformers for language modeling have opened new
areas of research in computer vision. Results from late 2019 showed vast
performance increases in both object detection and recognition when
convolutions are replaced by local self-attention kernels. Models using local
self-attention kernels were also shown to have less parameters and FLOPS
compared to equivalent architectures that only use convolutions. In this work
we propose a novel method for learning the local self-attention kernel size. We
then compare its performance to fixed-size local attention and convolution
kernels. The code for all our experiments and models is available at
https://github.com/JoeRoussy/adaptive-attention-in-cv",2020-04-18T21:32:47Z,http://arxiv.org/pdf/2004.08708v1,"['cs.CV', 'cs.LG']"
1211.4860v1,Domain Adaptations for Computer Vision Applications,['Oscar Beijbom'],"A basic assumption of statistical learning theory is that train and test data
are drawn from the same underlying distribution. Unfortunately, this assumption
doesn't hold in many applications. Instead, ample labeled data might exist in a
particular `source' domain while inference is needed in another, `target'
domain. Domain adaptation methods leverage labeled data from both domains to
improve classification on unseen data in the target domain. In this work we
survey domain transfer learning methods for various application domains with
focus on recent work in Computer Vision.",2012-11-20T20:54:30Z,http://arxiv.org/pdf/1211.4860v1,"['cs.CV', 'cs.LG', 'stat.ML']"
2305.08075v1,Analyzing Compression Techniques for Computer Vision,"['Maniratnam Mandal', 'Imran Khan']","Compressing deep networks is highly desirable for practical use-cases in
computer vision applications. Several techniques have been explored in the
literature, and research has been done in finding efficient strategies for
combining them. For this project, we aimed to explore three different basic
compression techniques - knowledge distillation, pruning, and quantization for
small-scale recognition tasks. Along with the basic methods, we also test the
efficacy of combining them in a sequential manner. We analyze them using MNIST
and CIFAR-10 datasets and present the results along with few observations
inferred from them.",2023-05-14T05:17:32Z,http://arxiv.org/pdf/2305.08075v1,['cs.CV']
2211.14743v1,Searching for Uncollected Litter with Computer Vision,"['Julian Hernandez', 'Clark Fitzgerald']","This study combines photo metadata and computer vision to quantify where
uncollected litter is present. Images from the Trash Annotations in Context
(TACO) dataset were used to teach an algorithm to detect 10 categories of
garbage. Although it worked well with smartphone photos, it struggled when
trying to process images from vehicle mounted cameras. However, increasing the
variety of perspectives and backgrounds in the dataset will help it improve in
unfamiliar situations. These data are plotted onto a map which, as accuracy
improves, could be used for measuring waste management strategies and
quantifying trends.",2022-11-27T06:30:03Z,http://arxiv.org/pdf/2211.14743v1,['cs.CV']
2412.00076v1,"Flaws of ImageNet, Computer Vision's Favourite Dataset","['Nikita Kisel', 'Illia Volkov', 'Katerina Hanzelkova', 'Klara Janouskova', 'Jiri Matas']","Since its release, ImageNet-1k dataset has become a gold standard for
evaluating model performance. It has served as the foundation for numerous
other datasets and training tasks in computer vision. As models have improved
in accuracy, issues related to label correctness have become increasingly
apparent. In this blog post, we analyze the issues in the ImageNet-1k dataset,
including incorrect labels, overlapping or ambiguous class definitions,
training-evaluation domain shifts, and image duplicates. The solutions for some
problems are straightforward. For others, we hope to start a broader
conversation about refining this influential dataset to better serve future
research.",2024-11-26T16:47:59Z,http://arxiv.org/pdf/2412.00076v1,['cs.CV']
1412.2672v1,When Computer Vision Gazes at Cognition,"['Tao Gao', 'Daniel Harari', 'Joshua Tenenbaum', 'Shimon Ullman']","Joint attention is a core, early-developing form of social interaction. It is
based on our ability to discriminate the third party objects that other people
are looking at. While it has been shown that people can accurately determine
whether another person is looking directly at them versus away, little is known
about human ability to discriminate a third person gaze directed towards
objects that are further away, especially in unconstraint cases where the
looker can move her head and eyes freely. In this paper we address this
question by jointly exploring human psychophysics and a cognitively motivated
computer vision model, which can detect the 3D direction of gaze from 2D face
images. The synthesis of behavioral study and computer vision yields several
interesting discoveries. (1) Human accuracy of discriminating targets
8{\deg}-10{\deg} of visual angle apart is around 40% in a free looking gaze
task; (2) The ability to interpret gaze of different lookers vary dramatically;
(3) This variance can be captured by the computational model; (4) Human
outperforms the current model significantly. These results collectively show
that the acuity of human joint attention is indeed highly impressive, given the
computational challenge of the natural looking task. Moreover, the gap between
human and model performance, as well as the variability of gaze interpretation
across different lookers, require further understanding of the underlying
mechanisms utilized by humans for this challenging task.",2014-12-08T17:25:57Z,http://arxiv.org/pdf/1412.2672v1,"['cs.AI', 'cs.CV']"
2111.08772v1,Computer Vision for Supporting Image Search,['Alan F. Smeaton'],"Computer vision and multimedia information processing have made extreme
progress within the last decade and many tasks can be done with a level of
accuracy as if done by humans, or better. This is because we leverage the
benefits of huge amounts of data available for training, we have enormous
computer processing available and we have seen the evolution of machine
learning as a suite of techniques to process data and deliver accurate
vision-based systems. What kind of applications do we use this processing for ?
We use this in autonomous vehicle navigation or in security applications,
searching CCTV for example, and in medical image analysis for healthcare
diagnostics. One application which is not widespread is image or video search
directly by users. In this paper we present the need for such image finding or
re-finding by examining human memory and when it fails, thus motivating the
need for a different approach to image search which is outlined, along with the
requirements of computer vision to support it.",2021-11-16T20:50:32Z,http://arxiv.org/pdf/2111.08772v1,"['cs.CV', 'cs.IR']"
2302.05011v1,Context Understanding in Computer Vision: A Survey,"['Xuan Wang', 'Zhigang Zhu']","Contextual information plays an important role in many computer vision tasks,
such as object detection, video action detection, image classification, etc.
Recognizing a single object or action out of context could be sometimes very
challenging, and context information may help improve the understanding of a
scene or an event greatly. Appearance context information, e.g., colors or
shapes of the background of an object can improve the recognition accuracy of
the object in the scene. Semantic context (e.g. a keyboard on an empty desk vs.
a keyboard next to a desktop computer ) will improve accuracy and exclude
unrelated events. Context information that are not in the image itself, such as
the time or location of an images captured, can also help to decide whether
certain event or action should occur. Other types of context (e.g. 3D structure
of a building) will also provide additional information to improve the
accuracy. In this survey, different context information that has been used in
computer vision tasks is reviewed. We categorize context into different types
and different levels. We also review available machine learning models and
image/video datasets that can employ context information. Furthermore, we
compare context based integration and context-free integration in mainly two
classes of tasks: image-based and video-based. Finally, this survey is
concluded by a set of promising future directions in context learning and
utilization.",2023-02-10T02:01:21Z,http://arxiv.org/pdf/2302.05011v1,['cs.CV']
2312.12848v1,Quantum Annealing for Computer Vision Minimization Problems,"['Shahrokh Heidari', 'Michael J. Dinneen', 'Patrice Delmas']","Computer Vision (CV) labelling algorithms play a pivotal role in the domain
of low-level vision. For decades, it has been known that these problems can be
elegantly formulated as discrete energy minimization problems derived from
probabilistic graphical models (such as Markov Random Fields). Despite recent
advances in inference algorithms (such as graph-cut and message-passing
algorithms), the resulting energy minimization problems are generally viewed as
intractable. The emergence of quantum computations, which offer the potential
for faster solutions to certain problems than classical methods, has led to an
increased interest in utilizing quantum properties to overcome intractable
problems. Recently, there has also been a growing interest in Quantum Computer
Vision (QCV), with the hope of providing a credible alternative or assistant to
deep learning solutions in the field. This study investigates a new Quantum
Annealing based inference algorithm for CV discrete energy minimization
problems. Our contribution is focused on Stereo Matching as a significant CV
labeling problem. As a proof of concept, we also use a hybrid quantum-classical
solver provided by D-Wave System to compare our results with the best classical
inference algorithms in the literature.",2023-12-20T08:56:35Z,http://arxiv.org/pdf/2312.12848v1,"['quant-ph', 'cs.CV']"
2408.14281v1,Uncertainties of Latent Representations in Computer Vision,['Michael Kirchhof'],"Uncertainty quantification is a key pillar of trustworthy machine learning.
It enables safe reactions under unsafe inputs, like predicting only when the
machine learning model detects sufficient evidence, discarding anomalous data,
or emitting warnings when an error is likely to be inbound. This is
particularly crucial in safety-critical areas like medical image classification
or self-driving cars. Despite the plethora of proposed uncertainty
quantification methods achieving increasingly higher scores on performance
benchmarks, uncertainty estimates are often shied away from in practice. Many
machine learning projects start from pretrained latent representations that
come without uncertainty estimates. Uncertainties would need to be trained by
practitioners on their own, which is notoriously difficult and
resource-intense.
  This thesis makes uncertainty estimates easily accessible by adding them to
the latent representation vectors of pretrained computer vision models. Besides
proposing approaches rooted in probability and decision theory, such as
Monte-Carlo InfoNCE (MCInfoNCE) and loss prediction, we delve into both
theoretical and empirical questions. We show that these unobservable
uncertainties about unobservable latent representations are indeed provably
correct. We also provide an uncertainty-aware representation learning (URL)
benchmark to compare these unobservables against observable ground-truths.
Finally, we compile our findings to pretrain lightweight representation
uncertainties on large-scale computer vision models that transfer to unseen
datasets in a zero-shot manner.
  Our findings do not only advance the current theoretical understanding of
uncertainties over latent variables, but also facilitate the access to
uncertainty quantification for future researchers inside and outside the field,
enabling straightforward but trustworthy machine learning.",2024-08-26T14:02:30Z,http://arxiv.org/pdf/2408.14281v1,"['cs.LG', 'cs.AI', 'cs.CV']"
1809.04659v2,"Are object detection assessment criteria ready for maritime computer
  vision?","['Dilip K. Prasad', 'Huixu Dong', 'Deepu Rajan', 'Chai Quek']","Maritime vessels equipped with visible and infrared cameras can complement
other conventional sensors for object detection. However, application of
computer vision techniques in maritime domain received attention only recently.
The maritime environment offers its own unique requirements and challenges.
Assessment of the quality of detections is a fundamental need in computer
vision. However, the conventional assessment metrics suitable for usual object
detection are deficient in the maritime setting. Thus, a large body of related
work in computer vision appears inapplicable to the maritime setting at the
first sight. We discuss the problem of defining assessment metrics suitable for
maritime computer vision. We consider new bottom edge proximity metrics as
assessment metrics for maritime computer vision. These metrics indicate that
existing computer vision approaches are indeed promising for maritime computer
vision and can play a foundational role in the emerging field of maritime
computer vision.",2018-09-12T20:18:04Z,http://arxiv.org/pdf/1809.04659v2,['cs.CV']
1808.03998v1,Enhancing camera surveillance using computer vision: a research note,"['Haroon Idrees', 'Mubarak Shah', 'Ray Surette']","$\mathbf{Purpose}$ - The growth of police operated surveillance cameras has
out-paced the ability of humans to monitor them effectively. Computer vision is
a possible solution. An ongoing research project on the application of computer
vision within a municipal police department is described. The paper aims to
discuss these issues.
  $\mathbf{Design/methodology/approach}$ - Following the demystification of
computer vision technology, its potential for police agencies is developed
within a focus on computer vision as a solution for two common surveillance
camera tasks (live monitoring of multiple surveillance cameras and summarizing
archived video files). Three unaddressed research questions (can specialized
computer vision applications for law enforcement be developed at this time, how
will computer vision be utilized within existing public safety camera
monitoring rooms, and what are the system-wide impacts of a computer vision
capability on local criminal justice systems) are considered.
  $\mathbf{Findings}$ - Despite computer vision becoming accessible to law
enforcement agencies the impact of computer vision has not been discussed or
adequately researched. There is little knowledge of computer vision or its
potential in the field.
  $\mathbf{Originality/value}$ - This paper introduces and discusses computer
vision from a law enforcement perspective and will be valuable to police
personnel tasked with monitoring large camera networks and considering computer
vision as a system upgrade.",2018-08-12T20:01:37Z,http://arxiv.org/pdf/1808.03998v1,['cs.CY']
2101.11217v1,Automated Crop Field Surveillance using Computer Vision,"['Tejas Atul Khare', 'Anuradha C. Phadke']","Artificial Intelligence is everywhere today. But unfortunately, Agriculture
has not been able to get that much attention from Artificial Intelligence (AI).
A lack of automation persists in the agriculture industry. For over many years,
farmers and crop field owners have been facing a problem of trespassing of wild
animals for which no feasible solution has been provided. Installing a fence or
barrier like structure is neither feasible nor efficient due to the large areas
covered by the fields. Also, if the landowner can afford to build a wall or
barrier, government policies for building walls are often very irksome. The
paper intends to give a simple intelligible solution to the problem with
Automated Crop Field Surveillance using Computer Vision. The solution will
significantly reduce the cost of crops destroyed annually and completely
automate the security of the field.",2021-01-27T05:58:28Z,http://arxiv.org/pdf/2101.11217v1,['cs.CV']
2107.04902v3,Industry and Academic Research in Computer Vision,"['Iuliia Kotseruba', 'Manos Papagelis', 'John K. Tsotsos']","This work aims to study the dynamic between research in the industry and
academia in computer vision. The results are demonstrated on a set of top-5
vision conferences that are representative of the field. Since data for such
analysis was not readily available, significant effort was spent on gathering
and processing meta-data from the original publications. First, this study
quantifies the share of industry-sponsored research. Specifically, it shows
that the proportion of papers published by industry-affiliated researchers is
increasing and that more academics join companies or collaborate with them.
Next, the possible impact of industry presence is further explored, namely in
the distribution of research topics and citation patterns. The results indicate
that the distribution of the research topics is similar in industry and
academic papers. However, there is a strong preference towards citing industry
papers. Finally, possible reasons for citation bias, such as code availability
and influence, are investigated.",2021-07-10T20:09:52Z,http://arxiv.org/pdf/2107.04902v3,['cs.CV']
2104.08702v1,Reconsidering CO2 emissions from Computer Vision,"['Andre Fu', 'Mahdi S. Hosseini', 'Konstantinos N. Plataniotis']","Climate change is a pressing issue that is currently affecting and will
affect every part of our lives. It's becoming incredibly vital we, as a
society, address the climate crisis as a universal effort, including those in
the Computer Vision (CV) community. In this work, we analyze the total cost of
CO2 emissions by breaking it into (1) the architecture creation cost and (2)
the life-time evaluation cost. We show that over time, these costs are
non-negligible and are having a direct impact on our future. Importantly, we
conduct an ethical analysis of how the CV-community is unintentionally
overlooking its own ethical AI principles by emitting this level of CO2. To
address these concerns, we propose adding ""enforcement"" as a pillar of ethical
AI and provide some recommendations for how architecture designers and broader
CV community can curb the climate crisis.",2021-04-18T04:01:40Z,http://arxiv.org/pdf/2104.08702v1,['cs.CV']
1603.09599v1,Total Variation Applications in Computer Vision,"['Vania V. Estrela', 'Hermes Aguiar Magalhaes', 'Osamu Saotome']","The objectives of this chapter are: (i) to introduce a concise overview of
regularization; (ii) to define and to explain the role of a particular type of
regularization called total variation norm (TV-norm) in computer vision tasks;
(iii) to set up a brief discussion on the mathematical background of TV
methods; and (iv) to establish a relationship between models and a few existing
methods to solve problems cast as TV-norm. For the most part, image-processing
algorithms blur the edges of the estimated images, however TV regularization
preserves the edges with no prior information on the observed and the original
images. The regularization scalar parameter {\lambda} controls the amount of
regularization allowed and it is an essential to obtain a high-quality
regularized output. A wide-ranging review of several ways to put into practice
TV regularization as well as its advantages and limitations are discussed.",2016-03-31T14:08:53Z,http://arxiv.org/pdf/1603.09599v1,['cs.CV']
2003.08863v3,Towards a Computer Vision Particle Flow,"['Francesco Armando Di Bello', 'Sanmay Ganguly', 'Eilam Gross', 'Marumi Kado', 'Michael Pitt', 'Lorenzo Santi', 'Jonathan Shlomi']","In High Energy Physics experiments Particle Flow (PFlow) algorithms are
designed to provide an optimal reconstruction of the nature and kinematic
properties of the particles produced within the detector acceptance during
collisions. At the heart of PFlow algorithms is the ability to distinguish the
calorimeter energy deposits of neutral particles from those of charged
particles, using the complementary measurements of charged particle tracking
devices, to provide a superior measurement of the particle content and
kinematics. In this paper, a computer vision approach to this fundamental
aspect of PFlow algorithms, based on calorimeter images, is proposed. A
comparative study of the state of the art deep learning techniques is
performed. A significantly improved reconstruction of the neutral particle
calorimeter energy deposits is obtained in a context of large overlaps with the
deposits from charged particles. Calorimeter images with augmented finer
granularity are also obtained using super-resolution techniques.",2020-03-19T15:26:23Z,http://arxiv.org/pdf/2003.08863v3,"['physics.data-an', 'hep-ex', 'hep-ph', 'physics.ins-det', 'stat.ML']"
2003.13988v2,Fashion Meets Computer Vision: A Survey,"['Wen-Huang Cheng', 'Sijie Song', 'Chieh-Yun Chen', 'Shintami Chusnul Hidayati', 'Jiaying Liu']","Fashion is the way we present ourselves to the world and has become one of
the world's largest industries. Fashion, mainly conveyed by vision, has thus
attracted much attention from computer vision researchers in recent years.
Given the rapid development, this paper provides a comprehensive survey of more
than 200 major fashion-related works covering four main aspects for enabling
intelligent fashion: (1) Fashion detection includes landmark detection, fashion
parsing, and item retrieval, (2) Fashion analysis contains attribute
recognition, style learning, and popularity prediction, (3) Fashion synthesis
involves style transfer, pose transformation, and physical simulation, and (4)
Fashion recommendation comprises fashion compatibility, outfit matching, and
hairstyle suggestion. For each task, the benchmark datasets and the evaluation
protocols are summarized. Furthermore, we highlight promising directions for
future research.",2020-03-31T07:08:23Z,http://arxiv.org/pdf/2003.13988v2,['cs.CV']
2304.10764v1,Hyperbolic Geometry in Computer Vision: A Survey,"['Pengfei Fang', 'Mehrtash Harandi', 'Trung Le', 'Dinh Phung']","Hyperbolic geometry, a Riemannian manifold endowed with constant sectional
negative curvature, has been considered an alternative embedding space in many
learning scenarios, \eg, natural language processing, graph learning, \etc, as
a result of its intriguing property of encoding the data's hierarchical
structure (like irregular graph or tree-likeness data). Recent studies prove
that such data hierarchy also exists in the visual dataset, and investigate the
successful practice of hyperbolic geometry in the computer vision (CV) regime,
ranging from the classical image classification to advanced model adaptation
learning. This paper presents the first and most up-to-date literature review
of hyperbolic spaces for CV applications. To this end, we first introduce the
background of hyperbolic geometry, followed by a comprehensive investigation of
algorithms, with geometric prior of hyperbolic space, in the context of visual
applications. We also conclude this manuscript and identify possible future
directions.",2023-04-21T06:22:16Z,http://arxiv.org/pdf/2304.10764v1,['cs.CV']
2401.03400v1,Entanglement Structure Detection via Computer Vision,"['Rui Li', 'Junling Du', 'Zheng Qin', 'Shikun Zhang', 'Chunxiao Du', 'Yang Zhou', 'Zhisong Xiao']","Quantum entanglement plays a pivotal role in various quantum information
processing tasks. However, there still lacks a universal and effective way to
detecting entanglement structures, especially for high-dimensional and
multipartite quantum systems. Noticing the mathematical similarities between
the common representations of many-body quantum states and the data structures
of images, we are inspired to employ advanced computer vision technologies for
data analysis. In this work, we propose a hybrid CNN-Transformer model for both
the classification of GHZ and W states and the detection of various
entanglement structures. By leveraging the feature extraction capabilities of
CNNs and the powerful modeling abilities of Transformers, we can not only
effectively reduce the time and computational resources required for the
training process but also obtain high detection accuracies. Through numerical
simulation and physical verification, it is confirmed that our hybrid model is
more effective than traditional techniques and thus offers a powerful tool for
independent detection of multipartite entanglement.",2024-01-07T07:11:22Z,http://arxiv.org/pdf/2401.03400v1,['quant-ph']
2403.00689v1,Hydra: Computer Vision for Data Quality Monitoring,"['Thomas Britton', 'Torri Jeske', 'David Lawrence', 'Kishansingh Rajput']","Hydra is a system which utilizes computer vision to perform near real time
data quality management, initially developed for Hall-D in 2019. Since then, it
has been deployed across all experimental halls at Jefferson Lab, with the
CLAS12 collaboration in Hall-B being the first outside of GlueX to fully
utilize Hydra. The system comprises back end processes that manage the models,
their inferences, and the data flow. The front-end components, accessible via
web pages, allow detector experts and shift crews to view and interact with the
system. This talk will give an overview of the Hydra system as well as
highlight significant developments in Hydra's feature set, acute challenges
with operating Hydra in all halls, and lessons learned along the way.",2024-03-01T17:20:58Z,http://arxiv.org/pdf/2403.00689v1,"['cs.CV', 'nucl-ex', 'physics.ins-det']"
2509.08712v1,Computational Imaging for Enhanced Computer Vision,"['Humera Shaikh', 'Kaur Jashanpreet']","This paper presents a comprehensive survey of computational imaging (CI)
techniques and their transformative impact on computer vision (CV)
applications. Conventional imaging methods often fail to deliver high-fidelity
visual data in challenging conditions, such as low light, motion blur, or high
dynamic range scenes, thereby limiting the performance of state-of-the-art CV
systems. Computational imaging techniques, including light field imaging, high
dynamic range (HDR) imaging, deblurring, high-speed imaging, and glare
mitigation, address these limitations by enhancing image acquisition and
reconstruction processes. This survey systematically explores the synergies
between CI techniques and core CV tasks, including object detection, depth
estimation, optical flow, face recognition, and keypoint detection. By
analyzing the relationships between CI methods and their practical
contributions to CV applications, this work highlights emerging opportunities,
challenges, and future research directions. We emphasize the potential for
task-specific, adaptive imaging pipelines that improve robustness, accuracy,
and efficiency in real-world scenarios, such as autonomous navigation,
surveillance, augmented reality, and robotics.",2025-09-10T16:02:42Z,http://arxiv.org/pdf/2509.08712v1,['cs.CV']
2306.09179v1,Neural World Models for Computer Vision,['Anthony Hu'],"Humans navigate in their environment by learning a mental model of the world
through passive observation and active interaction. Their world model allows
them to anticipate what might happen next and act accordingly with respect to
an underlying objective. Such world models hold strong promises for planning in
complex environments like in autonomous driving. A human driver, or a
self-driving system, perceives their surroundings with their eyes or their
cameras. They infer an internal representation of the world which should: (i)
have spatial memory (e.g. occlusions), (ii) fill partially observable or noisy
inputs (e.g. when blinded by sunlight), and (iii) be able to reason about
unobservable events probabilistically (e.g. predict different possible
futures). They are embodied intelligent agents that can predict, plan, and act
in the physical world through their world model. In this thesis we present a
general framework to train a world model and a policy, parameterised by deep
neural networks, from camera observations and expert demonstrations. We
leverage important computer vision concepts such as geometry, semantics, and
motion to scale world models to complex urban driving scenes.
  First, we propose a model that predicts important quantities in computer
vision: depth, semantic segmentation, and optical flow. We then use 3D geometry
as an inductive bias to operate in the bird's-eye view space. We present for
the first time a model that can predict probabilistic future trajectories of
dynamic agents in bird's-eye view from 360{\deg} surround monocular cameras
only. Finally, we demonstrate the benefits of learning a world model in
closed-loop driving. Our model can jointly predict static scene, dynamic scene,
and ego-behaviour in an urban driving environment.",2023-06-15T14:58:21Z,http://arxiv.org/pdf/2306.09179v1,"['cs.CV', 'cs.AI', 'cs.RO']"
1506.04130v3,CloudCV: Large Scale Distributed Computer Vision as a Cloud Service,"['Harsh Agrawal', 'Clint Solomon Mathialagan', 'Yash Goyal', 'Neelima Chavali', 'Prakriti Banik', 'Akrit Mohapatra', 'Ahmed Osman', 'Dhruv Batra']","We are witnessing a proliferation of massive visual data. Unfortunately
scaling existing computer vision algorithms to large datasets leaves
researchers repeatedly solving the same algorithmic, logistical, and
infrastructural problems. Our goal is to democratize computer vision; one
should not have to be a computer vision, big data and distributed computing
expert to have access to state-of-the-art distributed computer vision
algorithms. We present CloudCV, a comprehensive system to provide access to
state-of-the-art distributed computer vision algorithms as a cloud service
through a Web Interface and APIs.",2015-06-12T19:50:07Z,http://arxiv.org/pdf/1506.04130v3,"['cs.CV', 'cs.DC']"
1512.00567v3,Rethinking the Inception Architecture for Computer Vision,"['Christian Szegedy', 'Vincent Vanhoucke', 'Sergey Ioffe', 'Jonathon Shlens', 'Zbigniew Wojna']","Convolutional networks are at the core of most state-of-the-art computer
vision solutions for a wide variety of tasks. Since 2014 very deep
convolutional networks started to become mainstream, yielding substantial gains
in various benchmarks. Although increased model size and computational cost
tend to translate to immediate quality gains for most tasks (as long as enough
labeled data is provided for training), computational efficiency and low
parameter count are still enabling factors for various use cases such as mobile
vision and big-data scenarios. Here we explore ways to scale up networks in
ways that aim at utilizing the added computation as efficiently as possible by
suitably factorized convolutions and aggressive regularization. We benchmark
our methods on the ILSVRC 2012 classification challenge validation set
demonstrate substantial gains over the state of the art: 21.2% top-1 and 5.6%
top-5 error for single frame evaluation using a network with a computational
cost of 5 billion multiply-adds per inference and with using less than 25
million parameters. With an ensemble of 4 models and multi-crop evaluation, we
report 3.5% top-5 error on the validation set (3.6% error on the test set) and
17.3% top-1 error on the validation set.",2015-12-02T03:44:38Z,http://arxiv.org/pdf/1512.00567v3,['cs.CV']
1609.09582v1,Digitizing Municipal Street Inspections Using Computer Vision,"['Varun Adibhatla', 'Shi Fan', 'Krystof Litomisky', 'Patrick Atwater']","""People want an authority to tell them how to value things. But they chose
this authority not based on facts or results. They chose it because it seems
authoritative and familiar."" - The Big Short
  The pavement condition index is one such a familiar measure used by many US
cities to measure street quality and justify billions of dollars spent every
year on street repair. These billion-dollar decisions are based on evaluation
criteria that are subjective and not representative. In this paper, we build
upon our initial submission to D4GX 2015 that approaches this problem of
information asymmetry in municipal decision-making.
  We describe a process to identify street-defects using computer vision
techniques on data collected using the Street Quality Identification Device
(SQUID). A User Interface to host a large quantity of image data towards
digitizing the street inspection process and enabling actionable intelligence
for a core public service is also described. This approach of combining device,
data and decision-making around street repair enables cities make targeted
decisions about street repair and could lead to an anticipatory response which
can result in significant cost savings. Lastly, we share lessons learnt from
the deployment of SQUID in the city of Syracuse, NY.",2016-09-30T03:36:03Z,http://arxiv.org/pdf/1609.09582v1,"['cs.CY', 'cs.CV']"
2003.08485v1,Self-Supervised Contextual Bandits in Computer Vision,"['Aniket Anand Deshmukh', 'Abhimanu Kumar', 'Levi Boyles', 'Denis Charles', 'Eren Manavoglu', 'Urun Dogan']","Contextual bandits are a common problem faced by machine learning
practitioners in domains as diverse as hypothesis testing to product
recommendations. There have been a lot of approaches in exploiting rich data
representations for contextual bandit problems with varying degree of success.
Self-supervised learning is a promising approach to find rich data
representations without explicit labels. In a typical self-supervised learning
scheme, the primary task is defined by the problem objective (e.g. clustering,
classification, embedding generation etc.) and the secondary task is defined by
the self-supervision objective (e.g. rotation prediction, words in
neighborhood, colorization, etc.). In the usual self-supervision, we learn
implicit labels from the training data for a secondary task. However, in the
contextual bandit setting, we don't have the advantage of getting implicit
labels due to lack of data in the initial phase of learning. We provide a novel
approach to tackle this issue by combining a contextual bandit objective with a
self supervision objective. By augmenting contextual bandit learning with
self-supervision we get a better cumulative reward. Our results on eight
popular computer vision datasets show substantial gains in cumulative reward.
We provide cases where the proposed scheme doesn't perform optimally and give
alternative methods for better learning in these cases.",2020-03-18T22:06:34Z,http://arxiv.org/pdf/2003.08485v1,"['cs.CV', 'cs.LG', 'stat.ML']"
2201.00095v1,Computer Vision Based Parking Optimization System,"['Siddharth Chandrasekaran', 'Jeffrey Matthew Reginald', 'Wei Wang', 'Ting Zhu']","An improvement in technology is linearly related to time and time-relevant
problems. It has been seen that as time progresses, the number of problems
humans face also increases. However, technology to resolve these problems tends
to improve as well. One of the earliest existing problems which started with
the invention of vehicles was parking. The ease of resolving this problem using
technology has evolved over the years but the problem of parking still remains
unsolved. The main reason behind this is that parking does not only involve one
problem but it consists of a set of problems within itself. One of these
problems is the occupancy detection of the parking slots in a distributed
parking ecosystem. In a distributed system, users would find preferable parking
spaces as opposed to random parking spaces. In this paper, we propose a
web-based application as a solution for parking space detection in different
parking spaces. The solution is based on Computer Vision (CV) and is built
using the Django framework written in Python 3.0. The solution works to resolve
the occupancy detection problem along with providing the user the option to
determine the block based on availability and his preference. The evaluation
results for our proposed system are promising and efficient. The proposed
system can also be integrated with different systems and be used for solving
other relevant parking problems.",2022-01-01T02:35:49Z,http://arxiv.org/pdf/2201.00095v1,"['cs.CV', 'cs.AI']"
2211.13137v1,Pruned Lightweight Encoders for Computer Vision,"['Jakub Žádník', 'Markku Mäkitalo', 'Pekka Jääskeläinen']","Latency-critical computer vision systems, such as autonomous driving or drone
control, require fast image or video compression when offloading neural network
inference to a remote computer. To ensure low latency on a near-sensor edge
device, we propose the use of lightweight encoders with constant bitrate and
pruned encoding configurations, namely, ASTC and JPEG XS. Pruning introduces
significant distortion which we show can be recovered by retraining the neural
network with compressed data after decompression. Such an approach does not
modify the network architecture or require coding format modifications. By
retraining with compressed datasets, we reduced the classification accuracy and
segmentation mean intersection over union (mIoU) degradation due to ASTC
compression to 4.9-5.0 percentage points (pp) and 4.4-4.0 pp, respectively.
With the same method, the mIoU lost due to JPEG XS compression at the main
profile was restored to 2.7-2.3 pp. In terms of encoding speed, our ASTC
encoder implementation is 2.3x faster than JPEG. Even though the JPEG XS
reference encoder requires optimizations to reach low latency, we showed that
disabling significance flag coding saves 22-23% of encoding time at the cost of
0.4-0.3 mIoU after retraining.",2022-11-23T17:11:48Z,http://arxiv.org/pdf/2211.13137v1,['cs.CV']
2301.05070v1,Wildfire Smoke Detection with Computer Vision,['Eldan R. Daniel'],"Wildfires are becoming more frequent and their effects more devastating every
day. Climate change has directly and indirectly affected the occurrence of
these, as well as social phenomena have increased the vulnerability of people.
Consequently, and given the inevitable occurrence of these, it is important to
have early warning systems that allow a timely and effective response.
Artificial intelligence, machine learning and Computer Vision offer an
effective and achievable alternative for opportune detection of wildfires and
thus reduce the risk of disasters. YOLOv7 offers a simple, fast, and efficient
algorithm for training object detection models which can be used in early
detection of smoke columns in the initial stage wildfires. The developed model
showed promising results, achieving a score of 0.74 in the F1 curve when the
confidence level is 0.298, that is, a higher score at lower confidence levels
was obtained. This means when the conditions are favorable for false positives.
The metrics demonstrates the resilience and effectiveness of the model in
detecting smoke columns.",2023-01-12T15:12:56Z,http://arxiv.org/pdf/2301.05070v1,"['cs.CV', 'cs.AI']"
2303.11684v2,SpikeCV: Open a Continuous Computer Vision Era,"['Yajing Zheng', 'Jiyuan Zhang', 'Rui Zhao', 'Jianhao Ding', 'Shiyan Chen', 'Ruiqin Xiong', 'Zhaofei Yu', 'Tiejun Huang']","SpikeCV is a new open-source computer vision platform for the spike camera,
which is a neuromorphic visual sensor that has developed rapidly in recent
years. In the spike camera, each pixel position directly accumulates the light
intensity and asynchronously fires spikes. The output binary spikes can reach a
frequency of 40,000 Hz. As a new type of visual expression, spike sequence has
high spatiotemporal completeness and preserves the continuous visual
information of the external world. Taking advantage of the low latency and high
dynamic range of the spike camera, many spike-based algorithms have made
significant progress, such as high-quality imaging and ultra-high-speed target
detection.
  To build up a community ecology for the spike vision to facilitate more users
to take advantage of the spike camera, SpikeCV provides a variety of
ultra-high-speed scene datasets, hardware interfaces, and an easy-to-use
modules library. SpikeCV focuses on encapsulation for spike data,
standardization for dataset interfaces, modularization for vision tasks, and
real-time applications for challenging scenes. With the advent of the
open-source Python ecosystem, modules of SpikeCV can be used as a Python
library to fulfilled most of the numerical analysis needs of researchers. We
demonstrate the efficiency of the SpikeCV on offline inference and real-time
applications. The project repository address are
\url{https://openi.pcl.ac.cn/Cordium/SpikeCV} and
\url{https://github.com/Zyj061/SpikeCV",2023-03-21T09:00:12Z,http://arxiv.org/pdf/2303.11684v2,['cs.CV']
2307.13992v2,Causal reasoning in typical computer vision tasks,"['Kexuan Zhang', 'Qiyu Sun', 'Chaoqiang Zhao', 'Yang Tang']","Deep learning has revolutionized the field of artificial intelligence. Based
on the statistical correlations uncovered by deep learning-based methods,
computer vision has contributed to tremendous growth in areas like autonomous
driving and robotics. Despite being the basis of deep learning, such
correlation is not stable and is susceptible to uncontrolled factors. In the
absence of the guidance of prior knowledge, statistical correlations can easily
turn into spurious correlations and cause confounders. As a result, researchers
are now trying to enhance deep learning methods with causal theory. Causal
theory models the intrinsic causal structure unaffected by data bias and is
effective in avoiding spurious correlations. This paper aims to comprehensively
review the existing causal methods in typical vision and vision-language tasks
such as semantic segmentation, object detection, and image captioning. The
advantages of causality and the approaches for building causal paradigms will
be summarized. Future roadmaps are also proposed, including facilitating the
development of causal theory and its application in other complex scenes and
systems.",2023-07-26T07:01:57Z,http://arxiv.org/pdf/2307.13992v2,['cs.CV']
2309.10878v1,DeepliteRT: Computer Vision at the Edge,"['Saad Ashfaq', 'Alexander Hoffman', 'Saptarshi Mitra', 'Sudhakar Sah', 'MohammadHossein AskariHemmat', 'Ehsan Saboori']","The proliferation of edge devices has unlocked unprecedented opportunities
for deep learning model deployment in computer vision applications. However,
these complex models require considerable power, memory and compute resources
that are typically not available on edge platforms. Ultra low-bit quantization
presents an attractive solution to this problem by scaling down the model
weights and activations from 32-bit to less than 8-bit. We implement highly
optimized ultra low-bit convolution operators for ARM-based targets that
outperform existing methods by up to 4.34x. Our operator is implemented within
Deeplite Runtime (DeepliteRT), an end-to-end solution for the compilation,
tuning, and inference of ultra low-bit models on ARM devices. Compiler passes
in DeepliteRT automatically convert a fake-quantized model in full precision to
a compact ultra low-bit representation, easing the process of quantized model
deployment on commodity hardware. We analyze the performance of DeepliteRT on
classification and detection models against optimized 32-bit floating-point,
8-bit integer, and 2-bit baselines, achieving significant speedups of up to
2.20x, 2.33x and 2.17x, respectively.",2023-09-19T18:58:38Z,http://arxiv.org/pdf/2309.10878v1,"['cs.LG', 'cs.CV']"
2404.01116v1,Intelligent Robotic Control System Based on Computer Vision Technology,"['Chang Che', 'Haotian Zheng', 'Zengyi Huang', 'Wei Jiang', 'Bo Liu']","The article explores the intersection of computer vision technology and
robotic control, highlighting its importance in various fields such as
industrial automation, healthcare, and environmental protection. Computer
vision technology, which simulates human visual observation, plays a crucial
role in enabling robots to perceive and understand their surroundings, leading
to advancements in tasks like autonomous navigation, object recognition, and
waste management. By integrating computer vision with robot control, robots
gain the ability to interact intelligently with their environment, improving
efficiency.",2024-04-01T13:46:23Z,http://arxiv.org/pdf/2404.01116v1,['cs.RO']
1304.2367v1,Utility-Based Control for Computer Vision,"['Tod S. Levitt', 'Thomas O. Binford', 'Gil J. Ettinger', 'Patrice Gelband']","Several key issues arise in implementing computer vision recognition of world
objects in terms of Bayesian networks. Computational efficiency is a driving
force. Perceptual networks are very deep, typically fifteen levels of
structure. Images are wide, e.g., an unspecified-number of edges may appear
anywhere in an image 512 x 512 pixels or larger. For efficiency, we dynamically
instantiate hypotheses of observed objects. The network is not fixed, but is
created incrementally at runtime. Generation of hypotheses of world objects and
indexing of models for recognition are important, but they are not considered
here [4,11]. This work is aimed at near-term implementation with parallel
computation in a radar surveillance system, ADRIES [5, 15], and a system for
industrial part recognition, SUCCESSOR [2]. For many applications, vision must
be faster to be practical and so efficiently controlling the machine vision
process is critical. Perceptual operators may scan megapixels and may require
minutes of computation time. It is necessary to avoid unnecessary sensor
actions and computation. Parallel computation is available at several levels of
processor capability. The potential for parallel, distributed computation for
high-level vision means distributing non-homogeneous computations. This paper
addresses the problem of task control in machine vision systems based on
Bayesian probability models. We separate control and inference to extend the
previous work [3] to maximize utility instead of probability. Maximizing
utility allows adopting perceptual strategies for efficient information
gathering with sensors and analysis of sensor data. Results of controlling
machine vision via utility to recognize military situations are presented in
this paper. Future work extends this to industrial part recognition for
SUCCESSOR.",2013-03-27T19:44:16Z,http://arxiv.org/pdf/1304.2367v1,"['cs.CV', 'cs.AI', 'cs.SY']"
1704.05072v1,Characterising dark matter haloes with computer vision,"['Julian Merten', 'Quim Llorens', 'Hans Winther']","This work explores the ability of computer vision algorithms to characterise
dark matter haloes formed in different models of structure formation. We
produce surface mass density maps of the most massive haloes in a suite of
eight numerical simulations, all based on the same initial conditions, but
implementing different models of gravity. This suite includes a standard
$\Lambda$CDM model, two variations of $f(R)$-gravity, two variations of
Symmetron gravity and three Dvali, Gabadadze and Porrati (DGP) models. We use
the publicly available WND-CHARM algorithm to extract 2919 image features from
either the raw pixel intensities of the maps, or from a variety of image
transformations including Fourier, Wavelet, Chebyshev and Edge transformations.
After discarding the most degenerate models, we achieve more than 60%
single-image classification success rate in distinguishing the four different
models of gravity while using a simple weighted neighbour distance (WND) to
define our classification metric. This number can be increased to more than 70%
if additional information, such as a rough estimate of the halo mass, is
included. We find that the classification success steeply declines when the
noise level in the images is increased, but that this trend can be largely
reduced by smoothing the noisy data. We find Zernike moments of the Fourier
transformation of either the raw image or its Wavelet transformation to be the
most descriptive feature, followed by the Gini coefficient of several
transformations and the Haralick and Tamura textures of the raw pixel data
eventually pre-processed by an Edge transformation. The proposed methodology is
general and does not only apply to the characterisation of modified gravity
models, but can be used to classify any set of models which show variations in
the 2D morphology of their respective structure.",2017-04-17T18:00:07Z,http://arxiv.org/pdf/1704.05072v1,"['astro-ph.CO', 'gr-qc']"
2209.05834v1,Computer vision system to count crustacean larvae,['Chen Rothschild'],"Fish products account for about 16 percent of the human diet worldwide, as of
2017. The counting action is a significant component in growing and producing
these products. Growers must count the fish accurately, to do so technological
solutions are needed. Two computer vision systems to automatically count
crustacean larvae grown in industrial ponds were developed. The first system
included an iPhone 11 camera with 3024X4032 resolution which acquired images
from an industrial pond in indoor conditions. Two experiments were performed
with this system, the first one included 200 images acquired in one day on
growth stages 9,10 with an iPhone 11 camera on specific illumination condition.
In the second experiment, a larvae industrial pond was photographed for 11 days
with two devices an iPhone 11 and a SONY DSCHX90V cameras. With the first
device (iPhone 11) two illumination conditions were tested. In each condition,
110 images were acquired. That system resulted in an accuracy of 88.4 percent
image detection. The second system included a DSLR Nikon D510 camera with a
2000X2000 resolution with which seven experiments were performed outside the
industrial pond. Images were acquired on day 1 of larvae growing stage
resulting in the acquisition of a total of 700 images. That system resulted in
an accuracy of 86 percent for a density of 50. An algorithm that automatically
counts the number of larvae was developed for both cases based on the YOLOv5
CNN model. In addition, in this study, a larvae growth function was developed.
Daily, several larvae were taken manually from the industrial pond and analyzed
under a microscope. Once the growth stage was determined, images of the larva
were acquired. Each larva's length was measured manually from the images. The
most suitable model was the Gompertz model with a goodness of fit index of R
squared of 0.983.",2022-09-13T09:18:13Z,http://arxiv.org/pdf/2209.05834v1,"['cs.CV', 'eess.IV']"
2210.05451v1,Enabling ISP-less Low-Power Computer Vision,"['Gourav Datta', 'Zeyu Liu', 'Zihan Yin', 'Linyu Sun', 'Akhilesh R. Jaiswal', 'Peter A. Beerel']","In order to deploy current computer vision (CV) models on
resource-constrained low-power devices, recent works have proposed in-sensor
and in-pixel computing approaches that try to partly/fully bypass the image
signal processor (ISP) and yield significant bandwidth reduction between the
image sensor and the CV processing unit by downsampling the activation maps in
the initial convolutional neural network (CNN) layers. However, direct
inference on the raw images degrades the test accuracy due to the difference in
covariance of the raw images captured by the image sensors compared to the
ISP-processed images used for training. Moreover, it is difficult to train deep
CV models on raw images, because most (if not all) large-scale open-source
datasets consist of RGB images. To mitigate this concern, we propose to invert
the ISP pipeline, which can convert the RGB images of any dataset to its raw
counterparts, and enable model training on raw images. We release the raw
version of the COCO dataset, a large-scale benchmark for generic high-level
vision tasks. For ISP-less CV systems, training on these raw images result in a
7.1% increase in test accuracy on the visual wake works (VWW) dataset compared
to relying on training with traditional ISP-processed RGB datasets. To further
improve the accuracy of ISP-less CV models and to increase the energy and
bandwidth benefits obtained by in-sensor/in-pixel computing, we propose an
energy-efficient form of analog in-pixel demosaicing that may be coupled with
in-pixel CNN computations. When evaluated on raw images captured by real
sensors from the PASCALRAW dataset, our approach results in a 8.1% increase in
mAP. Lastly, we demonstrate a further 20.5% increase in mAP by using a novel
application of few-shot learning with thirty shots each for the novel PASCALRAW
dataset, constituting 3 classes.",2022-10-11T13:47:30Z,http://arxiv.org/pdf/2210.05451v1,"['cs.CV', 'eess.IV']"
1707.03720v1,"Multiband NFC for High-Throughput Wireless Computer Vision Sensor
  Network","['F. Li', 'J. Du']","Vision sensors lie in the heart of computer vision. In many computer vision
applications, such as AR/VR, non-contacting near-field communication (NFC) with
high throughput is required to transfer information to algorithms. In this
work, we proposed a novel NFC system which utilizes multiple frequency bands to
achieve high throughput.",2017-05-28T06:43:29Z,http://arxiv.org/pdf/1707.03720v1,"['cs.NI', 'cs.CV']"
2501.10343v1,3rd Workshop on Maritime Computer Vision (MaCVi) 2025: Challenge Results,"['Benjamin Kiefer', 'Lojze Žust', 'Jon Muhovič', 'Matej Kristan', 'Janez Perš', 'Matija Teršek', 'Uma Mudenagudi Chaitra Desai', 'Arnold Wiliem', 'Marten Kreis', 'Nikhil Akalwadi', 'Yitong Quan', 'Zhiqiang Zhong', 'Zhe Zhang', 'Sujie Liu', 'Xuran Chen', 'Yang Yang', 'Matej Fabijanić', 'Fausto Ferreira', 'Seongju Lee', 'Junseok Lee', 'Kyoobin Lee', 'Shanliang Yao', 'Runwei Guan', 'Xiaoyu Huang', 'Yi Ni', 'Himanshu Kumar', 'Yuan Feng', 'Yi-Ching Cheng', 'Tzu-Yu Lin', 'Chia-Ming Lee', 'Chih-Chung Hsu', 'Jannik Sheikh', 'Andreas Michel', 'Wolfgang Gross', 'Martin Weinmann', 'Josip Šarić', 'Yipeng Lin', 'Xiang Yang', 'Nan Jiang', 'Yutang Lu', 'Fei Feng', 'Ali Awad', 'Evan Lucas', 'Ashraf Saleem', 'Ching-Heng Cheng', 'Yu-Fan Lin', 'Tzu-Yu Lin', 'Chih-Chung Hsu']","The 3rd Workshop on Maritime Computer Vision (MaCVi) 2025 addresses maritime
computer vision for Unmanned Surface Vehicles (USV) and underwater. This report
offers a comprehensive overview of the findings from the challenges. We provide
both statistical and qualitative analyses, evaluating trends from over 700
submissions. All datasets, evaluation code, and the leaderboard are available
to the public at https://macvi.org/workshop/macvi25.",2025-01-17T18:34:47Z,http://arxiv.org/pdf/2501.10343v1,"['cs.CV', 'cs.AI']"
1601.06615v1,A Taxonomy of Deep Convolutional Neural Nets for Computer Vision,"['Suraj Srinivas', 'Ravi Kiran Sarvadevabhatla', 'Konda Reddy Mopuri', 'Nikita Prabhu', 'Srinivas S S Kruthiventi', 'R. Venkatesh Babu']","Traditional architectures for solving computer vision problems and the degree
of success they enjoyed have been heavily reliant on hand-crafted features.
However, of late, deep learning techniques have offered a compelling
alternative -- that of automatically learning problem-specific features. With
this new paradigm, every problem in computer vision is now being re-examined
from a deep learning perspective. Therefore, it has become important to
understand what kind of deep networks are suitable for a given problem.
Although general surveys of this fast-moving paradigm (i.e. deep-networks)
exist, a survey specific to computer vision is missing. We specifically
consider one form of deep networks widely used in computer vision -
convolutional neural networks (CNNs). We start with ""AlexNet"" as our base CNN
and then examine the broad variations proposed over time to suit different
applications. We hope that our recipe-style survey will serve as a guide,
particularly for novice practitioners intending to use deep-learning techniques
for computer vision.",2016-01-25T14:25:07Z,http://arxiv.org/pdf/1601.06615v1,"['cs.CV', 'cs.LG', 'cs.MM']"
2203.15269v1,"Vision Transformers in Medical Computer Vision -- A Contemplative
  Retrospection","['Arshi Parvaiz', 'Muhammad Anwaar Khalid', 'Rukhsana Zafar', 'Huma Ameer', 'Muhammad Ali', 'Muhammad Moazam Fraz']","Recent escalation in the field of computer vision underpins a huddle of
algorithms with the magnificent potential to unravel the information contained
within images. These computer vision algorithms are being practised in medical
image analysis and are transfiguring the perception and interpretation of
Imaging data. Among these algorithms, Vision Transformers are evolved as one of
the most contemporary and dominant architectures that are being used in the
field of computer vision. These are immensely utilized by a plenty of
researchers to perform new as well as former experiments. Here, in this article
we investigate the intersection of Vision Transformers and Medical images and
proffered an overview of various ViTs based frameworks that are being used by
different researchers in order to decipher the obstacles in Medical Computer
Vision. We surveyed the application of Vision transformers in different areas
of medical computer vision such as image-based disease classification,
anatomical structure segmentation, registration, region-based lesion Detection,
captioning, report generation, reconstruction using multiple medical imaging
modalities that greatly assist in medical diagnosis and hence treatment
process. Along with this, we also demystify several imaging modalities used in
Medical Computer Vision. Moreover, to get more insight and deeper
understanding, self-attention mechanism of transformers is also explained
briefly. Conclusively, we also put some light on available data sets, adopted
methodology, their performance measures, challenges and their solutions in form
of discussion. We hope that this review article will open future directions for
researchers in medical computer vision.",2022-03-29T06:32:43Z,http://arxiv.org/pdf/2203.15269v1,"['eess.IV', 'cs.CV', 'cs.LG']"
1604.04372v2,The Chow Form of the Essential Variety in Computer Vision,"['Gunnar Fløystad', 'Joe Kileel', 'Giorgio Ottaviani']","The Chow form of the essential variety in computer vision is calculated. Our
derivation uses secant varieties, Ulrich sheaves and representation theory.
Numerical experiments show that our formula can detect noisy point
correspondences between two images.",2016-04-15T06:57:09Z,http://arxiv.org/pdf/1604.04372v2,"['math.AG', 'cs.CV', 'math.AC', '14M12, 14C05, 14Q15, 13D02, 13C14, 68T45']"
2004.09420v2,Computer Vision For COVID-19 Control: A Survey,"['Anwaar Ulhaq', 'Asim Khan', 'Douglas Gomes', 'Manoranjan Paul']","The COVID-19 pandemic has triggered an urgent need to contribute to the fight
against an immense threat to the human population. Computer Vision, as a
subfield of Artificial Intelligence, has enjoyed recent success in solving
various complex problems in health care and has the potential to contribute to
the fight of controlling COVID-19. In response to this call, computer vision
researchers are putting their knowledge base at work to devise effective ways
to counter COVID-19 challenge and serve the global community. New contributions
are being shared with every passing day. It motivated us to review the recent
work, collect information about available research resources and an indication
of future research directions. We want to make it available to computer vision
researchers to save precious time. This survey paper is intended to provide a
preliminary review of the available literature on the computer vision efforts
against COVID-19 pandemic.",2020-04-15T05:43:52Z,http://arxiv.org/pdf/2004.09420v2,"['eess.IV', 'cs.CV', 'I.4.9']"
2001.02366v2,What can robotics research learn from computer vision research?,"['Peter Corke', 'Feras Dayoub', 'David Hall', 'John Skinner', 'Niko Sünderhauf']","The computer vision and robotics research communities are each strong.
However progress in computer vision has become turbo-charged in recent years
due to big data, GPU computing, novel learning algorithms and a very effective
research methodology. By comparison, progress in robotics seems slower. It is
true that robotics came later to exploring the potential of learning -- the
advantages over the well-established body of knowledge in dynamics, kinematics,
planning and control is still being debated, although reinforcement learning
seems to offer real potential. However, the rapid development of computer
vision compared to robotics cannot be only attributed to the former's adoption
of deep learning. In this paper, we argue that the gains in computer vision are
due to research methodology -- evaluation under strict constraints versus
experiments; bold numbers versus videos.",2020-01-08T04:32:10Z,http://arxiv.org/pdf/2001.02366v2,"['cs.RO', 'cs.CV']"
2305.06611v1,Hyperbolic Deep Learning in Computer Vision: A Survey,"['Pascal Mettes', 'Mina Ghadimi Atigh', 'Martin Keller-Ressel', 'Jeffrey Gu', 'Serena Yeung']","Deep representation learning is a ubiquitous part of modern computer vision.
While Euclidean space has been the de facto standard manifold for learning
visual representations, hyperbolic space has recently gained rapid traction for
learning in computer vision. Specifically, hyperbolic learning has shown a
strong potential to embed hierarchical structures, learn from limited samples,
quantify uncertainty, add robustness, limit error severity, and more. In this
paper, we provide a categorization and in-depth overview of current literature
on hyperbolic learning for computer vision. We research both supervised and
unsupervised literature and identify three main research themes in each
direction. We outline how hyperbolic learning is performed in all themes and
discuss the main research problems that benefit from current advances in
hyperbolic learning for computer vision. Moreover, we provide a high-level
intuition behind hyperbolic geometry and outline open research questions to
further advance research in this direction.",2023-05-11T07:14:23Z,http://arxiv.org/pdf/2305.06611v1,['cs.CV']
2109.00783v4,Computer Vision Self-supervised Learning Methods on Time Series,"['Daesoo Lee', 'Erlend Aune']","Self-supervised learning (SSL) has had great success in both computer vision.
Most of the current mainstream computer vision SSL frameworks are based on
Siamese network architecture. These approaches often rely on cleverly crafted
loss functions and training setups to avoid feature collapse. In this study, we
evaluate if those computer-vision SSL frameworks are also effective on a
different modality (\textit{i.e.,} time series). The effectiveness is
experimented and evaluated on the UCR and UEA archives, and we show that the
computer vision SSL frameworks can be effective even for time series. In
addition, we propose a new method that improves on the recently proposed VICReg
method. Our method improves on a \textit{covariance} term proposed in VICReg,
and in addition we augment the head of the architecture by an iterative
normalization layer that accelerates the convergence of the model.",2021-09-02T08:45:53Z,http://arxiv.org/pdf/2109.00783v4,"['cs.LG', 'cs.AI', 'stat.ML']"
2301.07583v1,A Survey of Advanced Computer Vision Techniques for Sports,"['Tiago Mendes-Neves', 'Luís Meireles', 'João Mendes-Moreira']","Computer Vision developments are enabling significant advances in many
fields, including sports. Many applications built on top of Computer Vision
technologies, such as tracking data, are nowadays essential for every top-level
analyst, coach, and even player. In this paper, we survey Computer Vision
techniques that can help many sports-related studies gather vast amounts of
data, such as Object Detection and Pose Estimation. We provide a use case for
such data: building a model for shot speed estimation with pose data obtained
using only Computer Vision models. Our model achieves a correlation of 67%. The
possibility of estimating shot speeds enables much deeper studies about
enabling the creation of new metrics and recommendation systems that will help
athletes improve their performance, in any sport. The proposed methodology is
easily replicable for many technical movements and is only limited by the
availability of video data.",2023-01-18T15:01:36Z,http://arxiv.org/pdf/2301.07583v1,"['cs.CV', 'cs.LG', '68T45, 68T01, 92C10']"
2103.00560v1,"Perspectives on individual animal identification from biology and
  computer vision","['Maxime Vidal', 'Nathan Wolf', 'Beth Rosenberg', 'Bradley P. Harris', 'Alexander Mathis']","Identifying individual animals is crucial for many biological investigations.
In response to some of the limitations of current identification methods, new
automated computer vision approaches have emerged with strong performance.
Here, we review current advances of computer vision identification techniques
to provide both computer scientists and biologists with an overview of the
available tools and discuss their applications. We conclude by offering
recommendations for starting an animal identification project, illustrate
current limitations and propose how they might be addressed in the future.",2021-02-28T16:50:09Z,http://arxiv.org/pdf/2103.00560v1,"['cs.CV', 'q-bio.QM']"
2305.18035v3,Physics-Informed Computer Vision: A Review and Perspectives,"['Chayan Banerjee', 'Kien Nguyen', 'Clinton Fookes', 'George Karniadakis']","The incorporation of physical information in machine learning frameworks is
opening and transforming many application domains. Here the learning process is
augmented through the induction of fundamental knowledge and governing physical
laws. In this work, we explore their utility for computer vision tasks in
interpreting and understanding visual data. We present a systematic literature
review of more than 250 papers on formulation and approaches to computer vision
tasks guided by physical laws. We begin by decomposing the popular computer
vision pipeline into a taxonomy of stages and investigate approaches to
incorporate governing physical equations in each stage. Existing approaches in
computer vision tasks are analyzed with regard to what governing physical
processes are modeled and formulated, and how they are incorporated, i.e.
modification of input data (observation bias), modification of network
architectures (inductive bias), and modification of training losses (learning
bias). The taxonomy offers a unified view of the application of the
physics-informed capability, highlighting where physics-informed learning has
been conducted and where the gaps and opportunities are. Finally, we highlight
open problems and challenges to inform future research. While still in its
early days, the study of physics-informed computer vision has the promise to
develop better computer vision models that can improve physical plausibility,
accuracy, data efficiency, and generalization in increasingly realistic
applications.",2023-05-29T11:55:11Z,http://arxiv.org/pdf/2305.18035v3,"['eess.IV', 'cs.CV']"
2401.11617v3,The State of Computer Vision Research in Africa,"['Abdul-Hakeem Omotayo', 'Ashery Mbilinyi', 'Lukman Ismaila', 'Houcemeddine Turki', 'Mahmoud Abdien', 'Karim Gamal', 'Idriss Tondji', 'Yvan Pimi', 'Naome A. Etori', 'Marwa M. Matar', 'Clifford Broni-Bediako', 'Abigail Oppong', 'Mai Gamal', 'Eman Ehab', 'Gbetondji Dovonon', 'Zainab Akinjobi', 'Daniel Ajisafe', 'Oluwabukola G. Adegboro', 'Mennatullah Siam']","Despite significant efforts to democratize artificial intelligence (AI),
computer vision which is a sub-field of AI, still lags in Africa. A significant
factor to this, is the limited access to computing resources, datasets, and
collaborations. As a result, Africa's contribution to top-tier publications in
this field has only been 0.06% over the past decade. Towards improving the
computer vision field and making it more accessible and inclusive, this study
analyzes 63,000 Scopus-indexed computer vision publications from Africa. We
utilize large language models to automatically parse their abstracts, to
identify and categorize topics and datasets. This resulted in listing more than
100 African datasets. Our objective is to provide a comprehensive taxonomy of
dataset categories to facilitate better understanding and utilization of these
resources. We also analyze collaboration trends of researchers within and
outside the continent. Additionally, we conduct a large-scale questionnaire
among African computer vision researchers to identify the structural barriers
they believe require urgent attention. In conclusion, our study offers a
comprehensive overview of the current state of computer vision research in
Africa, to empower marginalized communities to participate in the design and
development of computer vision systems.",2024-01-21T22:50:44Z,http://arxiv.org/pdf/2401.11617v3,['cs.CV']
2111.11066v1,FedCV: A Federated Learning Framework for Diverse Computer Vision Tasks,"['Chaoyang He', 'Alay Dilipbhai Shah', 'Zhenheng Tang', 'Di Fan1Adarshan Naiynar Sivashunmugam', 'Keerti Bhogaraju', 'Mita Shimpi', 'Li Shen', 'Xiaowen Chu', 'Mahdi Soltanolkotabi', 'Salman Avestimehr']","Federated Learning (FL) is a distributed learning paradigm that can learn a
global or personalized model from decentralized datasets on edge devices.
However, in the computer vision domain, model performance in FL is far behind
centralized training due to the lack of exploration in diverse tasks with a
unified FL framework. FL has rarely been demonstrated effectively in advanced
computer vision tasks such as object detection and image segmentation. To
bridge the gap and facilitate the development of FL for computer vision tasks,
in this work, we propose a federated learning library and benchmarking
framework, named FedCV, to evaluate FL on the three most representative
computer vision tasks: image classification, image segmentation, and object
detection. We provide non-I.I.D. benchmarking datasets, models, and various
reference FL algorithms. Our benchmark study suggests that there are multiple
challenges that deserve future exploration: centralized training tricks may not
be directly applied to FL; the non-I.I.D. dataset actually downgrades the model
accuracy to some degree in different tasks; improving the system efficiency of
federated training is challenging given the huge number of parameters and the
per-client memory cost. We believe that such a library and benchmark, along
with comparable evaluation settings, is necessary to make meaningful progress
in FL on computer vision tasks. FedCV is publicly available:
https://github.com/FedML-AI/FedCV.",2021-11-22T09:26:08Z,http://arxiv.org/pdf/2111.11066v1,"['cs.CV', 'cs.AI', 'cs.LG']"
2111.11432v1,Florence: A New Foundation Model for Computer Vision,"['Lu Yuan', 'Dongdong Chen', 'Yi-Ling Chen', 'Noel Codella', 'Xiyang Dai', 'Jianfeng Gao', 'Houdong Hu', 'Xuedong Huang', 'Boxin Li', 'Chunyuan Li', 'Ce Liu', 'Mengchen Liu', 'Zicheng Liu', 'Yumao Lu', 'Yu Shi', 'Lijuan Wang', 'Jianfeng Wang', 'Bin Xiao', 'Zhen Xiao', 'Jianwei Yang', 'Michael Zeng', 'Luowei Zhou', 'Pengchuan Zhang']","Automated visual understanding of our diverse and open world demands computer
vision models to generalize well with minimal customization for specific tasks,
similar to human vision. Computer vision foundation models, which are trained
on diverse, large-scale dataset and can be adapted to a wide range of
downstream tasks, are critical for this mission to solve real-world computer
vision applications. While existing vision foundation models such as CLIP,
ALIGN, and Wu Dao 2.0 focus mainly on mapping images and textual
representations to a cross-modal shared representation, we introduce a new
computer vision foundation model, Florence, to expand the representations from
coarse (scene) to fine (object), from static (images) to dynamic (videos), and
from RGB to multiple modalities (caption, depth). By incorporating universal
visual-language representations from Web-scale image-text data, our Florence
model can be easily adapted for various computer vision tasks, such as
classification, retrieval, object detection, VQA, image caption, video
retrieval and action recognition. Moreover, Florence demonstrates outstanding
performance in many types of transfer learning: fully sampled fine-tuning,
linear probing, few-shot transfer and zero-shot transfer for novel images and
objects. All of these properties are critical for our vision foundation model
to serve general purpose vision tasks. Florence achieves new state-of-the-art
results in majority of 44 representative benchmarks, e.g., ImageNet-1K
zero-shot classification with top-1 accuracy of 83.74 and the top-5 accuracy of
97.18, 62.4 mAP on COCO fine tuning, 80.36 on VQA, and 87.8 on Kinetics-600.",2021-11-22T18:59:55Z,http://arxiv.org/pdf/2111.11432v1,"['cs.CV', 'cs.AI', 'cs.LG']"
2408.02464v1,Fairness and Bias Mitigation in Computer Vision: A Survey,"['Sepehr Dehdashtian', 'Ruozhen He', 'Yi Li', 'Guha Balakrishnan', 'Nuno Vasconcelos', 'Vicente Ordonez', 'Vishnu Naresh Boddeti']","Computer vision systems have witnessed rapid progress over the past two
decades due to multiple advances in the field. As these systems are
increasingly being deployed in high-stakes real-world applications, there is a
dire need to ensure that they do not propagate or amplify any discriminatory
tendencies in historical or human-curated data or inadvertently learn biases
from spurious correlations. This paper presents a comprehensive survey on
fairness that summarizes and sheds light on ongoing trends and successes in the
context of computer vision. The topics we discuss include 1) The origin and
technical definitions of fairness drawn from the wider fair machine learning
literature and adjacent disciplines. 2) Work that sought to discover and
analyze biases in computer vision systems. 3) A summary of methods proposed to
mitigate bias in computer vision systems in recent years. 4) A comprehensive
summary of resources and datasets produced by researchers to measure, analyze,
and mitigate bias and enhance fairness. 5) Discussion of the field's success,
continuing trends in the context of multimodal foundation and generative
models, and gaps that still need to be addressed. The presented
characterization should help researchers understand the importance of
identifying and mitigating bias in computer vision and the state of the field
and identify potential directions for future research.",2024-08-05T13:44:22Z,http://arxiv.org/pdf/2408.02464v1,['cs.CV']
1607.07405v3,gvnn: Neural Network Library for Geometric Computer Vision,"['Ankur Handa', 'Michael Bloesch', 'Viorica Patraucean', 'Simon Stent', 'John McCormac', 'Andrew Davison']","We introduce gvnn, a neural network library in Torch aimed towards bridging
the gap between classic geometric computer vision and deep learning. Inspired
by the recent success of Spatial Transformer Networks, we propose several new
layers which are often used as parametric transformations on the data in
geometric computer vision. These layers can be inserted within a neural network
much in the spirit of the original spatial transformers and allow
backpropagation to enable end-to-end learning of a network involving any domain
knowledge in geometric computer vision. This opens up applications in learning
invariance to 3D geometric transformation for place recognition, end-to-end
visual odometry, depth estimation and unsupervised learning through warping
with a parametric transformation for image reconstruction error.",2016-07-25T18:57:17Z,http://arxiv.org/pdf/1607.07405v3,"['cs.CV', 'cs.LG']"
1708.08169v1,ChainerCV: a Library for Deep Learning in Computer Vision,"['Yusuke Niitani', 'Toru Ogawa', 'Shunta Saito', 'Masaki Saito']","Despite significant progress of deep learning in the field of computer
vision, there has not been a software library that covers these methods in a
unifying manner. We introduce ChainerCV, a software library that is intended to
fill this gap. ChainerCV supports numerous neural network models as well as
software components needed to conduct research in computer vision. These
implementations emphasize simplicity, flexibility and good software engineering
practices. The library is designed to perform on par with the results reported
in published papers and its tools can be used as a baseline for future research
in computer vision. Our implementation includes sophisticated models like
Faster R-CNN and SSD, and covers tasks such as object detection and semantic
segmentation.",2017-08-28T02:54:11Z,http://arxiv.org/pdf/1708.08169v1,['cs.CV']
2104.08188v1,I Find Your Lack of Uncertainty in Computer Vision Disturbing,['Matias Valdenegro-Toro'],"Neural networks are used for many real world applications, but often they
have problems estimating their own confidence. This is particularly problematic
for computer vision applications aimed at making high stakes decisions with
humans and their lives. In this paper we make a meta-analysis of the
literature, showing that most if not all computer vision applications do not
use proper epistemic uncertainty quantification, which means that these models
ignore their own limitations. We describe the consequences of using models
without proper uncertainty quantification, and motivate the community to adopt
versions of the models they use that have proper calibrated epistemic
uncertainty, in order to enable out of distribution detection. We close the
paper with a summary of challenges on estimating uncertainty for computer
vision applications and recommendations.",2021-04-16T15:58:27Z,http://arxiv.org/pdf/2104.08188v1,"['cs.CV', 'cs.LG']"
1802.06464v3,Robust Fitting in Computer Vision: Easy or Hard?,"['Tat-Jun Chin', 'Zhipeng Cai', 'Frank Neumann']","Robust model fitting plays a vital role in computer vision, and research into
algorithms for robust fitting continues to be active. Arguably the most popular
paradigm for robust fitting in computer vision is consensus maximisation, which
strives to find the model parameters that maximise the number of inliers.
Despite the significant developments in algorithms for consensus maximisation,
there has been a lack of fundamental analysis of the problem in the computer
vision literature. In particular, whether consensus maximisation is ""tractable""
remains a question that has not been rigorously dealt with, thus making it
difficult to assess and compare the performance of proposed algorithms,
relative to what is theoretically achievable. To shed light on these issues, we
present several computational hardness results for consensus maximisation. Our
results underline the fundamental intractability of the problem, and resolve
several ambiguities existing in the literature.",2018-02-18T22:54:50Z,http://arxiv.org/pdf/1802.06464v3,"['cs.CV', 'cs.CC']"
1909.10225v1,WiCV 2019: The Sixth Women In Computer Vision Workshop,"['Irene Amerini', 'Elena Balashova', 'Sayna Ebrahimi', 'Kathryn Leonard', 'Arsha Nagrani', 'Amaia Salvador']","In this paper we present the Women in Computer Vision Workshop - WiCV 2019,
organized in conjunction with CVPR 2019. This event is meant for increasing the
visibility and inclusion of women researchers in the computer vision field.
Computer vision and machine learning have made incredible progress over the
past years, but the number of female researchers is still low both in academia
and in industry. WiCV is organized especially for the following reason: to
raise visibility of female researchers, to increase collaborations between
them, and to provide mentorship to female junior researchers in the field. In
this paper, we present a report of trends over the past years, along with a
summary of statistics regarding presenters, attendees, and sponsorship for the
current workshop.",2019-09-23T08:52:33Z,http://arxiv.org/pdf/1909.10225v1,['cs.CV']
1911.05931v1,"VisionISP: Repurposing the Image Signal Processor for Computer Vision
  Applications","['Chyuan-Tyng Wu', 'Leo F. Isikdogan', 'Sushma Rao', 'Bhavin Nayak', 'Timo Gerasimow', 'Aleksandar Sutic', 'Liron Ain-kedem', 'Gilad Michael']","Traditional image signal processors (ISPs) are primarily designed and
optimized to improve the image quality perceived by humans. However, optimal
perceptual image quality does not always translate into optimal performance for
computer vision applications. We propose a set of methods, which we
collectively call VisionISP, to repurpose the ISP for machine consumption.
VisionISP significantly reduces data transmission needs by reducing the
bit-depth and resolution while preserving the relevant information. The blocks
in VisionISP are simple, content-aware, and trainable. Experimental results
show that VisionISP boosts the performance of a subsequent computer vision
system trained to detect objects in an autonomous driving setting. The results
demonstrate the potential and the practicality of VisionISP for computer vision
applications.",2019-11-14T04:19:28Z,http://arxiv.org/pdf/1911.05931v1,"['eess.IV', 'cs.CV']"
2203.05825v1,WiCV 2021: The Eighth Women In Computer Vision Workshop,"['Arushi Goel', 'Niveditha Kalavakonda', 'Nour Karessli', 'Tejaswi Kasarla', 'Kathryn Leonard', 'Boyi Li', 'Nermin Samet and', 'Ghada Zamzmi']","In this paper, we present the details of Women in Computer Vision Workshop -
WiCV 2021, organized alongside the virtual CVPR 2021. It provides a voice to a
minority (female) group in the computer vision community and focuses on
increasing the visibility of these researchers, both in academia and industry.
WiCV believes that such an event can play an important role in lowering the
gender imbalance in the field of computer vision. WiCV is organized each year
where it provides a)~opportunity for collaboration between researchers from
minority groups, b)~mentorship to female junior researchers, c)~financial
support to presenters to overcome monetary burden and d)~large and diverse
choice of role models, who can serve as examples to younger researchers at the
beginning of their careers. In this paper, we present a report on the workshop
program, trends over the past years, a summary of statistics regarding
presenters, attendees, and sponsorship for the WiCV 2021 workshop.",2022-03-11T10:03:13Z,http://arxiv.org/pdf/2203.05825v1,['cs.CV']
2208.11388v1,WiCV 2022: The Tenth Women In Computer Vision Workshop,"['Doris Antensteiner', 'Silvia Bucci', 'Arushi Goel', 'Marah Halawa', 'Niveditha Kalavakonda', 'Tejaswi Kasarla', 'Miaomiao Liu', 'Nermin Samet', 'Ivaxi Sheth']","In this paper, we present the details of Women in Computer Vision Workshop -
WiCV 2022, organized alongside the hybrid CVPR 2022 in New Orleans, Louisiana.
It provides a voice to a minority (female) group in the computer vision
community and focuses on increasing the visibility of these researchers, both
in academia and industry. WiCV believes that such an event can play an
important role in lowering the gender imbalance in the field of computer
vision. WiCV is organized each year where it provides a) opportunity for
collaboration between researchers from minority groups, b) mentorship to female
junior researchers, c) financial support to presenters to overcome monetary
burden and d) large and diverse choice of role models, who can serve as
examples to younger researchers at the beginning of their careers. In this
paper, we present a report on the workshop program, trends over the past years,
a summary of statistics regarding presenters, attendees, and sponsorship for
the WiCV 2022 workshop.",2022-08-24T09:12:36Z,http://arxiv.org/pdf/2208.11388v1,['cs.CV']
2304.06009v2,"Literature Review: Computer Vision Applications in Transportation
  Logistics and Warehousing","['Alexander Naumann', 'Felix Hertlein', 'Laura Dörr', 'Steffen Thoma', 'Kai Furmans']","Computer vision applications in transportation logistics and warehousing have
a huge potential for process automation. We present a structured literature
review on research in the field to help leverage this potential. The literature
is categorized w.r.t. the application, i.e. the task it tackles and w.r.t. the
computer vision techniques that are used. Regarding applications, we subdivide
the literature in two areas: Monitoring, i.e. observing and retrieving relevant
information from the environment, and manipulation, where approaches are used
to analyze and interact with the environment. Additionally, we point out
directions for future research and link to recent developments in computer
vision that are suitable for application in logistics. Finally, we present an
overview of existing datasets and industrial solutions. The results of our
analysis are also available online at https://a-nau.github.io/cv-in-logistics.",2023-04-12T17:33:41Z,http://arxiv.org/pdf/2304.06009v2,"['cs.CV', 'cs.LG']"
2002.06028v1,Constrained Dominant sets and Its applications in computer vision,['Alemu Leulseged Tesfaye'],"In this thesis, we present new schemes which leverage a constrained
clustering method to solve several computer vision tasks ranging from image
retrieval, image segmentation and co-segmentation, to person re-identification.
In the last decades clustering methods have played a vital role in computer
vision applications; herein, we focus on the extension, reformulation, and
integration of a well-known graph and game theoretic clustering method known as
Dominant Sets. Thus, we have demonstrated the validity of the proposed methods
with extensive experiments which are conducted on several benchmark datasets.",2020-02-12T20:19:44Z,http://arxiv.org/pdf/2002.06028v1,['cs.CV']
2507.18650v1,Features extraction for image identification using computer vision,"['Venant Niyonkuru', 'Sylla Sekou', 'Jimmy Jackson Sinzinkayo']","This study examines various feature extraction techniques in computer vision,
the primary focus of which is on Vision Transformers (ViTs) and other
approaches such as Generative Adversarial Networks (GANs), deep feature models,
traditional approaches (SIFT, SURF, ORB), and non-contrastive and contrastive
feature models. Emphasizing ViTs, the report summarizes their architecture,
including patch embedding, positional encoding, and multi-head self-attention
mechanisms with which they overperform conventional convolutional neural
networks (CNNs). Experimental results determine the merits and limitations of
both methods and their utilitarian applications in advancing computer vision.",2025-07-22T10:43:52Z,http://arxiv.org/pdf/2507.18650v1,['cs.CV']
1708.07455v2,Review on Computer Vision Techniques in Emergency Situation,"['Laura Lopez-Fuentes', 'Joost van de Weijer', 'Manuel Gonzalez-Hidalgo', 'Harald Skinnemoen', 'Andrew D. Bagdanov']","In emergency situations, actions that save lives and limit the impact of
hazards are crucial. In order to act, situational awareness is needed to decide
what to do. Geolocalized photos and video of the situations as they evolve can
be crucial in better understanding them and making decisions faster. Cameras
are almost everywhere these days, either in terms of smartphones, installed
CCTV cameras, UAVs or others. However, this poses challenges in big data and
information overflow. Moreover, most of the time there are no disasters at any
given location, so humans aiming to detect sudden situations may not be as
alert as needed at any point in time. Consequently, computer vision tools can
be an excellent decision support. The number of emergencies where computer
vision tools has been considered or used is very wide, and there is a great
overlap across related emergency research. Researchers tend to focus on
state-of-the-art systems that cover the same emergency as they are studying,
obviating important research in other fields. In order to unveil this overlap,
the survey is divided along four main axes: the types of emergencies that have
been studied in computer vision, the objective that the algorithms can address,
the type of hardware needed and the algorithms used. Therefore, this review
provides a broad overview of the progress of computer vision covering all sorts
of emergencies.",2017-08-24T15:24:47Z,http://arxiv.org/pdf/1708.07455v2,['cs.CV']
2101.03787v1,WiCV 2020: The Seventh Women In Computer Vision Workshop,"['Hazel Doughty', 'Nour Karessli', 'Kathryn Leonard', 'Boyi Li', 'Carianne Martinez', 'Azadeh Mobasher', 'Arsha Nagrani', 'Srishti Yadav']","In this paper we present the details of Women in Computer Vision Workshop -
WiCV 2020, organized in alongside virtual CVPR 2020. This event aims at
encouraging the women researchers in the field of computer vision. It provides
a voice to a minority (female) group in computer vision community and focuses
on increasingly the visibility of these researchers, both in academia and
industry. WiCV believes that such an event can play an important role in
lowering the gender imbalance in the field of computer vision. WiCV is
organized each year where it provides a.) opportunity for collaboration with
between researchers b.) mentorship to female junior researchers c.) financial
support to presenters to overcome monetary burden and d.) large and diverse
choice of role models, who can serve as examples to younger researchers at the
beginning of their careers. In this paper, we present a report on the workshop
program, trends over the past years, a summary of statistics regarding
presenters, attendees, and sponsorship for the current workshop.",2021-01-11T09:48:29Z,http://arxiv.org/pdf/2101.03787v1,['cs.CV']
2107.03436v1,Tensor Methods in Computer Vision and Deep Learning,"['Yannis Panagakis', 'Jean Kossaifi', 'Grigorios G. Chrysos', 'James Oldfield', 'Mihalis A. Nicolaou', 'Anima Anandkumar', 'Stefanos Zafeiriou']","Tensors, or multidimensional arrays, are data structures that can naturally
represent visual data of multiple dimensions. Inherently able to efficiently
capture structured, latent semantic spaces and high-order interactions, tensors
have a long history of applications in a wide span of computer vision problems.
With the advent of the deep learning paradigm shift in computer vision, tensors
have become even more fundamental. Indeed, essential ingredients in modern deep
learning architectures, such as convolutions and attention mechanisms, can
readily be considered as tensor mappings. In effect, tensor methods are
increasingly finding significant applications in deep learning, including the
design of memory and compute efficient network architectures, improving
robustness to random noise and adversarial attacks, and aiding the theoretical
understanding of deep networks.
  This article provides an in-depth and practical review of tensors and tensor
methods in the context of representation learning and deep learning, with a
particular focus on visual data analysis and computer vision applications.
Concretely, besides fundamental work in tensor-based visual data analysis
methods, we focus on recent developments that have brought on a gradual
increase of tensor methods, especially in deep learning architectures, and
their implications in computer vision applications. To further enable the
newcomer to grasp such concepts quickly, we provide companion Python notebooks,
covering key aspects of the paper and implementing them, step-by-step with
TensorLy.",2021-07-07T18:42:45Z,http://arxiv.org/pdf/2107.03436v1,['cs.CV']
2108.11510v1,Deep Reinforcement Learning in Computer Vision: A Comprehensive Survey,"['Ngan Le', 'Vidhiwar Singh Rathour', 'Kashu Yamazaki', 'Khoa Luu', 'Marios Savvides']","Deep reinforcement learning augments the reinforcement learning framework and
utilizes the powerful representation of deep neural networks. Recent works have
demonstrated the remarkable successes of deep reinforcement learning in various
domains including finance, medicine, healthcare, video games, robotics, and
computer vision. In this work, we provide a detailed review of recent and
state-of-the-art research advances of deep reinforcement learning in computer
vision. We start with comprehending the theories of deep learning,
reinforcement learning, and deep reinforcement learning. We then propose a
categorization of deep reinforcement learning methodologies and discuss their
advantages and limitations. In particular, we divide deep reinforcement
learning into seven main categories according to their applications in computer
vision, i.e. (i)landmark localization (ii) object detection; (iii) object
tracking; (iv) registration on both 2D image and 3D image volumetric data (v)
image segmentation; (vi) videos analysis; and (vii) other applications. Each of
these categories is further analyzed with reinforcement learning techniques,
network design, and performance. Moreover, we provide a comprehensive analysis
of the existing publicly available datasets and examine source code
availability. Finally, we present some open issues and discuss future research
directions on deep reinforcement learning in computer vision",2021-08-25T23:01:48Z,http://arxiv.org/pdf/2108.11510v1,"['cs.CV', 'cs.AI']"
1904.03321v2,Computer Vision Approach to Study Deformation of Materials,"['Chaoyi Zhu', 'Haoren Wang', 'Kevin Kaufmann', 'Kenneth Vecchio']","Characterization of the deformation of materials across different length
scales has continuously attracted enormous attention from the mechanics and
materials communities. In this study, the possibility of utilizing a computer
vision algorithm to extract deformation information of materials has been
explored, which greatly expands the use of computer vision approaches to
studying mechanics of materials and potentially opens new dialogues between the
two communities. The computer vision algorithm is first developed and tested on
computationally deformed images, before evaluating experimentally collected
images on speckle painted samples before and after deformation. Moreover, a
virtual experiment has also shown the feasibility of mapping surface strain of
a sample based on its natural pattern with significantly improved accuracy
compared to DIC result, which provides new opportunities in experimentation and
computer algorithms to study deformation mechanics of materials. Validation
experiments include evaluating the performance of strain mapping using the
computer vision approach in the uniaxial tensile test and three-point bending
test, compared with extensometer reading and digital image correlation
respectively.",2019-04-05T23:51:38Z,http://arxiv.org/pdf/1904.03321v2,"['physics.comp-ph', 'cond-mat.mtrl-sci']"
1904.13307v1,"Survey of Computer Vision and Machine Learning in Gastrointestinal
  Endoscopy",['Anant S. Vemuri'],"This paper attempts to provide the reader a place to begin studying the
application of computer vision and machine learning to gastrointestinal (GI)
endoscopy. They have been classified into 18 categories. It should be be noted
by the reader that this is a review from pre-deep learning era. A lot of deep
learning based applications have not been covered in this thesis.",2019-04-26T12:46:03Z,http://arxiv.org/pdf/1904.13307v1,"['physics.med-ph', 'cs.CV', 'eess.IV']"
2010.06188v1,When Wireless Communications Meet Computer Vision in Beyond 5G,"['Takayuki Nishio', 'Yusuke Koda', 'Jihong Park', 'Mehdi Bennis', 'Klaus Doppler']","This article articulates the emerging paradigm, sitting at the confluence of
computer vision and wireless communication, to enable beyond-5G/6G
mission-critical applications (autonomous/remote-controlled vehicles,
visuo-haptic VR, and other cyber-physical applications). First, drawing on
recent advances in machine learning and the availability of non-RF data,
vision-aided wireless networks are shown to significantly enhance the
reliability of wireless communication without sacrificing spectral efficiency.
In particular, we demonstrate how computer vision enables {look-ahead}
prediction in a millimeter-wave channel blockage scenario, before the blockage
actually happens. From a computer vision perspective, we highlight how radio
frequency (RF) based sensing and imaging are instrumental in robustifying
computer vision applications against occlusion and failure. This is
corroborated via an RF-based image reconstruction use case, showcasing a
receiver-side image failure correction resulting in reduced retransmission and
latency. Taken together, this article sheds light on the much-needed
convergence of RF and non-RF modalities to enable ultra-reliable communication
and truly intelligent 6G networks.",2020-10-13T05:25:35Z,http://arxiv.org/pdf/2010.06188v1,"['cs.CV', 'cs.NI']"
1902.06804v1,Democratisation of Usable Machine Learning in Computer Vision,"['Raymond Bond', 'Ansgar Koene', 'Alan Dix', 'Jennifer Boger', 'Maurice D. Mulvenna', 'Mykola Galushka', 'Bethany Waterhouse Bradley', 'Fiona Browne', 'Hui Wang', 'Alexander Wong']","Many industries are now investing heavily in data science and automation to
replace manual tasks and/or to help with decision making, especially in the
realm of leveraging computer vision to automate many monitoring, inspection,
and surveillance tasks. This has resulted in the emergence of the 'data
scientist' who is conversant in statistical thinking, machine learning (ML),
computer vision, and computer programming. However, as ML becomes more
accessible to the general public and more aspects of ML become automated,
applications leveraging computer vision are increasingly being created by
non-experts with less opportunity for regulatory oversight. This points to the
overall need for more educated responsibility for these lay-users of usable ML
tools in order to mitigate potentially unethical ramifications. In this paper,
we undertake a SWOT analysis to study the strengths, weaknesses, opportunities,
and threats of building usable ML tools for mass adoption for important areas
leveraging ML such as computer vision. The paper proposes a set of data science
literacy criteria for educating and supporting lay-users in the responsible
development and deployment of ML applications.",2019-02-18T21:22:45Z,http://arxiv.org/pdf/1902.06804v1,"['cs.CV', 'cs.AI', 'cs.LG']"
2003.01994v1,The iCub multisensor datasets for robot and computer vision applications,"['Murat Kirtay', 'Ugo Albanese', 'Lorenzo Vannucci', 'Guido Schillaci', 'Cecilia Laschi', 'Egidio Falotico']","This document presents novel datasets, constructed by employing the iCub
robot equipped with an additional depth sensor and color camera. We used the
robot to acquire color and depth information for 210 objects in different
acquisition scenarios. At this end, the results were large scale datasets for
robot and computer vision applications: object representation, object
recognition and classification, and action recognition.",2020-03-04T10:59:29Z,http://arxiv.org/pdf/2003.01994v1,"['cs.RO', 'cs.CV', 'cs.LG']"
2401.16424v2,Computer Vision for Primate Behavior Analysis in the Wild,"['Richard Vogg', 'Timo Lüddecke', 'Jonathan Henrich', 'Sharmita Dey', 'Matthias Nuske', 'Valentin Hassler', 'Derek Murphy', 'Julia Fischer', 'Julia Ostner', 'Oliver Schülke', 'Peter M. Kappeler', 'Claudia Fichtel', 'Alexander Gail', 'Stefan Treue', 'Hansjörg Scherberger', 'Florentin Wörgötter', 'Alexander S. Ecker']","Advances in computer vision as well as increasingly widespread video-based
behavioral monitoring have great potential for transforming how we study animal
cognition and behavior. However, there is still a fairly large gap between the
exciting prospects and what can actually be achieved in practice today,
especially in videos from the wild. With this perspective paper, we want to
contribute towards closing this gap, by guiding behavioral scientists in what
can be expected from current methods and steering computer vision researchers
towards problems that are relevant to advance research in animal behavior. We
start with a survey of the state-of-the-art methods for computer vision
problems that are directly relevant to the video-based study of animal
behavior, including object detection, multi-individual tracking, individual
identification, and (inter)action recognition. We then review methods for
effort-efficient learning, which is one of the biggest challenges from a
practical perspective. Finally, we close with an outlook into the future of the
emerging field of computer vision for animal behavior, where we argue that the
field should develop approaches to unify detection, tracking, identification
and (inter)action recognition in a single, video-based framework.",2024-01-29T18:59:56Z,http://arxiv.org/pdf/2401.16424v2,"['cs.CV', 'q-bio.QM']"
2402.12536v1,Designing High-Performing Networks for Multi-Scale Computer Vision,['Cédric Picron'],"Since the emergence of deep learning, the computer vision field has
flourished with models improving at a rapid pace on more and more complex
tasks. We distinguish three main ways to improve a computer vision model: (1)
improving the data aspect by for example training on a large, more diverse
dataset, (2) improving the training aspect by for example designing a better
optimizer, and (3) improving the network architecture (or network for short).
In this thesis, we chose to improve the latter, i.e. improving the network
designs of computer vision models. More specifically, we investigate new
network designs for multi-scale computer vision tasks, which are tasks
requiring to make predictions about concepts at different scales. The goal of
these new network designs is to outperform existing baseline designs from the
literature. Specific care is taken to make sure the comparisons are fair, by
guaranteeing that the different network designs were trained and evaluated with
the same settings. Code is publicly available at
https://github.com/CedricPicron/DetSeg.",2024-02-19T20:50:55Z,http://arxiv.org/pdf/2402.12536v1,['cs.CV']
2005.03318v1,A Review of Computer Vision Methods in Network Security,"['Jiawei Zhao', 'Rahat Masood', 'Suranga Seneviratne']","Network security has become an area of significant importance more than ever
as highlighted by the eye-opening numbers of data breaches, attacks on critical
infrastructure, and malware/ransomware/cryptojacker attacks that are reported
almost every day. Increasingly, we are relying on networked infrastructure and
with the advent of IoT, billions of devices will be connected to the internet,
providing attackers with more opportunities to exploit. Traditional machine
learning methods have been frequently used in the context of network security.
However, such methods are more based on statistical features extracted from
sources such as binaries, emails, and packet flows.
  On the other hand, recent years witnessed a phenomenal growth in computer
vision mainly driven by the advances in the area of convolutional neural
networks. At a glance, it is not trivial to see how computer vision methods are
related to network security. Nonetheless, there is a significant amount of work
that highlighted how methods from computer vision can be applied in network
security for detecting attacks or building security solutions. In this paper,
we provide a comprehensive survey of such work under three topics; i) phishing
attempt detection, ii) malware detection, and iii) traffic anomaly detection.
Next, we review a set of such commercial products for which public information
is available and explore how computer vision methods are effectively used in
those products. Finally, we discuss existing research gaps and future research
directions, especially focusing on how network security research community and
the industry can leverage the exponential growth of computer vision methods to
build much secure networked systems.",2020-05-07T08:29:11Z,http://arxiv.org/pdf/2005.03318v1,"['cs.NI', 'cs.CR', 'cs.CV']"
1909.08148v1,AdaCompress: Adaptive Compression for Online Computer Vision Services,"['Hongshan Li', 'Yu Guo', 'Zhi Wang', 'Shutao Xia', 'Wenwu Zhu']","With the growth of computer vision based applications and services, an
explosive amount of images have been uploaded to cloud servers which host such
computer vision algorithms, usually in the form of deep learning models. JPEG
has been used as the {\em de facto} compression and encapsulation method before
one uploads the images, due to its wide adaptation. However, standard JPEG
configuration does not always perform well for compressing images that are to
be processed by a deep learning model, e.g., the standard quality level of JPEG
leads to 50\% of size overhead (compared with the best quality level selection)
on ImageNet under the same inference accuracy in popular computer vision models
including InceptionNet, ResNet, etc. Knowing this, designing a better JPEG
configuration for online computer vision services is still extremely
challenging: 1) Cloud-based computer vision models are usually a black box to
end-users; thus it is difficult to design JPEG configuration without knowing
their model structures. 2) JPEG configuration has to change when different
users use it. In this paper, we propose a reinforcement learning based JPEG
configuration framework. In particular, we design an agent that adaptively
chooses the compression level according to the input image's features and
backend deep learning models. Then we train the agent in a reinforcement
learning way to adapt it for different deep learning cloud services that act as
the {\em interactive training environment} and feeding a reward with
comprehensive consideration of accuracy and data size. In our real-world
evaluation on Amazon Rekognition, Face++ and Baidu Vision, our approach can
reduce the size of images by 1/2 -- 1/3 while the overall classification
accuracy only decreases slightly.",2019-09-17T23:45:28Z,http://arxiv.org/pdf/1909.08148v1,"['cs.MM', 'eess.IV']"
2309.13744v3,"A Systematic Literature Review of Computer Vision Applications in
  Robotized Wire Harness Assembly","['Hao Wang', 'Omkar Salunkhe', 'Walter Quadrini', 'Dan Lämkull', 'Fredrik Ore', 'Mélanie Despeisse', 'Luca Fumagalli', 'Johan Stahre', 'Björn Johansson']","This article provides a systematic literature review of computer vision
applications in robotized wire harness assembly.",2023-09-24T20:28:01Z,http://arxiv.org/pdf/2309.13744v3,"['cs.CV', 'cs.AI', 'cs.RO']"
1310.0315v1,Computer Vision Systems in Road Vehicles: A Review,"['Kristian Kovačić', 'Edouard Ivanjko', 'Hrvoje Gold']","The number of road vehicles significantly increased in recent decades. This
trend accompanied a build-up of road infrastructure and development of various
control systems to increase road traffic safety, road capacity and travel
comfort. In traffic safety significant development has been made and today's
systems more and more include cameras and computer vision methods. Cameras are
used as part of the road infrastructure or in vehicles. In this paper a review
on computer vision systems in vehicles from the stand point of traffic
engineering is given. Safety problems of road vehicles are presented, current
state of the art in-vehicle vision systems is described and open problems with
future research directions are discussed.",2013-10-01T14:19:11Z,http://arxiv.org/pdf/1310.0315v1,['cs.CV']
1705.07632v3,"Computer vision-based food calorie estimation: dataset, method, and
  experiment","['Yanchao Liang', 'Jianhua Li']","Computer vision has been introduced to estimate calories from food images.
But current food image data sets don't contain volume and mass records of
foods, which leads to an incomplete calorie estimation. In this paper, we
present a novel food image data set with volume and mass records of foods, and
a deep learning method for food detection, to make a complete calorie
estimation. Our data set includes 2978 images, and every image contains
corresponding each food's annotation, volume and mass records, as well as a
certain calibration reference. To estimate calorie of food in the proposed data
set, a deep learning method using Faster R-CNN first is put forward to detect
the food. And the experiment results show our method is effective to estimate
calories and our data set contains adequate information for calorie estimation.
Our data set is the first released food image data set which can be used to
evaluate computer vision-based calorie estimation methods.",2017-05-22T09:47:29Z,http://arxiv.org/pdf/1705.07632v3,['cs.CV']
1808.08275v1,Binary Image Features Proposed to Empower Computer Vision,"['Soumi Ray', 'Vinod Kumar']","This literature has proposed three fast and easy computable image features to
improve computer vision by offering more human-like vision power. These
features are not based on image pixels absolute or relative intensity; neither
based on shape or colour. So, no complex pixel by pixel calculation is
required. For human eyes, pixel by pixel calculation is like seeing an image
with maximum zoom which is done only when a higher level of details is
required. Normally, first we look at an image to get an overall idea about it
to know whether it deserves further investigation or not. This capacity of
getting an idea at a glance is analysed and three basic features are proposed
to empower computer vision. Potential of proposed features is tested and
established through different medical dataset. Achieved accuracy in
classification demonstrates possibilities and potential of the use of the
proposed features in image processing.",2018-08-14T06:39:58Z,http://arxiv.org/pdf/1808.08275v1,['cs.CV']
1905.00310v1,Towards computer vision powered color-nutrient assessment of pureed food,"['Kaylen J. Pfisterer', 'Robert Amelard', 'Braeden Syrnyk', 'Alexander Wong']","With one in four individuals afflicted with malnutrition, computer vision may
provide a way of introducing a new level of automation in the nutrition field
to reliably monitor food and nutrient intake. In this study, we present a novel
approach to modeling the link between color and vitamin A content using
transmittance imaging of a pureed foods dilution series in a computer vision
powered nutrient sensing system via a fine-tuned deep autoencoder network,
which in this case was trained to predict the relative concentration of sweet
potato purees. Experimental results show the deep autoencoder network can
achieve an accuracy of 80% across beginner (6 month) and intermediate (8 month)
commercially prepared pureed sweet potato samples. Prediction errors may be
explained by fundamental differences in optical properties which are further
discussed.",2019-05-01T13:42:19Z,http://arxiv.org/pdf/1905.00310v1,"['cs.CV', 'cs.NE', 'eess.IV']"
2107.04259v2,Unity Perception: Generate Synthetic Data for Computer Vision,"['Steve Borkman', 'Adam Crespi', 'Saurav Dhakad', 'Sujoy Ganguly', 'Jonathan Hogins', 'You-Cyuan Jhang', 'Mohsen Kamalzadeh', 'Bowen Li', 'Steven Leal', 'Pete Parisi', 'Cesar Romero', 'Wesley Smith', 'Alex Thaman', 'Samuel Warren', 'Nupur Yadav']","We introduce the Unity Perception package which aims to simplify and
accelerate the process of generating synthetic datasets for computer vision
tasks by offering an easy-to-use and highly customizable toolset. This
open-source package extends the Unity Editor and engine components to generate
perfectly annotated examples for several common computer vision tasks.
Additionally, it offers an extensible Randomization framework that lets the
user quickly construct and configure randomized simulation parameters in order
to introduce variation into the generated datasets. We provide an overview of
the provided tools and how they work, and demonstrate the value of the
generated synthetic datasets by training a 2D object detection model. The model
trained with mostly synthetic data outperforms the model trained using only
real data.",2021-07-09T07:09:00Z,http://arxiv.org/pdf/2107.04259v2,['cs.CV']
1211.4907v2,Mahotas: Open source software for scriptable computer vision,['Luis Pedro Coelho'],"Mahotas is a computer vision library for Python. It contains traditional
image processing functionality such as filtering and morphological operations
as well as more modern computer vision functions for feature computation,
including interest point detection and local descriptors.
  The interface is in Python, a dynamic programming language, which is very
appropriate for fast development, but the algorithms are implemented in C++ and
are tuned for speed. The library is designed to fit in with the scientific
software ecosystem in this language and can leverage the existing
infrastructure developed in that language.
  Mahotas is released under a liberal open source license (MIT License) and is
available from (http://github.com/luispedro/mahotas) and from the Python
Package Index (http://pypi.python.org/pypi/mahotas).",2012-11-21T00:51:10Z,http://arxiv.org/pdf/1211.4907v2,"['cs.CV', 'cs.SE']"
1909.13579v1,Meta-learning algorithms for Few-Shot Computer Vision,['Etienne Bennequin'],"Few-Shot Learning is the challenge of training a model with only a small
amount of data. Many solutions to this problem use meta-learning algorithms,
i.e. algorithms that learn to learn. By sampling few-shot tasks from a larger
dataset, we can teach these algorithms to solve new, unseen tasks. This
document reports my work on meta-learning algorithms for Few-Shot Computer
Vision. This work was done during my internship at Sicara, a French company
building image recognition solutions for businesses. It contains: 1. an
extensive review of the state-of-the-art in few-shot computer vision; 2. a
benchmark of meta-learning algorithms for few-shot image classification; 3. the
introduction to a novel meta-learning algorithm for few-shot object detection,
which is still in development.",2019-09-30T10:51:16Z,http://arxiv.org/pdf/1909.13579v1,"['cs.CV', 'cs.LG']"
1910.02190v2,"Kornia: an Open Source Differentiable Computer Vision Library for
  PyTorch","['Edgar Riba', 'Dmytro Mishkin', 'Daniel Ponsa', 'Ethan Rublee', 'Gary Bradski']","This work presents Kornia -- an open source computer vision library which
consists of a set of differentiable routines and modules to solve generic
computer vision problems. The package uses PyTorch as its main backend both for
efficiency and to take advantage of the reverse-mode auto-differentiation to
define and compute the gradient of complex functions. Inspired by OpenCV,
Kornia is composed of a set of modules containing operators that can be
inserted inside neural networks to train models to perform image
transformations, camera calibration, epipolar geometry, and low level image
processing techniques, such as filtering and edge detection that operate
directly on high dimensional tensor representations. Examples of classical
vision problems implemented using our framework are provided including a
benchmark comparing to existing vision libraries.",2019-10-05T01:29:54Z,http://arxiv.org/pdf/1910.02190v2,['cs.CV']
2305.14986v1,Non-adversarial Robustness of Deep Learning Methods for Computer Vision,"['Gorana Gojić', 'Vladimir Vincan', 'Ognjen Kundačina', 'Dragiša Mišković', 'Dinu Dragan']","Non-adversarial robustness, also known as natural robustness, is a property
of deep learning models that enables them to maintain performance even when
faced with distribution shifts caused by natural variations in data. However,
achieving this property is challenging because it is difficult to predict in
advance the types of distribution shifts that may occur. To address this
challenge, researchers have proposed various approaches, some of which
anticipate potential distribution shifts, while others utilize knowledge about
the shifts that have already occurred to enhance model generalizability. In
this paper, we present a brief overview of the most recent techniques for
improving the robustness of computer vision methods, as well as a summary of
commonly used robustness benchmark datasets for evaluating the model's
performance under data distribution shifts. Finally, we examine the strengths
and limitations of the approaches reviewed and identify general trends in deep
learning robustness improvement for computer vision.",2023-05-24T10:21:31Z,http://arxiv.org/pdf/2305.14986v1,"['cs.LG', 'cs.CV']"
1906.07328v2,"Losing Confidence in Quality: Unspoken Evolution of Computer Vision
  Services","['Alex Cummaudo', 'Rajesh Vasa', 'John Grundy', 'Mohamed Abdelrazek', 'Andrew Cain']","Recent advances in artificial intelligence (AI) and machine learning (ML),
such as computer vision, are now available as intelligent services and their
accessibility and simplicity is compelling. Multiple vendors now offer this
technology as cloud services and developers want to leverage these advances to
provide value to end-users. However, there is no firm investigation into the
maintenance and evolution risks arising from use of these intelligent services;
in particular, their behavioural consistency and transparency of their
functionality. We evaluated the responses of three different intelligent
services (specifically computer vision) over 11 months using 3 different data
sets, verifying responses against the respective documentation and assessing
evolution risk. We found that there are: (1) inconsistencies in how these
services behave; (2) evolution risk in the responses; and (3) a lack of clear
communication that documents these risks and inconsistencies. We propose a set
of recommendations to both developers and intelligent service providers to
inform risk and assist maintainability.",2019-06-18T01:11:43Z,http://arxiv.org/pdf/1906.07328v2,"['cs.SE', 'cs.AI']"
2109.11369v4,Recent Advances of Continual Learning in Computer Vision: An Overview,"['Haoxuan Qu', 'Hossein Rahmani', 'Li Xu', 'Bryan Williams', 'Jun Liu']","In contrast to batch learning where all training data is available at once,
continual learning represents a family of methods that accumulate knowledge and
learn continuously with data available in sequential order. Similar to the
human learning process with the ability of learning, fusing, and accumulating
new knowledge coming at different time steps, continual learning is considered
to have high practical significance. Hence, continual learning has been studied
in various artificial intelligence tasks. In this paper, we present a
comprehensive review of the recent progress of continual learning in computer
vision. In particular, the works are grouped by their representative
techniques, including regularization, knowledge distillation, memory,
generative replay, parameter isolation, and a combination of the above
techniques. For each category of these techniques, both its characteristics and
applications in computer vision are presented. At the end of this overview,
several subareas, where continuous knowledge accumulation is potentially
helpful while continual learning has not been well studied, are discussed.",2021-09-23T13:30:18Z,http://arxiv.org/pdf/2109.11369v4,['cs.CV']
2211.13508v2,1st Workshop on Maritime Computer Vision (MaCVi) 2023: Challenge Results,"['Benjamin Kiefer', 'Matej Kristan', 'Janez Perš', 'Lojze Žust', 'Fabio Poiesi', 'Fabio Augusto de Alcantara Andrade', 'Alexandre Bernardino', 'Matthew Dawkins', 'Jenni Raitoharju', 'Yitong Quan', 'Adem Atmaca', 'Timon Höfer', 'Qiming Zhang', 'Yufei Xu', 'Jing Zhang', 'Dacheng Tao', 'Lars Sommer', 'Raphael Spraul', 'Hangyue Zhao', 'Hongpu Zhang', 'Yanyun Zhao', 'Jan Lukas Augustin', 'Eui-ik Jeon', 'Impyeong Lee', 'Luca Zedda', 'Andrea Loddo', 'Cecilia Di Ruberto', 'Sagar Verma', 'Siddharth Gupta', 'Shishir Muralidhara', 'Niharika Hegde', 'Daitao Xing', 'Nikolaos Evangeliou', 'Anthony Tzes', 'Vojtěch Bartl', 'Jakub Špaňhel', 'Adam Herout', 'Neelanjan Bhowmik', 'Toby P. Breckon', 'Shivanand Kundargi', 'Tejas Anvekar', 'Chaitra Desai', 'Ramesh Ashok Tabib', 'Uma Mudengudi', 'Arpita Vats', 'Yang Song', 'Delong Liu', 'Yonglin Li', 'Shuman Li', 'Chenhao Tan', 'Long Lan', 'Vladimir Somers', 'Christophe De Vleeschouwer', 'Alexandre Alahi', 'Hsiang-Wei Huang', 'Cheng-Yen Yang', 'Jenq-Neng Hwang', 'Pyong-Kun Kim', 'Kwangju Kim', 'Kyoungoh Lee', 'Shuai Jiang', 'Haiwen Li', 'Zheng Ziqiang', 'Tuan-Anh Vu', 'Hai Nguyen-Truong', 'Sai-Kit Yeung', 'Zhuang Jia', 'Sophia Yang', 'Chih-Chung Hsu', 'Xiu-Yu Hou', 'Yu-An Jhang', 'Simon Yang', 'Mau-Tsuen Yang']","The 1$^{\text{st}}$ Workshop on Maritime Computer Vision (MaCVi) 2023 focused
on maritime computer vision for Unmanned Aerial Vehicles (UAV) and Unmanned
Surface Vehicle (USV), and organized several subchallenges in this domain: (i)
UAV-based Maritime Object Detection, (ii) UAV-based Maritime Object Tracking,
(iii) USV-based Maritime Obstacle Segmentation and (iv) USV-based Maritime
Obstacle Detection. The subchallenges were based on the SeaDronesSee and MODS
benchmarks. This report summarizes the main findings of the individual
subchallenges and introduces a new benchmark, called SeaDronesSee Object
Detection v2, which extends the previous benchmark by including more classes
and footage. We provide statistical and qualitative analyses, and assess trends
in the best-performing methodologies of over 130 submissions. The methods are
summarized in the appendix. The datasets, evaluation code and the leaderboard
are publicly available at https://seadronessee.cs.uni-tuebingen.de/macvi.",2022-11-24T09:59:13Z,http://arxiv.org/pdf/2211.13508v2,"['cs.CV', 'cs.AI', 'cs.LG', 'cs.RO']"
2303.15919v3,Fully Hyperbolic Convolutional Neural Networks for Computer Vision,"['Ahmad Bdeir', 'Kristian Schwethelm', 'Niels Landwehr']","Real-world visual data exhibit intrinsic hierarchical structures that can be
represented effectively in hyperbolic spaces. Hyperbolic neural networks (HNNs)
are a promising approach for learning feature representations in such spaces.
However, current HNNs in computer vision rely on Euclidean backbones and only
project features to the hyperbolic space in the task heads, limiting their
ability to fully leverage the benefits of hyperbolic geometry. To address this,
we present HCNN, a fully hyperbolic convolutional neural network (CNN) designed
for computer vision tasks. Based on the Lorentz model, we generalize
fundamental components of CNNs and propose novel formulations of the
convolutional layer, batch normalization, and multinomial logistic regression.
{Experiments on standard vision tasks demonstrate the promising performance of
our HCNN framework in both hybrid and fully hyperbolic settings.} Overall, we
believe our contributions provide a foundation for developing more powerful
HNNs that can better represent complex structures found in image data. Our code
is publicly available at https://github.com/kschwethelm/HyperbolicCV.",2023-03-28T12:20:52Z,http://arxiv.org/pdf/2303.15919v3,"['cs.CV', 'cs.LG']"
2311.14762v1,The 2nd Workshop on Maritime Computer Vision (MaCVi) 2024,"['Benjamin Kiefer', 'Lojze Žust', 'Matej Kristan', 'Janez Perš', 'Matija Teršek', 'Arnold Wiliem', 'Martin Messmer', 'Cheng-Yen Yang', 'Hsiang-Wei Huang', 'Zhongyu Jiang', 'Heng-Cheng Kuo', 'Jie Mei', 'Jenq-Neng Hwang', 'Daniel Stadler', 'Lars Sommer', 'Kaer Huang', 'Aiguo Zheng', 'Weitu Chong', 'Kanokphan Lertniphonphan', 'Jun Xie', 'Feng Chen', 'Jian Li', 'Zhepeng Wang', 'Luca Zedda', 'Andrea Loddo', 'Cecilia Di Ruberto', 'Tuan-Anh Vu', 'Hai Nguyen-Truong', 'Tan-Sang Ha', 'Quan-Dung Pham', 'Sai-Kit Yeung', 'Yuan Feng', 'Nguyen Thanh Thien', 'Lixin Tian', 'Sheng-Yao Kuan', 'Yuan-Hao Ho', 'Angel Bueno Rodriguez', 'Borja Carrillo-Perez', 'Alexander Klein', 'Antje Alex', 'Yannik Steiniger', 'Felix Sattler', 'Edgardo Solano-Carrillo', 'Matej Fabijanić', 'Magdalena Šumunec', 'Nadir Kapetanović', 'Andreas Michel', 'Wolfgang Gross', 'Martin Weinmann']","The 2nd Workshop on Maritime Computer Vision (MaCVi) 2024 addresses maritime
computer vision for Unmanned Aerial Vehicles (UAV) and Unmanned Surface
Vehicles (USV). Three challenges categories are considered: (i) UAV-based
Maritime Object Tracking with Re-identification, (ii) USV-based Maritime
Obstacle Segmentation and Detection, (iii) USV-based Maritime Boat Tracking.
The USV-based Maritime Obstacle Segmentation and Detection features three
sub-challenges, including a new embedded challenge addressing efficicent
inference on real-world embedded devices. This report offers a comprehensive
overview of the findings from the challenges. We provide both statistical and
qualitative analyses, evaluating trends from over 195 submissions. All
datasets, evaluation code, and the leaderboard are available to the public at
https://macvi.org/workshop/macvi24.",2023-11-23T21:01:14Z,http://arxiv.org/pdf/2311.14762v1,"['cs.CV', 'cs.AI']"
2403.07153v1,2023 Low-Power Computer Vision Challenge (LPCVC) Summary,"['Leo Chen', 'Benjamin Boardley', 'Ping Hu', 'Yiru Wang', 'Yifan Pu', 'Xin Jin', 'Yongqiang Yao', 'Ruihao Gong', 'Bo Li', 'Gao Huang', 'Xianglong Liu', 'Zifu Wan', 'Xinwang Chen', 'Ning Liu', 'Ziyi Zhang', 'Dongping Liu', 'Ruijie Shan', 'Zhengping Che', 'Fachao Zhang', 'Xiaofeng Mou', 'Jian Tang', 'Maxim Chuprov', 'Ivan Malofeev', 'Alexander Goncharenko', 'Andrey Shcherbin', 'Arseny Yanchenko', 'Sergey Alyamkin', 'Xiao Hu', 'George K. Thiruvathukal', 'Yung Hsiang Lu']","This article describes the 2023 IEEE Low-Power Computer Vision Challenge
(LPCVC). Since 2015, LPCVC has been an international competition devoted to
tackling the challenge of computer vision (CV) on edge devices. Most CV
researchers focus on improving accuracy, at the expense of ever-growing sizes
of machine models. LPCVC balances accuracy with resource requirements. Winners
must achieve high accuracy with short execution time when their CV solutions
run on an embedded device, such as Raspberry PI or Nvidia Jetson Nano. The
vision problem for 2023 LPCVC is segmentation of images acquired by Unmanned
Aerial Vehicles (UAVs, also called drones) after disasters. The 2023 LPCVC
attracted 60 international teams that submitted 676 solutions during the
submission window of one month. This article explains the setup of the
competition and highlights the winners' methods that improve accuracy and
shorten execution time.",2024-03-11T20:51:18Z,http://arxiv.org/pdf/2403.07153v1,['cs.CV']
2404.00936v4,A Comprehensive Review of Knowledge Distillation in Computer Vision,"['Gousia Habib', 'Tausifa jan Saleem', 'Sheikh Musa Kaleem', 'Tufail Rouf', 'Brejesh Lall']","Deep learning techniques have been demonstrated to surpass preceding
cutting-edge machine learning techniques in recent years, with computer vision
being one of the most prominent examples. However, deep learning models suffer
from significant drawbacks when deployed in resource-constrained environments
due to their large model size and high complexity. Knowledge Distillation is
one of the prominent solutions to overcome this challenge. This review paper
examines the current state of research on knowledge distillation, a technique
for compressing complex models into smaller and simpler ones. The paper
provides an overview of the major principles and techniques associated with
knowledge distillation and reviews the applications of knowledge distillation
in the domain of computer vision. The review focuses on the benefits of
knowledge distillation, as well as the problems that must be overcome to
improve its effectiveness.",2024-04-01T05:46:15Z,http://arxiv.org/pdf/2404.00936v4,['cs.CV']
2412.09612v3,Olympus: A Universal Task Router for Computer Vision Tasks,"['Yuanze Lin', 'Yunsheng Li', 'Dongdong Chen', 'Weijian Xu', 'Ronald Clark', 'Philip H. S. Torr']","We introduce Olympus, a new approach that transforms Multimodal Large
Language Models (MLLMs) into a unified framework capable of handling a wide
array of computer vision tasks. Utilizing a controller MLLM, Olympus delegates
over 20 specialized tasks across images, videos, and 3D objects to dedicated
modules. This instruction-based routing enables complex workflows through
chained actions without the need for training heavy generative models. Olympus
easily integrates with existing MLLMs, expanding their capabilities with
comparable performance. Experimental results demonstrate that Olympus achieves
an average routing accuracy of 94.75% across 20 tasks and precision of 91.82%
in chained action scenarios, showcasing its effectiveness as a universal task
router that can solve a diverse range of computer vision tasks. Project page:
http://yuanze-lin.me/Olympus_page/",2024-12-12T18:59:40Z,http://arxiv.org/pdf/2412.09612v3,"['cs.CV', 'cs.AI', 'cs.CL']"
2507.22000v1,Staining and locking computer vision models without retraining,"['Oliver J. Sutton', 'Qinghua Zhou', 'George Leete', 'Alexander N. Gorban', 'Ivan Y. Tyukin']","We introduce new methods of staining and locking computer vision models, to
protect their owners' intellectual property. Staining, also known as
watermarking, embeds secret behaviour into a model which can later be used to
identify it, while locking aims to make a model unusable unless a secret
trigger is inserted into input images. Unlike existing methods, our algorithms
can be used to stain and lock pre-trained models without requiring fine-tuning
or retraining, and come with provable, computable guarantees bounding their
worst-case false positive rates. The stain and lock are implemented by directly
modifying a small number of the model's weights and have minimal impact on the
(unlocked) model's performance. Locked models are unlocked by inserting a small
`trigger patch' into the corner of the input image. We present experimental
results showing the efficacy of our methods and demonstrating their practical
performance on a variety of computer vision models.",2025-07-29T16:47:34Z,http://arxiv.org/pdf/2507.22000v1,"['cs.CV', 'cs.AI', 'cs.LG', '68T07, 68T45, 68W40', 'I.2.10; F.2.0; K.5.1; K.6.5']"
1809.05076v1,Computer Vision-aided Atom Tracking in STEM Imaging,"['Yawei Hui', 'Yaohua Liu']","To address the SMC'17 data challenge -- ""Data mining atomically resolved
images for material properties"", we first used the classic ""blob detection""
algorithms developed in computer vision to identify all atom centers in each
STEM image frame. With the help of nearest neighbor analysis, we then found and
labeled every atom center common to all the STEM frames and tracked their
movements through the given time interval for both Molybdenum or Selenium
atoms.",2018-09-13T17:33:18Z,http://arxiv.org/pdf/1809.05076v1,['cs.CV']
1906.01529v6,"Generative Adversarial Networks in Computer Vision: A Survey and
  Taxonomy","['Zhengwei Wang', 'Qi She', 'Tomas E. Ward']","Generative adversarial networks (GANs) have been extensively studied in the
past few years. Arguably their most significant impact has been in the area of
computer vision where great advances have been made in challenges such as
plausible image generation, image-to-image translation, facial attribute
manipulation and similar domains. Despite the significant successes achieved to
date, applying GANs to real-world problems still poses significant challenges,
three of which we focus on here. These are: (1) the generation of high quality
images, (2) diversity of image generation, and (3) stable training. Focusing on
the degree to which popular GAN technologies have made progress against these
challenges, we provide a detailed review of the state of the art in GAN-related
research in the published scientific literature. We further structure this
review through a convenient taxonomy we have adopted based on variations in GAN
architectures and loss functions. While several reviews for GANs have been
presented to date, none have considered the status of this field based on their
progress towards addressing practical challenges relevant to computer vision.
Accordingly, we review and critically discuss the most popular
architecture-variant, and loss-variant GANs, for tackling these challenges. Our
objective is to provide an overview as well as a critical analysis of the
status of GAN research in terms of relevant progress towards important computer
vision application requirements. As we do this we also discuss the most
compelling applications in computer vision in which GANs have demonstrated
considerable success along with some suggestions for future research
directions. Code related to GAN-variants studied in this work is summarized on
https://github.com/sheqi/GAN_Review.",2019-06-04T15:40:53Z,http://arxiv.org/pdf/1906.01529v6,"['cs.LG', 'cs.CV']"
2105.09137v1,TableZa -- A classical Computer Vision approach to Tabular Extraction,"['Saumya Banthia', 'Anantha Sharma', 'Ravi Mangipudi']","Computer aided Tabular Data Extraction has always been a very challenging and
error prone task because it demands both Spectral and Spatial Sanity of data.
In this paper we discuss an approach for Tabular Data Extraction in the realm
of document comprehension. Given the different kinds of the Tabular formats
that are often found across various documents, we discuss a novel approach
using Computer Vision for extraction of tabular data from images or vector
pdf(s) converted to image(s).",2021-05-19T13:55:33Z,http://arxiv.org/pdf/2105.09137v1,"['cs.CL', 'cs.CV', 'cs.IR', 'I.5.1; I.5.2; I.5.4']"
2211.02208v1,Automated Logging Drone: A Computer Vision Drone Implementation,"['Aaron Yagnik', 'Adrian S. -W. Tam']","In recent years, Artificial Intelligence (AI) and Computer Vision (CV) have
become the pinnacle of technology with new developments seemingly every day.
This technology along with more powerful drone technology have made autonomous
surveillance more sought after. Here an overview of the Automated Logging Drone
(ALD) project is presented along with examples of how this project can be used
with more refining and added features.",2022-11-04T01:36:32Z,http://arxiv.org/pdf/2211.02208v1,['cs.HC']
2302.12185v1,Scaling Up Computer Vision Neural Networks Using Fast Fourier Transform,['Siddharth Agrawal'],"Deep Learning-based Computer Vision field has recently been trying to explore
larger kernels for convolution to effectively scale up Convolutional Neural
Networks. Simultaneously, new paradigm of models such as Vision Transformers
find it difficult to scale up to larger higher resolution images due to their
quadratic complexity in terms of input sequence. In this report, Fast Fourier
Transform is utilised in various ways to provide some solutions to these
issues.",2023-02-02T19:19:10Z,http://arxiv.org/pdf/2302.12185v1,"['cs.CV', 'cs.LG']"
2202.08452v1,PCB Component Detection using Computer Vision for Hardware Assurance,"['Wenwei Zhao', 'Suprith Gurudu', 'Shayan Taheri', 'Shajib Ghosh', 'Mukhil Azhagan Mallaiyan Sathiaseelan', 'Navid Asadizanjani']","Printed Circuit Board (PCB) assurance in the optical domain is a crucial
field of study. Though there are many existing PCB assurance methods using
image processing, computer vision (CV), and machine learning (ML), the PCB
field is complex and increasingly evolving so new techniques are required to
overcome the emerging problems. Existing ML-based methods outperform
traditional CV methods, however they often require more data, have low
explainability, and can be difficult to adapt when a new technology arises. To
overcome these challenges, CV methods can be used in tandem with ML methods. In
particular, human-interpretable CV algorithms such as those that extract color,
shape, and texture features increase PCB assurance explainability. This allows
for incorporation of prior knowledge, which effectively reduce the number of
trainable ML parameters and thus, the amount of data needed to achieve high
accuracy when training or retraining an ML model. Hence, this study explores
the benefits and limitations of a variety of common computer vision-based
features for the task of PCB component detection using semantic data. Results
of this study indicate that color features demonstrate promising performance
for PCB component detection. The purpose of this paper is to facilitate
collaboration between the hardware assurance, computer vision, and machine
learning communities.",2022-02-17T05:46:53Z,http://arxiv.org/pdf/2202.08452v1,['cs.CV']
1709.04411v1,"Exploiting skeletal structure in computer vision annotation with Benders
  decomposition","['Shaofei Wang', 'Konrad Kording', 'Julian Yarkony']","Many annotation problems in computer vision can be phrased as integer linear
programs (ILPs). The use of standard industrial solvers does not to exploit the
underlying structure of such problems eg, the skeleton in pose estimation. The
leveraging of the underlying structure in conjunction with industrial solvers
promises increases in both speed and accuracy. Such structure can be exploited
using Bender's decomposition, a technique from operations research, that solves
complex ILPs or mixed integer linear programs by decomposing them into
sub-problems that communicate via a master problem. The intuition is that
conditioned on a small subset of the variables the solution to the remaining
variables can be computed easily by taking advantage of properties of the ILP
constraint matrix such as block structure. In this paper we apply Benders
decomposition to a typical problem in computer vision where we have many
sub-ILPs (eg, partitioning of detections, body-parts) coupled to a master ILP
(eg, constructing skeletons). Dividing inference problems into a master problem
and sub-problems motivates the development of a plethora of novel models, and
inference approaches for the field of computer vision.",2017-09-13T16:43:07Z,http://arxiv.org/pdf/1709.04411v1,['cs.CV']
2112.03444v2,GPU-Based Homotopy Continuation for Minimal Problems in Computer Vision,"['Chiang-Heng Chien', 'Hongyi Fan', 'Ahmad Abdelfattah', 'Elias Tsigaridas', 'Stanimire Tomov', 'Benjamin Kimia']","Systems of polynomial equations arise frequently in computer vision,
especially in multiview geometry problems. Traditional methods for solving
these systems typically aim to eliminate variables to reach a univariate
polynomial, e.g., a tenth-order polynomial for 5-point pose estimation, using
clever manipulations, or more generally using Grobner basis, resultants, and
elimination templates, leading to successful algorithms for multiview geometry
and other problems. However, these methods do not work when the problem is
complex and when they do, they face efficiency and stability issues. Homotopy
Continuation (HC) can solve more complex problems without the stability issues,
and with guarantees of a global solution, but they are known to be slow. In
this paper we show that HC can be parallelized on a GPU, showing significant
speedups up to 26 times on polynomial benchmarks. We also show that GPU-HC can
be generically applied to a range of computer vision problems, including 4-view
triangulation and trifocal pose estimation with unknown focal length, which
cannot be solved with elimination template but they can be efficiently solved
with HC. GPU-HC opens the door to easy formulation and solution of a range of
computer vision problems.",2021-12-07T01:45:12Z,http://arxiv.org/pdf/2112.03444v2,['cs.CV']
2204.02581v1,"Banana Sub-Family Classification and Quality Prediction using Computer
  Vision","['Narayana Darapaneni', 'Arjun Tanndalam', 'Mohit Gupta', 'Neeta Taneja', 'Prabu Purushothaman', 'Swati Eswar', 'Anwesh Reddy Paduri', 'Thangaselvi Arichandrapandian']","India is the second largest producer of fruits and vegetables in the world,
and one of the largest consumers of fruits like Banana, Papaya and Mangoes
through retail and ecommerce giants like BigBasket, Grofers and Amazon Fresh.
However, adoption of technology in supply chain and retail stores is still low
and there is a great potential to adopt computer-vision based technology for
identification and classification of fruits. We have chosen banana fruit to
build a computer vision based model to carry out the following three use-cases
(a) Identify Banana from a given image (b) Determine sub-family or variety of
Banana (c) Determine the quality of Banana. Successful execution of these
use-cases using computer-vision model would greatly help with overall inventory
management automation, quality control, quick and efficient weighing and
billing which all are manual labor intensive currently. In this work, we
suggest a machine learning pipeline that combines the ideas of CNNs, transfer
learning, and data augmentation towards improving Banana fruit sub family and
quality image classification. We have built a basic CNN and then went on to
tune a MobileNet Banana classification model using a combination of
self-curated and publicly-available dataset of 3064 images. The results show an
overall 93.4% and 100% accuracy for sub-family/variety and for quality test
classifications respectively.",2022-04-06T05:06:51Z,http://arxiv.org/pdf/2204.02581v1,"['cs.CV', 'cs.AI']"
2408.00493v1,Explainable Emotion Decoding for Human and Computer Vision,"['Alessio Borriero', 'Martina Milazzo', 'Matteo Diano', 'Davide Orsenigo', 'Maria Chiara Villa', 'Chiara Di Fazio', 'Marco Tamietto', 'Alan Perotti']","Modern Machine Learning (ML) has significantly advanced various research
fields, but the opaque nature of ML models hinders their adoption in several
domains. Explainable AI (XAI) addresses this challenge by providing additional
information to help users understand the internal decision-making process of ML
models. In the field of neuroscience, enriching a ML model for brain decoding
with attribution-based XAI techniques means being able to highlight which brain
areas correlate with the task at hand, thus offering valuable insights to
domain experts. In this paper, we analyze human and Computer Vision (CV)
systems in parallel, training and explaining two ML models based respectively
on functional Magnetic Resonance Imaging (fMRI) and movie frames. We do so by
leveraging the ""StudyForrest"" dataset, which includes functional Magnetic
Resonance Imaging (fMRI) scans of subjects watching the ""Forrest Gump"" movie,
emotion annotations, and eye-tracking data. For human vision the ML task is to
link fMRI data with emotional annotations, and the explanations highlight the
brain regions strongly correlated with the label. On the other hand, for
computer vision, the input data is movie frames, and the explanations are
pixel-level heatmaps. We cross-analyzed our results, linking human attention
(obtained through eye-tracking) with XAI saliency on CV models and brain region
activations. We show how a parallel analysis of human and computer vision can
provide useful information for both the neuroscience community (allocation
theory) and the ML community (biological plausibility of convolutional models).",2024-08-01T11:53:44Z,http://arxiv.org/pdf/2408.00493v1,"['cs.CV', 'eess.IV', 'q-bio.NC']"
2505.12425v1,Kornia-rs: A Low-Level 3D Computer Vision Library In Rust,"['Edgar Riba', 'Jian Shi', 'Aditya Kumar', 'Andrew Shen', 'Gary Bradski']","We present \textit{kornia-rs}, a high-performance 3D computer vision library
written entirely in native Rust, designed for safety-critical and real-time
applications. Unlike C++-based libraries like OpenCV or wrapper-based solutions
like OpenCV-Rust, \textit{kornia-rs} is built from the ground up to leverage
Rust's ownership model and type system for memory and thread safety.
\textit{kornia-rs} adopts a statically-typed tensor system and a modular set of
crates, providing efficient image I/O, image processing and 3D operations. To
aid cross-platform compatibility, \textit{kornia-rs} offers Python bindings,
enabling seamless and efficient integration with Rust code. Empirical results
show that \textit{kornia-rs} achieves a 3~ 5 times speedup in image
transformation tasks over native Rust alternatives, while offering comparable
performance to C++ wrapper-based libraries. In addition to 2D vision
capabilities, \textit{kornia-rs} addresses a significant gap in the Rust
ecosystem by providing a set of 3D computer vision operators. This paper
presents the architecture and performance characteristics of
\textit{kornia-rs}, demonstrating its effectiveness in real-world computer
vision applications.",2025-05-18T13:50:00Z,http://arxiv.org/pdf/2505.12425v1,['cs.CV']
0110157v1,Some Applications of Algebraic Curves to Computational Vision,"['Michael Fryers', 'Jeremy Yirmeyahu Kaminski', 'Mina Teicher']","We introduce a new formalism and a number of new results in the context of
geometric computational vision. The classical scope of the research in
geometric computer vision is essentially limited to static configurations of
points and lines in $P^3$ . By using some well known material from algebraic
geometry, we open new branches to computational vision. We introduce algebraic
curves embedded in $P^3$ as the building blocks from which the tensor of a
couple of cameras (projections) can be computed. In the process we address
dimensional issues and as a result establish the minimal number of algebraic
curves required for the tensor variety to be discrete as a function of their
degree and genus. We then establish new results on the reconstruction of an
algebraic curves in $P^3$ from multiple projections on projective planes
embedded in $P^3$ . We address three different presentations of the curve: (i)
definition by a set of equations, for which we show that for a generic
configuration, two projections of a curve of degree d defines a curve in $P^3$
with two irreducible components, one of degree d and the other of degree $d(d -
1)$, (ii) the dual presentation in the dual space $P^{3*}$, for which we derive
a lower bound for the number of projections necessary for linear reconstruction
as a function of the degree and the genus, and (iii) the presentation as an
hypersurface of $P^5$, defined by the set of lines in $P^3$ meeting the curve,
for which we also derive lower bounds for the number of projections necessary
for linear reconstruction as a function of the degree (of the curve). Moreover
we show that the latter representation yields a new and efficient algorithm for
dealing with mixed configurations of static and moving points in $P^3$.",2001-10-15T18:37:04Z,http://arxiv.org/pdf/math/0110157v1,"['math.AG', 'cs.IT', 'math.IT']"
2207.00449v3,Dissecting Self-Supervised Learning Methods for Surgical Computer Vision,"['Sanat Ramesh', 'Vinkle Srivastav', 'Deepak Alapatt', 'Tong Yu', 'Aditya Murali', 'Luca Sestini', 'Chinedu Innocent Nwoye', 'Idris Hamoud', 'Saurav Sharma', 'Antoine Fleurentin', 'Georgios Exarchakis', 'Alexandros Karargyris', 'Nicolas Padoy']","The field of surgical computer vision has undergone considerable
breakthroughs in recent years with the rising popularity of deep neural
network-based methods. However, standard fully-supervised approaches for
training such models require vast amounts of annotated data, imposing a
prohibitively high cost; especially in the clinical domain. Self-Supervised
Learning (SSL) methods, which have begun to gain traction in the general
computer vision community, represent a potential solution to these annotation
costs, allowing to learn useful representations from only unlabeled data.
Still, the effectiveness of SSL methods in more complex and impactful domains,
such as medicine and surgery, remains limited and unexplored. In this work, we
address this critical need by investigating four state-of-the-art SSL methods
(MoCo v2, SimCLR, DINO, SwAV) in the context of surgical computer vision. We
present an extensive analysis of the performance of these methods on the
Cholec80 dataset for two fundamental and popular tasks in surgical context
understanding, phase recognition and tool presence detection. We examine their
parameterization, then their behavior with respect to training data quantities
in semi-supervised settings. Correct transfer of these methods to surgery, as
described and conducted in this work, leads to substantial performance gains
over generic uses of SSL - up to 7.4% on phase recognition and 20% on tool
presence detection - as well as state-of-the-art semi-supervised phase
recognition approaches by up to 14%. Further results obtained on a highly
diverse selection of surgical datasets exhibit strong generalization
properties. The code is available at
https://github.com/CAMMA-public/SelfSupSurg.",2022-07-01T14:17:11Z,http://arxiv.org/pdf/2207.00449v3,['cs.CV']
2401.17061v1,"OmniSCV: An Omnidirectional Synthetic Image Generator for Computer
  Vision","['Bruno Berenguel-Baeta', 'Jesus Bermudez-Cameo', 'Jose J. Guerrero']","Omnidirectional and 360{\deg} images are becoming widespread in industry and
in consumer society, causing omnidirectional computer vision to gain attention.
Their wide field of view allows the gathering of a great amount of information
about the environment from only an image. However, the distortion of these
images requires the development of specific algorithms for their treatment and
interpretation. Moreover, a high number of images is essential for the correct
training of computer vision algorithms based on learning. In this paper, we
present a tool for generating datasets of omnidirectional images with semantic
and depth information. These images are synthesized from a set of captures that
are acquired in a realistic virtual environment for Unreal Engine 4 through an
interface plugin. We gather a variety of well-known projection models such as
equirectangular and cylindrical panoramas, different fish-eye lenses,
catadioptric systems, and empiric models. Furthermore, we include in our tool
photorealistic non-central-projection systems as non-central panoramas and
non-central catadioptric systems. As far as we know, this is the first reported
tool for generating photorealistic non-central images in the literature.
Moreover, since the omnidirectional images are made virtually, we provide
pixel-wise information about semantics and depth as well as perfect knowledge
of the calibration parameters of the cameras. This allows the creation of
ground-truth information with pixel precision for training learning algorithms
and testing 3D vision approaches. To validate the proposed tool, different
computer vision algorithms are tested as line extractions from dioptric and
catadioptric central images, 3D Layout recovery and SLAM using equirectangular
panoramas, and 3D reconstruction from non-central panoramas.",2024-01-30T14:40:19Z,http://arxiv.org/pdf/2401.17061v1,['cs.CV']
1305.1916v1,"Computer vision applications for coronagraphic optical alignment and
  image processing","['Dmitry Savransky', 'Sandrine J. Thomas', 'Lisa A. Poyneer', 'Bruce A. Macintosh']","Modern coronagraphic systems require very precise alignment between optical
components and can benefit greatly from automated image processing. We discuss
three techniques commonly employed in the fields of computer vision and image
analysis as applied to the Gemini Planet Imager, a new facility instrument for
the Gemini South Observatory. We describe how feature extraction and clustering
methods can be used to aid in automated system alignment tasks, and also
present a search algorithm for finding regular features in science images used
for calibration and data processing. Along with discussions of each technique,
we present our specific implementation and show results of each one in
operation.",2013-05-08T19:00:54Z,http://arxiv.org/pdf/1305.1916v1,['astro-ph.IM']
2209.15455v1,"Road Network Deterioration Monitoring Using Aerial Images and Computer
  Vision","['Nicolas Parra-A', 'Vladimir Vargas-Calderón', 'Herbert Vinck-Posada', 'Nicanor Vinck']","Road maintenance is an essential process for guaranteeing the quality of
transportation in any city. A crucial step towards effective road maintenance
is the ability to update the inventory of the road network. We present a proof
of concept of a protocol for maintaining said inventory based on the use of
unmanned aerial vehicles to quickly collect images which are processed by a
computer vision program that automatically identifies potholes and their
severity. Our protocol aims to provide information to local governments to
prioritise the road network maintenance budget, and to be able to detect early
stages of road deterioration so as to minimise maintenance expenditure.",2022-09-30T13:05:03Z,http://arxiv.org/pdf/2209.15455v1,"['cs.CV', 'cs.CY']"
1610.02431v1,ResearchDoom and CocoDoom: Learning Computer Vision with Games,"['A. Mahendran', 'H. Bilen', 'J. F. Henriques', 'A. Vedaldi']","In this short note we introduce ResearchDoom, an implementation of the Doom
first-person shooter that can extract detailed metadata from the game. We also
introduce the CocoDoom dataset, a collection of pre-recorded data extracted
from Doom gaming sessions along with annotations in the MS Coco format.
ResearchDoom and CocoDoom can be used to train and evaluate a variety of
computer vision methods such as object recognition, detection and segmentation
at the level of instances and categories, tracking, ego-motion estimation,
monocular depth estimation and scene segmentation. The code and data are
available at http://www.robots.ox.ac.uk/~vgg/research/researchdoom.",2016-10-07T21:35:02Z,http://arxiv.org/pdf/1610.02431v1,['cs.CV']
2106.03805v1,3DB: A Framework for Debugging Computer Vision Models,"['Guillaume Leclerc', 'Hadi Salman', 'Andrew Ilyas', 'Sai Vemprala', 'Logan Engstrom', 'Vibhav Vineet', 'Kai Xiao', 'Pengchuan Zhang', 'Shibani Santurkar', 'Greg Yang', 'Ashish Kapoor', 'Aleksander Madry']","We introduce 3DB: an extendable, unified framework for testing and debugging
vision models using photorealistic simulation. We demonstrate, through a wide
range of use cases, that 3DB allows users to discover vulnerabilities in
computer vision systems and gain insights into how models make decisions. 3DB
captures and generalizes many robustness analyses from prior work, and enables
one to study their interplay. Finally, we find that the insights generated by
the system transfer to the physical world.
  We are releasing 3DB as a library (https://github.com/3db/3db) alongside a
set of example analyses, guides, and documentation: https://3db.github.io/3db/ .",2021-06-07T17:16:12Z,http://arxiv.org/pdf/2106.03805v1,"['cs.CV', 'cs.LG', 'stat.ML']"
2204.08601v1,A Tour of Visualization Techniques for Computer Vision Datasets,"['Bilal Alsallakh', 'Pamela Bhattacharya', 'Vanessa Feng', 'Narine Kokhlikyan', 'Orion Reblitz-Richardson', 'Rahul Rajan', 'David Yan']","We survey a number of data visualization techniques for analyzing Computer
Vision (CV) datasets. These techniques help us understand properties and latent
patterns in such data, by applying dataset-level analysis. We present various
examples of how such analysis helps predict the potential impact of the dataset
properties on CV models and informs appropriate mitigation of their
shortcomings. Finally, we explore avenues for further visualization techniques
of different modalities of CV datasets as well as ones that are tailored to
support specific CV tasks and analysis needs.",2022-04-19T01:04:28Z,http://arxiv.org/pdf/2204.08601v1,"['cs.CV', 'cs.GR']"
2309.11608v1,Dataset Factory: A Toolchain For Generative Computer Vision Datasets,"['Daniel Kharitonov', 'Ryan Turner']","Generative AI workflows heavily rely on data-centric tasks - such as
filtering samples by annotation fields, vector distances, or scores produced by
custom classifiers. At the same time, computer vision datasets are quickly
approaching petabyte volumes, rendering data wrangling difficult. In addition,
the iterative nature of data preparation necessitates robust dataset sharing
and versioning mechanisms, both of which are hard to implement ad-hoc. To solve
these challenges, we propose a ""dataset factory"" approach that separates the
storage and processing of samples from metadata and enables data-centric
operations at scale for machine learning teams and individual researchers.",2023-09-20T19:43:37Z,http://arxiv.org/pdf/2309.11608v1,['cs.AI']
2406.08898v1,Computer Vision Approaches for Automated Bee Counting Application,"['Simon Bilik', 'Ilona Janakova', 'Adam Ligocki', 'Dominik Ficek', 'Karel Horak']","Many application from the bee colony health state monitoring could be
efficiently solved using a computer vision techniques. One of such challenges
is an efficient way for counting the number of incoming and outcoming bees,
which could be used to further analyse many trends, such as the bee colony
health state, blooming periods, or for investigating the effects of
agricultural spraying. In this paper, we compare three methods for the
automated bee counting over two own datasets. The best performing method is
based on the ResNet-50 convolutional neural network classifier, which achieved
accuracy of 87% over the BUT1 dataset and the accuracy of 93% over the BUT2
dataset.",2024-06-13T07:51:08Z,http://arxiv.org/pdf/2406.08898v1,"['cs.CV', 'cs.AI', 'cs.LG']"
1405.4802v2,Use of Computer Vision to Detect Tangles in Tangled Objects,['Paritosh Parmar'],"Untangling of structures like ropes and wires by autonomous robots can be
useful in areas such as personal robotics, industries and electrical wiring &
repairing by robots. This problem can be tackled by using computer vision
system in robot. This paper proposes a computer vision based method for
analyzing visual data acquired from camera for perceiving the overlap of wires,
ropes, hoses i.e. detecting tangles. Information obtained after processing
image according to the proposed method comprises of position of tangles in
tangled object and which wire passes over which wire. This information can then
be used to guide robot to untangle wire/s. Given an image, preprocessing is
done to remove noise. Then edges of wire are detected. After that, the image is
divided into smaller blocks and each block is checked for wire overlap/s and
finding other relevant information. TANGLED-100 dataset was introduced, which
consists of images of tangled linear deformable objects. Method discussed in
here was tested on the TANGLED-100 dataset. Accuracy achieved during
experiments was found to be 74.9%. Robotic simulations were carried out to
demonstrate the use of the proposed method in applications of robot. Proposed
method is a general method that can be used by robots working in different
situations.",2014-05-19T16:51:11Z,http://arxiv.org/pdf/1405.4802v2,['cs.CV']
1604.04024v3,"Towards Automated Melanoma Screening: Proper Computer Vision & Reliable
  Results","['Michel Fornaciali', 'Micael Carvalho', 'Flávia Vasques Bittencourt', 'Sandra Avila', 'Eduardo Valle']","In this paper we survey, analyze and criticize current art on automated
melanoma screening, reimplementing a baseline technique, and proposing two
novel ones. Melanoma, although highly curable when detected early, ends as one
of the most dangerous types of cancer, due to delayed diagnosis and treatment.
Its incidence is soaring, much faster than the number of trained professionals
able to diagnose it. Automated screening appears as an alternative to make the
most of those professionals, focusing their time on the patients at risk while
safely discharging the other patients. However, the potential of automated
melanoma diagnosis is currently unfulfilled, due to the emphasis of current
literature on outdated computer vision models. Even more problematic is the
irreproducibility of current art. We show how streamlined pipelines based upon
current Computer Vision outperform conventional models - a model based on an
advanced bags of words reaches an AUC of 84.6%, and a model based on deep
neural networks reaches 89.3%, while the baseline (a classical bag of words)
stays at 81.2%. We also initiate a dialog to improve reproducibility in our
community",2016-04-14T03:26:28Z,http://arxiv.org/pdf/1604.04024v3,['cs.CV']
1605.09527v2,Biconvex Relaxation for Semidefinite Programming in Computer Vision,"['Sohil Shah', 'Abhay Kumar', 'Carlos Castillo', 'David Jacobs', 'Christoph Studer', 'Tom Goldstein']","Semidefinite programming is an indispensable tool in computer vision, but
general-purpose solvers for semidefinite programs are often too slow and memory
intensive for large-scale problems. We propose a general framework to
approximately solve large-scale semidefinite problems (SDPs) at low complexity.
Our approach, referred to as biconvex relaxation (BCR), transforms a general
SDP into a specific biconvex optimization problem, which can then be solved in
the original, low-dimensional variable space at low complexity. The resulting
biconvex problem is solved using an efficient alternating minimization (AM)
procedure. Since AM has the potential to get stuck in local minima, we propose
a general initialization scheme that enables BCR to start close to a global
optimum - this is key for our algorithm to quickly converge to optimal or
near-optimal solutions. We showcase the efficacy of our approach on three
applications in computer vision, namely segmentation, co-segmentation, and
manifold metric learning. BCR achieves solution quality comparable to
state-of-the-art SDP methods with speedups between 4X and 35X. At the same
time, BCR handles a more general set of SDPs than previous approaches, which
are more specialized.",2016-05-31T08:43:44Z,http://arxiv.org/pdf/1605.09527v2,"['cs.CV', 'cs.NA', 'math.NA', 'math.OC']"
1811.11316v1,Using Computer Vision Techniques for Moving Poster Design,"['Sérgio Rebelo', 'Pedro Martins', 'João Bicker', 'Penousal Machado']","Graphic Design encompasses a wide range of activities from the design of
traditional print media (e.g., books and posters) to site-specific (e.g.,
signage systems) and electronic media (e.g., interfaces). Its practice always
explores the new possibilities of information and communication technologies.
Therefore, interactivity and participation have become key features in the
design process. Even in traditional print media, graphic designers are trying
to enhance user experience and exploring new interaction models. Moving posters
are an example of this. This type of posters combine the specific features of
motion and print worlds in order to produce attractive forms of communication
that explore and exploit the potential of digital screens. In our opinion, the
next step towards the integration of moving posters with the surroundings,
where they operate, is incorporating data from the environment, which also
enables the seamless participation of the audience. As such, the adoption of
computer vision techniques for moving poster design becomes a natural approach.
Following this line of thought, we present a system wherein computer vision
techniques are used to shape a moving poster. Although it is still a work in
progress, the system is already able to sense the surrounding physical
environment and translate the collected data into graphical information. The
data is gathered from the environment in two ways: (1) directly using motion
tracking; and (2) indirectly via contextual ambient data. In this sense, each
user interaction with the system results in a different experience and in a
unique poster design.",2018-11-27T23:59:46Z,http://arxiv.org/pdf/1811.11316v1,['cs.HC']
2004.13060v3,GIMP-ML: Python Plugins for using Computer Vision Models in GIMP,['Kritik Soman'],"This paper introduces GIMP-ML v1.1, a set of Python plugins for the widely
popular GNU Image Manipulation Program (GIMP). It enables the use of recent
advances in computer vision to the conventional image editing pipeline.
Applications from deep learning such as monocular depth estimation, semantic
segmentation, mask generative adversarial networks, image super-resolution,
de-noising, de-hazing, matting, enlightening and coloring have been
incorporated with GIMP through Python-based plugins. Additionally, operations
on images such as k-means based color clustering have also been added. GIMP-ML
relies on standard Python packages such as numpy, pytorch, open-cv, scipy.
Apart from these, several image manipulation techniques using these plugins
have been compiled and demonstrated in the YouTube channel
(https://youtube.com/user/kritiksoman) with the objective of demonstrating the
use-cases for machine learning based image modification. In addition, GIMP-ML
also aims to bring the benefits of using deep learning networks used for
computer vision tasks to routine image processing workflows. The code and
installation procedure for configuring these plugins is available at
https://github.com/kritiksoman/GIMP-ML.",2020-04-27T18:00:37Z,http://arxiv.org/pdf/2004.13060v3,"['cs.CV', '65D19']"
2009.11931v1,A Computer Vision Approach to Combat Lyme Disease,"['Sina Akbarian', 'Tania Cawston', 'Laurent Moreno', 'Samir Patel', 'Vanessa Allen', 'Elham Dolatabadi']","Lyme disease is an infectious disease transmitted to humans by a bite from an
infected Ixodes species (blacklegged ticks). It is one of the fastest growing
vector-borne illness in North America and is expanding its geographic
footprint. Lyme disease treatment is time-sensitive, and can be cured by
administering an antibiotic (prophylaxis) to the patient within 72 hours after
a tick bite by the Ixodes species. However, the laboratory-based identification
of each tick that might carry the bacteria is time-consuming and labour
intensive and cannot meet the maximum turn-around-time of 72 hours for an
effective treatment. Early identification of blacklegged ticks using computer
vision technologies is a potential solution in promptly identifying a tick and
administering prophylaxis within a crucial window period. In this work, we
build an automated detection tool that can differentiate blacklegged ticks from
other ticks species using advanced deep learning and computer vision
approaches. We demonstrate the classification of tick species using Convolution
Neural Network (CNN) models, trained end-to-end from tick images directly.
Advanced knowledge transfer techniques within teacher-student learning
frameworks are adopted to improve the performance of classification of tick
species. Our best CNN model achieves 92% accuracy on test set. The tool can be
integrated with the geography of exposure to determine the risk of Lyme disease
infection and need for prophylaxis treatment.",2020-09-24T20:00:02Z,http://arxiv.org/pdf/2009.11931v1,"['cs.CV', 'cs.LG', 'eess.IV']"
2104.04430v1,Ice Core Science Meets Computer Vision: Challenges and Perspectives,"['P. Bohleber', 'M. Roman', 'C. Barbante', 'S. Vascon', 'K. Siddiqi', 'M. Pelillo']","Polar ice cores play a central role in studies of the earth's climate system
through natural archives. A pressing issue is the analysis of the oldest,
highly thinned ice core sections, where the identification of paleoclimate
signals is particularly challenging. For this, state-of-the-art imaging by
laser-ablation inductively-coupled plasma mass spectrometry (LA-ICP-MS) has the
potential to be revolutionary due to its combination of micron-scale 2D
chemical information with visual features. However, the quantitative study of
record preservation in chemical images raises new questions that call for the
expertise of the computer vision community. To illustrate this new
inter-disciplinary frontier, we describe a selected set of key questions. One
critical task is to assess the paleoclimate significance of single line
profiles along the main core axis, which we show is a scale-dependent problem
for which advanced image analysis methods are critical. Another important issue
is the evaluation of post-depositional layer changes, for which the chemical
images provide rich information. Accordingly, the time is ripe to begin an
intensified exchange among the two scientific communities of computer vision
and ice core science. The collaborative building of a new framework for
investigating high-resolution chemical images with automated image analysis
techniques will also benefit the already wide-spread application of LA-ICP-MS
chemical imaging in the geosciences.",2021-04-09T15:27:44Z,http://arxiv.org/pdf/2104.04430v1,"['cs.CV', 'physics.geo-ph']"
2207.00291v2,A Comparative Study of Graph Matching Algorithms in Computer Vision,"['Stefan Haller', 'Lorenz Feineis', 'Lisa Hutschenreiter', 'Florian Bernard', 'Carsten Rother', 'Dagmar Kainmüller', 'Paul Swoboda', 'Bogdan Savchynskyy']","The graph matching optimization problem is an essential component for many
tasks in computer vision, such as bringing two deformable objects in
correspondence. Naturally, a wide range of applicable algorithms have been
proposed in the last decades. Since a common standard benchmark has not been
developed, their performance claims are often hard to verify as evaluation on
differing problem instances and criteria make the results incomparable. To
address these shortcomings, we present a comparative study of graph matching
algorithms. We create a uniform benchmark where we collect and categorize a
large set of existing and publicly available computer vision graph matching
problems in a common format. At the same time we collect and categorize the
most popular open-source implementations of graph matching algorithms. Their
performance is evaluated in a way that is in line with the best practices for
comparing optimization algorithms. The study is designed to be reproducible and
extensible to serve as a valuable resource in the future.
  Our study provides three notable insights:
  1.) popular problem instances are exactly solvable in substantially less than
1 second and, therefore, are insufficient for future empirical evaluations;
  2.) the most popular baseline methods are highly inferior to the best
available methods;
  3.) despite the NP-hardness of the problem, instances coming from vision
applications are often solvable in a few seconds even for graphs with more than
500 vertices.",2022-07-01T09:37:34Z,http://arxiv.org/pdf/2207.00291v2,"['cs.CV', 'math.OC']"
1904.08298v1,Events-to-Video: Bringing Modern Computer Vision to Event Cameras,"['Henri Rebecq', 'René Ranftl', 'Vladlen Koltun', 'Davide Scaramuzza']","Event cameras are novel sensors that report brightness changes in the form of
asynchronous ""events"" instead of intensity frames. They have significant
advantages over conventional cameras: high temporal resolution, high dynamic
range, and no motion blur. Since the output of event cameras is fundamentally
different from conventional cameras, it is commonly accepted that they require
the development of specialized algorithms to accommodate the particular nature
of events. In this work, we take a different view and propose to apply
existing, mature computer vision techniques to videos reconstructed from event
data. We propose a novel recurrent network to reconstruct videos from a stream
of events, and train it on a large amount of simulated event data. Our
experiments show that our approach surpasses state-of-the-art reconstruction
methods by a large margin (> 20%) in terms of image quality. We further apply
off-the-shelf computer vision algorithms to videos reconstructed from event
data on tasks such as object classification and visual-inertial odometry, and
show that this strategy consistently outperforms algorithms that were
specifically designed for event data. We believe that our approach opens the
door to bringing the outstanding properties of event cameras to an entirely new
range of tasks. A video of the experiments is available at
https://youtu.be/IdYrC4cUO0I",2019-04-17T14:54:49Z,http://arxiv.org/pdf/1904.08298v1,['cs.CV']
1906.01620v3,"Evaluating Scalable Bayesian Deep Learning Methods for Robust Computer
  Vision","['Fredrik K. Gustafsson', 'Martin Danelljan', 'Thomas B. Schön']","While deep neural networks have become the go-to approach in computer vision,
the vast majority of these models fail to properly capture the uncertainty
inherent in their predictions. Estimating this predictive uncertainty can be
crucial, for example in automotive applications. In Bayesian deep learning,
predictive uncertainty is commonly decomposed into the distinct types of
aleatoric and epistemic uncertainty. The former can be estimated by letting a
neural network output the parameters of a certain probability distribution.
Epistemic uncertainty estimation is a more challenging problem, and while
different scalable methods recently have emerged, no extensive comparison has
been performed in a real-world setting. We therefore accept this task and
propose a comprehensive evaluation framework for scalable epistemic uncertainty
estimation methods in deep learning. Our proposed framework is specifically
designed to test the robustness required in real-world computer vision
applications. We also apply this framework to provide the first properly
extensive and conclusive comparison of the two current state-of-the-art
scalable methods: ensembling and MC-dropout. Our comparison demonstrates that
ensembling consistently provides more reliable and practically useful
uncertainty estimates. Code is available at
https://github.com/fregu856/evaluating_bdl.",2019-06-04T17:54:20Z,http://arxiv.org/pdf/1906.01620v3,"['cs.LG', 'cs.CV', 'stat.ML']"
2301.13514v1,Fourier Sensitivity and Regularization of Computer Vision Models,"['Kiran Krishnamachari', 'See-Kiong Ng', 'Chuan-Sheng Foo']","Recent work has empirically shown that deep neural networks latch on to the
Fourier statistics of training data and show increased sensitivity to
Fourier-basis directions in the input. Understanding and modifying this
Fourier-sensitivity of computer vision models may help improve their
robustness. Hence, in this paper we study the frequency sensitivity
characteristics of deep neural networks using a principled approach. We first
propose a basis trick, proving that unitary transformations of the
input-gradient of a function can be used to compute its gradient in the basis
induced by the transformation. Using this result, we propose a general measure
of any differentiable model's Fourier-sensitivity using the unitary
Fourier-transform of its input-gradient. When applied to deep neural networks,
we find that computer vision models are consistently sensitive to particular
frequencies dependent on the dataset, training method and architecture. Based
on this measure, we further propose a Fourier-regularization framework to
modify the Fourier-sensitivities and frequency bias of models. Using our
proposed regularizer-family, we demonstrate that deep neural networks obtain
improved classification accuracy on robustness evaluations.",2023-01-31T10:05:35Z,http://arxiv.org/pdf/2301.13514v1,"['cs.CV', 'cs.AI', 'cs.LG']"
2312.01771v1,IMProv: Inpainting-based Multimodal Prompting for Computer Vision Tasks,"['Jiarui Xu', 'Yossi Gandelsman', 'Amir Bar', 'Jianwei Yang', 'Jianfeng Gao', 'Trevor Darrell', 'Xiaolong Wang']","In-context learning allows adapting a model to new tasks given a task
description at test time. In this paper, we present IMProv - a generative model
that is able to in-context learn visual tasks from multimodal prompts. Given a
textual description of a visual task (e.g. ""Left: input image, Right:
foreground segmentation""), a few input-output visual examples, or both, the
model in-context learns to solve it for a new test input. We train a masked
generative transformer on a new dataset of figures from computer vision papers
and their associated captions, together with a captioned large-scale image-text
dataset. During inference time, we prompt the model with text and/or image task
example(s) and have the model inpaint the corresponding output. We show that
training our model with text conditioning and scaling the dataset size improves
in-context learning for computer vision tasks by over +10\% AP for Foreground
Segmentation, over +5\% gains in AP for Single Object Detection, and almost
20\% lower LPIPS in Colorization. Our empirical results suggest that vision and
language prompts are complementary and it is advantageous to use both to
achieve better in-context learning performance. Project page is available at
https://jerryxu.net/IMProv .",2023-12-04T09:48:29Z,http://arxiv.org/pdf/2312.01771v1,['cs.CV']
2402.09781v1,A Comprehensive Review on Computer Vision Analysis of Aerial Data,"['Vivek Tetarwal', 'Sandeep Kumar']","With the emergence of new technologies in the field of airborne platforms and
imaging sensors, aerial data analysis is becoming very popular, capitalizing on
its advantages over land data. This paper presents a comprehensive review of
the computer vision tasks within the domain of aerial data analysis. While
addressing fundamental aspects such as object detection and tracking, the
primary focus is on pivotal tasks like change detection, object segmentation,
and scene-level analysis. The paper provides the comparison of various hyper
parameters employed across diverse architectures and tasks. A substantial
section is dedicated to an in-depth discussion on libraries, their
categorization, and their relevance to different domain expertise. The paper
encompasses aerial datasets, the architectural nuances adopted, and the
evaluation metrics associated with all the tasks in aerial data analysis.
Applications of computer vision tasks in aerial data across different domains
are explored, with case studies providing further insights. The paper
thoroughly examines the challenges inherent in aerial data analysis, offering
practical solutions. Additionally, unresolved issues of significance are
identified, paving the way for future research directions in the field of
aerial data analysis.",2024-02-15T08:10:09Z,http://arxiv.org/pdf/2402.09781v1,"['cs.CV', 'cs.IT', 'math.IT']"
2407.03755v2,A Computer Vision Approach to Estimate the Localized Sea State,"['Aleksandar Vorkapic', 'Miran Pobar', 'Marina Ivasic-Kos']","This research presents a novel application of computer vision (CV) and deep
learning methods for real-time sea state recognition, aiming to contribute to
improving the operational safety and energy efficiency of seagoing vessels, key
factors in meeting the legislative carbon reduction targets. Our work focuses
on utilizing sea images in operational envelopes captured by a single
stationary camera mounted on the ship bridge. The collected images are used to
train a deep learning model to automatically recognize the state of the sea
based on the Beaufort scale. To recognize the sea state, we used 4
state-of-the-art deep neural networks with different characteristics that
proved useful in various computer vision tasks: Resnet-101, NASNet,
MobileNet_v2, and Transformer ViT-b32. Furthermore, we have defined a unique
large-scale dataset, collected over a broad range of sea conditions from an
ocean-going vessel prepared for machine learning. We used the transfer learning
approach to fine-tune the models on our dataset. The obtained results
demonstrate the potential for this approach to complement traditional methods,
particularly where in-situ measurements are unfeasible or interpolated weather
buoy data is insufficiently accurate. This study sets the groundwork for
further development of sea state classification models to address recognized
gaps in maritime research and enable safer and more efficient maritime
operations.",2024-07-04T09:07:25Z,http://arxiv.org/pdf/2407.03755v2,['cs.CV']
2408.08250v1,"Computer Vision Model Compression Techniques for Embedded Systems: A
  Survey","['Alexandre Lopes', 'Fernando Pereira dos Santos', 'Diulhio de Oliveira', 'Mauricio Schiezaro', 'Helio Pedrini']","Deep neural networks have consistently represented the state of the art in
most computer vision problems. In these scenarios, larger and more complex
models have demonstrated superior performance to smaller architectures,
especially when trained with plenty of representative data. With the recent
adoption of Vision Transformer (ViT) based architectures and advanced
Convolutional Neural Networks (CNNs), the total number of parameters of leading
backbone architectures increased from 62M parameters in 2012 with AlexNet to 7B
parameters in 2024 with AIM-7B. Consequently, deploying such deep architectures
faces challenges in environments with processing and runtime constraints,
particularly in embedded systems. This paper covers the main model compression
techniques applied for computer vision tasks, enabling modern models to be used
in embedded systems. We present the characteristics of compression subareas,
compare different approaches, and discuss how to choose the best technique and
expected variations when analyzing it on various embedded devices. We also
share codes to assist researchers and new practitioners in overcoming initial
implementation challenges for each subarea and present trends for Model
Compression. Case studies for compression models are available at
\href{https://github.com/venturusbr/cv-model-compression}{https://github.com/venturusbr/cv-model-compression}.",2024-08-15T16:41:55Z,http://arxiv.org/pdf/2408.08250v1,['cs.CV']
2411.01001v1,Automated Assessment of Residual Plots with Computer Vision Models,"['Weihao Li', 'Dianne Cook', 'Emi Tanaka', 'Susan VanderPlas', 'Klaus Ackermann']","Plotting the residuals is a recommended procedure to diagnose deviations from
linear model assumptions, such as non-linearity, heteroscedasticity, and
non-normality. The presence of structure in residual plots can be tested using
the lineup protocol to do visual inference. There are a variety of conventional
residual tests, but the lineup protocol, used as a statistical test, performs
better for diagnostic purposes because it is less sensitive and applies more
broadly to different types of departures. However, the lineup protocol relies
on human judgment which limits its scalability. This work presents a solution
by providing a computer vision model to automate the assessment of residual
plots. It is trained to predict a distance measure that quantifies the
disparity between the residual distribution of a fitted classical normal linear
regression model and the reference distribution, based on Kullback-Leibler
divergence. From extensive simulation studies, the computer vision model
exhibits lower sensitivity than conventional tests but higher sensitivity than
human visual tests. It is slightly less effective on non-linearity patterns.
Several examples from classical papers and contemporary data illustrate the new
procedures, highlighting its usefulness in automating the diagnostic process
and supplementing existing methods.",2024-11-01T19:51:44Z,http://arxiv.org/pdf/2411.01001v1,"['stat.ML', 'cs.CV', 'cs.LG']"
2501.15119v2,Leveraging Motion Estimation for Efficient Bayer-Domain Computer Vision,"['Haichao Wang', 'Xinyue Xi', 'Jiangtao Wen', 'Yuxing Han']","Existing computer vision processing pipeline acquires visual information
using an image sensor that captures pixel information in the Bayer pattern. The
raw sensor data are then processed using an image signal processor (ISP) that
first converts Bayer pixel data to RGB on a pixel by pixel basis, followed by
video convolutional network (VCN) processing on a frame by frame basis. Both
ISP and VCN are computationally expensive with high power consumption and
latency. In this paper, we propose a novel framework that eliminates the ISP
and leverages motion estimation to accelerate video vision tasks directly in
the Bayer domain. We introduce Motion Estimation-based Video Convolution
(MEVC), which integrates sliding-window motion estimation into each
convolutional layer, enabling prediction and residual-based refinement that
reduces redundant computations across frames. This design bridges the
structural gap between block-based motion estimation and spatial convolution,
enabling accurate, low-cost processing. Our end-to-end pipeline supports raw
Bayer input and achieves over 70\% reduction in FLOPs with minimal accuracy
degradation across video semantic segmentation, depth estimation, and object
detection benchmarks, using both synthetic Bayer-converted and real Bayer video
datasets. This framework generalizes across convolution-based models and marks
the first effective reuse of motion estimation for accelerating video computer
vision directly from raw sensor data.",2025-01-25T08:09:54Z,http://arxiv.org/pdf/2501.15119v2,"['cs.CV', 'eess.IV']"
2504.04242v2,Task-based Loss Functions in Computer Vision: A Comprehensive Review,"['Omar Elharrouss', 'Yasir Mahmood', 'Yassine Bechqito', 'Mohamed Adel Serhani', 'Elarbi Badidi', 'Jamal Riffi', 'Hamid Tairi']","Loss functions are at the heart of deep learning, shaping how models learn
and perform across diverse tasks. They are used to quantify the difference
between predicted outputs and ground truth labels, guiding the optimization
process to minimize errors. Selecting the right loss function is critical, as
it directly impacts model convergence, generalization, and overall performance
across various applications, from computer vision to time series forecasting.
This paper presents a comprehensive review of loss functions, covering
fundamental metrics like Mean Squared Error and Cross-Entropy to advanced
functions such as Adversarial and Diffusion losses. We explore their
mathematical foundations, impact on model training, and strategic selection for
various applications, including computer vision (Discriminative and
generative), tabular data prediction, and time series forecasting. For each of
these categories, we discuss the most used loss functions in the recent
advancements of deep learning techniques. Also, this review explore the
historical evolution, computational efficiency, and ongoing challenges in loss
function design, underlining the need for more adaptive and robust solutions.
Emphasis is placed on complex scenarios involving multi-modal data, class
imbalances, and real-world constraints. Finally, we identify key future
directions, advocating for loss functions that enhance interpretability,
scalability, and generalization, leading to more effective and resilient deep
learning models.",2025-04-05T18:07:20Z,http://arxiv.org/pdf/2504.04242v2,"['cs.LG', 'cs.CV']"
2506.19939v1,"Computer Vision based Automated Quantification of Agricultural Sprayers
  Boom Displacement","['Aryan Singh Dalal', 'Sidharth Rai', 'Rahul Singh', 'Treman Singh Kaloya', 'Rahul Harsha Cheppally', 'Ajay Sharda']","Application rate errors when using self-propelled agricultural sprayers for
agricultural production remain a concern. Among other factors, spray boom
instability is one of the major contributors to application errors. Spray
booms' width of 38m, combined with 30 kph driving speeds, varying terrain, and
machine dynamics when maneuvering complex field boundaries, make controls of
these booms very complex. However, there is no quantitative knowledge on the
extent of boom movement to systematically develop a solution that might include
boom designs and responsive boom control systems. Therefore, this study was
conducted to develop an automated computer vision system to quantify the boom
movement of various agricultural sprayers. A computer vision system was
developed to track a target on the edge of the sprayer boom in real time. YOLO
V7, V8, and V11 neural network models were trained to track the boom's
movements in field operations to quantify effective displacement in the
vertical and transverse directions. An inclinometer sensor was mounted on the
boom to capture boom angles and validate the neural network model output. The
results showed that the model could detect the target with more than 90 percent
accuracy, and distance estimates of the target on the boom were within 0.026 m
of the inclinometer sensor data. This system can quantify the boom movement on
the current sprayer and potentially on any other sprayer with minor
modifications. The data can be used to make design improvements to make sprayer
booms more stable and achieve greater application accuracy.",2025-06-24T18:30:18Z,http://arxiv.org/pdf/2506.19939v1,['cs.CV']
2508.12802v1,"Morphological classification of eclipsing binary stars using computer
  vision methods","['Štefan Parimucha', 'Maksim Gabdeev', 'Yanna Markus', 'Martin Vaňko', 'Pavol Gajdoš']","We present an application of computer vision methods to classify the light
curves of eclipsing binaries (EB). We have used pre-trained models based on
convolutional neural networks ($\textit{ResNet50}$) and vision transformers
($\textit{vit\_base\_patch16\_224}$), which were fine-tuned on images created
from synthetic datasets. To improve model generalisation and reduce
overfitting, we developed a novel image representation by transforming
phase-folded light curves into polar coordinates combined with hexbin
visualisation. Our hierarchical approach in the first stage classifies systems
into detached and overcontact types, and in the second stage identifies the
presence or absence of spots. The binary classification models achieved high
accuracy ($>96\%$) on validation data across multiple passbands (Gaia~$G$, $I$,
and $TESS$) and demonstrated strong performance ($>94\%$, up to $100\%$ for
$TESS$) when tested on extensive observational data from the OGLE, DEBCat, and
WUMaCat catalogues. While the primary binary classification was highly
successful, the secondary task of automated spot detection performed poorly,
revealing a significant limitation of our models for identifying subtle
photometric features. This study highlights the potential of computer vision
for EB morphological classification in large-scale surveys, but underscores the
need for further research into robust, automated spot detection.",2025-08-18T10:29:19Z,http://arxiv.org/pdf/2508.12802v1,"['cs.CV', 'astro-ph.IM', 'astro-ph.SR', 'I.5.1; J.2']"
2508.17975v1,Enhanced Drift-Aware Computer Vision Architecture for Autonomous Driving,"['Md Shahi Amran Hossain', 'Abu Shad Ahammed', 'Sayeri Mukherjee', 'Roman Obermaisser']","The use of computer vision in automotive is a trending research in which
safety and security are a primary concern. In particular, for autonomous
driving, preventing road accidents requires highly accurate object detection
under diverse conditions. To address this issue, recently the International
Organization for Standardization (ISO) released the 8800 norm, providing
structured frameworks for managing associated AI relevant risks. However,
challenging scenarios such as adverse weather or low lighting often introduce
data drift, leading to degraded model performance and potential safety
violations. In this work, we present a novel hybrid computer vision
architecture trained with thousands of synthetic image data from the road
environment to improve robustness in unseen drifted environments. Our dual mode
framework utilized YOLO version 8 for swift detection and incorporated a
five-layer CNN for verification. The system functioned in sequence and improved
the detection accuracy by more than 90\% when tested with drift-augmented road
images. The focus was to demonstrate how such a hybrid model can provide better
road safety when working together in a hybrid structure.",2025-08-25T12:43:29Z,http://arxiv.org/pdf/2508.17975v1,"['cs.CV', 'math.LO']"
2509.07504v1,Backdoor Attacks and Defenses in Computer Vision Domain: A Survey,"['Bilal Hussain Abbasi', 'Yanjun Zhang', 'Leo Zhang', 'Shang Gao']","Backdoor (trojan) attacks embed hidden, controllable behaviors into
machine-learning models so that models behave normally on benign inputs but
produce attacker-chosen outputs when a trigger is present. This survey reviews
the rapidly growing literature on backdoor attacks and defenses in the
computer-vision domain. We introduce a multi-dimensional taxonomy that
organizes attacks and defenses by injection stage (dataset poisoning,
model/parameter modification, inference-time injection), trigger type (patch,
blended/frequency, semantic, transformation), labeling strategy (dirty-label
vs. clean-label / feature-collision), representation stage (instance-specific,
manifold/class-level, neuron/parameter hijacking, distributed encodings), and
target task (classification, detection, segmentation, video, multimodal). For
each axis we summarize representative methods, highlight evaluation practices,
and discuss where defenses succeed or fail. For example, many classical
sanitization and reverse-engineering tools are effective against reusable patch
attacks but struggle with input-aware, sample-specific, or parameter-space
backdoors and with transfer via compromised pre-trained encoders or hardware
bit-flips. We synthesize trends, identify persistent gaps (supply-chain and
hardware threats, certifiable defenses, cross-task benchmarks), and propose
practical guidelines for threat-aware evaluation and layered defenses. This
survey aims to orient researchers and practitioners to the current threat
landscape and pressing research directions in secure computer vision.",2025-09-09T08:38:05Z,http://arxiv.org/pdf/2509.07504v1,['cs.CR']
1407.5675v3,Jet-Images: Computer Vision Inspired Techniques for Jet Tagging,"['Josh Cogan', 'Michael Kagan', 'Emanuel Strauss', 'Ariel Schwartzman']","We introduce a novel approach to jet tagging and classification through the
use of techniques inspired by computer vision. Drawing parallels to the problem
of facial recognition in images, we define a jet-image using calorimeter towers
as the elements of the image and establish jet-image preprocessing methods. For
the jet-image processing step, we develop a discriminant for classifying the
jet-images derived using Fisher discriminant analysis. The effectiveness of the
technique is shown within the context of identifying boosted hadronic W boson
decays with respect to a background of quark- and gluon- initiated jets. Using
Monte Carlo simulation, we demonstrate that the performance of this technique
introduces additional discriminating power over other substructure approaches,
and gives significant insight into the internal structure of jets.",2014-07-21T22:07:37Z,http://arxiv.org/pdf/1407.5675v3,"['hep-ph', 'hep-ex', 'physics.data-an']"
1611.09942v2,Photographic home styles in Congress: a computer vision approach,"['L. Jason Anastasopoulos', 'Dhruvil Badani', 'Crystal Lee', 'Shiry Ginosar', 'Jake Williams']","While members of Congress now routinely communicate with constituents using
images on a variety of internet platforms, little is known about how images are
used as a means of strategic political communication. This is due primarily to
computational limitations which have prevented large-scale, systematic analyses
of image features. New developments in computer vision, however, are bringing
the systematic study of images within reach. Here, we develop a framework for
understanding visual political communication by extending Fenno's analysis of
home style (Fenno 1978) to images and introduce ""photographic"" home styles.
Using approximately 192,000 photographs collected from MCs Facebook profiles,
we build machine learning software with convolutional neural networks and
conduct an image manipulation experiment to explore how the race of people that
MCs pose with shape photographic home styles. We find evidence that electoral
pressures shape photographic home styles and demonstrate that Democratic and
Republican members of Congress use images in very different ways.",2016-11-29T23:41:00Z,http://arxiv.org/pdf/1611.09942v2,"['cs.SI', 'cs.CV']"
1708.05869v2,Sim4CV: A Photo-Realistic Simulator for Computer Vision Applications,"['Matthias Müller', 'Vincent Casser', 'Jean Lahoud', 'Neil Smith', 'Bernard Ghanem']","We present a photo-realistic training and evaluation simulator (Sim4CV) with
extensive applications across various fields of computer vision. Built on top
of the Unreal Engine, the simulator integrates full featured physics based
cars, unmanned aerial vehicles (UAVs), and animated human actors in diverse
urban and suburban 3D environments. We demonstrate the versatility of the
simulator with two case studies: autonomous UAV-based tracking of moving
objects and autonomous driving using supervised learning. The simulator fully
integrates both several state-of-the-art tracking algorithms with a benchmark
evaluation tool and a deep neural network (DNN) architecture for training
vehicles to drive autonomously. It generates synthetic photo-realistic datasets
with automatic ground truth annotations to easily extend existing real-world
datasets and provides extensive synthetic data variety through its ability to
reconfigure synthetic worlds on the fly using an automatic world generation
tool. The supplementary video can be viewed a https://youtu.be/SqAxzsQ7qUU",2017-08-19T16:09:06Z,http://arxiv.org/pdf/1708.05869v2,['cs.CV']
1803.04493v2,Particle Identification In Camera Image Sensors Using Computer Vision,"['Miles Winter', 'James Bourbeau', 'Silvia Bravo', 'Felipe Campos', 'Matthew Meehan', 'Jeffrey Peacock', 'Tyler Ruggles', 'Cassidy Schneider', 'Ariel Levi Simons', 'Justin Vandenbroucke']","We present a deep learning, computer vision algorithm constructed for the
purposes of identifying and classifying charged particles in camera image
sensors. We apply our algorithm to data collected by the Distributed Electronic
Cosmic-ray Observatory (DECO), a global network of smartphones that monitors
camera image sensors for the signatures of cosmic rays and other energetic
particles, such as those produced by radioactive decays. The algorithm, whose
core component is a convolutional neural network, achieves classification
performance comparable to human quality across four distinct DECO event
topologies. We apply our model to the entire DECO data set and determine a
selection that achieves $\ge90\%$ purity for all event types. In particular, we
estimate a purity of $95\%$ when applied to cosmic-ray muons. The automated
classification is run on the public DECO data set in real time in order to
provide classified particle interaction images to users of the app and other
interested members of the public.",2018-03-12T19:49:18Z,http://arxiv.org/pdf/1803.04493v2,"['astro-ph.IM', 'physics.data-an']"
1803.06312v2,EVA$^2$: Exploiting Temporal Redundancy in Live Computer Vision,"['Mark Buckler', 'Philip Bedoukian', 'Suren Jayasuriya', 'Adrian Sampson']","Hardware support for deep convolutional neural networks (CNNs) is critical to
advanced computer vision in mobile and embedded devices. Current designs,
however, accelerate generic CNNs; they do not exploit the unique
characteristics of real-time vision. We propose to use the temporal redundancy
in natural video to avoid unnecessary computation on most frames. A new
algorithm, activation motion compensation, detects changes in the visual input
and incrementally updates a previously-computed output. The technique takes
inspiration from video compression and applies well-known motion estimation
techniques to adapt to visual changes. We use an adaptive key frame rate to
control the trade-off between efficiency and vision quality as the input
changes. We implement the technique in hardware as an extension to existing
state-of-the-art CNN accelerator designs. The new unit reduces the average
energy per frame by 54.2%, 61.7%, and 87.6% for three CNNs with less than 1%
loss in vision accuracy.",2018-03-16T16:59:47Z,http://arxiv.org/pdf/1803.06312v2,"['cs.CV', 'eess.IV']"
1804.03928v1,Deep Learning For Computer Vision Tasks: A review,"['Rajat Kumar Sinha', 'Ruchi Pandey', 'Rohan Pattnaik']","Deep learning has recently become one of the most popular sub-fields of
machine learning owing to its distributed data representation with multiple
levels of abstraction. A diverse range of deep learning algorithms are being
employed to solve conventional artificial intelligence problems. This paper
gives an overview of some of the most widely used deep learning algorithms
applied in the field of computer vision. It first inspects the various
approaches of deep learning algorithms, followed by a description of their
applications in image classification, object identification, image extraction
and semantic segmentation in the presence of noise. The paper concludes with
the discussion of the future scope and challenges for construction and training
of deep neural networks.",2018-04-11T11:13:35Z,http://arxiv.org/pdf/1804.03928v1,['cs.CV']
1811.10847v1,Algae Detection Using Computer Vision and Deep Learning,"['Arabinda Samantaray', 'Baijian Yang', 'J. Eric Dietz', 'Byung-Cheol Min']","A disconcerting ramification of water pollution caused by burgeoning
populations, rapid industrialization and modernization of agriculture, has been
the exponential increase in the incidence of algal growth across the globe.
Harmful algal blooms (HABs) have devastated fisheries, contaminated drinking
water and killed livestock, resulting in economic losses to the tune of
millions of dollars. Therefore, it is important to constantly monitor water
bodies and identify any algae build-up so that prompt action against its
accumulation can be taken and the harmful consequences can be avoided. In this
paper, we propose a computer vision system based on deep learning for algae
monitoring. The proposed system is fast, accurate and cheap, and it can be
installed on any robotic platforms such as USVs and UAVs for autonomous algae
monitoring. The experimental results demonstrate that the proposed system can
detect algae in distinct environments regardless of the underlying hardware
with high accuracy and in real time.",2018-11-27T07:31:26Z,http://arxiv.org/pdf/1811.10847v1,"['cs.CV', 'cs.LG', 'cs.RO']"
2101.09744v3,"Classic versus deep learning approaches to address computer vision
  challenges","['Nati Ofir', 'Jean-Christophe Nebel']","Computer vision and image processing address many challenging applications.
While the last decade has seen deep neural network architectures
revolutionizing those fields, early methods relied on 'classic', i.e.,
non-learned approaches. In this study, we explore the differences between
classic and deep learning (DL) algorithms to gain new insight regarding which
is more suitable for a given application. The focus is on two challenging
ill-posed problems, namely faint edge detection and multispectral image
registration, studying recent state-of-the-art DL and classic solutions. While
those DL algorithms outperform classic methods in terms of accuracy and
development time, they tend to have higher resource requirements and are unable
to perform outside their training space. Moreover, classic algorithms are more
transparent, which facilitates their adoption for real-life applications. As
both classes of approaches have unique strengths and limitations, the choice of
a solution is clearly application dependent.",2021-01-24T16:27:23Z,http://arxiv.org/pdf/2101.09744v3,['cs.CV']
2108.13465v2,Full-Cycle Energy Consumption Benchmark for Low-Carbon Computer Vision,"['Bo Li', 'Xinyang Jiang', 'Donglin Bai', 'Yuge Zhang', 'Ningxin Zheng', 'Xuanyi Dong', 'Lu Liu', 'Yuqing Yang', 'Dongsheng Li']","The energy consumption of deep learning models is increasing at a
breathtaking rate, which raises concerns due to potential negative effects on
carbon neutrality in the context of global warming and climate change. With the
progress of efficient deep learning techniques, e.g., model compression,
researchers can obtain efficient models with fewer parameters and smaller
latency. However, most of the existing efficient deep learning methods do not
explicitly consider energy consumption as a key performance indicator.
Furthermore, existing methods mostly focus on the inference costs of the
resulting efficient models, but neglect the notable energy consumption
throughout the entire life cycle of the algorithm. In this paper, we present
the first large-scale energy consumption benchmark for efficient computer
vision models, where a new metric is proposed to explicitly evaluate the
full-cycle energy consumption under different model usage intensity. The
benchmark can provide insights for low carbon emission when selecting efficient
deep learning algorithms in different model usage scenarios.",2021-08-30T18:22:36Z,http://arxiv.org/pdf/2108.13465v2,"['cs.CV', 'cs.LG']"
2104.08885v1,A survey of image labelling for computer vision applications,"['Christoph Sager', 'Christian Janiesch', 'Patrick Zschech']","Supervised machine learning methods for image analysis require large amounts
of labelled training data to solve computer vision problems. The recent rise of
deep learning algorithms for recognising image content has led to the emergence
of many ad-hoc labelling tools. With this survey, we capture and systematise
the commonalities as well as the distinctions between existing image labelling
software. We perform a structured literature review to compile the underlying
concepts and features of image labelling software such as annotation
expressiveness and degree of automation. We structure the manual labelling task
by its organisation of work, user interface design options, and user support
techniques to derive a systematisation schema for this survey. Applying it to
available software and the body of literature, enabled us to uncover several
application archetypes and key domains such as image retrieval or instance
identification in healthcare or television.",2021-04-18T16:01:55Z,http://arxiv.org/pdf/2104.08885v1,"['cs.CV', 'cs.HC', 'cs.LG']"
2202.07242v1,Neural Architecture Search for Dense Prediction Tasks in Computer Vision,"['Thomas Elsken', 'Arber Zela', 'Jan Hendrik Metzen', 'Benedikt Staffler', 'Thomas Brox', 'Abhinav Valada', 'Frank Hutter']","The success of deep learning in recent years has lead to a rising demand for
neural network architecture engineering. As a consequence, neural architecture
search (NAS), which aims at automatically designing neural network
architectures in a data-driven manner rather than manually, has evolved as a
popular field of research. With the advent of weight sharing strategies across
architectures, NAS has become applicable to a much wider range of problems. In
particular, there are now many publications for dense prediction tasks in
computer vision that require pixel-level predictions, such as semantic
segmentation or object detection. These tasks come with novel challenges, such
as higher memory footprints due to high-resolution data, learning multi-scale
representations, longer training times, and more complex and larger neural
architectures. In this manuscript, we provide an overview of NAS for dense
prediction tasks by elaborating on these novel challenges and surveying ways to
address them to ease future research and application of existing methods to
novel problems.",2022-02-15T08:06:50Z,http://arxiv.org/pdf/2202.07242v1,"['cs.CV', 'cs.LG']"
2207.07428v1,"Automatic detection of equiaxed dendrites using computer vision neural
  networks","['A. Viardin', 'K. Noth', 'M. Torabi Rad', 'L. Sturz']","Equaixed dendrites are frequently encountered in solidification. They
typically form in large numbers, which makes their detection, localization, and
tracking practically impossible for a human eye. In this paper, we show how
recent progress in the field of machine learning can be leveraged to tackle
this problem and we present computer vision neural network to automatically
detect equiaxed dendrites. Our network is trained using phase-field simulation
results, and proper data augmentation allows to perform the detection task in
solidification conditions entirely different from those simulated for training.
For example, here we show how they can successfully detect dendrites of various
sizes in a microgravity solidification experiment. We discuss challenges in
training such a network along with our solutions for them, and compare the
performance of neural network with traditional methods of shapes detection.",2022-07-15T12:12:47Z,http://arxiv.org/pdf/2207.07428v1,['cond-mat.mtrl-sci']
1907.10915v3,Self-supervised Domain Adaptation for Computer Vision Tasks,"['Jiaolong Xu', 'Liang Xiao', 'Antonio M. Lopez']","Recent progress of self-supervised visual representation learning has
achieved remarkable success on many challenging computer vision benchmarks.
However, whether these techniques can be used for domain adaptation has not
been explored. In this work, we propose a generic method for self-supervised
domain adaptation, using object recognition and semantic segmentation of urban
scenes as use cases. Focusing on simple pretext/auxiliary tasks (e.g. image
rotation prediction), we assess different learning strategies to improve domain
adaptation effectiveness by self-supervision. Additionally, we propose two
complementary strategies to further boost the domain adaptation accuracy on
semantic segmentation within our method, consisting of prediction layer
alignment and batch normalization calibration. The experimental results show
adaptation levels comparable to most studied domain adaptation methods, thus,
bringing self-supervision as a new alternative for reaching domain adaptation.
The code is available at https://github.com/Jiaolong/self-supervised-da.",2019-07-25T09:20:29Z,http://arxiv.org/pdf/1907.10915v3,"['cs.CV', 'cs.LG']"
1911.10037v1,Computer Vision-based Accident Detection in Traffic Surveillance,"['Earnest Paul Ijjina', 'Dhananjai Chand', 'Savyasachi Gupta', 'Goutham K']","Computer vision-based accident detection through video surveillance has
become a beneficial but daunting task. In this paper, a neoteric framework for
detection of road accidents is proposed. The proposed framework capitalizes on
Mask R-CNN for accurate object detection followed by an efficient centroid
based object tracking algorithm for surveillance footage. The probability of an
accident is determined based on speed and trajectory anomalies in a vehicle
after an overlap with other vehicles. The proposed framework provides a robust
method to achieve a high Detection Rate and a low False Alarm Rate on general
road-traffic CCTV surveillance footage. This framework was evaluated on diverse
conditions such as broad daylight, low visibility, rain, hail, and snow using
the proposed dataset. This framework was found effective and paves the way to
the development of general-purpose vehicular accident detection algorithms in
real-time.",2019-11-22T13:38:06Z,http://arxiv.org/pdf/1911.10037v1,['cs.CV']
2010.13714v1,ActiveNet: A computer-vision based approach to determine lethargy,"['Aitik Gupta', 'Aadit Agarwal']","The outbreak of COVID-19 has forced everyone to stay indoors, fabricating a
significant drop in physical activeness. Our work is constructed upon the idea
to formulate a backbone mechanism, to detect levels of activeness in real-time,
using a single monocular image of a target person. The scope can be generalized
under many applications, be it in an interview, online classes, security
surveillance, et cetera. We propose a Computer Vision based multi-stage
approach, wherein the pose of a person is first detected, encoded with a novel
approach, and then assessed by a classical machine learning algorithm to
determine the level of activeness. An alerting system is wrapped around the
approach to provide a solution to inhibit lethargy by sending notification
alerts to individuals involved.",2020-10-26T16:54:03Z,http://arxiv.org/pdf/2010.13714v1,"['cs.CV', 'cs.HC', 'I.2.10; I.4.7; I.4.8; I.4.9; I.5.4']"
2305.09293v1,Out-of-Distribution Detection for Adaptive Computer Vision,"['Simon Kristoffersson Lind', 'Rudolph Triebel', 'Luigi Nardi', 'Volker Krueger']","It is well known that computer vision can be unreliable when faced with
previously unseen imaging conditions. This paper proposes a method to adapt
camera parameters according to a normalizing flow-based out-of-distibution
detector. A small-scale study is conducted which shows that adapting camera
parameters according to this out-of-distibution detector leads to an average
increase of 3 to 4 percentage points in mAP, mAR and F1 performance metrics of
a YOLOv4 object detector. As a secondary result, this paper also shows that it
is possible to train a normalizing flow model for out-of-distribution detection
on the COCO dataset, which is larger and more diverse than most benchmarks for
out-of-distibution detectors.",2023-05-16T09:01:42Z,http://arxiv.org/pdf/2305.09293v1,"['cs.CV', 'cs.LG']"
1901.00211v1,Mapping Areas using Computer Vision Algorithms and Drones,"['Bashar Alhafni', 'Saulo Fernando Guedes', 'Lays Cavalcante Ribeiro', 'Juhyun Park', 'Jeongkyu Lee']","The goal of this paper is to implement a system, titled as Drone Map Creator
(DMC) using Computer Vision techniques. DMC can process visual information from
an HD camera in a drone and automatically create a map by stitching together
visual information captured by a drone. The proposed approach employs the
Speeded up robust features (SURF) method to detect the key points for each
image frame; then the corresponding points between the frames are identified by
maximizing the determinant of a Hessian matrix. Finally, two images are
stitched together by using the identified points. Our results show that despite
some limitations from the external environment, we could have successfully
stitched images together along video sequences.",2019-01-01T21:24:07Z,http://arxiv.org/pdf/1901.00211v1,['cs.CV']
1902.11128v1,"FixyNN: Efficient Hardware for Mobile Computer Vision via Transfer
  Learning","['Paul N. Whatmough', 'Chuteng Zhou', 'Patrick Hansen', 'Shreyas Kolala Venkataramanaiah', 'Jae-sun Seo', 'Matthew Mattina']","The computational demands of computer vision tasks based on state-of-the-art
Convolutional Neural Network (CNN) image classification far exceed the energy
budgets of mobile devices. This paper proposes FixyNN, which consists of a
fixed-weight feature extractor that generates ubiquitous CNN features, and a
conventional programmable CNN accelerator which processes a dataset-specific
CNN. Image classification models for FixyNN are trained end-to-end via transfer
learning, with the common feature extractor representing the transfered part,
and the programmable part being learnt on the target dataset. Experimental
results demonstrate FixyNN hardware can achieve very high energy efficiencies
up to 26.6 TOPS/W ($4.81 \times$ better than iso-area programmable
accelerator). Over a suite of six datasets we trained models via transfer
learning with an accuracy loss of $<1\%$ resulting in up to 11.2 TOPS/W -
nearly $2 \times$ more efficient than a conventional programmable CNN
accelerator of the same area.",2019-02-27T02:42:33Z,http://arxiv.org/pdf/1902.11128v1,"['cs.CV', 'cs.AR', 'cs.LG', 'stat.ML']"
2003.03396v1,"Scalable Uncertainty for Computer Vision with Functional Variational
  Inference","['Eduardo D C Carvalho', 'Ronald Clark', 'Andrea Nicastro', 'Paul H J Kelly']","As Deep Learning continues to yield successful applications in Computer
Vision, the ability to quantify all forms of uncertainty is a paramount
requirement for its safe and reliable deployment in the real-world. In this
work, we leverage the formulation of variational inference in function space,
where we associate Gaussian Processes (GPs) to both Bayesian CNN priors and
variational family. Since GPs are fully determined by their mean and covariance
functions, we are able to obtain predictive uncertainty estimates at the cost
of a single forward pass through any chosen CNN architecture and for any
supervised learning task. By leveraging the structure of the induced covariance
matrices, we propose numerically efficient algorithms which enable fast
training in the context of high-dimensional tasks such as depth estimation and
semantic segmentation. Additionally, we provide sufficient conditions for
constructing regression loss functions whose probabilistic counterparts are
compatible with aleatoric uncertainty quantification.",2020-03-06T19:09:42Z,http://arxiv.org/pdf/2003.03396v1,"['cs.CV', 'cs.LG']"
2007.08364v1,A high fidelity synthetic face framework for computer vision,"['Tadas Baltrusaitis', 'Erroll Wood', 'Virginia Estellers', 'Charlie Hewitt', 'Sebastian Dziadzio', 'Marek Kowalski', 'Matthew Johnson', 'Thomas J. Cashman', 'Jamie Shotton']","Analysis of faces is one of the core applications of computer vision, with
tasks ranging from landmark alignment, head pose estimation, expression
recognition, and face recognition among others. However, building reliable
methods requires time-consuming data collection and often even more
time-consuming manual annotation, which can be unreliable. In our work we
propose synthesizing such facial data, including ground truth annotations that
would be almost impossible to acquire through manual annotation at the
consistency and scale possible through use of synthetic data. We use a
parametric face model together with hand crafted assets which enable us to
generate training data with unprecedented quality and diversity (varying shape,
texture, expression, pose, lighting, and hair).",2020-07-16T14:40:28Z,http://arxiv.org/pdf/2007.08364v1,"['cs.CV', 'cs.LG']"
2110.00791v1,Optimizing Neural Network for Computer Vision task in Edge Device,"['Ranjith M S', 'S Parameshwara', 'Pavan Yadav A', 'Shriganesh Hegde']","The field of computer vision has grown very rapidly in the past few years due
to networks like convolution neural networks and their variants. The memory
required to store the model and computational expense are very high for such a
network limiting it to deploy on the edge device. Many times, applications rely
on the cloud but that makes it hard for working in real-time due to round-trip
delays. We overcome these problems by deploying the neural network on the edge
device itself. The computational expense for edge devices is reduced by
reducing the floating-point precision of the parameters in the model. After
this the memory required for the model decreases and the speed of the
computation increases where the performance of the model is least affected.
This makes an edge device to predict from the neural network all by itself.",2021-10-02T12:25:18Z,http://arxiv.org/pdf/2110.00791v1,"['cs.CV', 'cs.AI']"
2110.02551v4,A Survey of Fish Tracking Techniques Based on Computer Vision,"['Weiran Li', 'Zhenbo Li', 'Fei Li', 'Meng Yuan', 'Chaojun Cen', 'Yanyu Qi', 'Qiannan Guo', 'You Li']","Fish tracking is a key technology for obtaining movement trajectories and
identifying abnormal behavior. However, it faces considerable challenges,
including occlusion, multi-scale tracking, and fish deformation. Notably,
extant reviews have focused more on behavioral analysis rather than providing a
comprehensive overview of computer vision-based fish tracking approaches. This
paper presents a comprehensive review of the advancements of fish tracking
technologies over the past seven years (2017-2023). It explores diverse fish
tracking techniques with an emphasis on fundamental localization and tracking
methods. Auxiliary plugins commonly integrated into fish tracking systems, such
as underwater image enhancement and re-identification, are also examined.
Additionally, this paper summarizes open-source datasets, evaluation metrics,
challenges, and applications in fish tracking research. Finally, a
comprehensive discussion offers insights and future directions for vision-based
fish tracking techniques. We hope that our work could provide a partial
reference in the development of fish tracking algorithms.",2021-10-06T07:46:35Z,http://arxiv.org/pdf/2110.02551v4,['cs.CV']
2403.19758v2,Quantum Natural Language Processing,"['Dominic Widdows', 'Willie Aboumrad', 'Dohun Kim', 'Sayonee Ray', 'Jonathan Mei']","Language processing is at the heart of current developments in artificial
intelligence, and quantum computers are becoming available at the same time.
This has led to great interest in quantum natural language processing, and
several early proposals and experiments.
  This paper surveys the state of this area, showing how NLP-related techniques
have been used in quantum language processing. We examine the art of word
embeddings and sequential models, proposing some avenues for future
investigation and discussing the tradeoffs present in these directions. We also
highlight some recent methods to compute attention in transformer models, and
perform grammatical parsing. We also introduce a new quantum design for the
basic task of text encoding (representing a string of characters in memory),
which has not been addressed in detail before.
  Quantum theory has contributed toward quantifying uncertainty and explaining
""What is intelligence?"" In this context, we argue that ""hallucinations"" in
modern artificial intelligence systems are a misunderstanding of the way facts
are conceptualized: language can express many plausible hypotheses, of which
only a few become actual.",2024-03-28T18:15:07Z,http://arxiv.org/pdf/2403.19758v2,"['quant-ph', 'cs.AI', 'cs.CL']"
2305.13246v1,Interactive Natural Language Processing,"['Zekun Wang', 'Ge Zhang', 'Kexin Yang', 'Ning Shi', 'Wangchunshu Zhou', 'Shaochun Hao', 'Guangzheng Xiong', 'Yizhi Li', 'Mong Yuan Sim', 'Xiuying Chen', 'Qingqing Zhu', 'Zhenzhu Yang', 'Adam Nik', 'Qi Liu', 'Chenghua Lin', 'Shi Wang', 'Ruibo Liu', 'Wenhu Chen', 'Ke Xu', 'Dayiheng Liu', 'Yike Guo', 'Jie Fu']","Interactive Natural Language Processing (iNLP) has emerged as a novel
paradigm within the field of NLP, aimed at addressing limitations in existing
frameworks while aligning with the ultimate goals of artificial intelligence.
This paradigm considers language models as agents capable of observing, acting,
and receiving feedback iteratively from external entities. Specifically,
language models in this context can: (1) interact with humans for better
understanding and addressing user needs, personalizing responses, aligning with
human values, and improving the overall user experience; (2) interact with
knowledge bases for enriching language representations with factual knowledge,
enhancing the contextual relevance of responses, and dynamically leveraging
external information to generate more accurate and informed responses; (3)
interact with models and tools for effectively decomposing and addressing
complex tasks, leveraging specialized expertise for specific subtasks, and
fostering the simulation of social behaviors; and (4) interact with
environments for learning grounded representations of language, and effectively
tackling embodied tasks such as reasoning, planning, and decision-making in
response to environmental observations. This paper offers a comprehensive
survey of iNLP, starting by proposing a unified definition and framework of the
concept. We then provide a systematic classification of iNLP, dissecting its
various components, including interactive objects, interaction interfaces, and
interaction methods. We proceed to delve into the evaluation methodologies used
in the field, explore its diverse applications, scrutinize its ethical and
safety issues, and discuss prospective research directions. This survey serves
as an entry point for researchers who are interested in this rapidly evolving
area and offers a broad view of the current landscape and future trajectory of
iNLP.",2023-05-22T17:18:29Z,http://arxiv.org/pdf/2305.13246v1,"['cs.CL', 'cs.AI']"
2302.03490v1,Natural Language Processing for Policymaking,"['Zhijing Jin', 'Rada Mihalcea']","Language is the medium for many political activities, from campaigns to news
reports. Natural language processing (NLP) uses computational tools to parse
text into key information that is needed for policymaking. In this chapter, we
introduce common methods of NLP, including text classification, topic modeling,
event extraction, and text scaling. We then overview how these methods can be
used for policymaking through four major applications including data collection
for evidence-based policymaking, interpretation of political decisions, policy
communication, and investigation of policy effects. Finally, we highlight some
potential limitations and ethical concerns when using NLP for policymaking.
  This text is from Chapter 7 (pages 141-162) of the Handbook of Computational
Social Science for Policy (2023). Open Access on Springer:
https://doi.org/10.1007/978-3-031-16624-2",2023-02-07T14:34:39Z,http://arxiv.org/pdf/2302.03490v1,"['cs.CL', 'cs.AI', 'cs.CY', 'cs.LG']"
2504.14530v1,Causality for Natural Language Processing,['Zhijing Jin'],"Causal reasoning is a cornerstone of human intelligence and a critical
capability for artificial systems aiming to achieve advanced understanding and
decision-making. This thesis delves into various dimensions of causal reasoning
and understanding in large language models (LLMs). It encompasses a series of
studies that explore the causal inference skills of LLMs, the mechanisms behind
their performance, and the implications of causal and anticausal learning for
natural language processing (NLP) tasks. Additionally, it investigates the
application of causal reasoning in text-based computational social science,
specifically focusing on political decision-making and the evaluation of
scientific impact through citations. Through novel datasets, benchmark tasks,
and methodological frameworks, this work identifies key challenges and
opportunities to improve the causal capabilities of LLMs, providing a
comprehensive foundation for future research in this evolving field.",2025-04-20T08:11:11Z,http://arxiv.org/pdf/2504.14530v1,"['cs.CL', 'cs.AI', 'cs.CY', 'cs.LG']"
2102.03732v1,Representation Learning for Natural Language Processing,"['Zhiyuan Liu', 'Yankai Lin', 'Maosong Sun']","This book aims to review and present the recent advances of distributed
representation learning for NLP, including why representation learning can
improve NLP, how representation learning takes part in various important topics
of NLP, and what challenges are still not well addressed by distributed
representation.",2021-02-07T07:37:07Z,http://arxiv.org/pdf/2102.03732v1,['cs.CL']
2110.15803v3,Natural Language Processing for Smart Healthcare,"['Binggui Zhou', 'Guanghua Yang', 'Zheng Shi', 'Shaodan Ma']","Smart healthcare has achieved significant progress in recent years. Emerging
artificial intelligence (AI) technologies enable various smart applications
across various healthcare scenarios. As an essential technology powered by AI,
natural language processing (NLP) plays a key role in smart healthcare due to
its capability of analysing and understanding human language. In this work, we
review existing studies that concern NLP for smart healthcare from the
perspectives of technique and application. We first elaborate on different NLP
approaches and the NLP pipeline for smart healthcare from the technical point
of view. Then, in the context of smart healthcare applications employing NLP
techniques, we introduce representative smart healthcare scenarios, including
clinical practice, hospital management, personal care, public health, and drug
development. We further discuss two specific medical issues, i.e., the
coronavirus disease 2019 (COVID-19) pandemic and mental health, in which
NLP-driven smart healthcare plays an important role. Finally, we discuss the
limitations of current works and identify the directions for future works.",2021-10-19T02:48:44Z,http://arxiv.org/pdf/2110.15803v3,"['cs.CL', 'cs.AI']"
1801.01331v2,VnCoreNLP: A Vietnamese Natural Language Processing Toolkit,"['Thanh Vu', 'Dat Quoc Nguyen', 'Dai Quoc Nguyen', 'Mark Dras', 'Mark Johnson']","We present an easy-to-use and fast toolkit, namely VnCoreNLP---a Java NLP
annotation pipeline for Vietnamese. Our VnCoreNLP supports key natural language
processing (NLP) tasks including word segmentation, part-of-speech (POS)
tagging, named entity recognition (NER) and dependency parsing, and obtains
state-of-the-art (SOTA) results for these tasks. We release VnCoreNLP to
provide rich linguistic annotations to facilitate research work on Vietnamese
NLP. Our VnCoreNLP is open-source and available at:
https://github.com/vncorenlp/VnCoreNLP",2018-01-04T12:52:43Z,http://arxiv.org/pdf/1801.01331v2,['cs.CL']
2410.14194v1,Speciesism in Natural Language Processing Research,"['Masashi Takeshita', 'Rafal Rzepka']","Natural Language Processing (NLP) research on AI Safety and social bias in AI
has focused on safety for humans and social bias against human minorities.
However, some AI ethicists have argued that the moral significance of nonhuman
animals has been ignored in AI research. Therefore, the purpose of this study
is to investigate whether there is speciesism, i.e., discrimination against
nonhuman animals, in NLP research. First, we explain why nonhuman animals are
relevant in NLP research. Next, we survey the findings of existing research on
speciesism in NLP researchers, data, and models and further investigate this
problem in this study. The findings of this study suggest that speciesism
exists within researchers, data, and models, respectively. Specifically, our
survey and experiments show that (a) among NLP researchers, even those who
study social bias in AI, do not recognize speciesism or speciesist bias; (b)
among NLP data, speciesist bias is inherent in the data annotated in the
datasets used to evaluate NLP models; (c) OpenAI GPTs, recent NLP models,
exhibit speciesist bias by default. Finally, we discuss how we can reduce
speciesism in NLP research.",2024-10-18T06:09:41Z,http://arxiv.org/pdf/2410.14194v1,"['cs.CL', 'cs.AI']"
2311.02579v1,mahaNLP: A Marathi Natural Language Processing Library,"['Vidula Magdum', 'Omkar Dhekane', 'Sharayu Hiwarkhedkar', 'Saloni Mittal', 'Raviraj Joshi']","We present mahaNLP, an open-source natural language processing (NLP) library
specifically built for the Marathi language. It aims to enhance the support for
the low-resource Indian language Marathi in the field of NLP. It is an
easy-to-use, extensible, and modular toolkit for Marathi text analysis built on
state-of-the-art MahaBERT-based transformer models. Our work holds significant
importance as other existing Indic NLP libraries provide basic Marathi
processing support and rely on older models with restricted performance. Our
toolkit stands out by offering a comprehensive array of NLP tasks, encompassing
both fundamental preprocessing tasks and advanced NLP tasks like sentiment
analysis, NER, hate speech detection, and sentence completion. This paper
focuses on an overview of the mahaNLP framework, its features, and its usage.
This work is a part of the L3Cube MahaNLP initiative, more information about it
can be found at https://github.com/l3cube-pune/MarathiNLP .",2023-11-05T06:59:59Z,http://arxiv.org/pdf/2311.02579v1,"['cs.CL', 'cs.LG']"
2311.07171v1,calamanCy: A Tagalog Natural Language Processing Toolkit,['Lester James V. Miranda'],"We introduce calamanCy, an open-source toolkit for constructing natural
language processing (NLP) pipelines for Tagalog. It is built on top of spaCy,
enabling easy experimentation and integration with other frameworks. calamanCy
addresses the development gap by providing a consistent API for building NLP
applications and offering general-purpose multitask models with out-of-the-box
support for dependency parsing, parts-of-speech (POS) tagging, and named entity
recognition (NER). calamanCy aims to accelerate the progress of Tagalog NLP by
consolidating disjointed resources in a unified framework. The calamanCy
toolkit is available on GitHub: https://github.com/ljvmiranda921/calamanCy.",2023-11-13T09:06:43Z,http://arxiv.org/pdf/2311.07171v1,['cs.CL']
9702005v1,Software Infrastructure for Natural Language Processing,"['Hamish Cunningham', 'Kevin Humphreys', 'Robert Gaizauskas', 'Yorick Wilks']","We classify and review current approaches to software infrastructure for
research, development and delivery of NLP systems. The task is motivated by a
discussion of current trends in the field of NLP and Language Engineering. We
describe a system called GATE (a General Architecture for Text Engineering)
that provides a software infrastructure on top of which heterogeneous NLP
processing modules may be evaluated and refined individually, or may be
combined into larger application systems. GATE aims to support both researchers
and developers working on component technologies (e.g. parsing, tagging,
morphological analysis) and those working on developing end-user applications
(e.g. information extraction, text summarisation, document generation, machine
translation, and second language learning). GATE promotes reuse of component
technology, permits specialisation and collaboration in large-scale projects,
and allows for the comparison and evaluation of alternative technologies. The
first release of GATE is now available - see
http://www.dcs.shef.ac.uk/research/groups/nlp/gate/",1997-02-10T21:07:20Z,http://arxiv.org/pdf/cmp-lg/9702005v1,"['cmp-lg', 'cs.CL']"
1209.6238v1,Natural Language Processing - A Survey,['Kevin Mote'],"The utility and power of Natural Language Processing (NLP) seems destined to
change our technological society in profound and fundamental ways. However
there are, to date, few accessible descriptions of the science of NLP that have
been written for a popular audience, or even for an audience of intelligent,
but uninitiated scientists. This paper aims to provide just such an overview.
In short, the objective of this article is to describe the purpose, procedures
and practical applications of NLP in a clear, balanced, and readable way. We
will examine the most recent literature describing the methods and processes of
NLP, analyze some of the challenges that researchers are faced with, and
briefly survey some of the current and future applications of this science to
IT research in general.",2012-09-25T21:05:08Z,http://arxiv.org/pdf/1209.6238v1,['cs.CL']
2005.00870v1,Predicting Performance for Natural Language Processing Tasks,"['Mengzhou Xia', 'Antonios Anastasopoulos', 'Ruochen Xu', 'Yiming Yang', 'Graham Neubig']","Given the complexity of combinations of tasks, languages, and domains in
natural language processing (NLP) research, it is computationally prohibitive
to exhaustively test newly proposed models on each possible experimental
setting. In this work, we attempt to explore the possibility of gaining
plausible judgments of how well an NLP model can perform under an experimental
setting, without actually training or testing the model. To do so, we build
regression models to predict the evaluation score of an NLP experiment given
the experimental settings as input. Experimenting on 9 different NLP tasks, we
find that our predictors can produce meaningful predictions over unseen
languages and different modeling architectures, outperforming reasonable
baselines as well as human experts. Going further, we outline how our predictor
can be used to find a small subset of representative experiments that should be
run in order to obtain plausible predictions for all other experimental
settings.",2020-05-02T16:02:18Z,http://arxiv.org/pdf/2005.00870v1,['cs.CL']
2109.12575v2,Paradigm Shift in Natural Language Processing,"['Tianxiang Sun', 'Xiangyang Liu', 'Xipeng Qiu', 'Xuanjing Huang']","In the era of deep learning, modeling for most NLP tasks has converged to
several mainstream paradigms. For example, we usually adopt the sequence
labeling paradigm to solve a bundle of tasks such as POS-tagging, NER,
Chunking, and adopt the classification paradigm to solve tasks like sentiment
analysis. With the rapid progress of pre-trained language models, recent years
have observed a rising trend of Paradigm Shift, which is solving one NLP task
by reformulating it as another one. Paradigm shift has achieved great success
on many tasks, becoming a promising way to improve model performance. Moreover,
some of these paradigms have shown great potential to unify a large number of
NLP tasks, making it possible to build a single model to handle diverse tasks.
In this paper, we review such phenomenon of paradigm shifts in recent years,
highlighting several paradigms that have the potential to solve different NLP
tasks.",2021-09-26T11:55:23Z,http://arxiv.org/pdf/2109.12575v2,"['cs.CL', 'cs.AI']"
2302.12039v1,Natural Language Processing in the Legal Domain,"['Daniel Martin Katz', 'Dirk Hartung', 'Lauritz Gerlach', 'Abhik Jana', 'Michael J. Bommarito II']","In this paper, we summarize the current state of the field of NLP & Law with
a specific focus on recent technical and substantive developments. To support
our analysis, we construct and analyze a nearly complete corpus of more than
six hundred NLP & Law related papers published over the past decade. Our
analysis highlights several major trends. Namely, we document an increasing
number of papers written, tasks undertaken, and languages covered over the
course of the past decade. We observe an increase in the sophistication of the
methods which researchers deployed in this applied context. Slowly but surely,
Legal NLP is beginning to match not only the methodological sophistication of
general NLP but also the professional standards of data availability and code
reproducibility observed within the broader scientific community. We believe
all of these trends bode well for the future of the field, but many questions
in both the academic and commercial sphere still remain open.",2023-02-23T14:02:47Z,http://arxiv.org/pdf/2302.12039v1,"['cs.CL', 'cs.AI']"
2306.08193v2,Operationalising Representation in Natural Language Processing,['Jacqueline Harding'],"Despite its centrality in the philosophy of cognitive science, there has been
little prior philosophical work engaging with the notion of representation in
contemporary NLP practice. This paper attempts to fill that lacuna: drawing on
ideas from cognitive science, I introduce a framework for evaluating the
representational claims made about components of neural NLP models, proposing
three criteria with which to evaluate whether a component of a model represents
a property and operationalising these criteria using probing classifiers, a
popular analysis technique in NLP (and deep learning more broadly).
  The project of operationalising a philosophically-informed notion of
representation should be of interest to both philosophers of science and NLP
practitioners. It affords philosophers a novel testing-ground for claims about
the nature of representation, and helps NLPers organise the large literature on
probing experiments, suggesting novel avenues for empirical research.",2023-06-14T01:34:16Z,http://arxiv.org/pdf/2306.08193v2,"['cs.CL', 'cs.AI', 'cs.LG']"
2405.10845v1,Natural Language Processing for Requirements Traceability,"['Jin L. C. Guo', 'Jan-Philipp Steghöfer', 'Andreas Vogelsang', 'Jane Cleland-Huang']","Traceability, the ability to trace relevant software artifacts to support
reasoning about the quality of the software and its development process, plays
a crucial role in requirements and software engineering, particularly for
safety-critical systems. In this chapter, we provide a comprehensive overview
of the representative tasks in requirement traceability for which natural
language processing (NLP) and related techniques have made considerable
progress in the past decade. We first present the definition of traceability in
the context of requirements and the overall engineering process, as well as
other important concepts related to traceability tasks. Then, we discuss two
tasks in detail, including trace link recovery and trace link maintenance. We
also introduce two other related tasks concerning when trace links are used in
practical contexts. For each task, we explain the characteristics of the task,
how it can be approached through NLP techniques, and how to design and conduct
the experiment to demonstrate the performance of the NLP techniques. We further
discuss practical considerations on how to effectively apply NLP techniques and
assess their effectiveness regarding the data set collection, the metrics
selection, and the role of humans when evaluating the NLP approaches. Overall,
this chapter prepares the readers with the fundamental knowledge of designing
automated traceability solutions enabled by NLP in practice.",2024-05-17T15:17:00Z,http://arxiv.org/pdf/2405.10845v1,['cs.SE']
2005.00912v1,Examining Citations of Natural Language Processing Literature,['Saif M. Mohammad'],"We extracted information from the ACL Anthology (AA) and Google Scholar (GS)
to examine trends in citations of NLP papers. We explore questions such as: how
well cited are papers of different types (journal articles, conference papers,
demo papers, etc.)? how well cited are papers from different areas of within
NLP? etc. Notably, we show that only about 56\% of the papers in AA are cited
ten or more times. CL Journal has the most cited papers, but its citation
dominance has lessened in recent years. On average, long papers get almost
three times as many citations as short papers; and papers on sentiment
classification, anaphora resolution, and entity recognition have the highest
median citations. The analyses presented here, and the associated dataset of
NLP papers mapped to citations, have a number of uses including: understanding
how the field is growing and quantifying the impact of different types of
papers.",2020-05-02T20:01:59Z,http://arxiv.org/pdf/2005.00912v1,"['cs.DL', 'cs.CL']"
2304.12404v1,Semantic Tokenizer for Enhanced Natural Language Processing,"['Sandeep Mehta', 'Darpan Shah', 'Ravindra Kulkarni', 'Cornelia Caragea']","Traditionally, NLP performance improvement has been focused on improving
models and increasing the number of model parameters. NLP vocabulary
construction has remained focused on maximizing the number of words represented
through subword regularization. We present a novel tokenizer that uses
semantics to drive vocabulary construction. The tokenizer includes a trainer
that uses stemming to enhance subword formation. Further optimizations and
adaptations are implemented to minimize the number of words that cannot be
encoded. The encoder is updated to integrate with the trainer. The tokenizer is
implemented as a drop-in replacement for the SentencePiece tokenizer. The new
tokenizer more than doubles the number of wordforms represented in the
vocabulary. The enhanced vocabulary significantly improves NLP model
convergence, and improves quality of word and sentence embeddings. Our
experimental results show top performance on two Glue tasks using BERT-base,
improving on models more than 50X in size.",2023-04-24T19:33:41Z,http://arxiv.org/pdf/2304.12404v1,['cs.CL']
2405.05966v4,Natural Language Processing RELIES on Linguistics,"['Juri Opitz', 'Shira Wein', 'Nathan Schneider']","Large Language Models (LLMs) have become capable of generating highly fluent
text in certain languages, without modules specially designed to capture
grammar or semantic coherence. What does this mean for the future of linguistic
expertise in NLP? We highlight several aspects in which NLP (still) relies on
linguistics, or where linguistic thinking can illuminate new directions. We
argue our case around the acronym RELIES that encapsulates six major facets
where linguistics contributes to NLP: Resources, Evaluation, Low-resource
settings, Interpretability, Explanation, and the Study of language. This list
is not exhaustive, nor is linguistics the main point of reference for every
effort under these themes; but at a macro level, these facets highlight the
enduring importance of studying machine systems vis-\`a-vis systems of human
language.",2024-05-09T17:59:32Z,http://arxiv.org/pdf/2405.05966v4,"['cs.CL', 'cs.AI']"
2507.21112v1,InsurTech innovation using natural language processing,"['Panyi Dong', 'Zhiyu Quan']","With the rapid rise of InsurTech, traditional insurance companies are
increasingly exploring alternative data sources and advanced technologies to
sustain their competitive edge. This paper provides both a conceptual overview
and practical case studies of natural language processing (NLP) and its
emerging applications within insurance operations with a focus on transforming
raw, unstructured text into structured data suitable for actuarial analysis and
decision-making. Leveraging real-world alternative data provided by an
InsurTech industry partner that enriches traditional insurance data sources, we
apply various NLP techniques to demonstrate practical use cases in the
commercial insurance context. These enriched, text-derived insights not only
add to and refine traditional rating factors for commercial insurance pricing
but also offer novel perspectives for assessing underlying risk by introducing
novel industry classifications. Through these demonstrations, we show that NLP
is not merely a supplementary tool but a foundational element for modern,
data-driven insurance analytics.",2025-07-12T23:10:59Z,http://arxiv.org/pdf/2507.21112v1,"['cs.CL', 'cs.LG', 'stat.ML']"
9607017v1,Natural Language Processing: Structure and Complexity,['Wlodek Zadrozny'],"We introduce a method for analyzing the complexity of natural language
processing tasks, and for predicting the difficulty new NLP tasks.
  Our complexity measures are derived from the Kolmogorov complexity of a class
of automata --- {\it meaning automata}, whose purpose is to extract relevant
pieces of information from sentences. Natural language semantics is defined
only relative to the set of questions an automaton can answer.
  The paper shows examples of complexity estimates for various NLP programs and
tasks, and some recipes for complexity management. It positions natural
language processing as a subdomain of software engineering, and lays down its
formal foundation.",1996-07-13T21:31:43Z,http://arxiv.org/pdf/cmp-lg/9607017v1,"['cmp-lg', 'cs.CL']"
1811.07253v1,Quantifying Uncertainties in Natural Language Processing Tasks,"['Yijun Xiao', 'William Yang Wang']","Reliable uncertainty quantification is a first step towards building
explainable, transparent, and accountable artificial intelligent systems.
Recent progress in Bayesian deep learning has made such quantification
realizable. In this paper, we propose novel methods to study the benefits of
characterizing model and data uncertainties for natural language processing
(NLP) tasks. With empirical experiments on sentiment analysis, named entity
recognition, and language modeling using convolutional and recurrent neural
network models, we show that explicitly modeling uncertainties is not only
necessary to measure output confidence levels, but also useful at enhancing
model performances in various NLP tasks.",2018-11-18T01:36:05Z,http://arxiv.org/pdf/1811.07253v1,"['cs.CL', 'cs.AI', 'cs.LG', 'cs.NE']"
1807.02200v1,Natural Language Processing for Music Knowledge Discovery,"['Sergio Oramas', 'Luis Espinosa-Anke', 'Francisco Gómez', 'Xavier Serra']","Today, a massive amount of musical knowledge is stored in written form, with
testimonies dated as far back as several centuries ago. In this work, we
present different Natural Language Processing (NLP) approaches to harness the
potential of these text collections for automatic music knowledge discovery,
covering different phases in a prototypical NLP pipeline, namely corpus
compilation, text-mining, information extraction, knowledge graph generation
and sentiment analysis. Each of these approaches is presented alongside
different use cases (i.e., flamenco, Renaissance and popular music) where large
collections of documents are processed, and conclusions stemming from
data-driven analyses are presented and discussed.",2018-07-06T00:07:27Z,http://arxiv.org/pdf/1807.02200v1,['cs.CL']
2105.02590v3,Reliability Testing for Natural Language Processing Systems,"['Samson Tan', 'Shafiq Joty', 'Kathy Baxter', 'Araz Taeihagh', 'Gregory A. Bennett', 'Min-Yen Kan']","Questions of fairness, robustness, and transparency are paramount to address
before deploying NLP systems. Central to these concerns is the question of
reliability: Can NLP systems reliably treat different demographics fairly and
function correctly in diverse and noisy environments? To address this, we argue
for the need for reliability testing and contextualize it among existing work
on improving accountability. We show how adversarial attacks can be reframed
for this goal, via a framework for developing reliability tests. We argue that
reliability testing -- with an emphasis on interdisciplinary collaboration --
will enable rigorous and targeted testing, and aid in the enactment and
enforcement of industry standards.",2021-05-06T11:24:58Z,http://arxiv.org/pdf/2105.02590v3,"['cs.LG', 'cs.AI', 'cs.CL', 'cs.CY', 'cs.NE']"
2208.10228v2,Review of Natural Language Processing in Pharmacology,"['Dimitar Trajanov', 'Vangel Trajkovski', 'Makedonka Dimitrieva', 'Jovana Dobreva', 'Milos Jovanovik', 'Matej Klemen', 'Aleš Žagar', 'Marko Robnik-Šikonja']","Natural language processing (NLP) is an area of artificial intelligence that
applies information technologies to process the human language, understand it
to a certain degree, and use it in various applications. This area has rapidly
developed in the last few years and now employs modern variants of deep neural
networks to extract relevant patterns from large text corpora. The main
objective of this work is to survey the recent use of NLP in the field of
pharmacology. As our work shows, NLP is a highly relevant information
extraction and processing approach for pharmacology. It has been used
extensively, from intelligent searches through thousands of medical documents
to finding traces of adversarial drug interactions in social media. We split
our coverage into five categories to survey modern NLP methodology, commonly
addressed tasks, relevant textual data, knowledge bases, and useful programming
libraries. We split each of the five categories into appropriate subcategories,
describe their main properties and ideas, and summarize them in a tabular form.
The resulting survey presents a comprehensive overview of the area, useful to
practitioners and interested observers.",2022-08-22T12:10:27Z,http://arxiv.org/pdf/2208.10228v2,"['cs.CL', 'cs.LG', 'q-bio.BM', 'J.3; A.1']"
2501.16836v1,Misspellings in Natural Language Processing: A survey,"['Gianluca Sperduti', 'Alejandro Moreo']","This survey provides an overview of the challenges of misspellings in natural
language processing (NLP). While often unintentional, misspellings have become
ubiquitous in digital communication, especially with the proliferation of Web
2.0, user-generated content, and informal text mediums such as social media,
blogs, and forums. Even if humans can generally interpret misspelled text, NLP
models frequently struggle to handle it: this causes a decline in performance
in common tasks like text classification and machine translation. In this
paper, we reconstruct a history of misspellings as a scientific problem. We
then discuss the latest advancements to address the challenge of misspellings
in NLP. Main strategies to mitigate the effect of misspellings include data
augmentation, double step, character-order agnostic, and tuple-based methods,
among others. This survey also examines dedicated data challenges and
competitions to spur progress in the field. Critical safety and ethical
concerns are also examined, for example, the voluntary use of misspellings to
inject malicious messages and hate speech on social networks. Furthermore, the
survey explores psycholinguistic perspectives on how humans process
misspellings, potentially informing innovative computational techniques for
text normalization and representation. Finally, the misspelling-related
challenges and opportunities associated with modern large language models are
also analyzed, including benchmarks, datasets, and performances of the most
prominent language models against misspellings. This survey aims to be an
exhaustive resource for researchers seeking to mitigate the impact of
misspellings in the rapidly evolving landscape of NLP.",2025-01-28T10:26:04Z,http://arxiv.org/pdf/2501.16836v1,"['cs.CL', 'cs.AI']"
2507.00297v1,Natural language processing for African languages,['David Ifeoluwa Adelani'],"Recent advances in word embeddings and language models use large-scale,
unlabelled data and self-supervised learning to boost NLP performance.
Multilingual models, often trained on web-sourced data like Wikipedia, face
challenges: few low-resource languages are included, their data is often noisy,
and lack of labeled datasets makes it hard to evaluate performance outside
high-resource languages like English. In this dissertation, we focus on
languages spoken in Sub-Saharan Africa where all the indigenous languages in
this region can be regarded as low-resourced in terms of the availability of
labelled data for NLP tasks and unlabelled data found on the web. We analyse
the noise in the publicly available corpora, and curate a high-quality corpus,
demonstrating that the quality of semantic representations learned in word
embeddings does not only depend on the amount of data but on the quality of
pre-training data. We demonstrate empirically the limitations of word
embeddings, and the opportunities the multilingual pre-trained language model
(PLM) offers especially for languages unseen during pre-training and
low-resource scenarios. We further study how to adapt and specialize
multilingual PLMs to unseen African languages using a small amount of
monolingual texts. To address the under-representation of the African languages
in NLP research, we developed large scale human-annotated labelled datasets for
21 African languages in two impactful NLP tasks: named entity recognition and
machine translation. We conduct an extensive empirical evaluation using
state-of-the-art methods across supervised, weakly-supervised, and transfer
learning settings.",2025-06-30T22:26:36Z,http://arxiv.org/pdf/2507.00297v1,"['cs.CL', 'cs.AI']"
2305.04572v2,Putting Natural in Natural Language Processing,['Grzegorz Chrupała'],"Human language is firstly spoken and only secondarily written. Text, however,
is a very convenient and efficient representation of language, and modern
civilization has made it ubiquitous. Thus the field of NLP has overwhelmingly
focused on processing written rather than spoken language. Work on spoken
language, on the other hand, has been siloed off within the largely separate
speech processing community which has been inordinately preoccupied with
transcribing speech into text. Recent advances in deep learning have led to a
fortuitous convergence in methods between speech processing and mainstream NLP.
Arguably, the time is ripe for a unification of these two fields, and for
starting to take spoken language seriously as the primary mode of human
communication. Truly natural language processing could lead to better
integration with the rest of language science and could lead to systems which
are more data-efficient and more human-like, and which can communicate beyond
the textual modality.",2023-05-08T09:29:31Z,http://arxiv.org/pdf/2305.04572v2,"['cs.CL', 'cs.AI', 'eess.AS']"
2109.13037v2,Language Invariant Properties in Natural Language Processing,"['Federico Bianchi', 'Debora Nozza', 'Dirk Hovy']","Meaning is context-dependent, but many properties of language (should) remain
the same even if we transform the context. For example, sentiment, entailment,
or speaker properties should be the same in a translation and original of a
text. We introduce language invariant properties: i.e., properties that should
not change when we transform text, and how they can be used to quantitatively
evaluate the robustness of transformation algorithms. We use translation and
paraphrasing as transformation examples, but our findings apply more broadly to
any transformation. Our results indicate that many NLP transformations change
properties like author characteristics, i.e., make them sound more male. We
believe that studying these properties will allow NLP to address both social
factors and pragmatic aspects of language. We also release an application suite
that can be used to evaluate the invariance of transformation applications.",2021-09-27T13:23:05Z,http://arxiv.org/pdf/2109.13037v2,['cs.CL']
2310.10930v1,Enhanced Transformer Architecture for Natural Language Processing,"['Woohyeon Moon', 'Taeyoung Kim', 'Bumgeun Park', 'Dongsoo Har']","Transformer is a state-of-the-art model in the field of natural language
processing (NLP). Current NLP models primarily increase the number of
transformers to improve processing performance. However, this technique
requires a lot of training resources such as computing capacity. In this paper,
a novel structure of Transformer is proposed. It is featured by full layer
normalization, weighted residual connection, positional encoding exploiting
reinforcement learning, and zero masked self-attention. The proposed
Transformer model, which is called Enhanced Transformer, is validated by the
bilingual evaluation understudy (BLEU) score obtained with the Multi30k
translation dataset. As a result, the Enhanced Transformer achieves 202.96%
higher BLEU score as compared to the original transformer with the translation
dataset.",2023-10-17T01:59:07Z,http://arxiv.org/pdf/2310.10930v1,"['cs.CL', 'cs.AI']"
1807.05519v1,Concept-Based Embeddings for Natural Language Processing,"['Yukun Ma', 'Erik Cambria']","In this work, we focus on effectively leveraging and integrating information
from concept-level as well as word-level via projecting concepts and words into
a lower dimensional space while retaining most critical semantics. In a broad
context of opinion understanding system, we investigate the use of the fused
embedding for several core NLP tasks: named entity detection and
classification, automatic speech recognition reranking, and targeted sentiment
analysis.",2018-07-15T09:36:39Z,http://arxiv.org/pdf/1807.05519v1,['cs.CL']
2303.12804v1,Features matching using natural language processing,['Muhammad Danial Khilji'],"The feature matching is a basic step in matching different datasets. This
article proposes shows a new hybrid model of a pretrained Natural Language
Processing (NLP) based model called BERT used in parallel with a statistical
model based on Jaccard similarity to measure the similarity between list of
features from two different datasets. This reduces the time required to search
for correlations or manually match each feature from one dataset to another.",2023-03-14T13:31:19Z,http://arxiv.org/pdf/2303.12804v1,"['cs.DB', 'cs.CL', 'cs.LG']"
1908.01851v1,Self-Knowledge Distillation in Natural Language Processing,"['Sangchul Hahn', 'Heeyoul Choi']","Since deep learning became a key player in natural language processing (NLP),
many deep learning models have been showing remarkable performances in a
variety of NLP tasks, and in some cases, they are even outperforming humans.
Such high performance can be explained by efficient knowledge representation of
deep learning models. While many methods have been proposed to learn more
efficient representation, knowledge distillation from pretrained deep networks
suggest that we can use more information from the soft target probability to
train other neural networks. In this paper, we propose a new knowledge
distillation method self-knowledge distillation, based on the soft target
probabilities of the training model itself, where multimode information is
distilled from the word embedding space right below the softmax layer. Due to
the time complexity, our method approximates the soft target probabilities. In
experiments, we applied the proposed method to two different and fundamental
NLP tasks: language model and neural machine translation. The experiment
results show that our proposed method improves performance on the tasks.",2019-08-02T15:17:27Z,http://arxiv.org/pdf/1908.01851v1,"['cs.CL', 'cs.LG', 'stat.ML']"
2108.13300v1,Deep Natural Language Processing for LinkedIn Search,"['Weiwei Guo', 'Xiaowei Liu', 'Sida Wang', 'Michaeel Kazi', 'Zhiwei Wang', 'Zhoutong Fu', 'Jun Jia', 'Liang Zhang', 'Huiji Gao', 'Bo Long']","Many search systems work with large amounts of natural language data, e.g.,
search queries, user profiles, and documents. Building a successful search
system requires a thorough understanding of textual data semantics, where deep
learning based natural language processing techniques (deep NLP) can be of
great help. In this paper, we introduce a comprehensive study for applying deep
NLP techniques to five representative tasks in search systems: query intent
prediction (classification), query tagging (sequential tagging), document
ranking (ranking), query auto completion (language modeling), and query
suggestion (sequence to sequence). We also introduce BERT pre-training as a
sixth task that can be applied to many of the other tasks. Through the model
design and experiments of the six tasks, readers can find answers to four
important questions: (1). When is deep NLP helpful/not helpful in search
systems? (2). How to address latency challenges? (3). How to ensure model
robustness? This work builds on existing efforts of LinkedIn search, and is
tested at scale on LinkedIn's commercial search engines. We believe our
experiences can provide useful insights for the industry and research
communities.",2021-08-16T23:37:33Z,http://arxiv.org/pdf/2108.13300v1,"['cs.IR', 'cs.CL']"
2105.05222v2,Including Signed Languages in Natural Language Processing,"['Kayo Yin', 'Amit Moryossef', 'Julie Hochgesang', 'Yoav Goldberg', 'Malihe Alikhani']","Signed languages are the primary means of communication for many deaf and
hard of hearing individuals. Since signed languages exhibit all the fundamental
linguistic properties of natural language, we believe that tools and theories
of Natural Language Processing (NLP) are crucial towards its modeling. However,
existing research in Sign Language Processing (SLP) seldom attempt to explore
and leverage the linguistic organization of signed languages. This position
paper calls on the NLP community to include signed languages as a research area
with high social and scientific impact. We first discuss the linguistic
properties of signed languages to consider during their modeling. Then, we
review the limitations of current SLP models and identify the open challenges
to extend NLP to signed languages. Finally, we urge (1) the adoption of an
efficient tokenization method; (2) the development of linguistically-informed
models; (3) the collection of real-world signed language data; (4) the
inclusion of local signed language communities as an active and leading voice
in the direction of research.",2021-05-11T17:37:55Z,http://arxiv.org/pdf/2105.05222v2,"['cs.CL', 'cs.AI', 'cs.LG']"
2109.03009v1,Sequential Attention Module for Natural Language Processing,"['Mengyuan Zhou', 'Jian Ma', 'Haiqin Yang', 'Lianxin Jiang', 'Yang Mo']","Recently, large pre-trained neural language models have attained remarkable
performance on many downstream natural language processing (NLP) applications
via fine-tuning. In this paper, we target at how to further improve the token
representations on the language models. We, therefore, propose a simple yet
effective plug-and-play module, Sequential Attention Module (SAM), on the token
embeddings learned from a pre-trained language model. Our proposed SAM consists
of two main attention modules deployed sequentially: Feature-wise Attention
Module (FAM) and Token-wise Attention Module (TAM). More specifically, FAM can
effectively identify the importance of features at each dimension and promote
the effect via dot-product on the original token embeddings for downstream NLP
applications. Meanwhile, TAM can further re-weight the features at the
token-wise level. Moreover, we propose an adaptive filter on FAM to prevent
noise impact and increase information absorption. Finally, we conduct extensive
experiments to demonstrate the advantages and properties of our proposed SAM.
We first show how SAM plays a primary role in the champion solution of two
subtasks of SemEval'21 Task 7. After that, we apply SAM on sentiment analysis
and three popular NLP tasks and demonstrate that SAM consistently outperforms
the state-of-the-art baselines.",2021-09-07T11:48:23Z,http://arxiv.org/pdf/2109.03009v1,"['cs.AI', 'cs.CL']"
2302.04725v1,Lightweight Transformers for Clinical Natural Language Processing,"['Omid Rohanian', 'Mohammadmahdi Nouriborji', 'Hannah Jauncey', 'Samaneh Kouchaki', 'ISARIC Clinical Characterisation Group', 'Lei Clifton', 'Laura Merson', 'David A. Clifton']","Specialised pre-trained language models are becoming more frequent in NLP
since they can potentially outperform models trained on generic texts. BioBERT
and BioClinicalBERT are two examples of such models that have shown promise in
medical NLP tasks. Many of these models are overparametrised and
resource-intensive, but thanks to techniques like Knowledge Distillation (KD),
it is possible to create smaller versions that perform almost as well as their
larger counterparts. In this work, we specifically focus on development of
compact language models for processing clinical texts (i.e. progress notes,
discharge summaries etc). We developed a number of efficient lightweight
clinical transformers using knowledge distillation and continual learning, with
the number of parameters ranging from 15 million to 65 million. These models
performed comparably to larger models such as BioBERT and ClinicalBioBERT and
significantly outperformed other compact models trained on general or
biomedical data. Our extensive evaluation was done across several standard
datasets and covered a wide range of clinical text-mining tasks, including
Natural Language Inference, Relation Extraction, Named Entity Recognition, and
Sequence Classification. To our knowledge, this is the first comprehensive
study specifically focused on creating efficient and compact transformers for
clinical NLP tasks. The models and code used in this study can be found on our
Huggingface profile at https://huggingface.co/nlpie and Github page at
https://github.com/nlpie-research/Lightweight-Clinical-Transformers,
respectively, promoting reproducibility of our results.",2023-02-09T16:07:31Z,http://arxiv.org/pdf/2302.04725v1,"['cs.CL', 'cs.AI', 'cs.LG', '68T50', 'I.2.7']"
2109.03383v1,DeepZensols: Deep Natural Language Processing Framework,"['Paul Landes', 'Barbara Di Eugenio', 'Cornelia Caragea']","Reproducing results in publications by distributing publicly available source
code is becoming ever more popular. Given the difficulty of reproducing machine
learning (ML) experiments, there have been significant efforts in reducing the
variance of these results. As in any science, the ability to consistently
reproduce results effectively strengthens the underlying hypothesis of the
work, and thus, should be regarded as important as the novel aspect of the
research itself. The contribution of this work is a framework that is able to
reproduce consistent results and provides a means of easily creating, training,
and evaluating natural language processing (NLP) deep learning (DL) models.",2021-09-08T01:16:05Z,http://arxiv.org/pdf/2109.03383v1,"['cs.CL', 'cs.AI']"
2310.20077v1,Partial Tensorized Transformers for Natural Language Processing,"['Subhadra Vadlamannati', 'Ryan Solgi']","The transformer architecture has revolutionized Natural Language Processing
(NLP) and other machine-learning tasks, due to its unprecedented accuracy.
However, their extensive memory and parameter requirements often hinder their
practical applications. In this work, we study the effect of tensor-train
decomposition to improve the accuracy and compress transformer vision-language
neural networks, namely BERT and ViT. We focus both on embedding-layer
compression and partial tensorization of neural networks (PTNN) through an
algorithmic approach. Our novel PTNN approach significantly improves the
accuracy of existing models by up to 5%, all without the need for post-training
adjustments, breaking new ground in the field of tensor decomposition.",2023-10-30T23:19:06Z,http://arxiv.org/pdf/2310.20077v1,"['cs.CL', 'cs.LG']"
2312.04649v1,PyThaiNLP: Thai Natural Language Processing in Python,"['Wannaphong Phatthiyaphaibun', 'Korakot Chaovavanich', 'Charin Polpanumas', 'Arthit Suriyawongkul', 'Lalita Lowphansirikul', 'Pattarawat Chormai', 'Peerat Limkonchotiwat', 'Thanathip Suntorntip', 'Can Udomcharoenchaikit']","We present PyThaiNLP, a free and open-source natural language processing
(NLP) library for Thai language implemented in Python. It provides a wide range
of software, models, and datasets for Thai language. We first provide a brief
historical context of tools for Thai language prior to the development of
PyThaiNLP. We then outline the functionalities it provided as well as datasets
and pre-trained language models. We later summarize its development milestones
and discuss our experience during its development. We conclude by demonstrating
how industrial and research communities utilize PyThaiNLP in their work. The
library is freely available at https://github.com/pythainlp/pythainlp.",2023-12-07T19:19:43Z,http://arxiv.org/pdf/2312.04649v1,"['cs.CL', 'I.2.7']"
1807.11714v2,Gender Bias in Neural Natural Language Processing,"['Kaiji Lu', 'Piotr Mardziel', 'Fangjing Wu', 'Preetam Amancharla', 'Anupam Datta']","We examine whether neural natural language processing (NLP) systems reflect
historical biases in training data. We define a general benchmark to quantify
gender bias in a variety of neural NLP tasks. Our empirical evaluation with
state-of-the-art neural coreference resolution and textbook RNN-based language
models trained on benchmark datasets finds significant gender bias in how
models view occupations. We then mitigate bias with CDA: a generic methodology
for corpus augmentation via causal interventions that breaks associations
between gendered and gender-neutral words. We empirically show that CDA
effectively decreases gender bias while preserving accuracy. We also explore
the space of mitigation strategies with CDA, a prior approach to word embedding
debiasing (WED), and their compositions. We show that CDA outperforms WED,
drastically so when word embeddings are trained. For pre-trained embeddings,
the two methods can be effectively composed. We also find that as training
proceeds on the original data set with gradient descent the gender bias grows
as the loss reduces, indicating that the optimization encourages bias; CDA
mitigates this behavior.",2018-07-31T09:27:27Z,http://arxiv.org/pdf/1807.11714v2,['cs.CL']
2301.04230v1,User-Centered Security in Natural Language Processing,['Chris Emmery'],"This dissertation proposes a framework of user-centered security in Natural
Language Processing (NLP), and demonstrates how it can improve the
accessibility of related research. Accordingly, it focuses on two security
domains within NLP with great public interest. First, that of author profiling,
which can be employed to compromise online privacy through invasive inferences.
Without access and detailed insight into these models' predictions, there is no
reasonable heuristic by which Internet users might defend themselves from such
inferences. Secondly, that of cyberbullying detection, which by default
presupposes a centralized implementation; i.e., content moderation across
social platforms. As access to appropriate data is restricted, and the nature
of the task rapidly evolves (both through lexical variation, and cultural
shifts), the effectiveness of its classifiers is greatly diminished and thereby
often misrepresented.
  Under the proposed framework, we predominantly investigate the use of
adversarial attacks on language; i.e., changing a given input (generating
adversarial samples) such that a given model does not function as intended.
These attacks form a common thread between our user-centered security problems;
they are highly relevant for privacy-preserving obfuscation methods against
author profiling, and adversarial samples might also prove useful to assess the
influence of lexical variation and augmentation on cyberbullying detection.",2023-01-10T22:34:19Z,http://arxiv.org/pdf/2301.04230v1,"['cs.CL', 'cs.CY']"
2011.08073v2,Analyzing Sustainability Reports Using Natural Language Processing,"['Alexandra Luccioni', 'Emily Baylor', 'Nicolas Duchene']","Climate change is a far-reaching, global phenomenon that will impact many
aspects of our society, including the global stock market
\cite{dietz2016climate}. In recent years, companies have increasingly been
aiming to both mitigate their environmental impact and adapt to the changing
climate context. This is reported via increasingly exhaustive reports, which
cover many types of climate risks and exposures under the umbrella of
Environmental, Social, and Governance (ESG). However, given this abundance of
data, sustainability analysts are obliged to comb through hundreds of pages of
reports in order to find relevant information. We leveraged recent progress in
Natural Language Processing (NLP) to create a custom model, ClimateQA, which
allows the analysis of financial reports in order to identify climate-relevant
sections based on a question answering approach. We present this tool and the
methodology that we used to develop it in the present article.",2020-11-03T21:22:42Z,http://arxiv.org/pdf/2011.08073v2,"['cs.CL', 'cs.LG']"
1903.02784v1,Arabic natural language processing: An overview,"['Imane Guellil', 'Houda Saâdane', 'Faical Azouaou', 'Billel Gueni', 'Damien Nouvel']","Arabic is recognised as the 4th most used language of the Internet. Arabic
has three main varieties: (1) classical Arabic (CA), (2) Modern Standard Arabic
(MSA), (3) Arabic Dialect (AD). MSA and AD could be written either in Arabic or
in Roman script (Arabizi), which corresponds to Arabic written with Latin
letters, numerals and punctuation. Due to the complexity of this language and
the number of corresponding challenges for NLP, many surveys have been
conducted, in order to synthesise the work done on Arabic. However these
surveys principally focus on two varieties of Arabic (MSA and AD, written in
Arabic letters only), they are slightly old (no such survey since 2015) and
therefore do not cover recent resources and tools. To bridge the gap, we
propose a survey focusing on 90 recent research papers (74% of which were
published after 2015). Our study presents and classifies the work done on the
three varieties of Arabic, by concentrating on both Arabic and Arabizi, and
associates each work to its publicly available resources whenever available.",2019-03-07T09:22:35Z,http://arxiv.org/pdf/1903.02784v1,['cs.CL']
1807.02383v1,Natural Language Processing for Information Extraction,['Sonit Singh'],"With rise of digital age, there is an explosion of information in the form of
news, articles, social media, and so on. Much of this data lies in unstructured
form and manually managing and effectively making use of it is tedious, boring
and labor intensive. This explosion of information and need for more
sophisticated and efficient information handling tools gives rise to
Information Extraction(IE) and Information Retrieval(IR) technology.
Information Extraction systems takes natural language text as input and
produces structured information specified by certain criteria, that is relevant
to a particular application. Various sub-tasks of IE such as Named Entity
Recognition, Coreference Resolution, Named Entity Linking, Relation Extraction,
Knowledge Base reasoning forms the building blocks of various high end Natural
Language Processing (NLP) tasks such as Machine Translation, Question-Answering
System, Natural Language Understanding, Text Summarization and Digital
Assistants like Siri, Cortana and Google Now. This paper introduces Information
Extraction technology, its various sub-tasks, highlights state-of-the-art
research in various IE subtasks, current challenges and future research
directions.",2018-07-06T12:44:31Z,http://arxiv.org/pdf/1807.02383v1,"['cs.CL', 'cs.AI']"
2509.04462v1,Benchmarking GPT-5 for biomedical natural language processing,"['Yu Hou', 'Zaifu Zhan', 'Rui Zhang']","The rapid expansion of biomedical literature has heightened the need for
scalable natural language processing (NLP) solutions. While GPT-4 substantially
narrowed the gap with task-specific systems, especially in question answering,
its performance across other domains remained uneven. We updated a standardized
BioNLP benchmark to evaluate GPT-5 and GPT-4o under zero-, one-, and five-shot
prompting across 12 datasets spanning six task families: named entity
recognition, relation extraction, multi-label document classification, question
answering, text summarization, and text simplification. Using fixed prompt
templates, identical decoding parameters, and batch inference, we report
primary metrics per dataset and include prior results for GPT-4, GPT-3.5, and
LLaMA-2-13B for comparison. GPT-5 achieved the strongest overall benchmark
performance, with macro-average scores rising to 0.557 under five-shot
prompting versus 0.506 for GPT-4 and 0.508 for GPT-4o. On MedQA, GPT-5 reached
94.1% accuracy, exceeding the previous supervised state of the art by over
fifty points, and attained parity with supervised systems on PubMedQA (0.734).
In extraction tasks, GPT-5 delivered major gains in chemical NER (0.886 F1) and
ChemProt relation extraction (0.616 F1), outperforming GPT-4 and GPT-4o, though
summarization and disease NER still lagged behind domain-specific baselines.
These results establish GPT-5 as a general-purpose model now offering
deployment-ready performance for reasoning-oriented biomedical QA, while
precision-critical extraction and evidence-dense summarization continue to
favor fine-tuned or hybrid approaches. The benchmark delineates where simple
prompting suffices and where retrieval-augmented or planning-based scaffolds
are likely required, providing actionable guidance for BioNLP system design as
frontier models advance.",2025-08-28T13:06:53Z,http://arxiv.org/pdf/2509.04462v1,"['cs.CL', 'cs.AI']"
1905.11833v4,"Interpreting and improving natural-language processing (in machines)
  with natural language-processing (in the brain)","['Mariya Toneva', 'Leila Wehbe']","Neural networks models for NLP are typically implemented without the explicit
encoding of language rules and yet they are able to break one performance
record after another. This has generated a lot of research interest in
interpreting the representations learned by these networks. We propose here a
novel interpretation approach that relies on the only processing system we have
that does understand language: the human brain. We use brain imaging recordings
of subjects reading complex natural text to interpret word and sequence
embeddings from 4 recent NLP models - ELMo, USE, BERT and Transformer-XL. We
study how their representations differ across layer depth, context length, and
attention type. Our results reveal differences in the context-related
representations across these models. Further, in the transformer models, we
find an interaction between layer depth and context length, and between layer
depth and attention type. We finally hypothesize that altering BERT to better
align with brain recordings would enable it to also better understand language.
Probing the altered BERT using syntactic NLP tasks reveals that the model with
increased brain-alignment outperforms the original model. Cognitive
neuroscientists have already begun using NLP networks to study the brain, and
this work closes the loop to allow the interaction between NLP and cognitive
neuroscience to be a true cross-pollination.",2019-05-28T14:13:09Z,http://arxiv.org/pdf/1905.11833v4,"['cs.CL', 'cs.AI', 'cs.LG', 'q-bio.NC']"
2205.01500v2,Meta Learning for Natural Language Processing: A Survey,"['Hung-yi Lee', 'Shang-Wen Li', 'Ngoc Thang Vu']","Deep learning has been the mainstream technique in natural language
processing (NLP) area. However, the techniques require many labeled data and
are less generalizable across domains. Meta-learning is an arising field in
machine learning studying approaches to learn better learning algorithms.
Approaches aim at improving algorithms in various aspects, including data
efficiency and generalizability. Efficacy of approaches has been shown in many
NLP tasks, but there is no systematic survey of these approaches in NLP, which
hinders more researchers from joining the field. Our goal with this survey
paper is to offer researchers pointers to relevant meta-learning works in NLP
and attract more attention from the NLP community to drive future innovation.
This paper first introduces the general concepts of meta-learning and the
common approaches. Then we summarize task construction settings and application
of meta-learning for various NLP problems and review the development of
meta-learning in NLP community.",2022-05-03T13:58:38Z,http://arxiv.org/pdf/2205.01500v2,"['cs.CL', 'cs.AI', 'cs.LG']"
2103.04044v1,Putting Humans in the Natural Language Processing Loop: A Survey,"['Zijie J. Wang', 'Dongjin Choi', 'Shenyu Xu', 'Diyi Yang']","How can we design Natural Language Processing (NLP) systems that learn from
human feedback? There is a growing research body of Human-in-the-loop (HITL)
NLP frameworks that continuously integrate human feedback to improve the model
itself. HITL NLP research is nascent but multifarious -- solving various NLP
problems, collecting diverse feedback from different people, and applying
different methods to learn from collected feedback. We present a survey of HITL
NLP work from both Machine Learning (ML) and Human-Computer Interaction (HCI)
communities that highlights its short yet inspiring history, and thoroughly
summarize recent frameworks focusing on their tasks, goals, human interactions,
and feedback learning methods. Finally, we discuss future directions for
integrating human feedback in the NLP development loop.",2021-03-06T06:26:00Z,http://arxiv.org/pdf/2103.04044v1,"['cs.CL', 'cs.AI', 'cs.HC', 'cs.LG']"
1807.00571v1,The Interplay between Lexical Resources and Natural Language Processing,"['Jose Camacho-Collados', 'Luis Espinosa-Anke', 'Mohammad Taher Pilehvar']","Incorporating linguistic, world and common sense knowledge into AI/NLP
systems is currently an important research area, with several open problems and
challenges. At the same time, processing and storing this knowledge in lexical
resources is not a straightforward task. This tutorial proposes to address
these complementary goals from two methodological perspectives: the use of NLP
methods to help the process of constructing and enriching lexical resources and
the use of lexical resources for improving NLP applications. Two main types of
audience can benefit from this tutorial: those working on language resources
who are interested in becoming acquainted with automatic NLP techniques, with
the end goal of speeding and/or easing up the process of resource curation; and
on the other hand, researchers in NLP who would like to benefit from the
knowledge of lexical resources to improve their systems and models. The slides
of the tutorial are available at https://bitbucket.org/luisespinosa/lr-nlp/",2018-07-02T09:53:50Z,http://arxiv.org/pdf/1807.00571v1,['cs.CL']
1401.0569v2,"Natural Language Processing in Biomedicine: A Unified System
  Architecture Overview","['Son Doan', 'Mike Conway', 'Tu Minh Phuong', 'Lucila Ohno-Machado']","In modern electronic medical records (EMR) much of the clinically important
data - signs and symptoms, symptom severity, disease status, etc. - are not
provided in structured data fields, but rather are encoded in clinician
generated narrative text. Natural language processing (NLP) provides a means of
""unlocking"" this important data source for applications in clinical decision
support, quality assurance, and public health. This chapter provides an
overview of representative NLP systems in biomedicine based on a unified
architectural view. A general architecture in an NLP system consists of two
main components: background knowledge that includes biomedical knowledge
resources and a framework that integrates NLP tools to process text. Systems
differ in both components, which we will review briefly. Additionally,
challenges facing current research efforts in biomedical NLP include the
paucity of large, publicly available annotated corpora, although initiatives
that facilitate data sharing, system evaluation, and collaborative work between
researchers in clinical NLP are starting to emerge.",2014-01-03T00:57:13Z,http://arxiv.org/pdf/1401.0569v2,['cs.CL']
2406.09765v2,Application of Natural Language Processing in Financial Risk Detection,"['Liyang Wang', 'Yu Cheng', 'Ao Xiang', 'Jingyu Zhang', 'Haowei Yang']","This paper explores the application of Natural Language Processing (NLP) in
financial risk detection. By constructing an NLP-based financial risk detection
model, this study aims to identify and predict potential risks in financial
documents and communications. First, the fundamental concepts of NLP and its
theoretical foundation, including text mining methods, NLP model design
principles, and machine learning algorithms, are introduced. Second, the
process of text data preprocessing and feature extraction is described.
Finally, the effectiveness and predictive performance of the model are
validated through empirical research. The results show that the NLP-based
financial risk detection model performs excellently in risk identification and
prediction, providing effective risk management tools for financial
institutions. This study offers valuable references for the field of financial
risk management, utilizing advanced NLP techniques to improve the accuracy and
efficiency of financial risk detection.",2024-06-14T07:06:24Z,http://arxiv.org/pdf/2406.09765v2,"['q-fin.RM', 'cs.CL']"
1702.01923v1,Comparative Study of CNN and RNN for Natural Language Processing,"['Wenpeng Yin', 'Katharina Kann', 'Mo Yu', 'Hinrich Schütze']","Deep neural networks (DNN) have revolutionized the field of natural language
processing (NLP). Convolutional neural network (CNN) and recurrent neural
network (RNN), the two main types of DNN architectures, are widely explored to
handle various NLP tasks. CNN is supposed to be good at extracting
position-invariant features and RNN at modeling units in sequence. The state of
the art on many NLP tasks often switches due to the battle between CNNs and
RNNs. This work is the first systematic comparison of CNN and RNN on a wide
range of representative NLP tasks, aiming to give basic guidance for DNN
selection.",2017-02-07T08:33:35Z,http://arxiv.org/pdf/1702.01923v1,['cs.CL']
2209.06169v1,The Role of Explanatory Value in Natural Language Processing,['Kees van Deemter'],"A key aim of science is explanation, yet the idea of explaining language
phenomena has taken a backseat in mainstream Natural Language Processing (NLP)
and many other areas of Artificial Intelligence. I argue that explanation of
linguistic behaviour should be a main goal of NLP, and that this is not the
same as making NLP models explainable. To illustrate these ideas, some recent
models of human language production are compared with each other. I conclude by
asking what it would mean for NLP research and institutional policies if our
community took explanatory value seriously, while heeding some possible
pitfalls.",2022-09-13T17:19:04Z,http://arxiv.org/pdf/2209.06169v1,['cs.CL']
2410.16498v2,Natural Language Processing for Human Resources: A Survey,"['Naoki Otani', 'Nikita Bhutani', 'Estevam Hruschka']","Advances in Natural Language Processing (NLP) have the potential to transform
HR processes, from recruitment to employee management. While recent
breakthroughs in NLP have generated significant interest in its industrial
applications, a comprehensive overview of how NLP can be applied across HR
activities is still lacking. This paper discovers opportunities for researchers
and practitioners to harness NLP's transformative potential in this domain. We
analyze key fundamental tasks such as information extraction and text
classification, and their roles in downstream applications like recommendation
and language generation, while also discussing ethical concerns. Additionally,
we identify gaps in current research and encourage future work to explore
holistic approaches for achieving broader objectives in this field.",2024-10-21T20:41:00Z,http://arxiv.org/pdf/2410.16498v2,['cs.CL']
2204.04282v1,"Classification of Natural Language Processing Techniques for
  Requirements Engineering","['Liping Zhao', 'Waad Alhoshan', 'Alessio Ferrari', 'Keletso J. Letsholo']","Research in applying natural language processing (NLP) techniques to
requirements engineering (RE) tasks spans more than 40 years, from initial
efforts carried out in the 1980s to more recent attempts with machine learning
(ML) and deep learning (DL) techniques. However, in spite of the progress, our
recent survey shows that there is still a lack of systematic understanding and
organization of commonly used NLP techniques in RE. We believe one hurdle
facing the industry is lack of shared knowledge of NLP techniques and their
usage in RE tasks. In this paper, we present our effort to synthesize and
organize 57 most frequently used NLP techniques in RE. We classify these NLP
techniques in two ways: first, by their NLP tasks in typical pipelines and
second, by their linguist analysis levels. We believe these two ways of
classification are complementary, contributing to a better understanding of the
NLP techniques in RE and such understanding is crucial to the development of
better NLP tools for RE.",2022-04-08T20:28:00Z,http://arxiv.org/pdf/2204.04282v1,"['cs.CL', 'cs.SE', '68-02', 'A.1; D.m; I.7.m']"
2108.04674v2,Natural Language Processing with Commonsense Knowledge: A Survey,"['Yubo Xie', 'Zonghui Liu', 'Zongyang Ma', 'Fanyuan Meng', 'Yan Xiao', 'Fahui Miao', 'Pearl Pu']","Commonsense knowledge is essential for advancing natural language processing
(NLP) by enabling models to engage in human-like reasoning, which requires a
deeper understanding of context and often involves making inferences based on
implicit external knowledge. This paper explores the integration of commonsense
knowledge into various NLP tasks. We begin by reviewing prominent commonsense
knowledge bases and then discuss the benchmarks used to evaluate the
commonsense reasoning capabilities of NLP models, particularly language models.
Furthermore, we highlight key methodologies for incorporating commonsense
knowledge and their applications across different NLP tasks. The paper also
examines the challenges and emerging trends in enhancing NLP systems with
commonsense reasoning. All literature referenced in this survey can be accessed
via our GitHub repository: https://github.com/yuboxie/awesome-commonsense.",2021-08-10T13:25:29Z,http://arxiv.org/pdf/2108.04674v2,['cs.CL']
1906.08976v1,Mitigating Gender Bias in Natural Language Processing: Literature Review,"['Tony Sun', 'Andrew Gaut', 'Shirlyn Tang', 'Yuxin Huang', 'Mai ElSherief', 'Jieyu Zhao', 'Diba Mirza', 'Elizabeth Belding', 'Kai-Wei Chang', 'William Yang Wang']","As Natural Language Processing (NLP) and Machine Learning (ML) tools rise in
popularity, it becomes increasingly vital to recognize the role they play in
shaping societal biases and stereotypes. Although NLP models have shown success
in modeling various applications, they propagate and may even amplify gender
bias found in text corpora. While the study of bias in artificial intelligence
is not new, methods to mitigate gender bias in NLP are relatively nascent. In
this paper, we review contemporary studies on recognizing and mitigating gender
bias in NLP. We discuss gender bias based on four forms of representation bias
and analyze methods recognizing gender bias. Furthermore, we discuss the
advantages and drawbacks of existing gender debiasing methods. Finally, we
discuss future studies for recognizing and mitigating gender bias in NLP.",2019-06-21T06:39:11Z,http://arxiv.org/pdf/1906.08976v1,['cs.CL']
2109.09138v2,Multi-Task Learning in Natural Language Processing: An Overview,"['Shijie Chen', 'Yu Zhang', 'Qiang Yang']","Deep learning approaches have achieved great success in the field of Natural
Language Processing (NLP). However, directly training deep neural models often
suffer from overfitting and data scarcity problems that are pervasive in NLP
tasks. In recent years, Multi-Task Learning (MTL), which can leverage useful
information of related tasks to achieve simultaneous performance improvement on
these tasks, has been used to handle these problems. In this paper, we give an
overview of the use of MTL in NLP tasks. We first review MTL architectures used
in NLP tasks and categorize them into four classes, including parallel
architecture, hierarchical architecture, modular architecture, and generative
adversarial architecture. Then we present optimization techniques on loss
construction, gradient regularization, data sampling, and task scheduling to
properly train a multi-task model. After presenting applications of MTL in a
variety of NLP tasks, we introduce some benchmark datasets. Finally, we make a
conclusion and discuss several possible research directions in this field.",2021-09-19T14:51:51Z,http://arxiv.org/pdf/2109.09138v2,['cs.AI']
2201.00768v1,"Robust Natural Language Processing: Recent Advances, Challenges, and
  Future Directions","['Marwan Omar', 'Soohyeon Choi', 'DaeHun Nyang', 'David Mohaisen']","Recent natural language processing (NLP) techniques have accomplished high
performance on benchmark datasets, primarily due to the significant improvement
in the performance of deep learning. The advances in the research community
have led to great enhancements in state-of-the-art production systems for NLP
tasks, such as virtual assistants, speech recognition, and sentiment analysis.
However, such NLP systems still often fail when tested with adversarial
attacks. The initial lack of robustness exposed troubling gaps in current
models' language understanding capabilities, creating problems when NLP systems
are deployed in real life. In this paper, we present a structured overview of
NLP robustness research by summarizing the literature in a systemic way across
various dimensions. We then take a deep-dive into the various dimensions of
robustness, across techniques, metrics, embeddings, and benchmarks. Finally, we
argue that robustness should be multi-dimensional, provide insights into
current research, identify gaps in the literature to suggest directions worth
pursuing to address these gaps.",2022-01-03T17:17:11Z,http://arxiv.org/pdf/2201.00768v1,"['cs.CL', 'cs.AI', 'cs.CR', 'cs.HC', 'cs.LG']"
2208.08140v1,Differential Privacy in Natural Language Processing: The Story So Far,"['Oleksandra Klymenko', 'Stephen Meisenbacher', 'Florian Matthes']","As the tide of Big Data continues to influence the landscape of Natural
Language Processing (NLP), the utilization of modern NLP methods has grounded
itself in this data, in order to tackle a variety of text-based tasks. These
methods without a doubt can include private or otherwise personally
identifiable information. As such, the question of privacy in NLP has gained
fervor in recent years, coinciding with the development of new
Privacy-Enhancing Technologies (PETs). Among these PETs, Differential Privacy
boasts several desirable qualities in the conversation surrounding data
privacy. Naturally, the question becomes whether Differential Privacy is
applicable in the largely unstructured realm of NLP. This topic has sparked
novel research, which is unified in one basic goal: how can one adapt
Differential Privacy to NLP methods? This paper aims to summarize the
vulnerabilities addressed by Differential Privacy, the current thinking, and
above all, the crucial next steps that must be considered.",2022-08-17T08:15:44Z,http://arxiv.org/pdf/2208.08140v1,['cs.CL']
2309.10880v1,"Classifying Organizations for Food System Ontologies using Natural
  Language Processing","['Tianyu Jiang', 'Sonia Vinogradova', 'Nathan Stringham', 'E. Louise Earl', 'Allan D. Hollander', 'Patrick R. Huber', 'Ellen Riloff', 'R. Sandra Schillo', 'Giorgio A. Ubbiali', 'Matthew Lange']","Our research explores the use of natural language processing (NLP) methods to
automatically classify entities for the purpose of knowledge graph population
and integration with food system ontologies. We have created NLP models that
can automatically classify organizations with respect to categories associated
with environmental issues as well as Standard Industrial Classification (SIC)
codes, which are used by the U.S. government to characterize business
activities. As input, the NLP models are provided with text snippets retrieved
by the Google search engine for each organization, which serves as a textual
description of the organization that is used for learning. Our experimental
results show that NLP models can achieve reasonably good performance for these
two classification tasks, and they rely on a general framework that could be
applied to many other classification problems as well. We believe that NLP
models represent a promising approach for automatically harvesting information
to populate knowledge graphs and aligning the information with existing
ontologies through shared categories and concepts.",2023-09-19T19:07:48Z,http://arxiv.org/pdf/2309.10880v1,"['cs.CL', 'cs.AI', 'cs.CY', 'cs.IR', 'H.3.1; I.2.7; J.3; J.4; K.4.3']"
2106.06090v2,Graph Neural Networks for Natural Language Processing: A Survey,"['Lingfei Wu', 'Yu Chen', 'Kai Shen', 'Xiaojie Guo', 'Hanning Gao', 'Shucheng Li', 'Jian Pei', 'Bo Long']","Deep learning has become the dominant approach in coping with various tasks
in Natural LanguageProcessing (NLP). Although text inputs are typically
represented as a sequence of tokens, there isa rich variety of NLP problems
that can be best expressed with a graph structure. As a result, thereis a surge
of interests in developing new deep learning techniques on graphs for a large
numberof NLP tasks. In this survey, we present a comprehensive overview onGraph
Neural Networks(GNNs) for Natural Language Processing. We propose a new
taxonomy of GNNs for NLP, whichsystematically organizes existing research of
GNNs for NLP along three axes: graph construction,graph representation
learning, and graph based encoder-decoder models. We further introducea large
number of NLP applications that are exploiting the power of GNNs and summarize
thecorresponding benchmark datasets, evaluation metrics, and open-source codes.
Finally, we discussvarious outstanding challenges for making the full use of
GNNs for NLP as well as future researchdirections. To the best of our
knowledge, this is the first comprehensive overview of Graph NeuralNetworks for
Natural Language Processing.",2021-06-10T23:59:26Z,http://arxiv.org/pdf/2106.06090v2,"['cs.CL', 'cs.LG']"
2106.07410v1,Model Explainability in Deep Learning Based Natural Language Processing,"['Shafie Gholizadeh', 'Nengfeng Zhou']","Machine learning (ML) model explainability has received growing attention,
especially in the area related to model risk and regulations. In this paper, we
reviewed and compared some popular ML model explainability methodologies,
especially those related to Natural Language Processing (NLP) models. We then
applied one of the NLP explainability methods Layer-wise Relevance Propagation
(LRP) to a NLP classification model. We used the LRP method to derive a
relevance score for each word in an instance, which is a local explainability.
The relevance scores are then aggregated together to achieve global variable
importance of the model. Through the case study, we also demonstrated how to
apply the local explainability method to false positive and false negative
instances to discover the weakness of a NLP model. These analysis can help us
to understand NLP models better and reduce the risk due to the black-box nature
of NLP models. We also identified some common issues due to the special natures
of NLP models and discussed how explainability analysis can act as a control to
detect these issues after the model has been trained.",2021-06-14T13:23:20Z,http://arxiv.org/pdf/2106.07410v1,"['cs.AI', 'cs.CL']"
2210.06929v1,On the Explainability of Natural Language Processing Deep Models,"['Julia El Zini', 'Mariette Awad']","While there has been a recent explosion of work on ExplainableAI ExAI on deep
models that operate on imagery and tabular data, textual datasets present new
challenges to the ExAI community. Such challenges can be attributed to the lack
of input structure in textual data, the use of word embeddings that add to the
opacity of the models and the difficulty of the visualization of the inner
workings of deep models when they are trained on textual data.
  Lately, methods have been developed to address the aforementioned challenges
and present satisfactory explanations on Natural Language Processing (NLP)
models. However, such methods are yet to be studied in a comprehensive
framework where common challenges are properly stated and rigorous evaluation
practices and metrics are proposed. Motivated to democratize ExAI methods in
the NLP field, we present in this work a survey that studies model-agnostic as
well as model-specific explainability methods on NLP models. Such methods can
either develop inherently interpretable NLP models or operate on pre-trained
models in a post-hoc manner. We make this distinction and we further decompose
the methods into three categories according to what they explain: (1) word
embeddings (input-level), (2) inner workings of NLP models (processing-level)
and (3) models' decisions (output-level). We also detail the different
evaluation approaches interpretability methods in the NLP field. Finally, we
present a case-study on the well-known neural machine translation in an
appendix and we propose promising future research directions for ExAI in the
NLP field.",2022-10-13T11:59:39Z,http://arxiv.org/pdf/2210.06929v1,"['cs.CL', 'cs.HC']"
2401.01262v2,"Fairness Certification for Natural Language Processing and Large
  Language Models","['Vincent Freiberger', 'Erik Buchmann']","Natural Language Processing (NLP) plays an important role in our daily lives,
particularly due to the enormous progress of Large Language Models (LLM).
However, NLP has many fairness-critical use cases, e.g., as an expert system in
recruitment or as an LLM-based tutor in education. Since NLP is based on human
language, potentially harmful biases can diffuse into NLP systems and produce
unfair results, discriminate against minorities or generate legal issues.
Hence, it is important to develop a fairness certification for NLP approaches.
We follow a qualitative research approach towards a fairness certification for
NLP. In particular, we have reviewed a large body of literature on algorithmic
fairness, and we have conducted semi-structured expert interviews with a wide
range of experts from that area. We have systematically devised six fairness
criteria for NLP, which can be further refined into 18 sub-categories. Our
criteria offer a foundation for operationalizing and testing processes to
certify fairness, both from the perspective of the auditor and the audited
organization.",2024-01-02T16:09:36Z,http://arxiv.org/pdf/2401.01262v2,"['cs.CL', 'cs.AI', 'cs.CY', 'cs.LG', '68T50', 'I.2.7']"
1708.02709v8,Recent Trends in Deep Learning Based Natural Language Processing,"['Tom Young', 'Devamanyu Hazarika', 'Soujanya Poria', 'Erik Cambria']","Deep learning methods employ multiple processing layers to learn hierarchical
representations of data and have produced state-of-the-art results in many
domains. Recently, a variety of model designs and methods have blossomed in the
context of natural language processing (NLP). In this paper, we review
significant deep learning related models and methods that have been employed
for numerous NLP tasks and provide a walk-through of their evolution. We also
summarize, compare and contrast the various models and put forward a detailed
understanding of the past, present and future of deep learning in NLP.",2017-08-09T04:02:17Z,http://arxiv.org/pdf/1708.02709v8,['cs.CL']
2209.00099v2,Efficient Methods for Natural Language Processing: A Survey,"['Marcos Treviso', 'Ji-Ung Lee', 'Tianchu Ji', 'Betty van Aken', 'Qingqing Cao', 'Manuel R. Ciosici', 'Michael Hassid', 'Kenneth Heafield', 'Sara Hooker', 'Colin Raffel', 'Pedro H. Martins', 'André F. T. Martins', 'Jessica Zosa Forde', 'Peter Milder', 'Edwin Simpson', 'Noam Slonim', 'Jesse Dodge', 'Emma Strubell', 'Niranjan Balasubramanian', 'Leon Derczynski', 'Iryna Gurevych', 'Roy Schwartz']","Recent work in natural language processing (NLP) has yielded appealing
results from scaling model parameters and training data; however, using only
scale to improve performance means that resource consumption also grows. Such
resources include data, time, storage, or energy, all of which are naturally
limited and unevenly distributed. This motivates research into efficient
methods that require fewer resources to achieve similar results. This survey
synthesizes and relates current methods and findings in efficient NLP. We aim
to provide both guidance for conducting NLP under limited resources, and point
towards promising research directions for developing more efficient methods.",2022-08-31T20:32:35Z,http://arxiv.org/pdf/2209.00099v2,['cs.CL']
2003.08271v4,Pre-trained Models for Natural Language Processing: A Survey,"['Xipeng Qiu', 'Tianxiang Sun', 'Yige Xu', 'Yunfan Shao', 'Ning Dai', 'Xuanjing Huang']","Recently, the emergence of pre-trained models (PTMs) has brought natural
language processing (NLP) to a new era. In this survey, we provide a
comprehensive review of PTMs for NLP. We first briefly introduce language
representation learning and its research progress. Then we systematically
categorize existing PTMs based on a taxonomy with four perspectives. Next, we
describe how to adapt the knowledge of PTMs to the downstream tasks. Finally,
we outline some potential directions of PTMs for future research. This survey
is purposed to be a hands-on guide for understanding, using, and developing
PTMs for various NLP tasks.",2020-03-18T15:22:51Z,http://arxiv.org/pdf/2003.08271v4,"['cs.CL', 'cs.LG']"
2204.09591v1,A Survey on Bias and Fairness in Natural Language Processing,['Rajas Bansal'],"As NLP models become more integrated with the everyday lives of people, it
becomes important to examine the social effect that the usage of these systems
has. While these models understand language and have increased accuracy on
difficult downstream tasks, there is evidence that these models amplify gender,
racial and cultural stereotypes and lead to a vicious cycle in many settings.
In this survey, we analyze the origins of biases, the definitions of fairness,
and how different subfields of NLP mitigate bias. We finally discuss how future
studies can work towards eradicating pernicious biases from NLP algorithms.",2022-03-06T18:12:30Z,http://arxiv.org/pdf/2204.09591v1,"['cs.CL', 'cs.AI']"
2405.01976v1,Conformal Prediction for Natural Language Processing: A Survey,"['Margarida M. Campos', 'António Farinhas', 'Chrysoula Zerva', 'Mário A. T. Figueiredo', 'André F. T. Martins']","The rapid proliferation of large language models and natural language
processing (NLP) applications creates a crucial need for uncertainty
quantification to mitigate risks such as hallucinations and to enhance
decision-making reliability in critical applications. Conformal prediction is
emerging as a theoretically sound and practically useful framework, combining
flexibility with strong statistical guarantees. Its model-agnostic and
distribution-free nature makes it particularly promising to address the current
shortcomings of NLP systems that stem from the absence of uncertainty
quantification. This paper provides a comprehensive survey of conformal
prediction techniques, their guarantees, and existing applications in NLP,
pointing to directions for future research and open challenges.",2024-05-03T10:00:45Z,http://arxiv.org/pdf/2405.01976v1,"['cs.CL', 'cs.LG']"
1311.6063v5,NILE: Fast Natural Language Processing for Electronic Health Records,"['Sheng Yu', 'Tianrun Cai', 'Tianxi Cai']","Objective: Narrative text in Electronic health records (EHR) contain rich
information for medical and data science studies. This paper introduces the
design and performance of Narrative Information Linear Extraction (NILE), a
natural language processing (NLP) package for EHR analysis that we share with
the medical informatics community. Methods: NILE uses a modified prefix-tree
search algorithm for named entity recognition, which can detect prefix and
suffix sharing. The semantic analyses are implemented as rule-based finite
state machines. Analyses include negation, location, modification, family
history, and ignoring. Result: The processing speed of NILE is hundreds to
thousands times faster than existing NLP software for medical text. The
accuracy of presence analysis of NILE is on par with the best performing models
on the 2010 i2b2/VA NLP challenge data. Conclusion: The speed, accuracy, and
being able to operate via API make NILE a valuable addition to the NLP software
for medical informatics and data science.",2013-11-23T22:39:52Z,http://arxiv.org/pdf/1311.6063v5,['cs.CL']
2004.13832v1,Towards an evolutionary-based approach for natural language processing,"['Luca Manzoni', 'Domagoj Jakobovic', 'Luca Mariot', 'Stjepan Picek', 'Mauro Castelli']","Tasks related to Natural Language Processing (NLP) have recently been the
focus of a large research endeavor by the machine learning community. The
increased interest in this area is mainly due to the success of deep learning
methods. Genetic Programming (GP), however, was not under the spotlight with
respect to NLP tasks. Here, we propose a first proof-of-concept that combines
GP with the well established NLP tool word2vec for the next word prediction
task. The main idea is that, once words have been moved into a vector space,
traditional GP operators can successfully work on vectors, thus producing
meaningful words as the output. To assess the suitability of this approach, we
perform an experimental evaluation on a set of existing newspaper headlines.
Individuals resulting from this (pre-)training phase can be employed as the
initial population in other NLP tasks, like sentence generation, which will be
the focus of future investigations, possibly employing adversarial
co-evolutionary approaches.",2020-04-23T18:44:12Z,http://arxiv.org/pdf/2004.13832v1,"['cs.CL', 'cs.AI', 'cs.NE']"
2003.01200v4,Natural Language Processing Advancements By Deep Learning: A Survey,"['Amirsina Torfi', 'Rouzbeh A. Shirvani', 'Yaser Keneshloo', 'Nader Tavaf', 'Edward A. Fox']","Natural Language Processing (NLP) helps empower intelligent machines by
enhancing a better understanding of the human language for linguistic-based
human-computer communication. Recent developments in computational power and
the advent of large amounts of linguistic data have heightened the need and
demand for automating semantic analysis using data-driven approaches. The
utilization of data-driven strategies is pervasive now due to the significant
improvements demonstrated through the usage of deep learning methods in areas
such as Computer Vision, Automatic Speech Recognition, and in particular, NLP.
This survey categorizes and addresses the different aspects and applications of
NLP that have benefited from deep learning. It covers core NLP tasks and
applications and describes how deep learning methods and models advance these
areas. We further analyze and compare different approaches and state-of-the-art
models.",2020-03-02T21:32:05Z,http://arxiv.org/pdf/2003.01200v4,"['cs.CL', 'cs.AI', 'cs.LG']"
2106.10512v1,TweeNLP: A Twitter Exploration Portal for Natural Language Processing,"['Viraj Shah', 'Shruti Singh', 'Mayank Singh']","We present TweeNLP, a one-stop portal that organizes Twitter's natural
language processing (NLP) data and builds a visualization and exploration
platform. It curates 19,395 tweets (as of April 2021) from various NLP
conferences and general NLP discussions. It supports multiple features such as
TweetExplorer to explore tweets by topics, visualize insights from Twitter
activity throughout the organization cycle of conferences, discover popular
research papers and researchers. It also builds a timeline of conference and
workshop submission deadlines. We envision TweeNLP to function as a collective
memory unit for the NLP community by integrating the tweets pertaining to
research papers with the NLPExplorer scientific literature search engine. The
current system is hosted at http://nlpexplorer.org/twitter/CFP .",2021-06-19T15:11:22Z,http://arxiv.org/pdf/2106.10512v1,"['cs.CL', 'cs.SI']"
2111.13827v3,Natural Language Processing in-and-for Design Research,"['L Siddharth', 'Lucienne T. M. Blessing', 'Jianxi Luo']","We review the scholarly contributions that utilise Natural Language
Processing (NLP) techniques to support the design process. Using a heuristic
approach, we gathered 223 articles that are published in 32 journals within the
period 1991-present. We present state-of-the-art NLP in-and-for design research
by reviewing these articles according to the type of natural language text
sources: internal reports, design concepts, discourse transcripts, technical
publications, consumer opinions, and others. Upon summarizing and identifying
the gaps in these contributions, we utilise an existing design innovation
framework to identify the applications that are currently being supported by
NLP. We then propose a few methodological and theoretical directions for future
NLP in-and-for design research.",2021-11-27T06:32:54Z,http://arxiv.org/pdf/2111.13827v3,"['cs.CL', 'cs.AI', 'cs.DL', 'cs.IR']"
2208.06525v1,"Automated Utterance Labeling of Conversations Using Natural Language
  Processing","['Maria Laricheva', 'Chiyu Zhang', 'Yan Liu', 'Guanyu Chen', 'Terence Tracey', 'Richard Young', 'Giuseppe Carenini']","Conversational data is essential in psychology because it can help
researchers understand individuals cognitive processes, emotions, and
behaviors. Utterance labelling is a common strategy for analyzing this type of
data. The development of NLP algorithms allows researchers to automate this
task. However, psychological conversational data present some challenges to NLP
researchers, including multilabel classification, a large number of classes,
and limited available data. This study explored how automated labels generated
by NLP methods are comparable to human labels in the context of conversations
on adulthood transition. We proposed strategies to handle three common
challenges raised in psychological studies. Our findings showed that the deep
learning method with domain adaptation (RoBERTa-CON) outperformed all other
machine learning methods; and the hierarchical labelling system that we
proposed was shown to help researchers strategically analyze conversational
data. Our Python code and NLP model are available at
https://github.com/mlaricheva/automated_labeling.",2022-08-12T23:03:45Z,http://arxiv.org/pdf/2208.06525v1,['cs.CL']
2302.14286v1,"HugNLP: A Unified and Comprehensive Library for Natural Language
  Processing","['Jianing Wang', 'Nuo Chen', 'Qiushi Sun', 'Wenkang Huang', 'Chengyu Wang', 'Ming Gao']","In this paper, we introduce HugNLP, a unified and comprehensive library for
natural language processing (NLP) with the prevalent backend of HuggingFace
Transformers, which is designed for NLP researchers to easily utilize
off-the-shelf algorithms and develop novel methods with user-defined models and
tasks in real-world scenarios. HugNLP consists of a hierarchical structure
including models, processors and applications that unifies the learning process
of pre-trained language models (PLMs) on different NLP tasks. Additionally, we
present some featured NLP applications to show the effectiveness of HugNLP,
such as knowledge-enhanced PLMs, universal information extraction, low-resource
mining, and code understanding and generation, etc. The source code will be
released on GitHub (https://github.com/wjn1996/HugNLP).",2023-02-28T03:38:26Z,http://arxiv.org/pdf/2302.14286v1,['cs.CL']
2307.10652v5,Exploring the Landscape of Natural Language Processing Research,"['Tim Schopf', 'Karim Arabi', 'Florian Matthes']","As an efficient approach to understand, generate, and process natural
language texts, research in natural language processing (NLP) has exhibited a
rapid spread and wide adoption in recent years. Given the increasing research
work in this area, several NLP-related approaches have been surveyed in the
research community. However, a comprehensive study that categorizes established
topics, identifies trends, and outlines areas for future research remains
absent. Contributing to closing this gap, we have systematically classified and
analyzed research papers in the ACL Anthology. As a result, we present a
structured overview of the research landscape, provide a taxonomy of fields of
study in NLP, analyze recent developments in NLP, summarize our findings, and
highlight directions for future work.",2023-07-20T07:33:30Z,http://arxiv.org/pdf/2307.10652v5,"['cs.CL', 'I.2.7']"
2503.00624v1,"An evaluation of DeepSeek Models in Biomedical Natural Language
  Processing","['Zaifu Zhan', 'Shuang Zhou', 'Huixue Zhou', 'Jiawen Deng', 'Yu Hou', 'Jeremy Yeung', 'Rui Zhang']","The advancement of Large Language Models (LLMs) has significantly impacted
biomedical Natural Language Processing (NLP), enhancing tasks such as named
entity recognition, relation extraction, event extraction, and text
classification. In this context, the DeepSeek series of models have shown
promising potential in general NLP tasks, yet their capabilities in the
biomedical domain remain underexplored. This study evaluates multiple DeepSeek
models (Distilled-DeepSeek-R1 series and Deepseek-LLMs) across four key
biomedical NLP tasks using 12 datasets, benchmarking them against
state-of-the-art alternatives (Llama3-8B, Qwen2.5-7B, Mistral-7B, Phi-4-14B,
Gemma-2-9B). Our results reveal that while DeepSeek models perform
competitively in named entity recognition and text classification, challenges
persist in event and relation extraction due to precision-recall trade-offs. We
provide task-specific model recommendations and highlight future research
directions. This evaluation underscores the strengths and limitations of
DeepSeek models in biomedical NLP, guiding their future deployment and
optimization.",2025-03-01T21:26:29Z,http://arxiv.org/pdf/2503.00624v1,"['cs.CL', 'cs.AI']"
2505.16061v1,Internal and External Impacts of Natural Language Processing Papers,['Yu Zhang'],"We investigate the impacts of NLP research published in top-tier conferences
(i.e., ACL, EMNLP, and NAACL) from 1979 to 2024. By analyzing citations from
research articles and external sources such as patents, media, and policy
documents, we examine how different NLP topics are consumed both within the
academic community and by the broader public. Our findings reveal that language
modeling has the widest internal and external influence, while linguistic
foundations have lower impacts. We also observe that internal and external
impacts generally align, but topics like ethics, bias, and fairness show
significant attention in policy documents with much fewer academic citations.
Additionally, external domains exhibit distinct preferences, with patents
focusing on practical NLP applications and media and policy documents engaging
more with the societal implications of NLP models.",2025-05-21T22:25:58Z,http://arxiv.org/pdf/2505.16061v1,"['cs.CL', 'cs.DL']"
9704010v1,The Theoretical Status of Ontologies in Natural Language Processing,['John A. Bateman'],"This paper discusses the use of `ontologies' in Natural Language Processing.
It classifies various kinds of ontologies that have been employed in NLP and
discusses various benefits and problems with those designs. Particular focus is
then placed on experiences gained in the use of the Upper Model, a
linguistically-motivated `ontology' originally designed for use with the Penman
text generation system. Some proposals for further NLP ontology design criteria
are then made.",1997-04-25T13:00:14Z,http://arxiv.org/pdf/cmp-lg/9704010v1,"['cmp-lg', 'cs.CL']"
2210.10109v2,A Survey of Active Learning for Natural Language Processing,"['Zhisong Zhang', 'Emma Strubell', 'Eduard Hovy']","In this work, we provide a survey of active learning (AL) for its
applications in natural language processing (NLP). In addition to a
fine-grained categorization of query strategies, we also investigate several
other important aspects of applying AL to NLP problems. These include AL for
structured prediction tasks, annotation cost, model learning (especially with
deep neural models), and starting and stopping AL. Finally, we conclude with a
discussion of related topics and future directions.",2022-10-18T19:14:42Z,http://arxiv.org/pdf/2210.10109v2,['cs.CL']
2405.06563v1,What Can Natural Language Processing Do for Peer Review?,"['Ilia Kuznetsov', 'Osama Mohammed Afzal', 'Koen Dercksen', 'Nils Dycke', 'Alexander Goldberg', 'Tom Hope', 'Dirk Hovy', 'Jonathan K. Kummerfeld', 'Anne Lauscher', 'Kevin Leyton-Brown', 'Sheng Lu', 'Mausam', 'Margot Mieskes', 'Aurélie Névéol', 'Danish Pruthi', 'Lizhen Qu', 'Roy Schwartz', 'Noah A. Smith', 'Thamar Solorio', 'Jingyan Wang', 'Xiaodan Zhu', 'Anna Rogers', 'Nihar B. Shah', 'Iryna Gurevych']","The number of scientific articles produced every year is growing rapidly.
Providing quality control over them is crucial for scientists and, ultimately,
for the public good. In modern science, this process is largely delegated to
peer review -- a distributed procedure in which each submission is evaluated by
several independent experts in the field. Peer review is widely used, yet it is
hard, time-consuming, and prone to error. Since the artifacts involved in peer
review -- manuscripts, reviews, discussions -- are largely text-based, Natural
Language Processing has great potential to improve reviewing. As the emergence
of large language models (LLMs) has enabled NLP assistance for many new tasks,
the discussion on machine-assisted peer review is picking up the pace. Yet,
where exactly is help needed, where can NLP help, and where should it stand
aside? The goal of our paper is to provide a foundation for the future efforts
in NLP for peer-reviewing assistance. We discuss peer review as a general
process, exemplified by reviewing at AI conferences. We detail each step of the
process from manuscript submission to camera-ready revision, and discuss the
associated challenges and opportunities for NLP assistance, illustrated by
existing work. We then turn to the big challenges in NLP for peer review as a
whole, including data acquisition and licensing, operationalization and
experimentation, and ethical issues. To help consolidate community efforts, we
create a companion repository that aggregates key datasets pertaining to peer
review. Finally, we issue a detailed call for action for the scientific
community, NLP and AI researchers, policymakers, and funding bodies to help
bring the research in NLP for peer review forward. We hope that our work will
help set the agenda for research in machine-assisted scientific quality control
in the age of AI, within the NLP community and beyond.",2024-05-10T16:06:43Z,http://arxiv.org/pdf/2405.06563v1,['cs.CL']
2401.05632v4,Natural Language Processing for Dialects of a Language: A Survey,"['Aditya Joshi', 'Raj Dabre', 'Diptesh Kanojia', 'Zhuang Li', 'Haolan Zhan', 'Gholamreza Haffari', 'Doris Dippold']","State-of-the-art natural language processing (NLP) models are trained on
massive training corpora, and report a superlative performance on evaluation
datasets. This survey delves into an important attribute of these datasets: the
dialect of a language. Motivated by the performance degradation of NLP models
for dialectal datasets and its implications for the equity of language
technologies, we survey past research in NLP for dialects in terms of datasets,
and approaches. We describe a wide range of NLP tasks in terms of two
categories: natural language understanding (NLU) (for tasks such as dialect
classification, sentiment analysis, parsing, and NLU benchmarks) and natural
language generation (NLG) (for summarisation, machine translation, and dialogue
systems). The survey is also broad in its coverage of languages which include
English, Arabic, German, among others. We observe that past work in NLP
concerning dialects goes deeper than mere dialect classification, and extends
to several NLU and NLG tasks. For these tasks, we describe classical machine
learning using statistical models, along with the recent deep learning-based
approaches based on pre-trained language models. We expect that this survey
will be useful to NLP researchers interested in building equitable language
technologies by rethinking LLM benchmarks and model architectures.",2024-01-11T03:04:38Z,http://arxiv.org/pdf/2401.05632v4,['cs.CL']
2412.15471v2,A Review of the Marathi Natural Language Processing,"['Asang Dani', 'Shailesh R Sathe']","Marathi is one of the most widely used languages in the world. One might
expect that the latest advances in NLP research in languages like English reach
such a large community. However, NLP advancements in English didn't immediately
reach Indian languages like Marathi. There were several reasons for this. They
included diversity of scripts used, lack of (publicly available) resources like
tokenization strategies, high quality datasets \& benchmarks, and evaluation
metrics. In addition to this, the morphologically rich nature of Marathi, made
NLP tasks challenging. Advances in Neural Network (NN) based models and tools
since the early 2000s helped improve this situation and make NLP research more
accessible. In the past 10 years, significant efforts were made to improve
language resources for all 22 scheduled languages of India. This paper presents
a broad overview of evolution of NLP research in Indic languages with a focus
on Marathi and state-of-the-art resources and tools available to the research
community. It also provides an overview of tools \& techniques associated with
Marathi NLP tasks.",2024-12-20T00:56:13Z,http://arxiv.org/pdf/2412.15471v2,"['cs.CL', 'I.2.7']"
2501.10319v1,Natural Language Processing of Privacy Policies: A Survey,"['Andrick Adhikari', 'Sanchari Das', 'Rinku Dewri']","Natural Language Processing (NLP) is an essential subset of artificial
intelligence. It has become effective in several domains, such as healthcare,
finance, and media, to identify perceptions, opinions, and misuse, among
others. Privacy is no exception, and initiatives have been taken to address the
challenges of usable privacy notifications to users with the help of NLP. To
this aid, we conduct a literature review by analyzing 109 papers at the
intersection of NLP and privacy policies. First, we provide a brief
introduction to privacy policies and discuss various facets of associated
problems, which necessitate the application of NLP to elevate the current state
of privacy notices and disclosures to users. Subsequently, we a) provide an
overview of the implementation and effectiveness of NLP approaches for better
privacy policy communication; b) identify the methodologies that can be further
enhanced to provide robust privacy policies; and c) identify the gaps in the
current state-of-the-art research. Our systematic analysis reveals that several
research papers focus on annotating and classifying privacy texts for analysis
but need to adequately dwell on other aspects of NLP applications, such as
summarization. More specifically, ample research opportunities exist in this
domain, covering aspects such as corpus generation, summarization vectors,
contextualized word embedding, identification of privacy-relevant statement
categories, fine-grained classification, and domain-specific model tuning.",2025-01-17T17:47:15Z,http://arxiv.org/pdf/2501.10319v1,['cs.CL']
2506.22481v1,"Theories of ""Sexuality"" in Natural Language Processing Bias Research",['Jacob Hobbs'],"In recent years, significant advancements in the field of Natural Language
Processing (NLP) have positioned commercialized language models as
wide-reaching, highly useful tools. In tandem, there has been an explosion of
multidisciplinary research examining how NLP tasks reflect, perpetuate, and
amplify social biases such as gender and racial bias. A significant gap in this
scholarship is a detailed analysis of how queer sexualities are encoded and
(mis)represented by both NLP systems and practitioners. Following previous work
in the field of AI fairness, we document how sexuality is defined and
operationalized via a survey and analysis of 55 articles that quantify
sexuality-based NLP bias. We find that sexuality is not clearly defined in a
majority of the literature surveyed, indicating a reliance on assumed or
normative conceptions of sexual/romantic practices and identities. Further, we
find that methods for extracting biased outputs from NLP technologies often
conflate gender and sexual identities, leading to monolithic conceptions of
queerness and thus improper quantifications of bias. With the goal of improving
sexuality-based NLP bias analyses, we conclude with recommendations that
encourage more thorough engagement with both queer communities and
interdisciplinary literature.",2025-06-22T18:16:53Z,http://arxiv.org/pdf/2506.22481v1,"['cs.CY', 'cs.CL']"
1707.01890v2,An Interactive Tool for Natural Language Processing on Clinical Text,"['Gaurav Trivedi', 'Phuong Pham', 'Wendy Chapman', 'Rebecca Hwa', 'Janyce Wiebe', 'Harry Hochheiser']","Natural Language Processing (NLP) systems often make use of machine learning
techniques that are unfamiliar to end-users who are interested in analyzing
clinical records. Although NLP has been widely used in extracting information
from clinical text, current systems generally do not support model revision
based on feedback from domain experts.
  We present a prototype tool that allows end users to visualize and review the
outputs of an NLP system that extracts binary variables from clinical text. Our
tool combines multiple visualizations to help the users understand these
results and make any necessary corrections, thus forming a feedback loop and
helping improve the accuracy of the NLP models. We have tested our prototype in
a formative think-aloud user study with clinicians and researchers involved in
colonoscopy research. Results from semi-structured interviews and a System
Usability Scale (SUS) analysis show that the users are able to quickly start
refining NLP models, despite having very little or no experience with machine
learning. Observations from these sessions suggest revisions to the interface
to better support review workflow and interpretation of results.",2017-07-06T17:44:15Z,http://arxiv.org/pdf/1707.01890v2,"['cs.HC', 'cs.CL', 'cs.IR']"
1902.00679v1,"Natural Language Processing, Sentiment Analysis and Clinical Analytics",['Adil Rajput'],"Recent advances in Big Data has prompted health care practitioners to utilize
the data available on social media to discern sentiment and emotions
expression. Health Informatics and Clinical Analytics depend heavily on
information gathered from diverse sources. Traditionally, a healthcare
practitioner will ask a patient to fill out a questionnaire that will form the
basis of diagnosing the medical condition. However, medical practitioners have
access to many sources of data including the patients writings on various
media. Natural Language Processing (NLP) allows researchers to gather such data
and analyze it to glean the underlying meaning of such writings. The field of
sentiment analysis (applied to many other domains) depend heavily on techniques
utilized by NLP. This work will look into various prevalent theories underlying
the NLP field and how they can be leveraged to gather users sentiments on
social media. Such sentiments can be culled over a period of time thus
minimizing the errors introduced by data input and other stressors.
Furthermore, we look at some applications of sentiment analysis and application
of NLP to mental health. The reader will also learn about the NLTK toolkit that
implements various NLP theories and how they can make the data scavenging
process a lot easier.",2019-02-02T09:30:26Z,http://arxiv.org/pdf/1902.00679v1,['cs.CL']
2110.10470v2,"Interpreting Deep Learning Models in Natural Language Processing: A
  Review","['Xiaofei Sun', 'Diyi Yang', 'Xiaoya Li', 'Tianwei Zhang', 'Yuxian Meng', 'Han Qiu', 'Guoyin Wang', 'Eduard Hovy', 'Jiwei Li']","Neural network models have achieved state-of-the-art performances in a wide
range of natural language processing (NLP) tasks. However, a long-standing
criticism against neural network models is the lack of interpretability, which
not only reduces the reliability of neural NLP systems but also limits the
scope of their applications in areas where interpretability is essential (e.g.,
health care applications). In response, the increasing interest in interpreting
neural NLP models has spurred a diverse array of interpretation methods over
recent years. In this survey, we provide a comprehensive review of various
interpretation methods for neural models in NLP. We first stretch out a
high-level taxonomy for interpretation methods in NLP, i.e., training-based
approaches, test-based approaches, and hybrid approaches. Next, we describe
sub-categories in each category in detail, e.g., influence-function based
methods, KNN-based methods, attention-based models, saliency-based methods,
perturbation-based methods, etc. We point out deficiencies of current methods
and suggest some avenues for future research.",2021-10-20T10:17:04Z,http://arxiv.org/pdf/2110.10470v2,['cs.CL']
2306.04459v1,"Uncertainty in Natural Language Processing: Sources, Quantification, and
  Applications","['Mengting Hu', 'Zhen Zhang', 'Shiwan Zhao', 'Minlie Huang', 'Bingzhe Wu']","As a main field of artificial intelligence, natural language processing (NLP)
has achieved remarkable success via deep neural networks. Plenty of NLP tasks
have been addressed in a unified manner, with various tasks being associated
with each other through sharing the same paradigm. However, neural networks are
black boxes and rely on probability computation. Making mistakes is inevitable.
Therefore, estimating the reliability and trustworthiness (in other words,
uncertainty) of neural networks becomes a key research direction, which plays a
crucial role in reducing models' risks and making better decisions. Therefore,
in this survey, we provide a comprehensive review of uncertainty-relevant works
in the NLP field. Considering the data and paradigms characteristics, we first
categorize the sources of uncertainty in natural language into three types,
including input, system, and output. Then, we systemically review uncertainty
quantification approaches and the main applications. Finally, we discuss the
challenges of uncertainty estimation in NLP and discuss potential future
directions, taking into account recent trends in the field. Though there have
been a few surveys about uncertainty estimation, our work is the first to
review uncertainty from the NLP perspective.",2023-06-05T06:46:53Z,http://arxiv.org/pdf/2306.04459v1,['cs.CL']
2401.17911v1,"SNNLP: Energy-Efficient Natural Language Processing Using Spiking Neural
  Networks","['R. Alexander Knipper', 'Kaniz Mishty', 'Mehdi Sadi', 'Shubhra Kanti Karmaker Santu']","As spiking neural networks receive more attention, we look toward
applications of this computing paradigm in fields other than computer vision
and signal processing. One major field, underexplored in the neuromorphic
setting, is Natural Language Processing (NLP), where most state-of-the-art
solutions still heavily rely on resource-consuming and power-hungry traditional
deep learning architectures. Therefore, it is compelling to design NLP models
for neuromorphic architectures due to their low energy requirements, with the
additional benefit of a more human-brain-like operating model for processing
information. However, one of the biggest issues with bringing NLP to the
neuromorphic setting is in properly encoding text into a spike train so that it
can be seamlessly handled by both current and future SNN architectures. In this
paper, we compare various methods of encoding text as spikes and assess each
method's performance in an associated SNN on a downstream NLP task, namely,
sentiment analysis. Furthermore, we go on to propose a new method of encoding
text as spikes that outperforms a widely-used rate-coding technique, Poisson
rate-coding, by around 13\% on our benchmark NLP tasks. Subsequently, we
demonstrate the energy efficiency of SNNs implemented in hardware for the
sentiment analysis task compared to traditional deep neural networks, observing
an energy efficiency increase of more than 32x during inference and 60x during
training while incurring the expected energy-performance tradeoff.",2024-01-31T15:16:25Z,http://arxiv.org/pdf/2401.17911v1,['cs.CL']
2004.13922v2,Revisiting Pre-Trained Models for Chinese Natural Language Processing,"['Yiming Cui', 'Wanxiang Che', 'Ting Liu', 'Bing Qin', 'Shijin Wang', 'Guoping Hu']","Bidirectional Encoder Representations from Transformers (BERT) has shown
marvelous improvements across various NLP tasks, and consecutive variants have
been proposed to further improve the performance of the pre-trained language
models. In this paper, we target on revisiting Chinese pre-trained language
models to examine their effectiveness in a non-English language and release the
Chinese pre-trained language model series to the community. We also propose a
simple but effective model called MacBERT, which improves upon RoBERTa in
several ways, especially the masking strategy that adopts MLM as correction
(Mac). We carried out extensive experiments on eight Chinese NLP tasks to
revisit the existing pre-trained language models as well as the proposed
MacBERT. Experimental results show that MacBERT could achieve state-of-the-art
performances on many NLP tasks, and we also ablate details with several
findings that may help future research. Resources available:
https://github.com/ymcui/MacBERT",2020-04-29T02:08:30Z,http://arxiv.org/pdf/2004.13922v2,['cs.CL']
2108.08252v1,Deep Natural Language Processing for LinkedIn Search Systems,"['Weiwei Guo', 'Xiaowei Liu', 'Sida Wang', 'Michaeel Kazi', 'Zhoutong Fu', 'Huiji Gao', 'Jun Jia', 'Liang Zhang', 'Bo Long']","Many search systems work with large amounts of natural language data, e.g.,
search queries, user profiles and documents, where deep learning based natural
language processing techniques (deep NLP) can be of great help. In this paper,
we introduce a comprehensive study of applying deep NLP techniques to five
representative tasks in search engines. Through the model design and
experiments of the five tasks, readers can find answers to three important
questions: (1) When is deep NLP helpful/not helpful in search systems? (2) How
to address latency challenges? (3) How to ensure model robustness? This work
builds on existing efforts of LinkedIn search, and is tested at scale on a
commercial search engine. We believe our experiences can provide useful
insights for the industry and research communities.",2021-07-30T17:40:36Z,http://arxiv.org/pdf/2108.08252v1,"['cs.CL', 'cs.AI']"
1907.01055v2,"Is artificial data useful for biomedical Natural Language Processing
  algorithms?","['Zixu Wang', 'Julia Ive', 'Sumithra Velupillai', 'Lucia Specia']","A major obstacle to the development of Natural Language Processing (NLP)
methods in the biomedical domain is data accessibility. This problem can be
addressed by generating medical data artificially. Most previous studies have
focused on the generation of short clinical text, and evaluation of the data
utility has been limited. We propose a generic methodology to guide the
generation of clinical text with key phrases. We use the artificial data as
additional training data in two key biomedical NLP tasks: text classification
and temporal relation extraction. We show that artificially generated training
data used in conjunction with real training data can lead to performance boosts
for data-greedy neural network algorithms. We also demonstrate the usefulness
of the generated data for NLP setups where it fully replaces real training
data.",2019-07-01T20:17:59Z,http://arxiv.org/pdf/1907.01055v2,"['cs.CL', 'cs.LG']"
1906.04393v1,"Lightweight and Efficient Neural Natural Language Processing with
  Quaternion Networks","['Yi Tay', 'Aston Zhang', 'Luu Anh Tuan', 'Jinfeng Rao', 'Shuai Zhang', 'Shuohang Wang', 'Jie Fu', 'Siu Cheung Hui']","Many state-of-the-art neural models for NLP are heavily parameterized and
thus memory inefficient. This paper proposes a series of lightweight and memory
efficient neural architectures for a potpourri of natural language processing
(NLP) tasks. To this end, our models exploit computation using Quaternion
algebra and hypercomplex spaces, enabling not only expressive inter-component
interactions but also significantly ($75\%$) reduced parameter size due to
lesser degrees of freedom in the Hamilton product. We propose Quaternion
variants of models, giving rise to new architectures such as the Quaternion
attention Model and Quaternion Transformer. Extensive experiments on a battery
of NLP tasks demonstrates the utility of proposed Quaternion-inspired models,
enabling up to $75\%$ reduction in parameter size without significant loss in
performance.",2019-06-11T04:56:17Z,http://arxiv.org/pdf/1906.04393v1,"['cs.CL', 'cs.LG']"
2112.13969v1,"LINDA: Unsupervised Learning to Interpolate in Natural Language
  Processing","['Yekyung Kim', 'Seohyeong Jeong', 'Kyunghyun Cho']","Despite the success of mixup in data augmentation, its applicability to
natural language processing (NLP) tasks has been limited due to the discrete
and variable-length nature of natural languages. Recent studies have thus
relied on domain-specific heuristics and manually crafted resources, such as
dictionaries, in order to apply mixup in NLP. In this paper, we instead propose
an unsupervised learning approach to text interpolation for the purpose of data
augmentation, to which we refer as ""Learning to INterpolate for Data
Augmentation"" (LINDA), that does not require any heuristics nor manually
crafted resources but learns to interpolate between any pair of natural
language sentences over a natural language manifold. After empirically
demonstrating the LINDA's interpolation capability, we show that LINDA indeed
allows us to seamlessly apply mixup in NLP and leads to better generalization
in text classification both in-domain and out-of-domain.",2021-12-28T02:56:41Z,http://arxiv.org/pdf/2112.13969v1,"['cs.CL', 'cs.LG']"
2307.13693v2,"Evaluating Large Language Models for Radiology Natural Language
  Processing","['Zhengliang Liu', 'Tianyang Zhong', 'Yiwei Li', 'Yutong Zhang', 'Yi Pan', 'Zihao Zhao', 'Peixin Dong', 'Chao Cao', 'Yuxiao Liu', 'Peng Shu', 'Yaonai Wei', 'Zihao Wu', 'Chong Ma', 'Jiaqi Wang', 'Sheng Wang', 'Mengyue Zhou', 'Zuowei Jiang', 'Chunlin Li', 'Jason Holmes', 'Shaochen Xu', 'Lu Zhang', 'Haixing Dai', 'Kai Zhang', 'Lin Zhao', 'Yuanhao Chen', 'Xu Liu', 'Peilong Wang', 'Pingkun Yan', 'Jun Liu', 'Bao Ge', 'Lichao Sun', 'Dajiang Zhu', 'Xiang Li', 'Wei Liu', 'Xiaoyan Cai', 'Xintao Hu', 'Xi Jiang', 'Shu Zhang', 'Xin Zhang', 'Tuo Zhang', 'Shijie Zhao', 'Quanzheng Li', 'Hongtu Zhu', 'Dinggang Shen', 'Tianming Liu']","The rise of large language models (LLMs) has marked a pivotal shift in the
field of natural language processing (NLP). LLMs have revolutionized a
multitude of domains, and they have made a significant impact in the medical
field. Large language models are now more abundant than ever, and many of these
models exhibit bilingual capabilities, proficient in both English and Chinese.
However, a comprehensive evaluation of these models remains to be conducted.
This lack of assessment is especially apparent within the context of radiology
NLP. This study seeks to bridge this gap by critically evaluating thirty two
LLMs in interpreting radiology reports, a crucial component of radiology NLP.
Specifically, the ability to derive impressions from radiologic findings is
assessed. The outcomes of this evaluation provide key insights into the
performance, strengths, and weaknesses of these LLMs, informing their practical
applications within the medical domain.",2023-07-25T17:57:18Z,http://arxiv.org/pdf/2307.13693v2,['cs.CL']
2507.17974v2,"Natural Language Processing for Tigrinya: Current State and Future
  Directions","['Fitsum Gaim', 'Jong C. Park']","Despite being spoken by millions of people, Tigrinya remains severely
underrepresented in Natural Language Processing (NLP) research. This work
presents a comprehensive survey of NLP research for Tigrinya, analyzing over 40
studies spanning more than a decade of work from 2011 to 2025. We
systematically review the current state of computational resources, models, and
applications across ten distinct downstream tasks, including morphological
processing, machine translation, speech recognition, and question-answering.
Our analysis reveals a clear trajectory from foundational, rule-based systems
to modern neural architectures, with progress consistently unlocked by resource
creation milestones. We identify key challenges rooted in Tigrinya's
morphological complexity and resource scarcity, while highlighting promising
research directions, including morphology-aware modeling, cross-lingual
transfer, and community-centered resource development. This work serves as both
a comprehensive reference for researchers and a roadmap for advancing Tigrinya
NLP. A curated metadata of the surveyed studies and resources is made publicly
available.",2025-07-23T22:45:30Z,http://arxiv.org/pdf/2507.17974v2,"['cs.CL', 'cs.AI', 'I.2.7']"
1407.6099v1,"Autonomous requirements specification processing using natural language
  processing","['S. G. Macdonell', 'K. Min', 'A. M. Connor']","We describe our ongoing research that centres on the application of natural
language processing (NLP) to software engineering and systems development
activities. In particular, this paper addresses the use of NLP in the
requirements analysis and systems design processes. We have developed a
prototype toolset that can assist the systems analyst or software engineer to
select and verify terms relevant to a project. In this paper we describe the
processes employed by the system to extract and classify objects of interest
from requirements documents. These processes are illustrated using a small
example.",2014-07-23T03:29:44Z,http://arxiv.org/pdf/1407.6099v1,"['cs.CL', 'cs.SE']"
1508.05154v2,"Posterior calibration and exploratory analysis for natural language
  processing models","['Khanh Nguyen', ""Brendan O'Connor""]","Many models in natural language processing define probabilistic distributions
over linguistic structures. We argue that (1) the quality of a model' s
posterior distribution can and should be directly evaluated, as to whether
probabilities correspond to empirical frequencies, and (2) NLP uncertainty can
be projected not only to pipeline components, but also to exploratory data
analysis, telling a user when to trust and not trust the NLP analysis. We
present a method to analyze calibration, and apply it to compare the
miscalibration of several commonly used models. We also contribute a
coreference sampling algorithm that can create confidence intervals for a
political event extraction task.",2015-08-21T00:25:51Z,http://arxiv.org/pdf/1508.05154v2,['cs.CL']
2103.07929v2,"A Systematic Review of Reproducibility Research in Natural Language
  Processing","['Anya Belz', 'Shubham Agarwal', 'Anastasia Shimorina', 'Ehud Reiter']","Against the background of what has been termed a reproducibility crisis in
science, the NLP field is becoming increasingly interested in, and
conscientious about, the reproducibility of its results. The past few years
have seen an impressive range of new initiatives, events and active research in
the area. However, the field is far from reaching a consensus about how
reproducibility should be defined, measured and addressed, with diversity of
views currently increasing rather than converging. With this focused
contribution, we aim to provide a wide-angle, and as near as possible complete,
snapshot of current work on reproducibility in NLP, delineating differences and
similarities, and providing pointers to common denominators.",2021-03-14T13:53:05Z,http://arxiv.org/pdf/2103.07929v2,['cs.CL']
2204.06251v2,"Experimental Standards for Deep Learning in Natural Language Processing
  Research","['Dennis Ulmer', 'Elisa Bassignana', 'Max Müller-Eberstein', 'Daniel Varab', 'Mike Zhang', 'Rob van der Goot', 'Christian Hardmeier', 'Barbara Plank']","The field of Deep Learning (DL) has undergone explosive growth during the
last decade, with a substantial impact on Natural Language Processing (NLP) as
well. Yet, compared to more established disciplines, a lack of common
experimental standards remains an open challenge to the field at large.
Starting from fundamental scientific principles, we distill ongoing discussions
on experimental standards in NLP into a single, widely-applicable methodology.
Following these best practices is crucial to strengthen experimental evidence,
improve reproducibility and support scientific progress. These standards are
further collected in a public repository to help them transparently adapt to
future needs.",2022-04-13T08:42:52Z,http://arxiv.org/pdf/2204.06251v2,"['cs.LG', 'cs.CL']"
2504.08910v1,"Assessing Physics Students' Scientific Argumentation using Natural
  Language Processing","['Winter Allen', 'Carina M. Rebello', 'N. Sanjay Rebello']","Scientific argumentation is an important science and engineering practice and
a necessary 21st Century workforce skill. Due to the nature of large enrollment
classes, it is difficult to individually assess students and provide feedback
on their argumentation. The recent developments in Natural Language Processing
(NLP) and Machine Learning (ML) may provide a solution. In this study we
investigate methods using NLP and ML to assess and understand students'
argumentation. Specifically, we investigate the use of topic modeling to
analyze student essays of argumentation after solving a problem in the
recitation section of an introductory calculus-based physics course four
semesters. We report on the emergent themes present in each semester.",2025-04-11T18:25:10Z,http://arxiv.org/pdf/2504.08910v1,['physics.ed-ph']
1301.3547v1,A Rhetorical Analysis Approach to Natural Language Processing,['Benjamin Englard'],"The goal of this research was to find a way to extend the capabilities of
computers through the processing of language in a more human way, and present
applications which demonstrate the power of this method. This research presents
a novel approach, Rhetorical Analysis, to solving problems in Natural Language
Processing (NLP). The main benefit of Rhetorical Analysis, as opposed to
previous approaches, is that it does not require the accumulation of large sets
of training data, but can be used to solve a multitude of problems within the
field of NLP. The NLP problems investigated with Rhetorical Analysis were the
Author Identification problem - predicting the author of a piece of text based
on its rhetorical strategies, Election Prediction - predicting the winner of a
presidential candidate's re-election campaign based on rhetorical strategies
within that president's inaugural address, Natural Language Generation - having
a computer produce text containing rhetorical strategies, and Document
Summarization. The results of this research indicate that an Author
Identification system based on Rhetorical Analysis could predict the correct
author 100% of the time, that a re-election predictor based on Rhetorical
Analysis could predict the correct winner of a re-election campaign 55% of the
time, that a Natural Language Generation system based on Rhetorical Analysis
could output text with up to 87.3% similarity to Shakespeare in style, and that
a Document Summarization system based on Rhetorical Analysis could extract
highly relevant sentences. Overall, this study demonstrated that Rhetorical
Analysis could be a useful approach to solving problems in NLP.",2013-01-16T01:42:53Z,http://arxiv.org/pdf/1301.3547v1,"['cs.CL', 'stat.ML']"
1811.00770v2,A Survey on Natural Language Processing for Fake News Detection,"['Ray Oshikawa', 'Jing Qian', 'William Yang Wang']","Fake news detection is a critical yet challenging problem in Natural Language
Processing (NLP). The rapid rise of social networking platforms has not only
yielded a vast increase in information accessibility but has also accelerated
the spread of fake news. Thus, the effect of fake news has been growing,
sometimes extending to the offline world and threatening public safety. Given
the massive amount of Web content, automatic fake news detection is a practical
NLP problem useful to all online content providers, in order to reduce the
human time and effort to detect and prevent the spread of fake news. In this
paper, we describe the challenges involved in fake news detection and also
describe related tasks. We systematically review and compare the task
formulations, datasets and NLP solutions that have been developed for this
task, and also discuss the potentials and limitations of them. Based on our
insights, we outline promising research directions, including more
fine-grained, detailed, fair, and practical detection models. We also highlight
the difference between fake news detection and other related tasks, and the
importance of NLP solutions for fake news detection.",2018-11-02T08:10:21Z,http://arxiv.org/pdf/1811.00770v2,"['cs.CL', 'cs.AI']"
2104.04069v2,A survey on extremism analysis using Natural Language Processing,"['Javier Torregrosa', 'Gema Bello-Orgaz', 'Eugenio Martinez-Camara', 'Javier Del Ser', 'David Camacho']","Extremism research has grown as an open problem for several countries during
recent years, especially due to the apparition of movements such as jihadism.
This and other extremist groups have taken advantage of different approaches,
such as the use of Social Media, to spread their ideology, promote their acts
and recruit followers. Natural Language Processing (NLP) represents a way of
detecting this type of content, and several authors make use of it to describe
and discriminate the discourse held by this groups, with the final objective of
detecting and preventing its spread. This survey aims to review the
contributions of NLP to the field of extremism research, providing the reader
with a comprehensive picture of the state of the art of this research area. The
content includes a description and comparison of the frequently used NLP
techniques, how they were applied, the insights they provided, the most
frequently used NLP software tools and the availability of datasets and data
sources for research. Finally, research questions are approached and answered
with highlights from the review, while future trends, challenges and directions
derived from these highlights are suggested.",2021-03-28T11:05:43Z,http://arxiv.org/pdf/2104.04069v2,['cs.CY']
2104.06535v1,NPE: An FPGA-based Overlay Processor for Natural Language Processing,"['Hamza Khan', 'Asma Khan', 'Zainab Khan', 'Lun Bin Huang', 'Kun Wang', 'Lei He']","In recent years, transformer-based models have shown state-of-the-art results
for Natural Language Processing (NLP). In particular, the introduction of the
BERT language model brought with it breakthroughs in tasks such as question
answering and natural language inference, advancing applications that allow
humans to interact naturally with embedded devices. FPGA-based overlay
processors have been shown as effective solutions for edge image and video
processing applications, which mostly rely on low precision linear matrix
operations. In contrast, transformer-based NLP techniques employ a variety of
higher precision nonlinear operations with significantly higher frequency. We
present NPE, an FPGA-based overlay processor that can efficiently execute a
variety of NLP models. NPE offers software-like programmability to the end user
and, unlike FPGA designs that implement specialized accelerators for each
nonlinear function, can be upgraded for future NLP models without requiring
reconfiguration. We demonstrate that NPE can meet real-time conversational AI
latency targets for the BERT language model with $4\times$ lower power than
CPUs and $6\times$ lower power than GPUs. We also show NPE uses $3\times$ fewer
FPGA resources relative to comparable BERT network-specific accelerators in the
literature. NPE provides a cost-effective and power-efficient FPGA-based
solution for Natural Language Processing at the edge.",2021-04-13T22:34:33Z,http://arxiv.org/pdf/2104.06535v1,['cs.AR']
2305.14671v2,A Survey of Diffusion Models in Natural Language Processing,"['Hao Zou', 'Zae Myung Kim', 'Dongyeop Kang']","This survey paper provides a comprehensive review of the use of diffusion
models in natural language processing (NLP). Diffusion models are a class of
mathematical models that aim to capture the diffusion of information or signals
across a network or manifold. In NLP, diffusion models have been used in a
variety of applications, such as natural language generation, sentiment
analysis, topic modeling, and machine translation. This paper discusses the
different formulations of diffusion models used in NLP, their strengths and
limitations, and their applications. We also perform a thorough comparison
between diffusion models and alternative generative models, specifically
highlighting the autoregressive (AR) models, while also examining how diverse
architectures incorporate the Transformer in conjunction with diffusion models.
Compared to AR models, diffusion models have significant advantages for
parallel generation, text interpolation, token-level controls such as syntactic
structures and semantic contents, and robustness. Exploring further
permutations of integrating Transformers into diffusion models would be a
valuable pursuit. Also, the development of multimodal diffusion models and
large-scale diffusion language models with notable capabilities for few-shot
learning would be important directions for the future advance of diffusion
models in NLP.",2023-05-24T03:25:32Z,http://arxiv.org/pdf/2305.14671v2,['cs.CL']
2007.09604v1,Meta-learning for Few-shot Natural Language Processing: A Survey,['Wenpeng Yin'],"Few-shot natural language processing (NLP) refers to NLP tasks that are
accompanied with merely a handful of labeled examples. This is a real-world
challenge that an AI system must learn to handle. Usually we rely on collecting
more auxiliary information or developing a more efficient learning algorithm.
However, the general gradient-based optimization in high capacity models, if
training from scratch, requires many parameter-updating steps over a large
number of labeled examples to perform well (Snell et al., 2017). If the target
task itself cannot provide more information, how about collecting more tasks
equipped with rich annotations to help the model learning? The goal of
meta-learning is to train a model on a variety of tasks with rich annotations,
such that it can solve a new task using only a few labeled samples. The key
idea is to train the model's initial parameters such that the model has maximal
performance on a new task after the parameters have been updated through zero
or a couple of gradient steps. There are already some surveys for
meta-learning, such as (Vilalta and Drissi, 2002; Vanschoren, 2018; Hospedales
et al., 2020). Nevertheless, this paper focuses on NLP domain, especially
few-shot applications. We try to provide clearer definitions, progress summary
and some common datasets of applying meta-learning to few-shot NLP.",2020-07-19T06:36:41Z,http://arxiv.org/pdf/2007.09604v1,"['cs.CL', 'cs.LG']"
2007.15779v6,"Domain-Specific Language Model Pretraining for Biomedical Natural
  Language Processing","['Yu Gu', 'Robert Tinn', 'Hao Cheng', 'Michael Lucas', 'Naoto Usuyama', 'Xiaodong Liu', 'Tristan Naumann', 'Jianfeng Gao', 'Hoifung Poon']","Pretraining large neural language models, such as BERT, has led to impressive
gains on many natural language processing (NLP) tasks. However, most
pretraining efforts focus on general domain corpora, such as newswire and Web.
A prevailing assumption is that even domain-specific pretraining can benefit by
starting from general-domain language models. In this paper, we challenge this
assumption by showing that for domains with abundant unlabeled text, such as
biomedicine, pretraining language models from scratch results in substantial
gains over continual pretraining of general-domain language models. To
facilitate this investigation, we compile a comprehensive biomedical NLP
benchmark from publicly-available datasets. Our experiments show that
domain-specific pretraining serves as a solid foundation for a wide range of
biomedical NLP tasks, leading to new state-of-the-art results across the board.
Further, in conducting a thorough evaluation of modeling choices, both for
pretraining and task-specific fine-tuning, we discover that some common
practices are unnecessary with BERT models, such as using complex tagging
schemes in named entity recognition (NER). To help accelerate research in
biomedical NLP, we have released our state-of-the-art pretrained and
task-specific models for the community, and created a leaderboard featuring our
BLURB benchmark (short for Biomedical Language Understanding & Reasoning
Benchmark) at https://aka.ms/BLURB.",2020-07-31T00:04:15Z,http://arxiv.org/pdf/2007.15779v6,"['cs.CL', 'cs.LG']"
2112.08628v2,Explainable Natural Language Processing with Matrix Product States,"['Jirawat Tangpanitanon', 'Chanatip Mangkang', 'Pradeep Bhadola', 'Yuichiro Minato', 'Dimitris G. Angelakis', 'Thiparat Chotibut']","Despite empirical successes of recurrent neural networks (RNNs) in natural
language processing (NLP), theoretical understanding of RNNs is still limited
due to intrinsically complex non-linear computations. We systematically analyze
RNNs' behaviors in a ubiquitous NLP task, the sentiment analysis of movie
reviews, via the mapping between a class of RNNs called recurrent arithmetic
circuits (RACs) and a matrix product state (MPS). Using the von-Neumann
entanglement entropy (EE) as a proxy for information propagation, we show that
single-layer RACs possess a maximum information propagation capacity, reflected
by the saturation of the EE. Enlarging the bond dimension beyond the EE
saturation threshold does not increase model prediction accuracies, so a
minimal model that best estimates the data statistics can be inferred. Although
the saturated EE is smaller than the maximum EE allowed by the area law, our
minimal model still achieves ~99% training accuracies in realistic sentiment
analysis data sets. Thus, low EE is not a warrant against the adoption of
single-layer RACs for NLP. Contrary to a common belief that long-range
information propagation is the main source of RNNs' successes, we show that
single-layer RACs harness high expressiveness from the subtle interplay between
the information propagation and the word vector embeddings. Our work sheds
light on the phenomenology of learning in RACs, and more generally on the
explainability of RNNs for NLP, using tools from many-body quantum physics.",2021-12-16T05:10:32Z,http://arxiv.org/pdf/2112.08628v2,"['cond-mat.dis-nn', 'cond-mat.stat-mech', 'cs.CL', 'cs.LG', 'quant-ph', '15A69', 'I.2.7']"
2212.05789v1,"Collaborating Heterogeneous Natural Language Processing Tasks via
  Federated Learning","['Chenhe Dong', 'Yuexiang Xie', 'Bolin Ding', 'Ying Shen', 'Yaliang Li']","The increasing privacy concerns on personal private text data promote the
development of federated learning (FL) in recent years. However, the existing
studies on applying FL in NLP are not suitable to coordinate participants with
heterogeneous or private learning objectives. In this study, we further broaden
the application scope of FL in NLP by proposing an Assign-Then-Contrast
(denoted as ATC) framework, which enables clients with heterogeneous NLP tasks
to construct an FL course and learn useful knowledge from each other.
Specifically, the clients are suggested to first perform local training with
the unified tasks assigned by the server rather than using their own learning
objectives, which is called the Assign training stage. After that, in the
Contrast training stage, clients train with different local learning objectives
and exchange knowledge with other clients who contribute consistent and useful
model updates. We conduct extensive experiments on six widely-used datasets
covering both Natural Language Understanding (NLU) and Natural Language
Generation (NLG) tasks, and the proposed ATC framework achieves significant
improvements compared with various baseline methods. The source code is
available at
\url{https://github.com/alibaba/FederatedScope/tree/master/federatedscope/nlp/hetero_tasks}.",2022-12-12T09:27:50Z,http://arxiv.org/pdf/2212.05789v1,['cs.CL']
2302.06476v3,Is ChatGPT a General-Purpose Natural Language Processing Task Solver?,"['Chengwei Qin', 'Aston Zhang', 'Zhuosheng Zhang', 'Jiaao Chen', 'Michihiro Yasunaga', 'Diyi Yang']","Spurred by advancements in scale, large language models (LLMs) have
demonstrated the ability to perform a variety of natural language processing
(NLP) tasks zero-shot -- i.e., without adaptation on downstream data. Recently,
the debut of ChatGPT has drawn a great deal of attention from the natural
language processing (NLP) community due to the fact that it can generate
high-quality responses to human input and self-correct previous mistakes based
on subsequent conversations. However, it is not yet known whether ChatGPT can
serve as a generalist model that can perform many NLP tasks zero-shot. In this
work, we empirically analyze the zero-shot learning ability of ChatGPT by
evaluating it on 20 popular NLP datasets covering 7 representative task
categories. With extensive empirical studies, we demonstrate both the
effectiveness and limitations of the current version of ChatGPT. We find that
ChatGPT performs well on many tasks favoring reasoning capabilities (e.g.,
arithmetic reasoning) while it still faces challenges when solving specific
tasks such as sequence tagging. We additionally provide in-depth analysis
through qualitative case studies.",2023-02-08T09:44:51Z,http://arxiv.org/pdf/2302.06476v3,"['cs.CL', 'cs.AI']"
2302.10499v2,"Intergenerational Test Generation for Natural Language Processing
  Applications","['Pin Ji', 'Yang Feng', 'Weitao Huang', 'Jia Liu', 'Zhihong Zhao']","The development of modern NLP applications often relies on various benchmark
datasets containing plenty of manually labeled tests to evaluate performance.
While constructing datasets often costs many resources, the performance on the
held-out data may not properly reflect their capability in real-world
application scenarios and thus cause tremendous misunderstanding and monetary
loss. To alleviate this problem, in this paper, we propose an automated test
generation method for detecting erroneous behaviors of various NLP
applications. Our method is designed based on the sentence parsing process of
classic linguistics, and thus it is capable of assembling basic grammatical
elements and adjuncts into a grammatically correct test with proper oracle
information. We implement this method into NLPLego, which is designed to fully
exploit the potential of seed sentences to automate the test generation.
NLPLego disassembles the seed sentence into the template and adjuncts and then
generates new sentences by assembling context-appropriate adjuncts with the
template in a specific order. Unlike the taskspecific methods, the tests
generated by NLPLego have derivation relations and different degrees of
variation, which makes constructing appropriate metamorphic relations easier.
Thus, NLPLego is general, meaning it can meet the testing requirements of
various NLP applications. To validate NLPLego, we experiment with three common
NLP tasks, identifying failures in four state-of-art models. Given seed tests
from SQuAD 2.0, SST, and QQP, NLPLego successfully detects 1,732, 5301, and
261,879 incorrect behaviors with around 95.7% precision in three tasks,
respectively.",2023-02-21T07:57:59Z,http://arxiv.org/pdf/2302.10499v2,['cs.SE']
2403.04105v3,Natural Language Processing in the Patent Domain: A Survey,"['Lekang Jiang', 'Stephan Goetz']","Patents, which encapsulate crucial technical and legal information in text
form and referenced drawings, present a rich domain for natural language
processing (NLP) applications. As NLP technologies evolve, large language
models (LLMs) have demonstrated outstanding capabilities in general text
processing and generation tasks. However, the application of LLMs in the patent
domain remains under-explored and under-developed due to the complexity of
patents, particularly their language and legal framework. Understanding the
unique characteristics of patent documents and related research in the patent
domain becomes essential for researchers to apply these tools effectively.
Therefore, this paper aims to equip NLP researchers with the essential
knowledge to navigate this complex domain efficiently. We introduce the
relevant fundamental aspects of patents to provide solid background
information. In addition, we systematically break down the structural and
linguistic characteristics unique to patents and map out how NLP can be
leveraged for patent analysis and generation. Moreover, we demonstrate the
spectrum of text-based and multimodal patent-related tasks, including nine
patent analysis and four patent generation tasks.",2024-03-06T23:17:16Z,http://arxiv.org/pdf/2403.04105v3,['cs.AI']
9607018v1,TSNLP - Test Suites for Natural Language Processing,"['Sabine Lehmann', 'Stephan Oepen', 'Sylvie Regnier-Prost', 'Klaus Netter', 'Veronika Lux', 'Judith Klein', 'Kirsten Falkedal', 'Frederik Fouvry', 'Dominique Estival', 'Eva Dauphin', 'Herve Compagnion', 'Judith Baur', 'Judith Baur', 'Lorna Balkan', 'Doug Arnold']","The TSNLP project has investigated various aspects of the construction,
maintenance and application of systematic test suites as diagnostic and
evaluation tools for NLP applications. The paper summarizes the motivation and
main results of the project: besides the solid methodological foundation, TSNLP
has produced substantial multi-purpose and multi-user test suites for three
European languages together with a set of specialized tools that facilitate the
construction, extension, maintenance, retrieval, and customization of the test
data. As TSNLP results, including the data and technology, are made publicly
available, the project presents a valuable linguistic resourc e that has the
potential of providing a wide-spread pre-standard diagnostic and evaluation
tool for both developers and users of NLP applications.",1996-07-15T10:28:12Z,http://arxiv.org/pdf/cmp-lg/9607018v1,"['cmp-lg', 'cs.CL']"
2004.06800v1,A hybrid classical-quantum workflow for natural language processing,"[""Lee J. O'Riordan"", 'Myles Doyle', 'Fabio Baruffa', 'Venkatesh Kannan']","Natural language processing (NLP) problems are ubiquitous in classical
computing, where they often require significant computational resources to
infer sentence meanings. With the appearance of quantum computing hardware and
simulators, it is worth developing methods to examine such problems on these
platforms. In this manuscript we demonstrate the use of quantum computing
models to perform NLP tasks, where we represent corpus meanings, and perform
comparisons between sentences of a given structure. We develop a hybrid
workflow for representing small and large scale corpus data sets to be encoded,
processed, and decoded using a quantum circuit model. In addition, we provide
our results showing the efficacy of the method, and release our developed
toolkit as an open software suite.",2020-04-12T12:19:17Z,http://arxiv.org/pdf/2004.06800v1,"['quant-ph', 'cs.CL', 'cs.LG']"
2107.12603v1,Federated Learning Meets Natural Language Processing: A Survey,"['Ming Liu', 'Stella Ho', 'Mengqi Wang', 'Longxiang Gao', 'Yuan Jin', 'He Zhang']","Federated Learning aims to learn machine learning models from multiple
decentralized edge devices (e.g. mobiles) or servers without sacrificing local
data privacy. Recent Natural Language Processing techniques rely on deep
learning and large pre-trained language models. However, both big deep neural
and language models are trained with huge amounts of data which often lies on
the server side. Since text data is widely originated from end users, in this
work, we look into recent NLP models and techniques which use federated
learning as the learning framework. Our survey discusses major challenges in
federated natural language processing, including the algorithm challenges,
system challenges as well as the privacy issues. We also provide a critical
review of the existing Federated NLP evaluation methods and tools. Finally, we
highlight the current research gaps and future directions.",2021-07-27T05:07:48Z,http://arxiv.org/pdf/2107.12603v1,"['cs.CL', 'cs.AI', 'cs.DC']"
2207.04959v1,Learning Mutual Fund Categorization using Natural Language Processing,"['Dimitrios Vamvourellis', 'Mate Attila Toth', 'Dhruv Desai', 'Dhagash Mehta', 'Stefano Pasquali']","Categorization of mutual funds or Exchange-Traded-funds (ETFs) have long
served the financial analysts to perform peer analysis for various purposes
starting from competitor analysis, to quantifying portfolio diversification.
The categorization methodology usually relies on fund composition data in the
structured format extracted from the Form N-1A. Here, we initiate a study to
learn the categorization system directly from the unstructured data as depicted
in the forms using natural language processing (NLP). Positing as a multi-class
classification problem with the input data being only the investment strategy
description as reported in the form and the target variable being the Lipper
Global categories, and using various NLP models, we show that the
categorization system can indeed be learned with high accuracy. We discuss
implications and applications of our findings as well as limitations of
existing pre-trained architectures in applying them to learn fund
categorization.",2022-07-11T15:40:18Z,http://arxiv.org/pdf/2207.04959v1,"['q-fin.CP', 'q-fin.ST', 'stat.ML']"
1911.10708v1,hauWE: Hausa Words Embedding for Natural Language Processing,"['Idris Abdulmumin', 'Bashir Shehu Galadanci']","Words embedding (distributed word vector representations) have become an
essential component of many natural language processing (NLP) tasks such as
machine translation, sentiment analysis, word analogy, named entity recognition
and word similarity. Despite this, the only work that provides word vectors for
Hausa language is that of Bojanowski et al. [1] trained using fastText,
consisting of only a few words vectors. This work presents words embedding
models using Word2Vec's Continuous Bag of Words (CBoW) and Skip Gram (SG)
models. The models, hauWE (Hausa Words Embedding), are bigger and better than
the only previous model, making them more useful in NLP tasks. To compare the
models, they were used to predict the 10 most similar words to 30 randomly
selected Hausa words. hauWE CBoW's 88.7% and hauWE SG's 79.3% prediction
accuracy greatly outperformed Bojanowski et al. [1]'s 22.3%.",2019-11-25T05:46:56Z,http://arxiv.org/pdf/1911.10708v1,"['cs.CL', 'cs.AI', 'cs.IR', 'cs.LG']"
2305.19383v1,"Quantum Natural Language Processing based Sentiment Analysis using
  lambeq Toolkit","['Srinjoy Ganguly', 'Sai Nandan Morapakula', 'Luis Miguel Pozo Coronado']","Sentiment classification is one the best use case of classical natural
language processing (NLP) where we can witness its power in various daily life
domains such as banking, business and marketing industry. We already know how
classical AI and machine learning can change and improve technology. Quantum
natural language processing (QNLP) is a young and gradually emerging technology
which has the potential to provide quantum advantage for NLP tasks. In this
paper we show the first application of QNLP for sentiment analysis and achieve
perfect test set accuracy for three different kinds of simulations and a decent
accuracy for experiments ran on a noisy quantum device. We utilize the lambeq
QNLP toolkit and $t|ket>$ by Cambridge Quantum (Quantinuum) to bring out the
results.",2023-05-30T19:54:02Z,http://arxiv.org/pdf/2305.19383v1,"['quant-ph', 'cs.CL']"
2007.04239v1,A Survey on Transfer Learning in Natural Language Processing,"['Zaid Alyafeai', 'Maged Saeed AlShaibani', 'Irfan Ahmad']","Deep learning models usually require a huge amount of data. However, these
large datasets are not always attainable. This is common in many challenging
NLP tasks. Consider Neural Machine Translation, for instance, where curating
such large datasets may not be possible specially for low resource languages.
Another limitation of deep learning models is the demand for huge computing
resources. These obstacles motivate research to question the possibility of
knowledge transfer using large trained models. The demand for transfer learning
is increasing as many large models are emerging. In this survey, we feature the
recent transfer learning advances in the field of NLP. We also provide a
taxonomy for categorizing different transfer learning approaches from the
literature.",2020-05-31T21:52:31Z,http://arxiv.org/pdf/2007.04239v1,"['cs.CL', 'cs.LG', 'stat.ML']"
2007.12969v1,Constructing a Testbed for Psychometric Natural Language Processing,"['Ahmed Abbasi', 'David G. Dobolyi', 'Richard G. Netemeyer']","Psychometric measures of ability, attitudes, perceptions, and beliefs are
crucial for understanding user behaviors in various contexts including health,
security, e-commerce, and finance. Traditionally, psychometric dimensions have
been measured and collected using survey-based methods. Inferring such
constructs from user-generated text could afford opportunities for timely,
unobtrusive, collection and analysis. In this paper, we describe our efforts to
construct a corpus for psychometric natural language processing (NLP). We
discuss our multi-step process to align user text with their survey-based
response items and provide an overview of the resulting testbed which
encompasses survey-based psychometric measures and accompanying user-generated
text from over 8,500 respondents. We report preliminary results on the use of
the text to categorize/predict users' survey response labels. We also discuss
the important implications of our work and resulting testbed for future
psychometric NLP research.",2020-07-25T16:29:24Z,http://arxiv.org/pdf/2007.12969v1,"['cs.CL', 'cs.CY']"
2012.09823v1,Continual Lifelong Learning in Natural Language Processing: A Survey,"['Magdalena Biesialska', 'Katarzyna Biesialska', 'Marta R. Costa-jussà']","Continual learning (CL) aims to enable information systems to learn from a
continuous data stream across time. However, it is difficult for existing deep
learning architectures to learn a new task without largely forgetting
previously acquired knowledge. Furthermore, CL is particularly challenging for
language learning, as natural language is ambiguous: it is discrete,
compositional, and its meaning is context-dependent. In this work, we look at
the problem of CL through the lens of various NLP tasks. Our survey discusses
major challenges in CL and current methods applied in neural network models. We
also provide a critical review of the existing CL evaluation methods and
datasets in NLP. Finally, we present our outlook on future research directions.",2020-12-17T18:44:36Z,http://arxiv.org/pdf/2012.09823v1,"['cs.CL', 'cs.AI', 'cs.LG', 'cs.NE']"
2012.15495v1,Towards Zero-Shot Knowledge Distillation for Natural Language Processing,"['Ahmad Rashid', 'Vasileios Lioutas', 'Abbas Ghaddar', 'Mehdi Rezagholizadeh']","Knowledge Distillation (KD) is a common knowledge transfer algorithm used for
model compression across a variety of deep learning based natural language
processing (NLP) solutions. In its regular manifestations, KD requires access
to the teacher's training data for knowledge transfer to the student network.
However, privacy concerns, data regulations and proprietary reasons may prevent
access to such data. We present, to the best of our knowledge, the first work
on Zero-Shot Knowledge Distillation for NLP, where the student learns from the
much larger teacher without any task specific data. Our solution combines out
of domain data and adversarial training to learn the teacher's output
distribution. We investigate six tasks from the GLUE benchmark and demonstrate
that we can achieve between 75% and 92% of the teacher's classification score
(accuracy or F1) while compressing the model 30 times.",2020-12-31T08:16:29Z,http://arxiv.org/pdf/2012.15495v1,"['cs.CL', 'cs.LG']"
2105.02388v1,"Security Vulnerability Detection Using Deep Learning Natural Language
  Processing","['Noah Ziems', 'Shaoen Wu']","Detecting security vulnerabilities in software before they are exploited has
been a challenging problem for decades. Traditional code analysis methods have
been proposed, but are often ineffective and inefficient. In this work, we
model software vulnerability detection as a natural language processing (NLP)
problem with source code treated as texts, and address the automated software
venerability detection with recent advanced deep learning NLP models assisted
by transfer learning on written English. For training and testing, we have
preprocessed the NIST NVD/SARD databases and built a dataset of over 100,000
files in $C$ programming language with 123 types of vulnerabilities. The
extensive experiments generate the best performance of over 93\% accuracy in
detecting security vulnerabilities.",2021-05-06T01:28:21Z,http://arxiv.org/pdf/2105.02388v1,"['cs.CR', 'cs.AI']"
2109.02846v1,Datasets: A Community Library for Natural Language Processing,"['Quentin Lhoest', 'Albert Villanova del Moral', 'Yacine Jernite', 'Abhishek Thakur', 'Patrick von Platen', 'Suraj Patil', 'Julien Chaumond', 'Mariama Drame', 'Julien Plu', 'Lewis Tunstall', 'Joe Davison', 'Mario Šaško', 'Gunjan Chhablani', 'Bhavitvya Malik', 'Simon Brandeis', 'Teven Le Scao', 'Victor Sanh', 'Canwen Xu', 'Nicolas Patry', 'Angelina McMillan-Major', 'Philipp Schmid', 'Sylvain Gugger', 'Clément Delangue', 'Théo Matussière', 'Lysandre Debut', 'Stas Bekman', 'Pierric Cistac', 'Thibault Goehringer', 'Victor Mustar', 'François Lagunas', 'Alexander M. Rush', 'Thomas Wolf']","The scale, variety, and quantity of publicly-available NLP datasets has grown
rapidly as researchers propose new tasks, larger models, and novel benchmarks.
Datasets is a community library for contemporary NLP designed to support this
ecosystem. Datasets aims to standardize end-user interfaces, versioning, and
documentation, while providing a lightweight front-end that behaves similarly
for small datasets as for internet-scale corpora. The design of the library
incorporates a distributed, community-driven approach to adding datasets and
documenting usage. After a year of development, the library now includes more
than 650 unique datasets, has more than 250 contributors, and has helped
support a variety of novel cross-dataset research projects and shared tasks.
The library is available at https://github.com/huggingface/datasets.",2021-09-07T03:59:22Z,http://arxiv.org/pdf/2109.02846v1,['cs.CL']
2201.01956v2,"HuSpaCy: an industrial-strength Hungarian natural language processing
  toolkit","['György Orosz', 'Zsolt Szántó', 'Péter Berkecz', 'Gergő Szabó', 'Richárd Farkas']","Although there are a couple of open-source language processing pipelines
available for Hungarian, none of them satisfies the requirements of today's NLP
applications. A language processing pipeline should consist of close to
state-of-the-art lemmatization, morphosyntactic analysis, entity recognition
and word embeddings. Industrial text processing applications have to satisfy
non-functional software quality requirements, what is more, frameworks
supporting multiple languages are more and more favored. This paper introduces
HuSpaCy, an industry-ready Hungarian language processing toolkit. The presented
tool provides components for the most important basic linguistic analysis
tasks. It is open-source and is available under a permissive license. Our
system is built upon spaCy's NLP components resulting in an easily usable, fast
yet accurate application. Experiments confirm that HuSpaCy has high accuracy
while maintaining resource-efficient prediction capabilities.",2022-01-06T07:49:45Z,http://arxiv.org/pdf/2201.01956v2,"['cs.CL', 'stat.ML', '68T50', 'I.2.7']"
2203.07580v1,"TSM: Measuring the Enticement of Honeyfiles with Natural Language
  Processing","['Roelien C. Timmer', 'David Liebowitz', 'Surya Nepal', 'Salil Kanhere']","Honeyfile deployment is a useful breach detection method in cyber deception
that can also inform defenders about the intent and interests of intruders and
malicious insiders. A key property of a honeyfile, enticement, is the extent to
which the file can attract an intruder to interact with it. We introduce a
novel metric, Topic Semantic Matching (TSM), which uses topic modelling to
represent files in the repository and semantic matching in an embedding vector
space to compare honeyfile text and topic words robustly. We also present a
honeyfile corpus created with different Natural Language Processing (NLP)
methods. Experiments show that TSM is effective in inter-corpus comparisons and
is a promising tool to measure the enticement of honeyfiles. TSM is the first
measure to use NLP techniques to quantify the enticement of honeyfile content
that compares the essential topical content of local contexts to honeyfiles and
is robust to paraphrasing.",2022-03-15T01:07:51Z,http://arxiv.org/pdf/2203.07580v1,"['cs.CL', 'cs.CR', 'cs.LG']"
2205.14728v2,"L3Cube-MahaNLP: Marathi Natural Language Processing Datasets, Models,
  and Library",['Raviraj Joshi'],"Despite being the third most popular language in India, the Marathi language
lacks useful NLP resources. Moreover, popular NLP libraries do not have support
for the Marathi language. With L3Cube-MahaNLP, we aim to build resources and a
library for Marathi natural language processing. We present datasets and
transformer models for supervised tasks like sentiment analysis, named entity
recognition, and hate speech detection. We have also published a monolingual
Marathi corpus for unsupervised language modeling tasks. Overall we present
MahaCorpus, MahaSent, MahaNER, and MahaHate datasets and their corresponding
MahaBERT models fine-tuned on these datasets. We aim to move ahead of benchmark
datasets and prepare useful resources for Marathi. The resources are available
at https://github.com/l3cube-pune/MarathiNLP.",2022-05-29T17:51:00Z,http://arxiv.org/pdf/2205.14728v2,"['cs.CL', 'cs.LG']"
2206.14774v3,TweetNLP: Cutting-Edge Natural Language Processing for Social Media,"['Jose Camacho-Collados', 'Kiamehr Rezaee', 'Talayeh Riahi', 'Asahi Ushio', 'Daniel Loureiro', 'Dimosthenis Antypas', 'Joanne Boisson', 'Luis Espinosa-Anke', 'Fangyu Liu', 'Eugenio Martínez-Cámara', 'Gonzalo Medina', 'Thomas Buhrmann', 'Leonardo Neves', 'Francesco Barbieri']","In this paper we present TweetNLP, an integrated platform for Natural
Language Processing (NLP) in social media. TweetNLP supports a diverse set of
NLP tasks, including generic focus areas such as sentiment analysis and named
entity recognition, as well as social media-specific tasks such as emoji
prediction and offensive language identification. Task-specific systems are
powered by reasonably-sized Transformer-based language models specialized on
social media text (in particular, Twitter) which can be run without the need
for dedicated hardware or cloud services. The main contributions of TweetNLP
are: (1) an integrated Python library for a modern toolkit supporting social
media analysis using our various task-specific models adapted to the social
domain; (2) an interactive online demo for codeless experimentation using our
models; and (3) a tutorial covering a wide variety of typical social media
applications.",2022-06-29T17:16:58Z,http://arxiv.org/pdf/2206.14774v3,['cs.CL']
2211.12701v2,Continual Learning of Natural Language Processing Tasks: A Survey,"['Zixuan Ke', 'Bing Liu']","Continual learning (CL) is a learning paradigm that emulates the human
capability of learning and accumulating knowledge continually without
forgetting the previously learned knowledge and also transferring the learned
knowledge to help learn new tasks better. This survey presents a comprehensive
review and analysis of the recent progress of CL in NLP, which has significant
differences from CL in computer vision and machine learning. It covers (1) all
CL settings with a taxonomy of existing techniques; (2) catastrophic forgetting
(CF) prevention, (3) knowledge transfer (KT), which is particularly important
for NLP tasks; and (4) some theory and the hidden challenge of inter-task class
separation (ICS). (1), (3) and (4) have not been included in the existing
survey. Finally, a list of future directions is discussed.",2022-11-23T04:46:28Z,http://arxiv.org/pdf/2211.12701v2,"['cs.CL', 'cs.AI', 'cs.LG', 'cs.NE']"
2302.13812v1,"Adapting Pre-trained Language Models for Quantum Natural Language
  Processing","['Qiuchi Li', 'Benyou Wang', 'Yudong Zhu', 'Christina Lioma', 'Qun Liu']","The emerging classical-quantum transfer learning paradigm has brought a
decent performance to quantum computational models in many tasks, such as
computer vision, by enabling a combination of quantum models and classical
pre-trained neural networks. However, using quantum computing with pre-trained
models has yet to be explored in natural language processing (NLP). Due to the
high linearity constraints of the underlying quantum computing infrastructures,
existing Quantum NLP models are limited in performance on real tasks. We fill
this gap by pre-training a sentence state with complex-valued BERT-like
architecture, and adapting it to the classical-quantum transfer learning scheme
for sentence classification. On quantum simulation experiments, the pre-trained
representation can bring 50\% to 60\% increases to the capacity of end-to-end
quantum models.",2023-02-24T14:59:02Z,http://arxiv.org/pdf/2302.13812v1,"['quant-ph', 'cs.CL']"
2306.14918v1,"Utilizing Natural Language Processing for Automated Assessment of
  Classroom Discussion","['Nhat Tran', 'Benjamin Pierce', 'Diane Litman', 'Richard Correnti', 'Lindsay Clare Matsumura']","Rigorous and interactive class discussions that support students to engage in
high-level thinking and reasoning are essential to learning and are a central
component of most teaching interventions. However, formally assessing
discussion quality 'at scale' is expensive and infeasible for most researchers.
In this work, we experimented with various modern natural language processing
(NLP) techniques to automatically generate rubric scores for individual
dimensions of classroom text discussion quality. Specifically, we worked on a
dataset of 90 classroom discussion transcripts consisting of over 18000 turns
annotated with fine-grained Analyzing Teaching Moves (ATM) codes and focused on
four Instructional Quality Assessment (IQA) rubrics. Despite the limited amount
of data, our work shows encouraging results in some of the rubrics while
suggesting that there is room for improvement in the others. We also found that
certain NLP approaches work better for certain rubrics.",2023-06-21T16:45:24Z,http://arxiv.org/pdf/2306.14918v1,"['cs.CL', 'cs.AI', 'cs.LG']"
2307.11032v1,A Natural Language Processing Approach to Malware Classification,"['Ritik Mehta', 'Olha Jurečková', 'Mark Stamp']","Many different machine learning and deep learning techniques have been
successfully employed for malware detection and classification. Examples of
popular learning techniques in the malware domain include Hidden Markov Models
(HMM), Random Forests (RF), Convolutional Neural Networks (CNN), Support Vector
Machines (SVM), and Recurrent Neural Networks (RNN) such as Long Short-Term
Memory (LSTM) networks. In this research, we consider a hybrid architecture,
where HMMs are trained on opcode sequences, and the resulting hidden states of
these trained HMMs are used as feature vectors in various classifiers. In this
context, extracting the HMM hidden state sequences can be viewed as a form of
feature engineering that is somewhat analogous to techniques that are commonly
employed in Natural Language Processing (NLP). We find that this NLP-based
approach outperforms other popular techniques on a challenging malware dataset,
with an HMM-Random Forrest model yielding the best results.",2023-07-07T23:16:23Z,http://arxiv.org/pdf/2307.11032v1,"['cs.CR', 'cs.LG']"
2312.01221v1,Enabling Quantum Natural Language Processing for Hindi Language,"['Naman Srivastava', 'Gaurang Belekar', 'Sunil Saumya', 'Aswath Babu H']","Quantum Natural Language Processing (QNLP) is taking huge leaps in solving
the shortcomings of classical Natural Language Processing (NLP) techniques and
moving towards a more ""Explainable"" NLP system. The current literature around
QNLP focuses primarily on implementing QNLP techniques in sentences in the
English language. In this paper, we propose to enable the QNLP approach to
HINDI, which is the third most spoken language in South Asia. We present the
process of building the parameterized quantum circuits required to undertake
QNLP on Hindi sentences. We use the pregroup representation of Hindi and the
DisCoCat framework to draw sentence diagrams. Later, we translate these
diagrams to Parameterised Quantum Circuits based on Instantaneous Quantum
Polynomial (IQP) style ansatz. Using these parameterized quantum circuits
allows one to train grammar and topic-aware sentence classifiers for the Hindi
Language.",2023-12-02T20:19:11Z,http://arxiv.org/pdf/2312.01221v1,['cs.CL']
2404.01443v1,"Enterprise Use Cases Combining Knowledge Graphs and Natural Language
  Processing","['Phillip Schneider', 'Tim Schopf', 'Juraj Vladika', 'Florian Matthes']","Knowledge management is a critical challenge for enterprises in today's
digital world, as the volume and complexity of data being generated and
collected continue to grow incessantly. Knowledge graphs (KG) emerged as a
promising solution to this problem by providing a flexible, scalable, and
semantically rich way to organize and make sense of data. This paper builds
upon a recent survey of the research literature on combining KGs and Natural
Language Processing (NLP). Based on selected application scenarios from
enterprise context, we discuss synergies that result from such a combination.
We cover various approaches from the three core areas of KG construction,
reasoning as well as KG-based NLP tasks. In addition to explaining innovative
enterprise use cases, we assess their maturity in terms of practical
applicability and conclude with an outlook on emergent application areas for
the future.",2024-04-01T19:28:52Z,http://arxiv.org/pdf/2404.01443v1,['cs.CL']
2412.18036v2,Explainability in Neural Networks for Natural Language Processing Tasks,"['Melkamu Mersha', 'Mingiziem Bitewa', 'Tsion Abay', 'Jugal Kalita']","Neural networks are widely regarded as black-box models, creating significant
challenges in understanding their inner workings, especially in natural
language processing (NLP) applications. To address this opacity, model
explanation techniques like Local Interpretable Model-Agnostic Explanations
(LIME) have emerged as essential tools for providing insights into the behavior
of these complex systems. This study leverages LIME to interpret a multi-layer
perceptron (MLP) neural network trained on a text classification task. By
analyzing the contribution of individual features to model predictions, the
LIME approach enhances interpretability and supports informed decision-making.
Despite its effectiveness in offering localized explanations, LIME has
limitations in capturing global patterns and feature interactions. This
research highlights the strengths and shortcomings of LIME and proposes
directions for future work to achieve more comprehensive interpretability in
neural NLP models.",2024-12-23T23:09:56Z,http://arxiv.org/pdf/2412.18036v2,"['cs.CL', 'cs.AI']"
2505.17642v2,A Survey on Stereotype Detection in Natural Language Processing,"['Alessandra Teresa Cignarella', 'Anastasia Giachanou', 'Els Lefever']","Stereotypes influence social perceptions and can escalate into discrimination
and violence. While NLP research has extensively addressed gender bias and hate
speech, stereotype detection remains an emerging field with significant
societal implications. In this work is presented a survey of existing research,
analyzing definitions from psychology, sociology, and philosophy. A
semi-automatic literature review was performed by using Semantic Scholar. We
retrieved and filtered over 6,000 papers (in the year range 2000-2025),
identifying key trends, methodologies, challenges and future directions. The
findings emphasize stereotype detection as a potential early-monitoring tool to
prevent bias escalation and the rise of hate speech. Conclusions highlight the
need for a broader, multilingual, and intersectional approach in NLP studies.",2025-05-23T09:03:56Z,http://arxiv.org/pdf/2505.17642v2,"['cs.CL', 'cs.CY']"
2103.11441v3,"TextFlint: Unified Multilingual Robustness Evaluation Toolkit for
  Natural Language Processing","['Tao Gui', 'Xiao Wang', 'Qi Zhang', 'Qin Liu', 'Yicheng Zou', 'Xin Zhou', 'Rui Zheng', 'Chong Zhang', 'Qinzhuo Wu', 'Jiacheng Ye', 'Zexiong Pang', 'Yongxin Zhang', 'Zhengyan Li', 'Ruotian Ma', 'Zichu Fei', 'Ruijian Cai', 'Jun Zhao', 'Xingwu Hu', 'Zhiheng Yan', 'Yiding Tan', 'Yuan Hu', 'Qiyuan Bian', 'Zhihua Liu', 'Bolin Zhu', 'Shan Qin', 'Xiaoyu Xing', 'Jinlan Fu', 'Yue Zhang', 'Minlong Peng', 'Xiaoqing Zheng', 'Yaqian Zhou', 'Zhongyu Wei', 'Xipeng Qiu', 'Xuanjing Huang']","Various robustness evaluation methodologies from different perspectives have
been proposed for different natural language processing (NLP) tasks. These
methods have often focused on either universal or task-specific generalization
capabilities. In this work, we propose a multilingual robustness evaluation
platform for NLP tasks (TextFlint) that incorporates universal text
transformation, task-specific transformation, adversarial attack,
subpopulation, and their combinations to provide comprehensive robustness
analysis. TextFlint enables practitioners to automatically evaluate their
models from all aspects or to customize their evaluations as desired with just
a few lines of code. To guarantee user acceptability, all the text
transformations are linguistically based, and we provide a human evaluation for
each one. TextFlint generates complete analytical reports as well as targeted
augmented data to address the shortcomings of the model's robustness. To
validate TextFlint's utility, we performed large-scale empirical evaluations
(over 67,000 evaluations) on state-of-the-art deep learning models, classic
supervised methods, and real-world systems. Almost all models showed
significant performance degradation, including a decline of more than 50% of
BERT's prediction accuracy on tasks such as aspect-level sentiment
classification, named entity recognition, and natural language inference.
Therefore, we call for the robustness to be included in the model evaluation,
so as to promote the healthy development of NLP technology.",2021-03-21T17:20:38Z,http://arxiv.org/pdf/2103.11441v3,"['cs.CL', 'cs.AI']"
2104.08815v3,"FedNLP: Benchmarking Federated Learning Methods for Natural Language
  Processing Tasks","['Bill Yuchen Lin', 'Chaoyang He', 'Zihang Zeng', 'Hulin Wang', 'Yufen Huang', 'Christophe Dupuy', 'Rahul Gupta', 'Mahdi Soltanolkotabi', 'Xiang Ren', 'Salman Avestimehr']","Increasing concerns and regulations about data privacy and sparsity
necessitate the study of privacy-preserving, decentralized learning methods for
natural language processing (NLP) tasks. Federated learning (FL) provides
promising approaches for a large number of clients (e.g., personal devices or
organizations) to collaboratively learn a shared global model to benefit all
clients while allowing users to keep their data locally. Despite interest in
studying FL methods for NLP tasks, a systematic comparison and analysis is
lacking in the literature. Herein, we present the FedNLP, a benchmarking
framework for evaluating federated learning methods on four different task
formulations: text classification, sequence tagging, question answering, and
seq2seq. We propose a universal interface between Transformer-based language
models (e.g., BERT, BART) and FL methods (e.g., FedAvg, FedOPT, etc.) under
various non-IID partitioning strategies. Our extensive experiments with FedNLP
provide empirical comparisons between FL methods and helps us better understand
the inherent challenges of this direction. The comprehensive analysis points to
intriguing and exciting future research aimed at developing FL methods for NLP
tasks.",2021-04-18T11:04:49Z,http://arxiv.org/pdf/2104.08815v3,"['cs.CL', 'cs.AI', 'cs.LG']"
2305.14716v1,"GlobalBench: A Benchmark for Global Progress in Natural Language
  Processing","['Yueqi Song', 'Catherine Cui', 'Simran Khanuja', 'Pengfei Liu', 'Fahim Faisal', 'Alissa Ostapenko', 'Genta Indra Winata', 'Alham Fikri Aji', 'Samuel Cahyawijaya', 'Yulia Tsvetkov', 'Antonios Anastasopoulos', 'Graham Neubig']","Despite the major advances in NLP, significant disparities in NLP system
performance across languages still exist. Arguably, these are due to uneven
resource allocation and sub-optimal incentives to work on less resourced
languages. To track and further incentivize the global development of equitable
language technology, we introduce GlobalBench. Prior multilingual benchmarks
are static and have focused on a limited number of tasks and languages. In
contrast, GlobalBench is an ever-expanding collection that aims to dynamically
track progress on all NLP datasets in all languages. Rather than solely
measuring accuracy, GlobalBench also tracks the estimated per-speaker utility
and equity of technology across all languages, providing a multi-faceted view
of how language technology is serving people of the world. Furthermore,
GlobalBench is designed to identify the most under-served languages, and
rewards research efforts directed towards those languages. At present, the most
under-served languages are the ones with a relatively high population, but
nonetheless overlooked by composite multilingual benchmarks (like Punjabi,
Portuguese, and Wu Chinese). Currently, GlobalBench covers 966 datasets in 190
languages, and has 1,128 system submissions spanning 62 languages.",2023-05-24T04:36:32Z,http://arxiv.org/pdf/2305.14716v1,['cs.CL']
1806.04820v2,Natural Language Processing for EHR-Based Computational Phenotyping,"['Zexian Zeng', 'Yu Deng', 'Xiaoyu Li', 'Tristan Naumann', 'Yuan Luo']","This article reviews recent advances in applying natural language processing
(NLP) to Electronic Health Records (EHRs) for computational phenotyping.
NLP-based computational phenotyping has numerous applications including
diagnosis categorization, novel phenotype discovery, clinical trial screening,
pharmacogenomics, drug-drug interaction (DDI) and adverse drug event (ADE)
detection, as well as genome-wide and phenome-wide association studies.
Significant progress has been made in algorithm development and resource
construction for computational phenotyping. Among the surveyed methods,
well-designed keyword search and rule-based systems often achieve good
performance. However, the construction of keyword and rule lists requires
significant manual effort, which is difficult to scale. Supervised machine
learning models have been favored because they are capable of acquiring both
classification patterns and structures from data. Recently, deep learning and
unsupervised learning have received growing attention, with the former favored
for its performance and the latter for its ability to find novel phenotypes.
Integrating heterogeneous data sources have become increasingly important and
have shown promise in improving model performance. Often better performance is
achieved by combining multiple modalities of information. Despite these many
advances, challenges and opportunities remain for NLP-based computational
phenotyping, including better model interpretability and generalizability, and
proper characterization of feature relations in clinical narratives",2018-06-13T02:14:19Z,http://arxiv.org/pdf/1806.04820v2,['cs.CL']
2105.12202v1,"Context-Sensitive Visualization of Deep Learning Natural Language
  Processing Models","['Andrew Dunn', 'Diana Inkpen', 'Răzvan Andonie']","The introduction of Transformer neural networks has changed the landscape of
Natural Language Processing (NLP) during the last years. So far, none of the
visualization systems has yet managed to examine all the facets of the
Transformers. This gave us the motivation of the current work. We propose a new
NLP Transformer context-sensitive visualization method that leverages existing
NLP tools to find the most significant groups of tokens (words) that have the
greatest effect on the output, thus preserving some context from the original
text. First, we use a sentence-level dependency parser to highlight promising
word groups. The dependency parser creates a tree of relationships between the
words in the sentence. Next, we systematically remove adjacent and non-adjacent
tuples of \emph{n} tokens from the input text, producing several new texts with
those tokens missing. The resulting texts are then passed to a pre-trained BERT
model. The classification output is compared with that of the full text, and
the difference in the activation strength is recorded. The modified texts that
produce the largest difference in the target classification output neuron are
selected, and the combination of removed words are then considered to be the
most influential on the model's output. Finally, the most influential word
combinations are visualized in a heatmap.",2021-05-25T20:26:38Z,http://arxiv.org/pdf/2105.12202v1,"['cs.CL', 'cs.LG']"
2211.04256v1,"Bridging Fairness and Environmental Sustainability in Natural Language
  Processing","['Marius Hessenthaler', 'Emma Strubell', 'Dirk Hovy', 'Anne Lauscher']","Fairness and environmental impact are important research directions for the
sustainable development of artificial intelligence. However, while each topic
is an active research area in natural language processing (NLP), there is a
surprising lack of research on the interplay between the two fields. This
lacuna is highly problematic, since there is increasing evidence that an
exclusive focus on fairness can actually hinder environmental sustainability,
and vice versa. In this work, we shed light on this crucial intersection in NLP
by (1) investigating the efficiency of current fairness approaches through
surveying example methods for reducing unfair stereotypical bias from the
literature, and (2) evaluating a common technique to reduce energy consumption
(and thus environmental impact) of English NLP models, knowledge distillation
(KD), for its impact on fairness. In this case study, we evaluate the effect of
important KD factors, including layer and dimensionality reduction, with
respect to: (a) performance on the distillation task (natural language
inference and semantic similarity prediction), and (b) multiple measures and
dimensions of stereotypical bias (e.g., gender bias measured via the Word
Embedding Association Test). Our results lead us to clarify current assumptions
regarding the effect of KD on unfair bias: contrary to other findings, we show
that KD can actually decrease model fairness.",2022-11-08T14:05:07Z,http://arxiv.org/pdf/2211.04256v1,['cs.CL']
2303.16039v2,"Exploring Natural Language Processing Methods for Interactive Behaviour
  Modelling","['Guanhua Zhang', 'Matteo Bortoletto', 'Zhiming Hu', 'Lei Shi', 'Mihai Bâce', 'Andreas Bulling']","Analysing and modelling interactive behaviour is an important topic in
human-computer interaction (HCI) and a key requirement for the development of
intelligent interactive systems. Interactive behaviour has a sequential
(actions happen one after another) and hierarchical (a sequence of actions
forms an activity driven by interaction goals) structure, which may be similar
to the structure of natural language. Designed based on such a structure,
natural language processing (NLP) methods have achieved groundbreaking success
in various downstream tasks. However, few works linked interactive behaviour
with natural language. In this paper, we explore the similarity between
interactive behaviour and natural language by applying an NLP method, byte pair
encoding (BPE), to encode mouse and keyboard behaviour. We then analyse the
vocabulary, i.e., the set of action sequences, learnt by BPE, as well as use
the vocabulary to encode the input behaviour for interactive task recognition.
An existing dataset collected in constrained lab settings and our novel
out-of-the-lab dataset were used for evaluation. Results show that this natural
language-inspired approach not only learns action sequences that reflect
specific interaction goals, but also achieves higher F1 scores on task
recognition than other methods. Our work reveals the similarity between
interactive behaviour and natural language, and presents the potential of
applying the new pack of methods that leverage insights from NLP to model
interactive behaviour in HCI.",2023-03-28T15:15:03Z,http://arxiv.org/pdf/2303.16039v2,['cs.HC']
2307.04648v1,Can ChatGPT's Responses Boost Traditional Natural Language Processing?,"['Mostafa M. Amin', 'Erik Cambria', 'Björn W. Schuller']","The employment of foundation models is steadily expanding, especially with
the launch of ChatGPT and the release of other foundation models. These models
have shown the potential of emerging capabilities to solve problems, without
being particularly trained to solve. A previous work demonstrated these
emerging capabilities in affective computing tasks; the performance quality was
similar to traditional Natural Language Processing (NLP) techniques, but
falling short of specialised trained models, like fine-tuning of the RoBERTa
language model. In this work, we extend this by exploring if ChatGPT has novel
knowledge that would enhance existing specialised models when they are fused
together. We achieve this by investigating the utility of verbose responses
from ChatGPT about solving a downstream task, in addition to studying the
utility of fusing that with existing NLP methods. The study is conducted on
three affective computing problems, namely sentiment analysis, suicide tendency
detection, and big-five personality assessment. The results conclude that
ChatGPT has indeed novel knowledge that can improve existing NLP techniques by
way of fusion, be it early or late fusion.",2023-07-06T15:42:05Z,http://arxiv.org/pdf/2307.04648v1,"['cs.CL', 'cs.AI']"
2206.02171v3,Near-Term Advances in Quantum Natural Language Processing,"['Dominic Widdows', 'Aaranya Alexander', 'Daiwei Zhu', 'Chase Zimmerman', 'Arunava Majumder']","This paper describes experiments showing that some tasks in natural language
processing (NLP) can already be performed using quantum computers, though so
far only with small datasets.
  We demonstrate various approaches to topic classification. The first uses an
explicit word-based approach, in which word-topic scoring weights are
implemented as fractional rotations of individual qubit, and a new phrase is
classified based on the accumulation of these weights in a scoring qubit using
entangling controlled-NOT gates. This is compared with more scalable quantum
encodings of word embedding vectors, which are used in the computation of
kernel values in a quantum support vector machine: this approach achieved an
average of 62% accuracy on classification tasks involving over 10000 words,
which is the largest such quantum computing experiment to date.
  We describe a quantum probability approach to bigram modeling that can be
applied to sequences of words and formal concepts, investigating a generative
approximation to these distributions using a quantum circuit Born machine, and
an approach to ambiguity resolution in verb-noun composition using single-qubit
rotations for simple nouns and 2-qubit controlled-NOT gates for simple verbs.
  The smaller systems described have been run successfully on physical quantum
computers, and the larger ones have been simulated. We show that statistically
meaningful results can be obtained using real datasets, but this is much more
difficult to predict than with easier artificial language examples used
previously in developing quantum NLP systems.
  Other approaches to quantum NLP are compared, partly with respect to
contemporary issues including informal language, fluency, and truthfulness.",2022-06-05T13:10:46Z,http://arxiv.org/pdf/2206.02171v3,"['cs.CL', 'quant-ph']"
2502.02722v1,Cross-Lingual Transfer for Low-Resource Natural Language Processing,['Iker García-Ferrero'],"Natural Language Processing (NLP) has seen remarkable advances in recent
years, particularly with the emergence of Large Language Models that have
achieved unprecedented performance across many tasks. However, these
developments have mainly benefited a small number of high-resource languages
such as English. The majority of languages still face significant challenges
due to the scarcity of training data and computational resources. To address
this issue, this thesis focuses on cross-lingual transfer learning, a research
area aimed at leveraging data and models from high-resource languages to
improve NLP performance for low-resource languages. Specifically, we focus on
Sequence Labeling tasks such as Named Entity Recognition, Opinion Target
Extraction, and Argument Mining.
  The research is structured around three main objectives: (1) advancing
data-based cross-lingual transfer learning methods through improved translation
and annotation projection techniques, (2) developing enhanced model-based
transfer learning approaches utilizing state-of-the-art multilingual models,
and (3) applying these methods to real-world problems while creating
open-source resources that facilitate future research in low-resource NLP.
  More specifically, this thesis presents a new method to improve data-based
transfer with T-Projection, a state-of-the-art annotation projection method
that leverages text-to-text multilingual models and machine translation
systems. T-Projection significantly outperforms previous annotation projection
methods by a wide margin. For model-based transfer, we introduce a constrained
decoding algorithm that enhances cross-lingual Sequence Labeling in zero-shot
settings using text-to-text models. Finally, we develop Medical mT5, the first
multilingual text-to-text medical model, demonstrating the practical impact of
our research on real-world applications.",2025-02-04T21:17:46Z,http://arxiv.org/pdf/2502.02722v1,['cs.CL']
1805.12518v2,"Incremental Natural Language Processing: Challenges, Strategies, and
  Evaluation",['Arne Köhn'],"Incrementality is ubiquitous in human-human interaction and beneficial for
human-computer interaction. It has been a topic of research in different parts
of the NLP community, mostly with focus on the specific topic at hand even
though incremental systems have to deal with similar challenges regardless of
domain. In this survey, I consolidate and categorize the approaches,
identifying similarities and differences in the computation and data, and show
trade-offs that have to be considered. A focus lies on evaluating incremental
systems because the standard metrics often fail to capture the incremental
properties of a system and coming up with a suitable evaluation scheme is
non-trivial.",2018-05-31T15:29:32Z,http://arxiv.org/pdf/1805.12518v2,['cs.CL']
2106.10899v2,"Ad Text Classification with Transformer-Based Natural Language
  Processing Methods","['Umut Özdil', 'Büşra Arslan', 'D. Emre Taşar', 'Gökçe Polat', 'Şükrü Ozan']","In this study, a natural language processing-based (NLP-based) method is
proposed for the sector-wise automatic classification of ad texts created on
online advertising platforms. Our data set consists of approximately 21,000
labeled advertising texts from 12 different sectors. In the study, the
Bidirectional Encoder Representations from Transformers (BERT) model, which is
a transformer-based language model that is recently used in fields such as text
classification in the natural language processing literature, was used. The
classification efficiencies obtained using a pre-trained BERT model for the
Turkish language are shown in detail.",2021-06-21T07:38:31Z,http://arxiv.org/pdf/2106.10899v2,['cs.CL']
2201.00490v2,Learning with Latent Structures in Natural Language Processing: A Survey,['Zhaofeng Wu'],"While end-to-end learning with fully differentiable models has enabled
tremendous success in natural language process (NLP) and machine learning,
there have been significant recent interests in learning with latent discrete
structures to incorporate better inductive biases for improved end-task
performance and better interpretability. This paradigm, however, is not
straightforwardly amenable to the mainstream gradient-based optimization
methods. This work surveys three main families of methods to learn such models:
surrogate gradients, continuous relaxation, and marginal likelihood
maximization via sampling. We conclude with a review of applications of these
methods and an inspection of the learned latent structure that they induce.",2022-01-03T06:16:17Z,http://arxiv.org/pdf/2201.00490v2,['cs.CL']
2205.11509v1,"Information Propagation by Composited Labels in Natural Language
  Processing",['Takeshi Inagaki'],"In natural language processing (NLP), labeling on regions of text, such as
words, sentences and paragraphs, is a basic task. In this paper, label is
defined as map between mention of entity in a region on text and context of
entity in a broader region on text containing the mention. This definition
naturally introduces linkage of entities induced from inclusion relation of
regions, and connected entities form a graph representing information flow
defined by map. It also enables calculation of information loss through map
using entropy, and entropy lost is regarded as distance between two entities
over a path on graph.",2022-05-23T23:19:14Z,http://arxiv.org/pdf/2205.11509v1,"['cs.CL', 'cs.AI', 'cs.LG']"
2212.05773v2,A Survey on Natural Language Processing for Programming,"['Qingfu Zhu', 'Xianzhen Luo', 'Fang Liu', 'Cuiyun Gao', 'Wanxiang Che']","Natural language processing for programming aims to use NLP techniques to
assist programming. It is increasingly prevalent for its effectiveness in
improving productivity. Distinct from natural language, a programming language
is highly structured and functional. Constructing a structure-based
representation and a functionality-oriented algorithm is at the heart of
program understanding and generation. In this paper, we conduct a systematic
review covering tasks, datasets, evaluation methods, techniques, and models
from the perspective of the structure-based and functionality-oriented
property, aiming to understand the role of the two properties in each
component. Based on the analysis, we illustrate unexplored areas and suggest
potential directions for future work.",2022-12-12T08:51:30Z,http://arxiv.org/pdf/2212.05773v2,['cs.CL']
2402.02864v1,EEVEE: An Easy Annotation Tool for Natural Language Processing,"['Axel Sorensen', 'Siyao Peng', 'Barbara Plank', 'Rob van der Goot']","Annotation tools are the starting point for creating Natural Language
Processing (NLP) datasets. There is a wide variety of tools available; setting
up these tools is however a hindrance. We propose EEVEE, an annotation tool
focused on simplicity, efficiency, and ease of use. It can run directly in the
browser (no setup required) and uses tab-separated files (as opposed to
character offsets or task-specific formats) for annotation. It allows for
annotation of multiple tasks on a single dataset and supports four task-types:
sequence labeling, span labeling, text classification and seq2seq.",2024-02-05T10:24:40Z,http://arxiv.org/pdf/2402.02864v1,"['cs.CL', 'cs.HC']"
1710.01025v3,"MMCR4NLP: Multilingual Multiway Corpora Repository for Natural Language
  Processing","['Raj Dabre', 'Sadao Kurohashi']","Multilinguality is gradually becoming ubiquitous in the sense that more and
more researchers have successfully shown that using additional languages help
improve the results in many Natural Language Processing tasks. Multilingual
Multiway Corpora (MMC) contain the same sentence in multiple languages. Such
corpora have been primarily used for Multi-Source and Pivot Language Machine
Translation but are also useful for developing multilingual sequence taggers by
transfer learning. While these corpora are available, they are not organized
for multilingual experiments and researchers need to write boilerplate code
every time they want to use said corpora. Moreover, because there is no
official MMC collection it becomes difficult to compare against existing
approaches. As such we present our work on creating a unified and
systematically organized repository of MMC spanning a large number of
languages. We also provide training, development and test splits for corpora
where official splits are unavailable. We hope that this will help speed up the
pace of multilingual NLP research and ensure that NLP researchers obtain
results that are more trustable since they can be compared easily. We indicate
corpora sources, extraction procedures if any and relevant statistics. We also
make our collection public for research purposes.",2017-10-03T08:19:24Z,http://arxiv.org/pdf/1710.01025v3,['cs.CL']
1803.07136v1,"Dynamic Natural Language Processing with Recurrence Quantification
  Analysis","['Rick Dale', 'Nicholas D. Duran', 'Moreno Coco']","Writing and reading are dynamic processes. As an author composes a text, a
sequence of words is produced. This sequence is one that, the author hopes,
causes a revisitation of certain thoughts and ideas in others. These processes
of composition and revisitation by readers are ordered in time. This means that
text itself can be investigated under the lens of dynamical systems. A common
technique for analyzing the behavior of dynamical systems, known as recurrence
quantification analysis (RQA), can be used as a method for analyzing sequential
structure of text. RQA treats text as a sequential measurement, much like a
time series, and can thus be seen as a kind of dynamic natural language
processing (NLP). The extension has several benefits. Because it is part of a
suite of time series analysis tools, many measures can be extracted in one
common framework. Secondly, the measures have a close relationship with some
commonly used measures from natural language processing. Finally, using
recurrence analysis offers an opportunity expand analysis of text by developing
theoretical descriptions derived from complex dynamic systems. We showcase an
example analysis on 8,000 texts from the Gutenberg Project, compare it to
well-known NLP approaches, and describe an R package (crqanlp) that can be used
in conjunction with R library crqa.",2018-03-19T19:45:38Z,http://arxiv.org/pdf/1803.07136v1,['cs.CL']
2004.04361v2,Calibrating Structured Output Predictors for Natural Language Processing,"['Abhyuday Jagannatha', 'Hong Yu']","We address the problem of calibrating prediction confidence for output
entities of interest in natural language processing (NLP) applications. It is
important that NLP applications such as named entity recognition and question
answering produce calibrated confidence scores for their predictions,
especially if the system is to be deployed in a safety-critical domain such as
healthcare. However, the output space of such structured prediction models is
often too large to adapt binary or multi-class calibration methods directly. In
this study, we propose a general calibration scheme for output entities of
interest in neural-network based structured prediction models. Our proposed
method can be used with any binary class calibration scheme and a neural
network model. Additionally, we show that our calibration method can also be
used as an uncertainty-aware, entity-specific decoding step to improve the
performance of the underlying model at no additional training cost or data
requirements. We show that our method outperforms current calibration
techniques for named-entity-recognition, part-of-speech and question answering.
We also improve our model's performance from our decoding step across several
tasks and benchmark datasets. Our method improves the calibration and model
performance on out-of-domain test scenarios as well.",2020-04-09T04:14:46Z,http://arxiv.org/pdf/2004.04361v2,"['cs.CL', 'cs.LG']"
2006.07116v1,"NAS-Bench-NLP: Neural Architecture Search Benchmark for Natural Language
  Processing","['Nikita Klyuchnikov', 'Ilya Trofimov', 'Ekaterina Artemova', 'Mikhail Salnikov', 'Maxim Fedorov', 'Evgeny Burnaev']","Neural Architecture Search (NAS) is a promising and rapidly evolving research
area. Training a large number of neural networks requires an exceptional amount
of computational power, which makes NAS unreachable for those researchers who
have limited or no access to high-performance clusters and supercomputers. A
few benchmarks with precomputed neural architectures performances have been
recently introduced to overcome this problem and ensure more reproducible
experiments. However, these benchmarks are only for the computer vision domain
and, thus, are built from the image datasets and convolution-derived
architectures. In this work, we step outside the computer vision domain by
leveraging the language modeling task, which is the core of natural language
processing (NLP). Our main contribution is as follows: we have provided search
space of recurrent neural networks on the text datasets and trained 14k
architectures within it; we have conducted both intrinsic and extrinsic
evaluation of the trained models using datasets for semantic relatedness and
language understanding evaluation; finally, we have tested several NAS
algorithms to demonstrate how the precomputed results can be utilized. We
believe that our results have high potential of usage for both NAS and NLP
communities.",2020-06-12T12:19:06Z,http://arxiv.org/pdf/2006.07116v1,"['cs.LG', 'cs.CL', 'stat.ML']"
2108.04990v2,"Perturbing Inputs for Fragile Interpretations in Deep Natural Language
  Processing","['Sanchit Sinha', 'Hanjie Chen', 'Arshdeep Sekhon', 'Yangfeng Ji', 'Yanjun Qi']","Interpretability methods like Integrated Gradient and LIME are popular
choices for explaining natural language model predictions with relative word
importance scores. These interpretations need to be robust for trustworthy NLP
applications in high-stake areas like medicine or finance. Our paper
demonstrates how interpretations can be manipulated by making simple word
perturbations on an input text. Via a small portion of word-level swaps, these
adversarial perturbations aim to make the resulting text semantically and
spatially similar to its seed input (therefore sharing similar
interpretations). Simultaneously, the generated examples achieve the same
prediction label as the seed yet are given a substantially different
explanation by the interpretation methods. Our experiments generate fragile
interpretations to attack two SOTA interpretation methods, across three popular
Transformer models and on two different NLP datasets. We observe that the rank
order correlation drops by over 20% when less than 10% of words are perturbed
on average. Further, rank-order correlation keeps decreasing as more words get
perturbed. Furthermore, we demonstrate that candidates generated from our
method have good quality metrics.",2021-08-11T02:07:21Z,http://arxiv.org/pdf/2108.04990v2,['cs.CL']
2202.13871v2,Wastewater Pipe Rating Model Using Natural Language Processing,"['Sai Nethra Betgeri', 'Shashank Reddy Vadyala', 'John C. Mattews', 'Hongfang Lu']","Closed-circuit video (CCTV) inspection has been the most popular technique
for visually evaluating the interior status of pipelines in recent decades.
Certified inspectors prepare the pipe repair document based on the CCTV
inspection. The traditional manual method of assessing sewage structural
conditions from pipe repair documents takes a long time and is prone to human
mistakes. The automatic identification of necessary texts has received little
attention. By building an automated framework employing Natural Language
Processing (NLP), this study presents an effective technique to automate the
identification of the pipe defect rating of the pipe repair documents. NLP
technologies are employed to break down textual material into grammatical units
in this research. Further analysis entails using words to discover pipe defect
symptoms and their frequency and then combining that information into a single
score. Our model achieves 95.0% accuracy,94.9% sensitivity, 94.4% specificity,
95.9% precision score, and 95.7% F1 score, showing the potential of the
proposed model to be used in large-scale pipe repair documents for accurate and
efficient pipeline failure detection to improve the quality of the pipeline.
Keywords: Sewer pipe inspection, Defect detection, Natural language processing,
Text recognition",2022-02-22T18:03:24Z,http://arxiv.org/pdf/2202.13871v2,"['cs.IR', 'cs.LG']"
1910.07370v1,Evolution of transfer learning in natural language processing,"['Aditya Malte', 'Pratik Ratadiya']","In this paper, we present a study of the recent advancements which have
helped bring Transfer Learning to NLP through the use of semi-supervised
training. We discuss cutting-edge methods and architectures such as BERT, GPT,
ELMo, ULMFit among others. Classically, tasks in natural language processing
have been performed through rule-based and statistical methodologies. However,
owing to the vast nature of natural languages these methods do not generalise
well and failed to learn the nuances of language. Thus machine learning
algorithms such as Naive Bayes and decision trees coupled with traditional
models such as Bag-of-Words and N-grams were used to usurp this problem.
Eventually, with the advent of advanced recurrent neural network architectures
such as the LSTM, we were able to achieve state-of-the-art performance in
several natural language processing tasks such as text classification and
machine translation. We talk about how Transfer Learning has brought about the
well-known ImageNet moment for NLP. Several advanced architectures such as the
Transformer and its variants have allowed practitioners to leverage knowledge
gained from unrelated task to drastically fasten convergence and provide better
performance on the target task. This survey represents an effort at providing a
succinct yet complete understanding of the recent advances in natural language
processing using deep learning in with a special focus on detailing transfer
learning and its potential advantages.",2019-10-16T14:24:37Z,http://arxiv.org/pdf/1910.07370v1,['cs.CL']
1911.03268v1,Inducing brain-relevant bias in natural language processing models,"['Dan Schwartz', 'Mariya Toneva', 'Leila Wehbe']","Progress in natural language processing (NLP) models that estimate
representations of word sequences has recently been leveraged to improve the
understanding of language processing in the brain. However, these models have
not been specifically designed to capture the way the brain represents language
meaning. We hypothesize that fine-tuning these models to predict recordings of
brain activity of people reading text will lead to representations that encode
more brain-activity-relevant language information. We demonstrate that a
version of BERT, a recently introduced and powerful language model, can improve
the prediction of brain activity after fine-tuning. We show that the
relationship between language and brain activity learned by BERT during this
fine-tuning transfers across multiple participants. We also show that, for some
participants, the fine-tuned representations learned from both
magnetoencephalography (MEG) and functional magnetic resonance imaging (fMRI)
are better for predicting fMRI than the representations learned from fMRI
alone, indicating that the learned representations capture
brain-activity-relevant information that is not simply an artifact of the
modality. While changes to language representations help the model predict
brain activity, they also do not harm the model's ability to perform downstream
NLP tasks. Our findings are notable for research on language understanding in
the brain.",2019-10-29T23:28:16Z,http://arxiv.org/pdf/1911.03268v1,"['q-bio.NC', 'cs.CL', 'cs.LG']"
2112.14168v1,A Survey on Gender Bias in Natural Language Processing,"['Karolina Stanczak', 'Isabelle Augenstein']","Language can be used as a means of reproducing and enforcing harmful
stereotypes and biases and has been analysed as such in numerous research. In
this paper, we present a survey of 304 papers on gender bias in natural
language processing. We analyse definitions of gender and its categories within
social sciences and connect them to formal definitions of gender bias in NLP
research. We survey lexica and datasets applied in research on gender bias and
then compare and contrast approaches to detecting and mitigating gender bias.
We find that research on gender bias suffers from four core limitations. 1)
Most research treats gender as a binary variable neglecting its fluidity and
continuity. 2) Most of the work has been conducted in monolingual setups for
English or other high-resource languages. 3) Despite a myriad of papers on
gender bias in NLP methods, we find that most of the newly developed algorithms
do not test their models for bias and disregard possible ethical considerations
of their work. 4) Finally, methodologies developed in this line of research are
fundamentally flawed covering very limited definitions of gender bias and
lacking evaluation baselines and pipelines. We suggest recommendations towards
overcoming these limitations as a guide for future research.",2021-12-28T14:54:18Z,http://arxiv.org/pdf/2112.14168v1,"['cs.CL', 'cs.CY']"
2208.08887v1,Brand Celebrity Matching Model Based on Natural Language Processing,"['Heming Yang', 'Ke Yang', 'Erhan Zhang']","Celebrity Endorsement is one of the most significant strategies in brand
communication. Nowadays, more and more companies try to build a vivid
characteristic for themselves. Therefore, their brand identity communications
should accord with some characteristics as humans and regulations. However, the
previous works mostly stop by assumptions, instead of proposing a specific way
to perform matching between brands and celebrities. In this paper, we propose a
brand celebrity matching model (BCM) based on Natural Language Processing (NLP)
techniques. Given a brand and a celebrity, we firstly obtain some descriptive
documents of them from the Internet, then summarize these documents, and
finally calculate a matching degree between the brand and the celebrity to
determine whether they are matched. According to the experimental result, our
proposed model outperforms the best baselines with a 0.362 F1 score and 6.3% of
accuracy, which indicates the effectiveness and application value of our model
in the real-world scene. What's more, to our best knowledge, the proposed BCM
model is the first work on using NLP to solve endorsement issues, so it can
provide some novel research ideas and methodologies for the following works.",2022-08-18T15:07:14Z,http://arxiv.org/pdf/2208.08887v1,['cs.CL']
2211.02899v1,"Tri-Attention: Explicit Context-Aware Attention Mechanism for Natural
  Language Processing","['Rui Yu', 'Yifeng Li', 'Wenpeng Lu', 'Longbing Cao']","In natural language processing (NLP), the context of a word or sentence plays
an essential role. Contextual information such as the semantic representation
of a passage or historical dialogue forms an essential part of a conversation
and a precise understanding of the present phrase or sentence. However, the
standard attention mechanisms typically generate weights using query and key
but ignore context, forming a Bi-Attention framework, despite their great
success in modeling sequence alignment. This Bi-Attention mechanism does not
explicitly model the interactions between the contexts, queries and keys of
target sequences, missing important contextual information and resulting in
poor attention performance. Accordingly, a novel and general triple-attention
(Tri-Attention) framework expands the standard Bi-Attention mechanism and
explicitly interacts query, key, and context by incorporating context as the
third dimension in calculating relevance scores. Four variants of Tri-Attention
are generated by expanding the two-dimensional vector-based additive,
dot-product, scaled dot-product, and bilinear operations in Bi-Attention to the
tensor operations for Tri-Attention. Extensive experiments on three NLP tasks
demonstrate that Tri-Attention outperforms about 30 state-of-the-art
non-attention, standard Bi-Attention, contextual Bi-Attention approaches and
pretrained neural language models1.",2022-11-05T13:07:40Z,http://arxiv.org/pdf/2211.02899v1,"['cs.CL', 'cs.AI']"
2212.09523v1,Natural Language Processing in Customer Service: A Systematic Review,"['Malak Mashaabi', 'Areej Alotaibi', 'Hala Qudaih', 'Raghad Alnashwan', 'Hend Al-Khalifa']","Artificial intelligence and natural language processing (NLP) are
increasingly being used in customer service to interact with users and answer
their questions. The goal of this systematic review is to examine existing
research on the use of NLP technology in customer service, including the
research domain, applications, datasets used, and evaluation methods. The
review also looks at the future direction of the field and any significant
limitations. The review covers the time period from 2015 to 2022 and includes
papers from five major scientific databases. Chatbots and question-answering
systems were found to be used in 10 main fields, with the most common use in
general, social networking, and e-commerce areas. Twitter was the second most
commonly used dataset, with most research also using their own original
datasets. Accuracy, precision, recall, and F1 were the most common evaluation
methods. Future work aims to improve the performance and understanding of user
behavior and emotions, and address limitations such as the volume, diversity,
and quality of datasets. This review includes research on different spoken
languages and models and techniques.",2022-12-16T18:17:07Z,http://arxiv.org/pdf/2212.09523v1,"['cs.CL', 'cs.AI']"
2409.04491v2,"Protein sequence classification using natural language processing
  techniques","['Huma Perveen', 'Julie Weeds']","Purpose: This study aimed to enhance protein sequence classification using
natural language processing (NLP) techniques while addressing the impact of
sequence similarity on model performance. We compared various machine learning
and deep learning models under two different data-splitting strategies: random
splitting and ECOD family-based splitting, which ensures evolutionary-related
sequences are grouped together. Methods: The study evaluated models such as
K-Nearest Neighbors (KNN), Multinomial Na\""ive Bayes, Logistic Regression,
Multi-Layer Perceptron (MLP), Decision Tree, Random Forest, XGBoost, Voting and
Stacking classifiers, Convolutional Neural Network (CNN), Long Short-Term
Memory (LSTM), and transformer models (BertForSequenceClassification,
DistilBERT, and ProtBert). Performance was tested using different amino acid
ranges and sequence lengths with a focus on generalization across unseen
evolutionary families. Results: The Voting classifier achieved the highest
performance with 74% accuracy, 74% weighted F1 score, and 65% macro F1 score
under random splitting, while ProtBERT obtained 77% accuracy, 76% weighted F1
score, and 61% macro F1 score among transformer models. However, performance
declined across all models when tested using ECOD-based splitting, revealing
the impact of sequence similarity on classification performance. Conclusion:
Advanced NLP techniques, particularly ensemble methods like Voting classifiers,
and transformer models show significant potential in protein classification,
with sufficient training data and sequence similarity management being crucial
for optimal performance. However, the use of biologically meaningful splitting
methods, such as ECOD family-based splitting, is crucial for realistic
performance evaluation and generalization to unseen evolutionary families.",2024-09-06T13:16:16Z,http://arxiv.org/pdf/2409.04491v2,"['q-bio.QM', 'cs.LG']"
2509.12782v1,Designing Shadow Tomography Protocols by Natural Language Processing,"['Yadong Wu', 'Pengfei Zhang', 'Ce Wang', 'Juan Yao', 'Yi-Zhuang You']","Quantum circuits form a foundational framework in quantum science, enabling
the description, analysis, and implementation of quantum computations. However,
designing efficient circuits, typically constructed from single- and two-qubit
gates, remains a major challenge for specific computational tasks. In this
work, we introduce a novel artificial intelligence-driven protocol for quantum
circuit design, benchmarked using shadow tomography for efficient quantum state
readout. Inspired by techniques from natural language processing (NLP), our
approach first selects a compact gate dictionary by optimizing the entangling
power of two-qubit gates. We identify the iSWAP gate as a key element that
significantly enhances sample efficiency, resulting in a minimal gate set of
{I, SWAP, iSWAP}. Building on this, we implement a recurrent neural network
trained via reinforcement learning to generate high-performing quantum
circuits. The trained model demonstrates strong generalization ability,
discovering efficient circuit architectures with low sample complexity beyond
the training set. Our NLP-inspired framework offers broad potential for quantum
computation, including extracting properties of logical qubits in quantum error
correction.",2025-09-16T07:58:43Z,http://arxiv.org/pdf/2509.12782v1,['quant-ph']
1510.07439v1,"Object Oriented Analysis using Natural Language Processing concepts: A
  Review","['Abinash Tripathy', 'Santanu Kumar Rath']","The Software Development Life Cycle (SDLC) starts with eliciting requirements
of the customers in the form of Software Requirement Specification (SRS). SRS
document needed for software development is mostly written in Natural
Language(NL) convenient for the client. From the SRS document only, the class
name, its attributes and the functions incorporated in the body of the class
are traced based on pre-knowledge of analyst. The paper intends to present a
review on Object Oriented (OO) analysis using Natural Language Processing (NLP)
techniques. This analysis can be manual where domain expert helps to generate
the required diagram or automated system, where the system generates the
required diagram, from the input in the form of SRS.",2015-10-26T11:12:59Z,http://arxiv.org/pdf/1510.07439v1,"['cs.SE', 'cs.CL']"
1903.01039v4,SECNLP: A Survey of Embeddings in Clinical Natural Language Processing,"['Kalyan KS', 'S Sangeetha']","Traditional representations like Bag of words are high dimensional, sparse
and ignore the order as well as syntactic and semantic information. Distributed
vector representations or embeddings map variable length text to dense fixed
length vectors as well as capture the prior knowledge which can transferred to
downstream tasks. Even though embedding has become de facto standard for
representations in deep learning based NLP tasks in both general and clinical
domains, there is no survey paper which presents a detailed review of
embeddings in Clinical Natural Language Processing. In this survey paper, we
discuss various medical corpora and their characteristics, medical codes and
present a brief overview as well as comparison of popular embeddings models. We
classify clinical embeddings into nine types and discuss each embedding type in
detail. We discuss various evaluation methods followed by possible solutions to
various challenges in clinical embeddings. Finally, we conclude with some of
the future directions which will advance the research in clinical embeddings.",2019-03-04T01:37:52Z,http://arxiv.org/pdf/1903.01039v4,['cs.CL']
2103.11072v3,"Local Interpretations for Explainable Natural Language Processing: A
  Survey","['Siwen Luo', 'Hamish Ivison', 'Caren Han', 'Josiah Poon']","As the use of deep learning techniques has grown across various fields over
the past decade, complaints about the opaqueness of the black-box models have
increased, resulting in an increased focus on transparency in deep learning
models. This work investigates various methods to improve the interpretability
of deep neural networks for Natural Language Processing (NLP) tasks, including
machine translation and sentiment analysis. We provide a comprehensive
discussion on the definition of the term interpretability and its various
aspects at the beginning of this work. The methods collected and summarised in
this survey are only associated with local interpretation and are specifically
divided into three categories: 1) interpreting the model's predictions through
related input features; 2) interpreting through natural language explanation;
3) probing the hidden states of models and word representations.",2021-03-20T02:28:33Z,http://arxiv.org/pdf/2103.11072v3,"['cs.CL', 'cs.AI', 'A.1; I.2.7']"
2104.12846v2,Teaching a Massive Open Online Course on Natural Language Processing,"['Ekaterina Artemova', 'Murat Apishev', 'Veronika Sarkisyan', 'Sergey Aksenov', 'Denis Kirjanov', 'Oleg Serikov']","This paper presents a new Massive Open Online Course on Natural Language
Processing, targeted at non-English speaking students. The course lasts 12
weeks; every week consists of lectures, practical sessions, and quiz
assignments. Three weeks out of 12 are followed by Kaggle-style coding
assignments.
  Our course intends to serve multiple purposes: (i) familiarize students with
the core concepts and methods in NLP, such as language modeling or word or
sentence representations, (ii) show that recent advances, including pre-trained
Transformer-based models, are built upon these concepts; (iii) introduce
architectures for most demanded real-life applications, (iv) develop practical
skills to process texts in multiple languages. The course was prepared and
recorded during 2020, launched by the end of the year, and in early 2021 has
received positive feedback.",2021-04-26T19:52:00Z,http://arxiv.org/pdf/2104.12846v2,['cs.CL']
2202.07101v2,A Survey on Dynamic Neural Networks for Natural Language Processing,"['Canwen Xu', 'Julian McAuley']","Effectively scaling large Transformer models is a main driver of recent
advances in natural language processing. Dynamic neural networks, as an
emerging research direction, are capable of scaling up neural networks with
sub-linear increases in computation and time by dynamically adjusting their
computational path based on the input. Dynamic neural networks could be a
promising solution to the growing parameter numbers of pretrained language
models, allowing both model pretraining with trillions of parameters and faster
inference on mobile devices. In this survey, we summarize progress of three
types of dynamic neural networks in NLP: skimming, mixture of experts, and
early exit. We also highlight current challenges in dynamic neural networks and
directions for future research.",2022-02-15T00:13:05Z,http://arxiv.org/pdf/2202.07101v2,"['cs.CL', 'cs.AI', 'cs.LG']"
2202.11766v1,A gentle introduction to Quantum Natural Language Processing,"['Shervin Le Du', 'Senaida Hernández Santana', 'Giannicola Scarpa']","The main goal of this master's thesis is to introduce Quantum Natural
Language Processing (QNLP) in a way understandable by both the NLP engineer and
the quantum computing practitioner. QNLP is a recent application of quantum
computing that aims at representing sentences' meaning as vectors encoded into
quantum computers. To achieve this, the distributional meaning of words is
extended by the compositional meaning of sentences (DisCoCat model) : the
vectors representing words' meanings are composed through the syntactic
structure of the sentence. This is done using an algorithm based on tensor
products. We see that this algorithm is inefficient on classical computers but
scales well using quantum circuits. After exposing the practical details of its
implementation, we go through three use-cases.",2022-02-23T20:17:00Z,http://arxiv.org/pdf/2202.11766v1,['cs.CL']
1807.06638v1,"Developing a Portable Natural Language Processing Based Phenotyping
  System","['Himanshu Sharma', 'Chengsheng Mao', 'Yizhen Zhang', 'Haleh Vatani', 'Liang Yao', 'Yizhen Zhong', 'Luke Rasmussen', 'Guoqian Jiang', 'Jyotishman Pathak', 'Yuan Luo']","This paper presents a portable phenotyping system that is capable of
integrating both rule-based and statistical machine learning based approaches.
Our system utilizes UMLS to extract clinically relevant features from the
unstructured text and then facilitates portability across different
institutions and data systems by incorporating OHDSI's OMOP Common Data Model
(CDM) to standardize necessary data elements. Our system can also store the key
components of rule-based systems (e.g., regular expression matches) in the
format of OMOP CDM, thus enabling the reuse, adaptation and extension of many
existing rule-based clinical NLP systems. We experimented with our system on
the corpus from i2b2's Obesity Challenge as a pilot study. Our system
facilitates portable phenotyping of obesity and its 15 comorbidities based on
the unstructured patient discharge summaries, while achieving a performance
that often ranked among the top 10 of the challenge participants. This
standardization enables a consistent application of numerous rule-based and
machine learning based classification techniques downstream.",2018-07-17T19:40:28Z,http://arxiv.org/pdf/1807.06638v1,"['cs.CL', 'cs.IR']"
2110.01852v3,Data Augmentation Approaches in Natural Language Processing: A Survey,"['Bohan Li', 'Yutai Hou', 'Wanxiang Che']","As an effective strategy, data augmentation (DA) alleviates data scarcity
scenarios where deep learning techniques may fail. It is widely applied in
computer vision then introduced to natural language processing and achieves
improvements in many tasks. One of the main focuses of the DA methods is to
improve the diversity of training data, thereby helping the model to better
generalize to unseen testing data. In this survey, we frame DA methods into
three categories based on the diversity of augmented data, including
paraphrasing, noising, and sampling. Our paper sets out to analyze DA methods
in detail according to the above categories. Further, we also introduce their
applications in NLP tasks as well as the challenges. Some helpful resources are
provided in the appendix.",2021-10-05T07:35:32Z,http://arxiv.org/pdf/2110.01852v3,"['cs.CL', 'cs.AI', 'cs.LG']"
2112.15471v2,A Survey on Using Gaze Behaviour for Natural Language Processing,"['Sandeep Mathias', 'Diptesh Kanojia', 'Abhijit Mishra', 'Pushpak Bhattacharyya']","Gaze behaviour has been used as a way to gather cognitive information for a
number of years. In this paper, we discuss the use of gaze behaviour in solving
different tasks in natural language processing (NLP) without having to record
it at test time. This is because the collection of gaze behaviour is a costly
task, both in terms of time and money. Hence, in this paper, we focus on
research done to alleviate the need for recording gaze behaviour at run time.
We also mention different eye tracking corpora in multiple languages, which are
currently available and can be used in natural language processing. We conclude
our paper by discussing applications in a domain - education - and how learning
gaze behaviour can help in solving the tasks of complex word identification and
automatic essay grading.",2021-12-21T15:52:56Z,http://arxiv.org/pdf/2112.15471v2,['cs.CL']
2206.11862v1,"Urdu News Article Recommendation Model using Natural Language Processing
  Techniques","['Syed Zain Abbas', 'Arif ur Rahman', 'Abdul Basit Mughal', 'Syed Mujtaba Haider']","There are several online newspapers in urdu but for the users it is difficult
to find the content they are looking for because these most of them contain
irrelevant data and most users did not get what they want to retrieve. Our
proposed framework will help to predict Urdu news in the interests of users and
reduce the users searching time for news. For this purpose, NLP techniques are
used for pre-processing, and then TF-IDF with cosine similarity is used for
gaining the highest similarity and recommended news on user preferences.
Moreover, the BERT language model is also used for similarity, and by using the
BERT model similarity increases as compared to TF-IDF so the approach works
better with the BERT language model and recommends news to the user on their
interest. The news is recommended when the similarity of the articles is above
60 percent.",2022-05-29T12:43:32Z,http://arxiv.org/pdf/2206.11862v1,"['cs.IR', 'cs.CL', 'cs.LG']"
2211.02956v1,Privacy-Preserving Models for Legal Natural Language Processing,"['Ying Yin', 'Ivan Habernal']","Pre-training large transformer models with in-domain data improves domain
adaptation and helps gain performance on the domain-specific downstream tasks.
However, sharing models pre-trained on potentially sensitive data is prone to
adversarial privacy attacks. In this paper, we asked to which extent we can
guarantee privacy of pre-training data and, at the same time, achieve better
downstream performance on legal tasks without the need of additional labeled
data. We extensively experiment with scalable self-supervised learning of
transformer models under the formal paradigm of differential privacy and show
that under specific training configurations we can improve downstream
performance without sacrifying privacy protection for the in-domain data. Our
main contribution is utilizing differential privacy for large-scale
pre-training of transformer language models in the legal NLP domain, which, to
the best of our knowledge, has not been addressed before.",2022-11-05T18:10:50Z,http://arxiv.org/pdf/2211.02956v1,['cs.CL']
2211.09680v1,"Analyse der Entwicklungstreiber militärischer Schwarmdrohnen durch
  Natural Language Processing",['Manuel Mundt'],"Military drones are taking an increasingly prominent role in armed conflict,
and the use of multiple drones in a swarm can be useful. Who the drivers of the
research are and what sub-domains exist is analyzed and visually presented in
this research using NLP techniques based on 946 studies. Most research is
conducted in the Western world, led by the United States, the United Kingdom,
and Germany. Through Tf-idf scoring, it is shown that countries have
significant differences in the subdomains studied. Overall, 2019 and 2020 saw
the most works published, with significant interest in military swarm drones as
early as 2008. This study provides a first glimpse into research in this area
and prompts further investigation.",2022-11-15T20:22:33Z,http://arxiv.org/pdf/2211.09680v1,"['cs.CL', 'cs.LG', 'cs.RO', '68U15', 'I.2.7']"
2303.05666v1,Research on CPI Prediction Based on Natural Language Processing,"['Xiaobin Tang', 'Nuo Lei']","In the past, the seed keywords for CPI prediction were often selected based
on empirical summaries of research and literature studies, which were prone to
select omitted and invalid variables. In this paper, we design a keyword
expansion technique for CPI prediction based on the cutting-edge NLP model,
PANGU. We improve the CPI prediction ability using the corresponding web search
index. Compared with the unsupervised pre-training and supervised downstream
fine-tuning natural language processing models such as BERT and NEZHA, the
PANGU model can be expanded to obtain more reliable CPI-generated keywords by
its excellent zero-sample learning capability without the limitation of the
downstream fine-tuning data set. Finally, this paper empirically tests the
keyword prediction ability obtained by this keyword expansion method with
historical CPI data.",2023-03-10T02:41:47Z,http://arxiv.org/pdf/2303.05666v1,"['econ.GN', 'q-fin.EC']"
2401.01487v1,Natural Language Processing and Multimodal Stock Price Prediction,"['Kevin Taylor', 'Jerry Ng']","In the realm of financial decision-making, predicting stock prices is
pivotal. Artificial intelligence techniques such as long short-term memory
networks (LSTMs), support-vector machines (SVMs), and natural language
processing (NLP) models are commonly employed to predict said prices. This
paper utilizes stock percentage change as training data, in contrast to the
traditional use of raw currency values, with a focus on analyzing publicly
released news articles. The choice of percentage change aims to provide models
with context regarding the significance of price fluctuations and overall price
change impact on a given stock. The study employs specialized BERT natural
language processing models to predict stock price trends, with a particular
emphasis on various data modalities. The results showcase the capabilities of
such strategies with a small natural language processing model to accurately
predict overall stock trends, and highlight the effectiveness of certain data
features and sector-specific data.",2024-01-03T01:21:30Z,http://arxiv.org/pdf/2401.01487v1,"['cs.LG', 'cs.CL']"
2407.13193v3,Retrieval-Augmented Generation for Natural Language Processing: A Survey,"['Shangyu Wu', 'Ying Xiong', 'Yufei Cui', 'Haolun Wu', 'Can Chen', 'Ye Yuan', 'Lianming Huang', 'Xue Liu', 'Tei-Wei Kuo', 'Nan Guan', 'Chun Jason Xue']","Large language models (LLMs) have demonstrated great success in various
fields, benefiting from their huge amount of parameters that store knowledge.
However, LLMs still suffer from several key issues, such as hallucination
problems, knowledge update issues, and lacking domain-specific expertise. The
appearance of retrieval-augmented generation (RAG), which leverages an external
knowledge database to augment LLMs, makes up those drawbacks of LLMs. This
paper reviews all significant techniques of RAG, especially in the retriever
and the retrieval fusions. Besides, tutorial codes are provided for
implementing the representative techniques in RAG. This paper further discusses
the RAG update, including RAG with/without knowledge update. Then, we introduce
RAG evaluation and benchmarking, as well as the application of RAG in
representative NLP tasks and industrial scenarios. Finally, this paper
discusses RAG's future directions and challenges for promoting this field's
development.",2024-07-18T06:06:53Z,http://arxiv.org/pdf/2407.13193v3,['cs.CL']
2410.12759v1,Unitary Multi-Margin BERT for Robust Natural Language Processing,"['Hao-Yuan Chang', 'Kang L. Wang']","Recent developments in adversarial attacks on deep learning leave many
mission-critical natural language processing (NLP) systems at risk of
exploitation. To address the lack of computationally efficient adversarial
defense methods, this paper reports a novel, universal technique that
drastically improves the robustness of Bidirectional Encoder Representations
from Transformers (BERT) by combining the unitary weights with the multi-margin
loss. We discover that the marriage of these two simple ideas amplifies the
protection against malicious interference. Our model, the unitary multi-margin
BERT (UniBERT), boosts post-attack classification accuracies significantly by
5.3% to 73.8% while maintaining competitive pre-attack accuracies. Furthermore,
the pre-attack and post-attack accuracy tradeoff can be adjusted via a single
scalar parameter to best fit the design requirements for the target
applications.",2024-10-16T17:30:58Z,http://arxiv.org/pdf/2410.12759v1,"['cs.CL', 'cs.AI']"
2505.02199v1,"Exploring new Approaches for Information Retrieval through Natural
  Language Processing","['Manak Raj', 'Nidhi Mishra']","This review paper explores recent advancements and emerging approaches in
Information Retrieval (IR) applied to Natural Language Processing (NLP). We
examine traditional IR models such as Boolean, vector space, probabilistic, and
inference network models, and highlight modern techniques including deep
learning, reinforcement learning, and pretrained transformer models like BERT.
We discuss key tools and libraries - Lucene, Anserini, and Pyserini - for
efficient text indexing and search. A comparative analysis of sparse, dense,
and hybrid retrieval methods is presented, along with applications in web
search engines, cross-language IR, argument mining, private information
retrieval, and hate speech detection. Finally, we identify open challenges and
future research directions to enhance retrieval accuracy, scalability, and
ethical considerations.",2025-05-04T17:37:26Z,http://arxiv.org/pdf/2505.02199v1,"['cs.IR', 'cs.CL', '68T50', 'H.3.3; I.2.7']"
2501.14701v2,"An Unsupervised Natural Language Processing Pipeline for Assessing
  Referral Appropriateness","['Vittorio Torri', 'Annamaria Bottelli', 'Michele Ercolanoni', 'Olivia Leoni', 'Francesca Ieva']","Objective: Assessing the appropriateness of diagnostic referrals is critical
for improving healthcare efficiency and reducing unnecessary procedures.
However, this task becomes challenging when referral reasons are recorded only
as free text rather than structured codes, like in the Italian NHS. To address
this gap, we propose a fully unsupervised Natural Language Processing (NLP)
pipeline capable of extracting and evaluating referral reasons without relying
on labelled datasets.
  Methods: Our pipeline leverages Transformer-based embeddings pre-trained on
Italian medical texts to cluster referral reasons and assess their alignment
with appropriateness guidelines. It operates in an unsupervised setting and is
designed to generalize across different examination types. We analyzed two
complete regional datasets from the Lombardy Region (Italy), covering all
referrals between 2019 and 2021 for venous echocolordoppler of the lower limbs
(ECD;n=496,971; development) and flexible endoscope colonoscopy (FEC;
n=407,949; testing only). For both, a random sample of 1,000 referrals was
manually annotated to measure performance.
  Results: The pipeline achieved high performance in identifying referral
reasons (Prec=92.43% (ECD), 93.59% (FEC); Rec=83.28% (ECD), 92.70% (FEC)) and
appropriateness (Prec=93.58% (ECD), 94.66% (FEC); Rec=91.52% (ECD), 93.96%
(FEC)). At the regional level, the analysis identified relevant inappropriate
referral groups and variation across contexts, findings that informed a new
Lombardy Region resolution to reinforce guideline adherence.
  Conclusions: This study presents a robust, scalable, unsupervised NLP
pipeline for assessing referral appropriateness in large, real-world datasets.
It demonstrates how such data can be effectively leveraged, providing public
health authorities with a deployable AI tool to monitor practices and support
evidence-based policy.",2025-01-24T18:24:16Z,http://arxiv.org/pdf/2501.14701v2,"['cs.CL', 'cs.LG', '68T50', 'I.2.7; J.1; J.3']"
1301.7738v2,PyPLN: a Distributed Platform for Natural Language Processing,"['Flávio Codeço Coelho', 'Renato Rocha Souza', 'Álvaro Justen', 'Flávio Amieiro', 'Heliana Mello']","This paper presents a distributed platform for Natural Language Processing
called PyPLN. PyPLN leverages a vast array of NLP and text processing open
source tools, managing the distribution of the workload on a variety of
configurations: from a single server to a cluster of linux servers. PyPLN is
developed using Python 2.7.3 but makes it very easy to incorporate other
softwares for specific tasks as long as a linux version is available. PyPLN
facilitates analyses both at document and corpus level, simplifying management
and publication of corpora and analytical results through an easy to use web
interface. In the current (beta) release, it supports English and Portuguese
languages with support to other languages planned for future releases. To
support the Portuguese language PyPLN uses the PALAVRAS parser\citep{Bick2000}.
Currently PyPLN offers the following features: Text extraction with encoding
normalization (to UTF-8), part-of-speech tagging, token frequency, semantic
annotation, n-gram extraction, word and sentence repertoire, and full-text
search across corpora. The platform is licensed as GPL-v3.",2013-01-31T20:21:52Z,http://arxiv.org/pdf/1301.7738v2,"['cs.CL', 'cs.IR']"
2101.11889v1,"Explaining Natural Language Processing Classifiers with Occlusion and
  Language Modeling",['David Harbecke'],"Deep neural networks are powerful statistical learners. However, their
predictions do not come with an explanation of their process. To analyze these
models, explanation methods are being developed. We present a novel explanation
method, called OLM, for natural language processing classifiers. This method
combines occlusion and language modeling, which are techniques central to
explainability and NLP, respectively. OLM gives explanations that are
theoretically sound and easy to understand.
  We make several contributions to the theory of explanation methods. Axioms
for explanation methods are an interesting theoretical concept to explore their
basics and deduce methods. We introduce a new axiom, give its intuition and
show it contradicts another existing axiom. Additionally, we point out
theoretical difficulties of existing gradient-based and some occlusion-based
explanation methods in natural language processing. We provide an extensive
argument why evaluation of explanation methods is difficult. We compare OLM to
other explanation methods and underline its uniqueness experimentally. Finally,
we investigate corner cases of OLM and discuss its validity and possible
improvements.",2021-01-28T09:44:04Z,http://arxiv.org/pdf/2101.11889v1,"['cs.CL', 'cs.LG']"
2103.13942v1,Visual Grounding Strategies for Text-Only Natural Language Processing,['Damien Sileo'],"Visual grounding is a promising path toward more robust and accurate Natural
Language Processing (NLP) models. Many multimodal extensions of BERT (e.g.,
VideoBERT, LXMERT, VL-BERT) allow a joint modeling of texts and images that
lead to state-of-the-art results on multimodal tasks such as Visual Question
Answering. Here, we leverage multimodal modeling for purely textual tasks
(language modeling and classification) with the expectation that the multimodal
pretraining provides a grounding that can improve text processing accuracy. We
propose possible strategies in this respect. A first type of strategy, referred
to as {\it transferred grounding} consists in applying multimodal models to
text-only tasks using a placeholder to replace image input. The second one,
which we call {\it associative grounding}, harnesses image retrieval to match
texts with related images during both pretraining and text-only downstream
tasks. We draw further distinctions into both strategies and then compare them
according to their impact on language modeling and commonsense-related
downstream tasks, showing improvement over text-only baselines.",2021-03-25T16:03:00Z,http://arxiv.org/pdf/2103.13942v1,['cs.CL']
2005.14187v1,"HAT: Hardware-Aware Transformers for Efficient Natural Language
  Processing","['Hanrui Wang', 'Zhanghao Wu', 'Zhijian Liu', 'Han Cai', 'Ligeng Zhu', 'Chuang Gan', 'Song Han']","Transformers are ubiquitous in Natural Language Processing (NLP) tasks, but
they are difficult to be deployed on hardware due to the intensive computation.
To enable low-latency inference on resource-constrained hardware platforms, we
propose to design Hardware-Aware Transformers (HAT) with neural architecture
search. We first construct a large design space with $\textit{arbitrary
encoder-decoder attention}$ and $\textit{heterogeneous layers}$. Then we train
a $\textit{SuperTransformer}$ that covers all candidates in the design space,
and efficiently produces many $\textit{SubTransformers}$ with weight sharing.
Finally, we perform an evolutionary search with a hardware latency constraint
to find a specialized $\textit{SubTransformer}$ dedicated to run fast on the
target hardware. Extensive experiments on four machine translation tasks
demonstrate that HAT can discover efficient models for different hardware (CPU,
GPU, IoT device). When running WMT'14 translation task on Raspberry Pi-4, HAT
can achieve $\textbf{3}\times$ speedup, $\textbf{3.7}\times$ smaller size over
baseline Transformer; $\textbf{2.7}\times$ speedup, $\textbf{3.6}\times$
smaller size over Evolved Transformer with $\textbf{12,041}\times$ less search
cost and no performance loss. HAT code is
https://github.com/mit-han-lab/hardware-aware-transformers.git",2020-05-28T17:58:56Z,http://arxiv.org/pdf/2005.14187v1,"['cs.CL', 'cs.LG', 'cs.NE']"
2002.09812v1,"Sketching Transformed Matrices with Applications to Natural Language
  Processing","['Yingyu Liang', 'Zhao Song', 'Mengdi Wang', 'Lin F. Yang', 'Xin Yang']","Suppose we are given a large matrix $A=(a_{i,j})$ that cannot be stored in
memory but is in a disk or is presented in a data stream. However, we need to
compute a matrix decomposition of the entry-wisely transformed matrix,
$f(A):=(f(a_{i,j}))$ for some function $f$. Is it possible to do it in a space
efficient way? Many machine learning applications indeed need to deal with such
large transformed matrices, for example word embedding method in NLP needs to
work with the pointwise mutual information (PMI) matrix, while the entrywise
transformation makes it difficult to apply known linear algebraic tools.
Existing approaches for this problem either need to store the whole matrix and
perform the entry-wise transformation afterwards, which is space consuming or
infeasible, or need to redesign the learning method, which is application
specific and requires substantial remodeling.
  In this paper, we first propose a space-efficient sketching algorithm for
computing the product of a given small matrix with the transformed matrix. It
works for a general family of transformations with provable small error bounds
and thus can be used as a primitive in downstream learning tasks. We then apply
this primitive to a concrete application: low-rank approximation. We show that
our approach obtains small error and is efficient in both space and time. We
complement our theoretical results with experiments on synthetic and real data.",2020-02-23T03:07:31Z,http://arxiv.org/pdf/2002.09812v1,"['cs.DS', 'cs.CL', 'cs.LG']"
2010.16357v1,"A Cross-lingual Natural Language Processing Framework for Infodemic
  Management","['Ridam Pal', 'Rohan Pandey', 'Vaibhav Gautam', 'Kanav Bhagat', 'Tavpritesh Sethi']","The COVID-19 pandemic has put immense pressure on health systems which are
further strained due to the misinformation surrounding it. Under such a
situation, providing the right information at the right time is crucial. There
is a growing demand for the management of information spread using Artificial
Intelligence. Hence, we have exploited the potential of Natural Language
Processing for identifying relevant information that needs to be disseminated
amongst the masses. In this work, we present a novel Cross-lingual Natural
Language Processing framework to provide relevant information by matching daily
news with trusted guidelines from the World Health Organization. The proposed
pipeline deploys various techniques of NLP such as summarizers, word
embeddings, and similarity metrics to provide users with news articles along
with a corresponding healthcare guideline. A total of 36 models were evaluated
and a combination of LexRank based summarizer on Word2Vec embedding with Word
Mover distance metric outperformed all other models. This novel open-source
approach can be used as a template for proactive dissemination of relevant
healthcare information in the midst of misinformation spread associated with
epidemics.",2020-10-30T16:26:35Z,http://arxiv.org/pdf/2010.16357v1,"['cs.CL', 'cs.AI', 'cs.LG']"
2111.06741v2,A Quantum Natural Language Processing Approach to Musical Intelligence,"['Eduardo Reck Miranda', 'Richie Yeung', 'Anna Pearson', 'Konstantinos Meichanetzidis', 'Bob Coecke']","There has been tremendous progress in Artificial Intelligence (AI) for music,
in particular for musical composition and access to large databases for
commercialisation through the Internet. We are interested in further advancing
this field, focusing on composition. In contrast to current black-box AI
methods, we are championing an interpretable compositional outlook on
generative music systems. In particular, we are importing methods from the
Distributional Compositional Categorical (DisCoCat) modelling framework for
Natural Language Processing (NLP), motivated by musical grammars. Quantum
computing is a nascent technology, which is very likely to impact the music
industry in time to come. Thus, we are pioneering a Quantum Natural Language
Processing (QNLP) approach to develop a new generation of intelligent musical
systems. This work follows from previous experimental implementations of
DisCoCat linguistic models on quantum hardware. In this chapter, we present
Quanthoven, the first proof-of-concept ever built, which (a) demonstrates that
it is possible to program a quantum computer to learn to classify music that
conveys different meanings and (b) illustrates how such a capability might be
leveraged to develop a system to compose meaningful pieces of music. After a
discussion about our current understanding of music as a communication medium
and its relationship to natural language, the chapter focuses on the techniques
developed to (a) encode musical compositions as quantum circuits, and (b)
design a quantum classifier. The chapter ends with demonstrations of
compositions created with the system.",2021-11-10T12:35:07Z,http://arxiv.org/pdf/2111.06741v2,"['quant-ph', 'cs.AI']"
2206.11867v1,"Lifelong Learning Natural Language Processing Approach for Multilingual
  Data Classification","['Jędrzej Kozal', 'Michał Leś', 'Paweł Zyblewski', 'Paweł Ksieniewicz', 'Michał Woźniak']","The abundance of information in digital media, which in today's world is the
main source of knowledge about current events for the masses, makes it possible
to spread disinformation on a larger scale than ever before. Consequently,
there is a need to develop novel fake news detection approaches capable of
adapting to changing factual contexts and generalizing previously or
concurrently acquired knowledge. To deal with this problem, we propose a
lifelong learning-inspired approach, which allows for fake news detection in
multiple languages and the mutual transfer of knowledge acquired in each of
them. Both classical feature extractors, such as Term frequency-inverse
document frequency or Latent Dirichlet Allocation, and integrated deep NLP
(Natural Language Processing) BERT (Bidirectional Encoder Representations from
Transformers) models paired with MLP (Multilayer Perceptron) classifier, were
employed. The results of experiments conducted on two datasets dedicated to the
fake news classification task (in English and Spanish, respectively), supported
by statistical analysis, confirmed that utilization of additional languages
could improve performance for traditional methods. Also, in some cases
supplementing the deep learning method with classical ones can positively
impact obtained results. The ability of models to generalize the knowledge
acquired between the analyzed languages was also observed.",2022-05-25T10:34:04Z,http://arxiv.org/pdf/2206.11867v1,"['cs.CL', 'cs.LG']"
2206.15076v1,"BigBIO: A Framework for Data-Centric Biomedical Natural Language
  Processing","['Jason Alan Fries', 'Leon Weber', 'Natasha Seelam', 'Gabriel Altay', 'Debajyoti Datta', 'Samuele Garda', 'Myungsun Kang', 'Ruisi Su', 'Wojciech Kusa', 'Samuel Cahyawijaya', 'Fabio Barth', 'Simon Ott', 'Matthias Samwald', 'Stephen Bach', 'Stella Biderman', 'Mario Sänger', 'Bo Wang', 'Alison Callahan', 'Daniel León Periñán', 'Théo Gigant', 'Patrick Haller', 'Jenny Chim', 'Jose David Posada', 'John Michael Giorgi', 'Karthik Rangasai Sivaraman', 'Marc Pàmies', 'Marianna Nezhurina', 'Robert Martin', 'Michael Cullan', 'Moritz Freidank', 'Nathan Dahlberg', 'Shubhanshu Mishra', 'Shamik Bose', 'Nicholas Michio Broad', 'Yanis Labrak', 'Shlok S Deshmukh', 'Sid Kiblawi', 'Ayush Singh', 'Minh Chien Vu', 'Trishala Neeraj', 'Jonas Golde', 'Albert Villanova del Moral', 'Benjamin Beilharz']","Training and evaluating language models increasingly requires the
construction of meta-datasets --diverse collections of curated data with clear
provenance. Natural language prompting has recently lead to improved zero-shot
generalization by transforming existing, supervised datasets into a diversity
of novel pretraining tasks, highlighting the benefits of meta-dataset curation.
While successful in general-domain text, translating these data-centric
approaches to biomedical language modeling remains challenging, as labeled
biomedical datasets are significantly underrepresented in popular data hubs. To
address this challenge, we introduce BigBIO a community library of 126+
biomedical NLP datasets, currently covering 12 task categories and 10+
languages. BigBIO facilitates reproducible meta-dataset curation via
programmatic access to datasets and their metadata, and is compatible with
current platforms for prompt engineering and end-to-end few/zero shot language
model evaluation. We discuss our process for task schema harmonization, data
auditing, contribution guidelines, and outline two illustrative use cases:
zero-shot evaluation of biomedical prompts and large-scale, multi-task
learning. BigBIO is an ongoing community effort and is available at
https://github.com/bigscience-workshop/biomedical",2022-06-30T07:15:45Z,http://arxiv.org/pdf/2206.15076v1,['cs.CL']
2212.06334v1,Auto-labelling of Bug Report using Natural Language Processing,"['Avinash Patil', 'Aryan Jadon']","The exercise of detecting similar bug reports in bug tracking systems is
known as duplicate bug report detection. Having prior knowledge of a bug
report's existence reduces efforts put into debugging problems and identifying
the root cause. Rule and Query-based solutions recommend a long list of
potential similar bug reports with no clear ranking. In addition, triage
engineers are less motivated to spend time going through an extensive list.
Consequently, this deters the use of duplicate bug report retrieval solutions.
In this paper, we have proposed a solution using a combination of NLP
techniques. Our approach considers unstructured and structured attributes of a
bug report like summary, description and severity, impacted products,
platforms, categories, etc. It uses a custom data transformer, a deep neural
network, and a non-generalizing machine learning method to retrieve existing
identical bug reports. We have performed numerous experiments with significant
data sources containing thousands of bug reports and showcased that the
proposed solution achieves a high retrieval accuracy of 70% for recall@5.",2022-12-13T02:32:42Z,http://arxiv.org/pdf/2212.06334v1,"['cs.SE', 'cs.AI', 'cs.LG']"
2103.00112v3,Transformer in Transformer,"['Kai Han', 'An Xiao', 'Enhua Wu', 'Jianyuan Guo', 'Chunjing Xu', 'Yunhe Wang']","Transformer is a new kind of neural architecture which encodes the input data
as powerful features via the attention mechanism. Basically, the visual
transformers first divide the input images into several local patches and then
calculate both representations and their relationship. Since natural images are
of high complexity with abundant detail and color information, the granularity
of the patch dividing is not fine enough for excavating features of objects in
different scales and locations. In this paper, we point out that the attention
inside these local patches are also essential for building visual transformers
with high performance and we explore a new architecture, namely, Transformer iN
Transformer (TNT). Specifically, we regard the local patches (e.g.,
16$\times$16) as ""visual sentences"" and present to further divide them into
smaller patches (e.g., 4$\times$4) as ""visual words"". The attention of each
word will be calculated with other words in the given visual sentence with
negligible computational costs. Features of both words and sentences will be
aggregated to enhance the representation ability. Experiments on several
benchmarks demonstrate the effectiveness of the proposed TNT architecture,
e.g., we achieve an 81.5% top-1 accuracy on the ImageNet, which is about 1.7%
higher than that of the state-of-the-art visual transformer with similar
computational cost. The PyTorch code is available at
https://github.com/huawei-noah/CV-Backbones, and the MindSpore code is
available at https://gitee.com/mindspore/models/tree/master/research/cv/TNT.",2021-02-27T03:12:16Z,http://arxiv.org/pdf/2103.00112v3,"['cs.CV', 'cs.AI']"
2307.01189v2,Trainable Transformer in Transformer,"['Abhishek Panigrahi', 'Sadhika Malladi', 'Mengzhou Xia', 'Sanjeev Arora']","Recent works attribute the capability of in-context learning (ICL) in large
pre-trained language models to implicitly simulating and fine-tuning an
internal model (e.g., linear or 2-layer MLP) during inference. However, such
constructions require large memory overhead, which makes simulation of more
sophisticated internal models intractable. In this work, we propose an
efficient construction, Transformer in Transformer (in short, TinT), that
allows a transformer to simulate and fine-tune complex models internally during
inference (e.g., pre-trained language models). In particular, we introduce
innovative approximation techniques that allow a TinT model with less than 2
billion parameters to simulate and fine-tune a 125 million parameter
transformer model within a single forward pass. TinT accommodates many common
transformer variants and its design ideas also improve the efficiency of past
instantiations of simple models inside transformers. We conduct end-to-end
experiments to validate the internal fine-tuning procedure of TinT on various
language modeling and downstream tasks. For example, even with a limited
one-step budget, we observe TinT for a OPT-125M model improves performance by
4-16% absolute on average compared to OPT-125M. These findings suggest that
large pre-trained language models are capable of performing intricate
subroutines. To facilitate further work, a modular and extensible codebase for
TinT is included.",2023-07-03T17:53:39Z,http://arxiv.org/pdf/2307.01189v2,"['cs.CL', 'cs.LG']"
0409265v1,Transformation Digroups,['Keqin Liu'],"We introduce the notion of a transformation digroup and prove that every
digroup is isomorphic to a transformation digroup.",2004-09-16T16:32:13Z,http://arxiv.org/pdf/math/0409265v1,"['math.GR', 'math.RA', '20N05, 20N99']"
1105.1427v2,Riesz transforms for Dunkl transform,"['Béchir Amri', 'Mohamed Sifi']","In this paper we obtain the $L^p$-boundedness of Riesz transforms for Dunkl
transform for all $1<p<\infty$.",2011-05-07T09:00:11Z,http://arxiv.org/pdf/1105.1427v2,"['math.CA', '17B22, 32A55, 43A32, 42A45']"
1107.3625v1,Appell Transformation and Canonical Transforms,['Amalia Torre'],"The interpretation of the optical Appell transformation, as previously
elaborated in relation to the free-space paraxial propagation under both a
rectangular and a circular cylindrical symmetry, is reviewed. Then, the caloric
Appell transformation, well known in the theory of heat equation, is shown to
be amenable for a similar interpretation involving the Laplace transform rather
than the Fourier transform, when dealing with the 1D heat equation.
Accordingly, when considering the radial heat equation, suitably defined
Hankel-type transforms come to be involved in the inherent Appell
transformation. The analysis is aimed at outlining the link between the Appell
transformation and the canonical transforms.",2011-07-19T05:25:36Z,http://arxiv.org/pdf/1107.3625v1,"['math-ph', 'math.MP', 'physics.optics']"
0604173v1,"Comment on ""Gauge transformations are Canonical transformations""","['Pathikrit Bhattacharya', 'Bhabani Prasad Mandal']","We comment on the work of Tai L Chow, Eur. J. Phys. 18, 467 (1997). By
considering the Lagrangians which are uniquely defined only to within an
additive total time derivative of a function of co-ordinates and time the
author has tried to show that the gauge transformations which relate these
Lagrangians are canonical transformations. He has obtained the right conclusion
only by using wrong canonical equations and the entire exercise has hence
become erroneous and inconclusive. By using the definition of canonical
transformation through Poisson brackets we prove that the above gauge
transformations are canonical transformations.",2006-04-21T04:06:28Z,http://arxiv.org/pdf/physics/0604173v1,"['physics.class-ph', 'hep-th', 'physics.gen-ph', 'quant-ph']"
1706.07699v1,Bicomplex Mobius Transformation,['Chinmay Ghosh'],"In this article the bicomplex version of Mobius transformation is defined and
special attention is paid to find the fixed points of a bicomplex Mobius
transformation.",2017-06-22T06:03:53Z,http://arxiv.org/pdf/1706.07699v1,"['math.CV', '30G35']"
1711.05359v1,On Finite Gauss Transform,"['Maxim Arnold', 'Anatoly Eydelzon']","We present an invariant density for the finite Gauss transformation of the
unit interval and discuss some properties of this transformation.",2017-11-15T00:03:24Z,http://arxiv.org/pdf/1711.05359v1,['math.DS']
9409051v1,On Hurwitz Transformations,"['M. Hage Hassan', 'M. Kibler']","A bibliography on the Hurwitz transformations is given. We deal here, with
some details, with two particular Hurwitz transformations, viz, the $\grq \to
\grt$ Kustaanheimo-Stiefel transformation and its $\grh \to \grc$ compact
extension. These transformations are derived in the context of
Fock-Bargmann-Schwinger calculus with special emphasis on angular momentum
theory.",1994-09-10T13:59:28Z,http://arxiv.org/pdf/hep-th/9409051v1,['hep-th']
9706228v1,Topological transformation groups,"['Alejandro Adem', 'James F. Davis']","This paper surveys some results and methods in topological transformation
groups.",1997-06-03T00:00:00Z,http://arxiv.org/pdf/math/9706228v1,['math.AT']
1201.6584v1,Polyhedron under Linear Transformations,['Zaikun Zhang'],"The image and the inverse image of a polyhedron under a linear transformation
are polyhedrons.",2012-01-31T15:56:10Z,http://arxiv.org/pdf/1201.6584v1,['math.FA']
1712.06453v2,Radon Transform for Sheaves,['Honghao Gao'],"We define the Radon transform functor for sheaves and prove that it is an
equivalence after suitable microlocal localizations. As a result, the sheaf
category associated to a Legendrian is invariant under the Radon transform. We
also manage to place the Radon transform and other transforms in microlocal
sheaf theory altogether in a diagram.",2017-12-18T15:06:15Z,http://arxiv.org/pdf/1712.06453v2,['math.SG']
1807.07109v1,The trinomial transform triangle,['László Németh'],"The trinomial transform of a sequence is a generalization of the well-known
binomial transform, replacing binomial coefficients with trinomial
coefficients. We examine Pascal-like triangles under trinomial transform,
focusing on the ternary linear recurrent sequences. We determine the sums and
alternating sums of the elements in columns, and we give some examples of the
trinomial transform triangle.",2018-07-18T19:13:57Z,http://arxiv.org/pdf/1807.07109v1,"['math.NT', 'math.CO', '11B37, 11B65, 11B75, 11B39']"
0306424v1,The Wilson function transform,['Wolter Groenevelt'],"Two unitary integral transforms with a very-well poised $_7F_6$-function as a
kernel are given. For both integral transforms the inverse is the same as the
original transform after an involution on the parameters. The $_7F_6$-function
involved can be considered as a non-polynomial extension of the Wilson
polynomial, and is therefore called a Wilson function. The two integral
transforms are called a Wilson function transform of type I and type II.
Furthermore, a few explicit transformations of hypergeometric functions are
calculated, and it is shown that the Wilson function transform of type I maps a
basis of orthogonal polynomials onto a similar basis of polynomials.",2003-06-30T12:32:40Z,http://arxiv.org/pdf/math/0306424v1,['math.CA']
1208.3342v1,Index hypergeometric integral transform,['Yury A. Neretin'],"This is a brief overview of the index hypergeometric transform (other terms
for this integral operator are: Olevskii transform, Jacobi transform,
generalized Mehler--Fock transform). We discuss applications of this transform
to special functions and harmonic analysis. The text is an addendum to the
Russian edition of the book by G.E.Andrews, R.Askey, and R.Roy, Special
Functions, Encycl. of Math. Appl. 71, Cambridge Univ. Press, 1999.",2012-08-16T11:23:28Z,http://arxiv.org/pdf/1208.3342v1,"['math.CA', '65R10, 33C05, 33C60, 53C35, 33C45']"
1309.1855v1,Bounded rank-one transformations,"['Su Gao', 'Aaron Hill']","We define the notion of canonical boundedness among rank-one transformations
and use it to characterize the class of all bounded rank-one transformations
with trivial centralizer. We also explicitly characterize totally ergodic
rank-one transformations with bounded cutting parameter. Together with a recent
result of Ryzhikov our results provide a simple procedure for determining
whether a bounded rank-one transformation has minimal self-joinings of all
orders purely in terms of the cutting and spacer parameters for the
transformation.",2013-09-07T11:51:42Z,http://arxiv.org/pdf/1309.1855v1,['math.DS']
1403.6568v4,Whirly 3-Interval Exchange Transformations,['Yue Wu'],"Irreducible interval exchange transformations are studied with regard to
whirly property, a condition for non-trivial spatial factor. Uniformly whirly
transformation is defined and to be further studied. An equivalent condition is
introduced for whirly transformation. We will prove that almost all 3-interval
exchange transformations are whirly, using a combinatorics approach with
application of the Rauzy-Veech Induction. It is still an open question whether
whirly property is a generic property for m-interval exchange transformations
(m>=4).",2014-03-26T03:36:13Z,http://arxiv.org/pdf/1403.6568v4,"['math.DS', '28D15, 22F10']"
1703.05022v1,Steerable Discrete Fourier Transform,"['Giulia Fracastoro', 'Enrico Magli']","Directional transforms have recently raised a lot of interest thanks to their
numerous applications in signal compression and analysis. In this letter, we
introduce a generalization of the discrete Fourier transform, called steerable
DFT (SDFT). Since the DFT is used in numerous fields, it may be of interest in
a wide range of applications. Moreover, we also show that the SDFT is highly
related to other well-known transforms, such as the Fourier sine and cosine
transforms and the Hilbert transforms.",2017-03-15T09:05:13Z,http://arxiv.org/pdf/1703.05022v1,"['cs.IT', 'math.IT']"
1409.0692v1,"Gauge transformations are canonical transformations, redux",['Z. K. Silagadze'],"In this short note we return to the old paper by Tai L. Chow (Eur. J. Phys.
18 (1997), 467-468) and correct its erroneous final part. We also note that the
main result of that paper, that gauge transformations of mechanics are
canonical transformations, was known much earlier.",2014-09-02T13:07:22Z,http://arxiv.org/pdf/1409.0692v1,"['physics.class-ph', 'math-ph', 'math.MP']"
1701.01326v1,Higher Order Context Transformations,"['Michal Vašinek', 'Jan Platoš']","The context transformation and generalized context transformation methods, we
introduced recently, were able to reduce zero order entropy by exchanging
digrams, and as a consequence, they were removing mutual information between
consecutive symbols of the input message. These transformations were intended
to be used as a preprocessor for zero-order entropy coding algorithms like
Arithmetic or Huffman coding, since we know, that especially Arithmetic coding
can achieve a compression rate almost of the size of Shannon's entropy.
  This paper introduces a novel algorithm based on the concept of generalized
context transformation, that allows transformation of words longer than simple
digrams. The higher order contexts are exploited using recursive form of a
generalized context transformation. It is shown that the zero order entropy of
transformed data drops significantly, but on the other hand, the overhead given
by a description of individual transformations increases and it has become a
limiting factor in a successful transformation of smaller files.",2017-01-05T14:26:48Z,http://arxiv.org/pdf/1701.01326v1,"['cs.IT', 'math.IT']"
2105.14424v1,Gaze Estimation using Transformer,"['Yihua Cheng', 'Feng Lu']","Recent work has proven the effectiveness of transformers in many computer
vision tasks. However, the performance of transformers in gaze estimation is
still unexplored. In this paper, we employ transformers and assess their
effectiveness for gaze estimation. We consider two forms of vision transformer
which are pure transformers and hybrid transformers. We first follow the
popular ViT and employ a pure transformer to estimate gaze from images. On the
other hand, we preserve the convolutional layers and integrate CNNs as well as
transformers. The transformer serves as a component to complement CNNs. We
compare the performance of the two transformers in gaze estimation. The Hybrid
transformer significantly outperforms the pure transformer in all evaluation
datasets with less parameters. We further conduct experiments to assess the
effectiveness of the hybrid transformer and explore the advantage of
self-attention mechanism. Experiments show the hybrid transformer can achieve
state-of-the-art performance in all benchmarks with pre-training.To facilitate
further research, we release codes and models in
https://github.com/yihuacheng/GazeTR.",2021-05-30T04:06:29Z,http://arxiv.org/pdf/2105.14424v1,['cs.CV']
1109.0337v1,On discrete cosine transform,['Jianqin Zhou'],"The discrete cosine transform (DCT), introduced by Ahmed, Natarajan and Rao,
has been used in many applications of digital signal processing, data
compression and information hiding. There are four types of the discrete cosine
transform. In simulating the discrete cosine transform, we propose a
generalized discrete cosine transform with three parameters, and prove its
orthogonality for some new cases. A new type of discrete cosine transform is
proposed and its orthogonality is proved. Finally, we propose a generalized
discrete W transform with three parameters, and prove its orthogonality for
some new cases.",2011-09-02T01:10:34Z,http://arxiv.org/pdf/1109.0337v1,"['cs.IT', 'math.IT']"
2210.08288v1,Transformer-based dimensionality reduction,"['Ruisheng Ran', 'Tianyu Gao', 'Bin Fang']","Recently, Transformer is much popular and plays an important role in the
fields of Machine Learning (ML), Natural Language Processing (NLP), and
Computer Vision (CV), etc. In this paper, based on the Vision Transformer (ViT)
model, a new dimensionality reduction (DR) model is proposed, named
Transformer-DR. From data visualization, image reconstruction and face
recognition, the representation ability of Transformer-DR after dimensionality
reduction is studied, and it is compared with some representative DR methods to
understand the difference between Transformer-DR and existing DR methods. The
experimental results show that Transformer-DR is an effective dimensionality
reduction method.",2022-10-15T13:24:43Z,http://arxiv.org/pdf/2210.08288v1,['cs.CV']
2309.05224v1,SparseSwin: Swin Transformer with Sparse Transformer Block,"['Krisna Pinasthika', 'Blessius Sheldo Putra Laksono', 'Riyandi Banovbi Putera Irsal', 'Syifa Hukma Shabiyya', 'Novanto Yudistira']","Advancements in computer vision research have put transformer architecture as
the state of the art in computer vision tasks. One of the known drawbacks of
the transformer architecture is the high number of parameters, this can lead to
a more complex and inefficient algorithm. This paper aims to reduce the number
of parameters and in turn, made the transformer more efficient. We present
Sparse Transformer (SparTa) Block, a modified transformer block with an
addition of a sparse token converter that reduces the number of tokens used. We
use the SparTa Block inside the Swin T architecture (SparseSwin) to leverage
Swin capability to downsample its input and reduce the number of initial tokens
to be calculated. The proposed SparseSwin model outperforms other state of the
art models in image classification with an accuracy of 86.96%, 97.43%, and
85.35% on the ImageNet100, CIFAR10, and CIFAR100 datasets respectively. Despite
its fewer parameters, the result highlights the potential of a transformer
architecture using a sparse token converter with a limited number of tokens to
optimize the use of the transformer and improve its performance.",2023-09-11T04:03:43Z,http://arxiv.org/pdf/2309.05224v1,"['cs.CV', 'cs.AI', 'cs.LG']"
0704.2744v2,Nahm transform and parabolic minimal Laplace transform,['Szilard Szabo'],"We prove that Nahm transform for integrable connections with a finite number
of regular singularities and an irregular singularity of rank 1 on the Riemann
sphere is equivalent -- up to considering integrable connections as holonomic
$\D$-modules -- to minimal Laplace transform. We assume semi-simplicity and
resonance-freeness conditions, and we work in the framework of objects with a
parabolic structure. In particular, we describe the definition of the parabolic
version of Laplace transform due to C. Sabbah. The proof of the main result
relies on the study of a twisted de Rham complex.",2007-04-20T15:00:53Z,http://arxiv.org/pdf/0704.2744v2,"['math.AG', '14H60, 14F40, 13N10']"
2004.06462v2,On dual transform of fractional Hankel transform,['Allal Ghanmi'],"We deal with a class of one-parameter family of integral transforms of
Bargmann type arising as dual transforms of fractional Hankel transform. Their
ranges are identified to be special subspaces of the weighted hyperholomorphic
left Hilbert spaces, generalizing the slice Bergman space of the second kind.
Their reproducing kernel is given by closed expression involving the
$\star$-regularization of Gauss hypergeometric function. We also discuss their
basic properties such as their boundedness and we determinate their singular
values. Moreover, we describe their compactness and membership in $p$-Schatten
classes.",2020-04-14T13:05:23Z,http://arxiv.org/pdf/2004.06462v2,"['math.CV', 'math.FA', 'math.SP', '44A20, 30G35, 30H20, 47B38, 30D55']"
9210212v1,Radon transform and curvature,['Peter W. Michor'],"We interpret the setting for a Radon transform as a submanifold of the space
of generalized functions, and compute its extrinsic curvature: it is the
Hessian composed with the Radon transform.",1992-10-01T00:00:00Z,http://arxiv.org/pdf/math/9210212v1,"['math.DG', 'math.FA', '44A12 58D15']"
1302.2527v2,The Tsallis-Laplace Transform,"['A. Plastino', 'M. C. Rocca']","We introduce here the q-Laplace transform as a new weapon in Tsallis'
arsenal, discussing its main properties and analyzing some examples. The
q-Gaussian instance receives special consideration. Also, we derive the
q-partition function from the q-Laplace transform.",2013-02-11T16:40:55Z,http://arxiv.org/pdf/1302.2527v2,"['math-ph', 'cond-mat.stat-mech', 'math.MP']"
1802.07563v1,Laplace transforms and valuations,"['Jin Li', 'Dan Ma']","It is proved that the classical Laplace transform is a continuous valuation
which is positively GL$(n)$ covariant and logarithmic translation covariant.
Conversely, these properties turn out to be sufficient to characterize this
transform.",2018-02-21T13:33:04Z,http://arxiv.org/pdf/1802.07563v1,"['math.MG', 'math.FA', '52A20, 52B45, 44A10']"
2505.07505v1,On discrete X-ray transform,"['Roman Novikov', 'Basant Lal Sharma']","We consider a discrete version of X-ray transform going back, in particular,
to Strichartz (1982). We suggest non-overdetermined reconstruction for this
discrete transform. Extensions to weighted (attenuated) analogues are given.
Connections to the continuous case are presented.",2025-05-12T12:41:05Z,http://arxiv.org/pdf/2505.07505v1,"['math.FA', '44A12, 46F12, 65R10, 65N21, 65N22']"
9411199v1,Quantum Canonical Transformations revisited,['A. Y. Shiekh'],"A preferred form for the path integral discretization is suggested that
allows the implementation of canonical transformations in quantum theory.",1994-11-28T10:42:08Z,http://arxiv.org/pdf/hep-th/9411199v1,"['hep-th', 'funct-an', 'hep-lat', 'math.FA']"
0207129v1,Transformation de Fourier homogene,['Gerard Laumon'],"In their proof of the Drinfeld-Langlands correspondence, Frenkel, Gaitsgory
and Vilonen make use of a geometric Fourier transformation. Therefore, they
work either with l-adic sheaves in characteristic p>0, or with D-modules in
characteristic 0. Actually, they only need to consider the Fourier transforms
of homogeneous sheaves for which one expects a uniform geometric construction
in any characteristic.
  In this note, we propose such a homogeneous geometric Fourier transformation.
It extends the geometric Radon transformation which has been studied by
Brylinski.",2002-07-16T12:19:28Z,http://arxiv.org/pdf/math/0207129v1,['math.AG']
0312045v1,Hyperkähler Nahm transform,"['Claudio Bartocci', 'Marcos Jardim']","Given two hyperk\""ahler manifolds $M$ and $N$ and a quaternionic instanton on
their product, a hyperk\""ahler Nahm transform can be defined, which maps
quaternionic instantons on $M$ to quaternionic instantons on $N$. This
construction includes the case of Nahm transform for periodic instantons on
$\bR^4$, the Fourier-Mukai transform for instantons on K3 surfaces, as well as
the Nahm transform for ALE instantons.",2003-12-02T03:02:01Z,http://arxiv.org/pdf/math/0312045v1,['math.DG']
0202020v2,Fractional Darboux Transformations,['Mayer Humi'],"In this paper we utilize the covariance of Ricatti equation with respect to
linear fractional transformations to define classes of conformally equivalent
second order differential equations. This motivates then the introduction of
fractional Darboux transformations which can be recognized also as generalized
Cole-Hopf transformations. We apply these transformations to find Schrodinger
equations with isospectral potentials and to the linearization of some new
classes of nonlinear partial differential equations.",2002-02-13T19:39:19Z,http://arxiv.org/pdf/math-ph/0202020v2,"['math-ph', 'math.DS', 'math.MP']"
0806.0489v1,Generalized field-transforming metamaterials,"['Sergei Tretyakov', 'Igor Nefedov', 'Pekka Alitalo']","In this paper we introduce a generalized concept of field-transforming
metamaterials, which perform field transformations defined as linear relations
between the original and transformed fields. These artificial media change the
fields in a prescribed fashion in the volume occupied by the medium. We show
what electromagnetic properties of transforming medium are required. The
coefficients of these linear functions can be arbitrary scalar functions of
position and frequency, which makes the approach quite general and opens a
possibility to realize various unusual devices.",2008-06-03T10:28:47Z,http://arxiv.org/pdf/0806.0489v1,"['physics.optics', 'physics.class-ph']"
1308.2233v2,Frame Transformations for Fermions,"['Chris W Patterson', 'William G Harter']","The analog to the Legendre addition theorem is found for half-integral
angular momentum using frame transformations for rotor states.",2013-08-09T20:08:57Z,http://arxiv.org/pdf/1308.2233v2,"['quant-ph', 'math-ph', 'math.MP']"
2502.10647v1,A Power Transform,['Jonathan T. Barron'],"Power transforms, such as the Box-Cox transform and Tukey's ladder of powers,
are a fundamental tool in mathematics and statistics. These transforms are
primarily used for normalizing and standardizing datasets, effectively by
raising values to a power. In this work I present a novel power transform, and
I show that it serves as a unifying framework for wide family of loss
functions, kernel functions, probability distributions, bump functions, and
neural network activation functions.",2025-02-15T02:47:55Z,http://arxiv.org/pdf/2502.10647v1,"['cs.LG', 'stat.ML', 'stat.TH']"
2505.23581v2,Quantum Hilbert Transform,"['Nitin Jha', 'Abhishek Parakh']","The Hilbert transform has been one of the foundational transforms in signal
processing, finding it's way into multiple disciplines from cryptography to
biomedical sciences. However, there does not exist any quantum analogue for the
Hilbert transform. In this work, we introduce a formulation for the quantum
Hilbert transform (QHT)and apply it to a quantum steganography protocol. By
bridging classical phase-shift techniques with quantum operations, QHT opens
new pathways in quantum signal processing, communications, sensing, and secure
information hiding.",2025-05-29T15:53:26Z,http://arxiv.org/pdf/2505.23581v2,"['quant-ph', 'cs.CR', 'cs.DM', 'cs.NI']"
0808.1551v2,On SYZ mirror transformations,"['Kwokwai Chan', 'Naichung Conan Leung']","In this expository paper, we discuss how Fourier-Mukai-type transformations,
which we call SYZ mirror transformations, can be applied to provide a geometric
understanding of the mirror symmetry phenomena for semi-flat Calabi-Yau
manifolds and toric Fano manifolds. We also speculate the possible applications
of these transformations to other more general settings.",2008-08-11T18:10:02Z,http://arxiv.org/pdf/0808.1551v2,"['math.SG', 'math.AG', '14J32, 53D45, 53D12, 14J45']"
1306.4899v2,Spacetime transformation acoustics,"['C. García-Meca', 'S. Carloni', 'C. Barceló', 'G. Jannes', 'J. Sánchez-Dehesa', 'A. Martínez']","A recently proposed analogue transformation method has allowed the extension
of transformation acoustics to general spacetime transformations. We analyze
here in detail the differences between this new analogue transformation
acoustics (ATA) method and the standard one (STA). We show explicitly that STA
is not suitable for transformations that mix space and time. ATA takes as
starting point the acoustic equation for the velocity potential, instead of
that for the pressure as in STA. This velocity-potential equation by itself
already allows for some transformations mixing space and time, but not all of
them. We explicitly obtain the entire set of transformations that do not leave
its form invariant. It is in these cases that ATA shows its true potential,
allowing for building a transformation acoustics method that enables the full
range of spacetime transformations. We provide an example of an important
transformation which cannot be achieved with STA. Using this transformation, we
design and simulate an acoustic frequency converter via the ATA approach.
Furthermore, in those cases in which one can apply both the STA and ATA
approaches, we study the different transformational properties of the
corresponding physical quantities.",2013-06-20T14:55:47Z,http://arxiv.org/pdf/1306.4899v2,"['gr-qc', 'cond-mat.mes-hall', 'cond-mat.mtrl-sci']"
1403.8088v3,Multiple Geronimus transformations,"['Maxim Derevyagin', 'Juan Carlos García-Ardila', 'Francisco Marcellán']","We consider multiple Geronimus transformations and show that they lead to
discrete (non-diagonal) Sobolev type inner products. Moreover, it is shown that
every discrete Sobolev inner product can be obtained as a multiple Geronimus
transformation. A connection with Geronimus spectral transformations for matrix
orthogonal polynomials is also considered.",2014-03-31T17:02:10Z,http://arxiv.org/pdf/1403.8088v3,"['math.CA', 'math.NA', 'Primary 42C05, Secondary 15A23']"
1803.04248v1,On Quaternion Shearlet Transforms,"['Firdous A. Shah', 'Azhar Y. Tantary']","In this paper, we introduce the notion of quaternion shearlet transform-
which is an extension of the ordinary shearlet transform. Firstly, we study the
fundamental properties of quaternion shearlet transforms and then establish
some basic results including Moyal's and inversion formulae. Finally, we derive
the associated Heisenberg's uncertainty inequality and the corresponding
logarithmic version for quaternion shearlet transforms.",2018-03-01T11:01:28Z,http://arxiv.org/pdf/1803.04248v1,"['math.FA', '42C40. 42C15. 81R30. 42A38']"
1804.00877v2,Mind Duggal Transforms,['C. Benhida'],"It is known that if an operator $T$ is complex symmetric then its Aluthge
transform is also complex symmetric. This Note is devoted to showing that the
Duggal transform doesn't inherit this property. For instance, we'll show that
the Duggal transform isn't always complex symmetric when $T$ is, as it was
claimed in \cite{Ga}.",2018-04-03T09:14:55Z,http://arxiv.org/pdf/1804.00877v2,['math.FA']
2006.01459v2,Infinite-Parameter ADHM Transform,['R. S. Ward'],"The Atiyah-Drinfeld-Hitchin-Manin (ADHM) transform and its various
generalizations are examples of non-linear integral transforms between
finite-dimensional moduli spaces. This note describes a natural
infinite-dimansional generalization, where the transform becomes a map from
boundary data to a family of solutions of the self-duality equations in a
domain.",2020-06-02T08:59:55Z,http://arxiv.org/pdf/2006.01459v2,"['math-ph', 'hep-th', 'math.MP']"
1901.01322v1,Transformed Snapshot Interpolation with High Resolution Transforms,['G. Welper'],"In the last few years, several methods have been developed to deal with jump
singularities in parametric or stochastic hyperbolic PDEs. They typically use
some alignment of the jump-sets in physical space before performing well
established reduced order modelling techniques such as reduced basis methods,
POD or simply interpolation. In the current literature, the transforms are
typically of low resolution in space, mostly low order polynomials, Fourier
modes or constant shifts. In this paper, we discuss higher resolution
transforms in one of the recent methods, the transformed snapshot interpolation
(TSI). We introduce a new discretization of the transforms with an appropriate
behaviour near singularities and consider their numerical computation via an
optimization procedure.",2019-01-04T21:48:27Z,http://arxiv.org/pdf/1901.01322v1,"['math.NA', 'cs.NA', '41A46, 41A25, 35L67, 65M12']"
1110.1589v2,Type-II Bäcklund Transformations via Gauge Transformations,"['A. R. Aguirre', 'T. R. Araujo', 'J. F. Gomes', 'A. H. Zimerman']","The construction of type II Backlund transformation for the sine-Gordon and
the Tzitzeica-Bullough-Dodd models are obtained from gauge transformation. An
infinite number of conserved quantities are constructed from the defect
matrices. This guarantees that the introduction of type II defects for these
models does not spoil their integrability. In particular, modified energy and
momentum are derived and compared with those presented in recent literature.",2011-10-07T17:19:27Z,http://arxiv.org/pdf/1110.1589v2,"['nlin.SI', 'hep-th', 'math-ph', 'math.MP']"
2211.14655v1,How Crucial is Transformer in Decision Transformer?,"['Max Siebenborn', 'Boris Belousov', 'Junning Huang', 'Jan Peters']","Decision Transformer (DT) is a recently proposed architecture for
Reinforcement Learning that frames the decision-making process as an
auto-regressive sequence modeling problem and uses a Transformer model to
predict the next action in a sequence of states, actions, and rewards. In this
paper, we analyze how crucial the Transformer model is in the complete DT
architecture on continuous control tasks. Namely, we replace the Transformer by
an LSTM model while keeping the other parts unchanged to obtain what we call a
Decision LSTM model. We compare it to DT on continuous control tasks, including
pendulum swing-up and stabilization, in simulation and on physical hardware.
Our experiments show that DT struggles with continuous control problems, such
as inverted pendulum and Furuta pendulum stabilization. On the other hand, the
proposed Decision LSTM is able to achieve expert-level performance on these
tasks, in addition to learning a swing-up controller on the real system. These
results suggest that the strength of the Decision Transformer for continuous
control tasks may lie in the overall sequential modeling architecture and not
in the Transformer per se.",2022-11-26T20:13:22Z,http://arxiv.org/pdf/2211.14655v1,"['cs.LG', 'cs.RO']"
9601105v1,The inverse loop transform,['Thomas Thiemann'],"The loop transform in quantum gauge field theory can be recognized as the
Fourier transform (or characteristic functional) of a measure on the space of
generalized connections modulo gauge transformations. Since this space is a
compact Hausdorff space, conversely, we know from the Riesz-Markov theorem that
every positive linear functional on the space of continuous functions thereon
qualifies as the loop transform of a regular Borel measure on the moduli space.
In the present article we show how one can compute the finite joint
distributions of a given characteristic functional, that is, we derive the
inverse loop transform.",1996-01-19T23:20:52Z,http://arxiv.org/pdf/hep-th/9601105v1,"['hep-th', 'gr-qc']"
1210.0803v2,Invertible Darboux Transformations,['Ekaterina Shemyakova'],"For operators of many different kinds it has been proved that (generalized)
Darboux transformations can be built using so called Wronskian formulae. Such
Darboux transformations are not invertible in the sense that the corresponding
mappings of the operator kernels are not invertible. The only known invertible
ones were Laplace transformations (and their compositions), which are special
cases of Darboux transformations for hyperbolic bivariate operators of order 2.
In the present paper we find a criteria for a bivariate linear partial
differential operator of an arbitrary order d to have an invertible Darboux
transformation. We show that Wronkian formulae may fail in some cases, and find
sufficient conditions for such formulae to work.",2012-10-02T15:21:56Z,http://arxiv.org/pdf/1210.0803v2,"['math-ph', 'math.DG', 'math.MP']"
1407.0456v1,Transformed Auto-correlation,"['Jianfeng Zhou', 'Yang Gao']","A transformed auto-correlation method is presented here, where a received
signal is transformed based on a priori reflecting model, and then the
transformed signal is cross-correlated to its original one. If the model is
correct, after transformation, the reflected signal will be coherent to the
transmitted signal, with zero delay. A map of transformed auto-correlation
function with zero delay can be generated in a given parametric space. The
significant peaks in the map may indicate the possible reflectors nearby the
central transmitter. The true values of the parameters of reflectors can be
estimated at the same time.",2014-07-02T05:47:16Z,http://arxiv.org/pdf/1407.0456v1,['astro-ph.IM']
2004.03761v1,Adaptive Transformers in RL,"['Shakti Kumar', 'Jerrod Parker', 'Panteha Naderian']","Recent developments in Transformers have opened new interesting areas of
research in partially observable reinforcement learning tasks. Results from
late 2019 showed that Transformers are able to outperform LSTMs on both memory
intense and reactive tasks. In this work we first partially replicate the
results shown in Stabilizing Transformers in RL on both reactive and memory
based environments. We then show performance improvement coupled with reduced
computation when adding adaptive attention span to this Stable Transformer on a
challenging DMLab30 environment. The code for all our experiments and models is
available at https://github.com/jerrodparker20/adaptive-transformers-in-rl.",2020-04-08T01:03:10Z,http://arxiv.org/pdf/2004.03761v1,"['cs.LG', 'cs.AI', 'cs.NE']"
2002.06170v1,Transformer on a Diet,"['Chenguang Wang', 'Zihao Ye', 'Aston Zhang', 'Zheng Zhang', 'Alexander J. Smola']","Transformer has been widely used thanks to its ability to capture sequence
information in an efficient way. However, recent developments, such as BERT and
GPT-2, deliver only heavy architectures with a focus on effectiveness. In this
paper, we explore three carefully-designed light Transformer architectures to
figure out whether the Transformer with less computations could produce
competitive results. Experimental results on language model benchmark datasets
hint that such trade-off is promising, and the light Transformer reduces 70%
parameters at best, while obtains competitive perplexity compared to standard
Transformer. The source code is publicly available.",2020-02-14T18:41:58Z,http://arxiv.org/pdf/2002.06170v1,"['cs.CL', 'cs.LG']"
1806.00208v1,Degenerate Miller-Paris transformations,"['Dmitrii B. Karp', 'Elena G. Prilepkina']","Important new transformations for the generalized hypergeometric functions
with integral parameter differences have been discovered some years ago by
Miller and Paris and studied in detail in a series of papers by a number of
authors. These transformations fail if the free bottom parameter is greater
than a free top parameter by a small positive integer. In this paper we fill
this gap in the theory of Miller-Paris transformations by computing the limit
cases of these transformations in such previously prohibited situations. This
leads to a number of new transformation and summation formulas including
extensions of Karlsson-Minton theorem.",2018-06-01T06:20:48Z,http://arxiv.org/pdf/1806.00208v1,"['math.CA', '33C20']"
1901.09458v2,Learning Transformation Synchronization,"['Xiangru Huang', 'Zhenxiao Liang', 'Xiaowei Zhou', 'Yao Xie', 'Leonidas Guibas', 'Qixing Huang']","Reconstructing the 3D model of a physical object typically requires us to
align the depth scans obtained from different camera poses into the same
coordinate system. Solutions to this global alignment problem usually proceed
in two steps. The first step estimates relative transformations between pairs
of scans using an off-the-shelf technique. Due to limited information presented
between pairs of scans, the resulting relative transformations are generally
noisy. The second step then jointly optimizes the relative transformations
among all input depth scans. A natural constraint used in this step is the
cycle-consistency constraint, which allows us to prune incorrect relative
transformations by detecting inconsistent cycles. The performance of such
approaches, however, heavily relies on the quality of the input relative
transformations. Instead of merely using the relative transformations as the
input to perform transformation synchronization, we propose to use a neural
network to learn the weights associated with each relative transformation. Our
approach alternates between transformation synchronization using weighted
relative transformations and predicting new weights of the input relative
transformations using a neural network. We demonstrate the usefulness of this
approach across a wide range of datasets.",2019-01-27T23:09:21Z,http://arxiv.org/pdf/1901.09458v2,"['cs.CV', 'cs.LG']"
2306.01128v2,Learning Transformer Programs,"['Dan Friedman', 'Alexander Wettig', 'Danqi Chen']","Recent research in mechanistic interpretability has attempted to
reverse-engineer Transformer models by carefully inspecting network weights and
activations. However, these approaches require considerable manual effort and
still fall short of providing complete, faithful descriptions of the underlying
algorithms. In this work, we introduce a procedure for training Transformers
that are mechanistically interpretable by design. We build on RASP [Weiss et
al., 2021], a programming language that can be compiled into Transformer
weights. Instead of compiling human-written programs into Transformers, we
design a modified Transformer that can be trained using gradient-based
optimization and then automatically converted into a discrete, human-readable
program. We refer to these models as Transformer Programs. To validate our
approach, we learn Transformer Programs for a variety of problems, including an
in-context learning task, a suite of algorithmic problems (e.g. sorting,
recognizing Dyck languages), and NLP tasks including named entity recognition
and text classification. The Transformer Programs can automatically find
reasonable solutions, performing on par with standard Transformers of
comparable size; and, more importantly, they are easy to interpret. To
demonstrate these advantages, we convert Transformers into Python programs and
use off-the-shelf code analysis tools to debug model errors and identify the
""circuits"" used to solve different sub-problems. We hope that Transformer
Programs open a new path toward the goal of intrinsically interpretable machine
learning.",2023-06-01T20:27:01Z,http://arxiv.org/pdf/2306.01128v2,"['cs.LG', 'cs.CL']"
2404.19350v1,Transform Dialect Tutorial,['Oleksandr Zinenko'],"Transform Dialect in MLIR provides operations that can be used to control
transformation of the Intermediate Representation (IR) using a different
portion of the IR. It refers to the IR being transformed as payload IR, and to
the IR guiding the transformation as transform IR.
  The main use case for this dialect is orchestrating fine-grain
transformations on individual IR objects (operations or values) or sets
thereof. For example, it may involve finding loop-like operations with specific
properties (e.g., large size) in the payload IR, applying loop tiling to those
and only those operations, and then applying loop unrolling to the inner loops
produced by the previous transformations. As such, it is not intended as a
replacement for the pass infrastructure, nor for the pattern rewriting
infrastructure. In the most common case, the transform IR will be processed and
applied to the payload IR by a pass. Transformations expressed by the Transform
dialect may be implemented using the pattern infrastructure or any other
relevant MLIR component.
  The rest of this document explains the main concepts and usage scenario of
the MLIR Transform Dialect combined with structured operations.",2024-04-30T08:25:36Z,http://arxiv.org/pdf/2404.19350v1,['cs.PL']
9702028v1,Efficient Quantum Transforms,['Peter Hoyer'],"Quantum mechanics requires the operation of quantum computers to be unitary,
and thus makes it important to have general techniques for developing fast
quantum algorithms for computing unitary transforms. A quantum routine for
computing a generalized Kronecker product is given. Applications include
re-development of the networks for computing the Walsh-Hadamard and the quantum
Fourier transform. New networks for two wavelet transforms are given. Quantum
computation of Fourier transforms for non-Abelian groups is defined. A slightly
relaxed definition is shown to simplify the analysis and the networks that
computes the transforms. Efficient networks for computing such transforms for a
class of metacyclic groups are introduced. A novel network for computing a
Fourier transform for a group used in quantum error-correction is also given.",1997-02-12T00:52:17Z,http://arxiv.org/pdf/quant-ph/9702028v1,['quant-ph']
1306.1669v1,Quaternionic Fourier-Mellin Transform,['Eckhard Hitzer'],"In this contribution we generalize the classical Fourier Mellin transform [S.
Dorrode and F. Ghorbel, Robust and efficient Fourier-Mellin transform
approximations for gray-level image reconstruction and complete invariant
description, Computer Vision and Image Understanding, 83(1) (2001), 57-78, DOI
10.1006/cviu.2001.0922.], which transforms functions $f$ representing, e.g., a
gray level image defined over a compact set of $\mathbb{R}^2$. The quaternionic
Fourier Mellin transform (QFMT) applies to functions $f: \mathbb{R}^2
\rightarrow \mathbb{H}$, for which $|f|$ is summable over $\mathbb{R}_+^*
\times \mathbb{S}^1$ under the measure $d\theta \frac{dr}{r}$. $\mathbb{R}_+^*$
is the multiplicative group of positive and non-zero real numbers. We
investigate the properties of the QFMT similar to the investigation of the
quaternionic Fourier Transform (QFT) in [E. Hitzer, Quaternion Fourier
Transform on Quaternion Fields and Generalizations, Advances in Applied
Clifford Algebras, 17(3) (2007), 497-517.; E. Hitzer, Directional Uncertainty
Principle for Quaternion Fourier Transforms, Advances in Applied Clifford
Algebras, 20(2) (2010), 271-284, online since 08 July 2009.].",2013-06-07T09:32:25Z,http://arxiv.org/pdf/1306.1669v1,"['math.RA', 'cs.CV']"
2004.12760v5,Unitary pseudonatural transformations,['Dominic Verdon'],"We suggest two approaches to a definition of unitarity for pseudonatural
transformations between unitary pseudofunctors on pivotal dagger 2-categories.
The first is to require that the 2-morphism components of the transformation be
unitary. The second is to require that the dagger of the transformation be
equal to its inverse. We show that the `inverse' making these definitions
equivalent is the right dual of the transformation in the 2-category Fun(C,D)
of pseudofunctors C -> D, pseudonatural transformations, and modifications. We
show that the subcategory Fun_u(C,D) $\subset$ Fun(C,D) whose objects are
unitary pseudofunctors and whose 1-morphisms are unitary pseudonatural
transformations is a pivotal dagger 2-category. We apply these results to
obtain a Morita-theoretical classification of unitary pseudonatural
transformations between fibre functors on the category of representations of a
compact quantum group.",2020-04-27T13:03:58Z,http://arxiv.org/pdf/2004.12760v5,"['math.CT', 'math.QA']"
2103.14803v2,Face Transformer for Recognition,"['Yaoyao Zhong', 'Weihong Deng']","Recently there has been a growing interest in Transformer not only in NLP but
also in computer vision. We wonder if transformer can be used in face
recognition and whether it is better than CNNs. Therefore, we investigate the
performance of Transformer models in face recognition. Considering the original
Transformer may neglect the inter-patch information, we modify the patch
generation process and make the tokens with sliding patches which overlaps with
each others. The models are trained on CASIA-WebFace and MS-Celeb-1M databases,
and evaluated on several mainstream benchmarks, including LFW, SLLFW, CALFW,
CPLFW, TALFW, CFP-FP, AGEDB and IJB-C databases. We demonstrate that Face
Transformer models trained on a large-scale database, MS-Celeb-1M, achieve
comparable performance as CNN with similar number of parameters and MACs. To
facilitate further researches, Face Transformer models and codes are available
at https://github.com/zhongyy/Face-Transformer.",2021-03-27T03:53:29Z,http://arxiv.org/pdf/2103.14803v2,['cs.CV']
2411.07218v1,TreeCoders: Trees of Transformers,"[""Pierre Colonna D'Istria"", 'Abdulrahman Altahhan']","In this paper, we introduce TreeCoders, a novel family of transformer trees.
We moved away from traditional linear transformers to complete k-ary trees.
Transformer blocks serve as nodes, and generic classifiers learn to select the
best child and route the sequence of tokens to a specific leaf. The selectors,
moved outside the transformer blocks, allow for the use of a variety of
architecture without further modifications. Furthermore, our proposed
architecture supports sparse node activation due to the logarithmic complexity
of a tree search. We validate our idea by testing a series of decoder-only tree
transformers, achieving competitive results across a diverse range of language
datasets. Our study demonstrates that the proposed tree transformer model
outperforms a size-equivalent linear transformer model 76\% of the time over a
wide range of tree architectures. Furthermore, our proposed model naturally
lends itself to distributed implementation.",2024-11-11T18:40:04Z,http://arxiv.org/pdf/2411.07218v1,"['cs.CL', 'cs.AI']"
0604220v1,Combined Reduced-Rank Transform,"['Anatoli Torokhti', 'Phil Howlett']","We propose and justify a new approach to constructing optimal nonlinear
transforms of random vectors. We show that the proposed transform improves such
characteristics of rank-reduced transforms as compression ratio, accuracy of
decompression and reduces required computational work. The proposed transform
${\mathcal T}_p$ is presented in the form of a sum with $p$ terms where each
term is interpreted as a particular rank-reduced transform. Moreover, terms in
${\mathcal T}_p$ are represented as a combination of three operations
${\mathcal F}_k$, ${\mathcal Q}_k$ and ${\boldsymbol{\phi}}_k$ with
$k=1,...,p$. The prime idea is to determine ${\mathcal F}_k$ separately, for
each $k=1,...,p$, from an associated rank-constrained minimization problem
similar to that used in the Karhunen--Lo\`{e}ve transform. The operations
${\mathcal Q}_k$ and ${\boldsymbol{\phi}}_k$ are auxiliary for finding
${\mathcal F}_k$. The contribution of each term in ${\mathcal T}_p$ improves
the entire transform performance. A corresponding unconstrained nonlinear
optimal transform is also considered. Such a transform is important in its own
right because it is treated as an optimal filter without signal compression. A
rigorous analysis of errors associated with the proposed transforms is given.",2006-04-10T10:43:51Z,http://arxiv.org/pdf/math/0604220v1,"['math.OC', 'math.CA', 'math.NA']"
2209.08167v2,Quantum Vision Transformers,"['El Amine Cherrat', 'Iordanis Kerenidis', 'Natansh Mathur', 'Jonas Landman', 'Martin Strahm', 'Yun Yvonna Li']","In this work, quantum transformers are designed and analysed in detail by
extending the state-of-the-art classical transformer neural network
architectures known to be very performant in natural language processing and
image analysis. Building upon the previous work, which uses parametrised
quantum circuits for data loading and orthogonal neural layers, we introduce
three types of quantum transformers for training and inference, including a
quantum transformer based on compound matrices, which guarantees a theoretical
advantage of the quantum attention mechanism compared to their classical
counterpart both in terms of asymptotic run time and the number of model
parameters. These quantum architectures can be built using shallow quantum
circuits and produce qualitatively different classification models. The three
proposed quantum attention layers vary on the spectrum between closely
following the classical transformers and exhibiting more quantum
characteristics. As building blocks of the quantum transformer, we propose a
novel method for loading a matrix as quantum states as well as two new
trainable quantum orthogonal layers adaptable to different levels of
connectivity and quality of quantum computers. We performed extensive
simulations of the quantum transformers on standard medical image datasets that
showed competitively, and at times better performance compared to the classical
benchmarks, including the best-in-class classical vision transformers. The
quantum transformers we trained on these small-scale datasets require fewer
parameters compared to standard classical benchmarks. Finally, we implemented
our quantum transformers on superconducting quantum computers and obtained
encouraging results for up to six qubit experiments.",2022-09-16T20:51:23Z,http://arxiv.org/pdf/2209.08167v2,"['quant-ph', 'cs.LG']"
2407.09777v1,Graph Transformers: A Survey,"['Ahsan Shehzad', 'Feng Xia', 'Shagufta Abid', 'Ciyuan Peng', 'Shuo Yu', 'Dongyu Zhang', 'Karin Verspoor']","Graph transformers are a recent advancement in machine learning, offering a
new class of neural network models for graph-structured data. The synergy
between transformers and graph learning demonstrates strong performance and
versatility across various graph-related tasks. This survey provides an
in-depth review of recent progress and challenges in graph transformer
research. We begin with foundational concepts of graphs and transformers. We
then explore design perspectives of graph transformers, focusing on how they
integrate graph inductive biases and graph attention mechanisms into the
transformer architecture. Furthermore, we propose a taxonomy classifying graph
transformers based on depth, scalability, and pre-training strategies,
summarizing key principles for effective development of graph transformer
models. Beyond technical analysis, we discuss the applications of graph
transformer models for node-level, edge-level, and graph-level tasks, exploring
their potential in other application scenarios as well. Finally, we identify
remaining challenges in the field, such as scalability and efficiency,
generalization and robustness, interpretability and explainability, dynamic and
complex graphs, as well as data quality and diversity, charting future
directions for graph transformer research.",2024-07-13T05:15:24Z,http://arxiv.org/pdf/2407.09777v1,"['cs.LG', 'cs.AI', '68T07, 68T05, 68U01', 'I.2.6']"
0511211v1,Gauge transformations are not canonical transformations,"['A. T. Suzuki', 'J. H. O. Sales']","In classical mechanics, we can describe the dynamics of a given system using
either the Lagrangian formalism or the Hamiltonian formalism, the choice of
either one being determined by whether one wants to deal with a second degree
differential equation or a pair of first degree ones. For the former approach,
we know that the Euler-Lagrange equation of motion remains invariant under
additive total derivative with respect to time of any function of coordinates
and time in the Lagrangian function, whereas the latter one is invariant under
canonical transformations. In this short paper we address the question whether
the transformation that leaves the Euler-Lagrange equation of motion invariant
is also a canonical transformation and show that it is not.",2005-11-21T18:20:51Z,http://arxiv.org/pdf/hep-th/0511211v1,['hep-th']
2305.16982v1,TranSFormer: Slow-Fast Transformer for Machine Translation,"['Bei Li', 'Yi Jing', 'Xu Tan', 'Zhen Xing', 'Tong Xiao', 'Jingbo Zhu']","Learning multiscale Transformer models has been evidenced as a viable
approach to augmenting machine translation systems. Prior research has
primarily focused on treating subwords as basic units in developing such
systems. However, the incorporation of fine-grained character-level features
into multiscale Transformer has not yet been explored. In this work, we present
a \textbf{S}low-\textbf{F}ast two-stream learning model, referred to as
Tran\textbf{SF}ormer, which utilizes a ``slow'' branch to deal with subword
sequences and a ``fast'' branch to deal with longer character sequences. This
model is efficient since the fast branch is very lightweight by reducing the
model width, and yet provides useful fine-grained features for the slow branch.
Our TranSFormer shows consistent BLEU improvements (larger than 1 BLEU point)
on several machine translation benchmarks.",2023-05-26T14:37:38Z,http://arxiv.org/pdf/2305.16982v1,"['cs.CL', 'cs.AI']"
2404.12362v1,Transformer tricks: Removing weights for skipless transformers,['Nils Graef'],"He and Hofmann (arXiv:2311.01906) detailed a skipless transformer without the
V and P (post-attention projection) linear layers, which reduces the total
number of weights. However, this scheme is only applicable to MHA (multi-head
attention), but not for MQA (multi-query attention) and GQA (grouped-query
attention). The latter schemes are used by many popular LLMs such as Llama 2,
Mistral, Mixtral, PaLM, and Gemma. Therefore, this micro-paper proposes
mathematically equivalent versions that are suitable for MQA and GQA. For
example, removing Q and P from a skipless version of Mistral-7B would remove
15% of its weights (and thus reduce its compute and memory complexity). See
arXiv:2402.13388 and https://github.com/OpenMachine-ai/transformer-tricks for
code and more transformer tricks.",2024-04-18T17:45:19Z,http://arxiv.org/pdf/2404.12362v1,['cs.LG']
0503668v1,The Hough transform estimator,"['Alexander Goldenshluger', 'Assaf Zeevi']","This article pursues a statistical study of the Hough transform, the
celebrated computer vision algorithm used to detect the presence of lines in a
noisy image. We first study asymptotic properties of the Hough transform
estimator, whose objective is to find the line that ``best'' fits a set of
planar points. In particular, we establish strong consistency and rates of
convergence, and characterize the limiting distribution of the Hough transform
estimator. While the convergence rates are seen to be slower than those found
in some standard regression methods, the Hough transform estimator is shown to
be more robust as measured by its breakdown point. We next study the Hough
transform in the context of the problem of detecting multiple lines. This is
addressed via the framework of excess mass functionals and modality testing.
Throughout, several numerical examples help illustrate various properties of
the estimator. Relations between the Hough transform and more mainstream
statistical paradigms and methods are discussed as well.",2005-03-29T10:12:30Z,http://arxiv.org/pdf/math/0503668v1,"['math.ST', 'stat.TH', '62F12, 62F35, 68T45 (Primary)']"
0607224v1,Composite Cosine Transforms,"['E. Ournycheva', 'B. Rubin']","The cosine transforms of functions on the unit sphere play an important role
in convex geometry, the Banach space theory, stochastic geometry and other
areas. Their higher-rank generalization to Grassmann manifolds represents an
interesting mathematical object useful for applications. We introduce more
general integral transforms that reveal distinctive features of higher-rank
objects in full generality. We call these new transforms the composite cosine
transforms, by taking into account that their kernels agree with the composite
power function of the cone of positive definite symmetric matrices. We show
that injectivity of the composite cosine transforms can be studied using
standard tools of the Fourier analysis on matrix spaces. In the framework of
this approach, we introduce associated generalized zeta integrals and give new
simple proofs to the relevant functional relations. Our technique is based on
application of the higher-rank Radon transform on matrix spaces.",2006-07-09T00:05:13Z,http://arxiv.org/pdf/math/0607224v1,"['math.FA', 'Primary 42B10; Secondary 52A22']"
0208153v1,Comparison of unitary transforms,"['Erika Andersson', 'Igor Jex', 'Stephen M. Barnett']","We analyze the problem of comparing unitary transformations. The task is to
decide, with minimal resources and maximal reliability, whether two given
unitary transformations are identical or different. It is possible to make such
comparisons without obtaining any information about the individual
transformations. Different comparison strategies are presented and compared
with respect to their efficiency. With an interferometric setup, it is possible
to compare two unitary transforms using only one test particle. Another
strategy makes use of a two-particle singlet state. This strategy is more
efficient than using a non-entangled two-particle test state, thus
demonstrating the benefit of entanglement. Generalisations to higher
dimensional transforms and to more than two transformations are made.",2002-08-26T17:18:42Z,http://arxiv.org/pdf/quant-ph/0208153v1,['quant-ph']
0711.3577v1,Transform martingale estimating functions,['T. Merkouris'],"An estimation method is proposed for a wide variety of discrete time
stochastic processes that have an intractable likelihood function but are
otherwise conveniently specified by an integral transform such as the
characteristic function, the Laplace transform or the probability generating
function. This method involves the construction of classes of transform-based
martingale estimating functions that fit into the general framework of
quasi-likelihood. In the parametric setting of a discrete time stochastic
process, we obtain transform quasi-score functions by projecting the
unavailable score function onto the special linear spaces formed by these
classes. The specification of the process by any of the main integral
transforms makes possible an arbitrarily close approximation of the score
function in an infinite-dimensional Hilbert space by optimally combining
transform martingale quasi-score functions. It also allows an extension of the
domain of application of quasi-likelihood methodology to processes with
infinite conditional second moment.",2007-11-22T14:03:14Z,http://arxiv.org/pdf/0711.3577v1,"['math.ST', 'stat.TH', '62M99, 60G42, 60E10 (Primary) 62M05, 62M09 (Secondary)']"
1611.02564v1,Generalizing the Lorentz transformations,"['James M. Chappell', 'David L. Berkahn', 'Nicolangelo Iannella', 'John G. Hartnett', 'Azhar Iqbal', 'Derek Abbott']","In this paper we develop a framework allowing a natural extension of the
Lorentz transformations. To begin, we show that by expanding conventional
four-dimensional spacetime to eight-dimensions that a natural generalization is
indeed obtained. We then find with these generalized coordinate transformations
acting on Maxwell's equations that the electromagnetic field transformations
are nevertheless unchanged. We find further, that if we assume the absence of
magnetic monopoles, in accordance with Maxwell's theory, our generalized
transformations are then restricted to be the conventional ones. While the
conventional Lorentz transformations are indeed recovered from our framework,
we nevertheless provide a new perspective into why the Lorentz transformations
are constrained to be the conventional ones. Also, this generalized framework
may assist in explaining several unresolved questions in electromagnetism as
well as to be able to describe quasi magnetic monopoles found in spin-ice
systems.",2016-11-01T01:46:43Z,http://arxiv.org/pdf/1611.02564v1,"['physics.gen-ph', 'J.2']"
1905.04116v1,Holomorphic fractional Fourier transforms,"['William D. Kirwin', 'José Mourão', 'João P. Nunes', 'Thomas Thiemann']","The Fractional Fourier Transform (FrFT) has widespread applications in areas
like signal analysis, Fourier optics, diffraction theory, etc. The Holomorphic
Fractional Fourier Transform (HFrFT) proposed in the present paper may be used
in the same wide range of applications with improved properties. The HFrFT of
signals spans a one-parameter family of (essentially) holomorphic functions,
where the parameter takes values in the bounded interval $t\in (0,\pi/2)$. At
the boundary values of the parameter, one obtains the original signal at $t=0$
and its Fourier transform at the other end of the interval $t=\pi/2$. If the
initial signal is $L^2 $, then, for an appropriate choice of inner product that
will be detailed below, the transform is unitary for all values of the
parameter in the interval. This transform provides a heat kernel smoothening of
the signals while preserving unitarity for $L^2$-signals and continuously
interpolating between the original signal and its Fourier transform.",2019-05-10T12:35:12Z,http://arxiv.org/pdf/1905.04116v1,"['math-ph', 'eess.SP', 'math.MP']"
1905.08494v2,Deep Signature Transforms,"['Patric Bonnier', 'Patrick Kidger', 'Imanol Perez Arribas', 'Cristopher Salvi', 'Terry Lyons']","The signature is an infinite graded sequence of statistics known to
characterise a stream of data up to a negligible equivalence class. It is a
transform which has previously been treated as a fixed feature transformation,
on top of which a model may be built. We propose a novel approach which
combines the advantages of the signature transform with modern deep learning
frameworks. By learning an augmentation of the stream prior to the signature
transform, the terms of the signature may be selected in a data-dependent way.
More generally, we describe how the signature transform may be used as a layer
anywhere within a neural network. In this context it may be interpreted as a
pooling operation. We present the results of empirical experiments to back up
the theoretical justification. Code available at
https://github.com/patrick-kidger/Deep-Signature-Transforms.",2019-05-21T08:39:55Z,http://arxiv.org/pdf/1905.08494v2,"['cs.LG', 'stat.ML', '68T01']"
2004.03637v2,Probabilistic Spatial Transformer Networks,"['Pola Schwöbel', 'Frederik Warburg', 'Martin Jørgensen', 'Kristoffer H. Madsen', 'Søren Hauberg']","Spatial Transformer Networks (STNs) estimate image transformations that can
improve downstream tasks by `zooming in' on relevant regions in an image.
However, STNs are hard to train and sensitive to mis-predictions of
transformations. To circumvent these limitations, we propose a probabilistic
extension that estimates a stochastic transformation rather than a
deterministic one. Marginalizing transformations allows us to consider each
image at multiple poses, which makes the localization task easier and the
training more robust. As an additional benefit, the stochastic transformations
act as a localized, learned data augmentation that improves the downstream
tasks. We show across standard imaging benchmarks and on a challenging
real-world dataset that these two properties lead to improved classification
performance, robustness and model calibration. We further demonstrate that the
approach generalizes to non-visual domains by improving model performance on
time-series data.",2020-04-07T18:22:02Z,http://arxiv.org/pdf/2004.03637v2,"['cs.LG', 'stat.ML']"
1802.05834v2,On discrete Wigner transforms,"['Zhenning Cai', 'Jianfeng Lu', 'Kevin Stubbs']","In this work, we derive a discrete analog of the Wigner transform over the
space $(\mathbb{C}^p)^{\otimes N}$ for any prime $p$ and any positive integer
$N$. We show that the Wigner transform over this space can be constructed as
the inverse Fourier transform of the standard Pauli matrices for $p=2$ or more
generally of the Heisenberg-Weyl group elements for $p > 2$. We connect our
work to a previous construction by Wootters of a discrete Wigner transform by
showing that for all $p$, Wootters' construction corresponds to taking the
inverse symplectic Fourier transform instead of the inverse Fourier transform.
Finally, we discuss some implications of these results for the numerical
simulation of many-body quantum spin systems.",2018-02-16T04:38:02Z,http://arxiv.org/pdf/1802.05834v2,"['math-ph', 'math.MP']"
1610.09152v2,Steerable Discrete Cosine Transform,"['Giulia Fracastoro', 'Sophie Marie Fosson', 'Enrico Magli']","In image compression, classical block-based separable transforms tend to be
inefficient when image blocks contain arbitrarily shaped discontinuities. For
this reason, transforms incorporating directional information are an appealing
alternative. In this paper, we propose a new approach to this problem, namely a
discrete cosine transform (DCT) that can be steered in any chosen direction.
Such transform, called steerable DCT (SDCT), allows to rotate in a flexible way
pairs of basis vectors, and enables precise matching of directionality in each
image block, achieving improved coding efficiency. The optimal rotation angles
for SDCT can be represented as solution of a suitable rate-distortion (RD)
problem. We propose iterative methods to search such solution, and we develop a
fully fledged image encoder to practically compare our techniques with other
competing transforms. Analytical and numerical results prove that SDCT
outperforms both DCT and state-of-the-art directional transforms.",2016-10-28T10:09:12Z,http://arxiv.org/pdf/1610.09152v2,"['cs.IT', 'cs.MM', 'math.IT', 'math.OC']"
2008.02934v1,Transformational Verification of Quicksort,"['Emanuele De Angelis', 'Fabio Fioravanti', 'Maurizio Proietti']","Many transformation techniques developed for constraint logic programs, also
known as constrained Horn clauses (CHCs), have found new useful applications in
the field of program verification. In this paper, we work out a nontrivial case
study through the transformation-based verification approach. We consider the
familiar Quicksort program for sorting lists, written in a functional
programming language, and we verify the pre/-postconditions that specify the
intended correctness properties of the functions defined in the program. We
verify these properties by: (1) translating them into CHCs, (2) transforming
the CHCs by removing all list occurrences, and (3) checking the satisfiability
of the transformed CHCs by using the Eldarica solver over booleans and
integers. The transformation mentioned at Point (2) requires an extension of
the algorithms for the elimination of inductively defined data structures
presented in previous work, because during one stage of the transformation we
use as lemmas some properties that have been proved at previous stages.",2020-08-07T01:23:40Z,http://arxiv.org/pdf/2008.02934v1,"['cs.LO', 'cs.PL']"
2111.11067v2,Semi-Supervised Vision Transformers,"['Zejia Weng', 'Xitong Yang', 'Ang Li', 'Zuxuan Wu', 'Yu-Gang Jiang']","We study the training of Vision Transformers for semi-supervised image
classification. Transformers have recently demonstrated impressive performance
on a multitude of supervised learning tasks. Surprisingly, we show Vision
Transformers perform significantly worse than Convolutional Neural Networks
when only a small set of labeled data is available. Inspired by this
observation, we introduce a joint semi-supervised learning framework,
Semiformer, which contains a transformer stream, a convolutional stream and a
carefully designed fusion module for knowledge sharing between these streams.
The convolutional stream is trained on limited labeled data and further used to
generate pseudo labels to supervise the training of the transformer stream on
unlabeled data. Extensive experiments on ImageNet demonstrate that Semiformer
achieves 75.5% top-1 accuracy, outperforming the state-of-the-art by a clear
margin. In addition, we show, among other things, Semiformer is a general
framework that is compatible with most modern transformer and convolutional
neural architectures. Code is available at
https://github.com/wengzejia1/Semiformer.",2021-11-22T09:28:13Z,http://arxiv.org/pdf/2111.11067v2,['cs.CV']
2201.05706v2,Perspective Transformation Layer,"['Nishan Khatri', 'Agnibh Dasgupta', 'Yucong Shen', 'Xin Zhong', 'Frank Y. Shih']","Incorporating geometric transformations that reflect the relative position
changes between an observer and an object into computer vision and deep
learning models has attracted much attention in recent years. However, the
existing proposals mainly focus on the affine transformation that is
insufficient to reflect such geometric position changes. Furthermore, current
solutions often apply a neural network module to learn a single transformation
matrix, which not only ignores the importance of multi-view analysis but also
includes extra training parameters from the module apart from the
transformation matrix parameters that increase the model complexity. In this
paper, a perspective transformation layer is proposed in the context of deep
learning. The proposed layer can learn homography, therefore reflecting the
geometric positions between observers and objects. In addition, by directly
training its transformation matrices, a single proposed layer can learn an
adjustable number of multiple viewpoints without considering module parameters.
The experiments and evaluations confirm the superiority of the proposed layer.",2022-01-14T23:09:26Z,http://arxiv.org/pdf/2201.05706v2,"['cs.CV', 'cs.LG']"
2302.04869v1,Reversible Vision Transformers,"['Karttikeya Mangalam', 'Haoqi Fan', 'Yanghao Li', 'Chao-Yuan Wu', 'Bo Xiong', 'Christoph Feichtenhofer', 'Jitendra Malik']","We present Reversible Vision Transformers, a memory efficient architecture
design for visual recognition. By decoupling the GPU memory requirement from
the depth of the model, Reversible Vision Transformers enable scaling up
architectures with efficient memory usage. We adapt two popular models, namely
Vision Transformer and Multiscale Vision Transformers, to reversible variants
and benchmark extensively across both model sizes and tasks of image
classification, object detection and video classification. Reversible Vision
Transformers achieve a reduced memory footprint of up to 15.5x at roughly
identical model complexity, parameters and accuracy, demonstrating the promise
of reversible vision transformers as an efficient backbone for hardware
resource limited training regimes. Finally, we find that the additional
computational burden of recomputing activations is more than overcome for
deeper models, where throughput can increase up to 2.3x over their
non-reversible counterparts. Full code and trained models are available at
https://github.com/facebookresearch/slowfast. A simpler, easy to understand and
modify version is also available at https://github.com/karttikeya/minREV",2023-02-09T18:59:54Z,http://arxiv.org/pdf/2302.04869v1,"['cs.CV', 'cs.AI']"
2304.10557v5,An Introduction to Transformers,['Richard E. Turner'],"The transformer is a neural network component that can be used to learn
useful representations of sequences or sets of data-points. The transformer has
driven recent advances in natural language processing, computer vision, and
spatio-temporal modelling. There are many introductions to transformers, but
most do not contain precise mathematical descriptions of the architecture and
the intuitions behind the design choices are often also missing. Moreover, as
research takes a winding path, the explanations for the components of the
transformer can be idiosyncratic. In this note we aim for a mathematically
precise, intuitive, and clean description of the transformer architecture. We
will not discuss training as this is rather standard. We assume that the reader
is familiar with fundamental topics in machine learning including multi-layer
perceptrons, linear transformations, softmax functions and basic probability.",2023-04-20T14:54:19Z,http://arxiv.org/pdf/2304.10557v5,"['cs.LG', 'cs.AI']"
2306.09539v4,Block-State Transformers,"['Mahan Fathi', 'Jonathan Pilault', 'Orhan Firat', 'Christopher Pal', 'Pierre-Luc Bacon', 'Ross Goroshin']","State space models (SSMs) have shown impressive results on tasks that require
modeling long-range dependencies and efficiently scale to long sequences owing
to their subquadratic runtime complexity. Originally designed for continuous
signals, SSMs have shown superior performance on a plethora of tasks, in vision
and audio; however, SSMs still lag Transformer performance in Language Modeling
tasks. In this work, we propose a hybrid layer named Block-State Transformer
(BST), that internally combines an SSM sublayer for long-range
contextualization, and a Block Transformer sublayer for short-term
representation of sequences. We study three different, and completely
parallelizable, variants that integrate SSMs and block-wise attention. We show
that our model outperforms similar Transformer-based architectures on language
modeling perplexity and generalizes to longer sequences. In addition, the
Block-State Transformer demonstrates more than tenfold increase in speed at the
layer level compared to the Block-Recurrent Transformer when model
parallelization is employed.",2023-06-15T22:48:08Z,http://arxiv.org/pdf/2306.09539v4,"['cs.CL', 'cs.LG']"
1605.08683v1,The Fourier and Hilbert transforms under the Bargmann transform,"['Xing-Tang Dong', 'Kehe Zhu']","There is a canonical unitary transformation from $L^2(\R)$ onto the Fock
space $F^2$, called the Bargmann transform. We study the action of the Bargmann
transform on several classical integral operators on $L^2(\R)$, including the
fractional Fourier transform, the fractional Hilbert transform, and the wavelet
transform.",2016-05-27T15:23:27Z,http://arxiv.org/pdf/1605.08683v1,"['math.CV', 'math.FA']"
9503416v1,The Foldy-Wouthuysen transformation,"['John P. Costella', 'Bruce H. J. McKellar']","The Foldy-Wouthuysen transformation of the Dirac Hamiltonian is generally
taught as simply a mathematical trick that allows one to obtain a two-component
theory in the low-energy limit. It is not often emphasized that the transformed
representation is the only one in which one can take a meaningful *classical
limit*, in terms of particles and antiparticles. We briefly review the history
and physics of this transformation.",1995-03-23T00:03:04Z,http://arxiv.org/pdf/hep-ph/9503416v1,['hep-ph']
0002133v2,Ramond-Ramond Field Transformation,['Yungui Gong'],"We find that the mixture of Ramond-Ramond fields and Neveu-Schwarz two form
are transformed as Majorana spinors under the T-duality group $O(d,d)$. The
Ramond-Ramond field transformation under the group $O(d,d)$ is realized in a
simple form by using the spinor representation. The Ramond-Ramond field
transformation rule obtained by Bergshoeff et al. is shown as a specific simple
example. We also give some explicit examples of the spinor representation.",2000-02-16T20:48:30Z,http://arxiv.org/pdf/hep-th/0002133v2,['hep-th']
0212105v1,Henstock--Kurzweil Fourier transforms,['Erik Talvila'],"The Fourier transform is considered as a Henstock--Kurzweil integral.
Sufficient conditions are given for the existence of the Fourier transform and
necessary and sufficient conditions are given for it to be continuous. The
Riemann--Lebesgue lemma fails: Henstock--Kurzweil Fourier transforms can have
arbitrarily large point-wise growth. Convolution and inversion theorems are
established. An appendix gives sufficient conditions for interchanging repeated
Henstock--Kurzweil integrals and gives an estimate on the integral of a
product.",2002-12-07T00:53:27Z,http://arxiv.org/pdf/math/0212105v1,"['math.CA', '42A38, 26A39']"
0507099v1,Relativistic force transformation,['Valery P. Dmitriyev'],"Formulae relating one and the same force in two inertial frames of reference
are derived directly from the Lorentz transformation of space and time
coordinates and relativistic equation for the dynamic law of motion in three
dimensions. We obtain firstly relativistic transformation for the velocity and
acceleration of a particle. Then we substitute them in the relativistic dynamic
equation and perform tedious algebraic manipulations. No recourse were made to
""general rules for the transformation of 4-tensors"". Formulae obtained were
verified in electrodynamics.",2005-07-13T04:37:18Z,http://arxiv.org/pdf/physics/0507099v1,['physics.ed-ph']
1112.3639v1,The Run Transform,"['David Callan', 'Emeric Deutsch']","We consider the transform from sequences to triangular arrays defined in
terms of generating functions by f(x) -> (1-x)/(1-xy) f(x(1-x)/(1-xy)). We
establish a criterion for the transform of a nonnegative sequence to be
nonnegative, and we show that the transform counts certain classes of lattice
paths by number of ""pyramid ascents"", as well as certain classes of ordered
partitions by number of blocks that consist of increasing consecutive integers.",2011-12-15T20:29:01Z,http://arxiv.org/pdf/1112.3639v1,"['math.CO', '05A15']"
1212.0957v1,Generalized Stirling transform,['Mourad Rahmani'],"In this paper, algorithms are developed for computing the Stirling transform
and the inverse Stirling transform; specifically, we investigate a class of
sequences satisfying a two-term recurrence. We derive a general identity which
generalizes the usual Stirling transform and investigate the corresponding
generating functions also. In addition, some interesting consequences of these
results related to classical sequences like Fibonacci, Bernoulli and the
numbers of derangements have been derived.",2012-12-05T08:06:28Z,http://arxiv.org/pdf/1212.0957v1,"['math.CO', 'math.NT', '05A19, 11B68']"
1705.07401v2,Transformations of partial matchings,['Inasa Nakamura'],"We consider partial matchings, which are finite graphs consisting of edges
and vertices of degree zero or one. We consider transformations between two
states of partial matchings. We introduce a method of presenting a
transformation between partial matchings. We introduce the notion of the
lattice presentation of a partial matching, and the lattice polytope associated
with a pair of lattice presentations, and we investigate transformations with
minimal area.",2017-05-21T06:08:39Z,http://arxiv.org/pdf/1705.07401v2,['math.GT']
2305.01857v1,Toward Textual Transform Coding,['Tsachy Weissman'],"Inspired by recent work on compression with and for young humans, the success
of transform-based approaches to information processing, and the rise of
powerful language-based AI, we propose \emph{textual transform coding}. It
shares some of its key properties with traditional transform-based coding
underlying much of our current multimedia compression technologies. It can form
the basis for compression at bit rates until recently considered uselessly low,
and for boosting human satisfaction from reconstructions at more traditional
bit rates.",2023-05-03T01:59:49Z,http://arxiv.org/pdf/2305.01857v1,"['cs.IT', 'math.IT']"
1401.0821v1,Intuitionistic Fuzzy Linear Transformations,"['Rajkumar Pradhan', 'Madhumangal Pal']","In this paper, we discussed about the intuitionistic fuzzy linear
transformations (IFLT) and shown that the set of all linear transformations
L(V) defined over an intuitionistic fuzzy vector space V does not form an
vector space. Here we determine the unique intuitionistic fuzzy matrix
associated with an intuitionistic fuzzy linear transformation with respect to
an ordered standard basis for an intuitionistic fuzzy vector space. We
introduced the concept of the inverse of an IFLT.",2014-01-04T15:41:27Z,http://arxiv.org/pdf/1401.0821v1,"['cs.DM', '08A72, 15B15']"
2111.13921v1,Transformed K-means Clustering,"['Anurag Goel', 'Angshul Majumdar']","In this work we propose a clustering framework based on the paradigm of
transform learning. In simple terms the representation from transform learning
is used for K-means clustering; however, the problem is not solved in such a
na\""ive piecemeal fashion. The K-means clustering loss is embedded into the
transform learning framework and the joint problem is solved using the
alternating direction method of multipliers. Results on document clustering
show that our proposed approach improves over the state-of-the-art.",2021-11-27T15:28:37Z,http://arxiv.org/pdf/2111.13921v1,"['cs.LG', 'stat.ML']"
2307.02649v1,Periodic discrete Darboux transforms,"['Joseph Cho', 'Katrin Leschke', 'Yuta Ogata']","We express Darboux transformations of discrete polarised curves as parallel
sections of discrete connections in the quaternionic formalism. This
immediately leads to the linearisation of the monodromy of the transformation.
We also consider the integrable reduction to the case of discrete bicycle
correspondence. Applying our method to the case of discrete circles, we obtain
closed-form discrete parametrisations of all (closed) Darboux transforms and
(closed) bicycle correspondences.",2023-07-05T20:47:23Z,http://arxiv.org/pdf/2307.02649v1,"['math.DG', '(2020): 53A70 (Primary) 58J72 (Secondary)']"
2503.10462v1,Convolutional transformer wave functions,"['Ao Chen', 'Vighnesh Dattatraya Naik', 'Markus Heyl']","Deep neural quantum states have recently achieved remarkable performance in
solving challenging quantum many-body problems. While transformer networks
appear particularly promising due to their success in computer science, we show
that previously reported transformer wave functions haven't so far been capable
to utilize their full power. Here, we introduce the convolutional transformer
wave function (CTWF). We show that our CTWFs exhibit superior performance in
ground-state search and non-equilibrium dynamics compared to previous results,
demonstrating promising capacity in complex quantum problems.",2025-03-13T15:32:21Z,http://arxiv.org/pdf/2503.10462v1,"['cond-mat.dis-nn', 'quant-ph']"
0907.1975v2,On semifast Fourier transform algorithms,['Sergei V. Fedorenko'],We consider the relations between well-known Fourier transform algorithms.,2009-07-11T17:13:50Z,http://arxiv.org/pdf/0907.1975v2,"['cs.IT', 'math.IT']"
9603004v1,Transformation de Fourier generalisee,['Gerard Laumon'],"In this paper I construct a geometric transformation for generalized
1-motives which extends the Fourier-Mukai transformation for O-Modules on
abelian varieties, the geometric Fourier transformation for D-Modules on vector
spaces and the geometric Mellin transformation for D-Modules on tori. In
particular, I construct an equivalence of triangulated categories between the
derived category of quasi-coherent D-Modules on an abelian variety and the
derived category of quasi-coherent O-Modules on the universal extension of the
dual abelian variety. This equivalence has also been obtained by Mitchell
Rothstein.",1996-03-05T12:45:12Z,http://arxiv.org/pdf/alg-geom/9603004v1,"['alg-geom', 'math.AG', '14F05 (Primary) 14K05 (Secondary)']"
9705001v1,Generalized Fourier-Mukai Transforms,['Antony Maciocia'],"The paper sets out a generalized framework for Fourier-Mukai transforms and
illustrates their use via vector bundle transforms. A Fourier-Mukai transform
is, roughly, an isomorphism of derived categories of (sheaves) on smooth
varieties X and Y. We show that these can only exist if the first Chern class
of the varieties vanishes and, in the case of vector bundle transforms, will
exist if and only if there is a bi-universal bundle on XxY which is ""strongly
simple"" in a suitable sense. Some applications are given to abelian varieties
extending the work of Mukai.",1997-05-01T15:31:54Z,http://arxiv.org/pdf/alg-geom/9705001v1,"['alg-geom', 'math.AG']"
9612007v1,Twisted Legendre transformation,['S. Zakrzewski'],"The general framework of Legendre transformation is extended to the case of
symplectic groupoids, using an appropriate generalization of the notion of
generating function (of a Lagrangian submanifold).",1996-12-04T12:38:07Z,http://arxiv.org/pdf/dg-ga/9612007v1,"['dg-ga', 'math.DG', '58F05 (Primary) 22A22, 58H05, 53Z05 (Secondary)']"
0412087v1,A New Integral Transform,['B. G. Sidharth'],"Using Bauer's expansion and properties of spherical Bessel and Legender
functions, we deduce a new transform and briefly indicate its use.",2004-12-04T16:20:22Z,http://arxiv.org/pdf/math/0412087v1,['math.GM']
0505248v1,An elliptic determinant transformation,['Hjalmar Rosengren'],"We prove a transformation formula relating two determinants involving
elliptic shifted factorials. Similar determinants have been applied to multiple
elliptic hypergeometric series.",2005-05-12T10:01:07Z,http://arxiv.org/pdf/math/0505248v1,"['math.CA', '15A15; 33D67; 33E05']"
0702107v1,The Quantum Mellin transform,"['J. Twamley', 'G. J. Milburn']","We uncover a new type of unitary operation for quantum mechanics on the
half-line which yields a transformation to ``Hyperbolic phase space''. We show
that this new unitary change of basis from the position x on the half line to
the Hyperbolic momentum $p_\eta$, transforms the wavefunction via a Mellin
transform on to the critial line $s=1/2-ip_\eta$. We utilise this new transform
to find quantum wavefunctions whose Hyperbolic momentum representation
approximate a class of higher transcendental functions, and in particular,
approximate the Riemann Zeta function. We finally give possible physical
realisations to perform an indirect measurement of the Hyperbolic momentum of a
quantum system on the half-line.",2007-02-12T11:42:37Z,http://arxiv.org/pdf/quant-ph/0702107v1,['quant-ph']
0708.1328v1,Limited scope adic transformations,['Sarah Bailey Frick'],"We introduce a family of adic transformations on diagrams that are
nonstationary and nonsimple. This family includes some previously studied adic
transformations. We relate the dimension group of each these diagrams to the
dynamical system determined by the adic transformation on the infinite edge
paths, and we explicitly compute the dimension group for a subfamily. We also
determine the ergodic adic invariant probability measures for this subfamily,
and show that each system of the subfamily is loosely Bernoulli. We also give
examples of particular adic transformations with roots of unity as well as one
which is totally ergodic called the Euler adic. We also show that the Euler
adic is loosely Bernoulli.",2007-08-09T20:16:00Z,http://arxiv.org/pdf/0708.1328v1,"['math.DS', '37A05, 37A25']"
1107.1695v1,On Krawtchouk Transforms,"['Philip Feinsilver', 'René Schott']","Krawtchouk polynomials appear in a variety of contexts, most notably as
orthogonal polynomials and in coding theory via the Krawtchouk transform. We
present an operator calculus formulation of the Krawtchouk transform that is
suitable for computer implementation. A positivity result for the Krawtchouk
transform is shown. Then our approach is compared with the use of the
Krawtchouk transform in coding theory where it appears in MacWilliams' and
Delsarte's theorems on weight enumerators. We conclude with a construction of
Krawtchouk polynomials in an arbitrary finite number of variables, orthogonal
with respect to the multinomial distribution.",2011-06-24T02:34:47Z,http://arxiv.org/pdf/1107.1695v1,"['cs.IT', 'math.CA', 'math.IT', 'Primary: 15.0, 15A69 Secondary: 05E35, 42C05']"
1303.7298v1,Generalized ideal transforms,"['Tran Tuan Nam', 'Nguyen minh Tri']","We study basic properties of the generalized ideal transforms $D_I(M, N)$ and
the set of associated primes of the modules $R^iD_I(M,N).$",2013-03-29T05:50:34Z,http://arxiv.org/pdf/1303.7298v1,"['math.AC', '13D45']"
1508.07879v3,Noncommutative bispectral Darboux transformations,"['Joel Geiger', 'Emil Horozov', 'Milen Yakimov']","We prove a general theorem establishing the bispectrality of noncommutative
Darboux transformations. It has a wide range of applications that establish
bispectrality of such transformations for differential, difference and
q-difference operators with values in all noncommutative algebras. All known
bispectral Darboux transformations are special cases of the theorem. Using the
methods of quasideterminants and the spectral theory of matrix polynomials, we
explicitly classify the set of bispectral Darboux transformations from rank one
differential operators and Airy operators with values in matrix algebras. These
sets generalize the classical Calogero-Moser spaces and Wilson's adelic
Grassmannian.",2015-08-31T15:47:00Z,http://arxiv.org/pdf/1508.07879v3,"['math.CA', 'math.RA', 'Primary 37K35, Secondary 16S32, 39A70']"
1611.08230v2,Learning Fast Sparsifying Transforms,"['Cristian Rusu', 'John Thompson']","Given a dataset, the task of learning a transform that allows sparse
representations of the data bears the name of dictionary learning. In many
applications, these learned dictionaries represent the data much better than
the static well-known transforms (Fourier, Hadamard etc.). The main downside of
learned transforms is that they lack structure and therefore they are not
computationally efficient, unlike their classical counterparts. These posse
several difficulties especially when using power limited hardware such as
mobile devices, therefore discouraging the application of sparsity techniques
in such scenarios. In this paper we construct orthogonal and non-orthogonal
dictionaries that are factorized as a product of a few basic transformations.
In the orthogonal case, we solve exactly the dictionary update problem for one
basic transformation, which can be viewed as a generalized Givens rotation, and
then propose to construct orthogonal dictionaries that are a product of these
transformations, guaranteeing their fast manipulation. We also propose a method
to construct fast square but non-orthogonal dictionaries that are factorized as
a product of few transforms that can be viewed as a further generalization of
Givens rotations to the non-orthogonal setting. We show how the proposed
transforms can balance very well data representation performance and
computational complexity. We also compare with classical fast and learned
general and orthogonal transforms.",2016-11-24T15:57:09Z,http://arxiv.org/pdf/1611.08230v2,['cs.LG']
1905.13475v1,Tetrahedron trinomial coefficient transform,['László Németh'],"We introduce the tetrahedron trinomial coefficient transform which takes a
Pascal-like arithmetical triangle to a sequence. We define a Pascal-like
infinite tetrahedron H, and prove that the application of the tetrahedron
trinomial transform to one face T of H provides the opposite edge E to T in H.
It follows from the construction that the other directions in H parallel to E
can be obtained similarly. In case of Pascal's triangle the sequence generated
by the trinomial transform coincides the binomial transform of the central
binomial coefficients.",2019-05-31T09:14:41Z,http://arxiv.org/pdf/1905.13475v1,"['math.CO', 'math.NT', '11B65, 11B75, 05A10']"
2108.02975v1,Biquaternion Z Transform,"['Wenshan Bi', 'Zhen-Feng Cai', 'Kit Ian Kou']","In this work, the biquaternion Z transformation method is proposed to solve a
class of biquaternion recurrence relations. Biqueternion Z transform is an
natural extension of the complex Z transform. In the design process, special
norm presentation is employed to analyze the region of convergence of the
biquaternion geometry sequence. In addition, some useful properties have been
given. It is shown that the proposed properties is helpful to understand the
biquaternion Z transform. Finally, several examples have been given to
illustrate the effectiveness of the proposed design method.",2021-08-06T07:00:34Z,http://arxiv.org/pdf/2108.02975v1,"['math.CA', 'math.CV']"
1511.08071v2,Catalytic coherence transformations,"['Kaifeng Bu', 'Uttam Singh', 'Junde Wu']","Catalytic coherence transformations allow the otherwise impossible state
transformations using only incoherent operations with the aid of an auxiliary
system with finite coherence which is not being consumed in anyway. Here we
find the necessary and sufficient conditions for the deterministic and
stochastic catalytic coherence transformations between pair of pure quantum
states. In particular, we show that the simultaneous decrease of a family of
R\'enyi entropies of the diagonal parts of the states under consideration are
necessary and sufficient conditions for the deterministic catalytic coherence
transformations. Similarly, for stochastic catalytic coherence transformations
we find the necessary and sufficient conditions for achieving higher optimal
probability of conversion. We, thus, completely characterize the coherence
transformations amongst pure quantum states under incoherent operations. We
give numerous examples to elaborate our results. We also explore the
possibility of the same system acting as a catalyst for itself and find that
indeed {\it self catalysis} is possible. Further, for the cases where no
catalytic coherence transformation is possible we provide entanglement assisted
coherence transformations and find the necessary and sufficient conditions for
such transformations.",2015-11-25T14:20:52Z,http://arxiv.org/pdf/1511.08071v2,['quant-ph']
2002.02337v1,The Generalized Crofoot Transform,['Rewayat Khan'],"We introduce a generalized Crofoot transform between the model spaces
corresponding to matrix-valued inner functions. As an application, we obtain
results about matrix-valued truncated Toeplitz operators.",2020-01-23T17:50:19Z,http://arxiv.org/pdf/2002.02337v1,"['math.FA', 'math.OA', '47B35, 47A45, 47B32, 30J05']"
2305.18487v1,Solar Irradiance Anticipative Transformer,"['Thomas M. Mercier', 'Tasmiat Rahman', 'Amin Sabet']","This paper proposes an anticipative transformer-based model for short-term
solar irradiance forecasting. Given a sequence of sky images, our proposed
vision transformer encodes features of consecutive images, feeding into a
transformer decoder to predict irradiance values associated with future unseen
sky images. We show that our model effectively learns to attend only to
relevant features in images in order to forecast irradiance. Moreover, the
proposed anticipative transformer captures long-range dependencies between sky
images to achieve a forecasting skill of 21.45 % on a 15 minute ahead
prediction for a newly introduced dataset of all-sky images when compared to a
smart persistence model.",2023-05-29T12:38:12Z,http://arxiv.org/pdf/2305.18487v1,"['cs.CV', 'cs.LG', 'physics.ao-ph']"
1806.08887v2,The Sparse Manifold Transform,"['Yubei Chen', 'Dylan M. Paiton', 'Bruno A. Olshausen']","We present a signal representation framework called the sparse manifold
transform that combines key ideas from sparse coding, manifold learning, and
slow feature analysis. It turns non-linear transformations in the primary
sensory signal space into linear interpolations in a representational embedding
space while maintaining approximate invertibility. The sparse manifold
transform is an unsupervised and generative framework that explicitly and
simultaneously models the sparse discreteness and low-dimensional manifold
structure found in natural scenes. When stacked, it also models hierarchical
composition. We provide a theoretical description of the transform and
demonstrate properties of the learned representation on both synthetic data and
natural videos.",2018-06-23T01:44:50Z,http://arxiv.org/pdf/1806.08887v2,"['stat.ML', 'cs.LG', 'eess.IV']"
2105.00493v2,Synthesizing Abstract Transformers,"['Pankaj Kumar Kalita', 'Sujit Kumar Muduli', ""Loris D'Antoni"", 'Thomas Reps', 'Subhajit Roy']","This paper addresses the problem of creating abstract transformers
automatically. The method we present automates the construction of static
analyzers in a fashion similar to the way $\textit{yacc}$ automates the
construction of parsers. Our method treats the problem as a program-synthesis
problem. The user provides specifications of (i) the concrete semantics of a
given operation $\textit{op}$, (ii) the abstract domain A to be used by the
analyzer, and (iii) the semantics of a domain-specific language $L$ in which
the abstract transformer is to be expressed. As output, our method creates an
abstract transformer for $\textit{op}$ in abstract domain A, expressed in $L$
(an ""$L$-transformer for $\textit{op}$ over A""). Moreover, the abstract
transformer obtained is a most-precise $L$-transformer for $\textit{op}$ over
A; that is, there is no other $L$-transformer for $\textit{op}$ over A that is
strictly more precise.
  We implemented our method in a tool called AMURTH. We used AMURTH to create
sets of replacement abstract transformers for those used in two existing
analyzers, and obtained essentially identical performance. However, when we
compared the existing transformers with the transformers obtained using AMURTH,
we discovered that four of the existing transformers were unsound, which
demonstrates the risk of using manually created transformers.",2021-05-02T15:09:41Z,http://arxiv.org/pdf/2105.00493v2,['cs.PL']
2106.04554v2,A Survey of Transformers,"['Tianyang Lin', 'Yuxin Wang', 'Xiangyang Liu', 'Xipeng Qiu']","Transformers have achieved great success in many artificial intelligence
fields, such as natural language processing, computer vision, and audio
processing. Therefore, it is natural to attract lots of interest from academic
and industry researchers. Up to the present, a great variety of Transformer
variants (a.k.a. X-formers) have been proposed, however, a systematic and
comprehensive literature review on these Transformer variants is still missing.
In this survey, we provide a comprehensive review of various X-formers. We
first briefly introduce the vanilla Transformer and then propose a new taxonomy
of X-formers. Next, we introduce the various X-formers from three perspectives:
architectural modification, pre-training, and applications. Finally, we outline
some potential directions for future research.",2021-06-08T17:43:08Z,http://arxiv.org/pdf/2106.04554v2,"['cs.LG', 'cs.AI', 'cs.CL']"
2112.04981v1,PE-former: Pose Estimation Transformer,"['Paschalis Panteleris', 'Antonis Argyros']","Vision transformer architectures have been demonstrated to work very
effectively for image classification tasks. Efforts to solve more challenging
vision tasks with transformers rely on convolutional backbones for feature
extraction. In this paper we investigate the use of a pure transformer
architecture (i.e., one with no CNN backbone) for the problem of 2D body pose
estimation. We evaluate two ViT architectures on the COCO dataset. We
demonstrate that using an encoder-decoder transformer architecture yields state
of the art results on this estimation problem.",2021-12-09T15:20:23Z,http://arxiv.org/pdf/2112.04981v1,"['cs.CV', 'cs.LG']"
2211.13184v1,TorchScale: Transformers at Scale,"['Shuming Ma', 'Hongyu Wang', 'Shaohan Huang', 'Wenhui Wang', 'Zewen Chi', 'Li Dong', 'Alon Benhaim', 'Barun Patra', 'Vishrav Chaudhary', 'Xia Song', 'Furu Wei']","Large Transformers have achieved state-of-the-art performance across many
tasks. Most open-source libraries on scaling Transformers focus on improving
training or inference with better parallelization. In this work, we present
TorchScale, an open-source toolkit that allows researchers and developers to
scale up Transformers efficiently and effectively. TorchScale has the
implementation of several modeling techniques, which can improve modeling
generality and capability, as well as training stability and efficiency.
Experimental results on language modeling and neural machine translation
demonstrate that TorchScale can successfully scale Transformers to different
sizes without tears. The library is available at https://aka.ms/torchscale.",2022-11-23T17:58:51Z,http://arxiv.org/pdf/2211.13184v1,"['cs.LG', 'cs.CL']"
2212.10554v1,A Length-Extrapolatable Transformer,"['Yutao Sun', 'Li Dong', 'Barun Patra', 'Shuming Ma', 'Shaohan Huang', 'Alon Benhaim', 'Vishrav Chaudhary', 'Xia Song', 'Furu Wei']","Position modeling plays a critical role in Transformers. In this paper, we
focus on length extrapolation, i.e., training on short texts while evaluating
longer sequences. We define attention resolution as an indicator of
extrapolation. Then we propose two designs to improve the above metric of
Transformers. Specifically, we introduce a relative position embedding to
explicitly maximize attention resolution. Moreover, we use blockwise causal
attention during inference for better resolution. We evaluate different
Transformer variants with language modeling. Experimental results show that our
model achieves strong performance in both interpolation and extrapolation
settings. The code will be available at https://aka.ms/LeX-Transformer.",2022-12-20T18:56:20Z,http://arxiv.org/pdf/2212.10554v1,['cs.CL']
2311.07373v2,Optical Darboux Transformer,['Auro M. Perego'],"The Optical Darboux Transformer is introduced as a photonic device which
performs the Darboux transformation directly in the optical domain. This
enables two major advances for signal processing based on the nonlinear Fourier
transform: (i) the multiplexing of different solitonic waveforms corresponding
to arbitrary number of discrete eigenvalues of the Zakharov-Shabat system in
the optical domain, and (ii) the selective filtering of an arbitrary number of
individual solitons too. The Optical Darboux Transformer can be built using
existing commercially available photonic technology components and constitutes
a universal tool for signal processing, optical communications, optical rogue
waves generation, and waveform shaping and control in the nonlinear Fourier
domain.",2023-11-13T14:42:27Z,http://arxiv.org/pdf/2311.07373v2,"['nlin.PS', 'physics.optics']"
2311.16925v1,Multiallelic Walsh transforms,['Devin Greene'],"A closed formula multiallelic Walsh (or Hadamard) transform is introduced.
Basic results are derived, and a statistical interpretation of some of the
resulting linear forms is discussed.",2023-11-28T16:30:58Z,http://arxiv.org/pdf/2311.16925v1,"['q-bio.QM', 'q-bio.PE']"
2405.06188v2,Multidimensional empirical wavelet transform,"['Charles-Gérard Lucas', 'Jérôme Gilles']","The empirical wavelet transform is a data-driven time-scale representation
consisting of an adaptive filter bank. Its robustness to data has made it the
subject of intense developments and an increasing number of applications in the
last decade. However, it has been mostly studied theoretically for signals and
its extension to images is limited to a particular generating function. This
work presents a general framework for multidimensional empirical wavelet
transform based on any wavelet kernel. It also provides conditions to build
wavelet frames for both continuous and discrete transforms. Moreover, numerical
simulations of transforms are given.",2024-05-10T02:06:34Z,http://arxiv.org/pdf/2405.06188v2,"['eess.IV', '42C15, 42C40, 68U10']"
2406.08443v2,Transform-Dependent Adversarial Attacks,"['Yaoteng Tan', 'Zikui Cai', 'M. Salman Asif']","Deep networks are highly vulnerable to adversarial attacks, yet conventional
attack methods utilize static adversarial perturbations that induce fixed
mispredictions. In this work, we exploit an overlooked property of adversarial
perturbations--their dependence on image transforms--and introduce
transform-dependent adversarial attacks. Unlike traditional attacks, our
perturbations exhibit metamorphic properties, enabling diverse adversarial
effects as a function of transformation parameters. We demonstrate that this
transform-dependent vulnerability exists across different architectures (e.g.,
CNN and transformer), vision tasks (e.g., image classification and object
detection), and a wide range of image transforms. Additionally, we show that
transform-dependent perturbations can serve as a defense mechanism, preventing
sensitive information disclosure when image enhancement transforms pose a risk
of revealing private content. Through analysis in blackbox and defended model
settings, we show that transform-dependent perturbations achieve high targeted
attack success rates, outperforming state-of-the-art transfer attacks by 17-31%
in blackbox scenarios. Our work introduces novel, controllable paradigm for
adversarial attack deployment, revealing a previously overlooked vulnerability
in deep networks.",2024-06-12T17:31:36Z,http://arxiv.org/pdf/2406.08443v2,"['cs.CV', 'cs.LG']"
2507.10739v1,Quantum Wave Atom Transforms,"['Marianna Podzorova', 'Yi-Kai Liu']","This paper constructs the first quantum algorithm for wavelet packet
transforms with a tree structure, sometimes called wave atom transforms.
Classically, wave atoms are used to construct sparse representations of
differential operators, which enable fast numerical algorithms for partial
differential equations. Compared to previous work, our quantum algorithm can
implement a larger class of wavelet and wave atom transforms, by using an
efficient representation for a larger class of possible tree structures. Our
quantum implementation has $O(\mathrm{poly}(n))$ gate complexity for the
transform of dimension $2^n$, while classical implementations have $O(n 2^n)$
floating point operations. The result can be used to improve existing quantum
algorithms for solving hyperbolic partial differential equations.",2025-07-14T19:03:22Z,http://arxiv.org/pdf/2507.10739v1,"['quant-ph', 'cs.NA', 'math.NA']"
1306.2024v2,The ridgelet transform of distributions,"['Sanja Kostadinova', 'Stevan Pilipovic', 'Katerina Saneva', 'Jasson Vindas']","We define and study the ridgelet transform of (Lizorkin) distributions. We
establish connections with the Radon and wavelet transforms.",2013-06-09T14:45:15Z,http://arxiv.org/pdf/1306.2024v2,"['math.FA', 'math.CA', 'Primary 44A15, 46F12. Secondary 42C20, 44A12, 44A35']"
1705.07298v1,The Integral Transform of N.I.Akhiezer,['Victor Katsnelson'],"We study the integral transform which appeared in a different form in
Akhiezer's textbook ""Lectures on Integral Transforms"".",2017-05-20T12:53:12Z,http://arxiv.org/pdf/1705.07298v1,"['math.CA', '44A15, 44A35']"
2302.01128v3,Mnemosyne: Learning to Train Transformers with Transformers,"['Deepali Jain', 'Krzysztof Marcin Choromanski', 'Avinava Dubey', 'Sumeet Singh', 'Vikas Sindhwani', 'Tingnan Zhang', 'Jie Tan']","In this work, we propose a new class of learnable optimizers, called
\textit{Mnemosyne}. It is based on the novel spatio-temporal low-rank implicit
attention Transformers that can learn to train entire neural network
architectures, including other Transformers, without any task-specific
optimizer tuning. We show that Mnemosyne: (a) outperforms popular LSTM
optimizers (also with new feature engineering to mitigate catastrophic
forgetting of LSTMs), (b) can successfully train Transformers while using
simple meta-training strategies that require minimal computational resources,
(c) matches accuracy-wise SOTA hand-designed optimizers with carefully tuned
hyper-parameters (often producing top performing models). Furthermore,
Mnemosyne provides space complexity comparable to that of its hand-designed
first-order counterparts, which allows it to scale to training larger sets of
parameters. We conduct an extensive empirical evaluation of Mnemosyne on: (a)
fine-tuning a wide range of Vision Transformers (ViTs) from medium-size
architectures to massive ViT-Hs (36 layers, 16 heads), (b) pre-training BERT
models and (c) soft prompt-tuning large 11B+ T5XXL models. We complement our
results with a comprehensive theoretical analysis of the compact associative
memory used by Mnemosyne which we believe was never done before.",2023-02-02T14:40:28Z,http://arxiv.org/pdf/2302.01128v3,"['cs.LG', 'cs.AI']"
2506.17671v2,TPTT: Transforming Pretrained Transformers into Titans,['Fabien Furfaro'],"Transformer-based large language models (LLMs) have achieved strong
performance across many natural language processing tasks. Nonetheless, their
quadratic computational and memory requirements, particularly in self-attention
layers, pose challenges for efficient inference on long contexts and for
deployment in resource-limited environments. We present TPTT (Transforming
Pretrained Transformers into Titans), a framework designed to augment
pretrained Transformers with linearized attention (LiZA) and internal memory
gating via Memory as Gate (MaG), applied without full retraining. TPTT supports
parameter-efficient fine-tuning (LoRA) and integrates with standard toolkits
such as Hugging Face Transformers. We evaluated TPTT on several pretrained
models, including Llama-1B, OlMoE-1B-7B, Qwen2.5-1.5B, Gemma3-270m,
OpenELM-1.3B, and Mistral-7B, in order to assess applicability across
architectures of different scales. Experiments on models with approximately 1
billion parameters, evaluated primarily on the MMLU benchmark, suggest
potential improvements in both efficiency and accuracy compared to baseline
models. For example, Titans-Llama-1B exhibited up to a 20\% relative increase
in Exact Match scores in one-shot evaluation. An additional finding is that it
is possible to convert a quadratic-attention model into a purely
linear-attention model using the DeltaProduct mechanism. All training runs were
carried out with modest computational resources. These preliminary findings
indicate that TPTT may help adapt pretrained LLMs for long-context tasks with
limited overhead. Further studies on larger models and a broader set of
benchmarks will be necessary to evaluate the generality and robustness of the
framework. Code is available at https://github.com/fabienfrfr/tptt . Python
package at https://pypi.org/project/tptt/ .",2025-06-21T10:06:07Z,http://arxiv.org/pdf/2506.17671v2,"['cs.CL', 'cs.AI', 'cs.LG']"
0603578v1,Fast complexified quaternion Fourier transform,"['Salem Said', 'Nicolas Le Bihan', 'Stephen J. Sangwine']","A discrete complexified quaternion Fourier transform is introduced. This is a
generalization of the discrete quaternion Fourier transform to the case where
either or both of the signal/image and the transform kernel are complex
quaternion-valued. It is shown how to compute the transform using four standard
complex Fourier transforms and the properties of the transform are briefly
discussed.",2006-03-24T15:30:14Z,http://arxiv.org/pdf/math/0603578v1,"['math.NA', 'math.FA', '65T50']"
0508104v1,A Generalised Hadamard Transform,['K. J. Horadam'],"A Generalised Hadamard Transform for multi-phase or multilevel signals is
introduced, which includes the Fourier, Generalised, Discrete Fourier,
Walsh-Hadamard and Reverse Jacket Transforms. The jacket construction is
formalised and shown to admit a tensor product decomposition. Primary matrices
under this decomposition are identified. New examples of primary jacket
matrices of orders 8 and 12 are presented.",2005-08-24T01:03:34Z,http://arxiv.org/pdf/cs/0508104v1,"['cs.IT', 'cs.DM', 'math.IT']"
9602019v1,Two Different Squeeze Transformations,"['D. Han', 'Y. S. Kim']","Lorentz boosts are squeeze transformations. While these transformations are
similar to those in squeezed states of light, they are fundamentally different
from both physical and mathematical points of view. The difference is
illustrated in terms of two coupled harmonic oscillators, and in terms of the
covariant harmonic oscillator formalism.",1996-02-05T15:28:54Z,http://arxiv.org/pdf/hep-th/9602019v1,['hep-th']
9901009v1,Fourier transform for D-algebras,"['Alexander Polishchuk', 'Mitchell Rothstein']","We construct a version of Fourier transform for a class of non-commutative
algebras over abelian varieties which include algebras of twisted differential
operators generalizing the previous construction of Laumon (alg-geom/9603004)
and of the second author (alg-geom/9602023). We also construct the microlocal
version of this transform and its etale localization in the framework of
Kapranov's theory of NC-schemes (see math.AG/9802041).",1999-01-04T21:45:13Z,http://arxiv.org/pdf/math/9901009v1,['math.AG']
0212199v1,The amplitude modulation transform,['Igor Rivin'],"Motivated by the study of the local extrema of sin(x)/x we define the
\emph{Amplitude Modulation} transform of functions defined on (subsets of) the
real line. We discuss certain properties of this transform and invert it in
some easy cases.",2002-12-15T23:56:50Z,http://arxiv.org/pdf/math/0212199v1,"['math.CA', '26A09; 14Q99']"
0404082v2,Transformations of Grassman Spaces,['Mark Pankov'],"This is a version of a part of the book ``Transformations of Grassman
Spaces'' (in progress). We study transformations of Grassman spaces preserving
certain geometrical constructions related to buildings. The next part will be
devoted to Grassman spaces associated with polar spaces.",2004-04-05T13:44:28Z,http://arxiv.org/pdf/math/0404082v2,"['math.GM', 'math.MG', '20B99']"
0507132v3,Laplace transformation updated,['Ernst Terhardt'],"The traditional theory of Laplace transformation in its currently prevalent
form is unsatisfactory. Its deficiencies can be traced back to a mismatch of
the definition intervals of the original function and of the inverse
L-transform. A new approach is outlined by which Laplace transformation becomes
liberated from its inconsistencies.",2005-07-07T05:40:06Z,http://arxiv.org/pdf/math/0507132v3,"['math.HO', '44A10']"
9905024v1,Octonionic Mobius Transformations,"['Corinne A. Manogue', 'Tevian Dray']","A vexing problem involving nonassociativity is resolved, allowing a
generalization of the usual complex Mobius transformations to the octonions.
This is accomplished by relating the octonionic Mobius transformations to the
Lorentz group in 10 spacetime dimensions. The result will be of particular
interest to physicists working with lightlike objects in 10 dimensions.",1999-05-27T16:51:12Z,http://arxiv.org/pdf/math-ph/9905024v1,"['math-ph', 'hep-th', 'math.MP', 'math.RA', '17A35']"
9607029v1,Gauge transformations and quasitriangularity,['S. Zakrzewski'],"Natural conditions on a Poisson/quantum group G to implement Poisson/quantum
gauge transformations on the lattice are investigated. In addition to our
previous result that transformations on one lattice link require G to be
coboundary, it is shown that for a sequence of links one needs a
quasitriangular G.",1996-07-29T12:09:06Z,http://arxiv.org/pdf/q-alg/9607029v1,"['q-alg', 'math.QA']"
1305.5224v3,Generalized Lorentz Transformations,['Virendra Gupta'],"Generalized Lorentz transformations with modified velocity parameter are
considered. Lorentz transformations depending on the mass of the observer are
suggested.The modified formula for the addition of velocities remarkably
preserves the constancy of the velocity of light for all observers. The Doppler
red shift is affected and can provide a test of such generalisations.",2013-05-22T18:36:40Z,http://arxiv.org/pdf/1305.5224v3,['physics.gen-ph']
1403.0274v4,Enumerating Transformation Semigroups,"['James East', 'Attila Egri-Nagy', 'James D. Mitchell']","We describe general methods for enumerating subsemigroups of finite
semigroups and techniques to improve the algorithmic efficiency of the
calculations. As a particular application we use our algorithms to enumerate
all transformation semigroups up to degree 4. Classification of these
semigroups up to conjugacy, isomorphism and anti-isomorphism, by size and rank,
provides a solid base for further investigations of transformation semigroups.",2014-03-02T22:40:31Z,http://arxiv.org/pdf/1403.0274v4,"['math.GR', '20M20']"
2207.09238v1,Formal Algorithms for Transformers,"['Mary Phuong', 'Marcus Hutter']","This document aims to be a self-contained, mathematically precise overview of
transformer architectures and algorithms (*not* results). It covers what
transformers are, how they are trained, what they are used for, their key
architectural components, and a preview of the most prominent models. The
reader is assumed to be familiar with basic ML terminology and simpler neural
network architectures such as MLPs.",2022-07-19T12:49:02Z,http://arxiv.org/pdf/2207.09238v1,"['cs.LG', 'cs.AI', 'cs.CL', 'cs.NE']"
1211.3285v2,Cramér transform and t-entropy,"['Urszula Ostaszewska', 'Krzysztof Zajkowski']","t-entropy is the convex conjugate of the logarithm of the spectral radius of
a weighted composition operator (WCO). Let $X$ be a nonnegative random
variable. We show how the Cram\'er transform with respect to the spectral
radius of WCO is expressed by the t-entropy and the Cram\'er transform of the
given random variable X.",2012-11-14T12:06:25Z,http://arxiv.org/pdf/1211.3285v2,"['math.PR', 'math.FA', '44A15, 47A10, 47B37, 60F99']"
1701.00544v1,Binomial transform of products,['Khristo N. Boyadzhiev'],"Given two infinite sequences with known binomial transforms, we compute the
binomial transform of the product sequence. Various identities are obtained and
numerous examples are given involving sequences of special numbers: Harmonic
numbers, Bernoulli numbers, Fibonacci numbers, and also Laguerre polynomials.",2017-01-02T22:15:49Z,http://arxiv.org/pdf/1701.00544v1,"['math.NT', '11B65, 05A10, 33C45, 40A99']"
2305.03232v2,Neuromodulation Gated Transformer,"['Kobe Knowles', 'Joshua Bensemann', 'Diana Benavides-Prado', 'Vithya Yogarajan', 'Michael Witbrock', 'Gillian Dobbie', 'Yang Chen']","We introduce a novel architecture, the Neuromodulation Gated Transformer
(NGT), which is a simple implementation of neuromodulation in transformers via
a multiplicative effect. We compare it to baselines and show that it results in
the best average performance on the SuperGLUE benchmark validation sets.",2023-05-05T01:23:22Z,http://arxiv.org/pdf/2305.03232v2,['cs.CL']
1901.11117v4,The Evolved Transformer,"['David R. So', 'Chen Liang', 'Quoc V. Le']","Recent works have highlighted the strength of the Transformer architecture on
sequence tasks while, at the same time, neural architecture search (NAS) has
begun to outperform human-designed models. Our goal is to apply NAS to search
for a better alternative to the Transformer. We first construct a large search
space inspired by the recent advances in feed-forward sequence models and then
run evolutionary architecture search with warm starting by seeding our initial
population with the Transformer. To directly search on the computationally
expensive WMT 2014 English-German translation task, we develop the Progressive
Dynamic Hurdles method, which allows us to dynamically allocate more resources
to more promising candidate models. The architecture found in our experiments
-- the Evolved Transformer -- demonstrates consistent improvement over the
Transformer on four well-established language tasks: WMT 2014 English-German,
WMT 2014 English-French, WMT 2014 English-Czech and LM1B. At a big model size,
the Evolved Transformer establishes a new state-of-the-art BLEU score of 29.8
on WMT'14 English-German; at smaller sizes, it achieves the same quality as the
original ""big"" Transformer with 37.6% less parameters and outperforms the
Transformer by 0.7 BLEU at a mobile-friendly model size of 7M parameters.",2019-01-30T22:03:01Z,http://arxiv.org/pdf/1901.11117v4,"['cs.LG', 'cs.CL', 'cs.NE', 'stat.ML']"
2003.05031v3,Transformations of Hypergeometric Motives,"['J. William Hoffman', 'Fang-Ting Tu']","We consider algebraic transformations of hypergeometric functions from a
geometric point of view. Hypergeometric functions are shown to arise from the
deRham realization of a hypergeometric motive. The $\ell$-adic realization of
the motive gives rise to hypergeometric characters sums over finite fields.
This helps to unify and explain some recent results about transformations of
hypergeometric character sums.",2020-03-10T23:16:58Z,http://arxiv.org/pdf/2003.05031v3,['math.NT']
2012.06963v1,The Arithmetic Fourier Transform,['Joel L. Schiff'],"The Arithmetic Fourier Transform is a numerical formulation for computing
Fourier series and Taylor series coefficients. It competes with the Fast
Fourier Transform in terms of speed and efficiency, requiring only addition
operations and can be performed by parallel processing. The AFT has some deep
connections with the Prime Number Theorem and its rich history is discussed in
this expository article.",2020-12-13T05:20:12Z,http://arxiv.org/pdf/2012.06963v1,"['math.CV', 'math.NT', '42A16, 11A25, 30J99']"
2307.01694v1,Spike-driven Transformer,"['Man Yao', 'Jiakui Hu', 'Zhaokun Zhou', 'Li Yuan', 'Yonghong Tian', 'Bo Xu', 'Guoqi Li']","Spiking Neural Networks (SNNs) provide an energy-efficient deep learning
option due to their unique spike-based event-driven (i.e., spike-driven)
paradigm. In this paper, we incorporate the spike-driven paradigm into
Transformer by the proposed Spike-driven Transformer with four unique
properties: 1) Event-driven, no calculation is triggered when the input of
Transformer is zero; 2) Binary spike communication, all matrix multiplications
associated with the spike matrix can be transformed into sparse additions; 3)
Self-attention with linear complexity at both token and channel dimensions; 4)
The operations between spike-form Query, Key, and Value are mask and addition.
Together, there are only sparse addition operations in the Spike-driven
Transformer. To this end, we design a novel Spike-Driven Self-Attention (SDSA),
which exploits only mask and addition operations without any multiplication,
and thus having up to $87.2\times$ lower computation energy than vanilla
self-attention. Especially in SDSA, the matrix multiplication between Query,
Key, and Value is designed as the mask operation. In addition, we rearrange all
residual connections in the vanilla Transformer before the activation functions
to ensure that all neurons transmit binary spike signals. It is shown that the
Spike-driven Transformer can achieve 77.1\% top-1 accuracy on ImageNet-1K,
which is the state-of-the-art result in the SNN field. The source code is
available at https://github.com/BICLab/Spike-Driven-Transformer.",2023-07-04T13:00:18Z,http://arxiv.org/pdf/2307.01694v1,"['cs.NE', 'cs.CV']"
2307.07843v1,Transformers are Universal Predictors,"['Sourya Basu', 'Moulik Choraria', 'Lav R. Varshney']","We find limits to the Transformer architecture for language modeling and show
it has a universal prediction property in an information-theoretic sense. We
further analyze performance in non-asymptotic data regimes to understand the
role of various components of the Transformer architecture, especially in the
context of data-efficient training. We validate our theoretical analysis with
experiments on both synthetic and real datasets.",2023-07-15T16:19:37Z,http://arxiv.org/pdf/2307.07843v1,"['cs.LG', 'cs.CL']"
2411.19659v2,Ruijsenaars spectral transform,"['N. Belousov', 'S. Khoroshkin']","Spectral decomposition with respect to the wave functions of Ruijsenaars
hyperbolic system defines an integral transform, which generalizes classical
Fourier integral. For a certain class of analytical symmetric functions we
prove inversion formula and orthogonality relations, valid for complex valued
parameters of the system. Besides, we study four regimes of unitarity, when
this transform defines isomorphisms of the corresponding $L_2$ spaces.",2024-11-29T12:32:48Z,http://arxiv.org/pdf/2411.19659v2,"['math-ph', 'hep-th', 'math.CA', 'math.MP', 'nlin.SI']"
9712017v2,Transformations of Quadrilateral Lattices,"['A. Doliwa', 'P. M. Santini', 'M. Manas']","Motivated by the classical studies on transformations of conjugate nets, we
develop the general geometric theory of transformations of their discrete
analogues: the multidimensional quadrilateral lattices, i.e. lattices x: Z^N ->
R^M, whose elementary quadrilaterals are planar. Our investigation is based on
the discrete analogue of the theory of the rectilinear congruences, which we
also present in detail. We study, in particular, the discrete analogues of the
Laplace, Combescure, Levy, radial and fundamental transformations and their
interrelations. The composition of these transformations and their
permutability is also investigated from a geometric point of view. The deep
connections between ""transformations"" and ""discretizations"" is also
investigated for quadrilateral lattices. We finally interpret these results
within the D-bar formalism.",1997-12-20T11:02:51Z,http://arxiv.org/pdf/solv-int/9712017v2,"['solv-int', 'nlin.SI']"
1202.1773v2,Fast Finite Shearlet Transform,"['S. Häuser', 'G. Steidl']","In recent years it has turned out that shearlets have the potential to
retrieve directional information so that they became interesting for many
applications. Moreover the continuous shearlet transform has the outstanding
property to stem from a square integrable group representation. However, to use
shearlets and the shearlet transform for reasonable applications one needs fast
algorithms to compute a discrete shearlet transform. In this tutorial we
present the steps towards an implementation of a fast and finite shearlet
transform that is only based on the FFT. Using band-limited shearlets we
construct a Parseval frame that provides a simple and straightforward inverse
shearlet transform. We provide all proofs and discuss several aspects of our
implementation.",2012-02-08T17:24:00Z,http://arxiv.org/pdf/1202.1773v2,['math.NA']
1406.0190v1,Amplified Quantum Transforms,['David Cornwell'],"In this thesis we investigate two new Amplified Quantum Transforms. In
particular we create and analyze the Amplified Quantum Fourier Transform
(Amplified-QFT) and the Amplified-Haar Wavelet Transform. First, we provide a
brief history of quantum mechanics and quantum computing. Second, we examine
the Amplified-QFT in detail and compare it against the Quantum Fourier
Transform (QFT) and Quantum Hidden Subgroup (QHS) algorithms for solving the
Local Period Problem. We calculate the probabilities of success of each
algorithm and show the Amplified-QFT is quadratically faster than the QFT and
QHS algorithms. Third, we examine the Amplified-QFT algorithm for solving The
Local Period Problem with an Error Stream. Fourth, we produce an uncertainty
relation for the Amplified-QFT algorithm. Fifth, we show how the Amplified-Haar
Wavelet Transform can solve the Local Constant or Balanced Signal Decision
Problem which is a generalization of the Deutsch-Jozsa algorithm.",2014-06-01T18:13:25Z,http://arxiv.org/pdf/1406.0190v1,['quant-ph']
1508.06749v4,Most Likely Transformations,"['Torsten Hothorn', 'Lisa Möst', 'Peter Bühlmann']","We propose and study properties of maximum likelihood estimators in the class
of conditional transformation models. Based on a suitable explicit
parameterisation of the unconditional or conditional transformation function,
we establish a cascade of increasingly complex transformation models that can
be estimated, compared and analysed in the maximum likelihood framework. Models
for the unconditional or conditional distribution function of any univariate
response variable can be set-up and estimated in the same theoretical and
computational framework simply by choosing an appropriate transformation
function and parameterisation thereof. The ability to evaluate the distribution
function directly allows us to estimate models based on the exact likelihood,
especially in the presence of random censoring or truncation. For discrete and
continuous responses, we establish the asymptotic normality of the proposed
estimators. A reference software implementation of maximum likelihood-based
estimation for conditional transformation models allowing the same flexibility
as the theory developed here was employed to illustrate the wide range of
possible applications.",2015-08-27T08:26:51Z,http://arxiv.org/pdf/1508.06749v4,['stat.ME']
2104.08500v4,Vision Transformer Pruning,"['Mingjian Zhu', 'Yehui Tang', 'Kai Han']","Vision transformer has achieved competitive performance on a variety of
computer vision applications. However, their storage, run-time memory, and
computational demands are hindering the deployment to mobile devices. Here we
present a vision transformer pruning approach, which identifies the impacts of
dimensions in each layer of transformer and then executes pruning accordingly.
By encouraging dimension-wise sparsity in the transformer, important dimensions
automatically emerge. A great number of dimensions with small importance scores
can be discarded to achieve a high pruning ratio without significantly
compromising accuracy. The pipeline for vision transformer pruning is as
follows: 1) training with sparsity regularization; 2) pruning dimensions of
linear projections; 3) fine-tuning. The reduced parameters and FLOPs ratios of
the proposed algorithm are well evaluated and analyzed on ImageNet dataset to
demonstrate the effectiveness of our proposed method.",2021-04-17T09:49:24Z,http://arxiv.org/pdf/2104.08500v4,['cs.CV']
2104.11227v1,Multiscale Vision Transformers,"['Haoqi Fan', 'Bo Xiong', 'Karttikeya Mangalam', 'Yanghao Li', 'Zhicheng Yan', 'Jitendra Malik', 'Christoph Feichtenhofer']","We present Multiscale Vision Transformers (MViT) for video and image
recognition, by connecting the seminal idea of multiscale feature hierarchies
with transformer models. Multiscale Transformers have several
channel-resolution scale stages. Starting from the input resolution and a small
channel dimension, the stages hierarchically expand the channel capacity while
reducing the spatial resolution. This creates a multiscale pyramid of features
with early layers operating at high spatial resolution to model simple
low-level visual information, and deeper layers at spatially coarse, but
complex, high-dimensional features. We evaluate this fundamental architectural
prior for modeling the dense nature of visual signals for a variety of video
recognition tasks where it outperforms concurrent vision transformers that rely
on large scale external pre-training and are 5-10x more costly in computation
and parameters. We further remove the temporal dimension and apply our model
for image classification where it outperforms prior work on vision
transformers. Code is available at:
https://github.com/facebookresearch/SlowFast",2021-04-22T17:59:45Z,http://arxiv.org/pdf/2104.11227v1,"['cs.CV', 'cs.AI', 'cs.LG']"
2402.09269v2,Personalized Large Language Models,"['Stanisław Woźniak', 'Bartłomiej Koptyra', 'Arkadiusz Janz', 'Przemysław Kazienko', 'Jan Kocoń']","Large language models (LLMs) have significantly advanced Natural Language
Processing (NLP) tasks in recent years. However, their universal nature poses
limitations in scenarios requiring personalized responses, such as
recommendation systems and chatbots. This paper investigates methods to
personalize LLMs, comparing fine-tuning and zero-shot reasoning approaches on
subjective tasks. Results demonstrate that personalized fine-tuning improves
model reasoning compared to non-personalized models. Experiments on datasets
for emotion recognition and hate speech detection show consistent performance
gains with personalized methods across different LLM architectures. These
findings underscore the importance of personalization for enhancing LLM
capabilities in subjective text perception tasks.",2024-02-14T15:55:30Z,http://arxiv.org/pdf/2402.09269v2,"['cs.CL', 'cs.AI']"
2509.05757v1,Hyperbolic Large Language Models,"['Sarang Patil', 'Zeyong Zhang', 'Yiran Huang', 'Tengfei Ma', 'Mengjia Xu']","Large language models (LLMs) have achieved remarkable success and
demonstrated superior performance across various tasks, including natural
language processing (NLP), weather forecasting, biological protein folding,
text generation, and solving mathematical problems. However, many real-world
data exhibit highly non-Euclidean latent hierarchical anatomy, such as protein
networks, transportation networks, financial networks, brain networks, and
linguistic structures or syntactic trees in natural languages. Effectively
learning intrinsic semantic entailment and hierarchical relationships from
these raw, unstructured input data using LLMs remains an underexplored area.
Due to its effectiveness in modeling tree-like hierarchical structures,
hyperbolic geometry -- a non-Euclidean space -- has rapidly gained popularity
as an expressive latent representation space for complex data modeling across
domains such as graphs, images, languages, and multi-modal data. Here, we
provide a comprehensive and contextual exposition of recent advancements in
LLMs that leverage hyperbolic geometry as a representation space to enhance
semantic representation learning and multi-scale reasoning. Specifically, the
paper presents a taxonomy of the principal techniques of Hyperbolic LLMs
(HypLLMs) in terms of four main categories: (1) hyperbolic LLMs through exp/log
maps; (2) hyperbolic fine-tuned models; (3) fully hyperbolic LLMs, and (4)
hyperbolic state-space models. We also explore crucial potential applications
and outline future research directions. A repository of key papers, models,
datasets, and code implementations is available at
https://github.com/sarangp2402/Hyperbolic-LLM-Models/tree/main.",2025-09-06T15:56:46Z,http://arxiv.org/pdf/2509.05757v1,['cs.AI']
2305.05364v1,Large Language Model Programs,"['Imanol Schlag', 'Sainbayar Sukhbaatar', 'Asli Celikyilmaz', 'Wen-tau Yih', 'Jason Weston', 'Jürgen Schmidhuber', 'Xian Li']","In recent years, large pre-trained language models (LLMs) have demonstrated
the ability to follow instructions and perform novel tasks from a few examples.
The possibility to parameterise an LLM through such in-context examples widens
their capability at a much lower cost than finetuning. We extend this line of
reasoning and present a method which further expands the capabilities of an LLM
by embedding it within an algorithm or program. To demonstrate the benefits of
this approach, we present an illustrative example of evidence-supported
question-answering. We obtain a 6.4\% improvement over the chain of thought
baseline through a more algorithmic approach without any finetuning.
Furthermore, we highlight recent work from this perspective and discuss the
advantages and disadvantages in comparison to the standard approaches.",2023-05-09T11:55:36Z,http://arxiv.org/pdf/2305.05364v1,"['cs.LG', 'cs.AI', 'cs.CL']"
2307.05782v2,Large Language Models,['Michael R. Douglas'],"Artificial intelligence is making spectacular progress, and one of the best
examples is the development of large language models (LLMs) such as OpenAI's
GPT series. In these lectures, written for readers with a background in
mathematics or physics, we give a brief history and survey of the state of the
art, and describe the underlying transformer architecture in detail. We then
explore some current ideas on how LLMs work and how models trained to predict
the next word in a text are able to perform other tasks displaying
intelligence.",2023-07-11T20:21:02Z,http://arxiv.org/pdf/2307.05782v2,"['cs.CL', 'hep-th', 'math.HO', 'physics.comp-ph', '68T01', 'I.2.7']"
2310.10683v2,Large Language Model Unlearning,"['Yuanshun Yao', 'Xiaojun Xu', 'Yang Liu']","We study how to perform unlearning, i.e. forgetting undesirable misbehaviors,
on large language models (LLMs). We show at least three scenarios of aligning
LLMs with human preferences can benefit from unlearning: (1) removing harmful
responses, (2) erasing copyright-protected content as requested, and (3)
reducing hallucinations. Unlearning, as an alignment technique, has three
advantages. (1) It only requires negative (e.g. harmful) examples, which are
much easier and cheaper to collect (e.g. via red teaming or user reporting)
than positive (e.g. helpful and often human-written) examples required in RLHF
(RL from human feedback). (2) It is computationally efficient. (3) It is
especially effective when we know which training samples cause the misbehavior.
To the best of our knowledge, our work is among the first to explore LLM
unlearning. We are also among the first to formulate the settings, goals, and
evaluations in LLM unlearning. We show that if practitioners only have limited
resources, and therefore the priority is to stop generating undesirable outputs
rather than to try to generate desirable outputs, unlearning is particularly
appealing. Despite only having negative samples, our ablation study shows that
unlearning can still achieve better alignment performance than RLHF with just
2% of its computational time.",2023-10-14T00:32:55Z,http://arxiv.org/pdf/2310.10683v2,"['cs.CL', 'cs.AI', 'cs.LG']"
2406.00030v1,Large Language Model Pruning,"['Hanjuan Huang', 'Hao-Jia Song', 'Hsing-Kuo Pao']","We surely enjoy the larger the better models for their superior performance
in the last couple of years when both the hardware and software support the
birth of such extremely huge models. The applied fields include text mining and
others. In particular, the success of LLMs on text understanding and text
generation draws attention from researchers who have worked on NLP and related
areas for years or even decades. On the side, LLMs may suffer from problems
like model overfitting, hallucination, and device limitation to name a few. In
this work, we suggest a model pruning technique specifically focused on LLMs.
The proposed methodology emphasizes the explainability of deep learning models.
By having the theoretical foundation, we obtain a trustworthy deep model so
that huge models with a massive number of model parameters become not quite
necessary. A mutual information-based estimation is adopted to find neurons
with redundancy to eliminate. Moreover, an estimator with well-tuned parameters
helps to find precise estimation to guide the pruning procedure. At the same
time, we also explore the difference between pruning on large-scale models vs.
pruning on small-scale models. The choice of pruning criteria is sensitive in
small models but not for large-scale models. It is a novel finding through this
work. Overall, we demonstrate the superiority of the proposed model to the
state-of-the-art models.",2024-05-24T18:22:15Z,http://arxiv.org/pdf/2406.00030v1,"['cs.CL', 'cs.AI', 'cs.LG']"
2405.06640v1,Linearizing Large Language Models,"['Jean Mercat', 'Igor Vasiljevic', 'Sedrick Keh', 'Kushal Arora', 'Achal Dave', 'Adrien Gaidon', 'Thomas Kollar']","Linear transformers have emerged as a subquadratic-time alternative to
softmax attention and have garnered significant interest due to their
fixed-size recurrent state that lowers inference cost. However, their original
formulation suffers from poor scaling and underperforms compute-matched
transformers. Recent linear models such as RWKV and Mamba have attempted to
address these shortcomings by proposing novel time-mixing and gating
architectures, but pre-training large language models requires significant data
and compute investments. Thus, the search for subquadratic architectures is
limited by the availability of compute and quality pre-training datasets. As a
cost-effective alternative to pre-training linear transformers, we propose
Scalable UPtraining for Recurrent Attention (SUPRA). We present a method to
uptrain existing large pre-trained transformers into Recurrent Neural Networks
(RNNs) with a modest compute budget. This allows us to leverage the strong
pre-training data and performance of existing transformer LLMs, while requiring
5% of the training cost. We find that our linearization technique leads to
competitive performance on standard benchmarks, but we identify persistent
in-context learning and long-context modeling shortfalls for even the largest
linear models. Our code and models can be found at
https://github.com/TRI-ML/linear_open_lm.",2024-05-10T17:59:08Z,http://arxiv.org/pdf/2405.06640v1,['cs.CL']
2412.07992v4,Concept Bottleneck Large Language Models,"['Chung-En Sun', 'Tuomas Oikarinen', 'Berk Ustun', 'Tsui-Wei Weng']","We introduce Concept Bottleneck Large Language Models (CB-LLMs), a novel
framework for building inherently interpretable Large Language Models (LLMs).
In contrast to traditional black-box LLMs that rely on limited post-hoc
interpretations, CB-LLMs integrate intrinsic interpretability directly into the
LLMs -- allowing accurate explanations with scalability and transparency. We
build CB-LLMs for two essential NLP tasks: text classification and text
generation. In text classification, CB-LLMs is competitive with, and at times
outperforms, traditional black-box models while providing explicit and
interpretable reasoning. For the more challenging task of text generation,
interpretable neurons in CB-LLMs enable precise concept detection, controlled
generation, and safer outputs. The embedded interpretability empowers users to
transparently identify harmful content, steer model behavior, and unlearn
undesired concepts -- significantly enhancing the safety, reliability, and
trustworthiness of LLMs, which are critical capabilities notably absent in
existing models. Our code is available at
https://github.com/Trustworthy-ML-Lab/CB-LLMs.",2024-12-11T00:04:10Z,http://arxiv.org/pdf/2412.07992v4,"['cs.CL', 'cs.LG']"
2402.06196v3,Large Language Models: A Survey,"['Shervin Minaee', 'Tomas Mikolov', 'Narjes Nikzad', 'Meysam Chenaghlu', 'Richard Socher', 'Xavier Amatriain', 'Jianfeng Gao']","Large Language Models (LLMs) have drawn a lot of attention due to their
strong performance on a wide range of natural language tasks, since the release
of ChatGPT in November 2022. LLMs' ability of general-purpose language
understanding and generation is acquired by training billions of model's
parameters on massive amounts of text data, as predicted by scaling laws
\cite{kaplan2020scaling,hoffmann2022training}. The research area of LLMs, while
very recent, is evolving rapidly in many different ways. In this paper, we
review some of the most prominent LLMs, including three popular LLM families
(GPT, LLaMA, PaLM), and discuss their characteristics, contributions and
limitations. We also give an overview of techniques developed to build, and
augment LLMs. We then survey popular datasets prepared for LLM training,
fine-tuning, and evaluation, review widely used LLM evaluation metrics, and
compare the performance of several popular LLMs on a set of representative
benchmarks. Finally, we conclude the paper by discussing open challenges and
future research directions.",2024-02-09T05:37:09Z,http://arxiv.org/pdf/2402.06196v3,"['cs.CL', 'cs.AI']"
2409.10482v3,Schrodinger's Memory: Large Language Models,"['Wei Wang', 'Qing Li']","Memory is the foundation of all human activities; without memory, it would be
nearly impossible for people to perform any task in daily life. With the
development of Large Language Models (LLMs), their language capabilities are
becoming increasingly comparable to those of humans. But do LLMs have memory?
Based on current performance, LLMs do appear to exhibit memory. So, what is the
underlying mechanism of this memory? Previous research has lacked a deep
exploration of LLMs' memory capabilities and the underlying theory. In this
paper, we use Universal Approximation Theorem (UAT) to explain the memory
mechanism in LLMs. We also conduct experiments to verify the memory
capabilities of various LLMs, proposing a new method to assess their abilities
based on these memory ability. We argue that LLM memory operates like
Schr\""odinger's memory, meaning that it only becomes observable when a specific
memory is queried. We can only determine if the model retains a memory based on
its output in response to the query; otherwise, it remains indeterminate.
Finally, we expand on this concept by comparing the memory capabilities of the
human brain and LLMs, highlighting the similarities and differences in their
operational mechanisms.",2024-09-16T17:18:11Z,http://arxiv.org/pdf/2409.10482v3,['cs.CL']
2502.12150v2,Idiosyncrasies in Large Language Models,"['Mingjie Sun', 'Yida Yin', 'Zhiqiu Xu', 'J. Zico Kolter', 'Zhuang Liu']","In this work, we unveil and study idiosyncrasies in Large Language Models
(LLMs) -- unique patterns in their outputs that can be used to distinguish the
models. To do so, we consider a simple classification task: given a particular
text output, the objective is to predict the source LLM that generates the
text. We evaluate this synthetic task across various groups of LLMs and find
that simply fine-tuning text embedding models on LLM-generated texts yields
excellent classification accuracy. Notably, we achieve 97.1% accuracy on
held-out validation data in the five-way classification problem involving
ChatGPT, Claude, Grok, Gemini, and DeepSeek. Our further investigation reveals
that these idiosyncrasies are rooted in word-level distributions. These
patterns persist even when the texts are rewritten, translated, or summarized
by an external LLM, suggesting that they are also encoded in the semantic
content. Additionally, we leverage LLM as judges to generate detailed,
open-ended descriptions of each model's idiosyncrasies. Finally, we discuss the
broader implications of our findings, including training on synthetic data,
inferring model similarity, and robust evaluation of LLMs. Code is available at
https://github.com/locuslab/llm-idiosyncrasies.",2025-02-17T18:59:02Z,http://arxiv.org/pdf/2502.12150v2,['cs.CL']
2503.04748v2,Large Language Models in Healthcare,"['Mohammed Al-Garadi', 'Tushar Mungle', 'Abdulaziz Ahmed', 'Abeed Sarker', 'Zhuqi Miao', 'Michael E. Matheny']","Large language models (LLMs) hold promise for transforming healthcare, from
streamlining administrative and clinical workflows to enriching patient
engagement and advancing clinical decision-making. However, their successful
integration requires rigorous development, adaptation, and evaluation
strategies tailored to clinical needs. In this Review, we highlight recent
advancements, explore emerging opportunities for LLM-driven innovation, and
propose a framework for their responsible implementation in healthcare
settings. We examine strategies for adapting LLMs to domain-specific healthcare
tasks, such as fine-tuning, prompt engineering, and multimodal integration with
electronic health records. We also summarize various evaluation metrics
tailored to healthcare, addressing clinical accuracy, fairness, robustness, and
patient outcomes. Furthermore, we discuss the challenges associated with
deploying LLMs in healthcare--including data privacy, bias mitigation,
regulatory compliance, and computational sustainability--and underscore the
need for interdisciplinary collaboration. Finally, these challenges present
promising future research directions for advancing LLM implementation in
clinical settings and healthcare.",2025-02-06T20:53:33Z,http://arxiv.org/pdf/2503.04748v2,['cs.CY']
2410.15319v1,Causality for Large Language Models,"['Anpeng Wu', 'Kun Kuang', 'Minqin Zhu', 'Yingrong Wang', 'Yujia Zheng', 'Kairong Han', 'Baohong Li', 'Guangyi Chen', 'Fei Wu', 'Kun Zhang']","Recent breakthroughs in artificial intelligence have driven a paradigm shift,
where large language models (LLMs) with billions or trillions of parameters are
trained on vast datasets, achieving unprecedented success across a series of
language tasks. However, despite these successes, LLMs still rely on
probabilistic modeling, which often captures spurious correlations rooted in
linguistic patterns and social stereotypes, rather than the true causal
relationships between entities and events. This limitation renders LLMs
vulnerable to issues such as demographic biases, social stereotypes, and LLM
hallucinations. These challenges highlight the urgent need to integrate
causality into LLMs, moving beyond correlation-driven paradigms to build more
reliable and ethically aligned AI systems.
  While many existing surveys and studies focus on utilizing prompt engineering
to activate LLMs for causal knowledge or developing benchmarks to assess their
causal reasoning abilities, most of these efforts rely on human intervention to
activate pre-trained models. How to embed causality into the training process
of LLMs and build more general and intelligent models remains unexplored.
Recent research highlights that LLMs function as causal parrots, capable of
reciting causal knowledge without truly understanding or applying it. These
prompt-based methods are still limited to human interventional improvements.
This survey aims to address this gap by exploring how causality can enhance
LLMs at every stage of their lifecycle-from token embedding learning and
foundation model training to fine-tuning, alignment, inference, and
evaluation-paving the way for more interpretable, reliable, and
causally-informed models. Additionally, we further outline six promising future
directions to advance LLM development, enhance their causal reasoning
capabilities, and address the current limitations these models face.",2024-10-20T07:22:23Z,http://arxiv.org/pdf/2410.15319v1,"['cs.CL', 'cs.AI', 'stat.ML']"
2407.00365v1,Financial Knowledge Large Language Model,"['Cehao Yang', 'Chengjin Xu', 'Yiyan Qi']","Artificial intelligence is making significant strides in the finance
industry, revolutionizing how data is processed and interpreted. Among these
technologies, large language models (LLMs) have demonstrated substantial
potential to transform financial services by automating complex tasks,
enhancing customer service, and providing detailed financial analysis. Firstly,
we introduce IDEA-FinBench, an evaluation benchmark specifically tailored for
assessing financial knowledge in large language models (LLMs). This benchmark
utilizes questions from two globally respected and authoritative financial
professional exams, aimimg to comprehensively evaluate the capability of LLMs
to directly address exam questions pertinent to the finance sector. Secondly,
we propose IDEA-FinKER, a Financial Knowledge Enhancement framework designed to
facilitate the rapid adaptation of general LLMs to the financial domain,
introducing a retrieval-based few-shot learning method for real-time
context-level knowledge injection, and a set of high-quality financial
knowledge instructions for fine-tuning any general LLM. Finally, we present
IDEA-FinQA, a financial question-answering system powered by LLMs. This system
is structured around a scheme of real-time knowledge injection and factual
enhancement using external knowledge. IDEA-FinQA is comprised of three main
modules: the data collector, the data querying module, and LLM-based agents
tasked with specific functions.",2024-06-29T08:26:49Z,http://arxiv.org/pdf/2407.00365v1,['cs.CL']
2312.04556v2,Large Language Models for Mathematicians,"['Simon Frieder', 'Julius Berner', 'Philipp Petersen', 'Thomas Lukasiewicz']","Large language models (LLMs) such as ChatGPT have received immense interest
for their general-purpose language understanding and, in particular, their
ability to generate high-quality text or computer code. For many professions,
LLMs represent an invaluable tool that can speed up and improve the quality of
work. In this note, we discuss to what extent they can aid professional
mathematicians. We first provide a mathematical description of the transformer
model used in all modern language models. Based on recent studies, we then
outline best practices and potential issues and report on the mathematical
abilities of language models. Finally, we shed light on the potential of LLMs
to change how mathematicians work.",2023-12-07T18:59:29Z,http://arxiv.org/pdf/2312.04556v2,"['cs.CL', 'cs.AI', 'cs.LG', 'math.HO']"
2305.05576v1,Large Language Models Humanize Technology,['Pratyush Kumar'],"Large Language Models (LLMs) have made rapid progress in recent months and
weeks, garnering significant public attention. This has sparked concerns about
aligning these models with human values, their impact on labor markets, and the
potential need for regulation in further research and development. However, the
discourse often lacks a focus on the imperative to widely diffuse the societal
benefits of LLMs. To qualify this societal benefit, we assert that LLMs exhibit
emergent abilities to humanize technology more effectively than previous
technologies, and for people across language, occupation, and accessibility
divides. We argue that they do so by addressing three mechanizing bottlenecks
in today's computing technologies: creating diverse and accessible content,
learning complex digital tools, and personalizing machine learning algorithms.
We adopt a case-based approach and illustrate each bottleneck with two examples
where current technology imposes bottlenecks that LLMs demonstrate the ability
to address. Given this opportunity to humanize technology widely, we advocate
for more widespread understanding of LLMs, tools and methods to simplify use of
LLMs, and cross-cutting institutional capacity.",2023-05-09T16:05:36Z,http://arxiv.org/pdf/2305.05576v1,"['cs.CY', 'cs.CL']"
2408.10946v2,Large Language Model Driven Recommendation,"['Anton Korikov', 'Scott Sanner', 'Yashar Deldjoo', 'Zhankui He', 'Julian McAuley', 'Arnau Ramisa', 'Rene Vidal', 'Mahesh Sathiamoorthy', 'Atoosa Kasrizadeh', 'Silvia Milano', 'Francesco Ricci']","While previous chapters focused on recommendation systems (RSs) based on
standardized, non-verbal user feedback such as purchases, views, and clicks --
the advent of LLMs has unlocked the use of natural language (NL) interactions
for recommendation. This chapter discusses how LLMs' abilities for general NL
reasoning present novel opportunities to build highly personalized RSs -- which
can effectively connect nuanced and diverse user preferences to items,
potentially via interactive dialogues. To begin this discussion, we first
present a taxonomy of the key data sources for language-driven recommendation,
covering item descriptions, user-system interactions, and user profiles. We
then proceed to fundamental techniques for LLM recommendation, reviewing the
use of encoder-only and autoregressive LLM recommendation in both tuned and
untuned settings. Afterwards, we move to multi-module recommendation
architectures in which LLMs interact with components such as retrievers and RSs
in multi-stage pipelines. This brings us to architectures for conversational
recommender systems (CRSs), in which LLMs facilitate multi-turn dialogues where
each turn presents an opportunity not only to make recommendations, but also to
engage with the user in interactive preference elicitation, critiquing, and
question-answering.",2024-08-20T15:36:24Z,http://arxiv.org/pdf/2408.10946v2,['cs.AI']
2402.07616v3,Anchor-based Large Language Models,"['Jianhui Pang', 'Fanghua Ye', 'Derek Fai Wong', 'Xin He', 'Wanshun Chen', 'Longyue Wang']","Large language models (LLMs) predominantly employ decoder-only transformer
architectures, necessitating the retention of keys/values information for
historical tokens to provide contextual information and avoid redundant
computation. However, the substantial size and parameter volume of these LLMs
require massive GPU memory. This memory demand increases with the length of the
input text, leading to an urgent need for more efficient methods of information
storage and processing. This study introduces Anchor-based LLMs (AnLLMs), which
utilize an innovative anchor-based self-attention network (AnSAN) and also an
anchor-based inference strategy. This approach enables LLMs to compress
sequence information into an anchor token, reducing the keys/values cache and
enhancing inference efficiency. Experiments on question-answering benchmarks
reveal that AnLLMs maintain similar accuracy levels while achieving up to 99%
keys/values cache reduction and up to 3.5 times faster inference. Despite a
minor compromise in accuracy, the substantial enhancements of AnLLMs employing
the AnSAN technique in resource utilization and computational efficiency
underscore their potential for practical LLM applications.",2024-02-12T12:48:02Z,http://arxiv.org/pdf/2402.07616v3,"['cs.CL', 'cs.AI']"
2410.21418v1,Large Language Models for Manufacturing,"['Yiwei Li', 'Huaqin Zhao', 'Hanqi Jiang', 'Yi Pan', 'Zhengliang Liu', 'Zihao Wu', 'Peng Shu', 'Jie Tian', 'Tianze Yang', 'Shaochen Xu', 'Yanjun Lyu', 'Parker Blenk', 'Jacob Pence', 'Jason Rupram', 'Eliza Banu', 'Ninghao Liu', 'Linbing Wang', 'Wenzhan Song', 'Xiaoming Zhai', 'Kenan Song', 'Dajiang Zhu', 'Beiwen Li', 'Xianqiao Wang', 'Tianming Liu']","The rapid advances in Large Language Models (LLMs) have the potential to
transform manufacturing industry, offering new opportunities to optimize
processes, improve efficiency, and drive innovation. This paper provides a
comprehensive exploration of the integration of LLMs into the manufacturing
domain, focusing on their potential to automate and enhance various aspects of
manufacturing, from product design and development to quality control, supply
chain optimization, and talent management. Through extensive evaluations across
multiple manufacturing tasks, we demonstrate the remarkable capabilities of
state-of-the-art LLMs, such as GPT-4V, in understanding and executing complex
instructions, extracting valuable insights from vast amounts of data, and
facilitating knowledge sharing. We also delve into the transformative potential
of LLMs in reshaping manufacturing education, automating coding processes,
enhancing robot control systems, and enabling the creation of immersive,
data-rich virtual environments through the industrial metaverse. By
highlighting the practical applications and emerging use cases of LLMs in
manufacturing, this paper aims to provide a valuable resource for
professionals, researchers, and decision-makers seeking to harness the power of
these technologies to address real-world challenges, drive operational
excellence, and unlock sustainable growth in an increasingly competitive
landscape.",2024-10-28T18:13:47Z,http://arxiv.org/pdf/2410.21418v1,"['cs.AI', 'cs.CL']"
2501.00885v1,Representation in large language models,['Cameron C. Yetman'],"The extraordinary success of recent Large Language Models (LLMs) on a diverse
array of tasks has led to an explosion of scientific and philosophical
theorizing aimed at explaining how they do what they do. Unfortunately,
disagreement over fundamental theoretical issues has led to stalemate, with
entrenched camps of LLM optimists and pessimists often committed to very
different views of how these systems work. Overcoming stalemate requires
agreement on fundamental questions, and the goal of this paper is to address
one such question, namely: is LLM behavior driven partly by
representation-based information processing of the sort implicated in
biological cognition, or is it driven entirely by processes of memorization and
stochastic table look-up? This is a question about what kind of algorithm LLMs
implement, and the answer carries serious implications for higher level
questions about whether these systems have beliefs, intentions, concepts,
knowledge, and understanding. I argue that LLM behavior is partially driven by
representation-based information processing, and then I describe and defend a
series of practical techniques for investigating these representations and
developing explanations on their basis. The resulting account provides a
groundwork for future theorizing about language models and their successors.",2025-01-01T16:19:48Z,http://arxiv.org/pdf/2501.00885v1,"['cs.CL', 'cs.AI', 'cs.LG']"
2501.05643v1,Iconicity in Large Language Models,"['Anna Marklová', 'Jiří Milička', 'Leonid Ryvkin', 'Ľudmila Lacková Bennet', 'Libuše Kormaníková']","Lexical iconicity, a direct relation between a word's meaning and its form,
is an important aspect of every natural language, most commonly manifesting
through sound-meaning associations. Since Large language models' (LLMs') access
to both meaning and sound of text is only mediated (meaning through textual
context, sound through written representation, further complicated by
tokenization), we might expect that the encoding of iconicity in LLMs would be
either insufficient or significantly different from human processing. This
study addresses this hypothesis by having GPT-4 generate highly iconic
pseudowords in artificial languages. To verify that these words actually carry
iconicity, we had their meanings guessed by Czech and German participants
(n=672) and subsequently by LLM-based participants (generated by GPT-4 and
Claude 3.5 Sonnet). The results revealed that humans can guess the meanings of
pseudowords in the generated iconic language more accurately than words in
distant natural languages and that LLM-based participants are even more
successful than humans in this task. This core finding is accompanied by
several additional analyses concerning the universality of the generated
language and the cues that both human and LLM-based participants utilize.",2025-01-10T01:00:05Z,http://arxiv.org/pdf/2501.05643v1,"['cs.CL', 'cs.AI']"
2212.03551v5,Talking About Large Language Models,['Murray Shanahan'],"Thanks to rapid progress in artificial intelligence, we have entered an era
when technology and philosophy intersect in interesting ways. Sitting squarely
at the centre of this intersection are large language models (LLMs). The more
adept LLMs become at mimicking human language, the more vulnerable we become to
anthropomorphism, to seeing the systems in which they are embedded as more
human-like than they really are. This trend is amplified by the natural
tendency to use philosophically loaded terms, such as ""knows"", ""believes"", and
""thinks"", when describing these systems. To mitigate this trend, this paper
advocates the practice of repeatedly stepping back to remind ourselves of how
LLMs, and the systems of which they form a part, actually work. The hope is
that increased scientific precision will encourage more philosophical nuance in
the discourse around artificial intelligence, both within the field and in the
public sphere.",2022-12-07T10:01:44Z,http://arxiv.org/pdf/2212.03551v5,"['cs.CL', 'cs.LG']"
2311.15180v1,Benchmarking Large Language Model Volatility,['Boyang Yu'],"The impact of non-deterministic outputs from Large Language Models (LLMs) is
not well examined for financial text understanding tasks. Through a compelling
case study on investing in the US equity market via news sentiment analysis, we
uncover substantial variability in sentence-level sentiment classification
results, underscoring the innate volatility of LLM outputs. These uncertainties
cascade downstream, leading to more significant variations in portfolio
construction and return. While tweaking the temperature parameter in the
language model decoder presents a potential remedy, it comes at the expense of
stifled creativity. Similarly, while ensembling multiple outputs mitigates the
effect of volatile outputs, it demands a notable computational investment. This
work furnishes practitioners with invaluable insights for adeptly navigating
uncertainty in the integration of LLMs into financial decision-making,
particularly in scenarios dictated by non-deterministic information.",2023-11-26T03:54:03Z,http://arxiv.org/pdf/2311.15180v1,"['q-fin.TR', 'cs.CL']"
2403.00835v4,CLLMs: Consistency Large Language Models,"['Siqi Kou', 'Lanxiang Hu', 'Zhezhi He', 'Zhijie Deng', 'Hao Zhang']","Parallel decoding methods such as Jacobi decoding show promise for more
efficient LLM inference as it breaks the sequential nature of the LLM decoding
process and transforms it into parallelizable computation. However, in
practice, it achieves little speedup compared to traditional autoregressive
(AR) decoding, primarily because Jacobi decoding seldom accurately predicts
more than one token in a single fixed-point iteration step. To address this, we
develop a new approach aimed at realizing fast convergence from any state to
the fixed point on a Jacobi trajectory. This is accomplished by refining the
target LLM to consistently predict the fixed point given any state as input.
Extensive experiments demonstrate the effectiveness of our method, showing
2.4$\times$ to 3.4$\times$ improvements in generation speed while preserving
generation quality across both domain-specific and open-domain benchmarks.",2024-02-28T20:17:04Z,http://arxiv.org/pdf/2403.00835v4,"['cs.CL', 'cs.AI']"
2407.05750v3,Large Language Models Understand Layout,"['Weiming Li', 'Manni Duan', 'Dong An', 'Yan Shao']","Large language models (LLMs) demonstrate extraordinary abilities in a wide
range of natural language processing (NLP) tasks. In this paper, we show that,
beyond text understanding capability, LLMs are capable of processing text
layouts that are denoted by spatial markers. They are able to answer questions
that require explicit spatial perceiving and reasoning, while a drastic
performance drop is observed when the spatial markers from the original data
are excluded. We perform a series of experiments with the GPT-3.5, Baichuan2,
Llama2 and ChatGLM3 models on various types of layout-sensitive datasets for
further analysis. The experimental results reveal that the layout understanding
ability of LLMs is mainly introduced by the coding data for pretraining, which
is further enhanced at the instruction-tuning stage. In addition, layout
understanding can be enhanced by integrating low-cost, auto-generated data
approached by a novel text game. Finally, we show that layout understanding
ability is beneficial for building efficient visual question-answering (VQA)
systems.",2024-07-08T09:03:12Z,http://arxiv.org/pdf/2407.05750v3,['cs.CL']
2503.06709v1,Delusions of Large Language Models,"['Hongshen Xu', 'Zixv yang', 'Zichen Zhu', 'Kunyao Lan', 'Zihan Wang', 'Mengyue Wu', 'Ziwei Ji', 'Lu Chen', 'Pascale Fung', 'Kai Yu']","Large Language Models often generate factually incorrect but plausible
outputs, known as hallucinations. We identify a more insidious phenomenon, LLM
delusion, defined as high belief hallucinations, incorrect outputs with
abnormally high confidence, making them harder to detect and mitigate. Unlike
ordinary hallucinations, delusions persist with low uncertainty, posing
significant challenges to model reliability. Through empirical analysis across
different model families and sizes on several Question Answering tasks, we show
that delusions are prevalent and distinct from hallucinations. LLMs exhibit
lower honesty with delusions, which are harder to override via finetuning or
self reflection. We link delusion formation with training dynamics and dataset
noise and explore mitigation strategies such as retrieval augmented generation
and multi agent debating to mitigate delusions. By systematically investigating
the nature, prevalence, and mitigation of LLM delusions, our study provides
insights into the underlying causes of this phenomenon and outlines future
directions for improving model reliability.",2025-03-09T17:59:16Z,http://arxiv.org/pdf/2503.06709v1,"['cs.CL', 'cs.AI']"
2410.12428v2,Conformity in Large Language Models,"['Xiaochen Zhu', 'Caiqi Zhang', 'Tom Stafford', 'Nigel Collier', 'Andreas Vlachos']","The conformity effect describes the tendency of individuals to align their
responses with the majority. Studying this bias in large language models (LLMs)
is crucial, as LLMs are increasingly used in various information-seeking and
decision-making tasks as conversation partners to improve productivity. Thus,
conformity to incorrect responses can compromise their effectiveness. In this
paper, we adapt psychological experiments to examine the extent of conformity
in popular LLMs. Our findings reveal that all tested models exhibit varying
levels of conformity toward the majority, regardless of their initial choice or
correctness, across different knowledge domains. Notably, we are the first to
show that LLMs are more likely to conform when they are more uncertain in their
own prediction. We further explore factors that influence conformity, such as
training paradigms and input characteristics, finding that instruction-tuned
models are less susceptible to conformity, while increasing the naturalness of
majority tones amplifies conformity. Finally, we propose two interventions,
Devil's Advocate and Question Distillation, to mitigate conformity, providing
insights into building more robust language models.",2024-10-16T10:16:34Z,http://arxiv.org/pdf/2410.12428v2,"['cs.CL', 'cs.AI']"
2504.18085v1,Random-Set Large Language Models,"['Muhammad Mubashar', 'Shireen Kudukkil Manchingal', 'Fabio Cuzzolin']","Large Language Models (LLMs) are known to produce very high-quality tests and
responses to our queries. But how much can we trust this generated text? In
this paper, we study the problem of uncertainty quantification in LLMs. We
propose a novel Random-Set Large Language Model (RSLLM) approach which predicts
finite random sets (belief functions) over the token space, rather than
probability vectors as in classical LLMs. In order to allow so efficiently, we
also present a methodology based on hierarchical clustering to extract and use
a budget of ""focal"" subsets of tokens upon which the belief prediction is
defined, rather than using all possible collections of tokens, making the
method scalable yet effective. RS-LLMs encode the epistemic uncertainty induced
in their generation process by the size and diversity of its training set via
the size of the credal sets associated with the predicted belief functions. The
proposed approach is evaluated on CoQA and OBQA datasets using Llama2-7b,
Mistral-7b and Phi-2 models and is shown to outperform the standard model in
both datasets in terms of correctness of answer while also showing potential in
estimating the second level uncertainty in its predictions and providing the
capability to detect when its hallucinating.",2025-04-25T05:25:27Z,http://arxiv.org/pdf/2504.18085v1,"['cs.CL', 'cs.AI', 'cs.LG', 'I.2.7']"
2306.08161v2,h2oGPT: Democratizing Large Language Models,"['Arno Candel', 'Jon McKinney', 'Philipp Singer', 'Pascal Pfeiffer', 'Maximilian Jeblick', 'Prithvi Prabhu', 'Jeff Gambera', 'Mark Landry', 'Shivam Bansal', 'Ryan Chesler', 'Chun Ming Lee', 'Marcos V. Conde', 'Pasha Stetsenko', 'Olivier Grellier', 'SriSatish Ambati']","Applications built on top of Large Language Models (LLMs) such as GPT-4
represent a revolution in AI due to their human-level capabilities in natural
language processing. However, they also pose many significant risks such as the
presence of biased, private, or harmful text, and the unauthorized inclusion of
copyrighted material.
  We introduce h2oGPT, a suite of open-source code repositories for the
creation and use of LLMs based on Generative Pretrained Transformers (GPTs).
The goal of this project is to create the world's best truly open-source
alternative to closed-source approaches. In collaboration with and as part of
the incredible and unstoppable open-source community, we open-source several
fine-tuned h2oGPT models from 7 to 40 Billion parameters, ready for commercial
use under fully permissive Apache 2.0 licenses. Included in our release is
100\% private document search using natural language.
  Open-source language models help boost AI development and make it more
accessible and trustworthy. They lower entry hurdles, allowing people and
groups to tailor these models to their needs. This openness increases
innovation, transparency, and fairness. An open-source strategy is needed to
share AI benefits fairly, and H2O.ai will continue to democratize AI and LLMs.",2023-06-13T22:19:53Z,http://arxiv.org/pdf/2306.08161v2,"['cs.CL', 'cs.AI', 'cs.HC', 'cs.IR', 'cs.LG']"
2309.03409v3,Large Language Models as Optimizers,"['Chengrun Yang', 'Xuezhi Wang', 'Yifeng Lu', 'Hanxiao Liu', 'Quoc V. Le', 'Denny Zhou', 'Xinyun Chen']","Optimization is ubiquitous. While derivative-based algorithms have been
powerful tools for various problems, the absence of gradient imposes challenges
on many real-world applications. In this work, we propose Optimization by
PROmpting (OPRO), a simple and effective approach to leverage large language
models (LLMs) as optimizers, where the optimization task is described in
natural language. In each optimization step, the LLM generates new solutions
from the prompt that contains previously generated solutions with their values,
then the new solutions are evaluated and added to the prompt for the next
optimization step. We first showcase OPRO on linear regression and traveling
salesman problems, then move on to our main application in prompt optimization,
where the goal is to find instructions that maximize the task accuracy. With a
variety of LLMs, we demonstrate that the best prompts optimized by OPRO
outperform human-designed prompts by up to 8% on GSM8K, and by up to 50% on
Big-Bench Hard tasks. Code at https://github.com/google-deepmind/opro.",2023-09-07T00:07:15Z,http://arxiv.org/pdf/2309.03409v3,"['cs.LG', 'cs.AI', 'cs.CL']"
2312.13951v1,Typhoon: Thai Large Language Models,"['Kunat Pipatanakul', 'Phatrasek Jirabovonvisut', 'Potsawee Manakul', 'Sittipong Sripaisarnmongkol', 'Ruangsak Patomwong', 'Pathomporn Chokchainant', 'Kasima Tharnpipitchai']","Typhoon is a series of Thai large language models (LLMs) developed
specifically for the Thai language. This technical report presents challenges
and insights in developing Thai LLMs, including data preparation, pretraining,
instruction-tuning, and evaluation. As one of the challenges of low-resource
languages is the amount of pretraining data, we apply continual training to
transfer existing world knowledge from a strong LLM. To evaluate the Thai
knowledge encapsulated in each model from the pretraining stage, we develop
ThaiExam, a benchmark based on examinations for high-school students and
investment professionals in Thailand. In addition, we fine-tune Typhoon to
follow Thai instructions, and we evaluate instruction-tuned models on Thai
instruction datasets as well as translation, summarization, and
question-answering tasks. Experimental results on a suite of Thai benchmarks
show that Typhoon outperforms all open-source Thai language models, and its
performance is on par with GPT-3.5 in Thai while having only 7 billion
parameters and being 2.62 times more efficient in tokenizing Thai text.",2023-12-21T15:38:41Z,http://arxiv.org/pdf/2312.13951v1,"['cs.CL', 'cs.AI']"
2402.18158v2,Evaluating Quantized Large Language Models,"['Shiyao Li', 'Xuefei Ning', 'Luning Wang', 'Tengxuan Liu', 'Xiangsheng Shi', 'Shengen Yan', 'Guohao Dai', 'Huazhong Yang', 'Yu Wang']","Post-training quantization (PTQ) has emerged as a promising technique to
reduce the cost of large language models (LLMs). Specifically, PTQ can
effectively mitigate memory consumption and reduce computational overhead in
LLMs. To meet the requirements of both high efficiency and performance across
diverse scenarios, a comprehensive evaluation of quantized LLMs is essential to
guide the selection of quantization methods. This paper presents a thorough
evaluation of these factors by evaluating the effect of PTQ on Weight,
Activation, and KV Cache on 11 model families, including OPT, LLaMA2, Falcon,
Bloomz, Mistral, ChatGLM, Vicuna, LongChat, StableLM, Gemma, and Mamba, with
parameters ranging from 125M to 180B. The evaluation encompasses five types of
tasks: basic NLP, emergent ability, trustworthiness, dialogue, and long-context
tasks. Moreover, we also evaluate the state-of-the-art (SOTA) quantization
methods to demonstrate their applicability. Based on the extensive experiments,
we systematically summarize the effect of quantization, provide recommendations
to apply quantization techniques, and point out future directions. The code can
be found in https://github.com/thu-nics/qllm-eval.",2024-02-28T08:43:05Z,http://arxiv.org/pdf/2402.18158v2,"['cs.CL', 'cs.AI']"
2406.07177v1,TernaryLLM: Ternarized Large Language Model,"['Tianqi Chen', 'Zhe Li', 'Weixiang Xu', 'Zeyu Zhu', 'Dong Li', 'Lu Tian', 'Emad Barsoum', 'Peisong Wang', 'Jian Cheng']","Large language models (LLMs) have achieved remarkable performance on Natural
Language Processing (NLP) tasks, but they are hindered by high computational
costs and memory requirements. Ternarization, an extreme form of quantization,
offers a solution by reducing memory usage and enabling energy-efficient
floating-point additions. However, applying ternarization to LLMs faces
challenges stemming from outliers in both weights and activations. In this
work, observing asymmetric outliers and non-zero means in weights, we introduce
Dual Learnable Ternarization (DLT), which enables both scales and shifts to be
learnable. We also propose Outlier-Friendly Feature Knowledge Distillation
(OFF) to recover the information lost in extremely low-bit quantization. The
proposed OFF can incorporate semantic information and is insensitive to
outliers. At the core of OFF is maximizing the mutual information between
features in ternarized and floating-point models using cosine similarity.
Extensive experiments demonstrate that our TernaryLLM surpasses previous
low-bit quantization methods on the standard text generation and zero-shot
benchmarks for different LLM families. Specifically, for one of the most
powerful open-source models, LLaMA-3, our approach (W1.58A16) outperforms the
previous state-of-the-art method (W2A16) by 5.8 in terms of perplexity on C4
and by 8.2% in terms of average accuracy on zero-shot tasks.",2024-06-11T11:40:12Z,http://arxiv.org/pdf/2406.07177v1,['cs.LG']
2205.12615v1,Autoformalization with Large Language Models,"['Yuhuai Wu', 'Albert Q. Jiang', 'Wenda Li', 'Markus N. Rabe', 'Charles Staats', 'Mateja Jamnik', 'Christian Szegedy']","Autoformalization is the process of automatically translating from natural
language mathematics to formal specifications and proofs. A successful
autoformalization system could advance the fields of formal verification,
program synthesis, and artificial intelligence. While the long-term goal of
autoformalization seemed elusive for a long time, we show large language models
provide new prospects towards this goal. We make the surprising observation
that LLMs can correctly translate a significant portion ($25.3\%$) of
mathematical competition problems perfectly to formal specifications in
Isabelle/HOL. We demonstrate the usefulness of this process by improving a
previously introduced neural theorem prover via training on these
autoformalized theorems. Our methodology results in a new state-of-the-art
result on the MiniF2F theorem proving benchmark, improving the proof rate from
$29.6\%$ to $35.2\%$.",2022-05-25T09:53:30Z,http://arxiv.org/pdf/2205.12615v1,"['cs.LG', 'cs.AI', 'cs.LO', 'cs.SE']"
2501.06271v1,Large Language Models for Bioinformatics,"['Wei Ruan', 'Yanjun Lyu', 'Jing Zhang', 'Jiazhang Cai', 'Peng Shu', 'Yang Ge', 'Yao Lu', 'Shang Gao', 'Yue Wang', 'Peilong Wang', 'Lin Zhao', 'Tao Wang', 'Yufang Liu', 'Luyang Fang', 'Ziyu Liu', 'Zhengliang Liu', 'Yiwei Li', 'Zihao Wu', 'Junhao Chen', 'Hanqi Jiang', 'Yi Pan', 'Zhenyuan Yang', 'Jingyuan Chen', 'Shizhe Liang', 'Wei Zhang', 'Terry Ma', 'Yuan Dou', 'Jianli Zhang', 'Xinyu Gong', 'Qi Gan', 'Yusong Zou', 'Zebang Chen', 'Yuanxin Qian', 'Shuo Yu', 'Jin Lu', 'Kenan Song', 'Xianqiao Wang', 'Andrea Sikora', 'Gang Li', 'Xiang Li', 'Quanzheng Li', 'Yingfeng Wang', 'Lu Zhang', 'Yohannes Abate', 'Lifang He', 'Wenxuan Zhong', 'Rongjie Liu', 'Chao Huang', 'Wei Liu', 'Ye Shen', 'Ping Ma', 'Hongtu Zhu', 'Yajun Yan', 'Dajiang Zhu', 'Tianming Liu']","With the rapid advancements in large language model (LLM) technology and the
emergence of bioinformatics-specific language models (BioLMs), there is a
growing need for a comprehensive analysis of the current landscape,
computational characteristics, and diverse applications. This survey aims to
address this need by providing a thorough review of BioLMs, focusing on their
evolution, classification, and distinguishing features, alongside a detailed
examination of training methodologies, datasets, and evaluation frameworks. We
explore the wide-ranging applications of BioLMs in critical areas such as
disease diagnosis, drug discovery, and vaccine development, highlighting their
impact and transformative potential in bioinformatics. We identify key
challenges and limitations inherent in BioLMs, including data privacy and
security concerns, interpretability issues, biases in training data and model
outputs, and domain adaptation complexities. Finally, we highlight emerging
trends and future directions, offering valuable insights to guide researchers
and clinicians toward advancing BioLMs for increasingly sophisticated
biological and clinical applications.",2025-01-10T01:43:05Z,http://arxiv.org/pdf/2501.06271v1,"['q-bio.QM', 'cs.AI', 'cs.CE']"
2311.07484v3,Psychometric Predictive Power of Large Language Models,"['Tatsuki Kuribayashi', 'Yohei Oseki', 'Timothy Baldwin']","Instruction tuning aligns the response of large language models (LLMs) with
human preferences. Despite such efforts in human--LLM alignment, we find that
instruction tuning does not always make LLMs human-like from a cognitive
modeling perspective. More specifically, next-word probabilities estimated by
instruction-tuned LLMs are often worse at simulating human reading behavior
than those estimated by base LLMs. In addition, we explore prompting
methodologies for simulating human reading behavior with LLMs. Our results show
that prompts reflecting a particular linguistic hypothesis improve psychometric
predictive power, but are still inferior to small base models. These findings
highlight that recent advancements in LLMs, i.e., instruction tuning and
prompting, do not offer better estimates than direct probability measurements
from base LLMs in cognitive modeling. In other words, pure next-word
probability remains a strong predictor for human reading behavior, even in the
age of LLMs.",2023-11-13T17:19:14Z,http://arxiv.org/pdf/2311.07484v3,"['cs.CL', 'cs.AI']"
2403.17688v2,Large Language Models Enhanced Collaborative Filtering,"['Zhongxiang Sun', 'Zihua Si', 'Xiaoxue Zang', 'Kai Zheng', 'Yang Song', 'Xiao Zhang', 'Jun Xu']","Recent advancements in Large Language Models (LLMs) have attracted
considerable interest among researchers to leverage these models to enhance
Recommender Systems (RSs). Existing work predominantly utilizes LLMs to
generate knowledge-rich texts or utilizes LLM-derived embeddings as features to
improve RSs. Although the extensive world knowledge embedded in LLMs generally
benefits RSs, the application can only take limited number of users and items
as inputs, without adequately exploiting collaborative filtering information.
Considering its crucial role in RSs, one key challenge in enhancing RSs with
LLMs lies in providing better collaborative filtering information through LLMs.
In this paper, drawing inspiration from the in-context learning and chain of
thought reasoning in LLMs, we propose the Large Language Models enhanced
Collaborative Filtering (LLM-CF) framework, which distils the world knowledge
and reasoning capabilities of LLMs into collaborative filtering. We also
explored a concise and efficient instruction-tuning method, which improves the
recommendation capabilities of LLMs while preserving their general
functionalities (e.g., not decreasing on the LLM benchmark). Comprehensive
experiments on three real-world datasets demonstrate that LLM-CF significantly
enhances several backbone recommendation models and consistently outperforms
competitive baselines, showcasing its effectiveness in distilling the world
knowledge and reasoning capabilities of LLM into collaborative filtering.",2024-03-26T13:31:33Z,http://arxiv.org/pdf/2403.17688v2,['cs.IR']
2401.07102v1,Evolving Code with A Large Language Model,"['Erik Hemberg', 'Stephen Moskal', ""Una-May O'Reilly""]","Algorithms that use Large Language Models (LLMs) to evolve code arrived on
the Genetic Programming (GP) scene very recently. We present LLM GP, a
formalized LLM-based evolutionary algorithm designed to evolve code. Like GP,
it uses evolutionary operators, but its designs and implementations of those
operators radically differ from GP's because they enlist an LLM, using
prompting and the LLM's pre-trained pattern matching and sequence completion
capability. We also present a demonstration-level variant of LLM GP and share
its code. By addressing algorithms that range from the formal to hands-on, we
cover design and LLM-usage considerations as well as the scientific challenges
that arise when using an LLM for genetic programming.",2024-01-13T15:57:54Z,http://arxiv.org/pdf/2401.07102v1,"['cs.NE', 'cs.AI', 'I.2.8']"
2407.04307v1,Crafting Large Language Models for Enhanced Interpretability,"['Chung-En Sun', 'Tuomas Oikarinen', 'Tsui-Wei Weng']","We introduce the Concept Bottleneck Large Language Model (CB-LLM), a
pioneering approach to creating inherently interpretable Large Language Models
(LLMs). Unlike traditional black-box LLMs that rely on post-hoc interpretation
methods with limited neuron function insights, CB-LLM sets a new standard with
its built-in interpretability, scalability, and ability to provide clear,
accurate explanations. This innovation not only advances transparency in
language models but also enhances their effectiveness. Our unique Automatic
Concept Correction (ACC) strategy successfully narrows the performance gap with
conventional black-box LLMs, positioning CB-LLM as a model that combines the
high accuracy of traditional LLMs with the added benefit of clear
interpretability -- a feature markedly absent in existing LLMs.",2024-07-05T07:22:44Z,http://arxiv.org/pdf/2407.04307v1,"['cs.CL', 'cs.LG']"
2310.19736v3,Evaluating Large Language Models: A Comprehensive Survey,"['Zishan Guo', 'Renren Jin', 'Chuang Liu', 'Yufei Huang', 'Dan Shi', 'Supryadi', 'Linhao Yu', 'Yan Liu', 'Jiaxuan Li', 'Bojian Xiong', 'Deyi Xiong']","Large language models (LLMs) have demonstrated remarkable capabilities across
a broad spectrum of tasks. They have attracted significant attention and been
deployed in numerous downstream applications. Nevertheless, akin to a
double-edged sword, LLMs also present potential risks. They could suffer from
private data leaks or yield inappropriate, harmful, or misleading content.
Additionally, the rapid progress of LLMs raises concerns about the potential
emergence of superintelligent systems without adequate safeguards. To
effectively capitalize on LLM capacities as well as ensure their safe and
beneficial development, it is critical to conduct a rigorous and comprehensive
evaluation of LLMs.
  This survey endeavors to offer a panoramic perspective on the evaluation of
LLMs. We categorize the evaluation of LLMs into three major groups: knowledge
and capability evaluation, alignment evaluation and safety evaluation. In
addition to the comprehensive review on the evaluation methodologies and
benchmarks on these three aspects, we collate a compendium of evaluations
pertaining to LLMs' performance in specialized domains, and discuss the
construction of comprehensive evaluation platforms that cover LLM evaluations
on capabilities, alignment, safety, and applicability.
  We hope that this comprehensive overview will stimulate further research
interests in the evaluation of LLMs, with the ultimate goal of making
evaluation serve as a cornerstone in guiding the responsible development of
LLMs. We envision that this will channel their evolution into a direction that
maximizes societal benefit while minimizing potential risks. A curated list of
related papers has been publicly available at
https://github.com/tjunlp-lab/Awesome-LLMs-Evaluation-Papers.",2023-10-30T17:00:52Z,http://arxiv.org/pdf/2310.19736v3,"['cs.CL', 'cs.AI']"
2407.14112v2,Large-Language-Model Enabled Semantic Communication Systems,"['Zhenyi Wang', 'Li Zou', 'Shengyun Wei', 'Kai Li', 'Feifan Liao', 'Haibo Mi', 'Rongxuan Lai']","Large language models (LLMs) have recently demonstrated state-of-the-art
performance across various natural language processing (NLP) tasks, achieving
near-human levels in multiple language understanding challenges and aligning
closely with the core principles of semantic communication. Inspired by LLMs'
advancements in semantic processing, we propose an innovative LLM-enabled
semantic communication system framework, named LLM-SC, that applies LLMs
directly to the physical layer coding and decoding for the first time. By
analyzing the relationship between the training process of LLMs and the
optimization objectives of semantic communication, we propose training a
semantic encoder through LLMs' tokenizer training and establishing a semantic
knowledge base via the LLMs' unsupervised pre-training process. This knowledge
base aids in constructing the optimal decoder by providing the prior
probability of the transmitted language sequence. Based on this foundation, we
derive the optimal decoding criterion for the receiver and introduce the beam
search algorithm to further reduce the complexity. Furthermore, we assert that
existing LLMs can be employed directly for LLM-SC without additional
re-training or fine-tuning. Simulation results demonstrate that LLM-SC
outperforms classical DeepSC at signal-to-noise ratios (SNR) exceeding 3 dB,
enabling error-free transmission of semantic information under high SNR, which
is unattainable by DeepSC. In addition to semantic-level performance, LLM-SC
demonstrates compatibility with technical-level performance, achieving
approximately 8 dB coding gain for a bit error ratio (BER) of $10^{-3}$ without
any channel coding while maintaining the same joint source-channel coding rate
as traditional communication systems.",2024-07-19T08:29:23Z,http://arxiv.org/pdf/2407.14112v2,['eess.SP']
2405.10098v1,When Large Language Model Meets Optimization,"['Sen Huang', 'Kaixiang Yang', 'Sheng Qi', 'Rui Wang']","Optimization algorithms and large language models (LLMs) enhance
decision-making in dynamic environments by integrating artificial intelligence
with traditional techniques. LLMs, with extensive domain knowledge, facilitate
intelligent modeling and strategic decision-making in optimization, while
optimization algorithms refine LLM architectures and output quality. This
synergy offers novel approaches for advancing general AI, addressing both the
computational challenges of complex problems and the application of LLMs in
practical scenarios. This review outlines the progress and potential of
combining LLMs with optimization algorithms, providing insights for future
research directions.",2024-05-16T13:54:37Z,http://arxiv.org/pdf/2405.10098v1,['cs.NE']
2401.01735v1,Economics Arena for Large Language Models,"['Shangmin Guo', 'Haoran Bu', 'Haochuan Wang', 'Yi Ren', 'Dianbo Sui', 'Yuming Shang', 'Siting Lu']","Large language models (LLMs) have been extensively used as the backbones for
general-purpose agents, and some economics literature suggest that LLMs are
capable of playing various types of economics games. Following these works, to
overcome the limitation of evaluating LLMs using static benchmarks, we propose
to explore competitive games as an evaluation for LLMs to incorporate
multi-players and dynamicise the environment. By varying the game history
revealed to LLMs-based players, we find that most of LLMs are rational in that
they play strategies that can increase their payoffs, but not as rational as
indicated by Nash Equilibria (NEs). Moreover, when game history are available,
certain types of LLMs, such as GPT-4, can converge faster to the NE strategies,
which suggests higher rationality level in comparison to other models. In the
meantime, certain types of LLMs can win more often when game history are
available, and we argue that the winning rate reflects the reasoning ability
with respect to the strategies of other players. Throughout all our
experiments, we observe that the ability to strictly follow the game rules
described by natural languages also vary among the LLMs we tested. In this
work, we provide an economics arena for the LLMs research community as a
dynamic simulation to test the above-mentioned abilities of LLMs, i.e.
rationality, strategic reasoning ability, and instruction-following capability.",2024-01-03T13:18:24Z,http://arxiv.org/pdf/2401.01735v1,['cs.GT']
2310.14540v3,Evaluating Spatial Understanding of Large Language Models,"['Yutaro Yamada', 'Yihan Bao', 'Andrew K. Lampinen', 'Jungo Kasai', 'Ilker Yildirim']","Large language models (LLMs) show remarkable capabilities across a variety of
tasks. Despite the models only seeing text in training, several recent studies
suggest that LLM representations implicitly capture aspects of the underlying
grounded concepts. Here, we explore LLM representations of a particularly
salient kind of grounded knowledge -- spatial relationships. We design
natural-language navigation tasks and evaluate the ability of LLMs, in
particular GPT-3.5-turbo, GPT-4, and Llama2 series models, to represent and
reason about spatial structures. These tasks reveal substantial variability in
LLM performance across different spatial structures, including square,
hexagonal, and triangular grids, rings, and trees. In extensive error analysis,
we find that LLMs' mistakes reflect both spatial and non-spatial factors. These
findings suggest that LLMs appear to capture certain aspects of spatial
structure implicitly, but room for improvement remains.",2023-10-23T03:44:40Z,http://arxiv.org/pdf/2310.14540v3,"['cs.CL', 'cs.AI']"
2405.13055v1,Large Language Models for Medicine: A Survey,"['Yanxin Zheng', 'Wensheng Gan', 'Zefeng Chen', 'Zhenlian Qi', 'Qian Liang', 'Philip S. Yu']","To address challenges in the digital economy's landscape of digital
intelligence, large language models (LLMs) have been developed. Improvements in
computational power and available resources have significantly advanced LLMs,
allowing their integration into diverse domains for human life. Medical LLMs
are essential application tools with potential across various medical
scenarios. In this paper, we review LLM developments, focusing on the
requirements and applications of medical LLMs. We provide a concise overview of
existing models, aiming to explore advanced research directions and benefit
researchers for future medical applications. We emphasize the advantages of
medical LLMs in applications, as well as the challenges encountered during
their development. Finally, we suggest directions for technical integration to
mitigate challenges and potential research directions for the future of medical
LLMs, aiming to meet the demands of the medical field better.",2024-05-20T02:32:26Z,http://arxiv.org/pdf/2405.13055v1,"['cs.CL', 'cs.AI', 'cs.CY']"
2406.05335v2,Critical Phase Transition in Large Language Models,"['Kai Nakaishi', 'Yoshihiko Nishikawa', 'Koji Hukushima']","Large Language Models (LLMs) have demonstrated impressive performance. To
understand their behaviors, we need to consider the fact that LLMs sometimes
show qualitative changes. The natural world also presents such changes called
phase transitions, which are defined by singular, divergent statistical
quantities. Therefore, an intriguing question is whether qualitative changes in
LLMs are phase transitions. In this work, we have conducted extensive analysis
on texts generated by LLMs and suggested that a phase transition occurs in LLMs
when varying the temperature parameter. Specifically, statistical quantities
have divergent properties just at the point between the low-temperature regime,
where LLMs generate sentences with clear repetitive structures, and the
high-temperature regime, where generated sentences are often incomprehensible.
In addition, critical behaviors near the phase transition point, such as a
power-law decay of correlation and slow convergence toward the stationary
state, are similar to those in natural languages. Our results suggest a
meaningful analogy between LLMs and natural phenomena.",2024-06-08T03:37:05Z,http://arxiv.org/pdf/2406.05335v2,"['cond-mat.dis-nn', 'cs.LG']"
2409.19450v2,Secret Use of Large Language Model (LLM),"['Zhiping Zhang', 'Chenxinran Shen', 'Bingsheng Yao', 'Dakuo Wang', 'Tianshi Li']","The advancements of Large Language Models (LLMs) have decentralized the
responsibility for the transparency of AI usage. Specifically, LLM users are
now encouraged or required to disclose the use of LLM-generated content for
varied types of real-world tasks. However, an emerging phenomenon, users'
secret use of LLM, raises challenges in ensuring end users adhere to the
transparency requirement. Our study used mixed-methods with an exploratory
survey (125 real-world secret use cases reported) and a controlled experiment
among 300 users to investigate the contexts and causes behind the secret use of
LLMs. We found that such secretive behavior is often triggered by certain
tasks, transcending demographic and personality differences among users. Task
types were found to affect users' intentions to use secretive behavior,
primarily through influencing perceived external judgment regarding LLM usage.
Our results yield important insights for future work on designing interventions
to encourage more transparent disclosure of the use of LLMs or other AI
technologies.",2024-09-28T20:31:53Z,http://arxiv.org/pdf/2409.19450v2,"['cs.HC', 'cs.AI']"
2412.10606v2,Do Large Language Models Speak Scientific Workflows?,"['Orcun Yildiz', 'Tom Peterka']","With the advent of large language models (LLMs), there is a growing interest
in applying LLMs to scientific tasks. In this work, we conduct an experimental
study to explore applicability of LLMs for configuring, annotating,
translating, explaining, and generating scientific workflows. We use 5
different workflow specific experiments and evaluate several open- and
closed-source language models using state-of-the-art workflow systems. Our
studies reveal that LLMs often struggle with workflow related tasks due to
their lack of knowledge of scientific workflows. We further observe that the
performance of LLMs varies across experiments and workflow systems. Our
findings can help workflow developers and users in understanding LLMs
capabilities in scientific workflows, and motivate further research applying
LLMs to workflows.",2024-12-13T23:19:21Z,http://arxiv.org/pdf/2412.10606v2,['cs.HC']
2311.08398v2,Are Large Language Models Temporally Grounded?,"['Yifu Qiu', 'Zheng Zhao', 'Yftah Ziser', 'Anna Korhonen', 'Edoardo M. Ponti', 'Shay B. Cohen']","Are Large language models (LLMs) temporally grounded? Since LLMs cannot
perceive and interact with the environment, it is impossible to answer this
question directly. Instead, we provide LLMs with textual narratives and probe
them with respect to their common-sense knowledge of the structure and duration
of events, their ability to order events along a timeline, and self-consistency
within their temporal model (e.g., temporal relations such as after and before
are mutually exclusive for any pair of events). We evaluate state-of-the-art
LLMs (such as LLaMA 2 and GPT-4) on three tasks reflecting these abilities.
Generally, we find that LLMs lag significantly behind both human performance as
well as small-scale, specialised LMs. In-context learning, instruction tuning,
and chain-of-thought prompting reduce this gap only to a limited degree.
Crucially, LLMs struggle the most with self-consistency, displaying incoherent
behaviour in at least 27.23% of their predictions. Contrary to expectations, we
also find that scaling the model size does not guarantee positive gains in
performance. To explain these results, we study the sources from which LLMs may
gather temporal information: we find that sentence ordering in unlabelled
texts, available during pre-training, is only weakly correlated with event
ordering. Moreover, public instruction tuning mixtures contain few temporal
tasks. Hence, we conclude that current LLMs lack a consistent temporal model of
textual narratives. Code, datasets, and LLM outputs are available at
https://github.com/yfqiu-nlp/temporal-llms.",2023-11-14T18:57:15Z,http://arxiv.org/pdf/2311.08398v2,"['cs.CL', 'cs.AI']"
2401.10491v2,Knowledge Fusion of Large Language Models,"['Fanqi Wan', 'Xinting Huang', 'Deng Cai', 'Xiaojun Quan', 'Wei Bi', 'Shuming Shi']","While training large language models (LLMs) from scratch can generate models
with distinct functionalities and strengths, it comes at significant costs and
may result in redundant capabilities. Alternatively, a cost-effective and
compelling approach is to merge existing pre-trained LLMs into a more potent
model. However, due to the varying architectures of these LLMs, directly
blending their weights is impractical. In this paper, we introduce the notion
of knowledge fusion for LLMs, aimed at combining the capabilities of existing
LLMs and transferring them into a single LLM. By leveraging the generative
distributions of source LLMs, we externalize their collective knowledge and
unique strengths, thereby potentially elevating the capabilities of the target
model beyond those of any individual source LLM. We validate our approach using
three popular LLMs with different architectures--Llama-2, MPT, and
OpenLLaMA--across various benchmarks and tasks. Our findings confirm that the
fusion of LLMs can improve the performance of the target model across a range
of capabilities such as reasoning, commonsense, and code generation. Our code,
model weights, and data are public at
\url{https://github.com/fanqiwan/FuseLLM}.",2024-01-19T05:02:46Z,http://arxiv.org/pdf/2401.10491v2,['cs.CL']
2404.17785v4,Temporal Scaling Law for Large Language Models,"['Yizhe Xiong', 'Xiansheng Chen', 'Xin Ye', 'Hui Chen', 'Zijia Lin', 'Haoran Lian', 'Zhenpeng Su', 'Wei Huang', 'Jianwei Niu', 'Jungong Han', 'Guiguang Ding']","Recently, Large Language Models (LLMs) have been widely adopted in a wide
range of tasks, leading to increasing attention towards the research on how
scaling LLMs affects their performance. Existing works, termed Scaling Laws,
have discovered that the final test loss of LLMs scales as power-laws with
model size, computational budget, and dataset size. However, the temporal
change of the test loss of an LLM throughout its pre-training process remains
unexplored, though it is valuable in many aspects, such as selecting better
hyperparameters \textit{directly} on the target LLM. In this paper, we propose
the novel concept of Temporal Scaling Law, studying how the test loss of an LLM
evolves as the training steps scale up. In contrast to modeling the test loss
as a whole in a coarse-grained manner, we break it down and dive into the
fine-grained test loss of each token position, and further develop a dynamic
hyperbolic-law. Afterwards, we derive the much more precise temporal scaling
law by studying the temporal patterns of the parameters in the dynamic
hyperbolic-law. Results on both in-distribution (ID) and out-of-distribution
(OOD) validation datasets demonstrate that our temporal scaling law accurately
predicts the test loss of LLMs across training steps. Our temporal scaling law
has broad practical applications. First, it enables direct and efficient
hyperparameter selection on the target LLM, such as data mixture proportions.
Secondly, viewing the LLM pre-training dynamics from the token position
granularity provides some insights to enhance the understanding of LLM
pre-training.",2024-04-27T05:49:11Z,http://arxiv.org/pdf/2404.17785v4,['cs.CL']
2502.01118v1,Large Language Model-Enhanced Multi-Armed Bandits,"['Jiahang Sun', 'Zhiyong Wang', 'Runhan Yang', 'Chenjun Xiao', 'John C. S. Lui', 'Zhongxiang Dai']","Large language models (LLMs) have been adopted to solve sequential
decision-making tasks such as multi-armed bandits (MAB), in which an LLM is
directly instructed to select the arms to pull in every iteration. However,
this paradigm of direct arm selection using LLMs has been shown to be
suboptimal in many MAB tasks. Therefore, we propose an alternative approach
which combines the strengths of classical MAB and LLMs. Specifically, we adopt
a classical MAB algorithm as the high-level framework and leverage the strong
in-context learning capability of LLMs to perform the sub-task of reward
prediction. Firstly, we incorporate the LLM-based reward predictor into the
classical Thompson sampling (TS) algorithm and adopt a decaying schedule for
the LLM temperature to ensure a transition from exploration to exploitation.
Next, we incorporate the LLM-based reward predictor (with a temperature of 0)
into a regression oracle-based MAB algorithm equipped with an explicit
exploration mechanism. We also extend our TS-based algorithm to dueling bandits
where only the preference feedback between pairs of arms is available, which
requires non-trivial algorithmic modifications. We conduct empirical
evaluations using both synthetic MAB tasks and experiments designed using
real-world text datasets, in which the results show that our algorithms
consistently outperform previous baseline methods based on direct arm
selection. Interestingly, we also demonstrate that in challenging tasks where
the arms lack semantic meanings that can be exploited by the LLM, our approach
achieves considerably better performance than LLM-based direct arm selection.",2025-02-03T07:19:05Z,http://arxiv.org/pdf/2502.01118v1,"['cs.LG', 'cs.AI']"
2502.17129v1,Thus Spake Long-Context Large Language Model,"['Xiaoran Liu', 'Ruixiao Li', 'Mianqiu Huang', 'Zhigeng Liu', 'Yuerong Song', 'Qipeng Guo', 'Siyang He', 'Qiqi Wang', 'Linlin Li', 'Qun Liu', 'Yaqian Zhou', 'Xuanjing Huang', 'Xipeng Qiu']","Long context is an important topic in Natural Language Processing (NLP),
running through the development of NLP architectures, and offers immense
opportunities for Large Language Models (LLMs) giving LLMs the lifelong
learning potential akin to humans. Unfortunately, the pursuit of a long context
is accompanied by numerous obstacles. Nevertheless, long context remains a core
competitive advantage for LLMs. In the past two years, the context length of
LLMs has achieved a breakthrough extension to millions of tokens. Moreover, the
research on long-context LLMs has expanded from length extrapolation to a
comprehensive focus on architecture, infrastructure, training, and evaluation
technologies.
  Inspired by the symphonic poem, Thus Spake Zarathustra, we draw an analogy
between the journey of extending the context of LLM and the attempts of humans
to transcend its mortality. In this survey, We will illustrate how LLM
struggles between the tremendous need for a longer context and its equal need
to accept the fact that it is ultimately finite. To achieve this, we give a
global picture of the lifecycle of long-context LLMs from four perspectives:
architecture, infrastructure, training, and evaluation, showcasing the full
spectrum of long-context technologies. At the end of this survey, we will
present 10 unanswered questions currently faced by long-context LLMs. We hope
this survey can serve as a systematic introduction to the research on
long-context LLMs.",2025-02-24T13:19:33Z,http://arxiv.org/pdf/2502.17129v1,['cs.CL']
2505.13205v2,Quantum Knowledge Distillation for Large Language Models,"['Lingxiao Li', 'Yihao Wang', 'Jiacheng Fan', 'Jing Li', 'Sujuan Qin', 'Qiaoyan Wen', 'Fei Gao']","As foundational tools in natural language processing, Large Language Models
(LLMs) have immense parameter scales, which makes deployment and inference
increasingly prohibitive, especially in resource-constrained devices.
Therefore, knowledge distillation for LLMs, i.e., compressing the LLM to a
smaller model, is meaningful. With strong parameter representation capacity,
quantum computing is regarded as a promising solution. Here, we propose a
Quantum knowledge Distillation model for LLMs (QD-LLM) that leverages
variational quantum circuits to learn from LLMs. In classical simulation,
QD-LLM outperforms several mainstream distillation methods on multiple text
classification tasks in terms of both accuracy and efficiency using only 11
qubits. The results reveal an interesting phenomenon that the simulation of
quantum student models may be regarded as a new class of quantum-inspired
classical algorithms. Remarkably, we deploy the obtained circuits on the Baihua
superconducting quantum processor via the Quafu platform to assess practical
feasibility. The model maintains stable inference performance despite hardware
constraints such as decoherence and finite sampling. In summary, QD-LLM marks a
foundational step in connecting quantum computing with LLMs, demonstrating the
feasibility of quantum-native approaches that aim to compress and deploy models
of increasingly larger scales. The code of this article has been open-sourced
at https://github.com/Lilingxiao-bupt/QD-LLM.",2025-05-19T14:56:24Z,http://arxiv.org/pdf/2505.13205v2,['quant-ph']
2506.01042v2,Probing Neural Topology of Large Language Models,"['Yu Zheng', 'Yuan Yuan', 'Yue Zhuo', 'Yong Li', 'Paolo Santi']","Probing large language models (LLMs) has yielded valuable insights into their
internal mechanisms by linking neural activations to interpretable semantics.
However, the complex mechanisms that link neuron's functional co-activation
with the emergent model capabilities remains largely unknown, hindering a
deeper understanding and safer development of LLMs. In this work, we introduce
graph probing, a method for uncovering the functional connectivity of LLM
neurons and relating it to language generation performance. By probing models
across diverse LLM families and scales, we discover a universal predictability
of next-token prediction performance using only neural topology, which persists
even when retaining just 1% of neuron connections. Strikingly, probing on
topology outperforms probing on activation by up to 130.4%, suggesting that
neural topology contains orders of richer information of LLM performance than
neural activation, which can be easily extracted with simple linear or MLP
probes. To explain the dependence between neural topology and language
performance, we identify default networks and hub neurons in LLMs and provide
causal evidence by interventional experiments on multiple benchmarks, showing
that LLMs actually exploit these topological information. Further analyses
suggest that neural topology can be effectively leveraged to improve the
efficiency, reliability, and safety of LLMs through proof-of-concept
applications in model pruning, hallucination detection, and LLM fingerprinting.
Codes and data for the graph probing toolbox are available at
https://github.com/DavyMorgan/llm-graph-probing.",2025-06-01T14:57:03Z,http://arxiv.org/pdf/2506.01042v2,"['cs.CL', 'cs.AI']"
2506.05725v1,Large Language Models are Good Relational Learners,"['Fang Wu', 'Vijay Prakash Dwivedi', 'Jure Leskovec']","Large language models (LLMs) have demonstrated remarkable capabilities across
various domains, yet their application to relational deep learning (RDL)
remains underexplored. Existing approaches adapt LLMs by traversing relational
links between entities in a database and converting the structured data into
flat text documents. Still, this text-based serialization disregards critical
relational structures, introduces redundancy, and often exceeds standard LLM
context lengths. We introduce Rel-LLM, a novel architecture that utilizes a
graph neural network (GNN)- based encoder to generate structured relational
prompts for LLMs within a retrieval-augmented generation (RAG) framework.
Unlike traditional text-based serialization approaches, our method preserves
the inherent relational structure of databases while enabling LLMs to
effectively process and reason over complex entity relationships. Specifically,
the GNN encoder extracts a local subgraph around an entity to build feature
representations that contain relevant entity relationships and temporal
dependencies. These representations are transformed into structured prompts
using a denormalization process, effectively allowing the LLM to reason over
relational structures. Through extensive experiments, we demonstrate that
Rel-LLM outperforms existing methods on key RDL tasks, offering a scalable and
efficient approach to integrating LLMs with structured data sources. Code is
available at https://github.com/smiles724/Rel-LLM.",2025-06-06T04:07:55Z,http://arxiv.org/pdf/2506.05725v1,"['cs.CL', 'cs.AI', 'cs.LG']"
2305.18456v1,Baselines for Identifying Watermarked Large Language Models,"['Leonard Tang', 'Gavin Uberti', 'Tom Shlomi']","We consider the emerging problem of identifying the presence and use of
watermarking schemes in widely used, publicly hosted, closed source large
language models (LLMs). We introduce a suite of baseline algorithms for
identifying watermarks in LLMs that rely on analyzing distributions of output
tokens and logits generated by watermarked and unmarked LLMs. Notably,
watermarked LLMs tend to produce distributions that diverge qualitatively and
identifiably from standard models. Furthermore, we investigate the
identifiability of watermarks at varying strengths and consider the tradeoffs
of each of our identification mechanisms with respect to watermarking scenario.
Along the way, we formalize the specific problem of identifying watermarks in
LLMs, as well as LLM watermarks and watermark detection in general, providing a
framework and foundations for studying them.",2023-05-29T04:26:16Z,http://arxiv.org/pdf/2305.18456v1,"['cs.LG', 'cs.AI', 'cs.CR', 'cs.CY']"
2210.11610v2,Large Language Models Can Self-Improve,"['Jiaxin Huang', 'Shixiang Shane Gu', 'Le Hou', 'Yuexin Wu', 'Xuezhi Wang', 'Hongkun Yu', 'Jiawei Han']","Large Language Models (LLMs) have achieved excellent performances in various
tasks. However, fine-tuning an LLM requires extensive supervision. Human, on
the other hand, may improve their reasoning abilities by self-thinking without
external inputs. In this work, we demonstrate that an LLM is also capable of
self-improving with only unlabeled datasets. We use a pre-trained LLM to
generate ""high-confidence"" rationale-augmented answers for unlabeled questions
using Chain-of-Thought prompting and self-consistency, and fine-tune the LLM
using those self-generated solutions as target outputs. We show that our
approach improves the general reasoning ability of a 540B-parameter LLM
(74.4%->82.1% on GSM8K, 78.2%->83.0% on DROP, 90.0%->94.4% on OpenBookQA, and
63.4%->67.9% on ANLI-A3) and achieves state-of-the-art-level performance,
without any ground truth label. We conduct ablation studies and show that
fine-tuning on reasoning is critical for self-improvement.",2022-10-20T21:53:54Z,http://arxiv.org/pdf/2210.11610v2,['cs.CL']
2307.00524v1,Large Language Models Enable Few-Shot Clustering,"['Vijay Viswanathan', 'Kiril Gashteovski', 'Carolin Lawrence', 'Tongshuang Wu', 'Graham Neubig']","Unlike traditional unsupervised clustering, semi-supervised clustering allows
users to provide meaningful structure to the data, which helps the clustering
algorithm to match the user's intent. Existing approaches to semi-supervised
clustering require a significant amount of feedback from an expert to improve
the clusters. In this paper, we ask whether a large language model can amplify
an expert's guidance to enable query-efficient, few-shot semi-supervised text
clustering. We show that LLMs are surprisingly effective at improving
clustering. We explore three stages where LLMs can be incorporated into
clustering: before clustering (improving input features), during clustering (by
providing constraints to the clusterer), and after clustering (using LLMs
post-correction). We find incorporating LLMs in the first two stages can
routinely provide significant improvements in cluster quality, and that LLMs
enable a user to make trade-offs between cost and accuracy to produce desired
clusters. We release our code and LLM prompts for the public to use.",2023-07-02T09:17:11Z,http://arxiv.org/pdf/2307.00524v1,['cs.CL']
2310.05204v3,Towards Optimizing with Large Language Models,"['Pei-Fu Guo', 'Ying-Hsuan Chen', 'Yun-Da Tsai', 'Shou-De Lin']","In this work, we conduct an assessment of the optimization capabilities of
LLMs across various tasks and data sizes. Each of these tasks corresponds to
unique optimization domains, and LLMs are required to execute these tasks with
interactive prompting. That is, in each optimization step, the LLM generates
new solutions from the past generated solutions with their values, and then the
new solutions are evaluated and considered in the next optimization step.
Additionally, we introduce three distinct metrics for a comprehensive
assessment of task performance from various perspectives. These metrics offer
the advantage of being applicable for evaluating LLM performance across a broad
spectrum of optimization tasks and are less sensitive to variations in test
samples. By applying these metrics, we observe that LLMs exhibit strong
optimization capabilities when dealing with small-sized samples. However, their
performance is significantly influenced by factors like data size and values,
underscoring the importance of further research in the domain of optimization
tasks for LLMs.",2023-10-08T15:35:00Z,http://arxiv.org/pdf/2310.05204v3,['cs.LG']
2311.01866v1,Towards Concept-Aware Large Language Models,"['Chen Shani', 'Jilles Vreeken', 'Dafna Shahaf']","Concepts play a pivotal role in various human cognitive functions, including
learning, reasoning and communication. However, there is very little work on
endowing machines with the ability to form and reason with concepts. In
particular, state-of-the-art large language models (LLMs) work at the level of
tokens, not concepts.
  In this work, we analyze how well contemporary LLMs capture human concepts
and their structure. We then discuss ways to develop concept-aware LLMs, taking
place at different stages of the pipeline. We sketch a method for pretraining
LLMs using concepts, and also explore the simpler approach that uses the output
of existing LLMs. Despite its simplicity, our proof-of-concept is shown to
better match human intuition, as well as improve the robustness of predictions.
These preliminary results underscore the promise of concept-aware LLMs.",2023-11-03T12:19:22Z,http://arxiv.org/pdf/2311.01866v1,"['cs.CL', 'cs.AI']"
2311.08838v2,Disinformation Capabilities of Large Language Models,"['Ivan Vykopal', 'Matúš Pikuliak', 'Ivan Srba', 'Robert Moro', 'Dominik Macko', 'Maria Bielikova']","Automated disinformation generation is often listed as an important risk
associated with large language models (LLMs). The theoretical ability to flood
the information space with disinformation content might have dramatic
consequences for societies around the world. This paper presents a
comprehensive study of the disinformation capabilities of the current
generation of LLMs to generate false news articles in the English language. In
our study, we evaluated the capabilities of 10 LLMs using 20 disinformation
narratives. We evaluated several aspects of the LLMs: how good they are at
generating news articles, how strongly they tend to agree or disagree with the
disinformation narratives, how often they generate safety warnings, etc. We
also evaluated the abilities of detection models to detect these articles as
LLM-generated. We conclude that LLMs are able to generate convincing news
articles that agree with dangerous disinformation narratives.",2023-11-15T10:25:30Z,http://arxiv.org/pdf/2311.08838v2,['cs.CL']
2402.01719v3,Measuring Moral Inconsistencies in Large Language Models,"['Vamshi Krishna Bonagiri', 'Sreeram Vennam', 'Manas Gaur', 'Ponnurangam Kumaraguru']","A Large Language Model (LLM) is considered consistent if semantically
equivalent prompts produce semantically equivalent responses. Despite recent
advancements showcasing the impressive capabilities of LLMs in conversational
systems, we show that even state-of-the-art LLMs are highly inconsistent in
their generations, questioning their reliability. Prior research has tried to
measure this with task-specific accuracy. However, this approach is unsuitable
for moral scenarios, such as the trolley problem, with no ""correct"" answer. To
address this issue, we propose a novel information-theoretic measure called
Semantic Graph Entropy (SGE) to measure the consistency of an LLM in moral
scenarios. We leverage ""Rules of Thumb"" (RoTs) to explain a model's
decision-making strategies and further enhance our metric. Compared to existing
consistency metrics, SGE correlates better with human judgments across five
LLMs. In the future, we aim to investigate the root causes of LLM
inconsistencies and propose improvements.",2024-01-26T18:05:47Z,http://arxiv.org/pdf/2402.01719v3,"['cs.CL', 'cs.LG']"
2404.01475v2,Are large language models superhuman chemists?,"['Adrian Mirza', 'Nawaf Alampara', 'Sreekanth Kunchapu', 'Martiño Ríos-García', 'Benedict Emoekabu', 'Aswanth Krishnan', 'Tanya Gupta', 'Mara Schilling-Wilhelmi', 'Macjonathan Okereke', 'Anagha Aneesh', 'Amir Mohammad Elahi', 'Mehrdad Asgari', 'Juliane Eberhardt', 'Hani M. Elbeheiry', 'María Victoria Gil', 'Maximilian Greiner', 'Caroline T. Holick', 'Christina Glaubitz', 'Tim Hoffmann', 'Abdelrahman Ibrahim', 'Lea C. Klepsch', 'Yannik Köster', 'Fabian Alexander Kreth', 'Jakob Meyer', 'Santiago Miret', 'Jan Matthias Peschel', 'Michael Ringleb', 'Nicole Roesner', 'Johanna Schreiber', 'Ulrich S. Schubert', 'Leanne M. Stafast', 'Dinga Wonanke', 'Michael Pieler', 'Philippe Schwaller', 'Kevin Maik Jablonka']","Large language models (LLMs) have gained widespread interest due to their
ability to process human language and perform tasks on which they have not been
explicitly trained.
  However, we possess only a limited systematic understanding of the chemical
capabilities of LLMs, which would be required to improve models and mitigate
potential harm. Here, we introduce ""ChemBench,"" an automated framework for
evaluating the chemical knowledge and reasoning abilities of state-of-the-art
LLMs against the expertise of chemists.
  We curated more than 2,700 question-answer pairs, evaluated leading open- and
closed-source LLMs, and found that the best models outperformed the best human
chemists in our study on average. However, the models struggle with some basic
tasks and provide overconfident predictions.
  These findings reveal LLMs' impressive chemical capabilities while
emphasizing the need for further research to improve their safety and
usefulness. They also suggest adapting chemistry education and show the value
of benchmarking frameworks for evaluating LLMs in specific domains.",2024-04-01T20:56:25Z,http://arxiv.org/pdf/2404.01475v2,"['cs.LG', 'cond-mat.mtrl-sci', 'cs.AI', 'physics.chem-ph']"
2405.06808v2,Large Language Model in Financial Regulatory Interpretation,"['Zhiyu Cao', 'Zachary Feinstein']","This study explores the innovative use of Large Language Models (LLMs) as
analytical tools for interpreting complex financial regulations. The primary
objective is to design effective prompts that guide LLMs in distilling verbose
and intricate regulatory texts, such as the Basel III capital requirement
regulations, into a concise mathematical framework that can be subsequently
translated into actionable code. This novel approach aims to streamline the
implementation of regulatory mandates within the financial reporting and risk
management systems of global banking institutions. A case study was conducted
to assess the performance of various LLMs, demonstrating that GPT-4 outperforms
other models in processing and collecting necessary information, as well as
executing mathematical calculations. The case study utilized numerical
simulations with asset holdings -- including fixed income, equities, currency
pairs, and commodities -- to demonstrate how LLMs can effectively implement the
Basel III capital adequacy requirements.
  Keywords: Large Language Models, Prompt Engineering, LLMs in Finance, Basel
III, Minimum Capital Requirements, LLM Ethics",2024-05-10T20:45:40Z,http://arxiv.org/pdf/2405.06808v2,"['q-fin.RM', 'cs.AI', 'cs.CL']"
2407.19807v2,Cool-Fusion: Fuse Large Language Models without Training,"['Cong Liu', 'Xiaojun Quan', 'Yan Pan', 'Liang Lin', 'Weigang Wu', 'Xu Chen']","We focus on the problem of fusing two or more heterogeneous large language
models (LLMs) to leverage their complementary strengths. One of the challenges
of model fusion is high computational load, specifically in fine-tuning or
aligning vocabularies. To address this, we propose Cool-Fusion, a simple yet
effective approach that fuses the knowledge of source LLMs, which does not
require training. Unlike ensemble methods, Cool-Fusion is applicable to any set
of source LLMs that have different vocabularies. To overcome the vocabulary
discrepancies among LLMs, we ensemble LLMs on text level, allowing them to
rerank the generated texts by each other with different granularities.
Extensive experiments have been conducted across a variety of benchmark
datasets. On GSM8K, Cool-Fusion increases accuracy from three strong source
LLMs by a significant margin of 17.4\%.",2024-07-29T09:02:19Z,http://arxiv.org/pdf/2407.19807v2,['cs.CL']
2408.14380v1,Probing Causality Manipulation of Large Language Models,"['Chenyang Zhang', 'Haibo Tong', 'Bin Zhang', 'Dongyu Zhang']","Large language models (LLMs) have shown various ability on natural language
processing, including problems about causality. It is not intuitive for LLMs to
command causality, since pretrained models usually work on statistical
associations, and do not focus on causes and effects in sentences. So that
probing internal manipulation of causality is necessary for LLMs. This paper
proposes a novel approach to probe causality manipulation hierarchically, by
providing different shortcuts to models and observe behaviors. We exploit
retrieval augmented generation (RAG) and in-context learning (ICL) for models
on a designed causality classification task. We conduct experiments on
mainstream LLMs, including GPT-4 and some smaller and domain-specific models.
Our results suggest that LLMs can detect entities related to causality and
recognize direct causal relationships. However, LLMs lack specialized cognition
for causality, merely treating them as part of the global semantic of the
sentence.",2024-08-26T16:00:41Z,http://arxiv.org/pdf/2408.14380v1,"['cs.CL', 'cs.AI']"
2410.06617v5,Learning Evolving Tools for Large Language Models,"['Guoxin Chen', 'Zhong Zhang', 'Xin Cong', 'Fangda Guo', 'Yesai Wu', 'Yankai Lin', 'Wenzheng Feng', 'Yasheng Wang']","Tool learning enables large language models (LLMs) to interact with external
tools and APIs, greatly expanding the application scope of LLMs. However, due
to the dynamic nature of external environments, these tools and APIs may become
outdated over time, preventing LLMs from correctly invoking tools. Existing
research primarily focuses on static environments and overlooks this issue,
limiting the adaptability of LLMs in real-world applications. In this paper, we
propose ToolEVO, a novel framework designed to enhance the adaptive and
reflective capabilities of LLMs against tool variability. By leveraging Monte
Carlo Tree Search, ToolEVO facilitates active exploration and interaction of
LLMs within dynamic environments, allowing for autonomous self-reflection and
self-updating of tool usage based on environmental feedback. Additionally, we
introduce ToolQA-D, a benchmark specifically designed to evaluate the impact of
tool variability. Extensive experiments demonstrate the effectiveness and
stability of our approach, highlighting the importance of adaptability to tool
variability for effective tool learning. Code:
https://github.com/Chen-GX/ToolEVO",2024-10-09T07:14:45Z,http://arxiv.org/pdf/2410.06617v5,"['cs.CL', 'cs.AI']"
2410.09817v2,Reverse Modeling in Large Language Models,"['Sicheng Yu', 'Yuanchen Xu', 'Cunxiao Du', 'Yanying Zhou', 'Minghui Qiu', 'Qianru Sun', 'Hao Zhang', 'Jiawei Wu']","Humans are accustomed to reading and writing in a forward manner, and this
natural bias extends to text understanding in auto-regressive large language
models (LLMs). This paper investigates whether LLMs, like humans, struggle with
reverse modeling, specifically with reversed text inputs. We found that
publicly available pre-trained LLMs cannot understand such inputs. However,
LLMs trained from scratch with both forward and reverse texts can understand
them equally well during inference across multiple languages. Our case study
shows that different-content texts result in different losses if input (to
LLMs) in different directions -- some get lower losses for forward while some
for reverse. This leads us to a simple and nice solution for data selection
based on the loss differences between forward and reverse directions. Using our
selected data in continued pretraining can boost LLMs' performance by a large
margin across different language understanding benchmarks.",2024-10-13T12:24:03Z,http://arxiv.org/pdf/2410.09817v2,['cs.CL']
2502.02289v1,Evalita-LLM: Benchmarking Large Language Models on Italian,"['Bernardo Magnini', 'Roberto Zanoli', 'Michele Resta', 'Martin Cimmino', 'Paolo Albano', 'Marco Madeddu', 'Viviana Patti']","We describe Evalita-LLM, a new benchmark designed to evaluate Large Language
Models (LLMs) on Italian tasks. The distinguishing and innovative features of
Evalita-LLM are the following: (i) all tasks are native Italian, avoiding
issues of translating from Italian and potential cultural biases; (ii) in
addition to well established multiple-choice tasks, the benchmark includes
generative tasks, enabling more natural interaction with LLMs; (iii) all tasks
are evaluated against multiple prompts, this way mitigating the model
sensitivity to specific prompts and allowing a fairer and objective evaluation.
We propose an iterative methodology, where candidate tasks and candidate
prompts are validated against a set of LLMs used for development. We report
experimental results from the benchmark's development phase, and provide
performance statistics for several state-of-the-art LLMs.",2025-02-04T12:58:19Z,http://arxiv.org/pdf/2502.02289v1,['cs.CL']
2501.02486v2,LLMPC: Large Language Model Predictive Control,['Gabriel Maher'],"Recent advancements in prompting techniques for Large Language Models (LLMs)
have improved their reasoning, planning, and action abilities. This paper
examines these prompting techniques through the lens of model predictive
control (MPC). We show that LLMs act as implicit planning cost function
minimizers when planning prompts are used. We propose a unified MPC framework
for planning with LLMs and demonstrate improved performance over few shot
prompting on several planning benchmarks.",2025-01-05T09:37:23Z,http://arxiv.org/pdf/2501.02486v2,"['cs.AI', 'cs.CL']"
2504.03931v2,NAACL2025 Tutorial: Adaptation of Large Language Models,"['Zixuan Ke', 'Yifei Ming', 'Shafiq Joty']","This tutorial on adaptation of LLMs is designed to address the growing demand
for models that go beyond the static capabilities of generic LLMs by providing
an overview of dynamic, domain-specific, and task-adaptive LLM adaptation
techniques. While general LLMs have demonstrated strong generalization across a
variety of tasks, they often struggle to perform well in specialized domains
such as finance, healthcare, and code generation for underrepresented
languages. Additionally, their static nature limits their ability to evolve
with the changing world, and they are often extremely large in size, making
them impractical and costly to deploy at scale. As a result, the adaptation of
LLMs has drawn much attention since the birth of LLMs and is of core
importance, both for industry, which focuses on serving its targeted users, and
academia, which can greatly benefit from small but powerful LLMs. To address
this gap, this tutorial aims to provide an overview of the LLM adaptation
techniques. We start with an introduction to LLM adaptation, from both the data
perspective and the model perspective. We then emphasize how the evaluation
metrics and benchmarks are different from other techniques. After establishing
the problems, we explore various adaptation techniques. We categorize
adaptation techniques into two main families. The first is parametric knowledge
adaptation, which focuses on updating the parametric knowledge within LLMs.
Additionally, we will discuss real-time adaptation techniques, including model
editing, which allows LLMs to be updated dynamically in production
environments. The second kind of adaptation is semi-parametric knowledge
adaptation, where the goal is to update LLM parameters to better leverage
external knowledge or tools through techniques like retrieval-augmented
generation (RAG) and agent-based systems.",2025-04-04T20:57:41Z,http://arxiv.org/pdf/2504.03931v2,"['cs.CL', 'cs.AI']"
2302.11957v1,Sentence Simplification via Large Language Models,"['Yutao Feng', 'Jipeng Qiang', 'Yun Li', 'Yunhao Yuan', 'Yi Zhu']","Sentence Simplification aims to rephrase complex sentences into simpler
sentences while retaining original meaning. Large Language models (LLMs) have
demonstrated the ability to perform a variety of natural language processing
tasks. However, it is not yet known whether LLMs can be served as a
high-quality sentence simplification system. In this work, we empirically
analyze the zero-/few-shot learning ability of LLMs by evaluating them on a
number of benchmark test sets. Experimental results show LLMs outperform
state-of-the-art sentence simplification methods, and are judged to be on a par
with human annotators.",2023-02-23T12:11:58Z,http://arxiv.org/pdf/2302.11957v1,"['cs.CL', 'cs.AI']"
2304.10436v1,Safety Assessment of Chinese Large Language Models,"['Hao Sun', 'Zhexin Zhang', 'Jiawen Deng', 'Jiale Cheng', 'Minlie Huang']","With the rapid popularity of large language models such as ChatGPT and GPT-4,
a growing amount of attention is paid to their safety concerns. These models
may generate insulting and discriminatory content, reflect incorrect social
values, and may be used for malicious purposes such as fraud and dissemination
of misleading information. Evaluating and enhancing their safety is
particularly essential for the wide application of large language models
(LLMs). To further promote the safe deployment of LLMs, we develop a Chinese
LLM safety assessment benchmark. Our benchmark explores the comprehensive
safety performance of LLMs from two perspectives: 8 kinds of typical safety
scenarios and 6 types of more challenging instruction attacks. Our benchmark is
based on a straightforward process in which it provides the test prompts and
evaluates the safety of the generated responses from the evaluated model. In
evaluation, we utilize the LLM's strong evaluation ability and develop it as a
safety evaluator by prompting. On top of this benchmark, we conduct safety
assessments and analyze 15 LLMs including the OpenAI GPT series and other
well-known Chinese LLMs, where we observe some interesting findings. For
example, we find that instruction attacks are more likely to expose safety
issues of all LLMs. Moreover, to promote the development and deployment of
safe, responsible, and ethical AI, we publicly release SafetyPrompts including
100k augmented prompts and responses by LLMs.",2023-04-20T16:27:35Z,http://arxiv.org/pdf/2304.10436v1,['cs.CL']
2307.06435v10,A Comprehensive Overview of Large Language Models,"['Humza Naveed', 'Asad Ullah Khan', 'Shi Qiu', 'Muhammad Saqib', 'Saeed Anwar', 'Muhammad Usman', 'Naveed Akhtar', 'Nick Barnes', 'Ajmal Mian']","Large Language Models (LLMs) have recently demonstrated remarkable
capabilities in natural language processing tasks and beyond. This success of
LLMs has led to a large influx of research contributions in this direction.
These works encompass diverse topics such as architectural innovations, better
training strategies, context length improvements, fine-tuning, multi-modal
LLMs, robotics, datasets, benchmarking, efficiency, and more. With the rapid
development of techniques and regular breakthroughs in LLM research, it has
become considerably challenging to perceive the bigger picture of the advances
in this direction. Considering the rapidly emerging plethora of literature on
LLMs, it is imperative that the research community is able to benefit from a
concise yet comprehensive overview of the recent developments in this field.
This article provides an overview of the existing literature on a broad range
of LLM-related concepts. Our self-contained comprehensive overview of LLMs
discusses relevant background concepts along with covering the advanced topics
at the frontier of research in LLMs. This review article is intended to not
only provide a systematic survey but also a quick comprehensive reference for
the researchers and practitioners to draw insights from extensive informative
summaries of the existing works to advance the LLM research.",2023-07-12T20:01:52Z,http://arxiv.org/pdf/2307.06435v10,['cs.CL']
2308.16361v2,Large Language Models as Data Preprocessors,"['Haochen Zhang', 'Yuyang Dong', 'Chuan Xiao', 'Masafumi Oyamada']","Large Language Models (LLMs), typified by OpenAI's GPT, have marked a
significant advancement in artificial intelligence. Trained on vast amounts of
text data, LLMs are capable of understanding and generating human-like text
across a diverse range of topics. This study expands on the applications of
LLMs, exploring their potential in data preprocessing, a critical stage in data
mining and analytics applications. Aiming at tabular data, we delve into the
applicability of state-of-the-art LLMs such as GPT-4 and GPT-4o for a series of
preprocessing tasks, including error detection, data imputation, schema
matching, and entity matching. Alongside showcasing the inherent capabilities
of LLMs, we highlight their limitations, particularly in terms of computational
expense and inefficiency. We propose an LLM-based framework for data
preprocessing, which integrates cutting-edge prompt engineering techniques,
coupled with traditional methods like contextualization and feature selection,
to improve the performance and efficiency of these models. The effectiveness of
LLMs in data preprocessing is evaluated through an experimental study spanning
a variety of public datasets. GPT-4 emerged as a standout, achieving 100\%
accuracy or F1 score on 4 of these datasets, suggesting LLMs' immense potential
in these tasks. Despite certain limitations, our study underscores the promise
of LLMs in this domain and anticipates future developments to overcome current
hurdles.",2023-08-30T23:28:43Z,http://arxiv.org/pdf/2308.16361v2,"['cs.AI', 'cs.DB']"
2310.00034v2,PB-LLM: Partially Binarized Large Language Models,"['Yuzhang Shang', 'Zhihang Yuan', 'Qiang Wu', 'Zhen Dong']","This paper explores network binarization, a radical form of quantization,
compressing model weights to a single bit, specifically for Large Language
Models (LLMs) compression. Due to previous binarization methods collapsing
LLMs, we propose a novel approach, Partially-Binarized LLM (PB-LLM), which can
achieve extreme low-bit quantization while maintaining the linguistic reasoning
capacity of quantized LLMs. Specifically, our exploration first uncovers the
ineffectiveness of naive applications of existing binarization algorithms and
highlights the imperative role of salient weights in achieving low-bit
quantization. Thus, PB-LLM filters a small ratio of salient weights during
binarization, allocating them to higher-bit storage, i.e.,
partially-binarization. PB-LLM is extended to recover the capacities of
quantized LMMs, by analyzing from the perspective of post-training quantization
(PTQ) and quantization-aware training (QAT). Under PTQ, combining the concepts
from GPTQ, we reconstruct the binarized weight matrix guided by the Hessian
matrix and successfully recover the reasoning capacity of PB-LLM in low-bit.
Under QAT, we freeze the salient weights during training, explore the
derivation of optimal scaling factors crucial for minimizing the quantization
error, and propose a scaling mechanism based on this derived scaling strategy
for residual binarized weights. Those explorations and the developed
methodologies significantly contribute to rejuvenating the performance of
low-bit quantized LLMs and present substantial advancements in the field of
network binarization for LLMs.The code is available at
https://github.com/hahnyuan/BinaryLLM.",2023-09-29T14:35:27Z,http://arxiv.org/pdf/2310.00034v2,"['cs.LG', 'cs.AI', 'cs.CL']"
2310.07554v2,Retrieve Anything To Augment Large Language Models,"['Peitian Zhang', 'Shitao Xiao', 'Zheng Liu', 'Zhicheng Dou', 'Jian-Yun Nie']","Large language models (LLMs) face significant challenges stemming from their
inherent limitations in knowledge, memory, alignment, and action. These
challenges cannot be addressed by LLMs alone, but should rely on assistance
from the external world, such as knowledge base, memory store, demonstration
examples, and tools. Retrieval augmentation stands as a vital mechanism for
bridging the gap between LLMs and the external assistance. However,
conventional methods encounter two pressing issues. On the one hand, the
general-purpose retrievers are not properly optimized for the retrieval
augmentation of LLMs. On the other hand, the task-specific retrievers lack the
required versatility, hindering their performance across the diverse retrieval
augmentation scenarios.
  In this work, we present a novel approach, the LLM-Embedder, which
comprehensively supports the diverse retrieval augmentation needs of LLMs with
one unified embedding model. Training such a unified model is non-trivial, as
various retrieval tasks aim to capture distinct semantic relationships, often
subject to mutual interference. To address this challenge, we systematically
optimize our training methodology. This includes reward formulation based on
LLMs' feedback, the stabilization of knowledge distillation, multi-task
fine-tuning with explicit instructions, and homogeneous in-batch negative
sampling. These optimization strategies contribute to the outstanding empirical
performance of the LLM-Embedder. Notably, it yields remarkable enhancements in
retrieval augmentation for LLMs, surpassing both general-purpose and
task-specific retrievers in various evaluation scenarios. Our checkpoint and
source code are publicly available at
https://github.com/FlagOpen/FlagEmbedding.",2023-10-11T14:59:53Z,http://arxiv.org/pdf/2310.07554v2,['cs.IR']
2311.07226v1,Large Language Models for Robotics: A Survey,"['Fanlong Zeng', 'Wensheng Gan', 'Yongheng Wang', 'Ning Liu', 'Philip S. Yu']","The human ability to learn, generalize, and control complex manipulation
tasks through multi-modality feedback suggests a unique capability, which we
refer to as dexterity intelligence. Understanding and assessing this
intelligence is a complex task. Amidst the swift progress and extensive
proliferation of large language models (LLMs), their applications in the field
of robotics have garnered increasing attention. LLMs possess the ability to
process and generate natural language, facilitating efficient interaction and
collaboration with robots. Researchers and engineers in the field of robotics
have recognized the immense potential of LLMs in enhancing robot intelligence,
human-robot interaction, and autonomy. Therefore, this comprehensive review
aims to summarize the applications of LLMs in robotics, delving into their
impact and contributions to key areas such as robot control, perception,
decision-making, and path planning. We first provide an overview of the
background and development of LLMs for robotics, followed by a description of
the benefits of LLMs for robotics and recent advancements in robotics models
based on LLMs. We then delve into the various techniques used in the model,
including those employed in perception, decision-making, control, and
interaction. Finally, we explore the applications of LLMs in robotics and some
potential challenges they may face in the near future. Embodied intelligence is
the future of intelligent science, and LLMs-based robotics is one of the
promising but challenging paths to achieve this.",2023-11-13T10:46:35Z,http://arxiv.org/pdf/2311.07226v1,"['cs.RO', 'cs.AI']"
2312.15922v1,Towards Probing Contact Center Large Language Models,"['Varun Nathan', 'Ayush Kumar', 'Digvijay Ingle', 'Jithendra Vepa']","Fine-tuning large language models (LLMs) with domain-specific instructions
has emerged as an effective method to enhance their domain-specific
understanding. Yet, there is limited work that examines the core
characteristics acquired during this process. In this study, we benchmark the
fundamental characteristics learned by contact-center (CC) specific instruction
fine-tuned LLMs with out-of-the-box (OOB) LLMs via probing tasks encompassing
conversational, channel, and automatic speech recognition (ASR) properties. We
explore different LLM architectures (Flan-T5 and Llama), sizes (3B, 7B, 11B,
13B), and fine-tuning paradigms (full fine-tuning vs PEFT). Our findings reveal
remarkable effectiveness of CC-LLMs on the in-domain downstream tasks, with
improvement in response acceptability by over 48% compared to OOB-LLMs.
Additionally, we compare the performance of OOB-LLMs and CC-LLMs on the widely
used SentEval dataset, and assess their capabilities in terms of surface,
syntactic, and semantic information through probing tasks. Intriguingly, we
note a relatively consistent performance of probing classifiers on the set of
probing tasks. Our observations indicate that CC-LLMs, while outperforming
their out-of-the-box counterparts, exhibit a tendency to rely less on encoding
surface, syntactic, and semantic properties, highlighting the intricate
interplay between domain-specific adaptation and probing task performance
opening up opportunities to explore behavior of fine-tuned language models in
specialized contexts.",2023-12-26T07:34:39Z,http://arxiv.org/pdf/2312.15922v1,['cs.CL']
2401.02789v1,Large Language Models in Plant Biology,"['Hilbert Yuen In Lam', 'Xing Er Ong', 'Marek Mutwil']","Large Language Models (LLMs), such as ChatGPT, have taken the world by storm
and have passed certain forms of the Turing test. However, LLMs are not limited
to human language and analyze sequential data, such as DNA, protein, and gene
expression. The resulting foundation models can be repurposed to identify the
complex patterns within the data, resulting in powerful, multi-purpose
prediction tools able to explain cellular systems. This review outlines the
different types of LLMs and showcases their recent uses in biology. Since LLMs
have not yet been embraced by the plant community, we also cover how these
models can be deployed for the plant kingdom.",2024-01-05T12:59:20Z,http://arxiv.org/pdf/2401.02789v1,"['q-bio.GN', 'cs.CL']"
2404.00806v4,Algorithmic Collusion by Large Language Models,"['Sara Fish', 'Yannai A. Gonczarowski', 'Ran I. Shorrer']","The rise of algorithmic pricing raises concerns of algorithmic collusion. We
conduct experiments with algorithmic pricing agents based on Large Language
Models (LLMs). We find that LLM-based pricing agents quickly and autonomously
reach supracompetitive prices and profits in oligopoly settings and that
variation in seemingly innocuous phrases in LLM instructions (""prompts"") may
substantially influence the degree of supracompetitive pricing. Off-path
analysis using novel techniques uncovers price-war concerns as contributing to
these phenomena. Our results extend to auction settings. Our findings uncover
unique challenges to any future regulation of LLM-based pricing agents, and
AI-based pricing agents more broadly.",2024-03-31T21:43:05Z,http://arxiv.org/pdf/2404.00806v4,"['econ.GN', 'cs.AI', 'cs.GT', 'q-fin.EC']"
2404.08706v2,Game Generation via Large Language Models,"['Chengpeng Hu', 'Yunlong Zhao', 'Jialin Liu']","Recently, the emergence of large language models (LLMs) has unlocked new
opportunities for procedural content generation. However, recent attempts
mainly focus on level generation for specific games with defined game rules
such as Super Mario Bros. and Zelda. This paper investigates the game
generation via LLMs. Based on video game description language, this paper
proposes an LLM-based framework to generate game rules and levels
simultaneously. Experiments demonstrate how the framework works with prompts
considering different combinations of context. Our findings extend the current
applications of LLMs and offer new insights for generating new games in the
area of procedural content generation.",2024-04-11T10:06:05Z,http://arxiv.org/pdf/2404.08706v2,['cs.AI']
2405.03695v1,Evaluating Large Language Models for Material Selection,"['Daniele Grandi', 'Yash Patawari Jain', 'Allin Groom', 'Brandon Cramer', 'Christopher McComb']","Material selection is a crucial step in conceptual design due to its
significant impact on the functionality, aesthetics, manufacturability, and
sustainability impact of the final product. This study investigates the use of
Large Language Models (LLMs) for material selection in the product design
process and compares the performance of LLMs against expert choices for various
design scenarios. By collecting a dataset of expert material preferences, the
study provides a basis for evaluating how well LLMs can align with expert
recommendations through prompt engineering and hyperparameter tuning. The
divergence between LLM and expert recommendations is measured across different
model configurations, prompt strategies, and temperature settings. This
approach allows for a detailed analysis of factors influencing the LLMs'
effectiveness in recommending materials. The results from this study highlight
two failure modes, and identify parallel prompting as a useful
prompt-engineering method when using LLMs for material selection. The findings
further suggest that, while LLMs can provide valuable assistance, their
recommendations often vary significantly from those of human experts. This
discrepancy underscores the need for further research into how LLMs can be
better tailored to replicate expert decision-making in material selection. This
work contributes to the growing body of knowledge on how LLMs can be integrated
into the design process, offering insights into their current limitations and
potential for future improvements.",2024-04-23T18:53:33Z,http://arxiv.org/pdf/2405.03695v1,['cs.CL']
2407.15071v1,Relational Database Augmented Large Language Model,"['Zongyue Qin', 'Chen Luo', 'Zhengyang Wang', 'Haoming Jiang', 'Yizhou Sun']","Large language models (LLMs) excel in many natural language processing (NLP)
tasks. However, since LLMs can only incorporate new knowledge through training
or supervised fine-tuning processes, they are unsuitable for applications that
demand precise, up-to-date, and private information not available in the
training corpora. This precise, up-to-date, and private information is
typically stored in relational databases. Thus, a promising solution is to
augment LLMs with the inclusion of relational databases as external memory.
This can ensure the timeliness, correctness, and consistency of data, and
assist LLMs in performing complex arithmetic operations beyond their inherent
capabilities. However, bridging the gap between LLMs and relational databases
is challenging. It requires the awareness of databases and data values stored
in databases to select correct databases and issue correct SQL queries.
Besides, it is necessary for the external memory to be independent of the LLM
to meet the needs of real-world applications. We introduce a novel LLM-agnostic
memory architecture comprising a database selection memory, a data value
memory, and relational databases. And we design an elegant pipeline to retrieve
information from it. Besides, we carefully design the prompts to instruct the
LLM to maximize the framework's potential. To evaluate our method, we compose a
new dataset with various types of questions. Experimental results show that our
framework enables LLMs to effectively answer database-related questions, which
is beyond their direct ability.",2024-07-21T06:19:10Z,http://arxiv.org/pdf/2407.15071v1,"['cs.DB', 'cs.CL']"
2408.08707v2,Beam Prediction based on Large Language Models,"['Yucheng Sheng', 'Kai Huang', 'Le Liang', 'Peng Liu', 'Shi Jin', 'Geoffrey Ye Li']","In this letter, we use large language models (LLMs) to develop a
high-performing and robust beam prediction method. We formulate the millimeter
wave (mmWave) beam prediction problem as a time series forecasting task, where
the historical observations are aggregated through cross-variable attention and
then transformed into text-based representations using a trainable tokenizer.
By leveraging the prompt-as-prefix (PaP) technique for contextual enrichment,
our method harnesses the power of LLMs to predict future optimal beams.
Simulation results demonstrate that our LLM-based approach outperforms
traditional learning-based models in prediction accuracy as well as robustness,
highlighting the significant potential of LLMs in enhancing wireless
communication systems.",2024-08-16T12:40:01Z,http://arxiv.org/pdf/2408.08707v2,"['cs.LG', 'cs.AI']"
2411.00027v3,Personalization of Large Language Models: A Survey,"['Zhehao Zhang', 'Ryan A. Rossi', 'Branislav Kveton', 'Yijia Shao', 'Diyi Yang', 'Hamed Zamani', 'Franck Dernoncourt', 'Joe Barrow', 'Tong Yu', 'Sungchul Kim', 'Ruiyi Zhang', 'Jiuxiang Gu', 'Tyler Derr', 'Hongjie Chen', 'Junda Wu', 'Xiang Chen', 'Zichao Wang', 'Subrata Mitra', 'Nedim Lipka', 'Nesreen Ahmed', 'Yu Wang']","Personalization of Large Language Models (LLMs) has recently become
increasingly important with a wide range of applications. Despite the
importance and recent progress, most existing works on personalized LLMs have
focused either entirely on (a) personalized text generation or (b) leveraging
LLMs for personalization-related downstream applications, such as
recommendation systems. In this work, we bridge the gap between these two
separate main directions for the first time by introducing a taxonomy for
personalized LLM usage and summarizing the key differences and challenges. We
provide a formalization of the foundations of personalized LLMs that
consolidates and expands notions of personalization of LLMs, defining and
discussing novel facets of personalization, usage, and desiderata of
personalized LLMs. We then unify the literature across these diverse fields and
usage scenarios by proposing systematic taxonomies for the granularity of
personalization, personalization techniques, datasets, evaluation methods, and
applications of personalized LLMs. Finally, we highlight challenges and
important open problems that remain to be addressed. By unifying and surveying
recent research using the proposed taxonomies, we aim to provide a clear guide
to the existing literature and different facets of personalization in LLMs,
empowering both researchers and practitioners.",2024-10-29T04:01:11Z,http://arxiv.org/pdf/2411.00027v3,['cs.CL']
2412.07031v2,Large Language Models: An Applied Econometric Framework,"['Jens Ludwig', 'Sendhil Mullainathan', 'Ashesh Rambachan']","How can we use the novel capacities of large language models (LLMs) in
empirical research? And how can we do so while accounting for their
limitations, which are themselves only poorly understood? We develop an
econometric framework to answer this question that distinguishes between two
types of empirical tasks. Using LLMs for prediction problems (including
hypothesis generation) is valid under one condition: no ``leakage'' between the
LLM's training dataset and the researcher's sample. No leakage can be ensured
by using open-source LLMs with documented training data and published weights.
Using LLM outputs for estimation problems to automate the measurement of some
economic concept (expressed either by some text or from human subjects)
requires the researcher to collect at least some validation data: without such
data, the errors of the LLM's automation cannot be assessed and accounted for.
As long as these steps are taken, LLM outputs can be used in empirical research
with the familiar econometric guarantees we desire. Using two illustrative
applications to finance and political economy, we find that these requirements
are stringent; when they are violated, the limitations of LLMs now result in
unreliable empirical estimates. Our results suggest the excitement around the
empirical uses of LLMs is warranted -- they allow researchers to effectively
use even small amounts of language data for both prediction and estimation --
but only with these safeguards in place.",2024-12-09T22:37:48Z,http://arxiv.org/pdf/2412.07031v2,"['econ.EM', 'cs.AI']"
2503.23037v2,"Agentic Large Language Models, a survey","['Aske Plaat', 'Max van Duijn', 'Niki van Stein', 'Mike Preuss', 'Peter van der Putten', 'Kees Joost Batenburg']","There is great interest in agentic LLMs, large language models that act as
agents. We review the growing body of work in this area and provide a research
agenda. Agentic LLMs are LLMs that (1) reason, (2) act, and (3) interact. We
organize the literature according to these three categories. The research in
the first category focuses on reasoning, reflection, and retrieval, aiming to
improve decision making; the second category focuses on action models, robots,
and tools, aiming for agents that act as useful assistants; the third category
focuses on multi-agent systems, aiming for collaborative task solving and
simulating interaction to study emergent social behavior. We find that works
mutually benefit from results in other categories: retrieval enables tool use,
reflection improves multi-agent collaboration, and reasoning benefits all
categories. We discuss applications of agentic LLMs and provide an agenda for
further research. Important applications are in medical diagnosis, logistics
and financial market analysis. Meanwhile, self-reflective agents playing roles
and interacting with one another augment the process of scientific research
itself. Further, agentic LLMs may provide a solution for the problem of LLMs
running out of training data: inference-time behavior generates new training
states, such that LLMs can keep learning without needing ever larger datasets.
We note that there is risk associated with LLM assistants taking action in the
real world, while agentic LLMs are also likely to benefit society.",2025-03-29T11:02:20Z,http://arxiv.org/pdf/2503.23037v2,"['cs.AI', 'cs.CL', 'cs.LG']"
2505.00467v2,Red Teaming Large Language Models for Healthcare,"['Vahid Balazadeh', 'Michael Cooper', 'David Pellow', 'Atousa Assadi', 'Jennifer Bell', 'Mark Coatsworth', 'Kaivalya Deshpande', 'Jim Fackler', 'Gabriel Funingana', 'Spencer Gable-Cook', 'Anirudh Gangadhar', 'Abhishek Jaiswal', 'Sumanth Kaja', 'Christopher Khoury', 'Amrit Krishnan', 'Randy Lin', 'Kaden McKeen', 'Sara Naimimohasses', 'Khashayar Namdar', 'Aviraj Newatia', 'Allan Pang', 'Anshul Pattoo', 'Sameer Peesapati', 'Diana Prepelita', 'Bogdana Rakova', 'Saba Sadatamin', 'Rafael Schulman', 'Ajay Shah', 'Syed Azhar Shah', 'Syed Ahmar Shah', 'Babak Taati', 'Balagopal Unnikrishnan', 'Iñigo Urteaga', 'Stephanie Williams', 'Rahul G Krishnan']","We present the design process and findings of the pre-conference workshop at
the Machine Learning for Healthcare Conference (2024) entitled Red Teaming
Large Language Models for Healthcare, which took place on August 15, 2024.
Conference participants, comprising a mix of computational and clinical
expertise, attempted to discover vulnerabilities -- realistic clinical prompts
for which a large language model (LLM) outputs a response that could cause
clinical harm. Red-teaming with clinicians enables the identification of LLM
vulnerabilities that may not be recognised by LLM developers lacking clinical
expertise. We report the vulnerabilities found, categorise them, and present
the results of a replication study assessing the vulnerabilities across all
LLMs provided.",2025-05-01T11:43:27Z,http://arxiv.org/pdf/2505.00467v2,"['cs.CL', 'cs.AI']"
2505.13452v2,Large Language Model Powered Symbolic Execution,"['Yihe Li', 'Ruijie Meng', 'Gregory J. Duck']","Large Language Models (LLMs) have emerged as a promising alternative to
traditional static program analysis methods, such as symbolic execution,
offering the ability to reason over code directly without relying on theorem
provers or SMT solvers. However, LLMs are also inherently approximate by
nature, and therefore face significant challenges in relation to the accuracy
and scale of analysis in real-world applications. Such issues often necessitate
the use of larger LLMs with higher token limits, but this requires
enterprise-grade hardware (GPUs) and thus limits accessibility for many users.
In this paper, we propose LLM-based symbolic execution -- a novel approach that
enhances LLM inference via a path-based decomposition of the program analysis
tasks into smaller (more tractable) subtasks. The core idea is to generalize
path constraints using a generic code-based representation that the LLM can
directly reason over, and without translation into another (less-expressive)
formal language. We implement our approach in the form of AutoBug, an LLM-based
symbolic execution engine that is lightweight and language-agnostic, making it
a practical tool for analyzing code that is challenging for traditional
approaches. We show that AutoBug can improve both the accuracy and scale of
LLM-based program analysis, especially for smaller LLMs that can run on
consumer-grade hardware.",2025-04-02T05:14:25Z,http://arxiv.org/pdf/2505.13452v2,['cs.PL']
2507.05448v1,On the Semantics of Large Language Models,['Martin Schuele'],"Large Language Models (LLMs) such as ChatGPT demonstrated the potential to
replicate human language abilities through technology, ranging from text
generation to engaging in conversations. However, it remains controversial to
what extent these systems truly understand language. We examine this issue by
narrowing the question down to the semantics of LLMs at the word and sentence
level. By examining the inner workings of LLMs and their generated
representation of language and by drawing on classical semantic theories by
Frege and Russell, we get a more nuanced picture of the potential semantic
capabilities of LLMs.",2025-07-07T20:02:57Z,http://arxiv.org/pdf/2507.05448v1,"['cs.CL', 'cs.AI']"
2509.12574v2,Yet Another Watermark for Large Language Models,"['Siyuan Bao', 'Ying Shi', 'Zhiguang Yang', 'Hanzhou Wu', 'Xinpeng Zhang']","Existing watermarking methods for large language models (LLMs) mainly embed
watermark by adjusting the token sampling prediction or post-processing,
lacking intrinsic coupling with LLMs, which may significantly reduce the
semantic quality of the generated marked texts. Traditional watermarking
methods based on training or fine-tuning may be extendable to LLMs. However,
most of them are limited to the white-box scenario, or very time-consuming due
to the massive parameters of LLMs. In this paper, we present a new watermarking
framework for LLMs, where the watermark is embedded into the LLM by
manipulating the internal parameters of the LLM, and can be extracted from the
generated text without accessing the LLM. Comparing with related methods, the
proposed method entangles the watermark with the intrinsic parameters of the
LLM, which better balances the robustness and imperceptibility of the
watermark. Moreover, the proposed method enables us to extract the watermark
under the black-box scenario, which is computationally efficient for use.
Experimental results have also verified the feasibility, superiority and
practicality. This work provides a new perspective different from mainstream
works, which may shed light on future research.",2025-09-16T02:04:55Z,http://arxiv.org/pdf/2509.12574v2,"['cs.CR', 'cs.CL']"
2401.05561v6,TrustLLM: Trustworthiness in Large Language Models,"['Yue Huang', 'Lichao Sun', 'Haoran Wang', 'Siyuan Wu', 'Qihui Zhang', 'Yuan Li', 'Chujie Gao', 'Yixin Huang', 'Wenhan Lyu', 'Yixuan Zhang', 'Xiner Li', 'Zhengliang Liu', 'Yixin Liu', 'Yijue Wang', 'Zhikun Zhang', 'Bertie Vidgen', 'Bhavya Kailkhura', 'Caiming Xiong', 'Chaowei Xiao', 'Chunyuan Li', 'Eric Xing', 'Furong Huang', 'Hao Liu', 'Heng Ji', 'Hongyi Wang', 'Huan Zhang', 'Huaxiu Yao', 'Manolis Kellis', 'Marinka Zitnik', 'Meng Jiang', 'Mohit Bansal', 'James Zou', 'Jian Pei', 'Jian Liu', 'Jianfeng Gao', 'Jiawei Han', 'Jieyu Zhao', 'Jiliang Tang', 'Jindong Wang', 'Joaquin Vanschoren', 'John Mitchell', 'Kai Shu', 'Kaidi Xu', 'Kai-Wei Chang', 'Lifang He', 'Lifu Huang', 'Michael Backes', 'Neil Zhenqiang Gong', 'Philip S. Yu', 'Pin-Yu Chen', 'Quanquan Gu', 'Ran Xu', 'Rex Ying', 'Shuiwang Ji', 'Suman Jana', 'Tianlong Chen', 'Tianming Liu', 'Tianyi Zhou', 'William Wang', 'Xiang Li', 'Xiangliang Zhang', 'Xiao Wang', 'Xing Xie', 'Xun Chen', 'Xuyu Wang', 'Yan Liu', 'Yanfang Ye', 'Yinzhi Cao', 'Yong Chen', 'Yue Zhao']","Large language models (LLMs), exemplified by ChatGPT, have gained
considerable attention for their excellent natural language processing
capabilities. Nonetheless, these LLMs present many challenges, particularly in
the realm of trustworthiness. Therefore, ensuring the trustworthiness of LLMs
emerges as an important topic. This paper introduces TrustLLM, a comprehensive
study of trustworthiness in LLMs, including principles for different dimensions
of trustworthiness, established benchmark, evaluation, and analysis of
trustworthiness for mainstream LLMs, and discussion of open challenges and
future directions. Specifically, we first propose a set of principles for
trustworthy LLMs that span eight different dimensions. Based on these
principles, we further establish a benchmark across six dimensions including
truthfulness, safety, fairness, robustness, privacy, and machine ethics. We
then present a study evaluating 16 mainstream LLMs in TrustLLM, consisting of
over 30 datasets. Our findings firstly show that in general trustworthiness and
utility (i.e., functional effectiveness) are positively related. Secondly, our
observations reveal that proprietary LLMs generally outperform most open-source
counterparts in terms of trustworthiness, raising concerns about the potential
risks of widely accessible open-source LLMs. However, a few open-source LLMs
come very close to proprietary ones. Thirdly, it is important to note that some
LLMs may be overly calibrated towards exhibiting trustworthiness, to the extent
that they compromise their utility by mistakenly treating benign prompts as
harmful and consequently not responding. Finally, we emphasize the importance
of ensuring transparency not only in the models themselves but also in the
technologies that underpin trustworthiness. Knowing the specific trustworthy
technologies that have been employed is crucial for analyzing their
effectiveness.",2024-01-10T22:07:21Z,http://arxiv.org/pdf/2401.05561v6,['cs.CL']
2412.17614v1,Emerging Security Challenges of Large Language Models,"['Herve Debar', 'Sven Dietrich', 'Pavel Laskov', 'Emil C. Lupu', 'Eirini Ntoutsi']","Large language models (LLMs) have achieved record adoption in a short period
of time across many different sectors including high importance areas such as
education [4] and healthcare [23]. LLMs are open-ended models trained on
diverse data without being tailored for specific downstream tasks, enabling
broad applicability across various domains. They are commonly used for text
generation, but also widely used to assist with code generation [3], and even
analysis of security information, as Microsoft Security Copilot demonstrates
[18]. Traditional Machine Learning (ML) models are vulnerable to adversarial
attacks [9]. So the concerns on the potential security implications of such
wide scale adoption of LLMs have led to the creation of this working group on
the security of LLMs. During the Dagstuhl seminar on ""Network Attack Detection
and Defense - AI-Powered Threats and Responses"", the working group discussions
focused on the vulnerability of LLMs to adversarial attacks, rather than their
potential use in generating malware or enabling cyberattacks. Although we note
the potential threat represented by the latter, the role of the LLMs in such
uses is mostly as an accelerator for development, similar to what it is in
benign use. To make the analysis more specific, the working group employed
ChatGPT as a concrete example of an LLM and addressed the following points,
which also form the structure of this report: 1. How do LLMs differ in
vulnerabilities from traditional ML models? 2. What are the attack objectives
in LLMs? 3. How complex it is to assess the risks posed by the vulnerabilities
of LLMs? 4. What is the supply chain in LLMs, how data flow in and out of
systems and what are the security implications? We conclude with an overview of
open challenges and outlook.",2024-12-23T14:36:37Z,http://arxiv.org/pdf/2412.17614v1,"['cs.CR', 'cs.AI']"
2412.17686v1,Large Language Model Safety: A Holistic Survey,"['Dan Shi', 'Tianhao Shen', 'Yufei Huang', 'Zhigen Li', 'Yongqi Leng', 'Renren Jin', 'Chuang Liu', 'Xinwei Wu', 'Zishan Guo', 'Linhao Yu', 'Ling Shi', 'Bojian Jiang', 'Deyi Xiong']","The rapid development and deployment of large language models (LLMs) have
introduced a new frontier in artificial intelligence, marked by unprecedented
capabilities in natural language understanding and generation. However, the
increasing integration of these models into critical applications raises
substantial safety concerns, necessitating a thorough examination of their
potential risks and associated mitigation strategies.
  This survey provides a comprehensive overview of the current landscape of LLM
safety, covering four major categories: value misalignment, robustness to
adversarial attacks, misuse, and autonomous AI risks. In addition to the
comprehensive review of the mitigation methodologies and evaluation resources
on these four aspects, we further explore four topics related to LLM safety:
the safety implications of LLM agents, the role of interpretability in
enhancing LLM safety, the technology roadmaps proposed and abided by a list of
AI companies and institutes for LLM safety, and AI governance aimed at LLM
safety with discussions on international cooperation, policy proposals, and
prospective regulatory directions.
  Our findings underscore the necessity for a proactive, multifaceted approach
to LLM safety, emphasizing the integration of technical solutions, ethical
considerations, and robust governance frameworks. This survey is intended to
serve as a foundational resource for academy researchers, industry
practitioners, and policymakers, offering insights into the challenges and
opportunities associated with the safe integration of LLMs into society.
Ultimately, it seeks to contribute to the safe and beneficial development of
LLMs, aligning with the overarching goal of harnessing AI for societal
advancement and well-being. A curated list of related papers has been publicly
available at https://github.com/tjunlp-lab/Awesome-LLM-Safety-Papers.",2024-12-23T16:11:27Z,http://arxiv.org/pdf/2412.17686v1,"['cs.AI', 'cs.CL']"
2509.22297v1,Large Language Models as Nondeterministic Causal Models,['Sander Beckers'],"Recent work by Chatzi et al. and Ravfogel et al. has developed, for the first
time, a method for generating counterfactuals of probabilistic Large Language
Models. Such counterfactuals tell us what would - or might - have been the
output of an LLM if some factual prompt ${\bf x}$ had been ${\bf x}^*$ instead.
The ability to generate such counterfactuals is an important necessary step
towards explaining, evaluating, and comparing, the behavior of LLMs. I argue,
however, that the existing method rests on an ambiguous interpretation of LLMs:
it does not interpret LLMs literally, for the method involves the assumption
that one can change the implementation of an LLM's sampling process without
changing the LLM itself, nor does it interpret LLMs as intended, for the method
involves explicitly representing a nondeterministic LLM as a deterministic
causal model. I here present a much simpler method for generating
counterfactuals that is based on an LLM's intended interpretation by
representing it as a nondeterministic causal model instead. The advantage of my
simpler method is that it is directly applicable to any black-box LLM without
modification, as it is agnostic to any implementation details. The advantage of
the existing method, on the other hand, is that it directly implements the
generation of a specific type of counterfactuals that is useful for certain
purposes, but not for others. I clarify how both methods relate by offering a
theoretical foundation for reasoning about counterfactuals in LLMs based on
their intended semantics, thereby laying the groundwork for novel
application-specific methods for generating counterfactuals.",2025-09-26T12:59:41Z,http://arxiv.org/pdf/2509.22297v1,['cs.AI']
2305.10519v2,Statistical Knowledge Assessment for Large Language Models,"['Qingxiu Dong', 'Jingjing Xu', 'Lingpeng Kong', 'Zhifang Sui', 'Lei Li']","Given varying prompts regarding a factoid question, can a large language
model (LLM) reliably generate factually correct answers? Existing LLMs may
generate distinct responses for different prompts. In this paper, we study the
problem of quantifying knowledge contained in an LLM regarding a given set of
facts. We propose KaRR, a statistical approach to assess factual knowledge for
LLMs. The main idea is to estimate the ratio of LLM generating text
corresponding to the answer entity given diverse prompts of the subject and the
querying relation, versus it generating by random chances. Our assessment suite
contains a comprehensive set of 994,123 entities and 600 relations, with
1,395,905 text aliases. We use our method to evaluate 20 LLMs of various sizes,
including LLaMA, Alpaca, OPT, etc. Experiments show that our results have a
strong correlation (0.43 Kendall's $\tau$) with the results of human assessment
on LLMs. Our results reveal that the knowledge in LLMs with the same backbone
architecture adheres to the scaling law, while tuning on instruction-following
data sometimes compromises the model's capability to generate factually correct
text reliably.",2023-05-17T18:54:37Z,http://arxiv.org/pdf/2305.10519v2,"['cs.CL', 'cs.LG']"
2307.00184v4,Personality Traits in Large Language Models,"['Greg Serapio-García', 'Mustafa Safdari', 'Clément Crepy', 'Luning Sun', 'Stephen Fitz', 'Peter Romero', 'Marwa Abdulhai', 'Aleksandra Faust', 'Maja Matarić']","The advent of large language models (LLMs) has revolutionized natural
language processing, enabling the generation of coherent and contextually
relevant human-like text. As LLMs increasingly powerconversational agents used
by the general public world-wide, the synthetic personality traits embedded in
these models, by virtue of training on large amounts of human data, is becoming
increasingly important. Since personality is a key factor determining the
effectiveness of communication, we present a novel and comprehensive
psychometrically valid and reliable methodology for administering and
validating personality tests on widely-used LLMs, as well as for shaping
personality in the generated text of such LLMs. Applying this method to 18
LLMs, we found: 1) personality measurements in the outputs of some LLMs under
specific prompting configurations are reliable and valid; 2) evidence of
reliability and validity of synthetic LLM personality is stronger for larger
and instruction fine-tuned models; and 3) personality in LLM outputs can be
shaped along desired dimensions to mimic specific human personality profiles.
We discuss the application and ethical implications of the measurement and
shaping method, in particular regarding responsible AI.",2023-07-01T00:58:51Z,http://arxiv.org/pdf/2307.00184v4,"['cs.CL', 'cs.AI', 'cs.CY', 'cs.HC', '68T35', 'I.2.7']"
2307.00457v2,GenRec: Large Language Model for Generative Recommendation,"['Jianchao Ji', 'Zelong Li', 'Shuyuan Xu', 'Wenyue Hua', 'Yingqiang Ge', 'Juntao Tan', 'Yongfeng Zhang']","In recent years, large language models (LLM) have emerged as powerful tools
for diverse natural language processing tasks. However, their potential for
recommender systems under the generative recommendation paradigm remains
relatively unexplored. This paper presents an innovative approach to
recommendation systems using large language models (LLMs) based on text data.
In this paper, we present a novel LLM for generative recommendation (GenRec)
that utilized the expressive power of LLM to directly generate the target item
to recommend, rather than calculating ranking score for each candidate item one
by one as in traditional discriminative recommendation. GenRec uses LLM's
understanding ability to interpret context, learn user preferences, and
generate relevant recommendation. Our proposed approach leverages the vast
knowledge encoded in large language models to accomplish recommendation tasks.
We first we formulate specialized prompts to enhance the ability of LLM to
comprehend recommendation tasks. Subsequently, we use these prompts to
fine-tune the LLaMA backbone LLM on a dataset of user-item interactions,
represented by textual data, to capture user preferences and item
characteristics. Our research underscores the potential of LLM-based generative
recommendation in revolutionizing the domain of recommendation systems and
offers a foundational framework for future explorations in this field. We
conduct extensive experiments on benchmark datasets, and the experiments shows
that our GenRec has significant better results on large dataset.",2023-07-02T02:37:07Z,http://arxiv.org/pdf/2307.00457v2,"['cs.IR', 'cs.AI', 'cs.CL', 'cs.LG']"
2307.09042v2,Emotional Intelligence of Large Language Models,"['Xuena Wang', 'Xueting Li', 'Zi Yin', 'Yue Wu', 'Liu Jia']","Large Language Models (LLMs) have demonstrated remarkable abilities across
numerous disciplines, primarily assessed through tasks in language generation,
knowledge utilization, and complex reasoning. However, their alignment with
human emotions and values, which is critical for real-world applications, has
not been systematically evaluated. Here, we assessed LLMs' Emotional
Intelligence (EI), encompassing emotion recognition, interpretation, and
understanding, which is necessary for effective communication and social
interactions. Specifically, we first developed a novel psychometric assessment
focusing on Emotion Understanding (EU), a core component of EI, suitable for
both humans and LLMs. This test requires evaluating complex emotions (e.g.,
surprised, joyful, puzzled, proud) in realistic scenarios (e.g., despite
feeling underperformed, John surprisingly achieved a top score). With a
reference frame constructed from over 500 adults, we tested a variety of
mainstream LLMs. Most achieved above-average EQ scores, with GPT-4 exceeding
89% of human participants with an EQ of 117. Interestingly, a multivariate
pattern analysis revealed that some LLMs apparently did not reply on the
human-like mechanism to achieve human-level performance, as their
representational patterns were qualitatively distinct from humans. In addition,
we discussed the impact of factors such as model size, training method, and
architecture on LLMs' EQ. In summary, our study presents one of the first
psychometric evaluations of the human-like characteristics of LLMs, which may
shed light on the future development of LLMs aiming for both high intellectual
and emotional intelligence. Project website:
https://emotional-intelligence.github.io/",2023-07-18T07:49:38Z,http://arxiv.org/pdf/2307.09042v2,['cs.AI']
2307.16513v2,Deception Abilities Emerged in Large Language Models,['Thilo Hagendorff'],"Large language models (LLMs) are currently at the forefront of intertwining
artificial intelligence (AI) systems with human communication and everyday
life. Thus, aligning them with human values is of great importance. However,
given the steady increase in reasoning abilities, future LLMs are under
suspicion of becoming able to deceive human operators and utilizing this
ability to bypass monitoring efforts. As a prerequisite to this, LLMs need to
possess a conceptual understanding of deception strategies. This study reveals
that such strategies emerged in state-of-the-art LLMs, such as GPT-4, but were
non-existent in earlier LLMs. We conduct a series of experiments showing that
state-of-the-art LLMs are able to understand and induce false beliefs in other
agents, that their performance in complex deception scenarios can be amplified
utilizing chain-of-thought reasoning, and that eliciting Machiavellianism in
LLMs can alter their propensity to deceive. In sum, revealing hitherto unknown
machine behavior in LLMs, our study contributes to the nascent field of machine
psychology.",2023-07-31T09:27:01Z,http://arxiv.org/pdf/2307.16513v2,"['cs.CL', 'cs.AI', 'cs.LG']"
2307.16645v1,Scaling Sentence Embeddings with Large Language Models,"['Ting Jiang', 'Shaohan Huang', 'Zhongzhi Luan', 'Deqing Wang', 'Fuzhen Zhuang']","Large language models (LLMs) have recently garnered significant interest.
With in-context learning, LLMs achieve impressive results in various natural
language tasks. However, the application of LLMs to sentence embeddings remains
an area of ongoing research. In this work, we propose an in-context
learning-based method aimed at improving sentence embeddings performance. Our
approach involves adapting the previous prompt-based representation method for
autoregressive models, constructing a demonstration set that enables LLMs to
perform in-context learning, and scaling up the LLMs to different model sizes.
Through extensive experiments, in-context learning enables LLMs to generate
high-quality sentence embeddings without any fine-tuning. It helps LLMs achieve
performance comparable to current contrastive learning methods. By scaling
model size, we find scaling to more than tens of billion parameters harms the
performance on semantic textual similarity (STS) tasks. However, the largest
model outperforms other counterparts and achieves the new state-of-the-art
result on transfer tasks. We also fine-tune LLMs with current contrastive
learning approach, and the 2.7B OPT model, incorporating our prompt-based
method, surpasses the performance of 4.8B ST5, achieving the new
state-of-the-art results on STS tasks. Our code is available at
https://github.com/kongds/scaling_sentemb.",2023-07-31T13:26:03Z,http://arxiv.org/pdf/2307.16645v1,['cs.CL']
2310.00935v3,Resolving Knowledge Conflicts in Large Language Models,"['Yike Wang', 'Shangbin Feng', 'Heng Wang', 'Weijia Shi', 'Vidhisha Balachandran', 'Tianxing He', 'Yulia Tsvetkov']","Large language models (LLMs) often encounter knowledge conflicts, scenarios
where discrepancy arises between the internal parametric knowledge of LLMs and
non-parametric information provided in the prompt context. In this work we ask
what are the desiderata for LLMs when a knowledge conflict arises and whether
existing LLMs fulfill them. We posit that LLMs should 1) identify knowledge
conflicts, 2) pinpoint conflicting information segments, and 3) provide
distinct answers or viewpoints in conflicting scenarios. To this end, we
introduce an evaluation framework for simulating contextual knowledge conflicts
and quantitatively evaluating to what extent LLMs achieve these goals. It
includes diverse and complex situations of knowledge conflict, knowledge from
diverse entities and domains, two synthetic conflict creation methods, and
settings with progressively increasing difficulty to reflect realistic
knowledge conflicts. Extensive experiments with the framework reveal that while
LLMs perform well in identifying the existence of knowledge conflicts, they
struggle to determine the specific conflicting knowledge and produce a response
with distinct answers amidst conflicting information. To address these
challenges, we propose new instruction-based approaches that augment LLMs to
better achieve the three goals. Further analysis shows that abilities to tackle
knowledge conflicts are greatly impacted by factors such as knowledge domain,
while generating robust responses to knowledge conflict scenarios remains an
open research question.",2023-10-02T06:57:45Z,http://arxiv.org/pdf/2310.00935v3,['cs.CL']
2310.09690v2,Configuration Validation with Large Language Models,"['Xinyu Lian', 'Yinfang Chen', 'Runxiang Cheng', 'Jie Huang', 'Parth Thakkar', 'Minjia Zhang', 'Tianyin Xu']","Misconfigurations are major causes of software failures. Existing practices
rely on developer-written rules or test cases to validate configurations, which
are expensive. Machine learning (ML) for configuration validation is considered
a promising direction, but has been facing challenges such as the need of
large-scale field data and system-specific models. Recent advances in Large
Language Models (LLMs) show promise in addressing some of the long-lasting
limitations of ML-based configuration validation. We present a first analysis
on the feasibility and effectiveness of using LLMs for configuration
validation. We empirically evaluate LLMs as configuration validators by
developing a generic LLM-based configuration validation framework, named Ciri.
Ciri employs effective prompt engineering with few-shot learning based on both
valid configuration and misconfiguration data. Ciri checks outputs from LLMs
when producing results, addressing hallucination and nondeterminism of LLMs. We
evaluate Ciri's validation effectiveness on eight popular LLMs using
configuration data of ten widely deployed open-source systems. Our analysis (1)
confirms the potential of using LLMs for configuration validation, (2) explores
design space of LLMbased validators like Ciri, and (3) reveals open challenges
such as ineffectiveness in detecting certain types of misconfigurations and
biases towards popular configuration parameters.",2023-10-15T00:50:27Z,http://arxiv.org/pdf/2310.09690v2,"['cs.SE', 'cs.AI', 'cs.OS']"
2311.10723v2,Large Language Models in Finance: A Survey,"['Yinheng Li', 'Shaofei Wang', 'Han Ding', 'Hang Chen']","Recent advances in large language models (LLMs) have opened new possibilities
for artificial intelligence applications in finance. In this paper, we provide
a practical survey focused on two key aspects of utilizing LLMs for financial
tasks: existing solutions and guidance for adoption.
  First, we review current approaches employing LLMs in finance, including
leveraging pretrained models via zero-shot or few-shot learning, fine-tuning on
domain-specific data, and training custom LLMs from scratch. We summarize key
models and evaluate their performance improvements on financial natural
language processing tasks.
  Second, we propose a decision framework to guide financial professionals in
selecting the appropriate LLM solution based on their use case constraints
around data, compute, and performance needs. The framework provides a pathway
from lightweight experimentation to heavy investment in customized LLMs.
  Lastly, we discuss limitations and challenges around leveraging LLMs in
financial applications. Overall, this survey aims to synthesize the
state-of-the-art and provide a roadmap for responsibly applying LLMs to advance
financial AI.",2023-09-28T06:04:04Z,http://arxiv.org/pdf/2311.10723v2,"['q-fin.GN', 'cs.AI', 'cs.CL']"
2402.08392v1,Large Language Models as Minecraft Agents,"['Chris Madge', 'Massimo Poesio']","In this work we examine the use of Large Language Models (LLMs) in the
challenging setting of acting as a Minecraft agent. We apply and evaluate LLMs
in the builder and architect settings, introduce clarification questions and
examining the challenges and opportunities for improvement. In addition, we
present a platform for online interaction with the agents and an evaluation
against previous works.",2024-02-13T11:37:30Z,http://arxiv.org/pdf/2402.08392v1,['cs.CL']
2402.08787v6,Rethinking Machine Unlearning for Large Language Models,"['Sijia Liu', 'Yuanshun Yao', 'Jinghan Jia', 'Stephen Casper', 'Nathalie Baracaldo', 'Peter Hase', 'Yuguang Yao', 'Chris Yuhao Liu', 'Xiaojun Xu', 'Hang Li', 'Kush R. Varshney', 'Mohit Bansal', 'Sanmi Koyejo', 'Yang Liu']","We explore machine unlearning (MU) in the domain of large language models
(LLMs), referred to as LLM unlearning. This initiative aims to eliminate
undesirable data influence (e.g., sensitive or illegal information) and the
associated model capabilities, while maintaining the integrity of essential
knowledge generation and not affecting causally unrelated information. We
envision LLM unlearning becoming a pivotal element in the life-cycle management
of LLMs, potentially standing as an essential foundation for developing
generative AI that is not only safe, secure, and trustworthy, but also
resource-efficient without the need of full retraining. We navigate the
unlearning landscape in LLMs from conceptual formulation, methodologies,
metrics, and applications. In particular, we highlight the often-overlooked
aspects of existing LLM unlearning research, e.g., unlearning scope, data-model
interaction, and multifaceted efficacy assessment. We also draw connections
between LLM unlearning and related areas such as model editing, influence
functions, model explanation, adversarial training, and reinforcement learning.
Furthermore, we outline an effective assessment framework for LLM unlearning
and explore its applications in copyright and privacy safeguards and
sociotechnical harm reduction.",2024-02-13T20:51:58Z,http://arxiv.org/pdf/2402.08787v6,"['cs.LG', 'cs.CL']"
2402.14700v3,Unveiling Linguistic Regions in Large Language Models,"['Zhihao Zhang', 'Jun Zhao', 'Qi Zhang', 'Tao Gui', 'Xuanjing Huang']","Large Language Models (LLMs) have demonstrated considerable cross-lingual
alignment and generalization ability. Current research primarily focuses on
improving LLMs' cross-lingual generalization capabilities. However, there is
still a lack of research on the intrinsic mechanisms of how LLMs achieve
cross-lingual alignment. From the perspective of region partitioning, this
paper conducts several investigations on the linguistic competence of LLMs. We
discover a core region in LLMs that corresponds to linguistic competence,
accounting for approximately 1% of the total model parameters. Removing this
core region by setting parameters to zero results in a significant performance
decrease across 30 different languages. Furthermore, this core region exhibits
significant dimensional dependence, perturbations to even a single parameter on
specific dimensions leading to a loss of linguistic competence. Moreover, we
discover that distinct monolingual regions exist for different languages, and
disruption to these specific regions substantially reduces the LLMs'
proficiency in those corresponding languages. Our research also indicates that
freezing the core linguistic region during further pre-training can mitigate
the issue of catastrophic forgetting (CF), a common phenomenon observed during
further pre-training of LLMs. Overall, exploring the LLMs' functional regions
provides insights into the foundation of their intelligence.",2024-02-22T16:56:13Z,http://arxiv.org/pdf/2402.14700v3,['cs.CL']
2404.00245v1,Aligning Large Language Models with Recommendation Knowledge,"['Yuwei Cao', 'Nikhil Mehta', 'Xinyang Yi', 'Raghunandan Keshavan', 'Lukasz Heldt', 'Lichan Hong', 'Ed H. Chi', 'Maheswaran Sathiamoorthy']","Large language models (LLMs) have recently been used as backbones for
recommender systems. However, their performance often lags behind conventional
methods in standard tasks like retrieval. We attribute this to a mismatch
between LLMs' knowledge and the knowledge crucial for effective
recommendations. While LLMs excel at natural language reasoning, they cannot
model complex user-item interactions inherent in recommendation tasks. We
propose bridging the knowledge gap and equipping LLMs with
recommendation-specific knowledge to address this. Operations such as Masked
Item Modeling (MIM) and Bayesian Personalized Ranking (BPR) have found success
in conventional recommender systems. Inspired by this, we simulate these
operations through natural language to generate auxiliary-task data samples
that encode item correlations and user preferences. Fine-tuning LLMs on such
auxiliary-task data samples and incorporating more informative
recommendation-task data samples facilitates the injection of
recommendation-specific knowledge into LLMs. Extensive experiments across
retrieval, ranking, and rating prediction tasks on LLMs such as FLAN-T5-Base
and FLAN-T5-XL show the effectiveness of our technique in domains such as
Amazon Toys & Games, Beauty, and Sports & Outdoors. Notably, our method
outperforms conventional and LLM-based baselines, including the current SOTA,
by significant margins in retrieval, showcasing its potential for enhancing
recommendation quality.",2024-03-30T04:46:16Z,http://arxiv.org/pdf/2404.00245v1,['cs.IR']
2405.12819v2,Large Language Models Meet NLP: A Survey,"['Libo Qin', 'Qiguang Chen', 'Xiachong Feng', 'Yang Wu', 'Yongheng Zhang', 'Yinghui Li', 'Min Li', 'Wanxiang Che', 'Philip S. Yu']","While large language models (LLMs) like ChatGPT have shown impressive
capabilities in Natural Language Processing (NLP) tasks, a systematic
investigation of their potential in this field remains largely unexplored. This
study aims to address this gap by exploring the following questions: (1) How
are LLMs currently applied to NLP tasks in the literature? (2) Have traditional
NLP tasks already been solved with LLMs? (3) What is the future of the LLMs for
NLP? To answer these questions, we take the first step to provide a
comprehensive overview of LLMs in NLP. Specifically, we first introduce a
unified taxonomy including (1) parameter-frozen paradigm and (2)
parameter-tuning paradigm to offer a unified perspective for understanding the
current progress of LLMs in NLP. Furthermore, we summarize the new frontiers
and the corresponding challenges, aiming to inspire further groundbreaking
advancements. We hope this work offers valuable insights into the potential and
limitations of LLMs, while also serving as a practical guide for building
effective LLMs in NLP.",2024-05-21T14:24:01Z,http://arxiv.org/pdf/2405.12819v2,"['cs.CL', 'cs.AI']"
2405.13001v1,Large Language Models for Education: A Survey,"['Hanyi Xu', 'Wensheng Gan', 'Zhenlian Qi', 'Jiayang Wu', 'Philip S. Yu']","Artificial intelligence (AI) has a profound impact on traditional education.
In recent years, large language models (LLMs) have been increasingly used in
various applications such as natural language processing, computer vision,
speech recognition, and autonomous driving. LLMs have also been applied in many
fields, including recommendation, finance, government, education, legal
affairs, and finance. As powerful auxiliary tools, LLMs incorporate various
technologies such as deep learning, pre-training, fine-tuning, and
reinforcement learning. The use of LLMs for smart education (LLMEdu) has been a
significant strategic direction for countries worldwide. While LLMs have shown
great promise in improving teaching quality, changing education models, and
modifying teacher roles, the technologies are still facing several challenges.
In this paper, we conduct a systematic review of LLMEdu, focusing on current
technologies, challenges, and future developments. We first summarize the
current state of LLMEdu and then introduce the characteristics of LLMs and
education, as well as the benefits of integrating LLMs into education. We also
review the process of integrating LLMs into the education industry, as well as
the introduction of related technologies. Finally, we discuss the challenges
and problems faced by LLMEdu, as well as prospects for future optimization of
LLMEdu.",2024-05-12T01:50:01Z,http://arxiv.org/pdf/2405.13001v1,"['cs.CL', 'cs.AI', 'cs.CY']"
2405.13041v3,Assessing Political Bias in Large Language Models,"['Luca Rettenberger', 'Markus Reischl', 'Mark Schutera']","The assessment of bias within Large Language Models (LLMs) has emerged as a
critical concern in the contemporary discourse surrounding Artificial
Intelligence (AI) in the context of their potential impact on societal
dynamics. Recognizing and considering political bias within LLM applications is
especially important when closing in on the tipping point toward performative
prediction. Then, being educated about potential effects and the societal
behavior LLMs can drive at scale due to their interplay with human operators.
In this way, the upcoming elections of the European Parliament will not remain
unaffected by LLMs. We evaluate the political bias of the currently most
popular open-source LLMs (instruct or assistant models) concerning political
issues within the European Union (EU) from a German voter's perspective. To do
so, we use the ""Wahl-O-Mat,"" a voting advice application used in Germany. From
the voting advice of the ""Wahl-O-Mat"" we quantize the degree of alignment of
LLMs with German political parties. We show that larger models, such as
Llama3-70B, tend to align more closely with left-leaning political parties,
while smaller models often remain neutral, particularly when prompted in
English. The central finding is that LLMs are similarly biased, with low
variances in the alignment concerning a specific party. Our findings underline
the importance of rigorously assessing and making bias transparent in LLMs to
safeguard the integrity and trustworthiness of applications that employ the
capabilities of performative prediction and the invisible hand of machine
learning prediction and language generation.",2024-05-17T15:30:18Z,http://arxiv.org/pdf/2405.13041v3,"['cs.CL', 'cs.AI']"
2406.07815v2,Are Large Language Models Good Statisticians?,"['Yizhang Zhu', 'Shiyin Du', 'Boyan Li', 'Yuyu Luo', 'Nan Tang']","Large Language Models (LLMs) have demonstrated impressive capabilities across
a range of scientific tasks including mathematics, physics, and chemistry.
Despite their successes, the effectiveness of LLMs in handling complex
statistical tasks remains systematically under-explored. To bridge this gap, we
introduce StatQA, a new benchmark designed for statistical analysis tasks.
StatQA comprises 11,623 examples tailored to evaluate LLMs' proficiency in
specialized statistical tasks and their applicability assessment capabilities,
particularly for hypothesis testing methods. We systematically experiment with
representative LLMs using various prompting strategies and show that even
state-of-the-art models such as GPT-4o achieve a best performance of only
64.83%, indicating significant room for improvement. Notably, while open-source
LLMs (e.g. LLaMA-3) show limited capability, those fine-tuned ones exhibit
marked improvements, outperforming all in-context learning-based methods (e.g.
GPT-4o). Moreover, our comparative human experiments highlight a striking
contrast in error types between LLMs and humans: LLMs primarily make
applicability errors, whereas humans mostly make statistical task confusion
errors. This divergence highlights distinct areas of proficiency and
deficiency, suggesting that combining LLM and human expertise could lead to
complementary strengths, inviting further investigation into their
collaborative potential. Our source code and data are available at
https://statqa.github.io/.",2024-06-12T02:23:51Z,http://arxiv.org/pdf/2406.07815v2,"['cs.CL', 'cs.AI']"
2407.01235v1,A Fingerprint for Large Language Models,"['Zhiguang Yang', 'Hanzhou Wu']","Recent advances show that scaling a pre-trained language model could achieve
state-of-the-art performance on many downstream tasks, prompting large language
models (LLMs) to become a hot research topic in the field of artificial
intelligence. However, due to the resource-intensive nature of training LLMs
from scratch, it is urgent and crucial to protect the intellectual property of
LLMs against infringement. This has motivated the authors in this paper to
propose a novel black-box fingerprinting technique for LLMs, which requires
neither model training nor model fine-tuning. We first demonstrate that the
outputs of LLMs span a unique vector space associated with each model. We model
the problem of ownership authentication as the task of evaluating the
similarity between the victim model's space and the output's space of the
suspect model. To deal with this problem, we propose two solutions, where the
first solution involves verifying whether the outputs of the suspected large
model are in the same space as those of the victim model, enabling rapid
identification of model infringement, and the second one reconstructs the union
of the vector spaces for LLM outputs and the victim model to address situations
where the victim model has undergone the Parameter-Efficient Fine-Tuning (PEFT)
attacks. Experimental results indicate that the proposed technique achieves
superior performance in ownership verification and robustness against PEFT
attacks. This work reveals inherent characteristics of LLMs and provides a
promising solution for ownership verification of LLMs in black-box scenarios,
ensuring efficiency, generality and practicality.",2024-07-01T12:25:42Z,http://arxiv.org/pdf/2407.01235v1,['cs.CR']
2407.08564v1,The Career Interests of Large Language Models,"['Meng Hua', 'Yuan Cheng', 'Hengshu Zhu']","Recent advancements in Large Language Models (LLMs) have significantly
extended their capabilities, evolving from basic text generation to complex,
human-like interactions. In light of the possibilities that LLMs could assume
significant workplace responsibilities, it becomes imminently necessary to
explore LLMs' capacities as professional assistants. This study focuses on the
aspect of career interests by applying the Occupation Network's Interest
Profiler short form to LLMs as if they were human participants and investigates
their hypothetical career interests and competence, examining how these vary
with language changes and model advancements. We analyzed the answers using a
general linear mixed model approach and found distinct career interest
inclinations among LLMs, particularly towards the social and artistic domains.
Interestingly, these preferences did not align with the occupations where LLMs
exhibited higher competence. This novel approach of using psychometric
instruments and sophisticated statistical tools on LLMs unveils fresh
perspectives on their integration into professional environments, highlighting
human-like tendencies and promoting a reevaluation of LLMs' self-perception and
competency alignment in the workforce.",2024-07-11T14:54:46Z,http://arxiv.org/pdf/2407.08564v1,['cs.AI']
2408.05568v1,Metacognitive Myopia in Large Language Models,"['Florian Scholten', 'Tobias R. Rebholz', 'Mandy Hütter']","Large Language Models (LLMs) exhibit potentially harmful biases that
reinforce culturally inherent stereotypes, cloud moral judgments, or amplify
positive evaluations of majority groups. Previous explanations mainly
attributed bias in LLMs to human annotators and the selection of training data.
Consequently, they have typically been addressed with bottom-up approaches such
as reinforcement learning or debiasing corpora. However, these methods only
treat the effects of LLM biases by indirectly influencing the model
architecture, but do not address the underlying causes in the computational
process. Here, we propose metacognitive myopia as a cognitive-ecological
framework that can account for a conglomerate of established and emerging LLM
biases and provide a lever to address problems in powerful but vulnerable
tools. Our theoretical framework posits that a lack of the two components of
metacognition, monitoring and control, causes five symptoms of metacognitive
myopia in LLMs: integration of invalid tokens and embeddings, susceptibility to
redundant information, neglect of base rates in conditional computation,
decision rules based on frequency, and inappropriate higher-order statistical
inference for nested data structures. As a result, LLMs produce erroneous
output that reaches into the daily high-stakes decisions of humans. By
introducing metacognitive regulatory processes into LLMs, engineers and
scientists can develop precise remedies for the underlying causes of these
biases. Our theory sheds new light on flawed human-machine interactions and
raises ethical concerns regarding the increasing, imprudent implementation of
LLMs in organizational structures.",2024-08-10T14:43:57Z,http://arxiv.org/pdf/2408.05568v1,"['cs.AI', 'cs.CL', 'cs.CY', 'stat.AP']"
2408.16098v1,Structured Event Reasoning with Large Language Models,['Li Zhang'],"Reasoning about real-life events is a unifying challenge in AI and NLP that
has profound utility in a variety of domains, while fallacy in high-stake
applications could be catastrophic. Able to work with diverse text in these
domains, large language models (LLMs) have proven capable of answering
questions and solving problems. However, I show that end-to-end LLMs still
systematically fail to reason about complex events, and they lack
interpretability due to their black-box nature. To address these issues, I
propose three general approaches to use LLMs in conjunction with a structured
representation of events. The first is a language-based representation
involving relations of sub-events that can be learned by LLMs via fine-tuning.
The second is a semi-symbolic representation involving states of entities that
can be predicted and leveraged by LLMs via few-shot prompting. The third is a
fully symbolic representation that can be predicted by LLMs trained with
structured data and be executed by symbolic solvers. On a suite of event
reasoning tasks spanning common-sense inference and planning, I show that each
approach greatly outperforms end-to-end LLMs with more interpretability. These
results suggest manners of synergy between LLMs and structured representations
for event reasoning and beyond.",2024-08-28T19:03:41Z,http://arxiv.org/pdf/2408.16098v1,['cs.CL']
2412.14501v2,Do Large Language Models Advocate for Inferentialism?,"['Yuzuki Arai', 'Sho Tsugawa']","The emergence of large language models (LLMs) such as ChatGPT and Claude
presents new challenges for philosophy of language, particularly regarding the
nature of linguistic meaning and representation. While LLMs have traditionally
been understood through distributional semantics, this paper explores Robert
Brandom's inferential semantics as an alternative foundational framework for
understanding these systems. We examine how key features of inferential
semantics -- including its anti-representationalist stance, logical
expressivism, and quasi-compositional approach -- align with the architectural
and functional characteristics of Transformer-based LLMs. Through analysis of
the ISA (Inference, Substitution, Anaphora) approach, we demonstrate that LLMs
exhibit fundamentally anti-representationalist properties in their processing
of language. We further develop a consensus theory of truth appropriate for
LLMs, grounded in their interactive and normative dimensions through mechanisms
like RLHF. While acknowledging significant tensions between inferentialism's
philosophical commitments and LLMs' sub-symbolic processing, this paper argues
that inferential semantics provides valuable insights into how LLMs generate
meaning without reference to external world representations. Our analysis
suggests that LLMs may challenge traditional assumptions in philosophy of
language, including strict compositionality and semantic externalism, though
further empirical investigation is needed to fully substantiate these
theoretical claims.",2024-12-19T03:48:40Z,http://arxiv.org/pdf/2412.14501v2,['cs.CL']
2503.03135v2,Bridging Molecular Graphs and Large Language Models,"['Runze Wang', 'Mingqi Yang', 'Yanming Shen']","While Large Language Models (LLMs) have shown exceptional generalization
capabilities, their ability to process graph data, such as molecular
structures, remains limited. To bridge this gap, this paper proposes
Graph2Token, an efficient solution that aligns graph tokens to LLM tokens. The
key idea is to represent a graph token with the LLM token vocabulary, without
fine-tuning the LLM backbone. To achieve this goal, we first construct a
molecule-text paired dataset from multisources, including CHEBI and HMDB, to
train a graph structure encoder, which reduces the distance between graphs and
texts representations in the feature space. Then, we propose a novel alignment
strategy that associates a graph token with LLM tokens. To further unleash the
potential of LLMs, we collect molecular IUPAC name identifiers, which are
incorporated into the LLM prompts. By aligning molecular graphs as special
tokens, we can activate LLM generalization ability to molecular few-shot
learning. Extensive experiments on molecular classification and regression
tasks demonstrate the effectiveness of our proposed Graph2Token.",2025-03-05T03:15:38Z,http://arxiv.org/pdf/2503.03135v2,['cs.LG']
2503.07627v1,Psychological Counseling Ability of Large Language Models,"['Fangyu Peng', 'Jingxin Nie']","With the development of science and the continuous progress of artificial
intelligence technology, Large Language Models (LLMs) have begun to be widely
utilized across various fields. However, in the field of psychological
counseling, the ability of LLMs have not been systematically assessed. In this
study, we assessed the psychological counseling ability of mainstream LLMs
using 1096 psychological counseling skill questions which were selected from
the Chinese National Counselor Level 3 Examination, including Knowledge-based,
Analytical-based, and Application-based question types. The analysis showed
that the correctness rates of the LLMs for Chinese questions, in descending
order, were GLM-3 (46.5%), GPT-4 (46.1%), Gemini (45.0%), ERNIE-3.5 (45.7%) and
GPT-3.5 (32.9%). The correctness rates of the LLMs for English questions, in
descending order, were ERNIE-3.5 (43.9%), GPT-4 (40.6%), Gemini (36.6%), GLM-3
(29.9%) and GPT-3.5 (29.5%). A chi-square test indicated significant
differences in the LLMs' performance on Chinese and English questions.
Furthermore, we subsequently utilized the Counselor's Guidebook (Level 3) as a
reference for ERNIE-3.5, resulting in a new correctness rate of 59.6%, a 13.8%
improvement over its initial rate of 45.8%. In conclusion, the study assessed
the psychological counseling ability of LLMs for the first time, which may
provide insights for future enhancement and improvement of psychological
counseling ability of LLMs.",2025-03-01T08:01:25Z,http://arxiv.org/pdf/2503.07627v1,"['cs.LG', 'cs.AI', 'cs.CL', 'cs.CY']"
2505.00662v1,DeepCritic: Deliberate Critique with Large Language Models,"['Wenkai Yang', 'Jingwen Chen', 'Yankai Lin', 'Ji-Rong Wen']","As Large Language Models (LLMs) are rapidly evolving, providing accurate
feedback and scalable oversight on their outputs becomes an urgent and critical
problem. Leveraging LLMs as critique models to achieve automated supervision is
a promising solution. In this work, we focus on studying and enhancing the math
critique ability of LLMs. Current LLM critics provide critiques that are too
shallow and superficial on each step, leading to low judgment accuracy and
struggling to offer sufficient feedback for the LLM generator to correct
mistakes. To tackle this issue, we propose a novel and effective two-stage
framework to develop LLM critics that are capable of deliberately critiquing on
each reasoning step of math solutions. In the first stage, we utilize
Qwen2.5-72B-Instruct to generate 4.5K long-form critiques as seed data for
supervised fine-tuning. Each seed critique consists of deliberate step-wise
critiques that includes multi-perspective verifications as well as in-depth
critiques of initial critiques for each reasoning step. Then, we perform
reinforcement learning on the fine-tuned model with either existing
human-labeled data from PRM800K or our automatically annotated data obtained
via Monte Carlo sampling-based correctness estimation, to further incentivize
its critique ability. Our developed critique model built on Qwen2.5-7B-Instruct
not only significantly outperforms existing LLM critics (including the
same-sized DeepSeek-R1-distill models and GPT-4o) on various error
identification benchmarks, but also more effectively helps the LLM generator
refine erroneous steps through more detailed feedback.",2025-05-01T17:03:17Z,http://arxiv.org/pdf/2505.00662v1,"['cs.CL', 'cs.AI', 'cs.LG']"
2305.16867v2,Playing repeated games with Large Language Models,"['Elif Akata', 'Lion Schulz', 'Julian Coda-Forno', 'Seong Joon Oh', 'Matthias Bethge', 'Eric Schulz']","LLMs are increasingly used in applications where they interact with humans
and other agents. We propose to use behavioural game theory to study LLM's
cooperation and coordination behaviour. We let different LLMs play finitely
repeated $2\times2$ games with each other, with human-like strategies, and
actual human players. Our results show that LLMs perform particularly well at
self-interested games like the iterated Prisoner's Dilemma family. However,
they behave sub-optimally in games that require coordination, like the Battle
of the Sexes. We verify that these behavioural signatures are stable across
robustness checks. We additionally show how GPT-4's behaviour can be modulated
by providing additional information about its opponent and by using a ""social
chain-of-thought"" (SCoT) strategy. This also leads to better scores and more
successful coordination when interacting with human players. These results
enrich our understanding of LLM's social behaviour and pave the way for a
behavioural game theory for machines.",2023-05-26T12:17:59Z,http://arxiv.org/pdf/2305.16867v2,['cs.CL']
2205.13621v2,Differentially Private Decoding in Large Language Models,"['Jimit Majmudar', 'Christophe Dupuy', 'Charith Peris', 'Sami Smaili', 'Rahul Gupta', 'Richard Zemel']","Recent large-scale natural language processing (NLP) systems use a
pre-trained Large Language Model (LLM) on massive and diverse corpora as a
headstart. In practice, the pre-trained model is adapted to a wide array of
tasks via fine-tuning on task-specific datasets. LLMs, while effective, have
been shown to memorize instances of training data thereby potentially revealing
private information processed during pre-training. The potential leakage might
further propagate to the downstream tasks for which LLMs are fine-tuned. On the
other hand, privacy-preserving algorithms usually involve retraining from
scratch, which is prohibitively expensive for LLMs. In this work, we propose a
simple, easy to interpret, and computationally lightweight perturbation
mechanism to be applied to an already trained model at the decoding stage. Our
perturbation mechanism is model-agnostic and can be used in conjunction with
any LLM. We provide theoretical analysis showing that the proposed mechanism is
differentially private, and experimental results showing a privacy-utility
trade-off.",2022-05-26T20:50:58Z,http://arxiv.org/pdf/2205.13621v2,"['cs.CL', 'cs.LG']"
2211.15458v2,Validating Large Language Models with ReLM,"['Michael Kuchnik', 'Virginia Smith', 'George Amvrosiadis']","Although large language models (LLMs) have been touted for their ability to
generate natural-sounding text, there are growing concerns around possible
negative effects of LLMs such as data memorization, bias, and inappropriate
language. Unfortunately, the complexity and generation capacities of LLMs make
validating (and correcting) such concerns difficult. In this work, we introduce
ReLM, a system for validating and querying LLMs using standard regular
expressions. ReLM formalizes and enables a broad range of language model
evaluations, reducing complex evaluation rules to simple regular expression
queries. Our results exploring queries surrounding memorization, gender bias,
toxicity, and language understanding show that ReLM achieves up to 15x higher
system efficiency, 2.5x data efficiency, and increased statistical and
prompt-tuning coverage compared to state-of-the-art ad-hoc queries. ReLM offers
a competitive and general baseline for the increasingly important problem of
LLM validation.",2022-11-21T21:40:35Z,http://arxiv.org/pdf/2211.15458v2,"['cs.LG', 'cs.CL']"
2302.05817v2,Level Generation Through Large Language Models,"['Graham Todd', 'Sam Earle', 'Muhammad Umair Nasir', 'Michael Cerny Green', 'Julian Togelius']","Large Language Models (LLMs) are powerful tools, capable of leveraging their
training on natural language to write stories, generate code, and answer
questions. But can they generate functional video game levels? Game levels,
with their complex functional constraints and spatial relationships in more
than one dimension, are very different from the kinds of data an LLM typically
sees during training. Datasets of game levels are also hard to come by,
potentially taxing the abilities of these data-hungry models. We investigate
the use of LLMs to generate levels for the game Sokoban, finding that LLMs are
indeed capable of doing so, and that their performance scales dramatically with
dataset size. We also perform preliminary experiments on controlling LLM level
generators and discuss promising areas for future work.",2023-02-11T23:34:42Z,http://arxiv.org/pdf/2302.05817v2,"['cs.AI', 'cs.CL', 'cs.NE']"
2304.00116v1,Enhancing Large Language Models with Climate Resources,"['Mathias Kraus', 'Julia Anna Bingler', 'Markus Leippold', 'Tobias Schimanski', 'Chiara Colesanti Senni', 'Dominik Stammbach', 'Saeid Ashraf Vaghefi', 'Nicolas Webersinke']","Large language models (LLMs) have significantly transformed the landscape of
artificial intelligence by demonstrating their ability in generating human-like
text across diverse topics. However, despite their impressive capabilities,
LLMs lack recent information and often employ imprecise language, which can be
detrimental in domains where accuracy is crucial, such as climate change. In
this study, we make use of recent ideas to harness the potential of LLMs by
viewing them as agents that access multiple sources, including databases
containing recent and precise information about organizations, institutions,
and companies. We demonstrate the effectiveness of our method through a
prototype agent that retrieves emission data from ClimateWatch
(https://www.climatewatchdata.org/) and leverages general Google search. By
integrating these resources with LLMs, our approach overcomes the limitations
associated with imprecise language and delivers more reliable and accurate
information in the critical domain of climate change. This work paves the way
for future advancements in LLMs and their application in domains where
precision is of paramount importance.",2023-03-31T20:24:14Z,http://arxiv.org/pdf/2304.00116v1,"['cs.CL', 'cs.IR']"
2306.09597v4,Clickbait Detection via Large Language Models,"['Han Wang', 'Yi Zhu', 'Ye Wang', 'Yun Li', 'Yunhao Yuan', 'Jipeng Qiang']","Clickbait, which aims to induce users with some surprising and even thrilling
headlines for increasing click-through rates, permeates almost all online
content publishers, such as news portals and social media. Recently, Large
Language Models (LLMs) have emerged as a powerful instrument and achieved
tremendous success in a series of NLP downstream tasks. However, it is not yet
known whether LLMs can be served as a high-quality clickbait detection system.
In this paper, we analyze the performance of LLMs in the few-shot and zero-shot
scenarios on several English and Chinese benchmark datasets. Experimental
results show that LLMs cannot achieve the best results compared to the
state-of-the-art deep and fine-tuning PLMs methods. Different from human
intuition, the experiments demonstrated that LLMs cannot make satisfied
clickbait detection just by the headlines.",2023-06-16T02:49:20Z,http://arxiv.org/pdf/2306.09597v4,"['cs.CL', 'cs.AI']"
2310.02932v2,Assessing Large Language Models on Climate Information,"['Jannis Bulian', 'Mike S. Schäfer', 'Afra Amini', 'Heidi Lam', 'Massimiliano Ciaramita', 'Ben Gaiarin', 'Michelle Chen Hübscher', 'Christian Buck', 'Niels G. Mede', 'Markus Leippold', 'Nadine Strauß']","As Large Language Models (LLMs) rise in popularity, it is necessary to assess
their capability in critically relevant domains. We present a comprehensive
evaluation framework, grounded in science communication research, to assess LLM
responses to questions about climate change. Our framework emphasizes both
presentational and epistemological adequacy, offering a fine-grained analysis
of LLM generations spanning 8 dimensions and 30 issues. Our evaluation task is
a real-world example of a growing number of challenging problems where AI can
complement and lift human performance. We introduce a novel protocol for
scalable oversight that relies on AI Assistance and raters with relevant
education. We evaluate several recent LLMs on a set of diverse climate
questions. Our results point to a significant gap between surface and
epistemological qualities of LLMs in the realm of climate communication.",2023-10-04T16:09:48Z,http://arxiv.org/pdf/2310.02932v2,"['cs.CL', 'cs.AI', 'cs.CY', 'cs.LG']"
2310.13002v1,Are Large Language Models Geospatially Knowledgeable?,"['Prabin Bhandari', 'Antonios Anastasopoulos', 'Dieter Pfoser']","Despite the impressive performance of Large Language Models (LLM) for various
natural language processing tasks, little is known about their comprehension of
geographic data and related ability to facilitate informed geospatial
decision-making. This paper investigates the extent of geospatial knowledge,
awareness, and reasoning abilities encoded within such pretrained LLMs. With a
focus on autoregressive language models, we devise experimental approaches
related to (i) probing LLMs for geo-coordinates to assess geospatial knowledge,
(ii) using geospatial and non-geospatial prepositions to gauge their geospatial
awareness, and (iii) utilizing a multidimensional scaling (MDS) experiment to
assess the models' geospatial reasoning capabilities and to determine locations
of cities based on prompting. Our results confirm that it does not only take
larger, but also more sophisticated LLMs to synthesize geospatial knowledge
from textual information. As such, this research contributes to understanding
the potential and limitations of LLMs in dealing with geospatial information.",2023-10-09T17:20:11Z,http://arxiv.org/pdf/2310.13002v1,['cs.CL']
2312.04528v2,Using Large Language Models for Hyperparameter Optimization,"['Michael R. Zhang', 'Nishkrit Desai', 'Juhan Bae', 'Jonathan Lorraine', 'Jimmy Ba']","This paper explores the use of foundational large language models (LLMs) in
hyperparameter optimization (HPO). Hyperparameters are critical in determining
the effectiveness of machine learning models, yet their optimization often
relies on manual approaches in limited-budget settings. By prompting LLMs with
dataset and model descriptions, we develop a methodology where LLMs suggest
hyperparameter configurations, which are iteratively refined based on model
performance. Our empirical evaluations on standard benchmarks reveal that
within constrained search budgets, LLMs can match or outperform traditional HPO
methods like Bayesian optimization across different models on standard
benchmarks. Furthermore, we propose to treat the code specifying our model as a
hyperparameter, which the LLM outputs and affords greater flexibility than
existing HPO approaches.",2023-12-07T18:46:50Z,http://arxiv.org/pdf/2312.04528v2,"['cs.LG', 'cs.AI']"
2312.05516v3,Stateful Large Language Model Serving with Pensieve,"['Lingfan Yu', 'Jinkun Lin', 'Jinyang Li']","Large Language Models (LLMs) are wildly popular today and it is important to
serve them efficiently. Existing LLM serving systems are stateless across
requests. Consequently, when LLMs are used in the common setting of multi-turn
conversations, a growing log of the conversation history must be processed
alongside any request by the serving system at each turn, resulting in repeated
processing.
  In this paper, we design $Pensieve$, a system optimized for multi-turn
conversation LLM serving. $Pensieve$ maintains the conversation state across
requests by caching previously processed history to avoid duplicate processing.
$Pensieve$'s multi-tier caching strategy can utilize both GPU and CPU memory to
efficiently store and retrieve cached data. $Pensieve$ also generalizes the
recent PagedAttention kernel to support attention between multiple input tokens
with a GPU cache spread over non-contiguous memory. Our evaluation shows that
$Pensieve$ can achieve $1.14$-$3.0\times$ the throughput of vLLM and
TensorRT-LLM and significantly reduce latency.",2023-12-09T09:55:07Z,http://arxiv.org/pdf/2312.05516v3,"['cs.LG', 'cs.DC']"
2402.03147v1,Detecting Scams Using Large Language Models,['Liming Jiang'],"Large Language Models (LLMs) have gained prominence in various applications,
including security. This paper explores the utility of LLMs in scam detection,
a critical aspect of cybersecurity. Unlike traditional applications, we propose
a novel use case for LLMs to identify scams, such as phishing, advance fee
fraud, and romance scams. We present notable security applications of LLMs and
discuss the unique challenges posed by scams. Specifically, we outline the key
steps involved in building an effective scam detector using LLMs, emphasizing
data collection, preprocessing, model selection, training, and integration into
target systems. Additionally, we conduct a preliminary evaluation using GPT-3.5
and GPT-4 on a duplicated email, highlighting their proficiency in identifying
common signs of phishing or scam emails. The results demonstrate the models'
effectiveness in recognizing suspicious elements, but we emphasize the need for
a comprehensive assessment across various language tasks. The paper concludes
by underlining the importance of ongoing refinement and collaboration with
cybersecurity experts to adapt to evolving threats.",2024-02-05T16:13:54Z,http://arxiv.org/pdf/2402.03147v1,['cs.CR']
2403.05063v2,Aligning Large Language Models for Controllable Recommendations,"['Wensheng Lu', 'Jianxun Lian', 'Wei Zhang', 'Guanghua Li', 'Mingyang Zhou', 'Hao Liao', 'Xing Xie']","Inspired by the exceptional general intelligence of Large Language Models
(LLMs), researchers have begun to explore their application in pioneering the
next generation of recommender systems - systems that are conversational,
explainable, and controllable. However, existing literature primarily
concentrates on integrating domain-specific knowledge into LLMs to enhance
accuracy, often neglecting the ability to follow instructions. To address this
gap, we initially introduce a collection of supervised learning tasks,
augmented with labels derived from a conventional recommender model, aimed at
explicitly improving LLMs' proficiency in adhering to recommendation-specific
instructions. Subsequently, we develop a reinforcement learning-based alignment
procedure to further strengthen LLMs' aptitude in responding to users'
intentions and mitigating formatting errors. Through extensive experiments on
two real-world datasets, our method markedly advances the capability of LLMs to
comply with instructions within recommender systems, while sustaining a high
level of accuracy performance.",2024-03-08T05:23:27Z,http://arxiv.org/pdf/2403.05063v2,"['cs.IR', 'cs.AI', '68T50']"
2403.06259v2,Editing Conceptual Knowledge for Large Language Models,"['Xiaohan Wang', 'Shengyu Mao', 'Ningyu Zhang', 'Shumin Deng', 'Yunzhi Yao', 'Yue Shen', 'Lei Liang', 'Jinjie Gu', 'Huajun Chen']","Recently, there has been a growing interest in knowledge editing for Large
Language Models (LLMs). Current approaches and evaluations merely explore the
instance-level editing, while whether LLMs possess the capability to modify
concepts remains unclear. This paper pioneers the investigation of editing
conceptual knowledge for LLMs, by constructing a novel benchmark dataset
ConceptEdit and establishing a suite of new metrics for evaluation. The
experimental results reveal that, although existing editing methods can
efficiently modify concept-level definition to some extent, they also have the
potential to distort the related instantial knowledge in LLMs, leading to poor
performance. We anticipate this can inspire further progress in better
understanding LLMs. Our project homepage is available at
https://zjunlp.github.io/project/ConceptEdit.",2024-03-10T16:57:10Z,http://arxiv.org/pdf/2403.06259v2,"['cs.CL', 'cs.AI', 'cs.DB', 'cs.IR', 'cs.LG']"
2404.16841v1,Machine Unlearning in Large Language Models,"['Kongyang Chen', 'Zixin Wang', 'Bing Mi', 'Waixi Liu', 'Shaowei Wang', 'Xiaojun Ren', 'Jiaxing Shen']","Recently, large language models (LLMs) have emerged as a notable field,
attracting significant attention for its ability to automatically generate
intelligent contents for various application domains. However, LLMs still
suffer from significant security and privacy issues. For example, LLMs might
expose user privacy from hacking attacks or targeted prompts. To address this
problem, this paper introduces a novel machine unlearning framework into LLMs.
Our objectives are to make LLMs not produce harmful, hallucinatory, or
privacy-compromising responses, while retaining their standard output
capabilities. To accomplish this, we use an evaluative model to pinpoint
dialogues needing unlearning. We also establish a distance loss to function as
the model's negative loss, diverting it from previous undesirable outputs.
Furthermore, we determine the expected output's cluster mean to formulate a
positive loss, directing the model's outputs toward preferable outcomes without
compromising its reasoning abilities and performance. Experimental results show
that our approach effectively meets unlearning objectives without substantially
compromising model performance.",2024-02-03T05:14:56Z,http://arxiv.org/pdf/2404.16841v1,['cs.CR']
2405.11581v2,DOLLmC: DevOps for Large Language model Customization,"['Panos Fitsilis', 'Vyron Damasiotis', 'Vasileios Kyriatzis', 'Paraskevi Tsoutsa']","The rapid integration of Large Language Models (LLMs) into various industries
presents both revolutionary opportunities and unique challenges. This research
aims to establish a scalable and efficient framework for LLM customization,
exploring how DevOps practices should be adapted to meet the specific demands
of LLM customization. By integrating ontologies, knowledge maps, and prompt
engineering into the DevOps pipeline, we propose a robust framework that
enhances continuous learning, seamless deployment, and rigorous version control
of LLMs. This methodology is demonstrated through the development of a
domain-specific chatbot for the agricultural sector, utilizing heterogeneous
data to deliver actionable insights. The proposed methodology, so called
DOLLmC, not only addresses the immediate challenges of LLM customization but
also promotes scalability and operational efficiency. However, the
methodology's primary limitation lies in the need for extensive testing,
validation, and broader adoption across different domains.",2024-05-19T15:20:27Z,http://arxiv.org/pdf/2405.11581v2,"['cs.SE', 'D.2.9']"
2405.19563v1,Unlearning Climate Misinformation in Large Language Models,"['Michael Fore', 'Simranjit Singh', 'Chaehong Lee', 'Amritanshu Pandey', 'Antonios Anastasopoulos', 'Dimitrios Stamoulis']","Misinformation regarding climate change is a key roadblock in addressing one
of the most serious threats to humanity. This paper investigates factual
accuracy in large language models (LLMs) regarding climate information. Using
true/false labeled Q&A data for fine-tuning and evaluating LLMs on
climate-related claims, we compare open-source models, assessing their ability
to generate truthful responses to climate change questions. We investigate the
detectability of models intentionally poisoned with false climate information,
finding that such poisoning may not affect the accuracy of a model's responses
in other domains. Furthermore, we compare the effectiveness of unlearning
algorithms, fine-tuning, and Retrieval-Augmented Generation (RAG) for factually
grounding LLMs on climate change topics. Our evaluation reveals that unlearning
algorithms can be effective for nuanced conceptual claims, despite previous
findings suggesting their inefficacy in privacy contexts. These insights aim to
guide the development of more factually reliable LLMs and highlight the need
for additional work to secure LLMs against misinformation attacks.",2024-05-29T23:11:53Z,http://arxiv.org/pdf/2405.19563v1,['cs.CL']
2406.07914v2,Can Large Language Models Understand Spatial Audio?,"['Changli Tang', 'Wenyi Yu', 'Guangzhi Sun', 'Xianzhao Chen', 'Tian Tan', 'Wei Li', 'Jun Zhang', 'Lu Lu', 'Zejun Ma', 'Yuxuan Wang', 'Chao Zhang']","This paper explores enabling large language models (LLMs) to understand
spatial information from multichannel audio, a skill currently lacking in
auditory LLMs. By leveraging LLMs' advanced cognitive and inferential
abilities, the aim is to enhance understanding of 3D environments via audio. We
study 3 spatial audio tasks: sound source localization (SSL), far-field speech
recognition (FSR), and localisation-informed speech extraction (LSE), achieving
notable progress in each task. For SSL, our approach achieves an MAE of
$2.70^{\circ}$ on the Spatial LibriSpeech dataset, substantially surpassing the
prior benchmark of about $6.60^{\circ}$. Moreover, our model can employ spatial
cues to improve FSR accuracy and execute LSE by selectively attending to sounds
originating from a specified direction via text prompts, even amidst
overlapping speech. These findings highlight the potential of adapting LLMs to
grasp physical audio concepts, paving the way for LLM-based agents in 3D
environments.",2024-06-12T06:34:21Z,http://arxiv.org/pdf/2406.07914v2,"['cs.SD', 'eess.AS']"
2406.18616v1,Towards Large Language Model Aided Program Refinement,"['Yufan Cai', 'Zhe Hou', 'Xiaokun Luan', 'David Miguel Sanan Baena', 'Yun Lin', 'Jun Sun', 'Jin Song Dong']","Program refinement involves correctness-preserving transformations from
formal high-level specification statements into executable programs.
Traditional verification tool support for program refinement is highly
interactive and lacks automation. On the other hand, the emergence of large
language models (LLMs) enables automatic code generations from informal natural
language specifications. However, code generated by LLMs is often unreliable.
Moreover, the opaque procedure from specification to code provided by LLM is an
uncontrolled black box. We propose LLM4PR, a tool that combines formal program
refinement techniques with informal LLM-based methods to (1) transform the
specification to preconditions and postconditions, (2) automatically build
prompts based on refinement calculus, (3) interact with LLM to generate code,
and finally, (4) verify that the generated code satisfies the conditions of
refinement calculus, thus guaranteeing the correctness of the code. We have
implemented our tool using GPT4, Coq, and Coqhammer, and evaluated it on the
HumanEval and EvalPlus datasets.",2024-06-26T04:29:27Z,http://arxiv.org/pdf/2406.18616v1,"['cs.SE', 'cs.AI', 'cs.CL', 'K.6.3']"
2407.15847v4,LLMmap: Fingerprinting For Large Language Models,"['Dario Pasquini', 'Evgenios M. Kornaropoulos', 'Giuseppe Ateniese']","We introduce LLMmap, a first-generation fingerprinting technique targeted at
LLM-integrated applications. LLMmap employs an active fingerprinting approach,
sending carefully crafted queries to the application and analyzing the
responses to identify the specific LLM version in use. Our query selection is
informed by domain expertise on how LLMs generate uniquely identifiable
responses to thematically varied prompts. With as few as 8 interactions, LLMmap
can accurately identify 42 different LLM versions with over 95% accuracy. More
importantly, LLMmap is designed to be robust across different application
layers, allowing it to identify LLM versions--whether open-source or
proprietary--from various vendors, operating under various unknown system
prompts, stochastic sampling hyperparameters, and even complex generation
frameworks such as RAG or Chain-of-Thought. We discuss potential mitigations
and demonstrate that, against resourceful adversaries, effective
countermeasures may be challenging or even unrealizable.",2024-07-22T17:59:45Z,http://arxiv.org/pdf/2407.15847v4,"['cs.CR', 'cs.AI']"
2408.11316v2,Probabilistic Medical Predictions of Large Language Models,"['Bowen Gu', 'Rishi J. Desai', 'Kueiyu Joshua Lin', 'Jie Yang']","Large Language Models (LLMs) have shown promise in clinical applications
through prompt engineering, allowing flexible clinical predictions. However,
they struggle to produce reliable prediction probabilities, which are crucial
for transparency and decision-making. While explicit prompts can lead LLMs to
generate probability estimates, their numerical reasoning limitations raise
concerns about reliability. We compared explicit probabilities from text
generation to implicit probabilities derived from the likelihood of predicting
the correct label token. Across six advanced open-source LLMs and five medical
datasets, explicit probabilities consistently underperformed implicit
probabilities in discrimination, precision, and recall. This discrepancy is
more pronounced with smaller LLMs and imbalanced datasets, highlighting the
need for cautious interpretation, improved probability estimation methods, and
further research for clinical use of LLMs.",2024-08-21T03:47:17Z,http://arxiv.org/pdf/2408.11316v2,['cs.AI']
2410.02724v2,Large Language Models as Markov Chains,"['Oussama Zekri', 'Ambroise Odonnat', 'Abdelhakim Benechehab', 'Linus Bleistein', 'Nicolas Boullé', 'Ievgen Redko']","Large language models (LLMs) are remarkably efficient across a wide range of
natural language processing tasks and well beyond them. However, a
comprehensive theoretical analysis of the LLMs' generalization capabilities
remains elusive. In our paper, we approach this task by drawing an equivalence
between autoregressive transformer-based language models and Markov chains
defined on a finite state space. This allows us to study the multi-step
inference mechanism of LLMs from first principles. We relate the obtained
results to the pathological behavior observed with LLMs such as repetitions and
incoherent replies with high temperature. Finally, we leverage the proposed
formalization to derive pre-training and in-context learning generalization
bounds for LLMs under realistic data and model assumptions. Experiments with
the most recent Llama and Gemma herds of models show that our theory correctly
captures their behavior in practice.",2024-10-03T17:45:31Z,http://arxiv.org/pdf/2410.02724v2,"['stat.ML', 'cs.AI', 'cs.CL', 'cs.LG']"
2411.14513v1,Towards a Middleware for Large Language Models,"['Narcisa Guran', 'Florian Knauf', 'Man Ngo', 'Stefan Petrescu', 'Jan S. Rellermeyer']","Large language models have gained widespread popularity for their ability to
process natural language inputs and generate insights derived from their
training data, nearing the qualities of true artificial intelligence. This
advancement has prompted enterprises worldwide to integrate LLMs into their
services. So far, this effort is dominated by commercial cloud-based solutions
like OpenAI's ChatGPT and Microsoft Azure. As the technology matures, however,
there is a strong incentive for independence from major cloud providers through
self-hosting ""LLM as a Service"", driven by privacy, cost, and customization
needs. In practice, hosting LLMs independently presents significant challenges
due to their complexity and integration issues with existing systems. In this
paper, we discuss our vision for a forward-looking middleware system
architecture that facilitates the deployment and adoption of LLMs in
enterprises, even for advanced use cases in which we foresee LLMs to serve as
gateways to a complete application ecosystem and, to some degree, absorb
functionality traditionally attributed to the middleware.",2024-11-21T13:55:24Z,http://arxiv.org/pdf/2411.14513v1,"['cs.SE', 'cs.CL']"
2412.10271v2,Benchmarking Linguistic Diversity of Large Language Models,"['Yanzhu Guo', 'Guokan Shang', 'Chloé Clavel']","The development and evaluation of Large Language Models (LLMs) has primarily
focused on their task-solving capabilities, with recent models even surpassing
human performance in some areas. However, this focus often neglects whether
machine-generated language matches the human level of diversity, in terms of
vocabulary choice, syntactic construction, and expression of meaning, raising
questions about whether the fundamentals of language generation have been fully
addressed. This paper emphasizes the importance of examining the preservation
of human linguistic richness by language models, given the concerning surge in
online content produced or aided by LLMs. We propose a comprehensive framework
for evaluating LLMs from various linguistic diversity perspectives including
lexical, syntactic, and semantic dimensions. Using this framework, we benchmark
several state-of-the-art LLMs across all diversity dimensions, and conduct an
in-depth case study for syntactic diversity. Finally, we analyze how different
development and deployment choices impact the linguistic diversity of LLM
outputs.",2024-12-13T16:46:03Z,http://arxiv.org/pdf/2412.10271v2,['cs.CL']
2501.13720v2,Musical ethnocentrism in Large Language Models,['Anna Kruspe'],"Large Language Models (LLMs) reflect the biases in their training data and,
by extension, those of the people who created this training data. Detecting,
analyzing, and mitigating such biases is becoming a focus of research. One type
of bias that has been understudied so far are geocultural biases. Those can be
caused by an imbalance in the representation of different geographic regions
and cultures in the training data, but also by value judgments contained
therein. In this paper, we make a first step towards analyzing musical biases
in LLMs, particularly ChatGPT and Mixtral. We conduct two experiments. In the
first, we prompt LLMs to provide lists of the ""Top 100"" musical contributors of
various categories and analyze their countries of origin. In the second
experiment, we ask the LLMs to numerically rate various aspects of the musical
cultures of different countries. Our results indicate a strong preference of
the LLMs for Western music cultures in both experiments.",2025-01-23T14:50:37Z,http://arxiv.org/pdf/2501.13720v2,"['cs.CL', 'cs.AI', 'cs.SD', 'eess.AS']"
2502.06065v1,Benchmarking Prompt Sensitivity in Large Language Models,"['Amirhossein Razavi', 'Mina Soltangheis', 'Negar Arabzadeh', 'Sara Salamat', 'Morteza Zihayat', 'Ebrahim Bagheri']","Large language Models (LLMs) are highly sensitive to variations in prompt
formulation, which can significantly impact their ability to generate accurate
responses. In this paper, we introduce a new task, Prompt Sensitivity
Prediction, and a dataset PromptSET designed to investigate the effects of
slight prompt variations on LLM performance. Using TriviaQA and HotpotQA
datasets as the foundation of our work, we generate prompt variations and
evaluate their effectiveness across multiple LLMs. We benchmark the prompt
sensitivity prediction task employing state-of-the-art methods from related
tasks, including LLM-based self-evaluation, text classification, and query
performance prediction techniques. Our findings reveal that existing methods
struggle to effectively address prompt sensitivity prediction, underscoring the
need to understand how information needs should be phrased for accurate LLM
responses.",2025-02-09T23:01:03Z,http://arxiv.org/pdf/2502.06065v1,"['cs.CL', 'cs.AI', 'cs.IR']"
2502.17504v2,Protein Large Language Models: A Comprehensive Survey,"['Yijia Xiao', 'Wanjia Zhao', 'Junkai Zhang', 'Yiqiao Jin', 'Han Zhang', 'Zhicheng Ren', 'Renliang Sun', 'Haixin Wang', 'Guancheng Wan', 'Pan Lu', 'Xiao Luo', 'Yu Zhang', 'James Zou', 'Yizhou Sun', 'Wei Wang']","Protein-specific large language models (Protein LLMs) are revolutionizing
protein science by enabling more efficient protein structure prediction,
function annotation, and design. While existing surveys focus on specific
aspects or applications, this work provides the first comprehensive overview of
Protein LLMs, covering their architectures, training datasets, evaluation
metrics, and diverse applications. Through a systematic analysis of over 100
articles, we propose a structured taxonomy of state-of-the-art Protein LLMs,
analyze how they leverage large-scale protein sequence data for improved
accuracy, and explore their potential in advancing protein engineering and
biomedical research. Additionally, we discuss key challenges and future
directions, positioning Protein LLMs as essential tools for scientific
discovery in protein science. Resources are maintained at
https://github.com/Yijia-Xiao/Protein-LLM-Survey.",2025-02-21T19:22:10Z,http://arxiv.org/pdf/2502.17504v2,"['q-bio.BM', 'cs.AI', 'cs.CE', 'cs.CL', 'cs.LG']"
2505.20993v1,Who Reasons in the Large Language Models?,"['Jie Shao', 'Jianxin Wu']","Despite the impressive performance of large language models (LLMs), the
process of endowing them with new capabilities--such as mathematical
reasoning--remains largely empirical and opaque. A critical open question is
whether reasoning abilities stem from the entire model, specific modules, or
are merely artifacts of overfitting. In this work, we hypothesize that the
reasoning capabilities in well-trained LLMs are primarily attributed to the
output projection module (oproj) in the Transformer's multi-head self-attention
(MHSA) mechanism. To support this hypothesis, we introduce Stethoscope for
Networks (SfN), a suite of diagnostic tools designed to probe and analyze the
internal behaviors of LLMs. Using SfN, we provide both circumstantial and
empirical evidence suggesting that oproj plays a central role in enabling
reasoning, whereas other modules contribute more to fluent dialogue. These
findings offer a new perspective on LLM interpretability and open avenues for
more targeted training strategies, potentially enabling more efficient and
specialized LLMs.",2025-05-27T10:26:47Z,http://arxiv.org/pdf/2505.20993v1,"['cs.CL', 'cs.AI']"
2506.20241v1,Enhancing Large Language Models through Structured Reasoning,"['Yubo Dong', 'Hehe Fan']","Recent Large Language Models (LLMs) have significantly advanced natural
language processing and automated decision-making. However, these models still
encounter difficulties when performing complex reasoning tasks involving
logical deduction and systematic planning, primarily due to their reliance on
implicit statistical relationships without structured knowledge
representation.Inspired by cognitive science and neurosymbolic AI, we introduce
a novel approach to enhance LLMs through explicit structured reasoning. First,
we convert unstructured data into structured formats by explicitly annotating
reasoning steps. We then employ this structured dataset to train LLMs through
Supervised Fine-Tuning (SFT). Additionally, we enhance the structured reasoning
capabilities of LLMs using Group Relative Policy Optimization (GRPO),
incorporating two innovative algorithms--MAX-Flow and Longest Common
Subsequence (LCS)--which notably improve reasoning effectiveness and reduce
computational complexity. Experimental results from fine-tuning a
DeepSeek-R1-Distill-Qwen-1.5B model demonstrate concise reasoning, robust
performance across various scenarios, and improved compatibility with
optimization techniques, validating the efficacy of structured reasoning
integration in LLMs.",2025-06-25T08:36:12Z,http://arxiv.org/pdf/2506.20241v1,"['cs.CL', 'cs.AI']"
2506.20274v1,Enterprise Large Language Model Evaluation Benchmark,"['Liya Wang', 'David Yi', 'Damien Jose', 'John Passarelli', 'James Gao', 'Jordan Leventis', 'Kang Li']","Large Language Models (LLMs) ) have demonstrated promise in boosting
productivity across AI-powered tools, yet existing benchmarks like Massive
Multitask Language Understanding (MMLU) inadequately assess enterprise-specific
task complexities. We propose a 14-task framework grounded in Bloom's Taxonomy
to holistically evaluate LLM capabilities in enterprise contexts. To address
challenges of noisy data and costly annotation, we develop a scalable pipeline
combining LLM-as-a-Labeler, LLM-as-a-Judge, and corrective retrieval-augmented
generation (CRAG), curating a robust 9,700-sample benchmark. Evaluation of six
leading models shows open-source contenders like DeepSeek R1 rival proprietary
models in reasoning tasks but lag in judgment-based scenarios, likely due to
overthinking. Our benchmark reveals critical enterprise performance gaps and
offers actionable insights for model optimization. This work provides
enterprises a blueprint for tailored evaluations and advances practical LLM
deployment.",2025-06-25T09:34:25Z,http://arxiv.org/pdf/2506.20274v1,['cs.AI']
2508.17953v1,Understanding Subword Compositionality of Large Language Models,"['Qiwei Peng', 'Yekun Chai', 'Anders Søgaard']","Large language models (LLMs) take sequences of subwords as input, requiring
them to effective compose subword representations into meaningful word-level
representations. In this paper, we present a comprehensive set of experiments
to probe how LLMs compose subword information, focusing on three key aspects:
structural similarity, semantic decomposability, and form retention. Our
analysis of the experiments suggests that these five LLM families can be
classified into three distinct groups, likely reflecting difference in their
underlying composition strategies. Specifically, we observe (i) three distinct
patterns in the evolution of structural similarity between subword compositions
and whole-word representations across layers; (ii) great performance when
probing layer by layer their sensitivity to semantic decompositionality; and
(iii) three distinct patterns when probing sensitivity to formal features,
e.g., character sequence length. These findings provide valuable insights into
the compositional dynamics of LLMs and highlight different compositional
pattens in how LLMs encode and integrate subword information.",2025-08-25T12:16:56Z,http://arxiv.org/pdf/2508.17953v1,"['cs.CL', 'cs.AI', 'cs.LG']"
2305.06972v3,Spear Phishing With Large Language Models,['Julian Hazell'],"Recent progress in artificial intelligence (AI), particularly in the domain
of large language models (LLMs), has resulted in powerful and versatile
dual-use systems. This intelligence can be put towards a wide variety of
beneficial tasks, yet it can also be used to cause harm. This study explores
one such harm by examining how LLMs can be used for spear phishing, a form of
cybercrime that involves manipulating targets into divulging sensitive
information. I first explore LLMs' ability to assist with the reconnaissance
and message generation stages of a spear phishing attack, where I find that
LLMs are capable of assisting with the email generation phase of a spear
phishing attack. To explore how LLMs could potentially be harnessed to scale
spear phishing campaigns, I then create unique spear phishing messages for over
600 British Members of Parliament using OpenAI's GPT-3.5 and GPT-4 models. My
findings provide some evidence that these messages are not only realistic but
also cost-effective, with each email costing only a fraction of a cent to
generate. Next, I demonstrate how basic prompt engineering can circumvent
safeguards installed in LLMs, highlighting the need for further research into
robust interventions that can help prevent models from being misused. To
further address these evolving risks, I explore two potential solutions:
structured access schemes, such as application programming interfaces, and
LLM-based defensive systems.",2023-05-11T16:55:19Z,http://arxiv.org/pdf/2305.06972v3,"['cs.CY', 'cs.AI', 'cs.CR']"
2210.03945v2,Understanding HTML with Large Language Models,"['Izzeddin Gur', 'Ofir Nachum', 'Yingjie Miao', 'Mustafa Safdari', 'Austin Huang', 'Aakanksha Chowdhery', 'Sharan Narang', 'Noah Fiedel', 'Aleksandra Faust']","Large language models (LLMs) have shown exceptional performance on a variety
of natural language tasks. Yet, their capabilities for HTML understanding --
i.e., parsing the raw HTML of a webpage, with applications to automation of
web-based tasks, crawling, and browser-assisted retrieval -- have not been
fully explored. We contribute HTML understanding models (fine-tuned LLMs) and
an in-depth analysis of their capabilities under three tasks: (i) Semantic
Classification of HTML elements, (ii) Description Generation for HTML inputs,
and (iii) Autonomous Web Navigation of HTML pages. While previous work has
developed dedicated architectures and training procedures for HTML
understanding, we show that LLMs pretrained on standard natural language
corpora transfer remarkably well to HTML understanding tasks. For instance,
fine-tuned LLMs are 12% more accurate at semantic classification compared to
models trained exclusively on the task dataset. Moreover, when fine-tuned on
data from the MiniWoB benchmark, LLMs successfully complete 50% more tasks
using 192x less data compared to the previous best supervised model. Out of the
LLMs we evaluate, we show evidence that T5-based models are ideal due to their
bidirectional encoder-decoder architecture. To promote further research on LLMs
for HTML understanding, we create and open-source a large-scale HTML dataset
distilled and auto-labeled from CommonCrawl.",2022-10-08T07:27:17Z,http://arxiv.org/pdf/2210.03945v2,"['cs.LG', 'cs.AI']"
2304.00472v3,Querying Large Language Models with SQL,"['Mohammed Saeed', 'Nicola De Cao', 'Paolo Papotti']","In many use-cases, information is stored in text but not available in
structured data. However, extracting data from natural language text to
precisely fit a schema, and thus enable querying, is a challenging task. With
the rise of pre-trained Large Language Models (LLMs), there is now an effective
solution to store and use information extracted from massive corpora of text
documents. Thus, we envision the use of SQL queries to cover a broad range of
data that is not captured by traditional databases by tapping the information
in LLMs. To ground this vision, we present Galois, a prototype based on a
traditional database architecture, but with new physical operators for querying
the underlying LLM. The main idea is to execute some operators of the the query
plan with prompts that retrieve data from the LLM. For a large class of SQL
queries, querying LLMs returns well structured relations, with encouraging
qualitative results. Preliminary experimental results make pre-trained LLMs a
promising addition to the field of database systems, introducing a new
direction for hybrid query processing. However, we pinpoint several research
challenges that must be addressed to build a DBMS that exploits LLMs. While
some of these challenges necessitate integrating concepts from the NLP
literature, others offer novel research avenues for the DB community.",2023-04-02T06:58:14Z,http://arxiv.org/pdf/2304.00472v3,"['cs.DB', 'cs.AI']"
2309.15025v1,Large Language Model Alignment: A Survey,"['Tianhao Shen', 'Renren Jin', 'Yufei Huang', 'Chuang Liu', 'Weilong Dong', 'Zishan Guo', 'Xinwei Wu', 'Yan Liu', 'Deyi Xiong']","Recent years have witnessed remarkable progress made in large language models
(LLMs). Such advancements, while garnering significant attention, have
concurrently elicited various concerns. The potential of these models is
undeniably vast; however, they may yield texts that are imprecise, misleading,
or even detrimental. Consequently, it becomes paramount to employ alignment
techniques to ensure these models to exhibit behaviors consistent with human
values.
  This survey endeavors to furnish an extensive exploration of alignment
methodologies designed for LLMs, in conjunction with the extant capability
research in this domain. Adopting the lens of AI alignment, we categorize the
prevailing methods and emergent proposals for the alignment of LLMs into outer
and inner alignment. We also probe into salient issues including the models'
interpretability, and potential vulnerabilities to adversarial attacks. To
assess LLM alignment, we present a wide variety of benchmarks and evaluation
methodologies. After discussing the state of alignment research for LLMs, we
finally cast a vision toward the future, contemplating the promising avenues of
research that lie ahead.
  Our aspiration for this survey extends beyond merely spurring research
interests in this realm. We also envision bridging the gap between the AI
alignment research community and the researchers engrossed in the capability
exploration of LLMs for both capable and safe LLMs.",2023-09-26T15:49:23Z,http://arxiv.org/pdf/2309.15025v1,"['cs.CL', 'cs.AI']"
2310.03025v2,Retrieval meets Long Context Large Language Models,"['Peng Xu', 'Wei Ping', 'Xianchao Wu', 'Lawrence McAfee', 'Chen Zhu', 'Zihan Liu', 'Sandeep Subramanian', 'Evelina Bakhturina', 'Mohammad Shoeybi', 'Bryan Catanzaro']","Extending the context window of large language models (LLMs) is getting
popular recently, while the solution of augmenting LLMs with retrieval has
existed for years. The natural questions are: i) Retrieval-augmentation versus
long context window, which one is better for downstream tasks? ii) Can both
methods be combined to get the best of both worlds? In this work, we answer
these questions by studying both solutions using two state-of-the-art
pretrained LLMs, i.e., a proprietary 43B GPT and Llama2-70B. Perhaps
surprisingly, we find that LLM with 4K context window using simple
retrieval-augmentation at generation can achieve comparable performance to
finetuned LLM with 16K context window via positional interpolation on long
context tasks, while taking much less computation. More importantly, we
demonstrate that retrieval can significantly improve the performance of LLMs
regardless of their extended context window sizes. Our best model,
retrieval-augmented Llama2-70B with 32K context window, outperforms
GPT-3.5-turbo-16k and Davinci003 in terms of average score on nine long context
tasks including question answering, query-based summarization, and in-context
few-shot learning tasks. It also outperforms its non-retrieval Llama2-70B-32k
baseline by a margin, while being much faster at generation. Our study provides
general insights on the choice of retrieval-augmentation versus long context
extension of LLM for practitioners.",2023-10-04T17:59:41Z,http://arxiv.org/pdf/2310.03025v2,"['cs.CL', 'cs.AI', 'cs.IR', 'cs.LG']"
2310.05177v1,Do Large Language Models Know about Facts?,"['Xuming Hu', 'Junzhe Chen', 'Xiaochuan Li', 'Yufei Guo', 'Lijie Wen', 'Philip S. Yu', 'Zhijiang Guo']","Large language models (LLMs) have recently driven striking performance
improvements across a range of natural language processing tasks. The factual
knowledge acquired during pretraining and instruction tuning can be useful in
various downstream tasks, such as question answering, and language generation.
Unlike conventional Knowledge Bases (KBs) that explicitly store factual
knowledge, LLMs implicitly store facts in their parameters. Content generated
by the LLMs can often exhibit inaccuracies or deviations from the truth, due to
facts that can be incorrectly induced or become obsolete over time. To this
end, we aim to comprehensively evaluate the extent and scope of factual
knowledge within LLMs by designing the benchmark Pinocchio. Pinocchio contains
20K diverse factual questions that span different sources, timelines, domains,
regions, and languages. Furthermore, we investigate whether LLMs are able to
compose multiple facts, update factual knowledge temporally, reason over
multiple pieces of facts, identify subtle factual differences, and resist
adversarial examples. Extensive experiments on different sizes and types of
LLMs show that existing LLMs still lack factual knowledge and suffer from
various spurious correlations. We believe this is a critical bottleneck for
realizing trustworthy artificial intelligence. The dataset Pinocchio and our
codes will be publicly available.",2023-10-08T14:26:55Z,http://arxiv.org/pdf/2310.05177v1,['cs.CL']
2310.17784v2,Data-Centric Financial Large Language Models,"['Zhixuan Chu', 'Huaiyu Guo', 'Xinyuan Zhou', 'Yijia Wang', 'Fei Yu', 'Hong Chen', 'Wanqing Xu', 'Xin Lu', 'Qing Cui', 'Longfei Li', 'Jun Zhou', 'Sheng Li']","Large language models (LLMs) show promise for natural language tasks but
struggle when applied directly to complex domains like finance. LLMs have
difficulty reasoning about and integrating all relevant information. We propose
a data-centric approach to enable LLMs to better handle financial tasks. Our
key insight is that rather than overloading the LLM with everything at once, it
is more effective to preprocess and pre-understand the data. We create a
financial LLM (FLLM) using multitask prompt-based finetuning to achieve data
pre-processing and pre-understanding. However, labeled data is scarce for each
task. To overcome manual annotation costs, we employ abductive augmentation
reasoning (AAR) to automatically generate training data by modifying the pseudo
labels from FLLM's own outputs. Experiments show our data-centric FLLM with AAR
substantially outperforms baseline financial LLMs designed for raw text,
achieving state-of-the-art on financial analysis and interpretation tasks. We
also open source a new benchmark for financial analysis and interpretation. Our
methodology provides a promising path to unlock LLMs' potential for complex
real-world domains.",2023-10-07T04:53:31Z,http://arxiv.org/pdf/2310.17784v2,"['cs.CL', 'cs.AI', 'cs.LG']"
2310.19046v3,Large Language Models as Evolutionary Optimizers,"['Shengcai Liu', 'Caishun Chen', 'Xinghua Qu', 'Ke Tang', 'Yew-Soon Ong']","Evolutionary algorithms (EAs) have achieved remarkable success in tackling
complex combinatorial optimization problems. However, EAs often demand
carefully-designed operators with the aid of domain expertise to achieve
satisfactory performance. In this work, we present the first study on large
language models (LLMs) as evolutionary combinatorial optimizers. The main
advantage is that it requires minimal domain knowledge and human efforts, as
well as no additional training of the model. This approach is referred to as
LLM-driven EA (LMEA). Specifically, in each generation of the evolutionary
search, LMEA instructs the LLM to select parent solutions from current
population, and perform crossover and mutation to generate offspring solutions.
Then, LMEA evaluates these new solutions and include them into the population
for the next generation. LMEA is equipped with a self-adaptation mechanism that
controls the temperature of the LLM. This enables it to balance between
exploration and exploitation and prevents the search from getting stuck in
local optima. We investigate the power of LMEA on the classical traveling
salesman problems (TSPs) widely used in combinatorial optimization research.
Notably, the results show that LMEA performs competitively to traditional
heuristics in finding high-quality solutions on TSP instances with up to 20
nodes. Additionally, we also study the effectiveness of LLM-driven
crossover/mutation and the self-adaptation mechanism in evolutionary search. In
summary, our results reveal the great potentials of LLMs as evolutionary
optimizers for solving combinatorial problems. We hope our research shall
inspire future explorations on LLM-driven EAs for complex optimization
challenges.",2023-10-29T15:44:52Z,http://arxiv.org/pdf/2310.19046v3,['cs.NE']
2312.04906v1,Ophtha-LLaMA2: A Large Language Model for Ophthalmology,"['Huan Zhao', 'Qian Ling', 'Yi Pan', 'Tianyang Zhong', 'Jin-Yu Hu', 'Junjie Yao', 'Fengqian Xiao', 'Zhenxiang Xiao', 'Yutong Zhang', 'San-Hua Xu', 'Shi-Nan Wu', 'Min Kang', 'Zihao Wu', 'Zhengliang Liu', 'Xi Jiang', 'Tianming Liu', 'Yi Shao']","In recent years, pre-trained large language models (LLMs) have achieved
tremendous success in the field of Natural Language Processing (NLP). Prior
studies have primarily focused on general and generic domains, with relatively
less research on specialized LLMs in the medical field. The specialization and
high accuracy requirements for diagnosis in the medical field, as well as the
challenges in collecting large-scale data, have constrained the application and
development of LLMs in medical scenarios. In the field of ophthalmology,
clinical diagnosis mainly relies on doctors' interpretation of reports and
making diagnostic decisions. In order to take advantage of LLMs to provide
decision support for doctors, we collected three modalities of ophthalmic
report data and fine-tuned the LLaMA2 model, successfully constructing an LLM
termed the ""Ophtha-LLaMA2"" specifically tailored for ophthalmic disease
diagnosis. Inference test results show that even with a smaller fine-tuning
dataset, Ophtha-LLaMA2 performs significantly better in ophthalmic diagnosis
compared to other LLMs. It demonstrates that the Ophtha-LLaMA2 exhibits
satisfying accuracy and efficiency in ophthalmic disease diagnosis, making it a
valuable tool for ophthalmologists to provide improved diagnostic support for
patients. This research provides a useful reference for the application of LLMs
in the field of ophthalmology, while showcasing the immense potential and
prospects in this domain.",2023-12-08T08:43:46Z,http://arxiv.org/pdf/2312.04906v1,['cs.CL']
2401.08273v3,Large Language Models are Null-Shot Learners,"['Pittawat Taveekitworachai', 'Febri Abdullah', 'Ruck Thawonmas']","This paper presents null-shot prompting. Null-shot prompting exploits
hallucination in large language models (LLMs) by instructing LLMs to utilize
information from the ""Examples"" section that never exists within the provided
context to perform a task. While reducing hallucination is crucial and
non-negligible for daily and critical uses of LLMs, we propose that in the
current landscape in which these LLMs still hallucinate, it is possible, in
fact, to exploit hallucination to increase performance in performing tasks
compared to standard zero-shot prompting. Experiments with eight LLMs show
improvements in performance across the majority of eight datasets, including
reading comprehension, arithmetic reasoning, and closed-book question
answering. The observed inconsistency in increased relative performance across
the LLMs also potentially indicates a different degree of inherent
hallucination in each model. These differences show that it is possible to
utilize null-shot prompting as a way to detect degrees of hallucination in LLMs
using existing benchmarking datasets. We also perform ablation studies,
including experimenting with a modified version of null-shot prompting that
incorporates ideas from zero-shot chain-of-thought prompting, which shows
different trends of results.",2024-01-16T10:53:11Z,http://arxiv.org/pdf/2401.08273v3,"['cs.CL', 'cs.AI', 'cs.LG']"
2402.02338v3,NetLLM: Adapting Large Language Models for Networking,"['Duo Wu', 'Xianda Wang', 'Yaqi Qiao', 'Zhi Wang', 'Junchen Jiang', 'Shuguang Cui', 'Fangxin Wang']","Many networking tasks now employ deep learning (DL) to solve complex
prediction and optimization problems. However, current design philosophy of
DL-based algorithms entails intensive engineering overhead due to the manual
design of deep neural networks (DNNs) for different networking tasks. Besides,
DNNs tend to achieve poor generalization performance on unseen data
distributions/environments.
  Motivated by the recent success of large language models (LLMs), this work
studies the LLM adaptation for networking to explore a more sustainable design
philosophy. With the powerful pre-trained knowledge, the LLM is promising to
serve as the foundation model to achieve ""one model for all tasks"" with even
better performance and stronger generalization. In pursuit of this vision, we
present NetLLM, the first framework that provides a coherent design to harness
the powerful capabilities of LLMs with low efforts to solve networking
problems. Specifically, NetLLM empowers the LLM to effectively process
multimodal data in networking and efficiently generate task-specific answers.
Besides, NetLLM drastically reduces the costs of fine-tuning the LLM to acquire
domain knowledge for networking. Across three networking-related use cases -
viewport prediction, adaptive bitrate streaming and cluster job scheduling, we
showcase that the NetLLM-adapted LLM significantly outperforms state-of-the-art
algorithms.",2024-02-04T04:21:34Z,http://arxiv.org/pdf/2402.02338v3,"['cs.NI', 'cs.LG']"
2403.08213v2,Can Large Language Models Identify Authorship?,"['Baixiang Huang', 'Canyu Chen', 'Kai Shu']","The ability to accurately identify authorship is crucial for verifying
content authenticity and mitigating misinformation. Large Language Models
(LLMs) have demonstrated an exceptional capacity for reasoning and
problem-solving. However, their potential in authorship analysis remains
under-explored. Traditional studies have depended on hand-crafted stylistic
features, whereas state-of-the-art approaches leverage text embeddings from
pre-trained language models. These methods, which typically require fine-tuning
on labeled data, often suffer from performance degradation in cross-domain
applications and provide limited explainability. This work seeks to address
three research questions: (1) Can LLMs perform zero-shot, end-to-end authorship
verification effectively? (2) Are LLMs capable of accurately attributing
authorship among multiple candidates authors (e.g., 10 and 20)? (3) Can LLMs
provide explainability in authorship analysis, particularly through the role of
linguistic features? Moreover, we investigate the integration of explicit
linguistic features to guide LLMs in their reasoning processes. Our assessment
demonstrates LLMs' proficiency in both tasks without the need for
domain-specific fine-tuning, providing explanations into their decision making
via a detailed analysis of linguistic features. This establishes a new
benchmark for future research on LLM-based authorship analysis.",2024-03-13T03:22:02Z,http://arxiv.org/pdf/2403.08213v2,['cs.CL']
2403.14469v1,ChatGPT Alternative Solutions: Large Language Models Survey,"['Hanieh Alipour', 'Nick Pendar', 'Kohinoor Roy']","In recent times, the grandeur of Large Language Models (LLMs) has not only
shone in the realm of natural language processing but has also cast its
brilliance across a vast array of applications. This remarkable display of LLM
capabilities has ignited a surge in research contributions within this domain,
spanning a diverse spectrum of topics. These contributions encompass
advancements in neural network architecture, context length enhancements, model
alignment, training datasets, benchmarking, efficiency improvements, and more.
Recent years have witnessed a dynamic synergy between academia and industry,
propelling the field of LLM research to new heights. A notable milestone in
this journey is the introduction of ChatGPT, a powerful AI chatbot grounded in
LLMs, which has garnered widespread societal attention. The evolving technology
of LLMs has begun to reshape the landscape of the entire AI community,
promising a revolutionary shift in the way we create and employ AI algorithms.
Given this swift-paced technical evolution, our survey embarks on a journey to
encapsulate the recent strides made in the world of LLMs. Through an
exploration of the background, key discoveries, and prevailing methodologies,
we offer an up-to-the-minute review of the literature. By examining multiple
LLM models, our paper not only presents a comprehensive overview but also
charts a course that identifies existing challenges and points toward potential
future research trajectories. This survey furnishes a well-rounded perspective
on the current state of generative AI, shedding light on opportunities for
further exploration, enhancement, and innovation.",2024-03-21T15:16:50Z,http://arxiv.org/pdf/2403.14469v1,"['cs.CL', 'cs.AI']"
2404.10229v2,Generative Text Steganography with Large Language Model,"['Jiaxuan Wu', 'Zhengxian Wu', 'Yiming Xue', 'Juan Wen', 'Wanli Peng']","Recent advances in large language models (LLMs) have blurred the boundary of
high-quality text generation between humans and machines, which is favorable
for generative text steganography. While, current advanced steganographic
mapping is not suitable for LLMs since most users are restricted to accessing
only the black-box API or user interface of the LLMs, thereby lacking access to
the training vocabulary and its sampling probabilities. In this paper, we
explore a black-box generative text steganographic method based on the user
interfaces of large language models, which is called LLM-Stega. The main goal
of LLM-Stega is that the secure covert communication between Alice (sender) and
Bob (receiver) is conducted by using the user interfaces of LLMs. Specifically,
We first construct a keyword set and design a new encrypted steganographic
mapping to embed secret messages. Furthermore, to guarantee accurate extraction
of secret messages and rich semantics of generated stego texts, an optimization
mechanism based on reject sampling is proposed. Comprehensive experiments
demonstrate that the proposed LLM-Stega outperforms current state-of-the-art
methods.",2024-04-16T02:19:28Z,http://arxiv.org/pdf/2404.10229v2,['cs.CL']
2405.16127v2,Finetuning Large Language Model for Personalized Ranking,"['Zhuoxi Bai', 'Ning Wu', 'Fengyu Cai', 'Xinyi Zhu', 'Yun Xiong']","Large Language Models (LLMs) have demonstrated remarkable performance across
various domains, motivating researchers to investigate their potential use in
recommendation systems. However, directly applying LLMs to recommendation tasks
has proven challenging due to the significant disparity between the data used
for pre-training LLMs and the specific requirements of recommendation tasks. In
this study, we introduce Direct Multi-Preference Optimization (DMPO), a
streamlined framework designed to bridge the gap and enhance the alignment of
LLMs for recommendation tasks. DMPO enhances the performance of LLM-based
recommenders by simultaneously maximizing the probability of positive samples
and minimizing the probability of multiple negative samples. We conducted
experimental evaluations to compare DMPO against traditional recommendation
methods and other LLM-based recommendation approaches. The results demonstrate
that DMPO significantly improves the recommendation capabilities of LLMs across
three real-world public datasets in few-shot scenarios. Additionally, the
experiments indicate that DMPO exhibits superior generalization ability in
cross-domain recommendations. A case study elucidates the reasons behind these
consistent improvements and also underscores DMPO's potential as an explainable
recommendation system.",2024-05-25T08:36:15Z,http://arxiv.org/pdf/2405.16127v2,['cs.IR']
2406.13261v3,BeHonest: Benchmarking Honesty in Large Language Models,"['Steffi Chern', 'Zhulin Hu', 'Yuqing Yang', 'Ethan Chern', 'Yuan Guo', 'Jiahe Jin', 'Binjie Wang', 'Pengfei Liu']","Previous works on Large Language Models (LLMs) have mainly focused on
evaluating their helpfulness or harmlessness. However, honesty, another crucial
alignment criterion, has received relatively less attention. Dishonest
behaviors in LLMs, such as spreading misinformation and defrauding users,
present severe risks that intensify as these models approach superintelligent
levels. Enhancing honesty in LLMs addresses critical limitations and helps
uncover latent capabilities that are not readily expressed. This underscores
the urgent need for reliable methods and benchmarks to effectively ensure and
evaluate the honesty of LLMs.
  In this paper, we introduce BeHonest, a pioneering benchmark specifically
designed to assess honesty in LLMs comprehensively. BeHonest evaluates three
essential aspects of honesty: awareness of knowledge boundaries, avoidance of
deceit, and consistency in responses. Building on this foundation, we designed
10 scenarios to evaluate and analyze 9 popular LLMs on the market, including
both closed-source and open-source models from different model families with
varied model sizes. Our findings indicate that there is still significant room
for improvement in the honesty of LLMs. We encourage the AI community to
prioritize honesty alignment in these models, which can harness their full
potential to benefit society while preventing them from causing harm through
deception or inconsistency. Our benchmark and code can be found at:
\url{https://github.com/GAIR-NLP/BeHonest}.",2024-06-19T06:46:59Z,http://arxiv.org/pdf/2406.13261v3,"['cs.CL', 'cs.AI']"
2407.06564v1,Combining Knowledge Graphs and Large Language Models,"['Amanda Kau', 'Xuzeng He', 'Aishwarya Nambissan', 'Aland Astudillo', 'Hui Yin', 'Amir Aryani']","In recent years, Natural Language Processing (NLP) has played a significant
role in various Artificial Intelligence (AI) applications such as chatbots,
text generation, and language translation. The emergence of large language
models (LLMs) has greatly improved the performance of these applications,
showing astonishing results in language understanding and generation. However,
they still show some disadvantages, such as hallucinations and lack of
domain-specific knowledge, that affect their performance in real-world tasks.
These issues can be effectively mitigated by incorporating knowledge graphs
(KGs), which organise information in structured formats that capture
relationships between entities in a versatile and interpretable fashion.
Likewise, the construction and validation of KGs present challenges that LLMs
can help resolve. The complementary relationship between LLMs and KGs has led
to a trend that combines these technologies to achieve trustworthy results.
This work collected 28 papers outlining methods for KG-powered LLMs, LLM-based
KGs, and LLM-KG hybrid approaches. We systematically analysed and compared
these approaches to provide a comprehensive overview highlighting key trends,
innovative techniques, and common challenges. This synthesis will benefit
researchers new to the field and those seeking to deepen their understanding of
how KGs and LLMs can be effectively combined to enhance AI applications
capabilities.",2024-07-09T05:42:53Z,http://arxiv.org/pdf/2407.06564v1,"['cs.CL', 'cs.AI']"
2407.17866v3,Financial Statement Analysis with Large Language Models,"['Alex Kim', 'Maximilian Muhn', 'Valeri Nikolaev']","We investigate whether large language models (LLMs) can successfully perform
financial statement analysis in a way similar to a professional human analyst.
We provide standardized and anonymous financial statements to GPT4 and instruct
the model to analyze them to determine the direction of firms' future earnings.
Even without narrative or industry-specific information, the LLM outperforms
financial analysts in its ability to predict earnings changes directionally.
The LLM exhibits a relative advantage over human analysts in situations when
the analysts tend to struggle. Furthermore, we find that the prediction
accuracy of the LLM is on par with a narrowly trained state-of-the-art ML
model. LLM prediction does not stem from its training memory. Instead, we find
that the LLM generates useful narrative insights about a company's future
performance. Lastly, our trading strategies based on GPT's predictions yield a
higher Sharpe ratio and alphas than strategies based on other models. Our
results suggest that LLMs may take a central role in analysis and
decision-making.",2024-07-25T08:36:58Z,http://arxiv.org/pdf/2407.17866v3,"['q-fin.ST', 'cs.AI', 'cs.CL', 'q-fin.GN', 'q-fin.PM']"
2408.09895v4,Performance Law of Large Language Models,"['Chuhan Wu', 'Ruiming Tang']","Guided by the belief of the scaling law, large language models (LLMs) have
achieved impressive performance in recent years. However, scaling law only
gives a qualitative estimation of loss, which is influenced by various factors
such as model architectures, data distributions, tokenizers, and computation
precision. Thus, estimating the real performance of LLMs with different
training settings rather than loss may be quite useful in practical
development. In this article, we present an empirical equation named
""Performance Law"" to directly predict the MMLU score of an LLM, which is a
widely used metric to indicate the general capability of LLMs in real-world
conversations and applications. Based on only a few key hyperparameters of the
LLM architecture and the size of training data, we obtain a quite accurate MMLU
prediction of various LLMs with diverse sizes and architectures developed by
different organizations in different years. Performance law can be used to
guide the choice of LLM architecture and the effective allocation of
computational resources without extensive experiments.",2024-08-19T11:09:12Z,http://arxiv.org/pdf/2408.09895v4,"['cs.CL', 'cs.LG']"
2408.15879v2,Persuasion Games using Large Language Models,"['Ganesh Prasath Ramani', 'Shirish Karande', 'Santhosh V', 'Yash Bhatia']","Large Language Models (LLMs) have emerged as formidable instruments capable
of comprehending and producing human-like text. This paper explores the
potential of LLMs, to shape user perspectives and subsequently influence their
decisions on particular tasks. This capability finds applications in diverse
domains such as Investment, Credit cards and Insurance, wherein they assist
users in selecting appropriate insurance policies, investment plans, Credit
cards, Retail, as well as in Behavioral Change Support Systems (BCSS).
  We present a sophisticated multi-agent framework wherein a consortium of
agents operate in collaborative manner. The primary agent engages directly with
user agents through persuasive dialogue, while the auxiliary agents perform
tasks such as information retrieval, response analysis, development of
persuasion strategies, and validation of facts. Empirical evidence from our
experiments demonstrates that this collaborative methodology significantly
enhances the persuasive efficacy of the LLM. We continuously analyze the
resistance of the user agent to persuasive efforts and counteract it by
employing a combination of rule-based and LLM-based resistance-persuasion
mapping techniques.
  We employ simulated personas and generate conversations in insurance,
banking, and retail domains to evaluate the proficiency of large language
models (LLMs) in recognizing, adjusting to, and influencing various personality
types. Concurrently, we examine the resistance mechanisms employed by LLM
simulated personas. Persuasion is quantified via measurable surveys before and
after interaction, LLM-generated scores on conversation, and user decisions
(purchase or non-purchase).",2024-08-28T15:50:41Z,http://arxiv.org/pdf/2408.15879v2,"['cs.AI', 'cs.CL']"
2409.05925v2,Assessing SPARQL capabilities of Large Language Models,"['Lars-Peter Meyer', 'Johannes Frey', 'Felix Brei', 'Natanael Arndt']","The integration of Large Language Models (LLMs) with Knowledge Graphs (KGs)
offers significant synergistic potential for knowledge-driven applications. One
possible integration is the interpretation and generation of formal languages,
such as those used in the Semantic Web, with SPARQL being a core technology for
accessing KGs. In this paper, we focus on measuring out-of-the box capabilities
of LLMs to work with SPARQL and more specifically with SPARQL SELECT queries
applying a quantitative approach.
  We implemented various benchmarking tasks in the LLM-KG-Bench framework for
automated execution and evaluation with several LLMs. The tasks assess
capabilities along the dimensions of syntax, semantic read, semantic create,
and the role of knowledge graph prompt inclusion.
  With this new benchmarking tasks, we evaluated a selection of GPT, Gemini,
and Claude models. Our findings indicate that working with SPARQL SELECT
queries is still challenging for LLMs and heavily depends on the specific LLM
as well as the complexity of the task. While fixing basic syntax errors seems
to pose no problems for the best of the current LLMs evaluated, creating
semantically correct SPARQL SELECT queries is difficult in several cases.",2024-09-09T08:29:39Z,http://arxiv.org/pdf/2409.05925v2,"['cs.DB', 'cs.AI', 'cs.CL', 'cs.IR']"
2409.17372v2,Search for Efficient Large Language Models,"['Xuan Shen', 'Pu Zhao', 'Yifan Gong', 'Zhenglun Kong', 'Zheng Zhan', 'Yushu Wu', 'Ming Lin', 'Chao Wu', 'Xue Lin', 'Yanzhi Wang']","Large Language Models (LLMs) have long held sway in the realms of artificial
intelligence research. Numerous efficient techniques, including weight pruning,
quantization, and distillation, have been embraced to compress LLMs, targeting
memory reduction and inference acceleration, which underscore the redundancy in
LLMs. However, most model compression techniques concentrate on weight
optimization, overlooking the exploration of optimal architectures. Besides,
traditional architecture search methods, limited by the elevated complexity
with extensive parameters, struggle to demonstrate their effectiveness on LLMs.
In this paper, we propose a training-free architecture search framework to
identify optimal subnets that preserve the fundamental strengths of the
original LLMs while achieving inference acceleration. Furthermore, after
generating subnets that inherit specific weights from the original LLMs, we
introduce a reformation algorithm that utilizes the omitted weights to rectify
the inherited weights with a small amount of calibration data. Compared with
SOTA training-free structured pruning works that can generate smaller networks,
our method demonstrates superior performance across standard benchmarks.
Furthermore, our generated subnets can directly reduce the usage of GPU memory
and achieve inference acceleration. Code:
https://github.com/shawnricecake/search-llm",2024-09-25T21:32:12Z,http://arxiv.org/pdf/2409.17372v2,['cs.AI']
2411.10813v1,Information Anxiety in Large Language Models,"['Prasoon Bajpai', 'Sarah Masud', 'Tanmoy Chakraborty']","Large Language Models (LLMs) have demonstrated strong performance as
knowledge repositories, enabling models to understand user queries and generate
accurate and context-aware responses. Extensive evaluation setups have
corroborated the positive correlation between the retrieval capability of LLMs
and the frequency of entities in their pretraining corpus. We take the
investigation further by conducting a comprehensive analysis of the internal
reasoning and retrieval mechanisms of LLMs. Our work focuses on three critical
dimensions - the impact of entity popularity, the models' sensitivity to
lexical variations in query formulation, and the progression of hidden state
representations across LLM layers. Our preliminary findings reveal that popular
questions facilitate early convergence of internal states toward the correct
answer. However, as the popularity of a query increases, retrieved attributes
across lexical variations become increasingly dissimilar and less accurate.
Interestingly, we find that LLMs struggle to disentangle facts, grounded in
distinct relations, from their parametric memory when dealing with highly
popular subjects. Through a case study, we explore these latent strains within
LLMs when processing highly popular queries, a phenomenon we term information
anxiety. The emergence of information anxiety in LLMs underscores the
adversarial injection in the form of linguistic variations and calls for a more
holistic evaluation of frequently occurring entities.",2024-11-16T14:28:33Z,http://arxiv.org/pdf/2411.10813v1,['cs.CL']
2412.06864v1,Political-LLM: Large Language Models in Political Science,"['Lincan Li', 'Jiaqi Li', 'Catherine Chen', 'Fred Gui', 'Hongjia Yang', 'Chenxiao Yu', 'Zhengguang Wang', 'Jianing Cai', 'Junlong Aaron Zhou', 'Bolin Shen', 'Alex Qian', 'Weixin Chen', 'Zhongkai Xue', 'Lichao Sun', 'Lifang He', 'Hanjie Chen', 'Kaize Ding', 'Zijian Du', 'Fangzhou Mu', 'Jiaxin Pei', 'Jieyu Zhao', 'Swabha Swayamdipta', 'Willie Neiswanger', 'Hua Wei', 'Xiyang Hu', 'Shixiang Zhu', 'Tianlong Chen', 'Yingzhou Lu', 'Yang Shi', 'Lianhui Qin', 'Tianfan Fu', 'Zhengzhong Tu', 'Yuzhe Yang', 'Jaemin Yoo', 'Jiaheng Zhang', 'Ryan Rossi', 'Liang Zhan', 'Liang Zhao', 'Emilio Ferrara', 'Yan Liu', 'Furong Huang', 'Xiangliang Zhang', 'Lawrence Rothenberg', 'Shuiwang Ji', 'Philip S. Yu', 'Yue Zhao', 'Yushun Dong']","In recent years, large language models (LLMs) have been widely adopted in
political science tasks such as election prediction, sentiment analysis, policy
impact assessment, and misinformation detection. Meanwhile, the need to
systematically understand how LLMs can further revolutionize the field also
becomes urgent. In this work, we--a multidisciplinary team of researchers
spanning computer science and political science--present the first principled
framework termed Political-LLM to advance the comprehensive understanding of
integrating LLMs into computational political science. Specifically, we first
introduce a fundamental taxonomy classifying the existing explorations into two
perspectives: political science and computational methodologies. In particular,
from the political science perspective, we highlight the role of LLMs in
automating predictive and generative tasks, simulating behavior dynamics, and
improving causal inference through tools like counterfactual generation; from a
computational perspective, we introduce advancements in data preparation,
fine-tuning, and evaluation methods for LLMs that are tailored to political
contexts. We identify key challenges and future directions, emphasizing the
development of domain-specific datasets, addressing issues of bias and
fairness, incorporating human expertise, and redefining evaluation criteria to
align with the unique requirements of computational political science.
Political-LLM seeks to serve as a guidebook for researchers to foster an
informed, ethical, and impactful use of Artificial Intelligence in political
science. Our online resource is available at: http://political-llm.org/.",2024-12-09T08:47:50Z,http://arxiv.org/pdf/2412.06864v1,"['cs.CL', 'cs.AI']"
2501.12619v3,Quantification of Large Language Model Distillation,"['Sunbowen Lee', 'Junting Zhou', 'Chang Ao', 'Kaige Li', 'Xinrun Du', 'Sirui He', 'Haihong Wu', 'Tianci Liu', 'Jiaheng Liu', 'Hamid Alinejad-Rokny', 'Min Yang', 'Yitao Liang', 'Zhoufutu Wen', 'Shiwen Ni']","Model distillation is a fundamental technique in building large language
models (LLMs), transferring knowledge from a teacher model to a student model.
However, distillation can lead to model homogenization, reducing diversity
among models and impairing their ability to robustly handle complex or novel
tasks. These limitations underscore the need to systematically quantify the
distillation process and its impact. In this work, we propose a framework to
evaluate and quantify model distillation. Our method addresses two key aspects:
(1) Identifying identity cognition contradictions to assess discrepancies in
how models perceive and represent identity-related information, and (2)
Analyzing multi-granularity response similarities across models to measure the
extent of homogenization. Experimental results demonstrate two key insights:
(1) Well-known closed-source and open-source LLMs usually exhibit high
distillation degrees, except for Claude, Doubao, and Gemini. (2) Base LLMs show
higher distillation degrees compared to aligned LLMs. By offering a systematic
approach to improve the transparency of LLM data distillation, we call for LLMs
with more independent development and more transparent technical reports to
improve LLMs' robustness and safety. The code and data are available under
https://github.com/Aegis1863/LLMs-Distillation-Quantification.",2025-01-22T03:57:52Z,http://arxiv.org/pdf/2501.12619v3,['cs.CL']
2502.16790v1,Are Large Language Models Good Data Preprocessors?,"['Elyas Meguellati', 'Nardiena Pratama', 'Shazia Sadiq', 'Gianluca Demartini']","High-quality textual training data is essential for the success of multimodal
data processing tasks, yet outputs from image captioning models like BLIP and
GIT often contain errors and anomalies that are difficult to rectify using
rule-based methods. While recent work addressing this issue has predominantly
focused on using GPT models for data preprocessing on relatively simple public
datasets, there is a need to explore a broader range of Large Language Models
(LLMs) and tackle more challenging and diverse datasets.
  In this study, we investigate the use of multiple LLMs, including LLaMA 3.1
70B, GPT-4 Turbo, and Sonnet 3.5 v2, to refine and clean the textual outputs of
BLIP and GIT. We assess the impact of LLM-assisted data cleaning by comparing
downstream-task (SemEval 2024 Subtask ""Multilabel Persuasion Detection in
Memes"") models trained on cleaned versus non-cleaned data. While our
experimental results show improvements when using LLM-cleaned captions,
statistical tests reveal that most of these improvements are not significant.
This suggests that while LLMs have the potential to enhance data cleaning and
repairing, their effectiveness may be limited depending on the context they are
applied to, the complexity of the task, and the level of noise in the text.
  Our findings highlight the need for further research into the capabilities
and limitations of LLMs in data preprocessing pipelines, especially when
dealing with challenging datasets, contributing empirical evidence to the
ongoing discussion about integrating LLMs into data preprocessing pipelines.",2025-02-24T02:57:21Z,http://arxiv.org/pdf/2502.16790v1,['cs.CL']
2503.21383v1,Controlling Large Language Model with Latent Actions,"['Chengxing Jia', 'Ziniu Li', 'Pengyuan Wang', 'Yi-Chen Li', 'Zhenyu Hou', 'Yuxiao Dong', 'Yang Yu']","Adapting Large Language Models (LLMs) to downstream tasks using Reinforcement
Learning (RL) has proven to be an effective approach. However, LLMs do not
inherently define the structure of an agent for RL training, particularly in
terms of defining the action space. This paper studies learning a compact
latent action space to enhance the controllability and exploration of RL for
LLMs. We propose Controlling Large Language Models with Latent Actions (CoLA),
a framework that integrates a latent action space into pre-trained LLMs. We
apply CoLA to the Llama-3.1-8B model. Our experiments demonstrate that,
compared to RL with token-level actions, CoLA's latent action enables greater
semantic diversity in text generation. For enhancing downstream tasks, we show
that CoLA with RL achieves a score of 42.4 on the math500 benchmark, surpassing
the baseline score of 38.2, and reaches 68.2 when augmented with a Monte Carlo
Tree Search variant. Furthermore, CoLA with RL consistently improves
performance on agent-based tasks without degrading the pre-trained LLM's
capabilities, unlike the baseline. Finally, CoLA reduces computation time by
half in tasks involving enhanced thinking prompts for LLMs by RL. These results
highlight CoLA's potential to advance RL-based adaptation of LLMs for
downstream applications.",2025-03-27T11:25:22Z,http://arxiv.org/pdf/2503.21383v1,"['cs.CL', 'cs.LG']"
2504.04342v1,Compression Laws for Large Language Models,"['Ayan Sengupta', 'Siddhant Chaudhary', 'Tanmoy Chakraborty']","We introduce compression laws for language language models (LLMs). While
recent scaling laws have sought to understand how LLMs scale with respect to
model size, pre-training data, and computational resources, we focus on
understanding how model compression affects the performance of a pre-trained
LLM on downstream tasks. We empirically examine the effects of structured model
compression on LLMs through over $1000$ experiments across eight models with
sizes ranging from $0.5B$ to $14B$ parameters. Our findings indicate that the
test cross-entropy loss increases quadratically with the compression ratio,
whereas performance on downstream tasks declines only linearly. Our study
emphasizes the importance of recovery fine-tuning in enhancing generation loss,
showing that the test loss of compressed LLMs can improve by up to 55% with
recovery fine-tuning. At higher compression ratios (up to 90%), compressed LLMs
demonstrate a speed increase of 60% during inference compared to their
uncompressed counterparts, compensating for the performance degradation at this
level. However, for smaller models ($\le 7B$), the computational gains are
limited, peaking at just 35%. We conclude that model compression can be highly
beneficial for larger models, especially when a smaller model within the same
computational budget is not available. These insights provide the practical
guidelines for utilizing model compression techniques for adopting LLMs in
real-life applications in resource-constrained settings.",2025-04-06T03:39:34Z,http://arxiv.org/pdf/2504.04342v1,['cs.CL']
2505.20633v1,Test-Time Learning for Large Language Models,"['Jinwu Hu', 'Zhitian Zhang', 'Guohao Chen', 'Xutao Wen', 'Chao Shuai', 'Wei Luo', 'Bin Xiao', 'Yuanqing Li', 'Mingkui Tan']","While Large Language Models (LLMs) have exhibited remarkable emergent
capabilities through extensive pre-training, they still face critical
limitations in generalizing to specialized domains and handling diverse
linguistic variations, known as distribution shifts. In this paper, we propose
a Test-Time Learning (TTL) paradigm for LLMs, namely TLM, which dynamically
adapts LLMs to target domains using only unlabeled test data during testing.
Specifically, we first provide empirical evidence and theoretical insights to
reveal that more accurate predictions from LLMs can be achieved by minimizing
the input perplexity of the unlabeled test data. Based on this insight, we
formulate the Test-Time Learning process of LLMs as input perplexity
minimization, enabling self-supervised enhancement of LLM performance.
Furthermore, we observe that high-perplexity samples tend to be more
informative for model optimization. Accordingly, we introduce a Sample
Efficient Learning Strategy that actively selects and emphasizes these
high-perplexity samples for test-time updates. Lastly, to mitigate catastrophic
forgetting and ensure adaptation stability, we adopt Low-Rank Adaptation (LoRA)
instead of full-parameter optimization, which allows lightweight model updates
while preserving more original knowledge from the model. We introduce the
AdaptEval benchmark for TTL and demonstrate through experiments that TLM
improves performance by at least 20% compared to original LLMs on domain
knowledge adaptation.",2025-05-27T02:18:59Z,http://arxiv.org/pdf/2505.20633v1,"['cs.CL', 'cs.AI', 'cs.LG']"
2506.02658v2,Computational Thinking Reasoning in Large Language Models,"['Kechi Zhang', 'Ge Li', 'Jia Li', 'Huangzhao Zhang', 'Jingjing Xu', 'Hao Zhu', 'Lecheng Wang', 'Jia Li', 'Yihong Dong', 'Jing Mai', 'Bin Gu', 'Zhi Jin']","While large language models (LLMs) have demonstrated remarkable reasoning
capabilities, they often struggle with complex tasks that require specific
thinking paradigms, such as divide-and-conquer and procedural deduction, \etc
Previous researches integrate external, reliable tools to alleviate logical
inconsistencies and hallucinations in LLMs' problem-solving processes. However,
we argue that the root challenge is more profound: LLMs lack the complex
thinking paradigms (\ie, computational thinking) during reasoning. In this
paper, we propose Computational Thinking Model (CTM), a novel framework that
incorporates computational thinking paradigms into LLMs. This framework enables
LLMs to reformulate complex problems through decomposition, abstraction,
reduction, and simulation, among other techniques. Specifically, live code
execution is seamlessly integrated into the reasoning process, allowing CTM to
think by computing. CTM directly instills computational thinking objectives
into LLMs through tailored reinforcement learning rewards, which encourages
problem simplification, modular planning, and iterative verification. We
conduct extensive evaluations on multiple code generation and mathematical
benchmarks. The results demonstrate that CTM outperforms conventional reasoning
models and tool-augmented baselines in terms of accuracy, interpretability, and
generalizability. We hope this study offers valuable insights for AI reasoning,
where LLMs can transform problems into robust, verifiable, and scalable
computational workflows, much like computer scientists do.",2025-06-03T09:11:15Z,http://arxiv.org/pdf/2506.02658v2,['cs.SE']
2506.06921v1,Teaching Astronomy with Large Language Models,"['Yuan-Sen Ting', ""Teaghan O'Briain""]","We present a study of LLM integration in final-year undergraduate astronomy
education, examining how students develop AI literacy through structured
guidance and documentation requirements. We developed AstroTutor, a
domain-specific astronomy tutoring system enhanced with curated arXiv content,
and deployed it alongside general-purpose LLMs in the course. Students
documented their AI usage through homework reflections and post-course surveys.
We analyzed student evolution in AI interaction strategies and conducted
experimental comparisons of LLM-assisted versus traditional grading methods.
LLM grading showed strong correlation with human evaluation while providing
more detailed and consistent feedback. We also piloted LLM-facilitated
interview-based examinations as a scalable alternative to traditional
assessments, demonstrating potential for individualized evaluation that
addresses common testing limitations. Students experienced decreased rather
than increased reliance on LLMs over the semester, developing critical
evaluation skills and strategic tool selection. They evolved from basic
assistance-seeking to verification workflows, with documentation requirements
fostering metacognitive awareness. Students developed effective prompting
strategies, contextual enrichment techniques, and cross-verification practices.
Our findings suggest that structured LLM integration with transparency
requirements and domain-specific tools can enhance astronomy education while
building essential AI literacy skills. We provide implementation guidelines for
educators and make our AstroTutor repository freely available.",2025-06-07T21:00:01Z,http://arxiv.org/pdf/2506.06921v1,"['physics.ed-ph', 'astro-ph.CO', 'astro-ph.GA', 'astro-ph.IM', 'astro-ph.SR']"
2507.08151v1,Distilling Empathy from Large Language Models,"['Henry J. Xie', 'Jinghan Zhang', 'Xinhao Zhang', 'Kunpeng Liu']","The distillation of knowledge from Large Language Models (LLMs) into Smaller
Language Models (SLMs), preserving the capabilities and performance of LLMs
while reducing model size, has played a key role in the proliferation of LLMs.
Because SLMs are considerably smaller than LLMs, they are often utilized in
domains where human interaction is frequent but resources are highly
constrained, e.g., smart phones. Therefore, it is crucial to ensure that
empathy, a fundamental aspect of positive human interactions, already instilled
into LLMs, is retained by SLMs after distillation. In this paper, we develop a
comprehensive approach for effective empathy distillation from LLMs into SLMs.
Our approach features a two-step fine-tuning process that fully leverages
datasets of empathetic dialogue responses distilled from LLMs. We explore
several distillation methods beyond basic direct prompting and propose four
unique sets of prompts for targeted empathy improvement to significantly
enhance the empathy distillation process. Our evaluations demonstrate that SLMs
fine-tuned through the two-step fine-tuning process with distillation datasets
enhanced by the targeted empathy improvement prompts significantly outperform
the base SLM at generating empathetic responses with a win rate of 90%. Our
targeted empathy improvement prompts substantially outperform the basic direct
prompting with a 10% improvement in win rate.",2025-07-10T20:20:02Z,http://arxiv.org/pdf/2507.08151v1,['cs.CL']
2410.13138v1,Data Defenses Against Large Language Models,"['William Agnew', 'Harry H. Jiang', 'Cella Sum', 'Maarten Sap', 'Sauvik Das']","Large language models excel at performing inference over text to extract
information, summarize information, or generate additional text. These
inference capabilities are implicated in a variety of ethical harms spanning
surveillance, labor displacement, and IP/copyright theft. While many policy,
legal, and technical mitigations have been proposed to counteract these harms,
these mitigations typically require cooperation from institutions that move
slower than technical advances (i.e., governments) or that have few incentives
to act to counteract these harms (i.e., the corporations that create and profit
from these LLMs). In this paper, we define and build ""data defenses"" -- a novel
strategy that directly empowers data owners to block LLMs from performing
inference on their data. We create data defenses by developing a method to
automatically generate adversarial prompt injections that, when added to input
text, significantly reduce the ability of LLMs to accurately infer personally
identifying information about the subject of the input text or to use
copyrighted text in inference. We examine the ethics of enabling such direct
resistance to LLM inference, and argue that making data defenses that resist
and subvert LLMs enables the realization of important values such as data
ownership, data sovereignty, and democratic control over AI systems. We verify
that our data defenses are cheap and fast to generate, work on the latest
commercial and open-source LLMs, resistance to countermeasures, and are robust
to several different attack settings. Finally, we consider the security
implications of LLM data defenses and outline several future research
directions in this area. Our code is available at
https://github.com/wagnew3/LLMDataDefenses and a tool for using our defenses to
protect text against LLM inference is at
https://wagnew3.github.io/LLM-Data-Defenses/.",2024-10-17T01:51:56Z,http://arxiv.org/pdf/2410.13138v1,"['cs.CL', 'cs.CR', 'cs.CY']"
2303.05279v2,Can large language models build causal graphs?,"['Stephanie Long', 'Tibor Schuster', 'Alexandre Piché']","Building causal graphs can be a laborious process. To ensure all relevant
causal pathways have been captured, researchers often have to discuss with
clinicians and experts while also reviewing extensive relevant medical
literature. By encoding common and medical knowledge, large language models
(LLMs) represent an opportunity to ease this process by automatically scoring
edges (i.e., connections between two variables) in potential graphs. LLMs
however have been shown to be brittle to the choice of probing words, context,
and prompts that the user employs. In this work, we evaluate if LLMs can be a
useful tool in complementing causal graph development.",2023-03-07T22:05:31Z,http://arxiv.org/pdf/2303.05279v2,"['cs.CL', 'cs.AI']"
2310.10826v3,Mechanism Design for Large Language Models,"['Paul Duetting', 'Vahab Mirrokni', 'Renato Paes Leme', 'Haifeng Xu', 'Song Zuo']","We investigate auction mechanisms for AI-generated content, focusing on
applications like ad creative generation. In our model, agents' preferences
over stochastically generated content are encoded as large language models
(LLMs). We propose an auction format that operates on a token-by-token basis,
and allows LLM agents to influence content creation through single dimensional
bids. We formulate two desirable incentive properties and prove their
equivalence to a monotonicity condition on output aggregation. This equivalence
enables a second-price rule design, even absent explicit agent valuation
functions. Our design is supported by demonstrations on a publicly available
LLM.",2023-10-16T21:01:12Z,http://arxiv.org/pdf/2310.10826v3,"['cs.GT', 'econ.TH']"
2310.16673v1,Exploring Large Language Models for Code Explanation,"['Paheli Bhattacharya', 'Manojit Chakraborty', 'Kartheek N S N Palepu', 'Vikas Pandey', 'Ishan Dindorkar', 'Rakesh Rajpurohit', 'Rishabh Gupta']","Automating code documentation through explanatory text can prove highly
beneficial in code understanding. Large Language Models (LLMs) have made
remarkable strides in Natural Language Processing, especially within software
engineering tasks such as code generation and code summarization. This study
specifically delves into the task of generating natural-language summaries for
code snippets, using various LLMs. The findings indicate that Code LLMs
outperform their generic counterparts, and zero-shot methods yield superior
results when dealing with datasets with dissimilar distributions between
training and testing sets.",2023-10-25T14:38:40Z,http://arxiv.org/pdf/2310.16673v1,"['cs.SE', 'cs.AI', 'cs.IR', 'D.2.3; I.7']"
2401.02509v2,"Memory, Consciousness and Large Language Model","['Jitang Li', 'Jinzheng Li']","With the development in cognitive science and Large Language Models (LLMs),
increasing connections have come to light between these two distinct fields.
Building upon these connections, we propose a conjecture suggesting the
existence of a duality between LLMs and Tulving's theory of memory. We identify
a potential correspondence between Tulving's synergistic ecphory model (SEM) of
retrieval and the emergent abilities observed in LLMs, serving as supporting
evidence for our conjecture. Furthermore, we speculate that consciousness may
be considered a form of emergent ability based on this duality. We also discuss
how other theories of consciousness intersect with our research.",2024-01-04T19:44:03Z,http://arxiv.org/pdf/2401.02509v2,"['q-bio.NC', 'cs.AI', 'cs.CL']"
2402.17762v2,Massive Activations in Large Language Models,"['Mingjie Sun', 'Xinlei Chen', 'J. Zico Kolter', 'Zhuang Liu']","We observe an empirical phenomenon in Large Language Models (LLMs) -- very
few activations exhibit significantly larger values than others (e.g., 100,000
times larger). We call them massive activations. First, we demonstrate the
widespread existence of massive activations across various LLMs and
characterize their locations. Second, we find their values largely stay
constant regardless of the input, and they function as indispensable bias terms
in LLMs. Third, these massive activations lead to the concentration of
attention probabilities to their corresponding tokens, and further, implicit
bias terms in the self-attention output. Last, we also study massive
activations in Vision Transformers. Code is available at
https://github.com/locuslab/massive-activations.",2024-02-27T18:55:17Z,http://arxiv.org/pdf/2402.17762v2,"['cs.CL', 'cs.LG']"
2405.20624v1,Leveraging Large Language Models for Entity Matching,"['Qianyu Huang', 'Tongfang Zhao']","Entity matching (EM) is a critical task in data integration, aiming to
identify records across different datasets that refer to the same real-world
entities. Traditional methods often rely on manually engineered features and
rule-based systems, which struggle with diverse and unstructured data. The
emergence of Large Language Models (LLMs) such as GPT-4 offers transformative
potential for EM, leveraging their advanced semantic understanding and
contextual capabilities. This vision paper explores the application of LLMs to
EM, discussing their advantages, challenges, and future research directions.
Additionally, we review related work on applying weak supervision and
unsupervised approaches to EM, highlighting how LLMs can enhance these methods.",2024-05-31T05:22:07Z,http://arxiv.org/pdf/2405.20624v1,"['cs.CL', 'cs.AI']"
2411.04223v3,Diversity Helps Jailbreak Large Language Models,"['Weiliang Zhao', 'Daniel Ben-Levi', 'Wei Hao', 'Junfeng Yang', 'Chengzhi Mao']","We have uncovered a powerful jailbreak technique that leverages large
language models' ability to diverge from prior context, enabling them to bypass
safety constraints and generate harmful outputs. By simply instructing the LLM
to deviate and obfuscate previous attacks, our method dramatically outperforms
existing approaches, achieving up to a 62.83% higher success rate in
compromising ten leading chatbots, including GPT-4, Gemini, and Llama, while
using only 12.9% of the queries. This revelation exposes a critical flaw in
current LLM safety training, suggesting that existing methods may merely mask
vulnerabilities rather than eliminate them. Our findings sound an urgent alarm
for the need to revolutionize testing methodologies to ensure robust and
reliable LLM security.",2024-11-06T19:39:48Z,http://arxiv.org/pdf/2411.04223v3,['cs.CL']
2412.16653v1,Internalized Self-Correction for Large Language Models,"['Nishanth Upadhyaya', 'Raghavendra Sridharamurthy']","In this article, we introduce 'Internalized Self-Correction' (InSeC) for
large language models (LLMs). While many approaches exist for self-reflection
at inference time, we propose a novel method that combines ideas from negative
sampling, self-reflection during training, and inference time. InSeC allows
LLMs to correct themselves by introducing mistakes and their corresponding
corrections during training, thereby converting the learning process into a
true supervised learning task with both positive and negative examples. This
approach can be extended to improve instruction following and correct
hallucinations or incorrect sentences generated by LLMs.",2024-12-21T14:53:13Z,http://arxiv.org/pdf/2412.16653v1,['cs.AI']
2501.06911v1,Risk-Averse Finetuning of Large Language Models,"['Sapana Chaudhary', 'Ujwal Dinesha', 'Dileep Kalathil', 'Srinivas Shakkottai']","We consider the challenge of mitigating the generation of negative or toxic
content by the Large Language Models (LLMs) in response to certain prompts. We
propose integrating risk-averse principles into LLM fine-tuning to minimize the
occurrence of harmful outputs, particularly rare but significant events. By
optimizing the risk measure of Conditional Value at Risk (CVaR), our
methodology trains LLMs to exhibit superior performance in avoiding toxic
outputs while maintaining effectiveness in generative tasks. Empirical
evaluations on sentiment modification and toxicity mitigation tasks demonstrate
the efficacy of risk-averse reinforcement learning with human feedback (RLHF)
in promoting a safer and more constructive online discourse environment.",2025-01-12T19:48:21Z,http://arxiv.org/pdf/2501.06911v1,"['cs.AI', 'cs.CL']"
2509.08480v1,Acquiescence Bias in Large Language Models,['Daniel Braun'],"Acquiescence bias, i.e. the tendency of humans to agree with statements in
surveys, independent of their actual beliefs, is well researched and
documented. Since Large Language Models (LLMs) have been shown to be very
influenceable by relatively small changes in input and are trained on
human-generated data, it is reasonable to assume that they could show a similar
tendency. We present a study investigating the presence of acquiescence bias in
LLMs across different models, tasks, and languages (English, German, and
Polish). Our results indicate that, contrary to humans, LLMs display a bias
towards answering no, regardless of whether it indicates agreement or
disagreement.",2025-09-10T10:39:24Z,http://arxiv.org/pdf/2509.08480v1,['cs.CL']
2301.13848v1,Benchmarking Large Language Models for News Summarization,"['Tianyi Zhang', 'Faisal Ladhak', 'Esin Durmus', 'Percy Liang', 'Kathleen McKeown', 'Tatsunori B. Hashimoto']","Large language models (LLMs) have shown promise for automatic summarization
but the reasons behind their successes are poorly understood. By conducting a
human evaluation on ten LLMs across different pretraining methods, prompts, and
model scales, we make two important observations. First, we find instruction
tuning, and not model size, is the key to the LLM's zero-shot summarization
capability. Second, existing studies have been limited by low-quality
references, leading to underestimates of human performance and lower few-shot
and finetuning performance. To better evaluate LLMs, we perform human
evaluation over high-quality summaries we collect from freelance writers.
Despite major stylistic differences such as the amount of paraphrasing, we find
that LMM summaries are judged to be on par with human written summaries.",2023-01-31T18:46:19Z,http://arxiv.org/pdf/2301.13848v1,"['cs.CL', 'cs.AI', 'cs.LG']"
2304.00008v5,On the Creativity of Large Language Models,"['Giorgio Franceschelli', 'Mirco Musolesi']","Large Language Models (LLMs) are revolutionizing several areas of Artificial
Intelligence. One of the most remarkable applications is creative writing,
e.g., poetry or storytelling: the generated outputs are often of astonishing
quality. However, a natural question arises: can LLMs be really considered
creative? In this article, we first analyze the development of LLMs under the
lens of creativity theories, investigating the key open questions and
challenges. In particular, we focus our discussion on the dimensions of value,
novelty, and surprise as proposed by Margaret Boden in her work. Then, we
consider different classic perspectives, namely product, process, press, and
person. We discuss a set of ``easy'' and ``hard'' problems in machine
creativity, presenting them in relation to LLMs. Finally, we examine the
societal impact of these technologies with a particular focus on the creative
industries, analyzing the opportunities offered, the challenges arising from
them, and the potential associated risks, from both legal and ethical points of
view.",2023-03-27T18:00:01Z,http://arxiv.org/pdf/2304.00008v5,"['cs.AI', 'cs.CL', 'cs.CY']"
2307.16648v2,LLMs4OL: Large Language Models for Ontology Learning,"['Hamed Babaei Giglou', ""Jennifer D'Souza"", 'Sören Auer']","We propose the LLMs4OL approach, which utilizes Large Language Models (LLMs)
for Ontology Learning (OL). LLMs have shown significant advancements in natural
language processing, demonstrating their ability to capture complex language
patterns in different knowledge domains. Our LLMs4OL paradigm investigates the
following hypothesis: \textit{Can LLMs effectively apply their language pattern
capturing capability to OL, which involves automatically extracting and
structuring knowledge from natural language text?} To test this hypothesis, we
conduct a comprehensive evaluation using the zero-shot prompting method. We
evaluate nine different LLM model families for three main OL tasks: term
typing, taxonomy discovery, and extraction of non-taxonomic relations.
Additionally, the evaluations encompass diverse genres of ontological
knowledge, including lexicosemantic knowledge in WordNet, geographical
knowledge in GeoNames, and medical knowledge in UMLS.",2023-07-31T13:27:21Z,http://arxiv.org/pdf/2307.16648v2,"['cs.AI', 'cs.CL', 'cs.IT', 'cs.LG', 'math.IT']"
2308.07505v2,Data Race Detection Using Large Language Models,"['Le Chen', 'Xianzhong Ding', 'Murali Emani', 'Tristan Vanderbruggen', 'Pei-hung Lin', 'Chuanhua Liao']","Large language models (LLMs) are demonstrating significant promise as an
alternate strategy to facilitate analyses and optimizations of high-performance
computing programs, circumventing the need for resource-intensive manual tool
creation. In this paper, we explore a novel LLM-based data race detection
approach combining prompting engineering and fine-tuning techniques. We create
a dedicated dataset named DRB-ML, which is derived from DataRaceBench, with
fine-grain labels showing the presence of data race pairs and their associated
variables, line numbers, and read/write information. DRB-ML is then used to
evaluate representative LLMs and fine-tune open-source ones. Our experiment
shows that LLMs can be a viable approach to data race detection. However, they
still cannot compete with traditional data race detection tools when we need
detailed information about variable pairs causing data races.",2023-08-15T00:08:43Z,http://arxiv.org/pdf/2308.07505v2,"['cs.LG', 'cs.CL']"
2309.02884v2,Aligning Large Language Models for Clinical Tasks,"['Supun Manathunga', 'Isuru Hettigoda']","Large Language Models (LLMs) have demonstrated remarkable adaptability,
showcasing their capacity to excel in tasks for which they were not explicitly
trained. However, despite their impressive natural language processing (NLP)
capabilities, effective alignment of LLMs remains a crucial challenge when
deploying them for specific clinical applications. The ability to generate
responses with factually accurate content and to engage in non-trivial
reasoning steps are crucial for the LLMs to be eligible for applications in
clinical medicine. Employing a combination of techniques including
instruction-tuning and in-prompt strategies like few-shot and chain-of-thought
prompting has significantly enhanced the performance of LLMs. Our proposed
alignment strategy for medical question-answering, known as
'expand-guess-refine', offers a parameter and data-efficient solution. A
preliminary analysis of this method demonstrated outstanding performance,
achieving a score of 70.63% on a subset of questions sourced from the USMLE
dataset.",2023-09-06T10:20:06Z,http://arxiv.org/pdf/2309.02884v2,"['cs.CL', 'I.2, I.7, J.3']"
2405.10369v1,Reinforcement learning,['Sarod Yatawatta'],"Observing celestial objects and advancing our scientific knowledge about them
involves tedious planning, scheduling, data collection and data
post-processing. Many of these operational aspects of astronomy are guided and
executed by expert astronomers. Reinforcement learning is a mechanism where we
(as humans and astronomers) can teach agents of artificial intelligence to
perform some of these tedious tasks. In this paper, we will present a state of
the art overview of reinforcement learning and how it can benefit astronomy.",2024-05-16T18:03:17Z,http://arxiv.org/pdf/2405.10369v1,"['astro-ph.IM', 'cs.AI', 'cs.LG']"
2005.14419v2,Reinforcement Learning,"['Olivier Buffet', 'Olivier Pietquin', 'Paul Weng']","Reinforcement learning (RL) is a general framework for adaptive control,
which has proven to be efficient in many domains, e.g., board games, video
games or autonomous vehicles. In such problems, an agent faces a sequential
decision-making problem where, at every time step, it observes its state,
performs an action, receives a reward and moves to a new state. An RL agent
learns by trial and error a good policy (or controller) based on observations
and numeric reward feedback on the previously performed action. In this
chapter, we present the basic framework of RL and recall the two main families
of approaches that have been developed to learn a good policy. The first one,
which is value-based, consists in estimating the value of an optimal policy,
value from which a policy can be recovered, while the other, called policy
search, directly works in a policy space. Actor-critic methods can be seen as a
policy search technique where the policy value that is learned guides the
policy improvement. Besides, we give an overview of some extensions of the
standard RL framework, notably when risk-averse behavior needs to be taken into
account or when rewards are not available or not known.",2020-05-29T06:53:29Z,http://arxiv.org/pdf/2005.14419v2,"['cs.LG', 'stat.ML']"
2307.16348v2,Rating-based Reinforcement Learning,"['Devin White', 'Mingkang Wu', 'Ellen Novoseller', 'Vernon J. Lawhern', 'Nicholas Waytowich', 'Yongcan Cao']","This paper develops a novel rating-based reinforcement learning approach that
uses human ratings to obtain human guidance in reinforcement learning.
Different from the existing preference-based and ranking-based reinforcement
learning paradigms, based on human relative preferences over sample pairs, the
proposed rating-based reinforcement learning approach is based on human
evaluation of individual trajectories without relative comparisons between
sample pairs. The rating-based reinforcement learning approach builds on a new
prediction model for human ratings and a novel multi-class loss function. We
conduct several experimental studies based on synthetic ratings and real human
ratings to evaluate the effectiveness and benefits of the new rating-based
reinforcement learning approach.",2023-07-30T23:54:22Z,http://arxiv.org/pdf/2307.16348v2,"['cs.LG', 'cs.AI', 'cs.RO']"
2010.14616v1,Lineage Evolution Reinforcement Learning,"['Zeyu Zhang', 'Guisheng Yin']","We propose a general agent population learning system, and on this basis, we
propose lineage evolution reinforcement learning algorithm. Lineage evolution
reinforcement learning is a kind of derivative algorithm which accords with the
general agent population learning system. We take the agents in DQN and its
related variants as the basic agents in the population, and add the selection,
mutation and crossover modules in the genetic algorithm to the reinforcement
learning algorithm. In the process of agent evolution, we refer to the
characteristics of natural genetic behavior, add lineage factor to ensure the
retention of potential performance of agent, and comprehensively consider the
current performance and lineage value when evaluating the performance of agent.
Without changing the parameters of the original reinforcement learning
algorithm, lineage evolution reinforcement learning can optimize different
reinforcement learning algorithms. Our experiments show that the idea of
evolution with lineage improves the performance of original reinforcement
learning algorithm in some games in Atari 2600.",2020-09-26T11:58:16Z,http://arxiv.org/pdf/2010.14616v1,"['cs.NE', 'cs.AI', 'cs.LG', 'cs.MA']"
2304.10098v2,Two-Memory Reinforcement Learning,"['Zhao Yang', 'Thomas. M. Moerland', 'Mike Preuss', 'Aske Plaat']","While deep reinforcement learning has shown important empirical success, it
tends to learn relatively slow due to slow propagation of rewards information
and slow update of parametric neural networks. Non-parametric episodic memory,
on the other hand, provides a faster learning alternative that does not require
representation learning and uses maximum episodic return as state-action values
for action selection. Episodic memory and reinforcement learning both have
their own strengths and weaknesses. Notably, humans can leverage multiple
memory systems concurrently during learning and benefit from all of them. In
this work, we propose a method called Two-Memory reinforcement learning agent
(2M) that combines episodic memory and reinforcement learning to distill both
of their strengths. The 2M agent exploits the speed of the episodic memory part
and the optimality and the generalization capacity of the reinforcement
learning part to complement each other. Our experiments demonstrate that the 2M
agent is more data efficient and outperforms both pure episodic memory and pure
reinforcement learning, as well as a state-of-the-art memory-augmented RL
agent. Moreover, the proposed approach provides a general framework that can be
used to combine any episodic memory agent with other off-policy reinforcement
learning algorithms.",2023-04-20T05:39:25Z,http://arxiv.org/pdf/2304.10098v2,"['cs.LG', 'cs.AI']"
9605103v1,Reinforcement Learning: A Survey,"['L. P. Kaelbling', 'M. L. Littman', 'A. W. Moore']","This paper surveys the field of reinforcement learning from a
computer-science perspective. It is written to be accessible to researchers
familiar with machine learning. Both the historical basis of the field and a
broad selection of current work are summarized. Reinforcement learning is the
problem faced by an agent that learns behavior through trial-and-error
interactions with a dynamic environment. The work described here has a
resemblance to work in psychology, but differs considerably in the details and
in the use of the word ``reinforcement.'' The paper discusses central issues of
reinforcement learning, including trading off exploration and exploitation,
establishing the foundations of the field via Markov decision theory, learning
from delayed reinforcement, constructing empirical models to accelerate
learning, making use of generalization and hierarchy, and coping with hidden
state. It concludes with a survey of some implemented systems and an assessment
of the practical utility of current methods for reinforcement learning.",1996-05-01T00:00:00Z,http://arxiv.org/pdf/cs/9605103v1,['cs.AI']
1812.07019v2,Malthusian Reinforcement Learning,"['Joel Z. Leibo', 'Julien Perolat', 'Edward Hughes', 'Steven Wheelwright', 'Adam H. Marblestone', 'Edgar Duéñez-Guzmán', 'Peter Sunehag', 'Iain Dunning', 'Thore Graepel']","Here we explore a new algorithmic framework for multi-agent reinforcement
learning, called Malthusian reinforcement learning, which extends self-play to
include fitness-linked population size dynamics that drive ongoing innovation.
In Malthusian RL, increases in a subpopulation's average return drive
subsequent increases in its size, just as Thomas Malthus argued in 1798 was the
relationship between preindustrial income levels and population growth.
Malthusian reinforcement learning harnesses the competitive pressures arising
from growing and shrinking population size to drive agents to explore regions
of state and policy spaces that they could not otherwise reach. Furthermore, in
environments where there are potential gains from specialization and division
of labor, we show that Malthusian reinforcement learning is better positioned
to take advantage of such synergies than algorithms based on self-play.",2018-12-17T19:36:14Z,http://arxiv.org/pdf/1812.07019v2,"['cs.NE', 'cs.MA', 'q-bio.PE']"
1905.02005v2,Deep Ordinal Reinforcement Learning,"['Alexander Zap', 'Tobias Joppen', 'Johannes Fürnkranz']","Reinforcement learning usually makes use of numerical rewards, which have
nice properties but also come with drawbacks and difficulties. Using rewards on
an ordinal scale (ordinal rewards) is an alternative to numerical rewards that
has received more attention in recent years. In this paper, a general approach
to adapting reinforcement learning problems to the use of ordinal rewards is
presented and motivated. We show how to convert common reinforcement learning
algorithms to an ordinal variation by the example of Q-learning and introduce
Ordinal Deep Q-Networks, which adapt deep reinforcement learning to ordinal
rewards. Additionally, we run evaluations on problems provided by the OpenAI
Gym framework, showing that our ordinal variants exhibit a performance that is
comparable to the numerical variations for a number of problems. We also give
first evidence that our ordinal variant is able to produce better results for
problems with less engineered and simpler-to-design reward signals.",2019-05-06T12:54:22Z,http://arxiv.org/pdf/1905.02005v2,"['cs.LG', 'cs.AI', 'stat.ML']"
1901.08277v3,Federated Deep Reinforcement Learning,"['Hankz Hankui Zhuo', 'Wenfeng Feng', 'Yufeng Lin', 'Qian Xu', 'Qiang Yang']","In deep reinforcement learning, building policies of high-quality is
challenging when the feature space of states is small and the training data is
limited. Despite the success of previous transfer learning approaches in deep
reinforcement learning, directly transferring data or models from an agent to
another agent is often not allowed due to the privacy of data and/or models in
many privacy-aware applications. In this paper, we propose a novel deep
reinforcement learning framework to federatively build models of high-quality
for agents with consideration of their privacies, namely Federated deep
Reinforcement Learning (FedRL). To protect the privacy of data and models, we
exploit Gausian differentials on the information shared with each other when
updating their local models. In the experiment, we evaluate our FedRL framework
in two diverse domains, Grid-world and Text2Action domains, by comparing to
various baselines.",2019-01-24T08:25:29Z,http://arxiv.org/pdf/1901.08277v3,"['cs.LG', 'cs.AI']"
1611.00862v1,Quantile Reinforcement Learning,"['Hugo Gilbert', 'Paul Weng']","In reinforcement learning, the standard criterion to evaluate policies in a
state is the expectation of (discounted) sum of rewards. However, this
criterion may not always be suitable, we consider an alternative criterion
based on the notion of quantiles. In the case of episodic reinforcement
learning problems, we propose an algorithm based on stochastic approximation
with two timescales. We evaluate our proposition on a simple model of the TV
show, Who wants to be a millionaire.",2016-11-03T02:28:53Z,http://arxiv.org/pdf/1611.00862v1,"['cs.LG', 'cs.AI']"
1904.10729v2,Neural Logic Reinforcement Learning,"['Zhengyao Jiang', 'Shan Luo']","Deep reinforcement learning (DRL) has achieved significant breakthroughs in
various tasks. However, most DRL algorithms suffer a problem of generalizing
the learned policy which makes the learning performance largely affected even
by minor modifications of the training environment. Except that, the use of
deep neural networks makes the learned policies hard to be interpretable. To
address these two challenges, we propose a novel algorithm named Neural Logic
Reinforcement Learning (NLRL) to represent the policies in reinforcement
learning by first-order logic. NLRL is based on policy gradient methods and
differentiable inductive logic programming that have demonstrated significant
advantages in terms of interpretability and generalisability in supervised
tasks. Extensive experiments conducted on cliff-walking and blocks manipulation
tasks demonstrate that NLRL can induce interpretable policies achieving
near-optimal performance while demonstrating good generalisability to
environments of different initial states and problem sizes.",2019-04-24T10:24:35Z,http://arxiv.org/pdf/1904.10729v2,['cs.LG']
1907.13196v4,Wasserstein Robust Reinforcement Learning,"['Mohammed Amin Abdullah', 'Hang Ren', 'Haitham Bou Ammar', 'Vladimir Milenkovic', 'Rui Luo', 'Mingtian Zhang', 'Jun Wang']","Reinforcement learning algorithms, though successful, tend to over-fit to
training environments hampering their application to the real-world. This paper
proposes $\text{W}\text{R}^{2}\text{L}$ -- a robust reinforcement learning
algorithm with significant robust performance on low and high-dimensional
control tasks. Our method formalises robust reinforcement learning as a novel
min-max game with a Wasserstein constraint for a correct and convergent solver.
Apart from the formulation, we also propose an efficient and scalable solver
following a novel zero-order optimisation method that we believe can be useful
to numerical optimisation in general. We empirically demonstrate significant
gains compared to standard and robust state-of-the-art algorithms on
high-dimensional MuJuCo environments.",2019-07-30T19:42:52Z,http://arxiv.org/pdf/1907.13196v4,"['cs.LG', 'cs.AI', 'stat.ML']"
2210.13504v1,Opportunistic Episodic Reinforcement Learning,"['Xiaoxiao Wang', 'Nader Bouacida', 'Xueying Guo', 'Xin Liu']","In this paper, we propose and study opportunistic reinforcement learning - a
new variant of reinforcement learning problems where the regret of selecting a
suboptimal action varies under an external environmental condition known as the
variation factor. When the variation factor is low, so is the regret of
selecting a suboptimal action and vice versa. Our intuition is to exploit more
when the variation factor is high, and explore more when the variation factor
is low. We demonstrate the benefit of this novel framework for finite-horizon
episodic MDPs by designing and evaluating OppUCRL2 and OppPSRL algorithms. Our
algorithms dynamically balance the exploration-exploitation trade-off for
reinforcement learning by introducing variation factor-dependent optimism to
guide exploration. We establish an $\tilde{O}(HS \sqrt{AT})$ regret bound for
the OppUCRL2 algorithm and show through simulations that both OppUCRL2 and
OppPSRL algorithm outperform their original corresponding algorithms.",2022-10-24T18:02:33Z,http://arxiv.org/pdf/2210.13504v1,"['cs.LG', 'cs.AI']"
2212.14214v4,Backward Curriculum Reinforcement Learning,['KyungMin Ko'],"Current reinforcement learning algorithms train an agent using
forward-generated trajectories, which provide little guidance so that the agent
can explore as much as possible. While realizing the value of reinforcement
learning results from sufficient exploration, this approach leads to a
trade-off in losing sample efficiency, an essential factor impacting algorithm
performance. Previous tasks use reward-shaping techniques and network structure
modification to increase sample efficiency. However, these methods require many
steps to implement. In this work, we propose novel backward curriculum
reinforcement learning that begins training the agent using the backward
trajectory of the episode instead of the original forward trajectory. This
approach provides the agent with a strong reward signal, enabling more
sample-efficient learning. Moreover, our method only requires a minor change in
the algorithm of reversing the order of the trajectory before agent training,
allowing a straightforward application to any state-of-the-art algorithm.",2022-12-29T08:23:39Z,http://arxiv.org/pdf/2212.14214v4,"['cs.AI', 'cs.LG']"
2305.19922v2,Representation-Driven Reinforcement Learning,"['Ofir Nabati', 'Guy Tennenholtz', 'Shie Mannor']","We present a representation-driven framework for reinforcement learning. By
representing policies as estimates of their expected values, we leverage
techniques from contextual bandits to guide exploration and exploitation.
Particularly, embedding a policy network into a linear feature space allows us
to reframe the exploration-exploitation problem as a
representation-exploitation problem, where good policy representations enable
optimal exploration. We demonstrate the effectiveness of this framework through
its application to evolutionary and policy gradient-based approaches, leading
to significantly improved performance compared to traditional methods. Our
framework provides a new perspective on reinforcement learning, highlighting
the importance of policy representation in determining optimal
exploration-exploitation strategies.",2023-05-31T14:59:12Z,http://arxiv.org/pdf/2305.19922v2,"['cs.LG', 'cs.AI']"
2109.02145v3,Temporal Shift Reinforcement Learning,"['Deepak George Thomas', 'Tichakorn Wongpiromsarn', 'Ali Jannesari']","The function approximators employed by traditional image-based Deep
Reinforcement Learning (DRL) algorithms usually lack a temporal learning
component and instead focus on learning the spatial component. We propose a
technique, Temporal Shift Reinforcement Learning (TSRL), wherein both temporal,
as well as spatial components are jointly learned. Moreover, TSRL does not
require additional parameters to perform temporal learning. We show that TSRL
outperforms the commonly used frame stacking heuristic on both of the Atari
environments we test on while beating the SOTA for one of them. This
investigation has implications in the robotics as well as sequential
decision-making domains.",2021-09-05T18:47:13Z,http://arxiv.org/pdf/2109.02145v3,['cs.LG']
2303.14623v4,Inverse Reinforcement Learning without Reinforcement Learning,"['Gokul Swamy', 'Sanjiban Choudhury', 'J. Andrew Bagnell', 'Zhiwei Steven Wu']","Inverse Reinforcement Learning (IRL) is a powerful set of techniques for
imitation learning that aims to learn a reward function that rationalizes
expert demonstrations. Unfortunately, traditional IRL methods suffer from a
computational weakness: they require repeatedly solving a hard reinforcement
learning (RL) problem as a subroutine. This is counter-intuitive from the
viewpoint of reductions: we have reduced the easier problem of imitation
learning to repeatedly solving the harder problem of RL. Another thread of work
has proved that access to the side-information of the distribution of states
where a strong policy spends time can dramatically reduce the sample and
computational complexities of solving an RL problem. In this work, we
demonstrate for the first time a more informed imitation learning reduction
where we utilize the state distribution of the expert to alleviate the global
exploration component of the RL subroutine, providing an exponential speedup in
theory. In practice, we find that we are able to significantly speed up the
prior art on continuous control tasks.",2023-03-26T04:35:53Z,http://arxiv.org/pdf/2303.14623v4,['cs.LG']
1810.00240v1,Reinforcement Learning in R,"['Nicolas Pröllochs', 'Stefan Feuerriegel']","Reinforcement learning refers to a group of methods from artificial
intelligence where an agent performs learning through trial and error. It
differs from supervised learning, since reinforcement learning requires no
explicit labels; instead, the agent interacts continuously with its
environment. That is, the agent starts in a specific state and then performs an
action, based on which it transitions to a new state and, depending on the
outcome, receives a reward. Different strategies (e.g. Q-learning) have been
proposed to maximize the overall reward, resulting in a so-called policy, which
defines the best possible action in each state. Mathematically, this process
can be formalized by a Markov decision process and it has been implemented by
packages in R; however, there is currently no package available for
reinforcement learning. As a remedy, this paper demonstrates how to perform
reinforcement learning in R and, for this purpose, introduces the
ReinforcementLearning package. The package provides a remarkably flexible
framework and is easily applied to a wide range of different problems. We
demonstrate its use by drawing upon common examples from the literature (e.g.
finding optimal game strategies).",2018-09-29T17:25:40Z,http://arxiv.org/pdf/1810.00240v1,"['cs.LG', 'stat.ML']"
1908.06973v1,Reinforcement Learning Applications,['Yuxi Li'],"We start with a brief introduction to reinforcement learning (RL), about its
successful stories, basics, an example, issues, the ICML 2019 Workshop on RL
for Real Life, how to use it, study material and an outlook. Then we discuss a
selection of RL applications, including recommender systems, computer systems,
energy, finance, healthcare, robotics, and transportation.",2019-08-19T09:47:22Z,http://arxiv.org/pdf/1908.06973v1,"['cs.LG', 'cs.AI']"
2207.00046v2,Performative Reinforcement Learning,"['Debmalya Mandal', 'Stelios Triantafyllou', 'Goran Radanovic']","We introduce the framework of performative reinforcement learning where the
policy chosen by the learner affects the underlying reward and transition
dynamics of the environment. Following the recent literature on performative
prediction~\cite{Perdomo et. al., 2020}, we introduce the concept of
performatively stable policy. We then consider a regularized version of the
reinforcement learning problem and show that repeatedly optimizing this
objective converges to a performatively stable policy under reasonable
assumptions on the transition dynamics. Our proof utilizes the dual perspective
of the reinforcement learning problem and may be of independent interest in
analyzing the convergence of other algorithms with decision-dependent
environments. We then extend our results for the setting where the learner just
performs gradient ascent steps instead of fully optimizing the objective, and
for the setting where the learner has access to a finite number of trajectories
from the changed environment. For both settings, we leverage the dual
formulation of performative reinforcement learning and establish convergence to
a stable solution. Finally, through extensive experiments on a grid-world
environment, we demonstrate the dependence of convergence on various parameters
e.g. regularization, smoothness, and the number of samples.",2022-06-30T18:26:03Z,http://arxiv.org/pdf/2207.00046v2,"['cs.LG', 'cs.GT']"
2201.09746v1,Reinforcement Learning Textbook,['Sergey Ivanov'],"This textbook covers principles behind main modern deep reinforcement
learning algorithms that achieved breakthrough results in many domains from
game AI to robotics. All required theory is explained with proofs using unified
notation and emphasize on the differences between different types of algorithms
and the reasons why they are constructed the way they are.",2022-01-19T15:54:39Z,http://arxiv.org/pdf/2201.09746v1,"['cs.LG', 'cs.AI', 'cs.NE', 'cs.RO']"
2405.17287v2,Opinion-Guided Reinforcement Learning,"['Kyanna Dagenais', 'Istvan David']","Human guidance is often desired in reinforcement learning to improve the
performance of the learning agent. However, human insights are often mere
opinions and educated guesses rather than well-formulated arguments. While
opinions are subject to uncertainty, e.g., due to partial informedness or
ignorance about a problem, they also emerge earlier than hard evidence can be
produced. Thus, guiding reinforcement learning agents by way of opinions offers
the potential for more performant learning processes, but comes with the
challenge of modeling and managing opinions in a formal way. In this article,
we present a method to guide reinforcement learning agents through opinions. To
this end, we provide an end-to-end method to model and manage advisors'
opinions. To assess the utility of the approach, we evaluate it with synthetic
(oracle) and human advisors, at different levels of uncertainty, and under
multiple advice strategies. Our results indicate that opinions, even if
uncertain, improve the performance of reinforcement learning agents, resulting
in higher rewards, more efficient exploration, and a better reinforced policy.
Although we demonstrate our approach through a two-dimensional topological
running example, our approach is applicable to complex problems with higher
dimensions as well.",2024-05-27T15:52:27Z,http://arxiv.org/pdf/2405.17287v2,"['cs.LG', 'cs.AI']"
2412.05265v4,Reinforcement Learning: An Overview,['Kevin Murphy'],"This manuscript gives a big-picture, up-to-date overview of the field of
(deep) reinforcement learning and sequential decision making, covering
value-based methods, policy-based methods, model-based methods, multi-agent RL,
LLMs and RL, and various other topics (e.g., offline RL, hierarchical RL,
intrinsic reward).",2024-12-06T18:53:49Z,http://arxiv.org/pdf/2412.05265v4,"['cs.AI', 'cs.LG']"
1809.06064v1,Object-sensitive Deep Reinforcement Learning,"['Yuezhang Li', 'Katia Sycara', 'Rahul Iyer']","Deep reinforcement learning has become popular over recent years, showing
superiority on different visual-input tasks such as playing Atari games and
robot navigation. Although objects are important image elements, few work
considers enhancing deep reinforcement learning with object characteristics. In
this paper, we propose a novel method that can incorporate object recognition
processing to deep reinforcement learning models. This approach can be adapted
to any existing deep reinforcement learning frameworks. State-of-the-art
results are shown in experiments on Atari games. We also propose a new approach
called ""object saliency maps"" to visually explain the actions made by deep
reinforcement learning agents.",2018-09-17T07:59:36Z,http://arxiv.org/pdf/1809.06064v1,"['cs.LG', 'cs.CV', 'stat.ML']"
1303.6977v4,ABC Reinforcement Learning,"['Christos Dimitrakakis', 'Nikolaos Tziortziotis']","This paper introduces a simple, general framework for likelihood-free
Bayesian reinforcement learning, through Approximate Bayesian Computation
(ABC). The main advantage is that we only require a prior distribution on a
class of simulators (generative models). This is useful in domains where an
analytical probabilistic model of the underlying process is too complex to
formulate, but where detailed simulation models are available. ABC-RL allows
the use of any Bayesian reinforcement learning technique, even in this case. In
addition, it can be seen as an extension of rollout algorithms to the case
where we do not know what the correct model to draw rollouts from is. We
experimentally demonstrate the potential of this approach in a comparison with
LSPI. Finally, we introduce a theorem showing that ABC is a sound methodology
in principle, even when non-sufficient statistics are used.",2013-03-27T20:51:33Z,http://arxiv.org/pdf/1303.6977v4,"['stat.ML', 'cs.LG']"
1810.06339v1,Deep Reinforcement Learning,['Yuxi Li'],"We discuss deep reinforcement learning in an overview style. We draw a big
picture, filled with details. We discuss six core elements, six important
mechanisms, and twelve applications, focusing on contemporary work, and in
historical contexts. We start with background of artificial intelligence,
machine learning, deep learning, and reinforcement learning (RL), with
resources. Next we discuss RL core elements, including value function, policy,
reward, model, exploration vs. exploitation, and representation. Then we
discuss important mechanisms for RL, including attention and memory,
unsupervised learning, hierarchical RL, multi-agent RL, relational RL, and
learning to learn. After that, we discuss RL applications, including games,
robotics, natural language processing (NLP), computer vision, finance, business
management, healthcare, education, energy, transportation, computer systems,
and, science, engineering, and art. Finally we summarize briefly, discuss
challenges and opportunities, and close with an epilogue.",2018-10-15T13:20:56Z,http://arxiv.org/pdf/1810.06339v1,"['cs.LG', 'stat.ML']"
1905.08513v8,Stochastic Inverse Reinforcement Learning,['Ce Ju'],"The goal of the inverse reinforcement learning (IRL) problem is to recover
the reward functions from expert demonstrations. However, the IRL problem like
any ill-posed inverse problem suffers the congenital defect that the policy may
be optimal for many reward functions, and expert demonstrations may be optimal
for many policies. In this work, we generalize the IRL problem to a well-posed
expectation optimization problem stochastic inverse reinforcement learning
(SIRL) to recover the probability distribution over reward functions. We adopt
the Monte Carlo expectation-maximization (MCEM) method to estimate the
parameter of the probability distribution as the first solution to the SIRL
problem. The solution is succinct, robust, and transferable for a learning task
and can generate alternative solutions to the IRL problem. Through our
formulation, it is possible to observe the intrinsic property of the IRL
problem from a global viewpoint, and our approach achieves a considerable
performance on the objectworld.",2019-05-21T09:29:18Z,http://arxiv.org/pdf/1905.08513v8,"['cs.LG', 'cs.AI', 'stat.ML', 'I.2.6']"
2209.06866v1,Robust Constrained Reinforcement Learning,"['Yue Wang', 'Fei Miao', 'Shaofeng Zou']","Constrained reinforcement learning is to maximize the expected reward subject
to constraints on utilities/costs. However, the training environment may not be
the same as the test one, due to, e.g., modeling error, adversarial attack,
non-stationarity, resulting in severe performance degradation and more
importantly constraint violation. We propose a framework of robust constrained
reinforcement learning under model uncertainty, where the MDP is not fixed but
lies in some uncertainty set, the goal is to guarantee that constraints on
utilities/costs are satisfied for all MDPs in the uncertainty set, and to
maximize the worst-case reward performance over the uncertainty set. We design
a robust primal-dual approach, and further theoretically develop guarantee on
its convergence, complexity and robust feasibility. We then investigate a
concrete example of $\delta$-contamination uncertainty set, design an online
and model-free algorithm and theoretically characterize its sample complexity.",2022-09-14T18:29:02Z,http://arxiv.org/pdf/2209.06866v1,['cs.LG']
1902.04178v1,Stochastic Reinforcement Learning,"['Nikki Lijing Kuang', 'Clement H. C. Leung', 'Vienne W. K. Sung']","In reinforcement learning episodes, the rewards and punishments are often
non-deterministic, and there are invariably stochastic elements governing the
underlying situation. Such stochastic elements are often numerous and cannot be
known in advance, and they have a tendency to obscure the underlying rewards
and punishments patterns. Indeed, if stochastic elements were absent, the same
outcome would occur every time and the learning problems involved could be
greatly simplified. In addition, in most practical situations, the cost of an
observation to receive either a reward or punishment can be significant, and
one would wish to arrive at the correct learning conclusion by incurring
minimum cost. In this paper, we present a stochastic approach to reinforcement
learning which explicitly models the variability present in the learning
environment and the cost of observation. Criteria and rules for learning
success are quantitatively analyzed, and probabilities of exceeding the
observation cost bounds are also obtained.",2019-02-11T23:13:32Z,http://arxiv.org/pdf/1902.04178v1,"['cs.LG', 'cs.AI', 'stat.ML']"
2402.07157v2,Natural Language Reinforcement Learning,"['Xidong Feng', 'Ziyu Wan', 'Mengyue Yang', 'Ziyan Wang', 'Girish A. Koushik', 'Yali Du', 'Ying Wen', 'Jun Wang']","Reinforcement Learning (RL) has shown remarkable abilities in learning
policies for decision-making tasks. However, RL is often hindered by issues
such as low sample efficiency, lack of interpretability, and sparse supervision
signals. To tackle these limitations, we take inspiration from the human
learning process and introduce Natural Language Reinforcement Learning (NLRL),
which innovatively combines RL principles with natural language representation.
Specifically, NLRL redefines RL concepts like task objectives, policy, value
function, Bellman equation, and policy iteration in natural language space. We
present how NLRL can be practically implemented with the latest advancements in
large language models (LLMs) like GPT-4. Initial experiments over tabular MDPs
demonstrate the effectiveness, efficiency, and also interpretability of the
NLRL framework.",2024-02-11T11:03:04Z,http://arxiv.org/pdf/2402.07157v2,"['cs.CL', 'cs.AI', 'cs.LG']"
2411.14251v3,Natural Language Reinforcement Learning,"['Xidong Feng', 'Bo Liu', 'Yan Song', 'Haotian Fu', 'Ziyu Wan', 'Girish A. Koushik', 'Zhiyuan Hu', 'Mengyue Yang', 'Ying Wen', 'Jun Wang']","Artificial intelligence progresses towards the ""Era of Experience,"" where
agents are expected to learn from continuous, grounded interaction. We argue
that traditional Reinforcement Learning (RL), which typically represents value
as a scalar, can restrict agent's deep understanding of environments and
hinders the active, deliberative learning crucial for navigating this new
paradigm. To address the issue, we introduce Natural Language Reinforcement
Learning (NLRL), a framework that extends RL principles into natural language
counterparts. Central to NLRL is the Language Value Function (LVF), which
redefines value as an interpretable linguistic narrative articulating the
rationale behind an evaluation. NLRL further extends this concept to core RL
components, including policy, the Bellman equation, and policy iteration.
Leveraging recent advancements in Large Language Models (LLMs), NLRL can be
practically implemented to achieve RL-like policy and value training through
unsupervised environment interactions. Experiments over 4 multi-step agentic
tasks demonstrate NLRL's effectiveness, efficiency, and its potential to foster
deeper understanding and more active learning strategies.",2024-11-21T15:57:02Z,http://arxiv.org/pdf/2411.14251v3,"['cs.LG', 'cs.AI', 'cs.CL']"
2501.15893v2,Benchmarking Quantum Reinforcement Learning,"['Nico Meyer', 'Christian Ufrecht', 'George Yammine', 'Georgios Kontes', 'Christopher Mutschler', 'Daniel D. Scherer']","Benchmarking and establishing proper statistical validation metrics for
reinforcement learning (RL) remain ongoing challenges, where no consensus has
been established yet. The emergence of quantum computing and its potential
applications in quantum reinforcement learning (QRL) further complicate
benchmarking efforts. To enable valid performance comparisons and to streamline
current research in this area, we propose a novel benchmarking methodology,
which is based on a statistical estimator for sample complexity and a
definition of statistical outperformance. Furthermore, considering QRL, our
methodology casts doubt on some previous claims regarding its superiority. We
conducted experiments on a novel benchmarking environment with flexible levels
of complexity. While we still identify possible advantages, our findings are
more nuanced overall. We discuss the potential limitations of these results and
explore their implications for empirical research on quantum advantage in QRL.",2025-01-27T09:40:18Z,http://arxiv.org/pdf/2501.15893v2,"['quant-ph', 'cs.LG']"
2504.16417v1,Anytime Safe Reinforcement Learning,"['Pol Mestres', 'Arnau Marzabal', 'Jorge Cortés']","This paper considers the problem of solving constrained
  reinforcement learning problems with anytime guarantees, meaning
  that the algorithmic solution returns a safe policy regardless of
  when it is terminated. Drawing inspiration from anytime constrained
  optimization, we introduce Reinforcement Learning-based Safe
  Gradient Flow (RL-SGF), an on-policy algorithm which employs
  estimates of the value functions and their respective gradients
  associated with the objective and safety constraints for the current
  policy, and updates the policy parameters by solving a convex
  quadratically constrained quadratic program. We show that if the
  estimates are computed with a sufficiently large number of episodes
  (for which we provide an explicit bound), safe policies are updated
  to safe policies with a probability higher than a prescribed
  tolerance. We also show that iterates asymptotically converge to a
  neighborhood of a KKT point, whose size can be arbitrarily reduced
  by refining the estimates of the value function and their gradients.
  We illustrate the performance of RL-SGF in a navigation example.",2025-04-23T04:51:31Z,http://arxiv.org/pdf/2504.16417v1,"['eess.SY', 'cs.SY']"
2506.00458v1,Reinforcement Learning for Hanabi,"['Nina Cohen', 'Kordel K. France']","Hanabi has become a popular game for research when it comes to reinforcement
learning (RL) as it is one of the few cooperative card games where you have
incomplete knowledge of the entire environment, thus presenting a challenge for
a RL agent. We explored different tabular and deep reinforcement learning
algorithms to see which had the best performance both against an agent of the
same type and also against other types of agents. We establish that certain
agents played their highest scoring games against specific agents while others
exhibited higher scores on average by adapting to the opposing agent's
behavior. We attempted to quantify the conditions under which each algorithm
provides the best advantage and identified the most interesting interactions
between agents of different types. In the end, we found that temporal
difference (TD) algorithms had better overall performance and balancing of play
types compared to tabular agents. Specifically, tabular Expected SARSA and deep
Q-Learning agents showed the best performance.",2025-05-31T08:24:16Z,http://arxiv.org/pdf/2506.00458v1,"['cs.LG', 'cs.AI', 'cs.GT', 'cs.MA']"
1905.01072v3,Deep Residual Reinforcement Learning,"['Shangtong Zhang', 'Wendelin Boehmer', 'Shimon Whiteson']","We revisit residual algorithms in both model-free and model-based
reinforcement learning settings. We propose the bidirectional target network
technique to stabilize residual algorithms, yielding a residual version of DDPG
that significantly outperforms vanilla DDPG in the DeepMind Control Suite
benchmark. Moreover, we find the residual algorithm an effective approach to
the distribution mismatch problem in model-based planning. Compared with the
existing TD($k$) method, our residual-based method makes weaker assumptions
about the model and yields a greater performance boost.",2019-05-03T08:38:35Z,http://arxiv.org/pdf/1905.01072v3,"['cs.LG', 'cs.AI', 'stat.ML']"
1908.08773v2,Opponent Aware Reinforcement Learning,"['Victor Gallego', 'Roi Naveiro', 'David Rios Insua', 'David Gomez-Ullate Oteiza']","We introduce Threatened Markov Decision Processes (TMDPs) as an extension of
the classical Markov Decision Process framework for Reinforcement Learning
(RL). TMDPs allow suporting a decision maker against potential opponents in a
RL context. We also propose a level-k thinking scheme resulting in a novel
learning approach to deal with TMDPs. After introducing our framework and
deriving theoretical results, relevant empirical evidence is given via
extensive experiments, showing the benefits of accounting for adversaries in RL
while the agent learns",2019-08-22T04:19:12Z,http://arxiv.org/pdf/1908.08773v2,"['cs.LG', 'stat.ML']"
2210.08263v1,Reinforcement Learning for ConnectX,"['Sheel Shah', 'Shubham Gupta']","ConnectX is a two-player game that generalizes the popular game Connect 4.
The objective is to get X coins across a row, column, or diagonal of an M x N
board. The first player to do so wins the game. The parameters (M, N, X) are
allowed to change in each game, making ConnectX a novel and challenging
problem. In this paper, we present our work on the implementation and
modification of various reinforcement learning algorithms to play ConnectX.",2022-10-15T11:38:19Z,http://arxiv.org/pdf/2210.08263v1,['cs.AI']
1804.02477v3,Programmatically Interpretable Reinforcement Learning,"['Abhinav Verma', 'Vijayaraghavan Murali', 'Rishabh Singh', 'Pushmeet Kohli', 'Swarat Chaudhuri']","We present a reinforcement learning framework, called Programmatically
Interpretable Reinforcement Learning (PIRL), that is designed to generate
interpretable and verifiable agent policies. Unlike the popular Deep
Reinforcement Learning (DRL) paradigm, which represents policies by neural
networks, PIRL represents policies using a high-level, domain-specific
programming language. Such programmatic policies have the benefits of being
more easily interpreted than neural networks, and being amenable to
verification by symbolic methods. We propose a new method, called Neurally
Directed Program Search (NDPS), for solving the challenging nonsmooth
optimization problem of finding a programmatic policy with maximal reward. NDPS
works by first learning a neural policy network using DRL, and then performing
a local search over programmatic policies that seeks to minimize a distance
from this neural ""oracle"". We evaluate NDPS on the task of learning to drive a
simulated car in the TORCS car-racing environment. We demonstrate that NDPS is
able to discover human-readable policies that pass some significant performance
bars. We also show that PIRL policies can have smoother trajectories, and can
be more easily transferred to environments not encountered during training,
than corresponding policies discovered by DRL.",2018-04-06T22:17:18Z,http://arxiv.org/pdf/1804.02477v3,"['cs.LG', 'cs.AI', 'cs.PL', 'stat.ML']"
2202.05135v5,Group-Agent Reinforcement Learning,"['Kaiyue Wu', 'Xiao-Jun Zeng']","It can largely benefit the reinforcement learning (RL) process of each agent
if multiple geographically distributed agents perform their separate RL tasks
cooperatively. Different from multi-agent reinforcement learning (MARL) where
multiple agents are in a common environment and should learn to cooperate or
compete with each other, in this case each agent has its separate environment
and only communicates with others to share knowledge without any cooperative or
competitive behaviour as a learning outcome. In fact, this scenario exists
widely in real life whose concept can be utilised in many applications, but is
not well understood yet and not well formulated. As the first effort, we
propose group-agent system for RL as a formulation of this scenario and the
third type of RL system with respect to single-agent and multi-agent systems.
We then propose a distributed RL framework called DDAL (Decentralised
Distributed Asynchronous Learning) designed for group-agent reinforcement
learning (GARL). We show through experiments that DDAL achieved desirable
performance with very stable training and has good scalability.",2022-02-10T16:40:59Z,http://arxiv.org/pdf/2202.05135v5,['cs.LG']
2110.07940v1,Wasserstein Unsupervised Reinforcement Learning,"['Shuncheng He', 'Yuhang Jiang', 'Hongchang Zhang', 'Jianzhun Shao', 'Xiangyang Ji']","Unsupervised reinforcement learning aims to train agents to learn a handful
of policies or skills in environments without external reward. These
pre-trained policies can accelerate learning when endowed with external reward,
and can also be used as primitive options in hierarchical reinforcement
learning. Conventional approaches of unsupervised skill discovery feed a latent
variable to the agent and shed its empowerment on agent's behavior by mutual
information (MI) maximization. However, the policies learned by MI-based
methods cannot sufficiently explore the state space, despite they can be
successfully identified from each other. Therefore we propose a new framework
Wasserstein unsupervised reinforcement learning (WURL) where we directly
maximize the distance of state distributions induced by different policies.
Additionally, we overcome difficulties in simultaneously training N(N >2)
policies, and amortizing the overall reward to each step. Experiments show
policies learned by our approach outperform MI-based methods on the metric of
Wasserstein distance while keeping high discriminability. Furthermore, the
agents trained by WURL can sufficiently explore the state space in mazes and
MuJoCo tasks and the pre-trained policies can be applied to downstream tasks by
hierarchical learning.",2021-10-15T08:41:51Z,http://arxiv.org/pdf/2110.07940v1,['cs.LG']
2204.02372v2,Jump-Start Reinforcement Learning,"['Ikechukwu Uchendu', 'Ted Xiao', 'Yao Lu', 'Banghua Zhu', 'Mengyuan Yan', 'Joséphine Simon', 'Matthew Bennice', 'Chuyuan Fu', 'Cong Ma', 'Jiantao Jiao', 'Sergey Levine', 'Karol Hausman']","Reinforcement learning (RL) provides a theoretical framework for continuously
improving an agent's behavior via trial and error. However, efficiently
learning policies from scratch can be very difficult, particularly for tasks
with exploration challenges. In such settings, it might be desirable to
initialize RL with an existing policy, offline data, or demonstrations.
However, naively performing such initialization in RL often works poorly,
especially for value-based methods. In this paper, we present a meta algorithm
that can use offline data, demonstrations, or a pre-existing policy to
initialize an RL policy, and is compatible with any RL approach. In particular,
we propose Jump-Start Reinforcement Learning (JSRL), an algorithm that employs
two policies to solve tasks: a guide-policy, and an exploration-policy. By
using the guide-policy to form a curriculum of starting states for the
exploration-policy, we are able to efficiently improve performance on a set of
simulated robotic tasks. We show via experiments that JSRL is able to
significantly outperform existing imitation and reinforcement learning
algorithms, particularly in the small-data regime. In addition, we provide an
upper bound on the sample complexity of JSRL and show that with the help of a
guide-policy, one can improve the sample complexity for non-optimism
exploration methods from exponential in horizon to polynomial.",2022-04-05T17:25:22Z,http://arxiv.org/pdf/2204.02372v2,['cs.LG']
2309.15293v5,Maximum diffusion reinforcement learning,"['Thomas A. Berrueta', 'Allison Pinosky', 'Todd D. Murphey']","Robots and animals both experience the world through their bodies and senses.
Their embodiment constrains their experiences, ensuring they unfold
continuously in space and time. As a result, the experiences of embodied agents
are intrinsically correlated. Correlations create fundamental challenges for
machine learning, as most techniques rely on the assumption that data are
independent and identically distributed. In reinforcement learning, where data
are directly collected from an agent's sequential experiences, violations of
this assumption are often unavoidable. Here, we derive a method that overcomes
this issue by exploiting the statistical mechanics of ergodic processes, which
we term maximum diffusion reinforcement learning. By decorrelating agent
experiences, our approach provably enables single-shot learning in continuous
deployments over the course of individual task attempts. Moreover, we prove our
approach generalizes well-known maximum entropy techniques, and robustly
exceeds state-of-the-art performance across popular benchmarks. Our results at
the nexus of physics, learning, and control form a foundation for transparent
and reliable decision-making in embodied reinforcement learning agents.",2023-09-26T22:14:56Z,http://arxiv.org/pdf/2309.15293v5,"['cs.LG', 'cond-mat.stat-mech', 'cs.AI', 'cs.RO']"
2003.10903v2,Distributional Reinforcement Learning with Ensembles,"['Björn Lindenberg', 'Jonas Nordqvist', 'Karl-Olof Lindahl']","It is well known that ensemble methods often provide enhanced performance in
reinforcement learning. In this paper, we explore this concept further by using
group-aided training within the distributional reinforcement learning paradigm.
Specifically, we propose an extension to categorical reinforcement learning,
where distributional learning targets are implicitly based on the total
information gathered by an ensemble. We empirically show that this may lead to
much more robust initial learning, a stronger individual performance level, and
good efficiency on a per-sample basis.",2020-03-24T14:59:54Z,http://arxiv.org/pdf/2003.10903v2,"['cs.LG', 'cs.AI', 'cs.MA', 'stat.ML', 'I.2.11; I.2.8']"
2307.01452v2,Causal Reinforcement Learning: A Survey,"['Zhihong Deng', 'Jing Jiang', 'Guodong Long', 'Chengqi Zhang']","Reinforcement learning is an essential paradigm for solving sequential
decision problems under uncertainty. Despite many remarkable achievements in
recent decades, applying reinforcement learning methods in the real world
remains challenging. One of the main obstacles is that reinforcement learning
agents lack a fundamental understanding of the world and must therefore learn
from scratch through numerous trial-and-error interactions. They may also face
challenges in providing explanations for their decisions and generalizing the
acquired knowledge. Causality, however, offers a notable advantage as it can
formalize knowledge in a systematic manner and leverage invariance for
effective knowledge transfer. This has led to the emergence of causal
reinforcement learning, a subfield of reinforcement learning that seeks to
enhance existing algorithms by incorporating causal relationships into the
learning process. In this survey, we comprehensively review the literature on
causal reinforcement learning. We first introduce the basic concepts of
causality and reinforcement learning, and then explain how causality can
address core challenges in non-causal reinforcement learning. We categorize and
systematically review existing causal reinforcement learning approaches based
on their target problems and methodologies. Finally, we outline open issues and
future directions in this emerging field.",2023-07-04T03:00:43Z,http://arxiv.org/pdf/2307.01452v2,"['cs.LG', 'cs.AI']"
1903.02710v1,Concurrent Meta Reinforcement Learning,"['Emilio Parisotto', 'Soham Ghosh', 'Sai Bhargav Yalamanchi', 'Varsha Chinnaobireddy', 'Yuhuai Wu', 'Ruslan Salakhutdinov']","State-of-the-art meta reinforcement learning algorithms typically assume the
setting of a single agent interacting with its environment in a sequential
manner. A negative side-effect of this sequential execution paradigm is that,
as the environment becomes more and more challenging, and thus requiring more
interaction episodes for the meta-learner, it needs the agent to reason over
longer and longer time-scales. To combat the difficulty of long time-scale
credit assignment, we propose an alternative parallel framework, which we name
""Concurrent Meta-Reinforcement Learning"" (CMRL), that transforms the temporal
credit assignment problem into a multi-agent reinforcement learning one. In
this multi-agent setting, a set of parallel agents are executed in the same
environment and each of these ""rollout"" agents are given the means to
communicate with each other. The goal of the communication is to coordinate, in
a collaborative manner, the most efficient exploration of the shared task the
agents are currently assigned. This coordination therefore represents the
meta-learning aspect of the framework, as each agent can be assigned or assign
itself a particular section of the current task's state space. This framework
is in contrast to standard RL methods that assume that each parallel rollout
occurs independently, which can potentially waste computation if many of the
rollouts end up sampling the same part of the state space. Furthermore, the
parallel setting enables us to define several reward sharing functions and
auxiliary losses that are non-trivial to apply in the sequential setting. We
demonstrate the effectiveness of our proposed CMRL at improving over sequential
methods in a variety of challenging tasks.",2019-03-07T03:28:41Z,http://arxiv.org/pdf/1903.02710v1,['cs.AI']
1611.03071v4,Fairness in Reinforcement Learning,"['Shahin Jabbari', 'Matthew Joseph', 'Michael Kearns', 'Jamie Morgenstern', 'Aaron Roth']","We initiate the study of fairness in reinforcement learning, where the
actions of a learning algorithm may affect its environment and future rewards.
Our fairness constraint requires that an algorithm never prefers one action
over another if the long-term (discounted) reward of choosing the latter action
is higher. Our first result is negative: despite the fact that fairness is
consistent with the optimal policy, any learning algorithm satisfying fairness
must take time exponential in the number of states to achieve non-trivial
approximation to the optimal policy. We then provide a provably fair polynomial
time algorithm under an approximate notion of fairness, thus establishing an
exponential gap between exact and approximate fairness",2016-11-09T20:19:45Z,http://arxiv.org/pdf/1611.03071v4,['cs.LG']
1705.05427v3,Repeated Inverse Reinforcement Learning,"['Kareem Amin', 'Nan Jiang', 'Satinder Singh']","We introduce a novel repeated Inverse Reinforcement Learning problem: the
agent has to act on behalf of a human in a sequence of tasks and wishes to
minimize the number of tasks that it surprises the human by acting suboptimally
with respect to how the human would have acted. Each time the human is
surprised, the agent is provided a demonstration of the desired behavior by the
human. We formalize this problem, including how the sequence of tasks is
chosen, in a few different ways and provide some foundational results.",2017-05-15T20:06:35Z,http://arxiv.org/pdf/1705.05427v3,"['cs.AI', 'cs.LG']"
1809.01560v2,Reinforcement Learning under Threats,"['Victor Gallego', 'Roi Naveiro', 'David Rios Insua']","In several reinforcement learning (RL) scenarios, mainly in security
settings, there may be adversaries trying to interfere with the reward
generating process. In this paper, we introduce Threatened Markov Decision
Processes (TMDPs), which provide a framework to support a decision maker
against a potential adversary in RL. Furthermore, we propose a level-$k$
thinking scheme resulting in a new learning framework to deal with TMDPs. After
introducing our framework and deriving theoretical results, relevant empirical
evidence is given via extensive experiments, showing the benefits of accounting
for adversaries while the agent learns.",2018-09-05T14:56:09Z,http://arxiv.org/pdf/1809.01560v2,"['cs.LG', 'cs.AI', 'cs.CR', 'stat.ML']"
1912.06085v1,Control-Tutored Reinforcement Learning,"['Francesco De Lellis', 'Fabrizia Auletta', 'Giovanni Russo', 'Piero De Lellis', 'Mario di Bernardo']","We introduce a control-tutored reinforcement learning (CTRL) algorithm. The
idea is to enhance tabular learning algorithms so as to improve the exploration
of the state-space, and substantially reduce learning times by leveraging some
limited knowledge of the plant encoded into a tutoring model-based control
strategy. We illustrate the benefits of our novel approach and its
effectiveness by using the problem of controlling one or more agents to herd
and contain within a goal region a set of target free-roving agents in the
plane.",2019-12-12T17:14:15Z,http://arxiv.org/pdf/1912.06085v1,"['math.OC', 'cs.LG', 'cs.MA', 'cs.SY', 'eess.SY', 'stat.ML']"
2001.05411v3,Lipschitz Lifelong Reinforcement Learning,"['Erwan Lecarpentier', 'David Abel', 'Kavosh Asadi', 'Yuu Jinnai', 'Emmanuel Rachelson', 'Michael L. Littman']","We consider the problem of knowledge transfer when an agent is facing a
series of Reinforcement Learning (RL) tasks. We introduce a novel metric
between Markov Decision Processes (MDPs) and establish that close MDPs have
close optimal value functions. Formally, the optimal value functions are
Lipschitz continuous with respect to the tasks space. These theoretical results
lead us to a value-transfer method for Lifelong RL, which we use to build a
PAC-MDP algorithm with improved convergence rate. Further, we show the method
to experience no negative transfer with high probability. We illustrate the
benefits of the method in Lifelong RL experiments.",2020-01-15T16:29:30Z,http://arxiv.org/pdf/2001.05411v3,"['cs.LG', 'cs.AI', 'stat.ML']"
1907.10323v1,Fairness in Reinforcement Learning,['Paul Weng'],"Decision support systems (e.g., for ecological conservation) and autonomous
systems (e.g., adaptive controllers in smart cities) start to be deployed in
real applications. Although their operations often impact many users or
stakeholders, no fairness consideration is generally taken into account in
their design, which could lead to completely unfair outcomes for some users or
stakeholders. To tackle this issue, we advocate for the use of social welfare
functions that encode fairness and present this general novel problem in the
context of (deep) reinforcement learning, although it could possibly be
extended to other machine learning tasks.",2019-07-24T09:27:11Z,http://arxiv.org/pdf/1907.10323v1,"['cs.LG', 'cs.AI', 'stat.ML']"
1910.08285v1,Multi-View Reinforcement Learning,"['Minne Li', 'Lisheng Wu', 'Haitham Bou Ammar', 'Jun Wang']","This paper is concerned with multi-view reinforcement learning (MVRL), which
allows for decision making when agents share common dynamics but adhere to
different observation models. We define the MVRL framework by extending
partially observable Markov decision processes (POMDPs) to support more than
one observation model and propose two solution methods through observation
augmentation and cross-view policy transfer. We empirically evaluate our method
and demonstrate its effectiveness in a variety of environments. Specifically,
we show reductions in sample complexities and computational time for acquiring
policies that handle multi-view environments.",2019-10-18T07:14:46Z,http://arxiv.org/pdf/1910.08285v1,"['cs.LG', 'stat.ML']"
1910.09322v2,Momentum in Reinforcement Learning,"['Nino Vieillard', 'Bruno Scherrer', 'Olivier Pietquin', 'Matthieu Geist']","We adapt the optimization's concept of momentum to reinforcement learning.
Seeing the state-action value functions as an analog to the gradients in
optimization, we interpret momentum as an average of consecutive $q$-functions.
We derive Momentum Value Iteration (MoVI), a variation of Value Iteration that
incorporates this momentum idea. Our analysis shows that this allows MoVI to
average errors over successive iterations. We show that the proposed approach
can be readily extended to deep learning. Specifically, we propose a simple
improvement on DQN based on MoVI, and experiment it on Atari games.",2019-10-21T12:51:38Z,http://arxiv.org/pdf/1910.09322v2,"['cs.LG', 'stat.ML']"
2102.07097v1,Domain Adversarial Reinforcement Learning,"['Bonnie Li', 'Vincent François-Lavet', 'Thang Doan', 'Joelle Pineau']","We consider the problem of generalization in reinforcement learning where
visual aspects of the observations might differ, e.g. when there are different
backgrounds or change in contrast, brightness, etc. We assume that our agent
has access to only a few of the MDPs from the MDP distribution during training.
The performance of the agent is then reported on new unknown test domains drawn
from the distribution (e.g. unseen backgrounds). For this ""zero-shot RL"" task,
we enforce invariance of the learned representations to visual domains via a
domain adversarial optimization process. We empirically show that this approach
allows achieving a significant generalization improvement to new unseen
domains.",2021-02-14T07:58:41Z,http://arxiv.org/pdf/2102.07097v1,"['cs.LG', 'cs.AI']"
2102.13446v1,Safe Distributional Reinforcement Learning,"['Jianyi Zhang', 'Paul Weng']","Safety in reinforcement learning (RL) is a key property in both training and
execution in many domains such as autonomous driving or finance. In this paper,
we formalize it with a constrained RL formulation in the distributional RL
setting. Our general model accepts various definitions of safety(e.g., bounds
on expected performance, CVaR, variance, or probability of reaching bad
states). To ensure safety during learning, we extend a safe policy optimization
method to solve our problem. The distributional RL perspective leads to a more
efficient algorithm while additionally catering for natural safe constraints.
We empirically validate our propositions on artificial and real domains against
appropriate state-of-the-art safe RL algorithms.",2021-02-26T13:03:27Z,http://arxiv.org/pdf/2102.13446v1,['cs.LG']
2302.10831v1,Minimax-Bayes Reinforcement Learning,"['Thomas Kleine Buening', 'Christos Dimitrakakis', 'Hannes Eriksson', 'Divya Grover', 'Emilio Jorge']","While the Bayesian decision-theoretic framework offers an elegant solution to
the problem of decision making under uncertainty, one question is how to
appropriately select the prior distribution. One idea is to employ a worst-case
prior. However, this is not as easy to specify in sequential decision making as
in simple statistical estimation problems. This paper studies (sometimes
approximate) minimax-Bayes solutions for various reinforcement learning
problems to gain insights into the properties of the corresponding priors and
policies. We find that while the worst-case prior depends on the setting, the
corresponding minimax policies are more robust than those that assume a
standard (i.e. uniform) prior.",2023-02-21T17:10:21Z,http://arxiv.org/pdf/2302.10831v1,"['cs.LG', 'stat.ML']"
2406.13127v2,Oralytics Reinforcement Learning Algorithm,"['Anna L. Trella', 'Kelly W. Zhang', 'Stephanie M. Carpenter', 'David Elashoff', 'Zara M. Greer', 'Inbal Nahum-Shani', 'Dennis Ruenger', 'Vivek Shetty', 'Susan A. Murphy']","Dental disease is still one of the most common chronic diseases in the United
States. While dental disease is preventable through healthy oral self-care
behaviors (OSCB), this basic behavior is not consistently practiced. We have
developed Oralytics, an online, reinforcement learning (RL) algorithm that
optimizes the delivery of personalized intervention prompts to improve OSCB. In
this paper, we offer a full overview of algorithm design decisions made using
prior data, domain expertise, and experiments in a simulation test bed. The
finalized RL algorithm was deployed in the Oralytics clinical trial, conducted
from fall 2023 to summer 2024.",2024-06-19T00:44:11Z,http://arxiv.org/pdf/2406.13127v2,['cs.AI']
2412.02931v1,Inverse Delayed Reinforcement Learning,"['Simon Sinong Zhan', 'Qingyuan Wu', 'Zhian Ruan', 'Frank Yang', 'Philip Wang', 'Yixuan Wang', 'Ruochen Jiao', 'Chao Huang', 'Qi Zhu']","Inverse Reinforcement Learning (IRL) has demonstrated effectiveness in a
variety of imitation tasks. In this paper, we introduce an IRL framework
designed to extract rewarding features from expert trajectories affected by
delayed disturbances. Instead of relying on direct observations, our approach
employs an efficient off-policy adversarial training framework to derive expert
features and recover optimal policies from augmented delayed observations.
Empirical evaluations in the MuJoCo environment under diverse delay settings
validate the effectiveness of our method. Furthermore, we provide a theoretical
analysis showing that recovering expert policies from augmented delayed
observations outperforms using direct delayed observations.",2024-12-04T00:53:55Z,http://arxiv.org/pdf/2412.02931v1,"['cs.LG', 'cs.AI', 'cs.SY', 'eess.SY']"
1606.02396v1,Deep Successor Reinforcement Learning,"['Tejas D. Kulkarni', 'Ardavan Saeedi', 'Simanta Gautam', 'Samuel J. Gershman']","Learning robust value functions given raw observations and rewards is now
possible with model-free and model-based deep reinforcement learning
algorithms. There is a third alternative, called Successor Representations
(SR), which decomposes the value function into two components -- a reward
predictor and a successor map. The successor map represents the expected future
state occupancy from any given state and the reward predictor maps states to
scalar rewards. The value function of a state can be computed as the inner
product between the successor map and the reward weights. In this paper, we
present DSR, which generalizes SR within an end-to-end deep reinforcement
learning framework. DSR has several appealing properties including: increased
sensitivity to distal reward changes due to factorization of reward and world
dynamics, and the ability to extract bottleneck states (subgoals) given
successor maps trained under a random policy. We show the efficacy of our
approach on two diverse environments given raw pixel observations -- simple
grid-world domains (MazeBase) and the Doom game engine.",2016-06-08T04:48:49Z,http://arxiv.org/pdf/1606.02396v1,"['stat.ML', 'cs.AI', 'cs.LG', 'cs.NE']"
1611.05763v3,Learning to reinforcement learn,"['Jane X Wang', 'Zeb Kurth-Nelson', 'Dhruva Tirumala', 'Hubert Soyer', 'Joel Z Leibo', 'Remi Munos', 'Charles Blundell', 'Dharshan Kumaran', 'Matt Botvinick']","In recent years deep reinforcement learning (RL) systems have attained
superhuman performance in a number of challenging task domains. However, a
major limitation of such applications is their demand for massive amounts of
training data. A critical present objective is thus to develop deep RL methods
that can adapt rapidly to new tasks. In the present work we introduce a novel
approach to this challenge, which we refer to as deep meta-reinforcement
learning. Previous work has shown that recurrent networks can support
meta-learning in a fully supervised context. We extend this approach to the RL
setting. What emerges is a system that is trained using one RL algorithm, but
whose recurrent dynamics implement a second, quite separate RL procedure. This
second, learned RL algorithm can differ from the original one in arbitrary
ways. Importantly, because it is learned, it is configured to exploit structure
in the training domain. We unpack these points in a series of seven
proof-of-concept experiments, each of which examines a key aspect of deep
meta-RL. We consider prospects for extending and scaling up the approach, and
also point out some potentially important implications for neuroscience.",2016-11-17T16:29:11Z,http://arxiv.org/pdf/1611.05763v3,"['cs.LG', 'cs.AI', 'stat.ML']"
1702.05796v1,Collaborative Deep Reinforcement Learning,"['Kaixiang Lin', 'Shu Wang', 'Jiayu Zhou']","Besides independent learning, human learning process is highly improved by
summarizing what has been learned, communicating it with peers, and
subsequently fusing knowledge from different sources to assist the current
learning goal. This collaborative learning procedure ensures that the knowledge
is shared, continuously refined, and concluded from different perspectives to
construct a more profound understanding. The idea of knowledge transfer has led
to many advances in machine learning and data mining, but significant
challenges remain, especially when it comes to reinforcement learning,
heterogeneous model structures, and different learning tasks. Motivated by
human collaborative learning, in this paper we propose a collaborative deep
reinforcement learning (CDRL) framework that performs adaptive knowledge
transfer among heterogeneous learning agents. Specifically, the proposed CDRL
conducts a novel deep knowledge distillation method to address the
heterogeneity among different learning tasks with a deep alignment network.
Furthermore, we present an efficient collaborative Asynchronous Advantage
Actor-Critic (cA3C) algorithm to incorporate deep knowledge distillation into
the online training of agents, and demonstrate the effectiveness of the CDRL
framework using extensive empirical evaluation on OpenAI gym.",2017-02-19T21:13:45Z,http://arxiv.org/pdf/1702.05796v1,['cs.LG']
1703.02702v1,Robust Adversarial Reinforcement Learning,"['Lerrel Pinto', 'James Davidson', 'Rahul Sukthankar', 'Abhinav Gupta']","Deep neural networks coupled with fast simulation and improved computation
have led to recent successes in the field of reinforcement learning (RL).
However, most current RL-based approaches fail to generalize since: (a) the gap
between simulation and real world is so large that policy-learning approaches
fail to transfer; (b) even if policy learning is done in real world, the data
scarcity leads to failed generalization from training to test scenarios (e.g.,
due to different friction or object masses). Inspired from H-infinity control
methods, we note that both modeling errors and differences in training and test
scenarios can be viewed as extra forces/disturbances in the system. This paper
proposes the idea of robust adversarial reinforcement learning (RARL), where we
train an agent to operate in the presence of a destabilizing adversary that
applies disturbance forces to the system. The jointly trained adversary is
reinforced -- that is, it learns an optimal destabilization policy. We
formulate the policy learning as a zero-sum, minimax objective function.
Extensive experiments in multiple environments (InvertedPendulum, HalfCheetah,
Swimmer, Hopper and Walker2d) conclusively demonstrate that our method (a)
improves training stability; (b) is robust to differences in training/test
conditions; and c) outperform the baseline even in the absence of the
adversary.",2017-03-08T04:58:51Z,http://arxiv.org/pdf/1703.02702v1,"['cs.LG', 'cs.AI', 'cs.MA', 'cs.RO']"
1803.10227v1,Forward-Backward Reinforcement Learning,"['Ashley D. Edwards', 'Laura Downs', 'James C. Davidson']","Goals for reinforcement learning problems are typically defined through
hand-specified rewards. To design such problems, developers of learning
algorithms must inherently be aware of what the task goals are, yet we often
require agents to discover them on their own without any supervision beyond
these sparse rewards. While much of the power of reinforcement learning derives
from the concept that agents can learn with little guidance, this requirement
greatly burdens the training process. If we relax this one restriction and
endow the agent with knowledge of the reward function, and in particular of the
goal, we can leverage backwards induction to accelerate training. To achieve
this, we propose training a model to learn to take imagined reversal steps from
known goal states. Rather than training an agent exclusively to determine how
to reach a goal while moving forwards in time, our approach travels backwards
to jointly predict how we got there. We evaluate our work in Gridworld and
Towers of Hanoi and empirically demonstrate that it yields better performance
than standard DDQN.",2018-03-27T04:33:08Z,http://arxiv.org/pdf/1803.10227v1,"['cs.LG', 'cs.AI', 'stat.ML']"
1805.09801v1,Meta-Gradient Reinforcement Learning,"['Zhongwen Xu', 'Hado van Hasselt', 'David Silver']","The goal of reinforcement learning algorithms is to estimate and/or optimise
the value function. However, unlike supervised learning, no teacher or oracle
is available to provide the true value function. Instead, the majority of
reinforcement learning algorithms estimate and/or optimise a proxy for the
value function. This proxy is typically based on a sampled and bootstrapped
approximation to the true value function, known as a return. The particular
choice of return is one of the chief components determining the nature of the
algorithm: the rate at which future rewards are discounted; when and how values
should be bootstrapped; or even the nature of the rewards themselves. It is
well-known that these decisions are crucial to the overall success of RL
algorithms. We discuss a gradient-based meta-learning algorithm that is able to
adapt the nature of the return, online, whilst interacting and learning from
the environment. When applied to 57 games on the Atari 2600 environment over
200 million frames, our algorithm achieved a new state-of-the-art performance.",2018-05-24T17:45:11Z,http://arxiv.org/pdf/1805.09801v1,"['cs.LG', 'cs.AI', 'stat.ML']"
1905.00976v2,Collaborative Evolutionary Reinforcement Learning,"['Shauharda Khadka', 'Somdeb Majumdar', 'Tarek Nassar', 'Zach Dwiel', 'Evren Tumer', 'Santiago Miret', 'Yinyin Liu', 'Kagan Tumer']","Deep reinforcement learning algorithms have been successfully applied to a
range of challenging control tasks. However, these methods typically struggle
with achieving effective exploration and are extremely sensitive to the choice
of hyperparameters. One reason is that most approaches use a noisy version of
their operating policy to explore - thereby limiting the range of exploration.
In this paper, we introduce Collaborative Evolutionary Reinforcement Learning
(CERL), a scalable framework that comprises a portfolio of policies that
simultaneously explore and exploit diverse regions of the solution space. A
collection of learners - typically proven algorithms like TD3 - optimize over
varying time-horizons leading to this diverse portfolio. All learners
contribute to and use a shared replay buffer to achieve greater sample
efficiency. Computational resources are dynamically distributed to favor the
best learners as a form of online algorithm selection. Neuroevolution binds
this entire process to generate a single emergent learner that exceeds the
capabilities of any individual learner. Experiments in a range of continuous
control benchmarks demonstrate that the emergent learner significantly
outperforms its composite learners while remaining overall more
sample-efficient - notably solving the Mujoco Humanoid benchmark where all of
its composite learners (TD3) fail entirely in isolation.",2019-05-02T21:45:03Z,http://arxiv.org/pdf/1905.00976v2,"['cs.LG', 'cs.AI', 'stat.ML']"
2005.12108v1,Gradient Monitored Reinforcement Learning,"['Mohammed Sharafath Abdul Hameed', 'Gavneet Singh Chadha', 'Andreas Schwung', 'Steven X. Ding']","This paper presents a novel neural network training approach for faster
convergence and better generalization abilities in deep reinforcement learning.
Particularly, we focus on the enhancement of training and evaluation
performance in reinforcement learning algorithms by systematically reducing
gradient's variance and thereby providing a more targeted learning process. The
proposed method which we term as Gradient Monitoring(GM), is an approach to
steer the learning in the weight parameters of a neural network based on the
dynamic development and feedback from the training process itself. We propose
different variants of the GM methodology which have been proven to increase the
underlying performance of the model. The one of the proposed variant, Momentum
with Gradient Monitoring (M-WGM), allows for a continuous adjustment of the
quantum of back-propagated gradients in the network based on certain learning
parameters. We further enhance the method with Adaptive Momentum with Gradient
Monitoring (AM-WGM) method which allows for automatic adjustment between
focused learning of certain weights versus a more dispersed learning depending
on the feedback from the rewards collected. As a by-product, it also allows for
automatic derivation of the required deep network sizes during training as the
algorithm automatically freezes trained weights. The approach is applied to two
discrete (Multi-Robot Co-ordination problem and Atari games) and one continuous
control task (MuJoCo) using Advantage Actor-Critic (A2C) and Proximal Policy
Optimization (PPO) respectively. The results obtained particularly underline
the applicability and performance improvements of the methods in terms of
generalization capability.",2020-05-25T13:45:47Z,http://arxiv.org/pdf/2005.12108v1,"['cs.LG', 'stat.ML']"
1911.08363v3,Attention-Privileged Reinforcement Learning,"['Sasha Salter', 'Dushyant Rao', 'Markus Wulfmeier', 'Raia Hadsell', 'Ingmar Posner']","Image-based Reinforcement Learning is known to suffer from poor sample
efficiency and generalisation to unseen visuals such as distractors
(task-independent aspects of the observation space). Visual domain
randomisation encourages transfer by training over visual factors of variation
that may be encountered in the target domain. This increases learning
complexity, can negatively impact learning rate and performance, and requires
knowledge of potential variations during deployment. In this paper, we
introduce Attention-Privileged Reinforcement Learning (APRiL) which uses a
self-supervised attention mechanism to significantly alleviate these drawbacks:
by focusing on task-relevant aspects of the observations, attention provides
robustness to distractors as well as significantly increased learning
efficiency. APRiL trains two attention-augmented actor-critic agents: one
purely based on image observations, available across training and transfer
domains; and one with access to privileged information (such as environment
states) available only during training. Experience is shared between both
agents and their attention mechanisms are aligned. The image-based policy can
then be deployed without access to privileged information. We experimentally
demonstrate accelerated and more robust learning on a diverse set of domains,
leading to improved final performance for environments both within and outside
the training distribution.",2019-11-19T15:49:29Z,http://arxiv.org/pdf/1911.08363v3,"['cs.AI', 'cs.LG']"
0810.3828v1,Quantum reinforcement learning,"['Daoyi Dong', 'Chunlin Chen', 'Hanxiong Li', 'Tzyh-Jong Tarn']","The key approaches for machine learning, especially learning in unknown
probabilistic environments are new representations and computation mechanisms.
In this paper, a novel quantum reinforcement learning (QRL) method is proposed
by combining quantum theory and reinforcement learning (RL). Inspired by the
state superposition principle and quantum parallelism, a framework of value
updating algorithm is introduced. The state (action) in traditional RL is
identified as the eigen state (eigen action) in QRL. The state (action) set can
be represented with a quantum superposition state and the eigen state (eigen
action) can be obtained by randomly observing the simulated quantum state
according to the collapse postulate of quantum measurement. The probability of
the eigen action is determined by the probability amplitude, which is
parallelly updated according to rewards. Some related characteristics of QRL
such as convergence, optimality and balancing between exploration and
exploitation are also analyzed, which shows that this approach makes a good
tradeoff between exploration and exploitation using the probability amplitude
and can speed up learning through the quantum parallelism. To evaluate the
performance and practicability of QRL, several simulated experiments are given
and the results demonstrate the effectiveness and superiority of QRL algorithm
for some complex problems. The present work is also an effective exploration on
the application of quantum computation to artificial intelligence.",2008-10-21T13:38:33Z,http://arxiv.org/pdf/0810.3828v1,"['quant-ph', 'cs.AI', 'cs.LG']"
2302.08854v4,Post Reinforcement Learning Inference,"['Vasilis Syrgkanis', 'Ruohan Zhan']","We consider estimation and inference using data collected from reinforcement
learning algorithms. These algorithms, characterized by their adaptive
experimentation, interact with individual units over multiple stages,
dynamically adjusting their strategies based on previous interactions. Our goal
is to evaluate a counterfactual policy post-data collection and estimate
structural parameters, like dynamic treatment effects, which can be used for
credit assignment and determining the effect of earlier actions on final
outcomes. Such parameters of interest can be framed as solutions to moment
equations, but not minimizers of a population loss function, leading to
Z-estimation approaches for static data. However, in the adaptive data
collection environment of reinforcement learning, where algorithms deploy
nonstationary behavior policies, standard estimators do not achieve asymptotic
normality due to the fluctuating variance. We propose a weighted Z-estimation
approach with carefully designed adaptive weights to stabilize the time-varying
estimation variance. We identify proper weighting schemes to restore the
consistency and asymptotic normality of the weighted Z-estimators for target
parameters, which allows for hypothesis testing and constructing uniform
confidence regions. Primary applications include dynamic treatment effect
estimation and dynamic off-policy evaluation.",2023-02-17T12:53:15Z,http://arxiv.org/pdf/2302.08854v4,"['stat.ML', 'cs.LG', 'econ.EM']"
2304.05099v6,Feudal Graph Reinforcement Learning,"['Tommaso Marzi', 'Arshjot Khehra', 'Andrea Cini', 'Cesare Alippi']","Graph-based representations and message-passing modular policies constitute
prominent approaches to tackling composable control problems in reinforcement
learning (RL). However, as shown by recent graph deep learning literature, such
local message-passing operators can create information bottlenecks and hinder
global coordination. The issue becomes more serious in tasks requiring
high-level planning. In this work, we propose a novel methodology, named Feudal
Graph Reinforcement Learning (FGRL), that addresses such challenges by relying
on hierarchical RL and a pyramidal message-passing architecture. In particular,
FGRL defines a hierarchy of policies where high-level commands are propagated
from the top of the hierarchy down through a layered graph structure. The
bottom layers mimic the morphology of the physical system, while the upper
layers correspond to higher-order sub-modules. The resulting agents are then
characterized by a committee of policies where actions at a certain level set
goals for the level below, thus implementing a hierarchical decision-making
structure that can naturally implement task decomposition. We evaluate the
proposed framework on a graph clustering problem and MuJoCo locomotion tasks;
simulation results show that FGRL compares favorably against relevant
baselines. Furthermore, an in-depth analysis of the command propagation
mechanism provides evidence that the introduced message-passing scheme favors
learning hierarchical decision-making policies.",2023-04-11T09:51:13Z,http://arxiv.org/pdf/2304.05099v6,['cs.LG']
2304.09870v2,Heterogeneous-Agent Reinforcement Learning,"['Yifan Zhong', 'Jakub Grudzien Kuba', 'Xidong Feng', 'Siyi Hu', 'Jiaming Ji', 'Yaodong Yang']","The necessity for cooperation among intelligent machines has popularised
cooperative multi-agent reinforcement learning (MARL) in AI research. However,
many research endeavours heavily rely on parameter sharing among agents, which
confines them to only homogeneous-agent setting and leads to training
instability and lack of convergence guarantees. To achieve effective
cooperation in the general heterogeneous-agent setting, we propose
Heterogeneous-Agent Reinforcement Learning (HARL) algorithms that resolve the
aforementioned issues. Central to our findings are the multi-agent advantage
decomposition lemma and the sequential update scheme. Based on these, we
develop the provably correct Heterogeneous-Agent Trust Region Learning (HATRL),
and derive HATRPO and HAPPO by tractable approximations. Furthermore, we
discover a novel framework named Heterogeneous-Agent Mirror Learning (HAML),
which strengthens theoretical guarantees for HATRPO and HAPPO and provides a
general template for cooperative MARL algorithmic designs. We prove that all
algorithms derived from HAML inherently enjoy monotonic improvement of joint
return and convergence to Nash Equilibrium. As its natural outcome, HAML
validates more novel algorithms in addition to HATRPO and HAPPO, including
HAA2C, HADDPG, and HATD3, which generally outperform their existing
MA-counterparts. We comprehensively test HARL algorithms on six challenging
benchmarks and demonstrate their superior effectiveness and stability for
coordinating heterogeneous agents compared to strong baselines such as MAPPO
and QMIX.",2023-04-19T05:08:02Z,http://arxiv.org/pdf/2304.09870v2,"['cs.LG', 'cs.AI', 'cs.MA']"
2311.02198v6,Imitation Bootstrapped Reinforcement Learning,"['Hengyuan Hu', 'Suvir Mirchandani', 'Dorsa Sadigh']","Despite the considerable potential of reinforcement learning (RL), robotic
control tasks predominantly rely on imitation learning (IL) due to its better
sample efficiency. However, it is costly to collect comprehensive expert
demonstrations that enable IL to generalize to all possible scenarios, and any
distribution shift would require recollecting data for finetuning. Therefore,
RL is appealing if it can build upon IL as an efficient autonomous
self-improvement procedure. We propose imitation bootstrapped reinforcement
learning (IBRL), a novel framework for sample-efficient RL with demonstrations
that first trains an IL policy on the provided demonstrations and then uses it
to propose alternative actions for both online exploration and bootstrapping
target values. Compared to prior works that oversample the demonstrations or
regularize RL with an additional imitation loss, IBRL is able to utilize high
quality actions from IL policies since the beginning of training, which greatly
accelerates exploration and training efficiency. We evaluate IBRL on 6
simulation and 3 real-world tasks spanning various difficulty levels. IBRL
significantly outperforms prior methods and the improvement is particularly
more prominent in harder tasks.",2023-11-03T19:03:20Z,http://arxiv.org/pdf/2311.02198v6,"['cs.LG', 'cs.AI']"
2402.08848v2,Hybrid Inverse Reinforcement Learning,"['Juntao Ren', 'Gokul Swamy', 'Zhiwei Steven Wu', 'J. Andrew Bagnell', 'Sanjiban Choudhury']","The inverse reinforcement learning approach to imitation learning is a
double-edged sword. On the one hand, it can enable learning from a smaller
number of expert demonstrations with more robustness to error compounding than
behavioral cloning approaches. On the other hand, it requires that the learner
repeatedly solve a computationally expensive reinforcement learning (RL)
problem. Often, much of this computation is wasted searching over policies very
dissimilar to the expert's. In this work, we propose using hybrid RL --
training on a mixture of online and expert data -- to curtail unnecessary
exploration. Intuitively, the expert data focuses the learner on good states
during training, which reduces the amount of exploration required to compute a
strong policy. Notably, such an approach doesn't need the ability to reset the
learner to arbitrary states in the environment, a requirement of prior work in
efficient inverse RL. More formally, we derive a reduction from inverse RL to
expert-competitive RL (rather than globally optimal RL) that allows us to
dramatically reduce interaction during the inner policy search loop while
maintaining the benefits of the IRL approach. This allows us to derive both
model-free and model-based hybrid inverse RL algorithms with strong policy
performance guarantees. Empirically, we find that our approaches are
significantly more sample efficient than standard inverse RL and several other
baselines on a suite of continuous control tasks.",2024-02-13T23:29:09Z,http://arxiv.org/pdf/2402.08848v2,"['cs.LG', 'cs.AI']"
2403.02290v1,Koopman-Assisted Reinforcement Learning,"['Preston Rozwood', 'Edward Mehrez', 'Ludger Paehler', 'Wen Sun', 'Steven L. Brunton']","The Bellman equation and its continuous form, the Hamilton-Jacobi-Bellman
(HJB) equation, are ubiquitous in reinforcement learning (RL) and control
theory. However, these equations quickly become intractable for systems with
high-dimensional states and nonlinearity. This paper explores the connection
between the data-driven Koopman operator and Markov Decision Processes (MDPs),
resulting in the development of two new RL algorithms to address these
limitations. We leverage Koopman operator techniques to lift a nonlinear system
into new coordinates where the dynamics become approximately linear, and where
HJB-based methods are more tractable. In particular, the Koopman operator is
able to capture the expectation of the time evolution of the value function of
a given system via linear dynamics in the lifted coordinates. By parameterizing
the Koopman operator with the control actions, we construct a ``Koopman
tensor'' that facilitates the estimation of the optimal value function. Then, a
transformation of Bellman's framework in terms of the Koopman tensor enables us
to reformulate two max-entropy RL algorithms: soft value iteration and soft
actor-critic (SAC). This highly flexible framework can be used for
deterministic or stochastic systems as well as for discrete or continuous-time
dynamics. Finally, we show that these Koopman Assisted Reinforcement Learning
(KARL) algorithms attain state-of-the-art (SOTA) performance with respect to
traditional neural network-based SAC and linear quadratic regulator (LQR)
baselines on four controlled dynamical systems: a linear state-space system,
the Lorenz system, fluid flow past a cylinder, and a double-well potential with
non-isotropic stochastic forcing.",2024-03-04T18:19:48Z,http://arxiv.org/pdf/2403.02290v1,"['cs.AI', 'cs.LG', 'math.DS', 'math.OC']"
2407.08250v2,Gradient Boosting Reinforcement Learning,"['Benjamin Fuhrer', 'Chen Tessler', 'Gal Dalal']","We present Gradient Boosting Reinforcement Learning (GBRL), a framework that
adapts the strengths of gradient boosting trees (GBT) to reinforcement learning
(RL) tasks. While neural networks (NNs) have become the de facto choice for RL,
they face significant challenges with structured and categorical features and
tend to generalize poorly to out-of-distribution samples. These are challenges
for which GBTs have traditionally excelled in supervised learning. However,
GBT's application in RL has been limited. The design of traditional GBT
libraries is optimized for static datasets with fixed labels, making them
incompatible with RL's dynamic nature, where both state distributions and
reward signals evolve during training. GBRL overcomes this limitation by
continuously interleaving tree construction with environment interaction.
Through extensive experiments, we demonstrate that GBRL outperforms NNs in
domains with structured observations and categorical features while maintaining
competitive performance on standard continuous control benchmarks. Like its
supervised learning counterpart, GBRL demonstrates superior robustness to
out-of-distribution samples and better handles irregular state-action
relationships.",2024-07-11T07:52:33Z,http://arxiv.org/pdf/2407.08250v2,"['cs.LG', 'cs.AI']"
2502.04909v2,Benchmarking Quantum Reinforcement Learning,"['Georg Kruse', 'Rodrigo Coelho', 'Andreas Rosskopf', 'Robert Wille', 'Jeanette Miriam Lorenz']","Quantum Reinforcement Learning (QRL) has emerged as a promising research
field, leveraging the principles of quantum mechanics to enhance the
performance of reinforcement learning (RL) algorithms. However, despite its
growing interest, QRL still faces significant challenges. It is still uncertain
if QRL can show any advantage over classical RL beyond artificial problem
formulations. Additionally, it is not yet clear which streams of QRL research
show the greatest potential. The lack of a unified benchmark and the need to
evaluate the reliance on quantum principles of QRL approaches are pressing
questions. This work aims to address these challenges by providing a
comprehensive comparison of three major QRL classes: Parameterized Quantum
Circuit based QRL (PQC-QRL) (with one policy gradient (QPG) and one Q-Learning
(QDQN) algorithm), Free Energy based QRL (FE-QRL), and Amplitude Amplification
based QRL (AA-QRL). We introduce a set of metrics to evaluate the QRL
algorithms on the widely applicable benchmark of gridworld games. Our results
provide a detailed analysis of the strengths and weaknesses of the QRL classes,
shedding light on the role of quantum principles in QRL and paving the way for
future research in this field.",2025-02-07T13:28:20Z,http://arxiv.org/pdf/2502.04909v2,['quant-ph']
2509.19464v1,Evaluation-Aware Reinforcement Learning,"['Shripad Vilasrao Deshmukh', 'Will Schwarzer', 'Scott Niekum']","Policy evaluation is often a prerequisite for deploying safety- and
performance-critical systems. Existing evaluation approaches frequently suffer
from high variance due to limited data and long-horizon tasks, or high bias due
to unequal support or inaccurate environmental models. We posit that these
challenges arise, in part, from the standard reinforcement learning (RL)
paradigm of policy learning without explicit consideration of evaluation. As an
alternative, we propose evaluation-aware reinforcement learning (EvA-RL), in
which a policy is trained to maximize expected return while simultaneously
minimizing expected evaluation error under a given value prediction scheme --
in other words, being ""easy"" to evaluate. We formalize a framework for EvA-RL
and design an instantiation that enables accurate policy evaluation,
conditioned on a small number of rollouts in an assessment environment that can
be different than the deployment environment. However, our theoretical analysis
and empirical results show that there is often a tradeoff between evaluation
accuracy and policy performance when using a fixed value-prediction scheme
within EvA-RL. To mitigate this tradeoff, we extend our approach to co-learn an
assessment-conditioned state-value predictor alongside the policy. Empirical
results across diverse discrete and continuous action domains demonstrate that
EvA-RL can substantially reduce evaluation error while maintaining competitive
returns. This work lays the foundation for a broad new class of RL methods that
treat reliable evaluation as a first-class principle during training.",2025-09-23T18:17:21Z,http://arxiv.org/pdf/2509.19464v1,"['cs.AI', 'cs.LG']"
1805.01907v2,Exploration by Distributional Reinforcement Learning,"['Yunhao Tang', 'Shipra Agrawal']","We propose a framework based on distributional reinforcement learning and
recent attempts to combine Bayesian parameter updates with deep reinforcement
learning. We show that our proposed framework conceptually unifies multiple
previous methods in exploration. We also derive a practical algorithm that
achieves efficient exploration on challenging control tasks.",2018-05-04T18:07:21Z,http://arxiv.org/pdf/1805.01907v2,"['cs.LG', 'cs.AI', 'stat.ML']"
1806.06798v2,Implicit Policy for Reinforcement Learning,"['Yunhao Tang', 'Shipra Agrawal']","We introduce Implicit Policy, a general class of expressive policies that can
flexibly represent complex action distributions in reinforcement learning, with
efficient algorithms to compute entropy regularized policy gradients. We
empirically show that, despite its simplicity in implementation, entropy
regularization combined with a rich policy class can attain desirable
properties displayed under maximum entropy reinforcement learning framework,
such as robustness and multi-modality.",2018-06-10T08:24:36Z,http://arxiv.org/pdf/1806.06798v2,"['cs.LG', 'cs.AI', 'stat.ML']"
1906.10025v2,Modern Deep Reinforcement Learning Algorithms,"['Sergey Ivanov', ""Alexander D'yakonov""]","Recent advances in Reinforcement Learning, grounded on combining classical
theoretical results with Deep Learning paradigm, led to breakthroughs in many
artificial intelligence tasks and gave birth to Deep Reinforcement Learning
(DRL) as a field of research. In this work latest DRL algorithms are reviewed
with a focus on their theoretical justification, practical limitations and
observed empirical properties.",2019-06-24T15:27:51Z,http://arxiv.org/pdf/1906.10025v2,"['cs.LG', 'cs.AI', 'stat.ML']"
1710.08070v2,Accelerated Reinforcement Learning,['K. Lakshmanan'],"Policy gradient methods are widely used in reinforcement learning algorithms
to search for better policies in the parameterized policy space. They do
gradient search in the policy space and are known to converge very slowly.
Nesterov developed an accelerated gradient search algorithm for convex
optimization problems. This has been recently extended for non-convex and also
stochastic optimization. We use Nesterov's acceleration for policy gradient
search in the well-known actor-critic algorithm and show the convergence using
ODE method. We tested this algorithm on a scheduling problem. Here an incoming
job is scheduled into one of the four queues based on the queue lengths. We see
from experimental results that algorithm using Nesterov's acceleration has
significantly better performance compared to algorithm which do not use
acceleration. To the best of our knowledge this is the first time Nesterov's
acceleration has been used with actor-critic algorithm.",2017-10-23T02:45:31Z,http://arxiv.org/pdf/1710.08070v2,['cs.LG']
1803.03835v1,Kickstarting Deep Reinforcement Learning,"['Simon Schmitt', 'Jonathan J. Hudson', 'Augustin Zidek', 'Simon Osindero', 'Carl Doersch', 'Wojciech M. Czarnecki', 'Joel Z. Leibo', 'Heinrich Kuttler', 'Andrew Zisserman', 'Karen Simonyan', 'S. M. Ali Eslami']","We present a method for using previously-trained 'teacher' agents to
kickstart the training of a new 'student' agent. To this end, we leverage ideas
from policy distillation and population based training. Our method places no
constraints on the architecture of the teacher or student agents, and it
regulates itself to allow the students to surpass their teachers in
performance. We show that, on a challenging and computationally-intensive
multi-task benchmark (DMLab-30), kickstarted training improves the data
efficiency of new agents, making it significantly easier to iterate on their
design. We also show that the same kickstarting pipeline can allow a single
student agent to leverage multiple 'expert' teachers which specialize on
individual tasks. In this setting kickstarting yields surprisingly large gains,
with the kickstarted agent matching the performance of an agent trained from
scratch in almost 10x fewer steps, and surpassing its final performance by 42
percent. Kickstarting is conceptually simple and can easily be incorporated
into reinforcement learning experiments.",2018-03-10T16:45:00Z,http://arxiv.org/pdf/1803.03835v1,['cs.LG']
1810.09202v5,Graph Convolutional Reinforcement Learning,"['Jiechuan Jiang', 'Chen Dun', 'Tiejun Huang', 'Zongqing Lu']","Learning to cooperate is crucially important in multi-agent environments. The
key is to understand the mutual interplay between agents. However, multi-agent
environments are highly dynamic, where agents keep moving and their neighbors
change quickly. This makes it hard to learn abstract representations of mutual
interplay between agents. To tackle these difficulties, we propose graph
convolutional reinforcement learning, where graph convolution adapts to the
dynamics of the underlying graph of the multi-agent environment, and relation
kernels capture the interplay between agents by their relation representations.
Latent features produced by convolutional layers from gradually increased
receptive fields are exploited to learn cooperation, and cooperation is further
improved by temporal relation regularization for consistency. Empirically, we
show that our method substantially outperforms existing methods in a variety of
cooperative scenarios.",2018-10-22T12:17:40Z,http://arxiv.org/pdf/1810.09202v5,"['cs.LG', 'cs.AI', 'cs.MA', 'stat.ML']"
2004.08600v1,Time Adaptive Reinforcement Learning,['Chris Reinke'],"Reinforcement learning (RL) allows to solve complex tasks such as Go often
with a stronger performance than humans. However, the learned behaviors are
usually fixed to specific tasks and unable to adapt to different contexts. Here
we consider the case of adapting RL agents to different time restrictions, such
as finishing a task with a given time limit that might change from one task
execution to the next. We define such problems as Time Adaptive Markov Decision
Processes and introduce two model-free, value-based algorithms: the Independent
Gamma-Ensemble and the n-Step Ensemble. In difference to classical approaches,
they allow a zero-shot adaptation between different time restrictions. The
proposed approaches represent general mechanisms to handle time adaptive tasks
making them compatible with many existing RL methods, algorithms, and
scenarios.",2020-04-18T11:52:07Z,http://arxiv.org/pdf/2004.08600v1,"['cs.LG', 'cs.AI', 'stat.ML', 'I.2.6']"
2101.03958v6,Evolving Reinforcement Learning Algorithms,"['John D. Co-Reyes', 'Yingjie Miao', 'Daiyi Peng', 'Esteban Real', 'Sergey Levine', 'Quoc V. Le', 'Honglak Lee', 'Aleksandra Faust']","We propose a method for meta-learning reinforcement learning algorithms by
searching over the space of computational graphs which compute the loss
function for a value-based model-free RL agent to optimize. The learned
algorithms are domain-agnostic and can generalize to new environments not seen
during training. Our method can both learn from scratch and bootstrap off known
existing algorithms, like DQN, enabling interpretable modifications which
improve performance. Learning from scratch on simple classical control and
gridworld tasks, our method rediscovers the temporal-difference (TD) algorithm.
Bootstrapped from DQN, we highlight two learned algorithms which obtain good
generalization performance over other classical control tasks, gridworld type
tasks, and Atari games. The analysis of the learned algorithm behavior shows
resemblance to recently proposed RL algorithms that address overestimation in
value-based methods.",2021-01-08T18:55:07Z,http://arxiv.org/pdf/2101.03958v6,"['cs.LG', 'cs.AI', 'cs.NE']"
2202.07995v2,Branching Reinforcement Learning,"['Yihan Du', 'Wei Chen']","In this paper, we propose a novel Branching Reinforcement Learning (Branching
RL) model, and investigate both Regret Minimization (RM) and Reward-Free
Exploration (RFE) metrics for this model. Unlike standard RL where the
trajectory of each episode is a single $H$-step path, branching RL allows an
agent to take multiple base actions in a state such that transitions branch out
to multiple successor states correspondingly, and thus it generates a
tree-structured trajectory. This model finds important applications in
hierarchical recommendation systems and online advertising. For branching RL,
we establish new Bellman equations and key lemmas, i.e., branching value
difference lemma and branching law of total variance, and also bound the total
variance by only $O(H^2)$ under an exponentially-large trajectory. For RM and
RFE metrics, we propose computationally efficient algorithms BranchVI and
BranchRFE, respectively, and derive nearly matching upper and lower bounds. Our
results are only polynomial in problem parameters despite exponentially-large
trajectories.",2022-02-16T11:19:03Z,http://arxiv.org/pdf/2202.07995v2,['cs.LG']
2207.00461v1,Lifelong Inverse Reinforcement Learning,"['Jorge A. Mendez', 'Shashank Shivkumar', 'Eric Eaton']","Methods for learning from demonstration (LfD) have shown success in acquiring
behavior policies by imitating a user. However, even for a single task, LfD may
require numerous demonstrations. For versatile agents that must learn many
tasks via demonstration, this process would substantially burden the user if
each task were learned in isolation. To address this challenge, we introduce
the novel problem of lifelong learning from demonstration, which allows the
agent to continually build upon knowledge learned from previously demonstrated
tasks to accelerate the learning of new tasks, reducing the amount of
demonstrations required. As one solution to this problem, we propose the first
lifelong learning approach to inverse reinforcement learning, which learns
consecutive tasks via demonstration, continually transferring knowledge between
tasks to improve performance.",2022-07-01T14:36:02Z,http://arxiv.org/pdf/2207.00461v1,['cs.LG']
2010.03691v2,Regularized Inverse Reinforcement Learning,"['Wonseok Jeon', 'Chen-Yang Su', 'Paul Barde', 'Thang Doan', 'Derek Nowrouzezahrai', 'Joelle Pineau']","Inverse Reinforcement Learning (IRL) aims to facilitate a learner's ability
to imitate expert behavior by acquiring reward functions that explain the
expert's decisions. Regularized IRL applies strongly convex regularizers to the
learner's policy in order to avoid the expert's behavior being rationalized by
arbitrary constant rewards, also known as degenerate solutions. We propose
tractable solutions, and practical methods to obtain them, for regularized IRL.
Current methods are restricted to the maximum-entropy IRL framework, limiting
them to Shannon-entropy regularizers, as well as proposing the solutions that
are intractable in practice. We present theoretical backing for our proposed
IRL method's applicability for both discrete and continuous controls,
empirically validating our performance on a variety of tasks.",2020-10-07T23:38:47Z,http://arxiv.org/pdf/2010.03691v2,['cs.LG']
2011.09999v3,Inverse Constrained Reinforcement Learning,"['Usman Anwar', 'Shehryar Malik', 'Alireza Aghasi', 'Ali Ahmed']","In real world settings, numerous constraints are present which are hard to
specify mathematically. However, for the real world deployment of reinforcement
learning (RL), it is critical that RL agents are aware of these constraints, so
that they can act safely. In this work, we consider the problem of learning
constraints from demonstrations of a constraint-abiding agent's behavior. We
experimentally validate our approach and show that our framework can
successfully learn the most likely constraints that the agent respects. We
further show that these learned constraints are \textit{transferable} to new
agents that may have different morphologies and/or reward functions. Previous
works in this regard have either mainly been restricted to tabular (discrete)
settings, specific types of constraints or assume the environment's transition
dynamics. In contrast, our framework is able to learn arbitrary
\textit{Markovian} constraints in high-dimensions in a completely model-free
setting. The code can be found it:
\url{https://github.com/shehryar-malik/icrl}.",2020-11-19T17:56:33Z,http://arxiv.org/pdf/2011.09999v3,"['cs.LG', 'cs.RO', 'cs.SY', 'eess.SY']"
2305.15284v4,Replicable Reinforcement Learning,"['Eric Eaton', 'Marcel Hussing', 'Michael Kearns', 'Jessica Sorrell']","The replicability crisis in the social, behavioral, and data sciences has led
to the formulation of algorithm frameworks for replicability -- i.e., a
requirement that an algorithm produce identical outputs (with high probability)
when run on two different samples from the same underlying distribution. While
still in its infancy, provably replicable algorithms have been developed for
many fundamental tasks in machine learning and statistics, including
statistical query learning, the heavy hitters problem, and distribution
testing. In this work we initiate the study of replicable reinforcement
learning, providing a provably replicable algorithm for parallel value
iteration, and a provably replicable version of R-max in the episodic setting.
These are the first formal replicability results for control problems, which
present different challenges for replication than batch learning settings.",2023-05-24T16:05:15Z,http://arxiv.org/pdf/2305.15284v4,['cs.LG']
1806.01830v2,Relational Deep Reinforcement Learning,"['Vinicius Zambaldi', 'David Raposo', 'Adam Santoro', 'Victor Bapst', 'Yujia Li', 'Igor Babuschkin', 'Karl Tuyls', 'David Reichert', 'Timothy Lillicrap', 'Edward Lockhart', 'Murray Shanahan', 'Victoria Langston', 'Razvan Pascanu', 'Matthew Botvinick', 'Oriol Vinyals', 'Peter Battaglia']","We introduce an approach for deep reinforcement learning (RL) that improves
upon the efficiency, generalization capacity, and interpretability of
conventional approaches through structured perception and relational reasoning.
It uses self-attention to iteratively reason about the relations between
entities in a scene and to guide a model-free policy. Our results show that in
a novel navigation and planning task called Box-World, our agent finds
interpretable solutions that improve upon baselines in terms of sample
complexity, ability to generalize to more complex scenes than experienced
during training, and overall performance. In the StarCraft II Learning
Environment, our agent achieves state-of-the-art performance on six mini-games
-- surpassing human grandmaster performance on four. By considering
architectural inductive biases, our work opens new directions for overcoming
important, but stubborn, challenges in deep RL.",2018-06-05T17:39:12Z,http://arxiv.org/pdf/1806.01830v2,"['cs.LG', 'stat.ML']"
1906.02457v1,Clustered Reinforcement Learning,"['Xiao Ma', 'Shen-Yi Zhao', 'Wu-Jun Li']","Exploration strategy design is one of the challenging problems in
reinforcement learning~(RL), especially when the environment contains a large
state space or sparse rewards. During exploration, the agent tries to discover
novel areas or high reward~(quality) areas. In most existing methods, the
novelty and quality in the neighboring area of the current state are not well
utilized to guide the exploration of the agent. To tackle this problem, we
propose a novel RL framework, called \underline{c}lustered
\underline{r}einforcement \underline{l}earning~(CRL), for efficient exploration
in RL. CRL adopts clustering to divide the collected states into several
clusters, based on which a bonus reward reflecting both novelty and quality in
the neighboring area~(cluster) of the current state is given to the agent.
Experiments on a continuous control task and several \emph{Atari 2600} games
show that CRL can outperform other state-of-the-art methods to achieve the best
performance in most cases.",2019-06-06T07:35:02Z,http://arxiv.org/pdf/1906.02457v1,"['cs.LG', 'cs.AI', 'stat.ML']"
2007.14430v3,Munchausen Reinforcement Learning,"['Nino Vieillard', 'Olivier Pietquin', 'Matthieu Geist']","Bootstrapping is a core mechanism in Reinforcement Learning (RL). Most
algorithms, based on temporal differences, replace the true value of a
transiting state by their current estimate of this value. Yet, another estimate
could be leveraged to bootstrap RL: the current policy. Our core contribution
stands in a very simple idea: adding the scaled log-policy to the immediate
reward. We show that slightly modifying Deep Q-Network (DQN) in that way
provides an agent that is competitive with distributional methods on Atari
games, without making use of distributional RL, n-step returns or prioritized
replay. To demonstrate the versatility of this idea, we also use it together
with an Implicit Quantile Network (IQN). The resulting agent outperforms
Rainbow on Atari, installing a new State of the Art with very little
modifications to the original algorithm. To add to this empirical study, we
provide strong theoretical insights on what happens under the hood -- implicit
Kullback-Leibler regularization and increase of the action-gap.",2020-07-28T18:30:23Z,http://arxiv.org/pdf/2007.14430v3,"['cs.LG', 'stat.ML']"
2112.03636v1,Godot Reinforcement Learning Agents,"['Edward Beeching', 'Jilles Debangoye', 'Olivier Simonin', 'Christian Wolf']","We present Godot Reinforcement Learning (RL) Agents, an open-source interface
for developing environments and agents in the Godot Game Engine. The Godot RL
Agents interface allows the design, creation and learning of agent behaviors in
challenging 2D and 3D environments with various on-policy and off-policy Deep
RL algorithms. We provide a standard Gym interface, with wrappers for learning
in the Ray RLlib and Stable Baselines RL frameworks. This allows users access
to over 20 state of the art on-policy, off-policy and multi-agent RL
algorithms. The framework is a versatile tool that allows researchers and game
designers the ability to create environments with discrete, continuous and
mixed action spaces. The interface is relatively performant, with 12k
interactions per second on a high end laptop computer, when parallized on 4 CPU
cores. An overview video is available here: https://youtu.be/g1MlZSFqIj4",2021-12-07T11:24:34Z,http://arxiv.org/pdf/2112.03636v1,['cs.LG']
2205.07467v1,$q$-Munchausen Reinforcement Learning,"['Lingwei Zhu', 'Zheng Chen', 'Eiji Uchibe', 'Takamitsu Matsubara']","The recently successful Munchausen Reinforcement Learning (M-RL) features
implicit Kullback-Leibler (KL) regularization by augmenting the reward function
with logarithm of the current stochastic policy. Though significant improvement
has been shown with the Boltzmann softmax policy, when the Tsallis sparsemax
policy is considered, the augmentation leads to a flat learning curve for
almost every problem considered. We show that it is due to the mismatch between
the conventional logarithm and the non-logarithmic (generalized) nature of
Tsallis entropy. Drawing inspiration from the Tsallis statistics literature, we
propose to correct the mismatch of M-RL with the help of
$q$-logarithm/exponential functions. The proposed formulation leads to implicit
Tsallis KL regularization under the maximum Tsallis entropy framework. We show
such formulation of M-RL again achieves superior performance on benchmark
problems and sheds light on more general M-RL with various entropic indices
$q$.",2022-05-16T06:26:10Z,http://arxiv.org/pdf/2205.07467v1,"['cs.LG', 'cs.AI']"
2208.09322v2,Entropy Augmented Reinforcement Learning,['Jianfei Ma'],"Deep reinforcement learning was instigated with the presence of trust region
methods, being scalable and efficient. However, the pessimism of such
algorithms, among which it forces to constrain in a trust region by all means,
has been proven to suppress the exploration and harm the performance.
Exploratory algorithm such as SAC, while utilizes the entropy to encourage
exploration, implicitly optimizing another objective yet. We first observed
this inconsistency, and therefore put forward an analogous augmentation
technique, which combines well with the on-policy algorithms, when a value
critic is involved. Surprisingly, the proposed method consistently satisfies
the soft policy improvement theorem, while being more extensible. As the
analysis advises, it is crucial to control the temperature coefficient to
balance the exploration and exploitation. Empirical tests on MuJoCo benchmark
tasks show that the agent is heartened towards higher reward regions, and
enjoys a finer performance. Furthermore, we verify the exploration bonus of our
method on a set of custom environments.",2022-08-19T13:09:32Z,http://arxiv.org/pdf/2208.09322v2,['cs.LG']
2308.15911v1,Cyclophobic Reinforcement Learning,"['Stefan Sylvius Wagner', 'Peter Arndt', 'Jan Robine', 'Stefan Harmeling']","In environments with sparse rewards, finding a good inductive bias for
exploration is crucial to the agent's success. However, there are two competing
goals: novelty search and systematic exploration. While existing approaches
such as curiosity-driven exploration find novelty, they sometimes do not
systematically explore the whole state space, akin to depth-first-search vs
breadth-first-search. In this paper, we propose a new intrinsic reward that is
cyclophobic, i.e., it does not reward novelty, but punishes redundancy by
avoiding cycles. Augmenting the cyclophobic intrinsic reward with a sequence of
hierarchical representations based on the agent's cropped observations we are
able to achieve excellent results in the MiniGrid and MiniHack environments.
Both are particularly hard, as they require complex interactions with different
objects in order to be solved. Detailed comparisons with previous approaches
and thorough ablation studies show that our newly proposed cyclophobic
reinforcement learning is more sample efficient than other state of the art
methods in a variety of tasks.",2023-08-30T09:38:44Z,http://arxiv.org/pdf/2308.15911v1,"['cs.LG', 'cs.AI', 'cs.RO']"
2405.20772v1,Reinforcement Learning for Sociohydrology,"['Tirthankar Roy', 'Shivendra Srivastava', 'Beichen Zhang']","In this study, we discuss how reinforcement learning (RL) provides an
effective and efficient framework for solving sociohydrology problems. The
efficacy of RL for these types of problems is evident because of its ability to
update policies in an iterative manner - something that is also foundational to
sociohydrology, where we are interested in representing the co-evolution of
human-water interactions. We present a simple case study to demonstrate the
implementation of RL in a problem of runoff reduction through management
decisions related to changes in land-use land-cover (LULC). We then discuss the
benefits of RL for these types of problems and share our perspectives on the
future research directions in this area.",2024-05-31T13:28:37Z,http://arxiv.org/pdf/2405.20772v1,"['cs.LG', 'cs.CY']"
2406.13961v1,Equivariant Offline Reinforcement Learning,"['Arsh Tangri', 'Ondrej Biza', 'Dian Wang', 'David Klee', 'Owen Howell', 'Robert Platt']","Sample efficiency is critical when applying learning-based methods to robotic
manipulation due to the high cost of collecting expert demonstrations and the
challenges of on-robot policy learning through online Reinforcement Learning
(RL). Offline RL addresses this issue by enabling policy learning from an
offline dataset collected using any behavioral policy, regardless of its
quality. However, recent advancements in offline RL have predominantly focused
on learning from large datasets. Given that many robotic manipulation tasks can
be formulated as rotation-symmetric problems, we investigate the use of
$SO(2)$-equivariant neural networks for offline RL with a limited number of
demonstrations. Our experimental results show that equivariant versions of
Conservative Q-Learning (CQL) and Implicit Q-Learning (IQL) outperform their
non-equivariant counterparts. We provide empirical evidence demonstrating how
equivariance improves offline learning algorithms in the low-data regime.",2024-06-20T03:02:49Z,http://arxiv.org/pdf/2406.13961v1,"['cs.LG', 'cs.RO']"
2408.07712v3,Introduction to Reinforcement Learning,"['Majid Ghasemi', 'Dariush Ebrahimi']","Reinforcement Learning (RL), a subfield of Artificial Intelligence (AI),
focuses on training agents to make decisions by interacting with their
environment to maximize cumulative rewards. This paper provides an overview of
RL, covering its core concepts, methodologies, and resources for further
learning. It offers a thorough explanation of fundamental components such as
states, actions, policies, and reward signals, ensuring readers develop a solid
foundational understanding. Additionally, the paper presents a variety of RL
algorithms, categorized based on the key factors such as model-free,
model-based, value-based, policy-based, and other key factors. Resources for
learning and implementing RL, such as books, courses, and online communities
are also provided. By offering a clear, structured introduction, this paper
aims to simplify the complexities of RL for beginners, providing a
straightforward pathway to understanding.",2024-08-13T23:08:06Z,http://arxiv.org/pdf/2408.07712v3,"['cs.AI', 'cs.LG']"
2408.15076v1,MiWaves Reinforcement Learning Algorithm,"['Susobhan Ghosh', 'Yongyi Guo', 'Pei-Yao Hung', 'Lara Coughlin', 'Erin Bonar', 'Inbal Nahum-Shani', 'Maureen Walton', 'Susan Murphy']","The escalating prevalence of cannabis use poses a significant public health
challenge globally. In the U.S., cannabis use is more prevalent among emerging
adults (EAs) (ages 18-25) than any other age group, with legalization in the
multiple states contributing to a public perception that cannabis is less risky
than in prior decades. To address this growing concern, we developed MiWaves, a
reinforcement learning (RL) algorithm designed to optimize the delivery of
personalized intervention prompts to reduce cannabis use among EAs. MiWaves
leverages domain expertise and prior data to tailor the likelihood of delivery
of intervention messages. This paper presents a comprehensive overview of the
algorithm's design, including key decisions and experimental outcomes. The
finalized MiWaves RL algorithm was deployed in a clinical trial from March to
May 2024.",2024-08-27T14:04:04Z,http://arxiv.org/pdf/2408.15076v1,"['cs.LG', 'cs.AI']"
2006.12478v1,Ecological Reinforcement Learning,"['John D. Co-Reyes', 'Suvansh Sanjeev', 'Glen Berseth', 'Abhishek Gupta', 'Sergey Levine']","Much of the current work on reinforcement learning studies episodic settings,
where the agent is reset between trials to an initial state distribution, often
with well-shaped reward functions. Non-episodic settings, where the agent must
learn through continuous interaction with the world without resets, and where
the agent receives only delayed and sparse reward signals, is substantially
more difficult, but arguably more realistic considering real-world environments
do not present the learner with a convenient ""reset mechanism"" and easy reward
shaping. In this paper, instead of studying algorithmic improvements that can
address such non-episodic and sparse reward settings, we instead study the
kinds of environment properties that can make learning under such conditions
easier. Understanding how properties of the environment impact the performance
of reinforcement learning agents can help us to structure our tasks in ways
that make learning tractable. We first discuss what we term ""environment
shaping"" -- modifications to the environment that provide an alternative to
reward shaping, and may be easier to implement. We then discuss an even simpler
property that we refer to as ""dynamism,"" which describes the degree to which
the environment changes independent of the agent's actions and can be measured
by environment transition entropy. Surprisingly, we find that even this
property can substantially alleviate the challenges associated with
non-episodic RL in sparse reward settings. We provide an empirical evaluation
on a set of new tasks focused on non-episodic learning with sparse rewards.
Through this study, we hope to shift the focus of the community towards
analyzing how properties of the environment can affect learning and the
ultimate type of behavior that is learned via RL.",2020-06-22T17:55:03Z,http://arxiv.org/pdf/2006.12478v1,"['cs.LG', 'cs.AI', 'stat.ML']"
1106.0221v1,Evolutionary Algorithms for Reinforcement Learning,"['J. J. Grefenstette', 'D. E. Moriarty', 'A. C. Schultz']","There are two distinct approaches to solving reinforcement learning problems,
namely, searching in value function space and searching in policy space.
Temporal difference methods and evolutionary algorithms are well-known examples
of these approaches. Kaelbling, Littman and Moore recently provided an
informative survey of temporal difference methods. This article focuses on the
application of evolutionary algorithms to the reinforcement learning problem,
emphasizing alternative policy representations, credit assignment methods, and
problem-specific genetic operators. Strengths and weaknesses of the
evolutionary approach to reinforcement learning are presented, along with a
survey of representative applications.",2011-06-01T16:16:14Z,http://arxiv.org/pdf/1106.0221v1,"['cs.LG', 'cs.AI', 'cs.NE']"
1806.08894v1,Deep Reinforcement Learning: An Overview,"['Seyed Sajad Mousavi', 'Michael Schukat', 'Enda Howley']","In recent years, a specific machine learning method called deep learning has
gained huge attraction, as it has obtained astonishing results in broad
applications such as pattern recognition, speech recognition, computer vision,
and natural language processing. Recent research has also been shown that deep
learning techniques can be combined with reinforcement learning methods to
learn useful representations for the problems with high dimensional raw data
input. This chapter reviews the recent advances in deep reinforcement learning
with a focus on the most used deep architectures such as autoencoders,
convolutional neural networks and recurrent neural networks which have
successfully been come together with the reinforcement learning framework.",2018-06-23T02:18:26Z,http://arxiv.org/pdf/1806.08894v1,"['cs.LG', 'cs.AI', 'stat.ML']"
0703138v1,Reinforcement Learning for Adaptive Routing,"['Leonid Peshkin', 'Virginia Savova']","Reinforcement learning means learning a policy--a mapping of observations
into actions--based on feedback from the environment. The learning can be
viewed as browsing a set of policies while evaluating them by trial through
interaction with the environment. We present an application of gradient ascent
algorithm for reinforcement learning to a complex domain of packet routing in
network communication and compare the performance of this algorithm to other
routing methods on a benchmark problem.",2007-03-28T04:41:54Z,http://arxiv.org/pdf/cs/0703138v1,"['cs.LG', 'cs.AI', 'cs.NI', 'C.2.1; C.2.2; C.2.4; C.2.6; F.1.1; I.2.6; I.2.8; I.2.9']"
1811.10732v2,Environments for Lifelong Reinforcement Learning,"['Khimya Khetarpal', 'Shagun Sodhani', 'Sarath Chandar', 'Doina Precup']","To achieve general artificial intelligence, reinforcement learning (RL)
agents should learn not only to optimize returns for one specific task but also
to constantly build more complex skills and scaffold their knowledge about the
world, without forgetting what has already been learned. In this paper, we
discuss the desired characteristics of environments that can support the
training and evaluation of lifelong reinforcement learning agents, review
existing environments from this perspective, and propose recommendations for
devising suitable environments in the future.",2018-11-26T23:01:49Z,http://arxiv.org/pdf/1811.10732v2,"['cs.AI', 'cs.LG']"
2111.08009v1,Piano Fingering with Reinforcement Learning,"['Pedro Ramoneda', 'Marius Miron', 'Xavier Serra']","Hand and finger movements are a mainstay of piano technique. Automatic
Fingering from symbolic music data allows us to simulate finger and hand
movements. Previous proposals achieve automatic piano fingering based on
knowledge-driven or data-driven techniques. We combine both approaches with
deep reinforcement learning techniques to derive piano fingering. Finally, we
explore how to incorporate past experience into reinforcement learning-based
piano fingering in further work.",2021-11-15T09:51:29Z,http://arxiv.org/pdf/2111.08009v1,['cs.OH']
2410.03706v1,Topological Foundations of Reinforcement Learning,['David Krame Kadurha'],"The goal of this work is to serve as a foundation for deep studies of the
topology of state, action, and policy spaces in reinforcement learning. By
studying these spaces from a mathematical perspective, we expect to gain more
insight into how to build better algorithms to solve decision problems.
Therefore, we focus on presenting the connection between the Banach fixed point
theorem and the convergence of reinforcement learning algorithms, and we
illustrate how the insights gained from this can practically help in designing
more efficient algorithms. Before doing so, however, we first introduce
relevant concepts such as metric spaces, normed spaces and Banach spaces for
better understanding, before expressing the entire reinforcement learning
problem in terms of Markov decision processes. This allows us to properly
introduce the Banach contraction principle in a language suitable for
reinforcement learning, and to write the Bellman equations in terms of
operators on Banach spaces to show why reinforcement learning algorithms
converge. Finally, we show how the insights gained from the mathematical study
of convergence are helpful in reasoning about the best ways to make
reinforcement learning algorithms more efficient.",2024-09-25T21:21:23Z,http://arxiv.org/pdf/2410.03706v1,"['cs.LG', 'cs.AI', 'math.FA', '68T05']"
1311.2097v3,Risk-sensitive Reinforcement Learning,"['Yun Shen', 'Michael J. Tobia', 'Tobias Sommer', 'Klaus Obermayer']","We derive a family of risk-sensitive reinforcement learning methods for
agents, who face sequential decision-making tasks in uncertain environments. By
applying a utility function to the temporal difference (TD) error, nonlinear
transformations are effectively applied not only to the received rewards but
also to the true transition probabilities of the underlying Markov decision
process. When appropriate utility functions are chosen, the agents' behaviors
express key features of human behavior as predicted by prospect theory
(Kahneman and Tversky, 1979), for example different risk-preferences for gains
and losses as well as the shape of subjective probability curves. We derive a
risk-sensitive Q-learning algorithm, which is necessary for modeling human
behavior when transition probabilities are unknown, and prove its convergence.
As a proof of principle for the applicability of the new framework we apply it
to quantify human behavior in a sequential investment task. We find, that the
risk-sensitive variant provides a significantly better fit to the behavioral
data and that it leads to an interpretation of the subject's responses which is
indeed consistent with prospect theory. The analysis of simultaneously measured
fMRI signals show a significant correlation of the risk-sensitive TD error with
BOLD signal change in the ventral striatum. In addition we find a significant
correlation of the risk-sensitive Q-values with neural activity in the
striatum, cingulate cortex and insula, which is not present if standard
Q-values are used.",2013-11-08T22:25:26Z,http://arxiv.org/pdf/1311.2097v3,['cs.LG']
1606.03137v4,Cooperative Inverse Reinforcement Learning,"['Dylan Hadfield-Menell', 'Anca Dragan', 'Pieter Abbeel', 'Stuart Russell']","For an autonomous system to be helpful to humans and to pose no unwarranted
risks, it needs to align its values with those of the humans in its environment
in such a way that its actions contribute to the maximization of value for the
humans. We propose a formal definition of the value alignment problem as
cooperative inverse reinforcement learning (CIRL). A CIRL problem is a
cooperative, partial-information game with two agents, human and robot; both
are rewarded according to the human's reward function, but the robot does not
initially know what this is. In contrast to classical IRL, where the human is
assumed to act optimally in isolation, optimal CIRL solutions produce behaviors
such as active teaching, active learning, and communicative actions that are
more effective in achieving value alignment. We show that computing optimal
joint policies in CIRL games can be reduced to solving a POMDP, prove that
optimality in isolation is suboptimal in CIRL, and derive an approximate CIRL
algorithm.",2016-06-09T22:39:54Z,http://arxiv.org/pdf/1606.03137v4,['cs.AI']
1805.11447v1,Virtuously Safe Reinforcement Learning,"['Henrik Aslund', 'El Mahdi El Mhamdi', 'Rachid Guerraoui', 'Alexandre Maurer']","We show that when a third party, the adversary, steps into the two-party
setting (agent and operator) of safely interruptible reinforcement learning, a
trade-off has to be made between the probability of following the optimal
policy in the limit, and the probability of escaping a dangerous situation
created by the adversary. So far, the work on safely interruptible agents has
assumed a perfect perception of the agent about its environment (no adversary),
and therefore implicitly set the second probability to zero, by explicitly
seeking a value of one for the first probability. We show that (1) agents can
be made both interruptible and adversary-resilient, and (2) the
interruptibility can be made safe in the sense that the agent itself will not
seek to avoid it. We also solve the problem that arises when the agent does not
go completely greedy, i.e. issues with safe exploration in the limit.
Resilience to perturbed perception, safe exploration in the limit, and safe
interruptibility are the three pillars of what we call \emph{virtuously safe
reinforcement learning}.",2018-05-29T13:34:39Z,http://arxiv.org/pdf/1805.11447v1,"['cs.LG', 'cs.AI', 'cs.GT', 'stat.ML']"
2104.00540v1,Reinforcement Learning Beyond Expectation,"['Bhaskar Ramasubramanian', 'Luyao Niu', 'Andrew Clark', 'Radha Poovendran']","The inputs and preferences of human users are important considerations in
situations where these users interact with autonomous cyber or cyber-physical
systems. In these scenarios, one is often interested in aligning behaviors of
the system with the preferences of one or more human users. Cumulative prospect
theory (CPT) is a paradigm that has been empirically shown to model a tendency
of humans to view gains and losses differently. In this paper, we consider a
setting where an autonomous agent has to learn behaviors in an unknown
environment. In traditional reinforcement learning, these behaviors are learned
through repeated interactions with the environment by optimizing an expected
utility. In order to endow the agent with the ability to closely mimic the
behavior of human users, we optimize a CPT-based cost. We introduce the notion
of the CPT-value of an action taken in a state, and establish the convergence
of an iterative dynamic programming-based approach to estimate this quantity.
We develop two algorithms to enable agents to learn policies to optimize the
CPT-vale, and evaluate these algorithms in environments where a target state
has to be reached while avoiding obstacles. We demonstrate that behaviors of
the agent learned using these algorithms are better aligned with that of a
human user who might be placed in the same environment, and is significantly
improved over a baseline that optimizes an expected utility.",2021-03-29T20:35:25Z,http://arxiv.org/pdf/2104.00540v1,"['cs.LG', 'cs.AI', 'cs.SY', 'eess.SY', 'math.OC']"
1701.08810v3,Reinforcement Learning Algorithm Selection,"['Romain Laroche', 'Raphael Feraud']","This paper formalises the problem of online algorithm selection in the
context of Reinforcement Learning. The setup is as follows: given an episodic
task and a finite number of off-policy RL algorithms, a meta-algorithm has to
decide which RL algorithm is in control during the next episode so as to
maximize the expected return. The article presents a novel meta-algorithm,
called Epochal Stochastic Bandit Algorithm Selection (ESBAS). Its principle is
to freeze the policy updates at each epoch, and to leave a rebooted stochastic
bandit in charge of the algorithm selection. Under some assumptions, a thorough
theoretical analysis demonstrates its near-optimality considering the
structural sampling budget limitations. ESBAS is first empirically evaluated on
a dialogue task where it is shown to outperform each individual algorithm in
most configurations. ESBAS is then adapted to a true online setting where
algorithms update their policies after each transition, which we call SSBAS.
SSBAS is evaluated on a fruit collection task where it is shown to adapt the
stepsize parameter more efficiently than the classical hyperbolic decay, and on
an Atari game, where it improves the performance by a wide margin.",2017-01-30T20:13:17Z,http://arxiv.org/pdf/1701.08810v3,"['stat.ML', 'cs.AI', 'cs.LG', 'math.OC']"
1907.06725v3,Mutual Reinforcement Learning,"['Sayanti Roy', 'Emily Kieson', 'Charles Abramson', 'Christopher Crick']","Recently, collaborative robots have begun to train humans to achieve complex
tasks, and the mutual information exchange between them can lead to successful
robot-human collaborations. In this paper we demonstrate the application and
effectiveness of a new approach called mutual reinforcement learning (MRL),
where both humans and autonomous agents act as reinforcement learners in a
skill transfer scenario over continuous communication and feedback. An
autonomous agent initially acts as an instructor who can teach a novice human
participant complex skills using the MRL strategy. While teaching skills in a
physical (block-building) ($n=34$) or simulated (Tetris) environment ($n=31$),
the expert tries to identify appropriate reward channels preferred by each
individual and adapts itself accordingly using an exploration-exploitation
strategy. These reward channel preferences can identify important behaviors of
the human participants, because they may well exercise the same behaviors in
similar situations later. In this way, skill transfer takes place between an
expert system and a novice human operator. We divided the subject population
into three groups and observed the skill transfer phenomenon, analyzing it with
Simpson""s psychometric model. 5-point Likert scales were also used to identify
the cognitive models of the human participants. We obtained a shared cognitive
model which not only improves human cognition but enhances the robot's
cognitive strategy to understand the mental model of its human partners while
building a successful robot-human collaborative framework.",2019-07-15T20:10:29Z,http://arxiv.org/pdf/1907.06725v3,"['cs.RO', 'cs.HC', 'cs.LG']"
1911.04448v4,Real-Time Reinforcement Learning,"['Simon Ramstedt', 'Christopher Pal']","Markov Decision Processes (MDPs), the mathematical framework underlying most
algorithms in Reinforcement Learning (RL), are often used in a way that
wrongfully assumes that the state of an agent's environment does not change
during action selection. As RL systems based on MDPs begin to find application
in real-world safety critical situations, this mismatch between the assumptions
underlying classical MDPs and the reality of real-time computation may lead to
undesirable outcomes. In this paper, we introduce a new framework, in which
states and actions evolve simultaneously and show how it is related to the
classical MDP formulation. We analyze existing algorithms under the new
real-time formulation and show why they are suboptimal when used in real-time.
We then use those insights to create a new algorithm Real-Time Actor-Critic
(RTAC) that outperforms the existing state-of-the-art continuous control
algorithm Soft Actor-Critic both in real-time and non-real-time settings. Code
and videos can be found at https://github.com/rmst/rtrl.",2019-11-11T18:52:04Z,http://arxiv.org/pdf/1911.04448v4,"['cs.LG', 'stat.ML']"
2011.04018v4,Online Sparse Reinforcement Learning,"['Botao Hao', 'Tor Lattimore', 'Csaba Szepesvári', 'Mengdi Wang']","We investigate the hardness of online reinforcement learning in fixed
horizon, sparse linear Markov decision process (MDP), with a special focus on
the high-dimensional regime where the ambient dimension is larger than the
number of episodes. Our contribution is two-fold. First, we provide a lower
bound showing that linear regret is generally unavoidable in this case, even if
there exists a policy that collects well-conditioned data. The lower bound
construction uses an MDP with a fixed number of states while the number of
actions scales with the ambient dimension. Note that when the horizon is fixed
to one, the case of linear stochastic bandits, the linear regret can be
avoided. Second, we show that if the learner has oracle access to a policy that
collects well-conditioned data then a variant of Lasso fitted Q-iteration
enjoys a nearly dimension-free regret of $\tilde{O}( s^{2/3} N^{2/3})$ where
$N$ is the number of episodes and $s$ is the sparsity level. This shows that in
the large-action setting, the difficulty of learning can be attributed to the
difficulty of finding a good exploratory policy.",2020-11-08T16:47:42Z,http://arxiv.org/pdf/2011.04018v4,"['cs.LG', 'math.ST', 'stat.ML', 'stat.TH']"
2209.09344v1,Understanding reinforcement learned crowds,"['Ariel Kwiatkowski', 'Vicky Kalogeiton', 'Julien Pettré', 'Marie-Paule Cani']","Simulating trajectories of virtual crowds is a commonly encountered task in
Computer Graphics. Several recent works have applied Reinforcement Learning
methods to animate virtual agents, however they often make different design
choices when it comes to the fundamental simulation setup. Each of these
choices comes with a reasonable justification for its use, so it is not obvious
what is their real impact, and how they affect the results. In this work, we
analyze some of these arbitrary choices in terms of their impact on the
learning performance, as well as the quality of the resulting simulation
measured in terms of the energy efficiency. We perform a theoretical analysis
of the properties of the reward function design, and empirically evaluate the
impact of using certain observation and action spaces on a variety of
scenarios, with the reward function and energy usage as metrics. We show that
directly using the neighboring agents' information as observation generally
outperforms the more widely used raycasting. Similarly, using nonholonomic
controls with egocentric observations tends to produce more efficient behaviors
than holonomic controls with absolute observations. Each of these choices has a
significant, and potentially nontrivial impact on the results, and so
researchers should be mindful about choosing and reporting them in their work.",2022-09-19T20:47:49Z,http://arxiv.org/pdf/2209.09344v1,"['cs.LG', 'cs.AI', 'cs.GR', '68Q32', 'I.2.6; I.3.8']"
1806.09605v1,Many-Goals Reinforcement Learning,"['Vivek Veeriah', 'Junhyuk Oh', 'Satinder Singh']","All-goals updating exploits the off-policy nature of Q-learning to update all
possible goals an agent could have from each transition in the world, and was
introduced into Reinforcement Learning (RL) by Kaelbling (1993). In prior work
this was mostly explored in small-state RL problems that allowed tabular
representations and where all possible goals could be explicitly enumerated and
learned separately. In this paper we empirically explore 3 different extensions
of the idea of updating many (instead of all) goals in the context of RL with
deep neural networks (or DeepRL for short). First, in a direct adaptation of
Kaelbling's approach we explore if many-goals updating can be used to achieve
mastery in non-tabular visual-observation domains. Second, we explore whether
many-goals updating can be used to pre-train a network to subsequently learn
faster and better on a single main task of interest. Third, we explore whether
many-goals updating can be used to provide auxiliary task updates in training a
network to learn faster and better on a single main task of interest. We
provide comparisons to baselines for each of the 3 extensions.",2018-06-22T18:31:24Z,http://arxiv.org/pdf/1806.09605v1,"['cs.LG', 'cs.AI', 'stat.ML']"
2007.06159v2,Implicit Distributional Reinforcement Learning,"['Yuguang Yue', 'Zhendong Wang', 'Mingyuan Zhou']","To improve the sample efficiency of policy-gradient based reinforcement
learning algorithms, we propose implicit distributional actor-critic (IDAC)
that consists of a distributional critic, built on two deep generator networks
(DGNs), and a semi-implicit actor (SIA), powered by a flexible policy
distribution. We adopt a distributional perspective on the discounted
cumulative return and model it with a state-action-dependent implicit
distribution, which is approximated by the DGNs that take state-action pairs
and random noises as their input. Moreover, we use the SIA to provide a
semi-implicit policy distribution, which mixes the policy parameters with a
reparameterizable distribution that is not constrained by an analytic density
function. In this way, the policy's marginal distribution is implicit,
providing the potential to model complex properties such as covariance
structure and skewness, but its parameter and entropy can still be estimated.
We incorporate these features with an off-policy algorithm framework to solve
problems with continuous action space and compare IDAC with state-of-the-art
algorithms on representative OpenAI Gym environments. We observe that IDAC
outperforms these baselines in most tasks. Python code is provided.",2020-07-13T02:52:18Z,http://arxiv.org/pdf/2007.06159v2,"['cs.LG', 'stat.ML']"
2007.08794v3,Discovering Reinforcement Learning Algorithms,"['Junhyuk Oh', 'Matteo Hessel', 'Wojciech M. Czarnecki', 'Zhongwen Xu', 'Hado van Hasselt', 'Satinder Singh', 'David Silver']","Reinforcement learning (RL) algorithms update an agent's parameters according
to one of several possible rules, discovered manually through years of
research. Automating the discovery of update rules from data could lead to more
efficient algorithms, or algorithms that are better adapted to specific
environments. Although there have been prior attempts at addressing this
significant scientific challenge, it remains an open question whether it is
feasible to discover alternatives to fundamental concepts of RL such as value
functions and temporal-difference learning. This paper introduces a new
meta-learning approach that discovers an entire update rule which includes both
'what to predict' (e.g. value functions) and 'how to learn from it' (e.g.
bootstrapping) by interacting with a set of environments. The output of this
method is an RL algorithm that we call Learned Policy Gradient (LPG). Empirical
results show that our method discovers its own alternative to the concept of
value functions. Furthermore it discovers a bootstrapping mechanism to maintain
and use its predictions. Surprisingly, when trained solely on toy environments,
LPG generalises effectively to complex Atari games and achieves non-trivial
performance. This shows the potential to discover general RL algorithms from
data.",2020-07-17T07:38:39Z,http://arxiv.org/pdf/2007.08794v3,"['cs.LG', 'cs.AI']"
2106.02757v2,Heuristic-Guided Reinforcement Learning,"['Ching-An Cheng', 'Andrey Kolobov', 'Adith Swaminathan']","We provide a framework for accelerating reinforcement learning (RL)
algorithms by heuristics constructed from domain knowledge or offline data.
Tabula rasa RL algorithms require environment interactions or computation that
scales with the horizon of the sequential decision-making task. Using our
framework, we show how heuristic-guided RL induces a much shorter-horizon
subproblem that provably solves the original task. Our framework can be viewed
as a horizon-based regularization for controlling bias and variance in RL under
a finite interaction budget. On the theoretical side, we characterize
properties of a good heuristic and its impact on RL acceleration. In
particular, we introduce the novel concept of an improvable heuristic, a
heuristic that allows an RL agent to extrapolate beyond its prior knowledge. On
the empirical side, we instantiate our framework to accelerate several
state-of-the-art algorithms in simulated robotic control tasks and procedurally
generated games. Our framework complements the rich literature on warm-starting
RL with expert demonstrations or exploratory datasets, and introduces a
principled method for injecting prior knowledge into RL.",2021-06-05T00:04:09Z,http://arxiv.org/pdf/2106.02757v2,"['cs.LG', 'cs.AI']"
2106.12764v1,Density Constrained Reinforcement Learning,"['Zengyi Qin', 'Yuxiao Chen', 'Chuchu Fan']","We study constrained reinforcement learning (CRL) from a novel perspective by
setting constraints directly on state density functions, rather than the value
functions considered by previous works. State density has a clear physical and
mathematical interpretation, and is able to express a wide variety of
constraints such as resource limits and safety requirements. Density
constraints can also avoid the time-consuming process of designing and tuning
cost functions required by value function-based constraints to encode system
specifications. We leverage the duality between density functions and Q
functions to develop an effective algorithm to solve the density constrained RL
problem optimally and the constrains are guaranteed to be satisfied. We prove
that the proposed algorithm converges to a near-optimal solution with a bounded
error even when the policy update is imperfect. We use a set of comprehensive
experiments to demonstrate the advantages of our approach over state-of-the-art
CRL methods, with a wide range of density constrained tasks as well as standard
CRL benchmarks such as Safety-Gym.",2021-06-24T04:22:03Z,http://arxiv.org/pdf/2106.12764v1,"['cs.LG', 'cs.SY', 'eess.SY']"
2205.07536v2,Reachability Constrained Reinforcement Learning,"['Dongjie Yu', 'Haitong Ma', 'Shengbo Eben Li', 'Jianyu Chen']","Constrained reinforcement learning (CRL) has gained significant interest
recently, since safety constraints satisfaction is critical for real-world
problems. However, existing CRL methods constraining discounted cumulative
costs generally lack rigorous definition and guarantee of safety. In contrast,
in the safe control research, safety is defined as persistently satisfying
certain state constraints. Such persistent safety is possible only on a subset
of the state space, called feasible set, where an optimal largest feasible set
exists for a given environment. Recent studies incorporate feasible sets into
CRL with energy-based methods such as control barrier function (CBF), safety
index (SI), and leverage prior conservative estimations of feasible sets, which
harms the performance of the learned policy. To deal with this problem, this
paper proposes the reachability CRL (RCRL) method by using reachability
analysis to establish the novel self-consistency condition and characterize the
feasible sets. The feasible sets are represented by the safety value function,
which is used as the constraint in CRL. We use the multi-time scale stochastic
approximation theory to prove that the proposed algorithm converges to a local
optimum, where the largest feasible set can be guaranteed. Empirical results on
different benchmarks validate the learned feasible set, the policy performance,
and constraint satisfaction of RCRL, compared to CRL and safe control
baselines.",2022-05-16T09:32:45Z,http://arxiv.org/pdf/2205.07536v2,"['cs.LG', 'cs.AI', 'cs.RO']"
2206.05581v3,Federated Offline Reinforcement Learning,"['Doudou Zhou', 'Yufeng Zhang', 'Aaron Sonabend-W', 'Zhaoran Wang', 'Junwei Lu', 'Tianxi Cai']","Evidence-based or data-driven dynamic treatment regimes are essential for
personalized medicine, which can benefit from offline reinforcement learning
(RL). Although massive healthcare data are available across medical
institutions, they are prohibited from sharing due to privacy constraints.
Besides, heterogeneity exists in different sites. As a result, federated
offline RL algorithms are necessary and promising to deal with the problems. In
this paper, we propose a multi-site Markov decision process model that allows
for both homogeneous and heterogeneous effects across sites. The proposed model
makes the analysis of the site-level features possible. We design the first
federated policy optimization algorithm for offline RL with sample complexity.
The proposed algorithm is communication-efficient, which requires only a single
round of communication interaction by exchanging summary statistics. We give a
theoretical guarantee for the proposed algorithm, where the suboptimality for
the learned policies is comparable to the rate as if data is not distributed.
Extensive simulations demonstrate the effectiveness of the proposed algorithm.
The method is applied to a sepsis dataset in multiple sites to illustrate its
use in clinical settings.",2022-06-11T18:03:26Z,http://arxiv.org/pdf/2206.05581v3,"['stat.ML', 'cs.LG', 'stat.ME']"
2206.11430v1,Recursive Reinforcement Learning,"['Ernst Moritz Hahn', 'Mateo Perez', 'Sven Schewe', 'Fabio Somenzi', 'Ashutosh Trivedi', 'Dominik Wojtczak']","Recursion is the fundamental paradigm to finitely describe potentially
infinite objects. As state-of-the-art reinforcement learning (RL) algorithms
cannot directly reason about recursion, they must rely on the practitioner's
ingenuity in designing a suitable ""flat"" representation of the environment. The
resulting manual feature constructions and approximations are cumbersome and
error-prone; their lack of transparency hampers scalability. To overcome these
challenges, we develop RL algorithms capable of computing optimal policies in
environments described as a collection of Markov decision processes (MDPs) that
can recursively invoke one another. Each constituent MDP is characterized by
several entry and exit points that correspond to input and output values of
these invocations. These recursive MDPs (or RMDPs) are expressively equivalent
to probabilistic pushdown systems (with call-stack playing the role of the
pushdown stack), and can model probabilistic programs with recursive procedural
calls. We introduce Recursive Q-learning -- a model-free RL algorithm for RMDPs
-- and prove that it converges for finite, single-exit and deterministic
multi-exit RMDPs under mild assumptions.",2022-06-23T00:29:42Z,http://arxiv.org/pdf/2206.11430v1,"['cs.LG', 'cs.AI']"
2208.12584v2,Socially Fair Reinforcement Learning,"['Debmalya Mandal', 'Jiarui Gan']","We consider the problem of episodic reinforcement learning where there are
multiple stakeholders with different reward functions. Our goal is to output a
policy that is socially fair with respect to different reward functions. Prior
works have proposed different objectives that a fair policy must optimize
including minimum welfare, and generalized Gini welfare. We first take an
axiomatic view of the problem, and propose four axioms that any such fair
objective must satisfy. We show that the Nash social welfare is the unique
objective that uniquely satisfies all four objectives, whereas prior objectives
fail to satisfy all four axioms. We then consider the learning version of the
problem where the underlying model i.e. Markov decision process is unknown. We
consider the problem of minimizing regret with respect to the fair policies
maximizing three different fair objectives -- minimum welfare, generalized Gini
welfare, and Nash social welfare. Based on optimistic planning, we propose a
generic learning algorithm and derive its regret bound with respect to the
three different policies. For the objective of Nash social welfare, we also
derive a lower bound in regret that grows exponentially with $n$, the number of
agents. Finally, we show that for the objective of minimum welfare, one can
improve regret by a factor of $O(H)$ for a weaker notion of regret.",2022-08-26T11:01:55Z,http://arxiv.org/pdf/2208.12584v2,"['cs.LG', 'cs.CY', 'cs.GT', 'cs.MA']"
2208.14863v1,Style-Agnostic Reinforcement Learning,"['Juyong Lee', 'Seokjun Ahn', 'Jaesik Park']","We present a novel method of learning style-agnostic representation using
both style transfer and adversarial learning in the reinforcement learning
framework. The style, here, refers to task-irrelevant details such as the color
of the background in the images, where generalizing the learned policy across
environments with different styles is still a challenge. Focusing on learning
style-agnostic representations, our method trains the actor with diverse image
styles generated from an inherent adversarial style perturbation generator,
which plays a min-max game between the actor and the generator, without
demanding expert knowledge for data augmentation or additional class labels for
adversarial training. We verify that our method achieves competitive or better
performances than the state-of-the-art approaches on Procgen and Distracting
Control Suite benchmarks, and further investigate the features extracted from
our model, showing that the model better captures the invariants and is less
distracted by the shifted style. The code is available at
https://github.com/POSTECH-CVLab/style-agnostic-RL.",2022-08-31T13:45:00Z,http://arxiv.org/pdf/2208.14863v1,"['cs.CV', 'cs.LG']"
2210.01542v1,Hyperbolic Deep Reinforcement Learning,"['Edoardo Cetin', 'Benjamin Chamberlain', 'Michael Bronstein', 'Jonathan J Hunt']","We propose a new class of deep reinforcement learning (RL) algorithms that
model latent representations in hyperbolic space. Sequential decision-making
requires reasoning about the possible future consequences of current behavior.
Consequently, capturing the relationship between key evolving features for a
given task is conducive to recovering effective policies. To this end,
hyperbolic geometry provides deep RL models with a natural basis to precisely
encode this inherently hierarchical information. However, applying existing
methodologies from the hyperbolic deep learning literature leads to fatal
optimization instabilities due to the non-stationarity and variance
characterizing RL gradient estimators. Hence, we design a new general method
that counteracts such optimization challenges and enables stable end-to-end
learning with deep hyperbolic representations. We empirically validate our
framework by applying it to popular on-policy and off-policy RL algorithms on
the Procgen and Atari 100K benchmarks, attaining near universal performance and
generalization benefits. Given its natural fit, we hope future RL research will
consider hyperbolic representations as a standard tool.",2022-10-04T12:03:04Z,http://arxiv.org/pdf/2210.01542v1,"['cs.LG', 'cs.AI']"
2211.03983v3,Doubly Inhomogeneous Reinforcement Learning,"['Liyuan Hu', 'Mengbing Li', 'Chengchun Shi', 'Zhenke Wu', 'Piotr Fryzlewicz']","This paper studies reinforcement learning (RL) in doubly inhomogeneous
environments under temporal non-stationarity and subject heterogeneity. In a
number of applications, it is commonplace to encounter datasets generated by
system dynamics that may change over time and population, challenging
high-quality sequential decision making. Nonetheless, most existing RL
solutions require either temporal stationarity or subject homogeneity, which
would result in sub-optimal policies if both assumptions were violated. To
address both challenges simultaneously, we propose an original algorithm to
determine the ``best data chunks"" that display similar dynamics over time and
across individuals for policy learning, which alternates between most recent
change point detection and cluster identification. Our method is general, and
works with a wide range of clustering and change point detection algorithms. It
is multiply robust in the sense that it takes multiple initial estimators as
input and only requires one of them to be consistent. Moreover, by borrowing
information over time and population, it allows us to detect weaker signals and
has better convergence properties when compared to applying the clustering
algorithm per time or the change point detection algorithm per subject.
Empirically, we demonstrate the usefulness of our method through extensive
simulations and a real data application.",2022-11-08T03:41:14Z,http://arxiv.org/pdf/2211.03983v3,"['stat.ML', 'cs.AI', 'cs.LG']"
2302.00270v3,Internally Rewarded Reinforcement Learning,"['Mengdi Li', 'Xufeng Zhao', 'Jae Hee Lee', 'Cornelius Weber', 'Stefan Wermter']","We study a class of reinforcement learning problems where the reward signals
for policy learning are generated by an internal reward model that is dependent
on and jointly optimized with the policy. This interdependence between the
policy and the reward model leads to an unstable learning process because
reward signals from an immature reward model are noisy and impede policy
learning, and conversely, an under-optimized policy impedes reward estimation
learning. We call this learning setting $\textit{Internally Rewarded
Reinforcement Learning}$ (IRRL) as the reward is not provided directly by the
environment but $\textit{internally}$ by a reward model. In this paper, we
formally formulate IRRL and present a class of problems that belong to IRRL. We
theoretically derive and empirically analyze the effect of the reward function
in IRRL and based on these analyses propose the clipped linear reward function.
Experimental results show that the proposed reward function can consistently
stabilize the training process by reducing the impact of reward noise, which
leads to faster convergence and higher performance compared with baselines in
diverse tasks.",2023-02-01T06:25:46Z,http://arxiv.org/pdf/2302.00270v3,"['cs.LG', 'cs.AI']"
2307.13372v2,Submodular Reinforcement Learning,"['Manish Prajapat', 'Mojmír Mutný', 'Melanie N. Zeilinger', 'Andreas Krause']","In reinforcement learning (RL), rewards of states are typically considered
additive, and following the Markov assumption, they are $\textit{independent}$
of states visited previously. In many important applications, such as coverage
control, experiment design and informative path planning, rewards naturally
have diminishing returns, i.e., their value decreases in light of similar
states visited previously. To tackle this, we propose $\textit{submodular RL}$
(SubRL), a paradigm which seeks to optimize more general, non-additive (and
history-dependent) rewards modelled via submodular set functions which capture
diminishing returns. Unfortunately, in general, even in tabular settings, we
show that the resulting optimization problem is hard to approximate. On the
other hand, motivated by the success of greedy algorithms in classical
submodular optimization, we propose SubPO, a simple policy gradient-based
algorithm for SubRL that handles non-additive rewards by greedily maximizing
marginal gains. Indeed, under some assumptions on the underlying Markov
Decision Process (MDP), SubPO recovers optimal constant factor approximations
of submodular bandits. Moreover, we derive a natural policy gradient approach
for locally optimizing SubRL instances even in large state- and action- spaces.
We showcase the versatility of our approach by applying SubPO to several
applications, such as biodiversity monitoring, Bayesian experiment design,
informative path planning, and coverage maximization. Our results demonstrate
sample efficiency, as well as scalability to high-dimensional state-action
spaces.",2023-07-25T09:46:02Z,http://arxiv.org/pdf/2307.13372v2,['cs.LG']
2308.07843v6,Dyadic Reinforcement Learning,"['Shuangning Li', 'Lluis Salvat Niell', 'Sung Won Choi', 'Inbal Nahum-Shani', 'Guy Shani', 'Susan Murphy']","Mobile health aims to enhance health outcomes by delivering interventions to
individuals as they go about their daily life. The involvement of care partners
and social support networks often proves crucial in helping individuals
managing burdensome medical conditions. This presents opportunities in mobile
health to design interventions that target the dyadic relationship -- the
relationship between a target person and their care partner -- with the aim of
enhancing social support. In this paper, we develop dyadic RL, an online
reinforcement learning algorithm designed to personalize intervention delivery
based on contextual factors and past responses of a target person and their
care partner. Here, multiple sets of interventions impact the dyad across
multiple time intervals. The developed dyadic RL is Bayesian and hierarchical.
We formally introduce the problem setup, develop dyadic RL and establish a
regret bound. We demonstrate dyadic RL's empirical performance through
simulation studies on both toy scenarios and on a realistic test bed
constructed from data collected in a mobile health study.",2023-08-15T15:43:12Z,http://arxiv.org/pdf/2308.07843v6,"['cs.LG', 'stat.AP', 'stat.ML']"
2309.11096v1,Delays in Reinforcement Learning,['Pierre Liotet'],"Delays are inherent to most dynamical systems. Besides shifting the process
in time, they can significantly affect their performance. For this reason, it
is usually valuable to study the delay and account for it. Because they are
dynamical systems, it is of no surprise that sequential decision-making
problems such as Markov decision processes (MDP) can also be affected by
delays. These processes are the foundational framework of reinforcement
learning (RL), a paradigm whose goal is to create artificial agents capable of
learning to maximise their utility by interacting with their environment.
  RL has achieved strong, sometimes astonishing, empirical results, but delays
are seldom explicitly accounted for. The understanding of the impact of delay
on the MDP is limited. In this dissertation, we propose to study the delay in
the agent's observation of the state of the environment or in the execution of
the agent's actions. We will repeatedly change our point of view on the problem
to reveal some of its structure and peculiarities. A wide spectrum of delays
will be considered, and potential solutions will be presented. This
dissertation also aims to draw links between celebrated frameworks of the RL
literature and the one of delays.",2023-09-20T07:04:46Z,http://arxiv.org/pdf/2309.11096v1,['cs.LG']
2312.17194v2,Resilient Constrained Reinforcement Learning,"['Dongsheng Ding', 'Zhengyan Huan', 'Alejandro Ribeiro']","We study a class of constrained reinforcement learning (RL) problems in which
multiple constraint specifications are not identified before training. It is
challenging to identify appropriate constraint specifications due to the
undefined trade-off between the reward maximization objective and the
constraint satisfaction, which is ubiquitous in constrained decision-making. To
tackle this issue, we propose a new constrained RL approach that searches for
policy and constraint specifications together. This method features the
adaptation of relaxing the constraint according to a relaxation cost introduced
in the learning objective. Since this feature mimics how ecological systems
adapt to disruptions by altering operation, our approach is termed as resilient
constrained RL. Specifically, we provide a set of sufficient conditions that
balance the constraint satisfaction and the reward maximization in notion of
resilient equilibrium, propose a tractable formulation of resilient constrained
policy optimization that takes this equilibrium as an optimal solution, and
advocate two resilient constrained policy search algorithms with non-asymptotic
convergence guarantees on the optimality gap and constraint satisfaction.
Furthermore, we demonstrate the merits and the effectiveness of our approach in
computational experiments.",2023-12-28T18:28:23Z,http://arxiv.org/pdf/2312.17194v2,"['math.OC', 'cs.LG', 'cs.SY', 'eess.SY']"
2405.18289v1,Highway Reinforcement Learning,"['Yuhui Wang', 'Miroslav Strupl', 'Francesco Faccio', 'Qingyuan Wu', 'Haozhe Liu', 'Michał Grudzień', 'Xiaoyang Tan', 'Jürgen Schmidhuber']","Learning from multi-step off-policy data collected by a set of policies is a
core problem of reinforcement learning (RL). Approaches based on importance
sampling (IS) often suffer from large variances due to products of IS ratios.
Typical IS-free methods, such as $n$-step Q-learning, look ahead for $n$ time
steps along the trajectory of actions (where $n$ is called the lookahead depth)
and utilize off-policy data directly without any additional adjustment. They
work well for proper choices of $n$. We show, however, that such IS-free
methods underestimate the optimal value function (VF), especially for large
$n$, restricting their capacity to efficiently utilize information from distant
future time steps. To overcome this problem, we introduce a novel, IS-free,
multi-step off-policy method that avoids the underestimation issue and
converges to the optimal VF. At its core lies a simple but non-trivial
\emph{highway gate}, which controls the information flow from the distant
future by comparing it to a threshold. The highway gate guarantees convergence
to the optimal VF for arbitrary $n$ and arbitrary behavioral policies. It gives
rise to a novel family of off-policy RL algorithms that safely learn even when
$n$ is very large, facilitating rapid credit assignment from the far future to
the past. On tasks with greatly delayed rewards, including video games where
the reward is given only at the end of the game, our new methods outperform
many existing multi-step off-policy algorithms.",2024-05-28T15:42:45Z,http://arxiv.org/pdf/2405.18289v1,"['cs.LG', 'cs.AI']"
2505.19002v1,Semi-pessimistic Reinforcement Learning,"['Jin Zhu', 'Xin Zhou', 'Jiaang Yao', 'Gholamali Aminian', 'Omar Rivasplata', 'Simon Little', 'Lexin Li', 'Chengchun Shi']","Offline reinforcement learning (RL) aims to learn an optimal policy from
pre-collected data. However, it faces challenges of distributional shift, where
the learned policy may encounter unseen scenarios not covered in the offline
data. Additionally, numerous applications suffer from a scarcity of labeled
reward data. Relying on labeled data alone often leads to a narrow state-action
distribution, further amplifying the distributional shift, and resulting in
suboptimal policy learning. To address these issues, we first recognize that
the volume of unlabeled data is typically substantially larger than that of
labeled data. We then propose a semi-pessimistic RL method to effectively
leverage abundant unlabeled data. Our approach offers several advantages. It
considerably simplifies the learning process, as it seeks a lower bound of the
reward function, rather than that of the Q-function or state transition
function. It is highly flexible, and can be integrated with a range of
model-free and model-based RL algorithms. It enjoys the guaranteed improvement
when utilizing vast unlabeled data, but requires much less restrictive
conditions. We compare our method with a number of alternative solutions, both
analytically and numerically, and demonstrate its clear competitiveness. We
further illustrate with an application to adaptive deep brain stimulation for
Parkinson's disease.",2025-05-25T06:47:36Z,http://arxiv.org/pdf/2505.19002v1,"['cs.LG', 'cs.AI', 'stat.ML']"
2201.02135v5,"Deep Reinforcement Learning, a textbook",['Aske Plaat'],"Deep reinforcement learning has gathered much attention recently. Impressive
results were achieved in activities as diverse as autonomous driving, game
playing, molecular recombination, and robotics. In all these fields, computer
programs have taught themselves to solve difficult problems. They have learned
to fly model helicopters and perform aerobatic manoeuvers such as loops and
rolls. In some applications they have even become better than the best humans,
such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement
learning explores complex environments reminds us of how children learn, by
playfully trying out things, getting feedback, and trying again. The computer
seems to truly possess aspects of human learning; this goes to the heart of the
dream of artificial intelligence. The successes in research have not gone
unnoticed by educators, and universities have started to offer courses on the
subject. The aim of this book is to provide a comprehensive overview of the
field of deep reinforcement learning. The book is written for graduate students
of artificial intelligence, and for researchers and practitioners who wish to
better understand deep reinforcement learning methods and their challenges. We
assume an undergraduate-level of understanding of computer science and
artificial intelligence; the programming language of this book is Python. We
describe the foundations, the algorithms and the applications of deep
reinforcement learning. We cover the established model-free and model-based
methods that form the basis of the field. Developments go quickly, and we also
cover advanced topics: deep multi-agent reinforcement learning, deep
hierarchical reinforcement learning, and deep meta learning.",2022-01-04T11:47:21Z,http://arxiv.org/pdf/2201.02135v5,"['cs.AI', 'cs.LG']"
1611.08944v1,Nonparametric General Reinforcement Learning,['Jan Leike'],"Reinforcement learning (RL) problems are often phrased in terms of Markov
decision processes (MDPs). In this thesis we go beyond MDPs and consider RL in
environments that are non-Markovian, non-ergodic and only partially observable.
Our focus is not on practical algorithms, but rather on the fundamental
underlying problems: How do we balance exploration and exploitation? How do we
explore optimally? When is an agent optimal? We follow the nonparametric
realizable paradigm.
  We establish negative results on Bayesian RL agents, in particular AIXI. We
show that unlucky or adversarial choices of the prior cause the agent to
misbehave drastically. Therefore Legg-Hutter intelligence and balanced Pareto
optimality, which depend crucially on the choice of the prior, are entirely
subjective. Moreover, in the class of all computable environments every policy
is Pareto optimal. This undermines all existing optimality properties for AIXI.
However, there are Bayesian approaches to general RL that satisfy objective
optimality guarantees: We prove that Thompson sampling is asymptotically
optimal in stochastic environments in the sense that its value converges to the
value of the optimal policy. We connect asymptotic optimality to regret given a
recoverability assumption on the environment that allows the agent to recover
from mistakes. Hence Thompson sampling achieves sublinear regret in these
environments.
  Our results culminate in a formal solution to the grain of truth problem: A
Bayesian agent acting in a multi-agent environment learns to predict the other
agents' policies if its prior assigns positive probability to them (the prior
contains a grain of truth). We construct a large but limit computable class
containing a grain of truth and show that agents based on Thompson sampling
over this class converge to play Nash equilibria in arbitrary unknown
computable multi-agent environments.",2016-11-28T00:36:40Z,http://arxiv.org/pdf/1611.08944v1,['cs.AI']
2202.08417v4,Retrieval-Augmented Reinforcement Learning,"['Anirudh Goyal', 'Abram L. Friesen', 'Andrea Banino', 'Theophane Weber', 'Nan Rosemary Ke', 'Adria Puigdomenech Badia', 'Arthur Guez', 'Mehdi Mirza', 'Peter C. Humphreys', 'Ksenia Konyushkova', 'Laurent Sifre', 'Michal Valko', 'Simon Osindero', 'Timothy Lillicrap', 'Nicolas Heess', 'Charles Blundell']","Most deep reinforcement learning (RL) algorithms distill experience into
parametric behavior policies or value functions via gradient updates. While
effective, this approach has several disadvantages: (1) it is computationally
expensive, (2) it can take many updates to integrate experiences into the
parametric model, (3) experiences that are not fully integrated do not
appropriately influence the agent's behavior, and (4) behavior is limited by
the capacity of the model. In this paper we explore an alternative paradigm in
which we train a network to map a dataset of past experiences to optimal
behavior. Specifically, we augment an RL agent with a retrieval process
(parameterized as a neural network) that has direct access to a dataset of
experiences. This dataset can come from the agent's past experiences, expert
demonstrations, or any other relevant source. The retrieval process is trained
to retrieve information from the dataset that may be useful in the current
context, to help the agent achieve its goal faster and more efficiently. he
proposed method facilitates learning agents that at test-time can condition
their behavior on the entire dataset and not only the current state, or current
trajectory. We integrate our method into two different RL agents: an offline
DQN agent and an online R2D2 agent. In offline multi-task problems, we show
that the retrieval-augmented DQN agent avoids task interference and learns
faster than the baseline DQN agent. On Atari, we show that retrieval-augmented
R2D2 learns significantly faster than the baseline R2D2 agent and achieves
higher scores. We run extensive ablations to measure the contributions of the
components of our proposed method.",2022-02-17T02:44:05Z,http://arxiv.org/pdf/2202.08417v4,['cs.LG']
2305.19562v2,Replicability in Reinforcement Learning,"['Amin Karbasi', 'Grigoris Velegkas', 'Lin F. Yang', 'Felix Zhou']","We initiate the mathematical study of replicability as an algorithmic
property in the context of reinforcement learning (RL). We focus on the
fundamental setting of discounted tabular MDPs with access to a generative
model. Inspired by Impagliazzo et al. [2022], we say that an RL algorithm is
replicable if, with high probability, it outputs the exact same policy after
two executions on i.i.d. samples drawn from the generator when its internal
randomness is the same. We first provide an efficient $\rho$-replicable
algorithm for $(\varepsilon, \delta)$-optimal policy estimation with sample and
time complexity $\widetilde
O\left(\frac{N^3\cdot\log(1/\delta)}{(1-\gamma)^5\cdot\varepsilon^2\cdot\rho^2}\right)$,
where $N$ is the number of state-action pairs. Next, for the subclass of
deterministic algorithms, we provide a lower bound of order
$\Omega\left(\frac{N^3}{(1-\gamma)^3\cdot\varepsilon^2\cdot\rho^2}\right)$.
Then, we study a relaxed version of replicability proposed by Kalavasis et al.
[2023] called TV indistinguishability. We design a computationally efficient TV
indistinguishable algorithm for policy estimation whose sample complexity is
$\widetilde
O\left(\frac{N^2\cdot\log(1/\delta)}{(1-\gamma)^5\cdot\varepsilon^2\cdot\rho^2}\right)$.
At the cost of $\exp(N)$ running time, we transform these TV indistinguishable
algorithms to $\rho$-replicable ones without increasing their sample
complexity. Finally, we introduce the notion of approximate-replicability where
we only require that two outputted policies are close under an appropriate
statistical divergence (e.g., Renyi) and show an improved sample complexity of
$\widetilde
O\left(\frac{N\cdot\log(1/\delta)}{(1-\gamma)^5\cdot\varepsilon^2\cdot\rho^2}\right)$.",2023-05-31T05:16:23Z,http://arxiv.org/pdf/2305.19562v2,"['cs.LG', 'cs.AI', 'stat.ML']"
1801.08099v8,Logically-Constrained Reinforcement Learning,"['Mohammadhosein Hasanbeig', 'Alessandro Abate', 'Daniel Kroening']","We present the first model-free Reinforcement Learning (RL) algorithm to
synthesise policies for an unknown Markov Decision Process (MDP), such that a
linear time property is satisfied. The given temporal property is converted
into a Limit Deterministic Buchi Automaton (LDBA) and a robust reward function
is defined over the state-action pairs of the MDP according to the resulting
LDBA. With this reward function, the policy synthesis procedure is
""constrained"" by the given specification. These constraints guide the MDP
exploration so as to minimize the solution time by only considering the portion
of the MDP that is relevant to satisfaction of the LTL property. This improves
performance and scalability of the proposed method by avoiding an exhaustive
update over the whole state space while the efficiency of standard methods such
as dynamic programming is hindered by excessive memory requirements, caused by
the need to store a full-model in memory. Additionally, we show that the RL
procedure sets up a local value iteration method to efficiently calculate the
maximum probability of satisfying the given property, at any given state of the
MDP. We prove that our algorithm is guaranteed to find a policy whose traces
probabilistically satisfy the LTL property if such a policy exists, and
additionally we show that our method produces reasonable control policies even
when the LTL property cannot be satisfied. The performance of the algorithm is
evaluated via a set of numerical examples. We observe an improvement of one
order of magnitude in the number of iterations required for the synthesis
compared to existing approaches.",2018-01-24T17:50:30Z,http://arxiv.org/pdf/1801.08099v8,"['cs.LG', 'cs.LO']"
2401.15480v2,Social Interpretable Reinforcement Learning,"['Leonardo Lucio Custode', 'Giovanni Iacca']","Reinforcement Learning (RL) bears the promise of being a game-changer in many
applications. However, since most of the literature in the field is currently
focused on opaque models, the use of RL in high-stakes scenarios, where
interpretability is crucial, is still limited. Recently, some approaches to
interpretable RL, e.g., based on Decision Trees, have been proposed, but one of
the main limitations of these techniques is their training cost. To overcome
this limitation, we propose a new method, called Social Interpretable RL
(SIRL), that can substantially reduce the number of episodes needed for
training. Our method mimics a social learning process, where each agent in a
group learns to solve a given task based both on its own individual experience
as well as the experience acquired together with its peers. Our approach is
divided into the following two phases. (1) In the collaborative phase, all the
agents in the population interact with a shared instance of the environment,
where each agent observes the state and independently proposes an action. Then,
voting is performed to choose the action that will actually be deployed in the
environment. (2) In the individual phase, then, each agent refines its
individual performance by interacting with its own instance of the environment.
This mechanism makes the agents experience a larger number of episodes with
little impact on the computational cost of the process. Our results (on 6
widely-known RL benchmarks) show that SIRL not only reduces the computational
cost by a factor varying from a minimum of 43% to a maximum 76%, but it also
increases the convergence speed and, often, improves the quality of the
solutions.",2024-01-27T19:05:21Z,http://arxiv.org/pdf/2401.15480v2,"['cs.LG', 'cs.AI', 'cs.MA', 'I.2.6; I.2.8']"
1909.11939v6,MERL: Multi-Head Reinforcement Learning,"['Yannis Flet-Berliac', 'Philippe Preux']","A common challenge in reinforcement learning is how to convert the agent's
interactions with an environment into fast and robust learning. For instance,
earlier work makes use of domain knowledge to improve existing reinforcement
learning algorithms in complex tasks. While promising, previously acquired
knowledge is often costly and challenging to scale up. Instead, we decide to
consider problem knowledge with signals from quantities relevant to solve any
task, e.g., self-performance assessment and accurate expectations.
$\mathcal{V}^{ex}$ is such a quantity. It is the fraction of variance explained
by the value function $V$ and measures the discrepancy between $V$ and the
returns. Taking advantage of $\mathcal{V}^{ex}$, we propose MERL, a general
framework for structuring reinforcement learning by injecting problem knowledge
into policy gradient updates. As a result, the agent is not only optimized for
a reward but learns using problem-focused quantities provided by MERL,
applicable out-of-the-box to any task. In this paper: (a) We introduce and
define MERL, the multi-head reinforcement learning framework we use throughout
this work. (b) We conduct experiments across a variety of standard benchmark
environments, including 9 continuous control tasks, where results show improved
performance. (c) We demonstrate that MERL also improves transfer learning on a
set of challenging pixel-based tasks. (d) We ponder how MERL tackles the
problem of reward sparsity and better conditions the feature space of
reinforcement learning agents.",2019-09-26T06:57:51Z,http://arxiv.org/pdf/1909.11939v6,"['cs.LG', 'cs.AI', 'stat.ML']"
2007.04725v2,EVO-RL: Evolutionary-Driven Reinforcement Learning,"['Ahmed Hallawa', 'Thorsten Born', 'Anke Schmeink', 'Guido Dartmann', 'Arne Peine', 'Lukas Martin', 'Giovanni Iacca', 'A. E. Eiben', 'Gerd Ascheid']","In this work, we propose a novel approach for reinforcement learning driven
by evolutionary computation. Our algorithm, dubbed as Evolutionary-Driven
Reinforcement Learning (evo-RL), embeds the reinforcement learning algorithm in
an evolutionary cycle, where we distinctly differentiate between purely
evolvable (instinctive) behaviour versus purely learnable behaviour.
Furthermore, we propose that this distinction is decided by the evolutionary
process, thus allowing evo-RL to be adaptive to different environments. In
addition, evo-RL facilitates learning on environments with rewardless states,
which makes it more suited for real-world problems with incomplete information.
To show that evo-RL leads to state-of-the-art performance, we present the
performance of different state-of-the-art reinforcement learning algorithms
when operating within evo-RL and compare it with the case when these same
algorithms are executed independently. Results show that reinforcement learning
algorithms embedded within our evo-RL approach significantly outperform the
stand-alone versions of the same RL algorithms on OpenAI Gym control problems
with rewardless states constrained by the same computational budget.",2020-07-09T11:52:19Z,http://arxiv.org/pdf/2007.04725v2,"['cs.LG', 'cs.AI', 'cs.NE', 'stat.ML']"
1703.09842v3,Inverse Risk-Sensitive Reinforcement Learning,"['Lillian J. Ratliff', 'Eric Mazumdar']","We address the problem of inverse reinforcement learning in Markov decision
processes where the agent is risk-sensitive. In particular, we model
risk-sensitivity in a reinforcement learning framework by making use of models
of human decision-making having their origins in behavioral psychology,
behavioral economics, and neuroscience. We propose a gradient-based inverse
reinforcement learning algorithm that minimizes a loss function defined on the
observed behavior. We demonstrate the performance of the proposed technique on
two examples, the first of which is the canonical Grid World example and the
second of which is a Markov decision process modeling passengers' decisions
regarding ride-sharing. In the latter, we use pricing and travel time data from
a ride-sharing company to construct the transition probabilities and rewards of
the Markov decision process.",2017-03-29T00:10:17Z,http://arxiv.org/pdf/1703.09842v3,"['cs.LG', 'stat.ML']"
1701.07274v6,Deep Reinforcement Learning: An Overview,['Yuxi Li'],"We give an overview of recent exciting achievements of deep reinforcement
learning (RL). We discuss six core elements, six important mechanisms, and
twelve applications. We start with background of machine learning, deep
learning and reinforcement learning. Next we discuss core RL elements,
including value function, in particular, Deep Q-Network (DQN), policy, reward,
model, planning, and exploration. After that, we discuss important mechanisms
for RL, including attention and memory, unsupervised learning, transfer
learning, multi-agent RL, hierarchical RL, and learning to learn. Then we
discuss various applications of RL, including games, in particular, AlphaGo,
robotics, natural language processing, including dialogue systems, machine
translation, and text generation, computer vision, neural architecture design,
business management, finance, healthcare, Industry 4.0, smart grid, intelligent
transportation systems, and computer systems. We mention topics not reviewed
yet, and list a collection of RL resources. After presenting a brief summary,
we close with discussions.
  Please see Deep Reinforcement Learning, arXiv:1810.06339, for a significant
update.",2017-01-25T11:52:11Z,http://arxiv.org/pdf/1701.07274v6,['cs.LG']
2305.04843v1,Reinforcement Learning for Topic Models,"['Jeremy Costello', 'Marek Z. Reformat']","We apply reinforcement learning techniques to topic modeling by replacing the
variational autoencoder in ProdLDA with a continuous action space reinforcement
learning policy. We train the system with a policy gradient algorithm
REINFORCE. Additionally, we introduced several modifications: modernize the
neural network architecture, weight the ELBO loss, use contextual embeddings,
and monitor the learning process via computing topic diversity and coherence
for each training step. Experiments are performed on 11 data sets. Our
unsupervised model outperforms all other unsupervised models and performs on
par with or better than most models using supervised labeling. Our model is
outperformed on certain data sets by a model using supervised labeling and
contrastive learning. We have also conducted an ablation study to provide
empirical evidence of performance improvements from changes we made to ProdLDA
and found that the reinforcement learning formulation boosts performance.",2023-05-08T16:41:08Z,http://arxiv.org/pdf/2305.04843v1,"['cs.CL', 'cs.LG']"
2007.00425v1,Interaction-limited Inverse Reinforcement Learning,"['Martin Troussard', 'Emmanuel Pignat', 'Parameswaran Kamalaruban', 'Sylvain Calinon', 'Volkan Cevher']","This paper proposes an inverse reinforcement learning (IRL) framework to
accelerate learning when the learner-teacher \textit{interaction} is
\textit{limited} during training. Our setting is motivated by the realistic
scenarios where a helpful teacher is not available or when the teacher cannot
access the learning dynamics of the student. We present two different training
strategies: Curriculum Inverse Reinforcement Learning (CIRL) covering the
teacher's perspective, and Self-Paced Inverse Reinforcement Learning (SPIRL)
focusing on the learner's perspective. Using experiments in simulations and
experiments with a real robot learning a task from a human demonstrator, we
show that our training strategies can allow a faster training than a random
teacher for CIRL and than a batch learner for SPIRL.",2020-07-01T12:31:52Z,http://arxiv.org/pdf/2007.00425v1,"['cs.LG', 'stat.ML']"
2311.04830v3,Real-Time Recurrent Reinforcement Learning,"['Julian Lemmel', 'Radu Grosu']","We introduce a biologically plausible RL framework for solving tasks in
partially observable Markov decision processes (POMDPs). The proposed algorithm
combines three integral parts: (1) A Meta-RL architecture, resembling the
mammalian basal ganglia; (2) A biologically plausible reinforcement learning
algorithm, exploiting temporal difference learning and eligibility traces to
train the policy and the value-function; (3) An online automatic
differentiation algorithm for computing the gradients with respect to
parameters of a shared recurrent network backbone. Our experimental results
show that the method is capable of solving a diverse set of partially
observable reinforcement learning tasks. The algorithm we call real-time
recurrent reinforcement learning (RTRRL) serves as a model of learning in
biological neural networks, mimicking reward pathways in the basal ganglia.",2023-11-08T16:56:16Z,http://arxiv.org/pdf/2311.04830v3,"['cs.LG', 'cs.NE', 'cs.SY', 'eess.SY']"
2405.13574v1,Reinforcement Learning for Adaptive MCMC,"['Congye Wang', 'Wilson Chen', 'Heishiro Kanagawa', 'Chris. J. Oates']","An informal observation, made by several authors, is that the adaptive design
of a Markov transition kernel has the flavour of a reinforcement learning task.
Yet, to-date it has remained unclear how to actually exploit modern
reinforcement learning technologies for adaptive MCMC. The aim of this paper is
to set out a general framework, called Reinforcement Learning
Metropolis--Hastings, that is theoretically supported and empirically
validated. Our principal focus is on learning fast-mixing Metropolis--Hastings
transition kernels, which we cast as deterministic policies and optimise via a
policy gradient. Control of the learning rate provably ensures conditions for
ergodicity are satisfied. The methodology is used to construct a gradient-free
sampler that out-performs a popular gradient-free adaptive Metropolis--Hastings
algorithm on $\approx 90 \%$ of tasks in the PosteriorDB benchmark.",2024-05-22T12:11:12Z,http://arxiv.org/pdf/2405.13574v1,"['stat.CO', 'cs.LG']"
2406.08406v1,RRLS : Robust Reinforcement Learning Suite,"['Adil Zouitine', 'David Bertoin', 'Pierre Clavier', 'Matthieu Geist', 'Emmanuel Rachelson']","Robust reinforcement learning is the problem of learning control policies
that provide optimal worst-case performance against a span of adversarial
environments. It is a crucial ingredient for deploying algorithms in real-world
scenarios with prevalent environmental uncertainties and has been a
long-standing object of attention in the community, without a standardized set
of benchmarks. This contribution endeavors to fill this gap. We introduce the
Robust Reinforcement Learning Suite (RRLS), a benchmark suite based on Mujoco
environments. RRLS provides six continuous control tasks with two types of
uncertainty sets for training and evaluation. Our benchmark aims to standardize
robust reinforcement learning tasks, facilitating reproducible and comparable
experiments, in particular those from recent state-of-the-art contributions,
for which we demonstrate the use of RRLS. It is also designed to be easily
expandable to new environments. The source code is available at
\href{https://github.com/SuReLI/RRLS}{https://github.com/SuReLI/RRLS}.",2024-06-12T16:53:51Z,http://arxiv.org/pdf/2406.08406v1,['cs.LG']
2407.10583v1,Three Dogmas of Reinforcement Learning,"['David Abel', 'Mark K. Ho', 'Anna Harutyunyan']","Modern reinforcement learning has been conditioned by at least three dogmas.
The first is the environment spotlight, which refers to our tendency to focus
on modeling environments rather than agents. The second is our treatment of
learning as finding the solution to a task, rather than adaptation. The third
is the reward hypothesis, which states that all goals and purposes can be well
thought of as maximization of a reward signal. These three dogmas shape much of
what we think of as the science of reinforcement learning. While each of the
dogmas have played an important role in developing the field, it is time we
bring them to the surface and reflect on whether they belong as basic
ingredients of our scientific paradigm. In order to realize the potential of
reinforcement learning as a canonical frame for researching intelligent agents,
we suggest that it is time we shed dogmas one and two entirely, and embrace a
nuanced approach to the third.",2024-07-15T10:03:24Z,http://arxiv.org/pdf/2407.10583v1,"['cs.AI', 'cs.LG']"
2508.00106v1,Hyperproperty-Constrained Secure Reinforcement Learning,"['Ernest Bonnah', 'Luan Viet Nguyen', 'Khaza Anuarul Hoque']","Hyperproperties for Time Window Temporal Logic (HyperTWTL) is a
domain-specific formal specification language known for its effectiveness in
compactly representing security, opacity, and concurrency properties for
robotics applications. This paper focuses on HyperTWTL-constrained secure
reinforcement learning (SecRL). Although temporal logic-constrained safe
reinforcement learning (SRL) is an evolving research problem with several
existing literature, there is a significant research gap in exploring
security-aware reinforcement learning (RL) using hyperproperties. Given the
dynamics of an agent as a Markov Decision Process (MDP) and opacity/security
constraints formalized as HyperTWTL, we propose an approach for learning
security-aware optimal policies using dynamic Boltzmann softmax RL while
satisfying the HyperTWTL constraints. The effectiveness and scalability of our
proposed approach are demonstrated using a pick-up and delivery robotic mission
case study. We also compare our results with two other baseline RL algorithms,
showing that our proposed method outperforms them.",2025-07-31T18:57:18Z,http://arxiv.org/pdf/2508.00106v1,"['cs.AI', 'cs.LG', 'cs.LO', 'cs.SY', 'eess.SY']"
1305.1809v2,Cover Tree Bayesian Reinforcement Learning,"['Nikolaos Tziortziotis', 'Christos Dimitrakakis', 'Konstantinos Blekas']","This paper proposes an online tree-based Bayesian approach for reinforcement
learning. For inference, we employ a generalised context tree model. This
defines a distribution on multivariate Gaussian piecewise-linear models, which
can be updated in closed form. The tree structure itself is constructed using
the cover tree method, which remains efficient in high dimensional spaces. We
combine the model with Thompson sampling and approximate dynamic programming to
obtain effective exploration policies in unknown environments. The flexibility
and computational simplicity of the model render it suitable for many
reinforcement learning problems in continuous state spaces. We demonstrate this
in an experimental comparison with least squares policy iteration.",2013-05-08T13:11:52Z,http://arxiv.org/pdf/1305.1809v2,"['stat.ML', 'cs.LG']"
1809.09501v1,Anderson Acceleration for Reinforcement Learning,"['Matthieu Geist', 'Bruno Scherrer']","Anderson acceleration is an old and simple method for accelerating the
computation of a fixed point. However, as far as we know and quite
surprisingly, it has never been applied to dynamic programming or reinforcement
learning. In this paper, we explain briefly what Anderson acceleration is and
how it can be applied to value iteration, this being supported by preliminary
experiments showing a significant speed up of convergence, that we critically
discuss. We also discuss how this idea could be applied more generally to
(deep) reinforcement learning.",2018-09-25T14:04:25Z,http://arxiv.org/pdf/1809.09501v1,"['cs.LG', 'stat.ML']"
1610.02707v1,Multi-Objective Deep Reinforcement Learning,"['Hossam Mossalam', 'Yannis M. Assael', 'Diederik M. Roijers', 'Shimon Whiteson']","We propose Deep Optimistic Linear Support Learning (DOL) to solve
high-dimensional multi-objective decision problems where the relative
importances of the objectives are not known a priori. Using features from the
high-dimensional inputs, DOL computes the convex coverage set containing all
potential optimal solutions of the convex combinations of the objectives. To
our knowledge, this is the first time that deep reinforcement learning has
succeeded in learning multi-objective policies. In addition, we provide a
testbed with two experiments to be used as a benchmark for deep multi-objective
reinforcement learning.",2016-10-09T19:08:36Z,http://arxiv.org/pdf/1610.02707v1,['cs.AI']
1809.06995v1,Interpretable Reinforcement Learning with Ensemble Methods,"['Alexander Brown', 'Marek Petrik']","We propose to use boosted regression trees as a way to compute
human-interpretable solutions to reinforcement learning problems. Boosting
combines several regression trees to improve their accuracy without
significantly reducing their inherent interpretability. Prior work has focused
independently on reinforcement learning and on interpretable machine learning,
but there has been little progress in interpretable reinforcement learning. Our
experimental results show that boosted regression trees compute solutions that
are both interpretable and match the quality of leading reinforcement learning
methods.",2018-09-19T03:23:35Z,http://arxiv.org/pdf/1809.06995v1,"['cs.LG', 'stat.ML']"
2001.09608v1,Some Insights into Lifelong Reinforcement Learning Systems,['Changjian Li'],"A lifelong reinforcement learning system is a learning system that has the
ability to learn through trail-and-error interaction with the environment over
its lifetime. In this paper, I give some arguments to show that the traditional
reinforcement learning paradigm fails to model this type of learning system.
Some insights into lifelong reinforcement learning are provided, along with a
simplistic prototype lifelong reinforcement learning system.",2020-01-27T07:26:12Z,http://arxiv.org/pdf/2001.09608v1,"['cs.LG', 'stat.ML']"
1608.02971v1,Neuroevolution-Based Inverse Reinforcement Learning,"['Karan K. Budhraja', 'Tim Oates']","The problem of Learning from Demonstration is targeted at learning to perform
tasks based on observed examples. One approach to Learning from Demonstration
is Inverse Reinforcement Learning, in which actions are observed to infer
rewards. This work combines a feature based state evaluation approach to
Inverse Reinforcement Learning with neuroevolution, a paradigm for modifying
neural networks based on their performance on a given task. Neural networks are
used to learn from a demonstrated expert policy and are evolved to generate a
policy similar to the demonstration. The algorithm is discussed and evaluated
against competitive feature-based Inverse Reinforcement Learning approaches. At
the cost of execution time, neural networks allow for non-linear combinations
of features in state evaluations. These valuations may correspond to state
value or state reward. This results in better correspondence to observed
examples as opposed to using linear combinations. This work also extends
existing work on Bayesian Non-Parametric Feature Construction for Inverse
Reinforcement Learning by using non-linear combinations of intermediate data to
improve performance. The algorithm is observed to be specifically suitable for
a linearly solvable non-deterministic Markov Decision Processes in which
multiple rewards are sparsely scattered in state space. A conclusive
performance hierarchy between evaluated algorithms is presented.",2016-08-09T20:04:40Z,http://arxiv.org/pdf/1608.02971v1,"['cs.NE', 'cs.AI', 'cs.LG']"
1908.11494v4,Reinforcement learning with world model,"['Jingbin Liu', 'Xinyang Gu', 'Shuai Liu']","Nowadays, model-free reinforcement learning algorithms have achieved
remarkable performance on many decision making and control tasks, but high
sample complexity and low sample efficiency still hinder the wide use of
model-free reinforcement learning algorithms. In this paper, we argue that if
we intend to design an intelligent agent that learns fast and transfers well,
the agent must be able to reflect key elements of intelligence, like intuition,
Memory, PredictionandCuriosity. We propose an agent framework that integrates
off-policy reinforcement learning with world model learning, so as to embody
the important features of intelligence in our algorithm design. We adopt the
state-of-art model-free reinforcement learning algorithm, Soft Actor-Critic, as
the agent intuition, and world model learning through RNN to endow the agent
with memory, curiosity, and the ability to predict. We show that these ideas
can work collaboratively with each other and our agent (RMC) can give new
state-of-art results while maintaining sample efficiency and training
stability. Moreover, our agent framework can be easily extended from MDP to
POMDP problems without performance loss.",2019-08-30T00:29:32Z,http://arxiv.org/pdf/1908.11494v4,['cs.AI']
2202.05839v3,Abstraction for Deep Reinforcement Learning,"['Murray Shanahan', 'Melanie Mitchell']","We characterise the problem of abstraction in the context of deep
reinforcement learning. Various well established approaches to analogical
reasoning and associative memory might be brought to bear on this issue, but
they present difficulties because of the need for end-to-end differentiability.
We review developments in AI and machine learning that could facilitate their
adoption.",2022-02-10T23:49:13Z,http://arxiv.org/pdf/2202.05839v3,"['cs.LG', 'cs.AI']"
2304.01315v2,Empirical Design in Reinforcement Learning,"['Andrew Patterson', 'Samuel Neumann', 'Martha White', 'Adam White']","Empirical design in reinforcement learning is no small task. Running good
experiments requires attention to detail and at times significant computational
resources. While compute resources available per dollar have continued to grow
rapidly, so have the scale of typical experiments in reinforcement learning. It
is now common to benchmark agents with millions of parameters against dozens of
tasks, each using the equivalent of 30 days of experience. The scale of these
experiments often conflict with the need for proper statistical evidence,
especially when comparing algorithms. Recent studies have highlighted how
popular algorithms are sensitive to hyper-parameter settings and implementation
details, and that common empirical practice leads to weak statistical evidence
(Machado et al., 2018; Henderson et al., 2018). Here we take this one step
further.
  This manuscript represents both a call to action, and a comprehensive
resource for how to do good experiments in reinforcement learning. In
particular, we cover: the statistical assumptions underlying common performance
measures, how to properly characterize performance variation and stability,
hypothesis testing, special considerations for comparing multiple agents,
baseline and illustrative example construction, and how to deal with
hyper-parameters and experimenter bias. Throughout we highlight common mistakes
found in the literature and the statistical consequences of those in example
experiments. The objective of this document is to provide answers on how we can
use our unprecedented compute to do good science in reinforcement learning, as
well as stay alert to potential pitfalls in our empirical design.",2023-04-03T19:32:24Z,http://arxiv.org/pdf/2304.01315v2,"['cs.LG', 'cs.AI']"
2410.00704v1,Contrastive Abstraction for Reinforcement Learning,"['Vihang Patil', 'Markus Hofmarcher', 'Elisabeth Rumetshofer', 'Sepp Hochreiter']","Learning agents with reinforcement learning is difficult when dealing with
long trajectories that involve a large number of states. To address these
learning problems effectively, the number of states can be reduced by abstract
representations that cluster states. In principle, deep reinforcement learning
can find abstract states, but end-to-end learning is unstable. We propose
contrastive abstraction learning to find abstract states, where we assume that
successive states in a trajectory belong to the same abstract state. Such
abstract states may be basic locations, achieved subgoals, inventory, or health
conditions. Contrastive abstraction learning first constructs clusters of state
representations by contrastive learning and then applies modern Hopfield
networks to determine the abstract states. The first phase of contrastive
abstraction learning is self-supervised learning, where contrastive learning
forces states with sequential proximity to have similar representations. The
second phase uses modern Hopfield networks to map similar state representations
to the same fixed point, i.e.\ to an abstract state. The level of abstraction
can be adjusted by determining the number of fixed points of the modern
Hopfield network. Furthermore, \textit{contrastive abstraction learning} does
not require rewards and facilitates efficient reinforcement learning for a wide
range of downstream tasks. Our experiments demonstrate the effectiveness of
contrastive abstraction learning for reinforcement learning.",2024-10-01T13:56:09Z,http://arxiv.org/pdf/2410.00704v1,"['cs.LG', 'cs.AI']"
1709.05067v1,Deep Reinforcement Learning for Conversational AI,"['Mahipal Jadeja', 'Neelanshi Varia', 'Agam Shah']","Deep reinforcement learning is revolutionizing the artificial intelligence
field. Currently, it serves as a good starting point for constructing
intelligent autonomous systems which offer a better knowledge of the visual
world. It is possible to scale deep reinforcement learning with the use of deep
learning and do amazing tasks such as use of pixels in playing video games. In
this paper, key concepts of deep reinforcement learning including reward
function, differences between reinforcement learning and supervised learning
and models for implementation of reinforcement are discussed. Key challenges
related to the implementation of reinforcement learning in conversational AI
domain are identified as well as discussed in detail. Various conversational
models which are based on deep reinforcement learning (as well as deep
learning) are also discussed. In summary, this paper discusses key aspects of
deep reinforcement learning which are crucial for designing an efficient
conversational AI.",2017-09-15T06:18:33Z,http://arxiv.org/pdf/1709.05067v1,['cs.AI']
2203.16464v3,"Towards Interpretable Deep Reinforcement Learning Models via Inverse
  Reinforcement Learning","['Sean Xie', 'Soroush Vosoughi', 'Saeed Hassanpour']","Artificial intelligence, particularly through recent advancements in deep
learning, has achieved exceptional performances in many tasks in fields such as
natural language processing and computer vision. In addition to desirable
evaluation metrics, a high level of interpretability is often required for
these models to be reliably utilized. Therefore, explanations that offer
insight into the process by which a model maps its inputs onto its outputs are
much sought-after. Unfortunately, the current black box nature of machine
learning models is still an unresolved issue and this very nature prevents
researchers from learning and providing explicative descriptions for a model's
behavior and final predictions. In this work, we propose a novel framework
utilizing Adversarial Inverse Reinforcement Learning that can provide global
explanations for decisions made by a Reinforcement Learning model and capture
intuitive tendencies that the model follows by summarizing the model's
decision-making process.",2022-03-30T17:01:59Z,http://arxiv.org/pdf/2203.16464v3,"['cs.LG', 'cs.AI']"
1007.2049v1,Reinforcement Learning via AIXI Approximation,"['Joel Veness', 'Kee Siong Ng', 'Marcus Hutter', 'David Silver']","This paper introduces a principled approach for the design of a scalable
general reinforcement learning agent. This approach is based on a direct
approximation of AIXI, a Bayesian optimality notion for general reinforcement
learning agents. Previously, it has been unclear whether the theory of AIXI
could motivate the design of practical algorithms. We answer this hitherto open
question in the affirmative, by providing the first computationally feasible
approximation to the AIXI agent. To develop our approximation, we introduce a
Monte Carlo Tree Search algorithm along with an agent-specific extension of the
Context Tree Weighting algorithm. Empirically, we present a set of encouraging
results on a number of stochastic, unknown, and partially observable domains.",2010-07-13T08:48:18Z,http://arxiv.org/pdf/1007.2049v1,['cs.LG']
1108.3614v1,Feature Reinforcement Learning In Practice,"['Phuong Nguyen', 'Peter Sunehag', 'Marcus Hutter']","Following a recent surge in using history-based methods for resolving
perceptual aliasing in reinforcement learning, we introduce an algorithm based
on the feature reinforcement learning framework called PhiMDP. To create a
practical algorithm we devise a stochastic search procedure for a class of
context trees based on parallel tempering and a specialized proposal
distribution. We provide the first empirical evaluation for PhiMDP. Our
proposed algorithm achieves superior performance to the classical U-tree
algorithm and the recent active-LZ algorithm, and is competitive with
MC-AIXI-CTW that maintains a bayesian mixture over all context trees up to a
chosen depth.We are encouraged by our ability to compete with this
sophisticated method using an algorithm that simply picks one single model, and
uses Q-learning on the corresponding MDP. Our PhiMDP algorithm is much simpler,
yet consumes less time and memory. These results show promise for our future
work on attacking more complex and larger problems.",2011-08-18T03:50:35Z,http://arxiv.org/pdf/1108.3614v1,"['cs.AI', 'cs.RO']"
1206.6449v1,Monte Carlo Bayesian Reinforcement Learning,"['Yi Wang', 'Kok Sung Won', 'David Hsu', 'Wee Sun Lee']","Bayesian reinforcement learning (BRL) encodes prior knowledge of the world in
a model and represents uncertainty in model parameters by maintaining a
probability distribution over them. This paper presents Monte Carlo BRL
(MC-BRL), a simple and general approach to BRL. MC-BRL samples a priori a
finite set of hypotheses for the model parameter values and forms a discrete
partially observable Markov decision process (POMDP) whose state space is a
cross product of the state space for the reinforcement learning task and the
sampled model parameter space. The POMDP does not require conjugate
distributions for belief representation, as earlier works do, and can be solved
relatively easily with point-based approximation algorithms. MC-BRL naturally
handles both fully and partially observable worlds. Theoretical and
experimental results show that the discrete POMDP approximates the underlying
BRL task well with guaranteed performance.",2012-06-27T19:59:59Z,http://arxiv.org/pdf/1206.6449v1,"['cs.LG', 'stat.ML']"
1706.04711v2,Reinforcement Learning under Model Mismatch,"['Aurko Roy', 'Huan Xu', 'Sebastian Pokutta']","We study reinforcement learning under model misspecification, where we do not
have access to the true environment but only to a reasonably close
approximation to it. We address this problem by extending the framework of
robust MDPs to the model-free Reinforcement Learning setting, where we do not
have access to the model parameters, but can only sample states from it. We
define robust versions of Q-learning, SARSA, and TD-learning and prove
convergence to an approximately optimal robust policy and approximate value
function respectively. We scale up the robust algorithms to large MDPs via
function approximation and prove convergence under two different settings. We
prove convergence of robust approximate policy iteration and robust approximate
value iteration for linear architectures (under mild assumptions). We also
define a robust loss function, the mean squared robust projected Bellman error
and give stochastic gradient descent algorithms that are guaranteed to converge
to a local minimum.",2017-06-15T01:06:05Z,http://arxiv.org/pdf/1706.04711v2,"['cs.LG', 'stat.ML']"
1803.00590v2,Hierarchical Imitation and Reinforcement Learning,"['Hoang M. Le', 'Nan Jiang', 'Alekh Agarwal', 'Miroslav Dudík', 'Yisong Yue', 'Hal Daumé III']","We study how to effectively leverage expert feedback to learn sequential
decision-making policies. We focus on problems with sparse rewards and long
time horizons, which typically pose significant challenges in reinforcement
learning. We propose an algorithmic framework, called hierarchical guidance,
that leverages the hierarchical structure of the underlying problem to
integrate different modes of expert interaction. Our framework can incorporate
different combinations of imitation learning (IL) and reinforcement learning
(RL) at different levels, leading to dramatic reductions in both expert effort
and cost of exploration. Using long-horizon benchmarks, including Montezuma's
Revenge, we demonstrate that our approach can learn significantly faster than
hierarchical RL, and be significantly more label-efficient than standard IL. We
also theoretically analyze labeling cost for certain instantiations of our
framework.",2018-03-01T19:12:27Z,http://arxiv.org/pdf/1803.00590v2,"['cs.LG', 'cs.AI', 'stat.ML']"
1805.07563v1,Reinforcement Learning of Theorem Proving,"['Cezary Kaliszyk', 'Josef Urban', 'Henryk Michalewski', 'Mirek Olšák']","We introduce a theorem proving algorithm that uses practically no domain
heuristics for guiding its connection-style proof search. Instead, it runs many
Monte-Carlo simulations guided by reinforcement learning from previous proof
attempts. We produce several versions of the prover, parameterized by different
learning and guiding algorithms. The strongest version of the system is trained
on a large corpus of mathematical problems and evaluated on previously unseen
problems. The trained system solves within the same number of inferences over
40% more problems than a baseline prover, which is an unusually high
improvement in this hard AI domain. To our knowledge this is the first time
reinforcement learning has been convincingly applied to solving general
mathematical problems on a large scale.",2018-05-19T10:05:43Z,http://arxiv.org/pdf/1805.07563v1,"['cs.AI', 'cs.LG', 'cs.LO']"
1812.05551v3,Exploration Conscious Reinforcement Learning Revisited,"['Lior Shani', 'Yonathan Efroni', 'Shie Mannor']","The Exploration-Exploitation tradeoff arises in Reinforcement Learning when
one cannot tell if a policy is optimal. Then, there is a constant need to
explore new actions instead of exploiting past experience. In practice, it is
common to resolve the tradeoff by using a fixed exploration mechanism, such as
$\epsilon$-greedy exploration or by adding Gaussian noise, while still trying
to learn an optimal policy. In this work, we take a different approach and
study exploration-conscious criteria, that result in optimal policies with
respect to the exploration mechanism. Solving these criteria, as we establish,
amounts to solving a surrogate Markov Decision Process. We continue and analyze
properties of exploration-conscious optimal policies and characterize two
general approaches to solve such criteria. Building on the approaches, we apply
simple changes in existing tabular and deep Reinforcement Learning algorithms
and empirically demonstrate superior performance relatively to their
non-exploration-conscious counterparts, both for discrete and continuous action
spaces.",2018-12-13T18:08:04Z,http://arxiv.org/pdf/1812.05551v3,"['cs.LG', 'stat.ML']"
1908.03568v3,Behaviour Suite for Reinforcement Learning,"['Ian Osband', 'Yotam Doron', 'Matteo Hessel', 'John Aslanides', 'Eren Sezener', 'Andre Saraiva', 'Katrina McKinney', 'Tor Lattimore', 'Csaba Szepesvari', 'Satinder Singh', 'Benjamin Van Roy', 'Richard Sutton', 'David Silver', 'Hado Van Hasselt']","This paper introduces the Behaviour Suite for Reinforcement Learning, or
bsuite for short. bsuite is a collection of carefully-designed experiments that
investigate core capabilities of reinforcement learning (RL) agents with two
objectives. First, to collect clear, informative and scalable problems that
capture key issues in the design of general and efficient learning algorithms.
Second, to study agent behaviour through their performance on these shared
benchmarks. To complement this effort, we open source
github.com/deepmind/bsuite, which automates evaluation and analysis of any
agent on bsuite. This library facilitates reproducible and accessible research
on the core issues in RL, and ultimately the design of superior learning
algorithms. Our code is Python, and easy to use within existing projects. We
include examples with OpenAI Baselines, Dopamine as well as new reference
implementations. Going forward, we hope to incorporate more excellent
experiments from the research community, and commit to a periodic review of
bsuite from a committee of prominent researchers.",2019-08-09T08:34:08Z,http://arxiv.org/pdf/1908.03568v3,"['cs.LG', 'cs.AI', 'stat.ML']"
1908.06012v1,Model-based Lookahead Reinforcement Learning,"['Zhang-Wei Hong', 'Joni Pajarinen', 'Jan Peters']","Model-based Reinforcement Learning (MBRL) allows data-efficient learning
which is required in real world applications such as robotics. However, despite
the impressive data-efficiency, MBRL does not achieve the final performance of
state-of-the-art Model-free Reinforcement Learning (MFRL) methods. We leverage
the strengths of both realms and propose an approach that obtains high
performance with a small amount of data. In particular, we combine MFRL and
Model Predictive Control (MPC). While MFRL's strength in exploration allows us
to train a better forward dynamics model for MPC, MPC improves the performance
of the MFRL policy by sampling-based planning. The experimental results in
standard continuous control benchmarks show that our approach can achieve
MFRL`s level of performance while being as data-efficient as MBRL.",2019-08-15T04:10:13Z,http://arxiv.org/pdf/1908.06012v1,"['cs.LG', 'cs.AI', 'stat.ML']"
2004.11812v5,Self-Paced Deep Reinforcement Learning,"['Pascal Klink', ""Carlo D'Eramo"", 'Jan Peters', 'Joni Pajarinen']","Curriculum reinforcement learning (CRL) improves the learning speed and
stability of an agent by exposing it to a tailored series of tasks throughout
learning. Despite empirical successes, an open question in CRL is how to
automatically generate a curriculum for a given reinforcement learning (RL)
agent, avoiding manual design. In this paper, we propose an answer by
interpreting the curriculum generation as an inference problem, where
distributions over tasks are progressively learned to approach the target task.
This approach leads to an automatic curriculum generation, whose pace is
controlled by the agent, with solid theoretical motivation and easily
integrated with deep RL algorithms. In the conducted experiments, the curricula
generated with the proposed algorithm significantly improve learning
performance across several environments and deep RL algorithms, matching or
outperforming state-of-the-art existing CRL algorithms.",2020-04-24T15:48:07Z,http://arxiv.org/pdf/2004.11812v5,"['cs.LG', 'cs.AI', 'stat.ML']"
2108.02323v3,Active Reinforcement Learning over MDPs,"['Qi Yang', 'Peng Yang', 'Ke Tang']","The past decade has seen the rapid development of Reinforcement Learning,
which acquires impressive performance with numerous training resources.
However, one of the greatest challenges in RL is generalization efficiency
(i.e., generalization performance in a unit time). This paper proposes a
framework of Active Reinforcement Learning (ARL) over MDPs to improve
generalization efficiency in a limited resource by instance selection. Given a
number of instances, the algorithm chooses out valuable instances as training
sets while training the policy, thereby costing fewer resources. Unlike
existing approaches, we attempt to actively select and use training data rather
than train on all the given data, thereby costing fewer resources. Furthermore,
we introduce a general instance evaluation metrics and selection mechanism into
the framework. Experiments results reveal that the proposed framework with
Proximal Policy Optimization as policy optimizer can effectively improve
generalization efficiency than unselect-ed and unbiased selected methods.",2021-08-05T00:18:11Z,http://arxiv.org/pdf/2108.02323v3,['cs.LG']
2001.11718v1,Locally Private Distributed Reinforcement Learning,"['Hajime Ono', 'Tsubasa Takahashi']","We study locally differentially private algorithms for reinforcement learning
to obtain a robust policy that performs well across distributed private
environments. Our algorithm protects the information of local agents' models
from being exploited by adversarial reverse engineering. Since a local policy
is strongly being affected by the individual environment, the output of the
agent may release the private information unconsciously. In our proposed
algorithm, local agents update the model in their environments and report noisy
gradients designed to satisfy local differential privacy (LDP) that gives a
rigorous local privacy guarantee. By utilizing a set of reported noisy
gradients, a central aggregator updates its model and delivers it to different
local agents. In our empirical evaluation, we demonstrate how our method
performs well under LDP. To the best of our knowledge, this is the first work
that actualizes distributed reinforcement learning under LDP. This work enables
us to obtain a robust agent that performs well across distributed private
environments.",2020-01-31T09:03:23Z,http://arxiv.org/pdf/2001.11718v1,"['cs.LG', 'cs.CR', 'stat.ML']"
2202.04337v1,Scenario-Assisted Deep Reinforcement Learning,"['Raz Yerushalmi', 'Guy Amir', 'Achiya Elyasaf', 'David Harel', 'Guy Katz', 'Assaf Marron']","Deep reinforcement learning has proven remarkably useful in training agents
from unstructured data. However, the opacity of the produced agents makes it
difficult to ensure that they adhere to various requirements posed by human
engineers. In this work-in-progress report, we propose a technique for
enhancing the reinforcement learning training process (specifically, its reward
calculation), in a way that allows human engineers to directly contribute their
expert knowledge, making the agent under training more likely to comply with
various relevant constraints. Moreover, our proposed approach allows
formulating these constraints using advanced model engineering techniques, such
as scenario-based modeling. This mix of black-box learning-based tools with
classical modeling approaches could produce systems that are effective and
efficient, but are also more transparent and maintainable. We evaluated our
technique using a case-study from the domain of internet congestion control,
obtaining promising results.",2022-02-09T08:46:13Z,http://arxiv.org/pdf/2202.04337v1,"['cs.LG', 'cs.SE', 'cs.SY', 'eess.SY']"
1709.02349v2,A Deep Reinforcement Learning Chatbot,"['Iulian V. Serban', 'Chinnadhurai Sankar', 'Mathieu Germain', 'Saizheng Zhang', 'Zhouhan Lin', 'Sandeep Subramanian', 'Taesup Kim', 'Michael Pieper', 'Sarath Chandar', 'Nan Rosemary Ke', 'Sai Rajeshwar', 'Alexandre de Brebisson', 'Jose M. R. Sotelo', 'Dendi Suhubdy', 'Vincent Michalski', 'Alexandre Nguyen', 'Joelle Pineau', 'Yoshua Bengio']","We present MILABOT: a deep reinforcement learning chatbot developed by the
Montreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prize
competition. MILABOT is capable of conversing with humans on popular small talk
topics through both speech and text. The system consists of an ensemble of
natural language generation and retrieval models, including template-based
models, bag-of-words models, sequence-to-sequence neural network and latent
variable neural network models. By applying reinforcement learning to
crowdsourced data and real-world user interactions, the system has been trained
to select an appropriate response from the models in its ensemble. The system
has been evaluated through A/B testing with real-world users, where it
performed significantly better than many competing systems. Due to its machine
learning architecture, the system is likely to improve with additional data.",2017-09-07T16:51:09Z,http://arxiv.org/pdf/1709.02349v2,"['cs.CL', 'cs.AI', 'cs.LG', 'cs.NE', 'stat.ML', 'I.5.1; I.2.7']"
1907.07503v1,Photonic architecture for reinforcement learning,"['Fulvio Flamini', 'Arne Hamann', 'Sofiène Jerbi', 'Lea M. Trenkwalder', 'Hendrik Poulsen Nautrup', 'Hans J. Briegel']","The last decade has seen an unprecedented growth in artificial intelligence
and photonic technologies, both of which drive the limits of modern-day
computing devices. In line with these recent developments, this work brings
together the state of the art of both fields within the framework of
reinforcement learning. We present the blueprint for a photonic implementation
of an active learning machine incorporating contemporary algorithms such as
SARSA, Q-learning, and projective simulation. We numerically investigate its
performance within typical reinforcement learning environments, showing that
realistic levels of experimental noise can be tolerated or even be beneficial
for the learning process. Remarkably, the architecture itself enables
mechanisms of abstraction and generalization, two features which are often
considered key ingredients for artificial intelligence. The proposed
architecture, based on single-photon evolution on a mesh of tunable
beamsplitters, is simple, scalable, and a first integration in portable systems
appears to be within the reach of near-term technology.",2019-07-17T13:23:58Z,http://arxiv.org/pdf/1907.07503v1,"['quant-ph', 'cs.LG']"
1909.04751v1,Reinforcement Learning and Video Games,['Yue Zheng'],"Reinforcement learning has exceeded human-level performance in game playing
AI with deep learning methods according to the experiments from DeepMind on Go
and Atari games. Deep learning solves high dimension input problems which stop
the development of reinforcement for many years. This study uses both two
techniques to create several agents with different algorithms that successfully
learn to play T-rex Runner. Deep Q network algorithm and three types of
improvements are implemented to train the agent. The results from some of them
are far from satisfactory but others are better than human experts. Batch
normalization is a method to solve internal covariate shift problems in deep
neural network. The positive influence of this on reinforcement learning has
also been proved in this study.",2019-09-10T20:51:42Z,http://arxiv.org/pdf/1909.04751v1,"['cs.LG', 'stat.ML']"
1910.02826v1,Self-Paced Contextual Reinforcement Learning,"['Pascal Klink', 'Hany Abdulsamad', 'Boris Belousov', 'Jan Peters']","Generalization and adaptation of learned skills to novel situations is a core
requirement for intelligent autonomous robots. Although contextual
reinforcement learning provides a principled framework for learning and
generalization of behaviors across related tasks, it generally relies on
uninformed sampling of environments from an unknown, uncontrolled context
distribution, thus missing the benefits of structured, sequential learning. We
introduce a novel relative entropy reinforcement learning algorithm that gives
the agent the freedom to control the intermediate task distribution, allowing
for its gradual progression towards the target context distribution. Empirical
evaluation shows that the proposed curriculum learning scheme drastically
improves sample efficiency and enables learning in scenarios with both broad
and sharp target context distributions in which classical approaches perform
sub-optimally.",2019-10-07T14:40:53Z,http://arxiv.org/pdf/1910.02826v1,"['cs.LG', 'stat.ML']"
2011.00791v1,Cooperative Heterogeneous Deep Reinforcement Learning,"['Han Zheng', 'Pengfei Wei', 'Jing Jiang', 'Guodong Long', 'Qinghua Lu', 'Chengqi Zhang']","Numerous deep reinforcement learning agents have been proposed, and each of
them has its strengths and flaws. In this work, we present a Cooperative
Heterogeneous Deep Reinforcement Learning (CHDRL) framework that can learn a
policy by integrating the advantages of heterogeneous agents. Specifically, we
propose a cooperative learning framework that classifies heterogeneous agents
into two classes: global agents and local agents. Global agents are off-policy
agents that can utilize experiences from the other agents. Local agents are
either on-policy agents or population-based evolutionary algorithms (EAs)
agents that can explore the local area effectively. We employ global agents,
which are sample-efficient, to guide the learning of local agents so that local
agents can benefit from sample-efficient agents and simultaneously maintain
their advantages, e.g., stability. Global agents also benefit from effective
local searches. Experimental studies on a range of continuous control tasks
from the Mujoco benchmark show that CHDRL achieves better performance compared
with state-of-the-art baselines.",2020-11-02T07:39:09Z,http://arxiv.org/pdf/2011.00791v1,"['cs.LG', 'cs.AI']"
1902.03079v4,Reinforcement Learning from Hierarchical Critics,"['Zehong Cao', 'Chin-Teng Lin']","In this study, we investigate the use of global information to speed up the
learning process and increase the cumulative rewards of reinforcement learning
(RL) in competition tasks. Within the actor-critic RL, we introduce multiple
cooperative critics from two levels of the hierarchy and propose a
reinforcement learning from hierarchical critics (RLHC) algorithm. In our
approach, each agent receives value information from local and global critics
regarding a competition task and accesses multiple cooperative critics in a
top-down hierarchy. Thus, each agent not only receives low-level details but
also considers coordination from higher levels, thereby obtaining global
information to improve the training performance. Then, we test the proposed
RLHC algorithm against the benchmark algorithm, proximal policy optimisation
(PPO), for two experimental scenarios performed in a Unity environment
consisting of tennis and soccer agents' competitions. The results showed that
RLHC outperforms the benchmark on both competition tasks.",2019-02-08T13:55:11Z,http://arxiv.org/pdf/1902.03079v4,"['cs.LG', 'cs.MA', 'stat.ML']"
1906.00131v1,Decision-Making in Reinforcement Learning,"['Arsh Javed Rehman', 'Pradeep Tomar']","In this research work, probabilistic decision-making approaches are studied,
e.g. Bayesian and Boltzmann strategies, along with various deterministic
exploration strategies, e.g. greedy, epsilon-Greedy and random approaches. In
this research work, a comparative study has been done between probabilistic and
deterministic decision-making approaches, the experiments are performed in
OpenAI gym environment, solving Cart Pole problem. This research work discusses
about the Bayesian approach to decision-making in deep reinforcement learning,
and about dropout, how it can reduce the computational cost. All the
exploration approaches are compared. It also discusses about the importance of
exploration in deep reinforcement learning, and how improving exploration
strategies may help in science and technology. This research work shows how
probabilistic decision-making approaches are better in the long run as compared
to the deterministic approaches. When there is uncertainty, Bayesian dropout
approach proved to be better than all other approaches in this research work.",2019-06-01T02:36:42Z,http://arxiv.org/pdf/1906.00131v1,['cs.AI']
2007.09998v3,Lagrangian Duality in Reinforcement Learning,['Pranay Pasula'],"Although duality is used extensively in certain fields, such as supervised
learning in machine learning, it has been much less explored in others, such as
reinforcement learning (RL). In this paper, we show how duality is involved in
a variety of RL work, from that which spearheaded the field, such as Richard
Bellman's value iteration, to that which was done within just the past few
years yet has already had significant impact, such as TRPO, A3C, and GAIL. We
show that duality is not uncommon in reinforcement learning, especially when
value iteration, or dynamic programming, is used or when first or second order
approximations are made to transform initially intractable problems into
tractable convex programs.",2020-07-20T10:55:12Z,http://arxiv.org/pdf/2007.09998v3,"['cs.LG', 'cs.AI', 'math.OC', 'stat.ML']"
2008.06036v2,Reinforcement Learning with Trajectory Feedback,"['Yonathan Efroni', 'Nadav Merlis', 'Shie Mannor']","The standard feedback model of reinforcement learning requires revealing the
reward of every visited state-action pair. However, in practice, it is often
the case that such frequent feedback is not available. In this work, we take a
first step towards relaxing this assumption and require a weaker form of
feedback, which we refer to as \emph{trajectory feedback}. Instead of observing
the reward obtained after every action, we assume we only receive a score that
represents the quality of the whole trajectory observed by the agent, namely,
the sum of all rewards obtained over this trajectory. We extend reinforcement
learning algorithms to this setting, based on least-squares estimation of the
unknown reward, for both the known and unknown transition model cases, and
study the performance of these algorithms by analyzing their regret. For cases
where the transition model is unknown, we offer a hybrid optimistic-Thompson
Sampling approach that results in a tractable algorithm.",2020-08-13T17:49:18Z,http://arxiv.org/pdf/2008.06036v2,"['cs.LG', 'stat.ML']"
2102.11329v2,Action Redundancy in Reinforcement Learning,"['Nir Baram', 'Guy Tennenholtz', 'Shie Mannor']","Maximum Entropy (MaxEnt) reinforcement learning is a powerful learning
paradigm which seeks to maximize return under entropy regularization. However,
action entropy does not necessarily coincide with state entropy, e.g., when
multiple actions produce the same transition. Instead, we propose to maximize
the transition entropy, i.e., the entropy of next states. We show that
transition entropy can be described by two terms; namely, model-dependent
transition entropy and action redundancy. Particularly, we explore the latter
in both deterministic and stochastic settings and develop tractable
approximation methods in a near model-free setup. We construct algorithms to
minimize action redundancy and demonstrate their effectiveness on a synthetic
environment with multiple redundant actions as well as contemporary benchmarks
in Atari and Mujoco. Our results suggest that action redundancy is a
fundamental problem in reinforcement learning.",2021-02-22T19:47:26Z,http://arxiv.org/pdf/2102.11329v2,"['cs.LG', 'cs.AI']"
2109.09037v1,Dual Behavior Regularized Reinforcement Learning,"['Chapman Siu', 'Jason Traish', 'Richard Yi Da Xu']","Reinforcement learning has been shown to perform a range of complex tasks
through interaction with an environment or collected leveraging experience.
However, many of these approaches presume optimal or near optimal experiences
or the presence of a consistent environment. In this work we propose dual,
advantage-based behavior policy based on counterfactual regret minimization. We
demonstrate the flexibility of this approach and how it can be adapted to
online contexts where the environment is available to collect experiences and a
variety of other contexts. We demonstrate this new algorithm can outperform
several strong baseline models in different contexts based on a range of
continuous environments. Additional ablations provide insights into how our
dual behavior regularized reinforcement learning approach is designed compared
with other plausible modifications and demonstrates its ability to generalize.",2021-09-19T00:47:18Z,http://arxiv.org/pdf/2109.09037v1,"['cs.LG', 'stat.ML']"
2110.15191v1,URLB: Unsupervised Reinforcement Learning Benchmark,"['Michael Laskin', 'Denis Yarats', 'Hao Liu', 'Kimin Lee', 'Albert Zhan', 'Kevin Lu', 'Catherine Cang', 'Lerrel Pinto', 'Pieter Abbeel']","Deep Reinforcement Learning (RL) has emerged as a powerful paradigm to solve
a range of complex yet specific control tasks. Yet training generalist agents
that can quickly adapt to new tasks remains an outstanding challenge. Recent
advances in unsupervised RL have shown that pre-training RL agents with
self-supervised intrinsic rewards can result in efficient adaptation. However,
these algorithms have been hard to compare and develop due to the lack of a
unified benchmark. To this end, we introduce the Unsupervised Reinforcement
Learning Benchmark (URLB). URLB consists of two phases: reward-free
pre-training and downstream task adaptation with extrinsic rewards. Building on
the DeepMind Control Suite, we provide twelve continuous control tasks from
three domains for evaluation and open-source code for eight leading
unsupervised RL methods. We find that the implemented baselines make progress
but are not able to solve URLB and propose directions for future research.",2021-10-28T15:07:01Z,http://arxiv.org/pdf/2110.15191v1,"['cs.LG', 'cs.AI', 'cs.RO']"
2204.03973v1,Gradient dynamics in reinforcement learning,"['Riccardo Fabbricatore', 'Vladimir V. Palyulin']","Despite the success achieved by the analysis of supervised learning
algorithms in the framework of statistical mechanics, reinforcement learning
has remained largely untouched. Here we move towards closing the gap by
analyzing the dynamics of the policy gradient algorithm. For a convex problem,
we show that it obeys a drift-diffusion motion with coeffcients tuned by
learning rate. Furthermore, we propose a mapping between a non-convex
reinforcement learning problem and a disordered system. This mapping enables us
to show how the learning rate acts as an effective temperature and thus is
capable of smoothing rough landscapes, corroborating what is displayed by the
drift-diffusive description and paving the way for physics-inspired algorithmic
optimization based on annealing procedures in disordered systems.",2022-04-08T10:01:54Z,http://arxiv.org/pdf/2204.03973v1,"['cond-mat.stat-mech', 'cond-mat.dis-nn', 'physics.comp-ph']"
2205.05569v1,Delayed Reinforcement Learning by Imitation,"['Pierre Liotet', 'Davide Maran', 'Lorenzo Bisi', 'Marcello Restelli']","When the agent's observations or interactions are delayed, classic
reinforcement learning tools usually fail. In this paper, we propose a simple
yet new and efficient solution to this problem. We assume that, in the
undelayed environment, an efficient policy is known or can be easily learned,
but the task may suffer from delays in practice and we thus want to take them
into account. We present a novel algorithm, Delayed Imitation with Dataset
Aggregation (DIDA), which builds upon imitation learning methods to learn how
to act in a delayed environment from undelayed demonstrations. We provide a
theoretical analysis of the approach that will guide the practical design of
DIDA. These results are also of general interest in the delayed reinforcement
learning literature by providing bounds on the performance between delayed and
undelayed tasks, under smoothness conditions. We show empirically that DIDA
obtains high performances with a remarkable sample efficiency on a variety of
tasks, including robotic locomotion, classic control, and trading.",2022-05-11T15:27:33Z,http://arxiv.org/pdf/2205.05569v1,['cs.LG']
2212.13769v1,Lexicographic Multi-Objective Reinforcement Learning,"['Joar Skalse', 'Lewis Hammond', 'Charlie Griffin', 'Alessandro Abate']","In this work we introduce reinforcement learning techniques for solving
lexicographic multi-objective problems. These are problems that involve
multiple reward signals, and where the goal is to learn a policy that maximises
the first reward signal, and subject to this constraint also maximises the
second reward signal, and so on. We present a family of both action-value and
policy gradient algorithms that can be used to solve such problems, and prove
that they converge to policies that are lexicographically optimal. We evaluate
the scalability and performance of these algorithms empirically, demonstrating
their practical applicability. As a more specific application, we show how our
algorithms can be used to impose safety constraints on the behaviour of an
agent, and compare their performance in this context with that of other
constrained reinforcement learning algorithms.",2022-12-28T10:22:36Z,http://arxiv.org/pdf/2212.13769v1,['cs.LG']
2302.14176v1,Reinforcement Learning with Depreciating Assets,"['Taylor Dohmen', 'Ashutosh Trivedi']","A basic assumption of traditional reinforcement learning is that the value of
a reward does not change once it is received by an agent. The present work
forgoes this assumption and considers the situation where the value of a reward
decays proportionally to the time elapsed since it was obtained. Emphasizing
the inflection point occurring at the time of payment, we use the term asset to
refer to a reward that is currently in the possession of an agent. Adopting
this language, we initiate the study of depreciating assets within the
framework of infinite-horizon quantitative optimization. In particular, we
propose a notion of asset depreciation, inspired by classical exponential
discounting, where the value of an asset is scaled by a fixed discount factor
at each time step after it is obtained by the agent. We formulate a
Bellman-style equational characterization of optimality in this context and
develop a model-free reinforcement learning approach to obtain optimal
policies.",2023-02-27T22:28:58Z,http://arxiv.org/pdf/2302.14176v1,"['cs.AI', 'cs.CE', 'math.OC']"
2304.09869v1,Evolving Constrained Reinforcement Learning Policy,"['Chengpeng Hu', 'Jiyuan Pei', 'Jialin Liu', 'Xin Yao']","Evolutionary algorithms have been used to evolve a population of actors to
generate diverse experiences for training reinforcement learning agents, which
helps to tackle the temporal credit assignment problem and improves the
exploration efficiency. However, when adapting this approach to address
constrained problems, balancing the trade-off between the reward and constraint
violation is hard. In this paper, we propose a novel evolutionary constrained
reinforcement learning (ECRL) algorithm, which adaptively balances the reward
and constraint violation with stochastic ranking, and at the same time,
restricts the policy's behaviour by maintaining a set of Lagrange relaxation
coefficients with a constraint buffer. Extensive experiments on robotic control
benchmarks show that our ECRL achieves outstanding performance compared to
state-of-the-art algorithms. Ablation analysis shows the benefits of
introducing stochastic ranking and constraint buffer.",2023-04-19T03:54:31Z,http://arxiv.org/pdf/2304.09869v1,"['cs.NE', 'cs.AI', 'cs.LG']"
2304.14421v1,One-Step Distributional Reinforcement Learning,"['Mastane Achab', 'Reda Alami', 'Yasser Abdelaziz Dahou Djilali', 'Kirill Fedyanin', 'Eric Moulines']","Reinforcement learning (RL) allows an agent interacting sequentially with an
environment to maximize its long-term expected return. In the distributional RL
(DistrRL) paradigm, the agent goes beyond the limit of the expected value, to
capture the underlying probability distribution of the return across all time
steps. The set of DistrRL algorithms has led to improved empirical performance.
Nevertheless, the theory of DistrRL is still not fully understood, especially
in the control case. In this paper, we present the simpler one-step
distributional reinforcement learning (OS-DistrRL) framework encompassing only
the randomness induced by the one-step dynamics of the environment. Contrary to
DistrRL, we show that our approach comes with a unified theory for both policy
evaluation and control. Indeed, we propose two OS-DistrRL algorithms for which
we provide an almost sure convergence analysis. The proposed approach compares
favorably with categorical DistrRL on various environments.",2023-04-27T06:57:00Z,http://arxiv.org/pdf/2304.14421v1,"['cs.LG', 'stat.ML']"
2402.09900v3,Recurrent Reinforcement Learning with Memoroids,"['Steven Morad', 'Chris Lu', 'Ryan Kortvelesy', 'Stephan Liwicki', 'Jakob Foerster', 'Amanda Prorok']","Memory models such as Recurrent Neural Networks (RNNs) and Transformers
address Partially Observable Markov Decision Processes (POMDPs) by mapping
trajectories to latent Markov states. Neither model scales particularly well to
long sequences, especially compared to an emerging class of memory models
called Linear Recurrent Models. We discover that the recurrent update of these
models resembles a monoid, leading us to reformulate existing models using a
novel monoid-based framework that we call memoroids. We revisit the traditional
approach to batching in recurrent reinforcement learning, highlighting
theoretical and empirical deficiencies. We leverage memoroids to propose a
batching method that improves sample efficiency, increases the return, and
simplifies the implementation of recurrent loss functions in reinforcement
learning.",2024-02-15T11:56:53Z,http://arxiv.org/pdf/2402.09900v3,"['cs.LG', 'cs.AI']"
2411.04225v2,Approximate Equivariance in Reinforcement Learning,"['Jung Yeon Park', 'Sujay Bhatt', 'Sihan Zeng', 'Lawson L. S. Wong', 'Alec Koppel', 'Sumitra Ganesh', 'Robin Walters']","Equivariant neural networks have shown great success in reinforcement
learning, improving sample efficiency and generalization when there is symmetry
in the task. However, in many problems, only approximate symmetry is present,
which makes imposing exact symmetry inappropriate. Recently, approximately
equivariant networks have been proposed for supervised classification and
modeling physical systems. In this work, we develop approximately equivariant
algorithms in reinforcement learning (RL). We define approximately equivariant
MDPs and theoretically characterize the effect of approximate equivariance on
the optimal $Q$ function. We propose novel RL architectures using relaxed group
and steerable convolutions and experiment on several continuous control domains
and stock trading with real financial data. Our results demonstrate that the
approximately equivariant network performs on par with exactly equivariant
networks when exact symmetries are present, and outperforms them when the
domains exhibit approximate symmetry. As an added byproduct of these
techniques, we observe increased robustness to noise at test time. Our code is
available at https://github.com/jypark0/approx_equiv_rl.",2024-11-06T19:44:46Z,http://arxiv.org/pdf/2411.04225v2,['cs.LG']
2411.06389v1,Optimal Execution with Reinforcement Learning,"['Yadh Hafsi', 'Edoardo Vittori']","This study investigates the development of an optimal execution strategy
through reinforcement learning, aiming to determine the most effective approach
for traders to buy and sell inventory within a limited time frame. Our proposed
model leverages input features derived from the current state of the limit
order book.
  To simulate this environment and overcome the limitations associated with
relying on historical data, we utilize the multi-agent market simulator ABIDES,
which provides a diverse range of depth levels within the limit order book.
  We present a custom MDP formulation followed by the results of our
methodology and benchmark the performance against standard execution
strategies. Our findings suggest that the reinforcement learning-based approach
demonstrates significant potential.",2024-11-10T08:21:03Z,http://arxiv.org/pdf/2411.06389v1,"['q-fin.TR', 'cs.LG']"
2503.02612v2,Reinforcement Learning-based Threat Assessment,"['Wuzhou Sun', 'Siyi Li', 'Qingxiang Zou', 'Zixing Liao']","In some game scenarios, due to the uncertainty of the number of enemy units
and the priority of various attributes, the evaluation of the threat level of
enemy units as well as the screening has been a challenging research topic, and
the core difficulty lies in how to reasonably set the priority of different
attributes in order to achieve quantitative evaluation of the threat. In this
paper, we innovatively transform the problem of threat assessment into a
reinforcement learning problem, and through systematic reinforcement learning
training, we successfully construct an efficient neural network evaluator. The
evaluator can not only comprehensively integrate the multidimensional attribute
features of the enemy, but also effectively combine our state information, thus
realizing a more accurate and scientific threat assessment.",2025-03-04T13:32:40Z,http://arxiv.org/pdf/2503.02612v2,"['cs.LG', 'cs.AI']"
2102.09114v1,Echo State Speech Recognition,"['Harsh Shrivastava', 'Ankush Garg', 'Yuan Cao', 'Yu Zhang', 'Tara Sainath']","We propose automatic speech recognition (ASR) models inspired by echo state
network (ESN), in which a subset of recurrent neural networks (RNN) layers in
the models are randomly initialized and untrained. Our study focuses on RNN-T
and Conformer models, and we show that model quality does not drop even when
the decoder is fully randomized. Furthermore, such models can be trained more
efficiently as the decoders do not require to be updated. By contrast,
randomizing encoders hurts model quality, indicating that optimizing encoders
and learn proper representations for acoustic inputs are more vital for speech
recognition. Overall, we challenge the common practice of training ASR models
for all components, and demonstrate that ESN-based models can perform equally
well but enable more efficient training and storage than fully-trainable
counterparts.",2021-02-18T02:04:14Z,http://arxiv.org/pdf/2102.09114v1,['cs.CL']
2105.11084v3,Unsupervised Speech Recognition,"['Alexei Baevski', 'Wei-Ning Hsu', 'Alexis Conneau', 'Michael Auli']","Despite rapid progress in the recent past, current speech recognition systems
still require labeled training data which limits this technology to a small
fraction of the languages spoken around the globe. This paper describes
wav2vec-U, short for wav2vec Unsupervised, a method to train speech recognition
models without any labeled data. We leverage self-supervised speech
representations to segment unlabeled audio and learn a mapping from these
representations to phonemes via adversarial training. The right representations
are key to the success of our method. Compared to the best previous
unsupervised work, wav2vec-U reduces the phoneme error rate on the TIMIT
benchmark from 26.1 to 11.3. On the larger English Librispeech benchmark,
wav2vec-U achieves a word error rate of 5.9 on test-other, rivaling some of the
best published systems trained on 960 hours of labeled data from only two years
ago. We also experiment on nine other languages, including low-resource
languages such as Kyrgyz, Swahili and Tatar.",2021-05-24T04:10:47Z,http://arxiv.org/pdf/2105.11084v3,"['cs.CL', 'cs.SD', 'eess.AS']"
2309.09843v1,Instruction-Following Speech Recognition,"['Cheng-I Jeff Lai', 'Zhiyun Lu', 'Liangliang Cao', 'Ruoming Pang']","Conventional end-to-end Automatic Speech Recognition (ASR) models primarily
focus on exact transcription tasks, lacking flexibility for nuanced user
interactions. With the advent of Large Language Models (LLMs) in speech
processing, more organic, text-prompt-based interactions have become possible.
However, the mechanisms behind these models' speech understanding and
""reasoning"" capabilities remain underexplored. To study this question from the
data perspective, we introduce instruction-following speech recognition,
training a Listen-Attend-Spell model to understand and execute a diverse set of
free-form text instructions. This enables a multitude of speech recognition
tasks -- ranging from transcript manipulation to summarization -- without
relying on predefined command sets. Remarkably, our model, trained from scratch
on Librispeech, interprets and executes simple instructions without requiring
LLMs or pre-trained speech modules. It also offers selective transcription
options based on instructions like ""transcribe first half and then turn off
listening,"" providing an additional layer of privacy and safety compared to
existing LLMs. Our findings highlight the significant potential of
instruction-following training to advance speech foundation models.",2023-09-18T14:59:10Z,http://arxiv.org/pdf/2309.09843v1,"['cs.CL', 'cs.LG', 'cs.SD', 'eess.AS']"
1409.1411v1,Visual Speech Recognition,['Ahmad B. A. Hassanat'],"Lip reading is used to understand or interpret speech without hearing it, a
technique especially mastered by people with hearing difficulties. The ability
to lip read enables a person with a hearing impairment to communicate with
others and to engage in social activities, which otherwise would be difficult.
Recent advances in the fields of computer vision, pattern recognition, and
signal processing has led to a growing interest in automating this challenging
task of lip reading. Indeed, automating the human ability to lip read, a
process referred to as visual speech recognition (VSR) (or sometimes speech
reading), could open the door for other novel related applications. VSR has
received a great deal of attention in the last decade for its potential use in
applications such as human-computer interaction (HCI), audio-visual speech
recognition (AVSR), speaker recognition, talking heads, sign language
recognition and video surveillance. Its main aim is to recognise spoken word(s)
by using only the visual signal that is produced during speech. Hence, VSR
deals with the visual domain of speech and involves image processing,
artificial intelligence, object detection, pattern recognition, statistical
modelling, etc.",2014-09-03T00:19:42Z,http://arxiv.org/pdf/1409.1411v1,['cs.CV']
2402.04254v1,Large Vocabulary Spontaneous Speech Recognition for Tigrigna,"['Ataklti Kahsu', 'Solomon Teferra']","This thesis proposes and describes a research attempt at designing and
developing a speaker independent spontaneous automatic speech recognition
system for Tigrigna The acoustic model of the Speech Recognition System is
developed using Carnegie Mellon University Automatic Speech Recognition
development tool (Sphinx) while the SRIM tool is used for the development of
the language model.
  Keywords Automatic Speech Recognition Tigrigna language",2023-10-15T13:07:41Z,http://arxiv.org/pdf/2402.04254v1,"['eess.AS', 'cs.LG', 'cs.SD', '68T50 (Primary)', 'H.1.2']"
1812.06864v2,Fully Convolutional Speech Recognition,"['Neil Zeghidour', 'Qiantong Xu', 'Vitaliy Liptchinsky', 'Nicolas Usunier', 'Gabriel Synnaeve', 'Ronan Collobert']","Current state-of-the-art speech recognition systems build on recurrent neural
networks for acoustic and/or language modeling, and rely on feature extraction
pipelines to extract mel-filterbanks or cepstral coefficients. In this paper we
present an alternative approach based solely on convolutional neural networks,
leveraging recent advances in acoustic models from the raw waveform and
language modeling. This fully convolutional approach is trained end-to-end to
predict characters from the raw waveform, removing the feature extraction step
altogether. An external convolutional language model is used to decode words.
On Wall Street Journal, our model matches the current state-of-the-art. On
Librispeech, we report state-of-the-art performance among end-to-end models,
including Deep Speech 2 trained with 12 times more acoustic data and
significantly more linguistic data.",2018-12-17T16:07:12Z,http://arxiv.org/pdf/1812.06864v2,['cs.CL']
2410.10434v2,In-Materia Speech Recognition,"['Mohamadreza Zolfagharinejad', 'Julian Büchel', 'Lorenzo Cassola', 'Sachin Kinge', 'Ghazi Sarwat Syed', 'Abu Sebastian', 'Wilfred G. van der Wiel']","With the rise of decentralized computing, as in the Internet of Things,
autonomous driving, and personalized healthcare, it is increasingly important
to process time-dependent signals at the edge efficiently: right at the place
where the temporal data are collected, avoiding time-consuming, insecure, and
costly communication with a centralized computing facility (or cloud). However,
modern-day processors often cannot meet the restrained power and time budgets
of edge systems because of intrinsic limitations imposed by their architecture
(von Neumann bottleneck) or domain conversions (analogue-to-digital and
time-to-frequency). Here, we propose an edge temporal-signal processor based on
two in-materia computing systems for both feature extraction and
classification, reaching a software-level accuracy of 96.2% for the TI-46-Word
speech-recognition task. First, a nonlinear, room-temperature
dopant-network-processing-unit (DNPU) layer realizes analogue, time-domain
feature extraction from the raw audio signals, similar to the human cochlea.
Second, an analogue in-memory computing (AIMC) chip, consisting of memristive
crossbar arrays, implements a compact neural network trained on the extracted
features for classification. With the DNPU feature extraction consuming 100s nW
and AIMC-based classification having the potential for less than 10 fJ per
multiply-accumulate operation, our findings offer a promising avenue for
advancing the compactness, efficiency, and performance of heterogeneous smart
edge processors through in-materia computing hardware.",2024-10-14T12:26:59Z,http://arxiv.org/pdf/2410.10434v2,"['eess.AS', 'cs.SD']"
2504.16213v1,TinyML for Speech Recognition,"['Andrew Barovic', 'Armin Moin']","We train and deploy a quantized 1D convolutional neural network model to
conduct speech recognition on a highly resource-constrained IoT edge device.
This can be useful in various Internet of Things (IoT) applications, such as
smart homes and ambient assisted living for the elderly and people with
disabilities, just to name a few examples. In this paper, we first create a new
dataset with over one hour of audio data that enables our research and will be
useful to future studies in this field. Second, we utilize the technologies
provided by Edge Impulse to enhance our model's performance and achieve a high
Accuracy of up to 97% on our dataset. For the validation, we implement our
prototype using the Arduino Nano 33 BLE Sense microcontroller board. This
microcontroller board is specifically designed for IoT and AI applications,
making it an ideal choice for our target use case scenarios. While most
existing research focuses on a limited set of keywords, our model can process
23 different keywords, enabling complex commands.",2025-04-22T19:00:40Z,http://arxiv.org/pdf/2504.16213v1,"['cs.SD', 'cs.AI', 'eess.AS']"
1711.07274v2,Speech recognition for medical conversations,"['Chung-Cheng Chiu', 'Anshuman Tripathi', 'Katherine Chou', 'Chris Co', 'Navdeep Jaitly', 'Diana Jaunzeikare', 'Anjuli Kannan', 'Patrick Nguyen', 'Hasim Sak', 'Ananth Sankar', 'Justin Tansuwan', 'Nathan Wan', 'Yonghui Wu', 'Xuedong Zhang']","In this work we explored building automatic speech recognition models for
transcribing doctor patient conversation. We collected a large scale dataset of
clinical conversations ($14,000$ hr), designed the task to represent the real
word scenario, and explored several alignment approaches to iteratively improve
data quality. We explored both CTC and LAS systems for building speech
recognition models. The LAS was more resilient to noisy data and CTC required
more data clean up. A detailed analysis is provided for understanding the
performance for clinical tasks. Our analysis showed the speech recognition
models performed well on important medical utterances, while errors occurred in
causal conversations. Overall we believe the resulting models can provide
reasonable quality in practice.",2017-11-20T12:07:22Z,http://arxiv.org/pdf/1711.07274v2,"['cs.CL', 'cs.SD', 'eess.AS', 'stat.ML']"
1908.02119v1,Practical Speech Recognition with HTK,['Zulkarnaen Hatala'],"The practical aspects of developing an Automatic Speech Recognition System
(ASR) with HTK are reviewed. Steps are explained concerning hardware, software,
libraries, applications and computer programs used. The common procedure to
rapidly apply speech recognition system is summarized. The procedure is
illustrated, to implement a speech based electrical switch in home automation
for the Indonesian language. The main key of the procedure is to match the
environment for training and testing using the training data recorded from the
testing program, HVite. Often the silence detector of HTK is wrongly triggered
by noises because the microphone is too sensitive. This problem is mitigated by
simply scaling down the volume. In this sub-word phone-based speech
recognition, noise is included in the training database and labelled
particularly. Illustration of the procedure is applied to a home automation
application. Electrical switches are controlled by Indonesian speech
recognizer. The results show 100% command completion rate.",2019-08-06T13:12:57Z,http://arxiv.org/pdf/1908.02119v1,"['eess.AS', 'cs.HC', 'cs.LG', 'cs.SD']"
1912.07730v5,Continuous Speech Recognition using EEG and Video,"['Gautam Krishna', 'Mason Carnahan', 'Co Tran', 'Ahmed H Tewfik']","In this paper we investigate whether electroencephalography (EEG) features
can be used to improve the performance of continuous visual speech recognition
systems. We implemented a connectionist temporal classification (CTC) based
end-to-end automatic speech recognition (ASR) model for performing recognition.
Our results demonstrate that EEG features are helpful in enhancing the
performance of continuous visual speech recognition systems.",2019-12-16T22:16:19Z,http://arxiv.org/pdf/1912.07730v5,"['cs.LG', 'eess.AS', 'eess.IV', 'stat.ML']"
2104.10747v2,Accented Speech Recognition: A Survey,"['Arthur Hinsvark', 'Natalie Delworth', 'Miguel Del Rio', 'Quinten McNamara', 'Joshua Dong', 'Ryan Westerman', 'Michelle Huang', 'Joseph Palakapilly', 'Jennifer Drexler', 'Ilya Pirkin', 'Nishchal Bhandari', 'Miguel Jette']","Automatic Speech Recognition (ASR) systems generalize poorly on accented
speech. The phonetic and linguistic variability of accents present hard
challenges for ASR systems today in both data collection and modeling
strategies. The resulting bias in ASR performance across accents comes at a
cost to both users and providers of ASR.
  We present a survey of current promising approaches to accented speech
recognition and highlight the key challenges in the space. Approaches mostly
focus on single model generalization and accent feature engineering. Among the
challenges, lack of a standard benchmark makes research and comparison
especially difficult.",2021-04-21T20:21:06Z,http://arxiv.org/pdf/2104.10747v2,"['cs.CL', 'cs.SD', 'eess.AS']"
2005.05592v2,Discriminative Multi-modality Speech Recognition,"['Bo Xu', 'Cheng Lu', 'Yandong Guo', 'Jacob Wang']","Vision is often used as a complementary modality for audio speech recognition
(ASR), especially in the noisy environment where performance of solo audio
modality significantly deteriorates. After combining visual modality, ASR is
upgraded to the multi-modality speech recognition (MSR). In this paper, we
propose a two-stage speech recognition model. In the first stage, the target
voice is separated from background noises with help from the corresponding
visual information of lip movements, making the model 'listen' clearly. At the
second stage, the audio modality combines visual modality again to better
understand the speech by a MSR sub-network, further improving the recognition
rate. There are some other key contributions: we introduce a pseudo-3D residual
convolution (P3D)-based visual front-end to extract more discriminative
features; we upgrade the temporal convolution block from 1D ResNet with the
temporal convolutional network (TCN), which is more suitable for the temporal
tasks; the MSR sub-network is built on the top of Element-wise-Attention Gated
Recurrent Unit (EleAtt-GRU), which is more effective than Transformer in long
sequences. We conducted extensive experiments on the LRS3-TED and the LRW
datasets. Our two-stage model (audio enhanced multi-modality speech
recognition, AE-MSR) consistently achieves the state-of-the-art performance by
a significant margin, which demonstrates the necessity and effectiveness of
AE-MSR.",2020-05-12T07:56:03Z,http://arxiv.org/pdf/2005.05592v2,"['cs.CV', 'cs.CL', 'cs.SD', 'eess.AS', 'eess.IV']"
1809.02108v2,Deep Audio-Visual Speech Recognition,"['Triantafyllos Afouras', 'Joon Son Chung', 'Andrew Senior', 'Oriol Vinyals', 'Andrew Zisserman']","The goal of this work is to recognise phrases and sentences being spoken by a
talking face, with or without the audio. Unlike previous works that have
focussed on recognising a limited number of words or phrases, we tackle lip
reading as an open-world problem - unconstrained natural language sentences,
and in the wild videos. Our key contributions are: (1) we compare two models
for lip reading, one using a CTC loss, and the other using a
sequence-to-sequence loss. Both models are built on top of the transformer
self-attention architecture; (2) we investigate to what extent lip reading is
complementary to audio speech recognition, especially when the audio signal is
noisy; (3) we introduce and publicly release a new dataset for audio-visual
speech recognition, LRS2-BBC, consisting of thousands of natural sentences from
British television. The models that we train surpass the performance of all
previous work on a lip reading benchmark dataset by a significant margin.",2018-09-06T17:34:27Z,http://arxiv.org/pdf/1809.02108v2,['cs.CV']
1904.02210v1,Massively Multilingual Adversarial Speech Recognition,"['Oliver Adams', 'Matthew Wiesner', 'Shinji Watanabe', 'David Yarowsky']","We report on adaptation of multilingual end-to-end speech recognition models
trained on as many as 100 languages. Our findings shed light on the relative
importance of similarity between the target and pretraining languages along the
dimensions of phonetics, phonology, language family, geographical location, and
orthography. In this context, experiments demonstrate the effectiveness of two
additional pretraining objectives in encouraging language-independent encoder
representations: a context-independent phoneme objective paired with a
language-adversarial classification objective.",2019-04-03T19:28:53Z,http://arxiv.org/pdf/1904.02210v1,"['cs.CL', 'cs.LG']"
2406.18135v1,Automatic Speech Recognition for Hindi,"['Anish Saha', 'A. G. Ramakrishnan']","Automatic speech recognition (ASR) is a key area in computational
linguistics, focusing on developing technologies that enable computers to
convert spoken language into text. This field combines linguistics and machine
learning. ASR models, which map speech audio to transcripts through supervised
learning, require handling real and unrestricted text. Text-to-speech systems
directly work with real text, while ASR systems rely on language models trained
on large text corpora. High-quality transcribed data is essential for training
predictive models. The research involved two main components: developing a web
application and designing a web interface for speech recognition. The web
application, created with JavaScript and Node.js, manages large volumes of
audio files and their transcriptions, facilitating collaborative human
correction of ASR transcripts. It operates in real-time using a client-server
architecture. The web interface for speech recognition records 16 kHz mono
audio from any device running the web app, performs voice activity detection
(VAD), and sends the audio to the recognition engine. VAD detects human speech
presence, aiding efficient speech processing and reducing unnecessary
processing during non-speech intervals, thus saving computation and network
bandwidth in VoIP applications. The final phase of the research tested a neural
network for accurately aligning the speech signal to hidden Markov model (HMM)
states. This included implementing a novel backpropagation method that utilizes
prior statistics of node co-activations.",2024-06-26T07:39:20Z,http://arxiv.org/pdf/2406.18135v1,"['cs.CL', 'cs.SD', 'eess.AS']"
0704.2201v1,Arabic Speech Recognition System using CMU-Sphinx4,"['H. Satori', 'M. Harti', 'N. Chenfour']","In this paper we present the creation of an Arabic version of Automated
Speech Recognition System (ASR). This system is based on the open source
Sphinx-4, from the Carnegie Mellon University. Which is a speech recognition
system based on discrete hidden Markov models (HMMs). We investigate the
changes that must be made to the model to adapt Arabic voice recognition.
  Keywords: Speech recognition, Acoustic model, Arabic language, HMMs,
CMUSphinx-4, Artificial intelligence.",2007-04-17T17:04:26Z,http://arxiv.org/pdf/0704.2201v1,"['cs.CL', 'cs.AI', 'I.2.7']"
2002.03851v7,Continuous Silent Speech Recognition using EEG,"['Gautam Krishna', 'Co Tran', 'Mason Carnahan', 'Ahmed Tewfik']","In this paper we explore continuous silent speech recognition using
electroencephalography (EEG) signals. We implemented a connectionist temporal
classification (CTC) automatic speech recognition (ASR) model to translate EEG
signals recorded in parallel while subjects were reading English sentences in
their mind without producing any voice to text. Our results demonstrate the
feasibility of using EEG signals for performing continuous silent speech
recognition. We demonstrate our results for a limited English vocabulary
consisting of 30 unique sentences.",2020-02-06T18:28:45Z,http://arxiv.org/pdf/2002.03851v7,"['eess.AS', 'cs.LG', 'cs.SD', 'stat.ML']"
2009.09395v1,Far-Field Automatic Speech Recognition,"['Reinhold Haeb-Umbach', 'Jahn Heymann', 'Lukas Drude', 'Shinji Watanabe', 'Marc Delcroix', 'Tomohiro Nakatani']","The machine recognition of speech spoken at a distance from the microphones,
known as far-field automatic speech recognition (ASR), has received a
significant increase of attention in science and industry, which caused or was
caused by an equally significant improvement in recognition accuracy. Meanwhile
it has entered the consumer market with digital home assistants with a spoken
language interface being its most prominent application. Speech recorded at a
distance is affected by various acoustic distortions and, consequently, quite
different processing pipelines have emerged compared to ASR for close-talk
speech. A signal enhancement front-end for dereverberation, source separation
and acoustic beamforming is employed to clean up the speech, and the back-end
ASR engine is robustified by multi-condition training and adaptation. We will
also describe the so-called end-to-end approach to ASR, which is a new
promising architecture that has recently been extended to the far-field
scenario. This tutorial article gives an account of the algorithms used to
enable accurate speech recognition from a distance, and it will be seen that,
although deep learning has a significant share in the technological
breakthroughs, a clever combination with traditional signal processing can lead
to surprisingly effective solutions.",2020-09-20T09:31:59Z,http://arxiv.org/pdf/2009.09395v1,['eess.AS']
2107.11190v3,Semantic Communications for Speech Recognition,"['Zhenzi Weng', 'Zhijin Qin', 'Geoffrey Ye Li']","The traditional communications transmit all the source data represented by
bits, regardless of the content of source and the semantic information required
by the receiver. However, in some applications, the receiver only needs part of
the source data that represents critical semantic information, which prompts to
transmit the application-related information, especially when bandwidth
resources are limited. In this paper, we consider a semantic communication
system for speech recognition by designing the transceiver as an end-to-end
(E2E) system. Particularly, a deep learning (DL)-enabled semantic communication
system, named DeepSC-SR, is developed to learn and extract text-related
semantic features at the transmitter, which motivates the system to transmit
much less than the source speech data without performance degradation.
Moreover, in order to facilitate the proposed DeepSC-SR for dynamic channel
environments, we investigate a robust model to cope with various channel
environments without requiring retraining. The simulation results demonstrate
that our proposed DeepSC-SR outperforms the traditional communication systems
in terms of the speech recognition metrics, such as character-error-rate and
word-error-rate, and is more robust to channel variations, especially in the
low signal-to-noise (SNR) regime.",2021-07-22T11:08:08Z,http://arxiv.org/pdf/2107.11190v3,"['eess.AS', 'cs.SD', 'eess.SP']"
1807.05162v3,Large-Scale Visual Speech Recognition,"['Brendan Shillingford', 'Yannis Assael', 'Matthew W. Hoffman', 'Thomas Paine', 'Cían Hughes', 'Utsav Prabhu', 'Hank Liao', 'Hasim Sak', 'Kanishka Rao', 'Lorrayne Bennett', 'Marie Mulville', 'Ben Coppin', 'Ben Laurie', 'Andrew Senior', 'Nando de Freitas']","This work presents a scalable solution to open-vocabulary visual speech
recognition. To achieve this, we constructed the largest existing visual speech
recognition dataset, consisting of pairs of text and video clips of faces
speaking (3,886 hours of video). In tandem, we designed and trained an
integrated lipreading system, consisting of a video processing pipeline that
maps raw video to stable videos of lips and sequences of phonemes, a scalable
deep neural network that maps the lip videos to sequences of phoneme
distributions, and a production-level speech decoder that outputs sequences of
words. The proposed system achieves a word error rate (WER) of 40.9% as
measured on a held-out set. In comparison, professional lipreaders achieve
either 86.4% or 92.9% WER on the same dataset when having access to additional
types of contextual information. Our approach significantly improves on other
lipreading approaches, including variants of LipNet and of Watch, Attend, and
Spell (WAS), which are only capable of 89.8% and 76.8% WER respectively.",2018-07-13T16:21:34Z,http://arxiv.org/pdf/1807.05162v3,"['cs.CV', 'cs.LG']"
2112.14678v1,Multi-Dialect Arabic Speech Recognition,['Abbas Raza Ali'],"This paper presents the design and development of multi-dialect automatic
speech recognition for Arabic. Deep neural networks are becoming an effective
tool to solve sequential data problems, particularly, adopting an end-to-end
training of the system. Arabic speech recognition is a complex task because of
the existence of multiple dialects, non-availability of large corpora, and
missing vocalization. Thus, the first contribution of this work is the
development of a large multi-dialectal corpus with either full or at least
partially vocalized transcription. Additionally, the open-source corpus has
been gathered from multiple sources that bring non-standard Arabic alphabets in
transcription which are normalized by defining a common character-set. The
second contribution is the development of a framework to train an acoustic
model achieving state-of-the-art performance. The network architecture
comprises of a combination of convolutional and recurrent layers. The
spectrogram features of the audio data are extracted in the frequency vs time
domain and fed in the network. The output frames, produced by the recurrent
model, are further trained to align the audio features with its corresponding
transcription sequences. The sequence alignment is performed using a beam
search decoder with a tetra-gram language model. The proposed system achieved a
14% error rate which outperforms previous systems.",2021-12-25T20:55:57Z,http://arxiv.org/pdf/2112.14678v1,"['eess.AS', 'cs.LG', 'cs.SD']"
1904.04479v4,Who Needs Words? Lexicon-Free Speech Recognition,"['Tatiana Likhomanenko', 'Gabriel Synnaeve', 'Ronan Collobert']","Lexicon-free speech recognition naturally deals with the problem of
out-of-vocabulary (OOV) words. In this paper, we show that character-based
language models (LM) can perform as well as word-based LMs for speech
recognition, in word error rates (WER), even without restricting the decoding
to a lexicon. We study character-based LMs and show that convolutional LMs can
effectively leverage large (character) contexts, which is key for good speech
recognition performance downstream. We specifically show that the lexicon-free
decoding performance (WER) on utterances with OOV words using character-based
LMs is better than lexicon-based decoding, both with character or word-based
LMs.",2019-04-09T06:06:54Z,http://arxiv.org/pdf/1904.04479v4,['cs.CL']
2204.02492v2,Towards End-to-end Unsupervised Speech Recognition,"['Alexander H. Liu', 'Wei-Ning Hsu', 'Michael Auli', 'Alexei Baevski']","Unsupervised speech recognition has shown great potential to make Automatic
Speech Recognition (ASR) systems accessible to every language. However,
existing methods still heavily rely on hand-crafted pre-processing. Similar to
the trend of making supervised speech recognition end-to-end, we introduce
wav2vec-U 2.0 which does away with all audio-side pre-processing and improves
accuracy through better architecture. In addition, we introduce an auxiliary
self-supervised objective that ties model predictions back to the input.
Experiments show that wav2vec-U 2.0 improves unsupervised recognition results
across different languages while being conceptually simpler.",2022-04-05T21:22:38Z,http://arxiv.org/pdf/2204.02492v2,"['cs.CL', 'cs.SD', 'eess.AS']"
1901.04699v1,Phoneme-Based Persian Speech Recognition,['Saber Malekzadeh'],"Undoubtedly, one of the most important issues in computer science is
intelligent speech recognition. In these systems, computers try to detect and
respond to the speeches they are listening to, like humans. In this research,
presenting of a suitable method for the diagnosis of Persian phonemes by AI
using the signal processing and classification algorithms have tried. For this
purpose, the STFT algorithm has been used to process the audio signals, as well
as to detect and classify the signals processed by the deep artificial neural
network. At first, educational samples were provided as two phonological
phrases in Persian language and then signal processing operations were
performed on them. Then the results for the data training have been given to
the artificial deep neural network. At the final stage, the experiment was
conducted on new sounds.",2019-01-15T08:07:48Z,http://arxiv.org/pdf/1901.04699v1,"['cs.SD', 'cs.LG', 'eess.AS']"
2302.12369v1,Factual Consistency Oriented Speech Recognition,"['Naoyuki Kanda', 'Takuya Yoshioka', 'Yang Liu']","This paper presents a novel optimization framework for automatic speech
recognition (ASR) with the aim of reducing hallucinations produced by an ASR
model. The proposed framework optimizes the ASR model to maximize an expected
factual consistency score between ASR hypotheses and ground-truth
transcriptions, where the factual consistency score is computed by a separately
trained estimator. Experimental results using the AMI meeting corpus and the
VoxPopuli corpus show that the ASR model trained with the proposed framework
generates ASR hypotheses that have significantly higher consistency scores with
ground-truth transcriptions while maintaining the word error rates close to
those of cross entropy-trained ASR models. Furthermore, it is shown that
training the ASR models with the proposed framework improves the speech
summarization quality as measured by the factual consistency of meeting
conversation summaries generated by a large language model.",2023-02-24T00:01:41Z,http://arxiv.org/pdf/2302.12369v1,"['eess.AS', 'cs.CL', 'cs.SD']"
2307.01672v1,Boosting Norwegian Automatic Speech Recognition,"['Javier de la Rosa', 'Rolv-Arild Braaten', 'Per Egil Kummervold', 'Freddy Wetjen', 'Svein Arne Brygfjeld']","In this paper, we present several baselines for automatic speech recognition
(ASR) models for the two official written languages in Norway: Bokm{\aa}l and
Nynorsk. We compare the performance of models of varying sizes and pre-training
approaches on multiple Norwegian speech datasets. Additionally, we measure the
performance of these models against previous state-of-the-art ASR models, as
well as on out-of-domain datasets. We improve the state of the art on the
Norwegian Parliamentary Speech Corpus (NPSC) from a word error rate (WER) of
17.10\% to 7.60\%, with models achieving 5.81\% for Bokm{\aa}l and 11.54\% for
Nynorsk. We also discuss the challenges and potential solutions for further
improving ASR models for Norwegian.",2023-07-04T12:05:15Z,http://arxiv.org/pdf/2307.01672v1,['cs.CL']
2001.00501v3,EEG based Continuous Speech Recognition using Transformers,"['Gautam Krishna', 'Co Tran', 'Mason Carnahan', 'Ahmed H Tewfik']","In this paper we investigate continuous speech recognition using
electroencephalography (EEG) features using recently introduced end-to-end
transformer based automatic speech recognition (ASR) model. Our results
demonstrate that transformer based model demonstrate faster training compared
to recurrent neural network (RNN) based sequence-to-sequence EEG models and
better performance during inference time for smaller test set vocabulary but as
we increase the vocabulary size, the performance of the RNN based models were
better than transformer based model on a limited English vocabulary.",2019-12-31T08:36:59Z,http://arxiv.org/pdf/2001.00501v3,"['eess.AS', 'cs.LG', 'cs.SD', 'stat.ML']"
2003.01787v1,Untangling in Invariant Speech Recognition,"['Cory Stephenson', 'Jenelle Feather', 'Suchismita Padhy', 'Oguz Elibol', 'Hanlin Tang', 'Josh McDermott', 'SueYeon Chung']","Encouraged by the success of deep neural networks on a variety of visual
tasks, much theoretical and experimental work has been aimed at understanding
and interpreting how vision networks operate. Meanwhile, deep neural networks
have also achieved impressive performance in audio processing applications,
both as sub-components of larger systems and as complete end-to-end systems by
themselves. Despite their empirical successes, comparatively little is
understood about how these audio models accomplish these tasks. In this work,
we employ a recently developed statistical mechanical theory that connects
geometric properties of network representations and the separability of classes
to probe how information is untangled within neural networks trained to
recognize speech. We observe that speaker-specific nuisance variations are
discarded by the network's hierarchy, whereas task-relevant properties such as
words and phonemes are untangled in later layers. Higher level concepts such as
parts-of-speech and context dependence also emerge in the later layers of the
network. Finally, we find that the deep representations carry out significant
temporal untangling by efficiently extracting task-relevant features at each
time step of the computation. Taken together, these findings shed light on how
deep auditory models process time dependent input signals to achieve invariant
speech recognition, and show how different concepts emerge through the layers
of the network.",2020-03-03T20:48:43Z,http://arxiv.org/pdf/2003.01787v1,"['cs.LG', 'cond-mat.dis-nn', 'cs.CL', 'cs.SD', 'eess.AS']"
2206.07684v1,AVATAR: Unconstrained Audiovisual Speech Recognition,"['Valentin Gabeur', 'Paul Hongsuck Seo', 'Arsha Nagrani', 'Chen Sun', 'Karteek Alahari', 'Cordelia Schmid']","Audio-visual automatic speech recognition (AV-ASR) is an extension of ASR
that incorporates visual cues, often from the movements of a speaker's mouth.
Unlike works that simply focus on the lip motion, we investigate the
contribution of entire visual frames (visual actions, objects, background
etc.). This is particularly useful for unconstrained videos, where the speaker
is not necessarily visible. To solve this task, we propose a new
sequence-to-sequence AudioVisual ASR TrAnsformeR (AVATAR) which is trained
end-to-end from spectrograms and full-frame RGB. To prevent the audio stream
from dominating training, we propose different word-masking strategies, thereby
encouraging our model to pay attention to the visual stream. We demonstrate the
contribution of the visual modality on the How2 AV-ASR benchmark, especially in
the presence of simulated noise, and show that our model outperforms all other
prior work by a large margin. Finally, we also create a new, real-world test
bed for AV-ASR called VisSpeech, which demonstrates the contribution of the
visual modality under challenging audio conditions.",2022-06-15T17:33:19Z,http://arxiv.org/pdf/2206.07684v1,"['cs.CV', 'cs.MM', 'cs.SD', 'eess.AS']"
1001.2267v1,"Speech Recognition by Machine, A Review","['M. A. Anusuya', 'S. K. Katti']","This paper presents a brief survey on Automatic Speech Recognition and
discusses the major themes and advances made in the past 60 years of research,
so as to provide a technological perspective and an appreciation of the
fundamental progress that has been accomplished in this important area of
speech communication. After years of research and development the accuracy of
automatic speech recognition remains one of the important research challenges
(e.g., variations of the context, speakers, and environment).The design of
Speech Recognition system requires careful attentions to the following issues:
Definition of various types of speech classes, speech representation, feature
extraction techniques, speech classifiers, database and performance evaluation.
The problems that are existing in ASR and the various techniques to solve these
problems constructed by various research workers have been presented in a
chronological order. Hence authors hope that this work shall be a contribution
in the area of speech recognition. The objective of this review paper is to
summarize and compare some of the well known methods used in various stages of
speech recognition system and identify research topic and applications which
are at the forefront of this exciting and challenging field.",2010-01-13T19:02:18Z,http://arxiv.org/pdf/1001.2267v1,['cs.CL']
1710.07168v2,Combining Multiple Views for Visual Speech Recognition,"['Marina Zimmermann', 'Mostafa Mehdipour Ghazi', 'Hazım Kemal Ekenel', 'Jean-Philippe Thiran']","Visual speech recognition is a challenging research problem with a particular
practical application of aiding audio speech recognition in noisy scenarios.
Multiple camera setups can be beneficial for the visual speech recognition
systems in terms of improved performance and robustness. In this paper, we
explore this aspect and provide a comprehensive study on combining multiple
views for visual speech recognition. The thorough analysis covers fusion of all
possible view angle combinations both at feature level and decision level. The
employed visual speech recognition system in this study extracts features
through a PCA-based convolutional neural network, followed by an LSTM network.
Finally, these features are processed in a tandem system, being fed into a
GMM-HMM scheme. The decision fusion acts after this point by combining the
Viterbi path log-likelihoods. The results show that the complementary
information contained in recordings from different view angles improves the
results significantly. For example, the sentence correctness on the test set is
increased from 76% for the highest performing single view ($30^\circ$) to up to
83% when combining this view with the frontal and $60^\circ$ view angles.",2017-10-19T14:52:34Z,http://arxiv.org/pdf/1710.07168v2,['cs.CV']
1305.2846v1,Opportunities & Challenges In Automatic Speech Recognition,"['Rashmi Makhijani', 'Urmila Shrawankar', 'V M Thakare']","Automatic speech recognition enables a wide range of current and emerging
applications such as automatic transcription, multimedia content analysis, and
natural human-computer interfaces. This paper provides a glimpse of the
opportunities and challenges that parallelism provides for automatic speech
recognition and related application research from the point of view of speech
researchers. The increasing parallelism in computing platforms opens three
major possibilities for speech recognition systems: improving recognition
accuracy in non-ideal, everyday noisy environments; increasing recognition
throughput in batch processing of speech data; and reducing recognition latency
in realtime usage scenarios. This paper describes technical challenges,
approaches taken, and possible directions for future research to guide the
design of efficient parallel software and hardware infrastructures.",2013-05-09T08:42:26Z,http://arxiv.org/pdf/1305.2846v1,"['cs.CL', 'cs.SD']"
2107.11414v3,Brazilian Portuguese Speech Recognition Using Wav2vec 2.0,"['Lucas Rafael Stefanel Gris', 'Edresson Casanova', 'Frederico Santos de Oliveira', 'Anderson da Silva Soares', 'Arnaldo Candido Junior']","Deep learning techniques have been shown to be efficient in various tasks,
especially in the development of speech recognition systems, that is, systems
that aim to transcribe an audio sentence in a sequence of written words.
Despite the progress in the area, speech recognition can still be considered
difficult, especially for languages lacking available data, such as Brazilian
Portuguese (BP). In this sense, this work presents the development of an public
Automatic Speech Recognition (ASR) system using only open available audio data,
from the fine-tuning of the Wav2vec 2.0 XLSR-53 model pre-trained in many
languages, over BP data. The final model presents an average word error rate of
12.4% over 7 different datasets (10.5% when applying a language model).
According to our knowledge, the obtained error is the lowest among open
end-to-end (E2E) ASR models for BP.",2021-07-23T18:54:39Z,http://arxiv.org/pdf/2107.11414v3,['cs.CL']
2202.08883v1,Curriculum optimization for low-resource speech recognition,"['Anastasia Kuznetsova', 'Anurag Kumar', 'Jennifer Drexler Fox', 'Francis Tyers']","Modern end-to-end speech recognition models show astonishing results in
transcribing audio signals into written text. However, conventional data
feeding pipelines may be sub-optimal for low-resource speech recognition, which
still remains a challenging task. We propose an automated curriculum learning
approach to optimize the sequence of training examples based on both the
progress of the model while training and prior knowledge about the difficulty
of the training examples. We introduce a new difficulty measure called
compression ratio that can be used as a scoring function for raw audio in
various noise conditions. The proposed method improves speech recognition Word
Error Rate performance by up to 33% relative over the baseline system",2022-02-17T19:47:50Z,http://arxiv.org/pdf/2202.08883v1,"['eess.AS', 'cs.LG', 'cs.SD']"
1909.11699v1,Speech Recognition with Augmented Synthesized Speech,"['Andrew Rosenberg', 'Yu Zhang', 'Bhuvana Ramabhadran', 'Ye Jia', 'Pedro Moreno', 'Yonghui Wu', 'Zelin Wu']","Recent success of the Tacotron speech synthesis architecture and its variants
in producing natural sounding multi-speaker synthesized speech has raised the
exciting possibility of replacing expensive, manually transcribed,
domain-specific, human speech that is used to train speech recognizers. The
multi-speaker speech synthesis architecture can learn latent embedding spaces
of prosody, speaker and style variations derived from input acoustic
representations thereby allowing for manipulation of the synthesized speech. In
this paper, we evaluate the feasibility of enhancing speech recognition
performance using speech synthesis using two corpora from different domains. We
explore algorithms to provide the necessary acoustic and lexical diversity
needed for robust speech recognition. Finally, we demonstrate the feasibility
of this approach as a data augmentation strategy for domain-transfer.
  We find that improvements to speech recognition performance is achievable by
augmenting training data with synthesized material. However, there remains a
substantial gap in performance between recognizers trained on human speech
those trained on synthesized speech.",2019-09-25T18:32:50Z,http://arxiv.org/pdf/1909.11699v1,"['cs.CL', 'cs.SD', 'eess.AS']"
1911.04571v1,Long-span language modeling for speech recognition,"['Sarangarajan Parthasarathy', 'William Gale', 'Xie Chen', 'George Polovets', 'Shuangyu Chang']","We explore neural language modeling for speech recognition where the context
spans multiple sentences. Rather than encode history beyond the current
sentence using a cache of words or document-level features, we focus our study
on the ability of LSTM and Transformer language models to implicitly learn to
carry over context across sentence boundaries. We introduce a new architecture
that incorporates an attention mechanism into LSTM to combine the benefits of
recurrent and attention architectures. We conduct language modeling and speech
recognition experiments on the publicly available LibriSpeech corpus. We show
that conventional training on a paragraph-level corpus results in significant
reductions in perplexity compared to training on a sentence-level corpus. We
also describe speech recognition experiments using long-span language models in
second-pass re-ranking, and provide insights into the ability of such models to
take advantage of context beyond the current sentence.",2019-11-11T21:18:53Z,http://arxiv.org/pdf/1911.04571v1,"['cs.CL', 'cs.SD', 'eess.AS']"
2210.11588v3,Anchored Speech Recognition with Neural Transducers,"['Desh Raj', 'Junteng Jia', 'Jay Mahadeokar', 'Chunyang Wu', 'Niko Moritz', 'Xiaohui Zhang', 'Ozlem Kalinli']","Neural transducers have achieved human level performance on standard speech
recognition benchmarks. However, their performance significantly degrades in
the presence of cross-talk, especially when the primary speaker has a low
signal-to-noise ratio. Anchored speech recognition refers to a class of methods
that use information from an anchor segment (e.g., wake-words) to recognize
device-directed speech while ignoring interfering background speech. In this
paper, we investigate anchored speech recognition to make neural transducers
robust to background speech. We extract context information from the anchor
segment with a tiny auxiliary network, and use encoder biasing and joiner
gating to guide the transducer towards the target speech. Moreover, to improve
the robustness of context embedding extraction, we propose auxiliary training
objectives to disentangle lexical content from speaking style. We evaluate our
methods on synthetic LibriSpeech-based mixtures comprising several SNR and
overlap conditions; they improve relative word error rates by 19.6% over a
strong baseline, when averaged over all conditions.",2022-10-20T21:00:42Z,http://arxiv.org/pdf/2210.11588v3,"['eess.AS', 'cs.SD']"
9607023v1,Phonological modeling for continuous speech recognition in Korean,"['WonIl Lee', 'Geunbae Lee', 'Jong-Hyeok Lee']","A new scheme to represent phonological changes during continuous speech
recognition is suggested. A phonological tag coupled with its morphological tag
is designed to represent the conditions of Korean phonological changes. A
pairwise language model of these morphological and phonological tags is
implemented in Korean speech recognition system. Performance of the model is
verified through the TDNN-based speech recognition experiments.",1996-07-18T01:56:13Z,http://arxiv.org/pdf/cmp-lg/9607023v1,"['cmp-lg', 'cs.CL']"
1711.01567v1,Robust Speech Recognition Using Generative Adversarial Networks,"['Anuroop Sriram', 'Heewoo Jun', 'Yashesh Gaur', 'Sanjeev Satheesh']","This paper describes a general, scalable, end-to-end framework that uses the
generative adversarial network (GAN) objective to enable robust speech
recognition. Encoders trained with the proposed approach enjoy improved
invariance by learning to map noisy audio to the same embedding space as that
of clean audio. Unlike previous methods, the new framework does not rely on
domain expertise or simplifying assumptions as are often needed in signal
processing, and directly encourages robustness in a data-driven way. We show
the new approach improves simulated far-field speech recognition of vanilla
sequence-to-sequence models without specialized front-ends or preprocessing.",2017-11-05T12:00:18Z,http://arxiv.org/pdf/1711.01567v1,"['cs.CL', 'cs.LG']"
1905.03828v2,Universal Adversarial Perturbations for Speech Recognition Systems,"['Paarth Neekhara', 'Shehzeen Hussain', 'Prakhar Pandey', 'Shlomo Dubnov', 'Julian McAuley', 'Farinaz Koushanfar']","In this work, we demonstrate the existence of universal adversarial audio
perturbations that cause mis-transcription of audio signals by automatic speech
recognition (ASR) systems. We propose an algorithm to find a single
quasi-imperceptible perturbation, which when added to any arbitrary speech
signal, will most likely fool the victim speech recognition model. Our
experiments demonstrate the application of our proposed technique by crafting
audio-agnostic universal perturbations for the state-of-the-art ASR system --
Mozilla DeepSpeech. Additionally, we show that such perturbations generalize to
a significant extent across models that are not available during training, by
performing a transferability test on a WaveNet based ASR system.",2019-05-09T19:35:30Z,http://arxiv.org/pdf/1905.03828v2,"['cs.LG', 'cs.SD', 'eess.AS', 'stat.ML']"
1911.11610v6,Improving EEG based Continuous Speech Recognition,"['Gautam Krishna', 'Co Tran', 'Mason Carnahan', 'Yan Han', 'Ahmed H Tewfik']","In this paper we introduce various techniques to improve the performance of
electroencephalography (EEG) features based continuous speech recognition (CSR)
systems. A connectionist temporal classification (CTC) based automatic speech
recognition (ASR) system was implemented for performing recognition. We
introduce techniques to initialize the weights of the recurrent layers in the
encoder of the CTC model with more meaningful weights rather than with random
weights and we make use of an external language model to improve the beam
search during decoding time.
  We finally study the problem of predicting articulatory features from EEG
features in this paper.",2019-11-24T16:00:49Z,http://arxiv.org/pdf/1911.11610v6,"['eess.AS', 'cs.LG', 'cs.SD', 'stat.ML']"
1801.00061v1,Multichannel Robot Speech Recognition Database: MChRSR,"['José Novoa', 'Juan Pablo Escudero', 'Josué Fredes', 'Jorge Wuth', 'Rodrigo Mahu', 'Néstor Becerra Yoma']","In real human robot interaction (HRI) scenarios, speech recognition
represents a major challenge due to robot noise, background noise and
time-varying acoustic channel. This document describes the procedure used to
obtain the Multichannel Robot Speech Recognition Database (MChRSR). It is
composed of 12 hours of multichannel evaluation data recorded in a real mobile
HRI scenario. This database was recorded with a PR2 robot performing different
translational and azimuthal movements. Accordingly, 16 evaluation sets were
obtained re-recording the clean set of the Aurora 4 database in different
movement conditions.",2017-12-30T00:01:08Z,http://arxiv.org/pdf/1801.00061v1,"['cs.HC', 'cs.RO']"
2309.17395v1,AV-CPL: Continuous Pseudo-Labeling for Audio-Visual Speech Recognition,"['Andrew Rouditchenko', 'Ronan Collobert', 'Tatiana Likhomanenko']","Audio-visual speech contains synchronized audio and visual information that
provides cross-modal supervision to learn representations for both automatic
speech recognition (ASR) and visual speech recognition (VSR). We introduce
continuous pseudo-labeling for audio-visual speech recognition (AV-CPL), a
semi-supervised method to train an audio-visual speech recognition (AVSR) model
on a combination of labeled and unlabeled videos with continuously regenerated
pseudo-labels. Our models are trained for speech recognition from audio-visual
inputs and can perform speech recognition using both audio and visual
modalities, or only one modality. Our method uses the same audio-visual model
for both supervised training and pseudo-label generation, mitigating the need
for external speech recognition models to generate pseudo-labels. AV-CPL
obtains significant improvements in VSR performance on the LRS3 dataset while
maintaining practical ASR and AVSR performance. Finally, using visual-only
speech data, our method is able to leverage unlabeled visual speech to improve
VSR.",2023-09-29T16:57:21Z,http://arxiv.org/pdf/2309.17395v1,"['cs.LG', 'cs.SD', 'eess.AS', 'stat.ML']"
2406.02555v1,PhoWhisper: Automatic Speech Recognition for Vietnamese,"['Thanh-Thien Le', 'Linh The Nguyen', 'Dat Quoc Nguyen']","We introduce PhoWhisper in five versions for Vietnamese automatic speech
recognition. PhoWhisper's robustness is achieved through fine-tuning the
Whisper model on an 844-hour dataset that encompasses diverse Vietnamese
accents. Our experimental study demonstrates state-of-the-art performances of
PhoWhisper on benchmark Vietnamese ASR datasets. We have open-sourced
PhoWhisper at: https://github.com/VinAIResearch/PhoWhisper",2024-03-27T13:10:06Z,http://arxiv.org/pdf/2406.02555v1,"['eess.AS', 'cs.CL']"
2012.07467v1,AV Taris: Online Audio-Visual Speech Recognition,"['George Sterpu', 'Naomi Harte']","In recent years, Automatic Speech Recognition (ASR) technology has approached
human-level performance on conversational speech under relatively clean
listening conditions. In more demanding situations involving distant
microphones, overlapped speech, background noise, or natural dialogue
structures, the ASR error rate is at least an order of magnitude higher. The
visual modality of speech carries the potential to partially overcome these
challenges and contribute to the sub-tasks of speaker diarisation, voice
activity detection, and the recovery of the place of articulation, and can
compensate for up to 15dB of noise on average. This article develops AV Taris,
a fully differentiable neural network model capable of decoding audio-visual
speech in real time. We achieve this by connecting two recently proposed models
for audio-visual speech integration and online speech recognition, namely AV
Align and Taris. We evaluate AV Taris under the same conditions as AV Align and
Taris on one of the largest publicly available audio-visual speech datasets,
LRS2. Our results show that AV Taris is superior to the audio-only variant of
Taris, demonstrating the utility of the visual modality to speech recognition
within the real time decoding framework defined by Taris. Compared to an
equivalent Transformer-based AV Align model that takes advantage of full
sentences without meeting the real-time requirement, we report an absolute
degradation of approximately 3% with AV Taris. As opposed to the more popular
alternative for online speech recognition, namely the RNN Transducer, Taris
offers a greatly simplified fully differentiable training pipeline. As a
consequence, AV Taris has the potential to popularise the adoption of
Audio-Visual Speech Recognition (AVSR) technology and overcome the inherent
limitations of the audio modality in less optimal listening conditions.",2020-12-14T12:39:02Z,http://arxiv.org/pdf/2012.07467v1,"['eess.AS', 'cs.LG']"
9608018v2,Algorithms for Speech Recognition and Language Processing,"['Mehryar Mohri', 'Michael Riley', 'Richard Sproat']","Speech processing requires very efficient methods and algorithms.
Finite-state transducers have been shown recently both to constitute a very
useful abstract model and to lead to highly efficient time and space algorithms
in this field. We present these methods and algorithms and illustrate them in
the case of speech recognition. In addition to classical techniques, we
describe many new algorithms such as minimization, global and local on-the-fly
determinization of weighted automata, and efficient composition of transducers.
These methods are currently used in large vocabulary speech recognition
systems. We then show how the same formalism and algorithms can be used in
text-to-speech applications and related areas of language processing such as
morphology, syntax, and local grammars, in a very efficient way. The tutorial
is self-contained and requires no specific computational or linguistic
knowledge other than classical results.",1996-08-27T21:32:40Z,http://arxiv.org/pdf/cmp-lg/9608018v2,"['cmp-lg', 'cs.CL']"
1305.2847v1,An Overview of Hindi Speech Recognition,"['Neema Mishra', 'Urmila Shrawankar', 'V M Thakare']","In this age of information technology, information access in a convenient
manner has gained importance. Since speech is a primary mode of communication
among human beings, it is natural for people to expect to be able to carry out
spoken dialogue with computer. Speech recognition system permits ordinary
people to speak to the computer to retrieve information. It is desirable to
have a human computer dialogue in local language. Hindi being the most widely
spoken Language in India is the natural primary human language candidate for
human machine interaction. There are five pairs of vowels in Hindi languages;
one member is longer than the other one. This paper describes an overview of
speech recognition system that includes how speech is produced and the
properties and characteristics of Hindi Phoneme.",2013-05-09T08:44:58Z,http://arxiv.org/pdf/1305.2847v1,"['cs.CL', 'cs.SD']"
1601.02553v2,Environmental Noise Embeddings for Robust Speech Recognition,"['Suyoun Kim', 'Bhiksha Raj', 'Ian Lane']","We propose a novel deep neural network architecture for speech recognition
that explicitly employs knowledge of the background environmental noise within
a deep neural network acoustic model. A deep neural network is used to predict
the acoustic environment in which the system in being used. The discriminative
embedding generated at the bottleneck layer of this network is then
concatenated with traditional acoustic features as input to a deep neural
network acoustic model. Through a series of experiments on Resource Management,
CHiME-3 task, and Aurora4, we show that the proposed approach significantly
improves speech recognition accuracy in noisy and highly reverberant
environments, outperforming multi-condition training, noise-aware training,
i-vector framework, and multi-task learning on both in-domain noise and unseen
noise.",2016-01-11T18:38:18Z,http://arxiv.org/pdf/1601.02553v2,['cs.CL']
1703.04783v1,Multichannel End-to-end Speech Recognition,"['Tsubasa Ochiai', 'Shinji Watanabe', 'Takaaki Hori', 'John R. Hershey']","The field of speech recognition is in the midst of a paradigm shift:
end-to-end neural networks are challenging the dominance of hidden Markov
models as a core technology. Using an attention mechanism in a recurrent
encoder-decoder architecture solves the dynamic time alignment problem,
allowing joint end-to-end training of the acoustic and language modeling
components. In this paper we extend the end-to-end framework to encompass
microphone array signal processing for noise suppression and speech enhancement
within the acoustic encoding network. This allows the beamforming components to
be optimized jointly within the recognition architecture to improve the
end-to-end speech recognition objective. Experiments on the noisy speech
benchmarks (CHiME-4 and AMI) show that our multichannel end-to-end system
outperformed the attention-based baseline with input from a conventional
adaptive beamformer.",2017-03-14T22:28:51Z,http://arxiv.org/pdf/1703.04783v1,"['cs.SD', 'cs.CL']"
1708.06073v2,The Microsoft 2017 Conversational Speech Recognition System,"['W. Xiong', 'L. Wu', 'F. Alleva', 'J. Droppo', 'X. Huang', 'A. Stolcke']","We describe the 2017 version of Microsoft's conversational speech recognition
system, in which we update our 2016 system with recent developments in
neural-network-based acoustic and language modeling to further advance the
state of the art on the Switchboard speech recognition task. The system adds a
CNN-BLSTM acoustic model to the set of model architectures we combined
previously, and includes character-based and dialog session aware LSTM language
models in rescoring. For system combination we adopt a two-stage approach,
whereby subsets of acoustic models are first combined at the senone/frame
level, followed by a word-level voting via confusion networks. We also added a
confusion network rescoring step after system combination. The resulting system
yields a 5.1\% word error rate on the 2000 Switchboard evaluation set.",2017-08-21T03:17:23Z,http://arxiv.org/pdf/1708.06073v2,['cs.CL']
1710.11201v1,Deep word embeddings for visual speech recognition,"['Themos Stafylakis', 'Georgios Tzimiropoulos']","In this paper we present a deep learning architecture for extracting word
embeddings for visual speech recognition. The embeddings summarize the
information of the mouth region that is relevant to the problem of word
recognition, while suppressing other types of variability such as speaker, pose
and illumination. The system is comprised of a spatiotemporal convolutional
layer, a Residual Network and bidirectional LSTMs and is trained on the
Lipreading in-the-wild database. We first show that the proposed architecture
goes beyond state-of-the-art on closed-set word identification, by attaining
11.92% error rate on a vocabulary of 500 words. We then examine the capacity of
the embeddings in modelling words unseen during training. We deploy
Probabilistic Linear Discriminant Analysis (PLDA) to model the embeddings and
perform low-shot learning experiments on words unseen during training. The
experiments demonstrate that word-level visual speech recognition is feasible
even in cases where the target words are not included in the training set.",2017-10-30T19:09:29Z,http://arxiv.org/pdf/1710.11201v1,['cs.CV']
1803.03759v2,Speech Recognition: Keyword Spotting Through Image Recognition,"['Sanjay Krishna Gouda', 'Salil Kanetkar', 'David Harrison', 'Manfred K Warmuth']","The problem of identifying voice commands has always been a challenge due to
the presence of noise and variability in speed, pitch, etc. We will compare the
efficacies of several neural network architectures for the speech recognition
problem. In particular, we will build a model to determine whether a one second
audio clip contains a particular word (out of a set of 10), an unknown word, or
silence. The models to be implemented are a CNN recommended by the Tensorflow
Speech Recognition tutorial, a low-latency CNN, and an adversarially trained
CNN. The result is a demonstration of how to convert a problem in audio
recognition to the better-studied domain of image classification, where the
powerful techniques of convolutional neural networks are fully developed.
Additionally, we demonstrate the applicability of the technique of Virtual
Adversarial Training (VAT) to this problem domain, functioning as a powerful
regularizer with promising potential future applications.",2018-03-10T05:16:18Z,http://arxiv.org/pdf/1803.03759v2,"['stat.ML', 'cs.LG']"
2107.00921v1,Supervised Contrastive Learning for Accented Speech Recognition,"['Tao Han', 'Hantao Huang', 'Ziang Yang', 'Wei Han']","Neural network based speech recognition systems suffer from performance
degradation due to accented speech, especially unfamiliar accents. In this
paper, we study the supervised contrastive learning framework for accented
speech recognition. To build different views (similar ""positive"" data samples)
for contrastive learning, three data augmentation techniques including noise
injection, spectrogram augmentation and TTS-same-sentence generation are
further investigated. From the experiments on the Common Voice dataset, we have
shown that contrastive learning helps to build data-augmentation invariant and
pronunciation invariant representations, which significantly outperforms
traditional joint training methods in both zero-shot and full-shot settings.
Experiments show that contrastive learning can improve accuracy by 3.66%
(zero-shot) and 3.78% (full-shot) on average, comparing to the joint training
method.",2021-07-02T09:23:33Z,http://arxiv.org/pdf/2107.00921v1,"['cs.SD', 'cs.LG', 'eess.AS']"
1912.08639v2,Detecting Adversarial Attacks On Audiovisual Speech Recognition,"['Pingchuan Ma', 'Stavros Petridis', 'Maja Pantic']","Adversarial attacks pose a threat to deep learning models. However, research
on adversarial detection methods, especially in the multi-modal domain, is very
limited. In this work, we propose an efficient and straightforward detection
method based on the temporal correlation between audio and video streams. The
main idea is that the correlation between audio and video in adversarial
examples will be lower than benign examples due to added adversarial noise. We
use the synchronisation confidence score as a proxy for audiovisual correlation
and based on it we can detect adversarial attacks. To the best of our
knowledge, this is the first work on detection of adversarial attacks on
audiovisual speech recognition models. We apply recent adversarial attacks on
two audiovisual speech recognition models trained on the GRID and LRW datasets.
The experimental results demonstrate that the proposed approach is an effective
way for detecting such attacks.",2019-12-18T14:43:43Z,http://arxiv.org/pdf/1912.08639v2,"['cs.CV', 'cs.SD', 'eess.AS']"
2005.08100v1,Conformer: Convolution-augmented Transformer for Speech Recognition,"['Anmol Gulati', 'James Qin', 'Chung-Cheng Chiu', 'Niki Parmar', 'Yu Zhang', 'Jiahui Yu', 'Wei Han', 'Shibo Wang', 'Zhengdong Zhang', 'Yonghui Wu', 'Ruoming Pang']","Recently Transformer and Convolution neural network (CNN) based models have
shown promising results in Automatic Speech Recognition (ASR), outperforming
Recurrent neural networks (RNNs). Transformer models are good at capturing
content-based global interactions, while CNNs exploit local features
effectively. In this work, we achieve the best of both worlds by studying how
to combine convolution neural networks and transformers to model both local and
global dependencies of an audio sequence in a parameter-efficient way. To this
regard, we propose the convolution-augmented transformer for speech
recognition, named Conformer. Conformer significantly outperforms the previous
Transformer and CNN based models achieving state-of-the-art accuracies. On the
widely used LibriSpeech benchmark, our model achieves WER of 2.1%/4.3% without
using a language model and 1.9%/3.9% with an external language model on
test/testother. We also observe competitive performance of 2.7%/6.3% with a
small model of only 10M parameters.",2020-05-16T20:56:25Z,http://arxiv.org/pdf/2005.08100v1,"['eess.AS', 'cs.LG', 'cs.SD']"
2104.10757v1,Scene-aware Far-field Automatic Speech Recognition,"['Zhenyu Tang', 'Dinesh Manocha']","We propose a novel method for generating scene-aware training data for
far-field automatic speech recognition. We use a deep learning-based estimator
to non-intrusively compute the sub-band reverberation time of an environment
from its speech samples. We model the acoustic characteristics of a scene with
its reverberation time and represent it using a multivariate Gaussian
distribution. We use this distribution to select acoustic impulse responses
from a large real-world dataset for augmenting speech data. The speech
recognition system trained on our scene-aware data consistently outperforms the
system trained using many more random acoustic impulse responses on the REVERB
and the AMI far-field benchmarks. In practice, we obtain 2.64% absolute
improvement in word error rate compared with using training data of the same
size with uniformly distributed reverberation times.",2021-04-21T20:58:30Z,http://arxiv.org/pdf/2104.10757v1,"['eess.AS', 'cs.SD']"
1909.12408v3,Optimizing Speech Recognition For The Edge,"['Yuan Shangguan', 'Jian Li', 'Qiao Liang', 'Raziel Alvarez', 'Ian McGraw']","While most deployed speech recognition systems today still run on servers, we
are in the midst of a transition towards deployments on edge devices. This leap
to the edge is powered by the progression from traditional speech recognition
pipelines to end-to-end (E2E) neural architectures, and the parallel
development of more efficient neural network topologies and optimization
techniques. Thus, we are now able to create highly accurate speech recognizers
that are both small and fast enough to execute on typical mobile devices. In
this paper, we begin with a baseline RNN-Transducer architecture comprised of
Long Short-Term Memory (LSTM) layers. We then experiment with a variety of more
computationally efficient layer types, as well as apply optimization techniques
like neural connection pruning and parameter quantization to construct a small,
high quality, on-device speech recognizer that is an order of magnitude smaller
than the baseline system without any optimizations.",2019-09-26T21:43:53Z,http://arxiv.org/pdf/1909.12408v3,"['cs.CL', 'cs.LG', 'eess.AS']"
2011.01570v1,Dynamic latency speech recognition with asynchronous revision,"['Mingkun Huang', 'Meng Cai', 'Jun Zhang', 'Yang Zhang', 'Yongbin You', 'Yi He', 'Zejun Ma']","In this work we propose an inference technique, asynchronous revision, to
unify streaming and non-streaming speech recognition models. Specifically, we
achieve dynamic latency with only one model by using arbitrary right context
during inference. The model is composed of a stack of convolutional layers for
audio encoding. In inference stage, the history states of encoder and decoder
can be asynchronously revised to trade off between the latency and the accuracy
of the model. To alleviate training and inference mismatch, we propose a
training technique, segment cropping, which randomly splits input utterances
into several segments with forward connections. This allows us to have dynamic
latency speech recognition results with large improvements in accuracy.
Experiments show that our dynamic latency model with asynchronous revision
gives 8\%-14\% relative improvements over the streaming models.",2020-11-03T08:50:43Z,http://arxiv.org/pdf/2011.01570v1,"['eess.AS', 'cs.SD']"
1610.05256v2,Achieving Human Parity in Conversational Speech Recognition,"['W. Xiong', 'J. Droppo', 'X. Huang', 'F. Seide', 'M. Seltzer', 'A. Stolcke', 'D. Yu', 'G. Zweig']","Conversational speech recognition has served as a flagship speech recognition
task since the release of the Switchboard corpus in the 1990s. In this paper,
we measure the human error rate on the widely used NIST 2000 test set, and find
that our latest automated system has reached human parity. The error rate of
professional transcribers is 5.9% for the Switchboard portion of the data, in
which newly acquainted pairs of people discuss an assigned topic, and 11.3% for
the CallHome portion where friends and family members have open-ended
conversations. In both cases, our automated system establishes a new state of
the art, and edges past the human benchmark, achieving error rates of 5.8% and
11.0%, respectively. The key to our system's performance is the use of various
convolutional and LSTM acoustic model architectures, combined with a novel
spatial smoothing method and lattice-free MMI acoustic training, multiple
recurrent neural network language modeling approaches, and a systematic use of
system combination.",2016-10-17T18:40:50Z,http://arxiv.org/pdf/1610.05256v2,"['cs.CL', 'eess.AS']"
1806.02786v1,Domain Adversarial Training for Accented Speech Recognition,"['Sining Sun', 'Ching-Feng Yeh', 'Mei-Yuh Hwang', 'Mari Ostendorf', 'Lei Xie']","In this paper, we propose a domain adversarial training (DAT) algorithm to
alleviate the accented speech recognition problem. In order to reduce the
mismatch between labeled source domain data (""standard"" accent) and unlabeled
target domain data (with heavy accents), we augment the learning objective for
a Kaldi TDNN network with a domain adversarial training (DAT) objective to
encourage the model to learn accent-invariant features. In experiments with
three Mandarin accents, we show that DAT yields up to 7.45% relative character
error rate reduction when we do not have transcriptions of the accented speech,
compared with the baseline trained on standard accent data only. We also find a
benefit from DAT when used in combination with training from automatic
transcriptions on the accented data. Furthermore, we find that DAT is superior
to multi-task learning for accented speech recognition.",2018-06-07T17:02:54Z,http://arxiv.org/pdf/1806.02786v1,['cs.CL']
2102.00291v1,Speech Recognition by Simply Fine-tuning BERT,"['Wen-Chin Huang', 'Chia-Hua Wu', 'Shang-Bao Luo', 'Kuan-Yu Chen', 'Hsin-Min Wang', 'Tomoki Toda']","We propose a simple method for automatic speech recognition (ASR) by
fine-tuning BERT, which is a language model (LM) trained on large-scale
unlabeled text data and can generate rich contextual representations. Our
assumption is that given a history context sequence, a powerful LM can narrow
the range of possible choices and the speech signal can be used as a simple
clue. Hence, comparing to conventional ASR systems that train a powerful
acoustic model (AM) from scratch, we believe that speech recognition is
possible by simply fine-tuning a BERT model. As an initial study, we
demonstrate the effectiveness of the proposed idea on the AISHELL dataset and
show that stacking a very simple AM on top of BERT can yield reasonable
performance.",2021-01-30T19:06:14Z,http://arxiv.org/pdf/2102.00291v1,"['cs.SD', 'cs.CL', 'eess.AS']"
2106.04897v2,Unsupervised Automatic Speech Recognition: A Review,"['Hanan Aldarmaki', 'Asad Ullah', 'Nazar Zaki']","Automatic Speech Recognition (ASR) systems can be trained to achieve
remarkable performance given large amounts of manually transcribed speech, but
large labeled data sets can be difficult or expensive to acquire for all
languages of interest. In this paper, we review the research literature to
identify models and ideas that could lead to fully unsupervised ASR, including
unsupervised segmentation of the speech signal, unsupervised mapping from
speech segments to text, and semi-supervised models with nominal amounts of
labeled examples. The objective of the study is to identify the limitations of
what can be learned from speech data alone and to understand the minimum
requirements for speech recognition. Identifying these limitations would help
optimize the resources and efforts in ASR development for low-resource
languages.",2021-06-09T08:33:20Z,http://arxiv.org/pdf/2106.04897v2,"['cs.CL', 'cs.SD', 'eess.AS']"
2111.00161v3,Pseudo-Labeling for Massively Multilingual Speech Recognition,"['Loren Lugosch', 'Tatiana Likhomanenko', 'Gabriel Synnaeve', 'Ronan Collobert']","Semi-supervised learning through pseudo-labeling has become a staple of
state-of-the-art monolingual speech recognition systems. In this work, we
extend pseudo-labeling to massively multilingual speech recognition with 60
languages. We propose a simple pseudo-labeling recipe that works well even with
low-resource languages: train a supervised multilingual model, fine-tune it
with semi-supervised learning on a target language, generate pseudo-labels for
that language, and train a final model using pseudo-labels for all languages,
either from scratch or by fine-tuning. Experiments on the labeled Common Voice
and unlabeled VoxPopuli datasets show that our recipe can yield a model with
better performance for many languages that also transfers well to LibriSpeech.",2021-10-30T03:30:17Z,http://arxiv.org/pdf/2111.00161v3,"['cs.CL', 'cs.SD', 'eess.AS']"
2201.01763v3,Robust Self-Supervised Audio-Visual Speech Recognition,"['Bowen Shi', 'Wei-Ning Hsu', 'Abdelrahman Mohamed']","Audio-based automatic speech recognition (ASR) degrades significantly in
noisy environments and is particularly vulnerable to interfering speech, as the
model cannot determine which speaker to transcribe. Audio-visual speech
recognition (AVSR) systems improve robustness by complementing the audio stream
with the visual information that is invariant to noise and helps the model
focus on the desired speaker. However, previous AVSR work focused solely on the
supervised learning setup; hence the progress was hindered by the amount of
labeled data available. In this work, we present a self-supervised AVSR
framework built upon Audio-Visual HuBERT (AV-HuBERT), a state-of-the-art
audio-visual speech representation learning model. On the largest available
AVSR benchmark dataset LRS3, our approach outperforms prior state-of-the-art by
~50% (28.0% vs. 14.1%) using less than 10% of labeled data (433hr vs. 30hr) in
the presence of babble noise, while reducing the WER of an audio-based model by
over 75% (25.8% vs. 5.8%) on average.",2022-01-05T18:50:50Z,http://arxiv.org/pdf/2201.01763v3,"['cs.SD', 'cs.CV', 'cs.LG', 'eess.AS']"
2306.07926v1,A Theory of Unsupervised Speech Recognition,"['Liming Wang', 'Mark Hasegawa-Johnson', 'Chang D. Yoo']","Unsupervised speech recognition (ASR-U) is the problem of learning automatic
speech recognition (ASR) systems from unpaired speech-only and text-only
corpora. While various algorithms exist to solve this problem, a theoretical
framework is missing from studying their properties and addressing such issues
as sensitivity to hyperparameters and training instability. In this paper, we
proposed a general theoretical framework to study the properties of ASR-U
systems based on random matrix theory and the theory of neural tangent kernels.
Such a framework allows us to prove various learnability conditions and sample
complexity bounds of ASR-U. Extensive ASR-U experiments on synthetic languages
with three classes of transition graphs provide strong empirical evidence for
our theory (code available at cactuswiththoughts/UnsupASRTheory.git).",2023-06-09T08:12:27Z,http://arxiv.org/pdf/2306.07926v1,"['eess.AS', 'cs.CL', 'cs.LG', 'cs.SD']"
2312.06558v1,Deep Photonic Reservoir Computer for Speech Recognition,"['Enrico Picco', 'Alessandro Lupo', 'Serge Massar']","Speech recognition is a critical task in the field of artificial intelligence
and has witnessed remarkable advancements thanks to large and complex neural
networks, whose training process typically requires massive amounts of labeled
data and computationally intensive operations. An alternative paradigm,
reservoir computing, is energy efficient and is well adapted to implementation
in physical substrates, but exhibits limitations in performance when compared
to more resource-intensive machine learning algorithms. In this work we address
this challenge by investigating different architectures of interconnected
reservoirs, all falling under the umbrella of deep reservoir computing. We
propose a photonic-based deep reservoir computer and evaluate its effectiveness
on different speech recognition tasks. We show specific design choices that aim
to simplify the practical implementation of a reservoir computer while
simultaneously achieving high-speed processing of high-dimensional audio
signals. Overall, with the present work we hope to help the advancement of
low-power and high-performance neuromorphic hardware.",2023-12-11T17:43:58Z,http://arxiv.org/pdf/2312.06558v1,"['cs.NE', 'cs.SD', 'eess.AS', 'physics.optics']"
2406.00038v1,ViSpeR: Multilingual Audio-Visual Speech Recognition,"['Sanath Narayan', 'Yasser Abdelaziz Dahou Djilali', 'Ankit Singh', 'Eustache Le Bihan', 'Hakim Hacid']","This work presents an extensive and detailed study on Audio-Visual Speech
Recognition (AVSR) for five widely spoken languages: Chinese, Spanish, English,
Arabic, and French. We have collected large-scale datasets for each language
except for English, and have engaged in the training of supervised learning
models. Our model, ViSpeR, is trained in a multi-lingual setting, resulting in
competitive performance on newly established benchmarks for each language. The
datasets and models are released to the community with an aim to serve as a
foundation for triggering and feeding further research work and exploration on
Audio-Visual Speech Recognition, an increasingly important area of research.
Code available at
\href{https://github.com/YasserdahouML/visper}{https://github.com/YasserdahouML/visper}.",2024-05-27T14:48:51Z,http://arxiv.org/pdf/2406.00038v1,"['cs.CL', 'cs.AI']"
2406.13431v2,Children's Speech Recognition through Discrete Token Enhancement,"['Vrunda N. Sukhadia', 'Shammur Absar Chowdhury']","Children's speech recognition is considered a low-resource task mainly due to
the lack of publicly available data. There are several reasons for such data
scarcity, including expensive data collection and annotation processes, and
data privacy, among others. Transforming speech signals into discrete tokens
that do not carry sensitive information but capture both linguistic and
acoustic information could be a solution for privacy concerns. In this study,
we investigate the integration of discrete speech tokens into children's speech
recognition systems as input without significantly degrading the ASR
performance. Additionally, we explored single-view and multi-view strategies
for creating these discrete labels. Furthermore, we tested the models for
generalization capabilities with unseen domain and nativity dataset. Results
reveal that the discrete token ASR for children achieves nearly equivalent
performance with an approximate 83% reduction in parameters.",2024-06-19T10:45:12Z,http://arxiv.org/pdf/2406.13431v2,"['cs.CL', 'cs.SD', 'eess.AS']"
2409.07210v1,Enhancing CTC-Based Visual Speech Recognition,"['Hendrik Laux', 'Anke Schmeink']","This paper presents LiteVSR2, an enhanced version of our previously
introduced efficient approach to Visual Speech Recognition (VSR). Building upon
our knowledge distillation framework from a pre-trained Automatic Speech
Recognition (ASR) model, we introduce two key improvements: a stabilized video
preprocessing technique and feature normalization in the distillation process.
These improvements yield substantial performance gains on the LRS2 and LRS3
benchmarks, positioning LiteVSR2 as the current best CTC-based VSR model
without increasing the volume of training data or computational resources
utilized. Furthermore, we explore the scalability of our approach by examining
performance metrics across varying model complexities and training data
volumes. LiteVSR2 maintains the efficiency of its predecessor while
significantly enhancing accuracy, thereby demonstrating the potential for
resource-efficient advancements in VSR technology.",2024-09-11T12:02:42Z,http://arxiv.org/pdf/2409.07210v1,"['cs.CV', 'cs.SD', 'eess.AS']"
2410.03752v1,Efficient Streaming LLM for Speech Recognition,"['Junteng Jia', 'Gil Keren', 'Wei Zhou', 'Egor Lakomkin', 'Xiaohui Zhang', 'Chunyang Wu', 'Frank Seide', 'Jay Mahadeokar', 'Ozlem Kalinli']","Recent works have shown that prompting large language models with audio
encodings can unlock speech recognition capabilities. However, existing
techniques do not scale efficiently, especially while handling long form
streaming audio inputs -- not only do they extrapolate poorly beyond the audio
length seen during training, but they are also computationally inefficient due
to the quadratic cost of attention.
  In this work, we introduce SpeechLLM-XL, a linear scaling decoder-only model
for streaming speech recognition. We process audios in configurable chunks
using limited attention window for reduced computation, and the text tokens for
each audio chunk are generated auto-regressively until an EOS is predicted.
During training, the transcript is segmented into chunks, using a CTC forced
alignment estimated from encoder output. SpeechLLM-XL with 1.28 seconds chunk
size achieves 2.7%/6.7% WER on LibriSpeech test clean/other, and it shows no
quality degradation on long form utterances 10x longer than the training
utterances.",2024-10-02T01:54:35Z,http://arxiv.org/pdf/2410.03752v1,"['cs.SD', 'cs.AI', 'cs.CL', 'eess.AS']"
2506.02178v1,Cocktail-Party Audio-Visual Speech Recognition,"['Thai-Binh Nguyen', 'Ngoc-Quan Pham', 'Alexander Waibel']","Audio-Visual Speech Recognition (AVSR) offers a robust solution for speech
recognition in challenging environments, such as cocktail-party scenarios,
where relying solely on audio proves insufficient. However, current AVSR models
are often optimized for idealized scenarios with consistently active speakers,
overlooking the complexities of real-world settings that include both speaking
and silent facial segments. This study addresses this gap by introducing a
novel audio-visual cocktail-party dataset designed to benchmark current AVSR
systems and highlight the limitations of prior approaches in realistic noisy
conditions. Additionally, we contribute a 1526-hour AVSR dataset comprising
both talking-face and silent-face segments, enabling significant performance
gains in cocktail-party environments. Our approach reduces WER by 67% relative
to the state-of-the-art, reducing WER from 119% to 39.2% in extreme noise,
without relying on explicit segmentation cues.",2025-06-02T19:07:51Z,http://arxiv.org/pdf/2506.02178v1,"['cs.SD', 'cs.CL']"
2509.01939v1,Group Relative Policy Optimization for Speech Recognition,"['Prashanth Gurunath Shivakumar', 'Yile Gu', 'Ankur Gandhe', 'Ivan Bulyko']","Speech Recognition has seen a dramatic shift towards adopting Large Language
Models (LLMs). This shift is partly driven by good scalability properties
demonstrated by LLMs, ability to leverage large amounts of labelled, unlabelled
speech and text data, streaming capabilities with auto-regressive framework and
multi-tasking with instruction following characteristics of LLMs. However,
simple next-token prediction objective, typically employed with LLMs, have
certain limitations in performance and challenges with hallucinations. In this
paper, we propose application of Group Relative Policy Optimization (GRPO) to
enable reinforcement learning from human feedback for automatic speech
recognition (ASR). We design simple rule based reward functions to guide the
policy updates. We demonstrate significant improvements in word error rate
(upto 18.4% relative), reduction in hallucinations, increased robustness on
out-of-domain datasets and effectiveness in domain adaptation.",2025-09-02T04:20:12Z,http://arxiv.org/pdf/2509.01939v1,['eess.AS']
2108.00084v1,The History of Speech Recognition to the Year 2030,['Awni Hannun'],"The decade from 2010 to 2020 saw remarkable improvements in automatic speech
recognition. Many people now use speech recognition on a daily basis, for
example to perform voice search queries, send text messages, and interact with
voice assistants like Amazon Alexa and Siri by Apple. Before 2010 most people
rarely used speech recognition. Given the remarkable changes in the state of
speech recognition over the previous decade, what can we expect over the coming
decade? I attempt to forecast the state of speech recognition research and
applications by the year 2030. While the changes to general speech recognition
accuracy will not be as dramatic as in the previous decade, I suggest we have
an exciting decade of progress in speech technology ahead of us.",2021-07-30T21:19:33Z,http://arxiv.org/pdf/2108.00084v1,"['cs.CL', 'cs.SD', 'eess.AS']"
2312.10959v1,Speaker Mask Transformer for Multi-talker Overlapped Speech Recognition,"['Peng Shen', 'Xugang Lu', 'Hisashi Kawai']","Multi-talker overlapped speech recognition remains a significant challenge,
requiring not only speech recognition but also speaker diarization tasks to be
addressed. In this paper, to better address these tasks, we first introduce
speaker labels into an autoregressive transformer-based speech recognition
model to support multi-speaker overlapped speech recognition. Then, to improve
speaker diarization, we propose a novel speaker mask branch to detection the
speech segments of individual speakers. With the proposed model, we can perform
both speech recognition and speaker diarization tasks simultaneously using a
single model. Experimental results on the LibriSpeech-based overlapped dataset
demonstrate the effectiveness of the proposed method in both speech recognition
and speaker diarization tasks, particularly enhancing the accuracy of speaker
diarization in relatively complex multi-talker scenarios.",2023-12-18T06:29:53Z,http://arxiv.org/pdf/2312.10959v1,"['cs.SD', 'cs.CL', 'eess.AS']"
0001023v1,Structured Language Modeling for Speech Recognition,"['Ciprian Chelba', 'Frederick Jelinek']","A new language model for speech recognition is presented. The model develops
hidden hierarchical syntactic-like structure incrementally and uses it to
extract meaningful information from the word history, thus complementing the
locality of currently used trigram models. The structured language model (SLM)
and its performance in a two-pass speech recognizer --- lattice decoding ---
are presented. Experiments on the WSJ corpus show an improvement in both
perplexity (PPL) and word error rate (WER) over conventional trigram models.",2000-01-25T19:35:01Z,http://arxiv.org/pdf/cs/0001023v1,"['cs.CL', 'G.3, I.2.7, I.5.1, I.5.4']"
1711.10271v1,Exploiting Nontrivial Connectivity for Automatic Speech Recognition,"['Marius Paraschiv', 'Lasse Borgholt', 'Tycho Max Sylvester Tax', 'Marco Singh', 'Lars Maaløe']","Nontrivial connectivity has allowed the training of very deep networks by
addressing the problem of vanishing gradients and offering a more efficient
method of reusing parameters. In this paper we make a comparison between
residual networks, densely-connected networks and highway networks on an image
classification task. Next, we show that these methodologies can easily be
deployed into automatic speech recognition and provide significant improvements
to existing models.",2017-11-28T13:13:41Z,http://arxiv.org/pdf/1711.10271v1,"['cs.SD', 'eess.AS', 'stat.ML']"
2108.12953v1,Multi-Channel Transformer Transducer for Speech Recognition,"['Feng-Ju Chang', 'Martin Radfar', 'Athanasios Mouchtaris', 'Maurizio Omologo']","Multi-channel inputs offer several advantages over single-channel, to improve
the robustness of on-device speech recognition systems. Recent work on
multi-channel transformer, has proposed a way to incorporate such inputs into
end-to-end ASR for improved accuracy. However, this approach is characterized
by a high computational complexity, which prevents it from being deployed in
on-device systems. In this paper, we present a novel speech recognition model,
Multi-Channel Transformer Transducer (MCTT), which features end-to-end
multi-channel training, low computation cost, and low latency so that it is
suitable for streaming decoding in on-device speech recognition. In a far-field
in-house dataset, our MCTT outperforms stagewise multi-channel models with
transformer-transducer up to 6.01% relative WER improvement (WERR). In
addition, MCTT outperforms the multi-channel transformer up to 11.62% WERR, and
is 15.8 times faster in terms of inference speed. We further show that we can
improve the computational cost of MCTT by constraining the future and previous
context in attention computations.",2021-08-30T01:50:51Z,http://arxiv.org/pdf/2108.12953v1,"['eess.AS', 'cs.LG', 'cs.SD']"
2010.10682v3,VenoMave: Targeted Poisoning Against Speech Recognition,"['Hojjat Aghakhani', 'Lea Schönherr', 'Thorsten Eisenhofer', 'Dorothea Kolossa', 'Thorsten Holz', 'Christopher Kruegel', 'Giovanni Vigna']","Despite remarkable improvements, automatic speech recognition is susceptible
to adversarial perturbations. Compared to standard machine learning
architectures, these attacks are significantly more challenging, especially
since the inputs to a speech recognition system are time series that contain
both acoustic and linguistic properties of speech. Extracting all
recognition-relevant information requires more complex pipelines and an
ensemble of specialized components. Consequently, an attacker needs to consider
the entire pipeline. In this paper, we present VENOMAVE, the first
training-time poisoning attack against speech recognition. Similar to the
predominantly studied evasion attacks, we pursue the same goal: leading the
system to an incorrect and attacker-chosen transcription of a target audio
waveform. In contrast to evasion attacks, however, we assume that the attacker
can only manipulate a small part of the training data without altering the
target audio waveform at runtime. We evaluate our attack on two datasets:
TIDIGITS and Speech Commands. When poisoning less than 0.17% of the dataset,
VENOMAVE achieves attack success rates of more than 80.0%, without access to
the victim's network architecture or hyperparameters. In a more realistic
scenario, when the target audio waveform is played over the air in different
rooms, VENOMAVE maintains a success rate of up to 73.3%. Finally, VENOMAVE
achieves an attack transferability rate of 36.4% between two different model
architectures.",2020-10-21T00:30:08Z,http://arxiv.org/pdf/2010.10682v3,"['cs.SD', 'cs.CR', 'cs.LG', 'eess.AS']"
2210.06472v1,Inner speech recognition through electroencephalographic signals,"['Francesca Gasparini', 'Elisa Cazzaniga', 'Aurora Saibene']","This work focuses on inner speech recognition starting from EEG signals.
Inner speech recognition is defined as the internalized process in which the
person thinks in pure meanings, generally associated with an auditory imagery
of own inner ""voice"". The decoding of the EEG into text should be understood as
the classification of a limited number of words (commands) or the presence of
phonemes (units of sound that make up words). Speech-related BCIs provide
effective vocal communication strategies for controlling devices through speech
commands interpreted from brain signals, improving the quality of life of
people who have lost the capability to speak, by restoring communication with
their environment. Two public inner speech datasets are analysed. Using this
data, some classification models are studied and implemented starting from
basic methods such as Support Vector Machines, to ensemble methods such as the
eXtreme Gradient Boosting classifier up to the use of neural networks such as
Long Short Term Memory (LSTM) and Bidirectional Long Short Term Memory
(BiLSTM). With the LSTM and BiLSTM models, generally not used in the literature
of inner speech recognition, results in line with or superior to those present
in the stateof-the-art are obtained.",2022-10-11T08:29:12Z,http://arxiv.org/pdf/2210.06472v1,"['cs.HC', 'cs.AI', 'cs.SD', 'eess.AS', 'q-bio.NC']"
2211.08726v2,Streaming Joint Speech Recognition and Disfluency Detection,"['Hayato Futami', 'Emiru Tsunoo', 'Kentaro Shibata', 'Yosuke Kashiwagi', 'Takao Okuda', 'Siddhant Arora', 'Shinji Watanabe']","Disfluency detection has mainly been solved in a pipeline approach, as
post-processing of speech recognition. In this study, we propose
Transformer-based encoder-decoder models that jointly solve speech recognition
and disfluency detection, which work in a streaming manner. Compared to
pipeline approaches, the joint models can leverage acoustic information that
makes disfluency detection robust to recognition errors and provide non-verbal
clues. Moreover, joint modeling results in low-latency and lightweight
inference. We investigate two joint model variants for streaming disfluency
detection: a transcript-enriched model and a multi-task model. The
transcript-enriched model is trained on text with special tags indicating the
starting and ending points of the disfluent part. However, it has problems with
latency and standard language model adaptation, which arise from the additional
disfluency tags. We propose a multi-task model to solve such problems, which
has two output layers at the Transformer decoder; one for speech recognition
and the other for disfluency detection. It is modeled to be conditioned on the
currently recognized token with an additional token-dependency mechanism. We
show that the proposed joint models outperformed a BERT-based pipeline approach
in both accuracy and latency, on both the Switchboard and the corpus of
spontaneous Japanese.",2022-11-16T07:34:20Z,http://arxiv.org/pdf/2211.08726v2,"['cs.CL', 'cs.SD', 'eess.AS']"
1903.00739v1,Speech Recognition with no speech or with noisy speech,"['Gautam Krishna', 'Co Tran', 'Jianguo Yu', 'Ahmed H Tewfik']","The performance of automatic speech recognition systems(ASR) degrades in the
presence of noisy speech. This paper demonstrates that using
electroencephalography (EEG) can help automatic speech recognition systems
overcome performance loss in the presence of noise. The paper also shows that
distillation training of automatic speech recognition systems using EEG
features will increase their performance. Finally, we demonstrate the ability
to recognize words from EEG with no speech signal on a limited English
vocabulary with high accuracy.",2019-03-02T17:53:49Z,http://arxiv.org/pdf/1903.00739v1,"['cs.LG', 'stat.ML']"
2104.00259v1,"Interactive spatial speech recognition maps based on simulated speech
  recognition experiments",['Marc René Schädler'],"In their everyday life, the speech recognition performance of human listeners
is influenced by diverse factors, such as the acoustic environment, the talker
and listener positions, possibly impaired hearing, and optional hearing
devices. Prediction models come closer to considering all required factors
simultaneously to predict the individual speech recognition performance in
complex acoustic environments. While such predictions may still not be
sufficiently accurate for serious applications, they can already be performed
and demand an accessible representation. In this contribution, an interactive
representation of speech recognition performance is proposed, which focuses on
the listeners head orientation and the spatial dimensions of an acoustic scene.
A exemplary modeling toolchain, including an acoustic rendering model, a
hearing device model, and a listener model, was used to generate a data set for
demonstration purposes. Using the spatial speech recognition maps to explore
this data set demonstrated the suitability of the approach to observe possibly
relevant behavior. The proposed representation provides a suitable target to
compare and validate different modeling approaches in ecologically relevant
contexts. Eventually, it may serve as a tool to use validated prediction models
in the design of spaces and devices which take speech communication into
account.",2021-04-01T05:35:46Z,http://arxiv.org/pdf/2104.00259v1,"['eess.AS', 'cs.SD']"
0703049v1,Algorithm of Segment-Syllabic Synthesis in Speech Recognition Problem,"['Oleg N. Karpov', 'Olga A. Savenkova']","Speech recognition based on the syllable segment is discussed in this paper.
The principal search methods in space of states for the speech recognition
problem by segment-syllabic parameters trajectory synthesis are investigated.
Recognition as comparison the parameters trajectories in chosen speech units on
the sections of the segmented speech is realized. Some experimental results are
given and discussed.",2007-03-10T23:59:55Z,http://arxiv.org/pdf/cs/0703049v1,"['cs.SD', 'cs.CL']"
1906.08871v9,Advancing Speech Recognition With No Speech Or With Noisy Speech,"['Gautam Krishna', 'Co Tran', 'Mason Carnahan', 'Ahmed H Tewfik']","In this paper we demonstrate end-to-end continuous speech recognition (CSR)
using electroencephalography (EEG) signals with no speech signal as input. An
attention model based automatic speech recognition (ASR) and connectionist
temporal classification (CTC) based ASR systems were implemented for performing
recognition. We further demonstrate CSR for noisy speech by fusing with EEG
features.",2019-06-17T23:06:51Z,http://arxiv.org/pdf/1906.08871v9,"['eess.AS', 'cs.CL', 'cs.LG', 'cs.SD', 'stat.ML']"
2410.22903v1,"Augmenting Polish Automatic Speech Recognition System With Synthetic
  Data","['Łukasz Bondaruk', 'Jakub Kubiak', 'Mateusz Czyżnikiewicz']","This paper presents a system developed for submission to Poleval 2024, Task
3: Polish Automatic Speech Recognition Challenge. We describe Voicebox-based
speech synthesis pipeline and utilize it to augment Conformer and Whisper
speech recognition models with synthetic data. We show that addition of
synthetic speech to training improves achieved results significantly. We also
present final results achieved by our models in the competition.",2024-10-30T11:02:57Z,http://arxiv.org/pdf/2410.22903v1,"['eess.AS', 'cs.SD']"
1501.05530v1,Belief Hidden Markov Model for speech recognition,"['Siwar Jendoubi', 'Boutheina Ben Yaghlane', 'Arnaud Martin']","Speech Recognition searches to predict the spoken words automatically. These
systems are known to be very expensive because of using several pre-recorded
hours of speech. Hence, building a model that minimizes the cost of the
recognizer will be very interesting. In this paper, we present a new approach
for recognizing speech based on belief HMMs instead of proba-bilistic HMMs.
Experiments shows that our belief recognizer is insensitive to the lack of the
data and it can be trained using only one exemplary of each acoustic unit and
it gives a good recognition rates. Consequently, using the belief HMM
recognizer can greatly minimize the cost of these systems.",2015-01-22T15:20:28Z,http://arxiv.org/pdf/1501.05530v1,['cs.AI']
1612.04675v2,Recurrent Deep Stacking Networks for Speech Recognition,"['Peidong Wang', 'Zhongqiu Wang', 'Deliang Wang']","This paper presented our work on applying Recurrent Deep Stacking Networks
(RDSNs) to Robust Automatic Speech Recognition (ASR) tasks. In the paper, we
also proposed a more efficient yet comparable substitute to RDSN, Bi- Pass
Stacking Network (BPSN). The main idea of these two models is to add
phoneme-level information into acoustic models, transforming an acoustic model
to the combination of an acoustic model and a phoneme-level N-gram model.
Experiments showed that RDSN and BPsn can substantially improve the
performances over conventional DNNs.",2016-12-14T15:07:51Z,http://arxiv.org/pdf/1612.04675v2,"['cs.CL', 'cs.SD']"
1808.03570v1,Densely Connected Convolutional Networks for Speech Recognition,"['Chia Yu Li', 'Ngoc Thang Vu']","This paper presents our latest investigation on Densely Connected
Convolutional Networks (DenseNets) for acoustic modelling (AM) in automatic
speech recognition. DenseN-ets are very deep, compact convolutional neural
networks, which have demonstrated incredible improvements over the
state-of-the-art results on several data sets in computer vision. Our
experimental results show that DenseNet can be used for AM significantly
outperforming other neural-based models such as DNNs, CNNs, VGGs. Furthermore,
results on Wall Street Journal revealed that with only a half of the training
data DenseNet was able to outperform other models trained with the full data
set by a large margin.",2018-08-10T14:54:10Z,http://arxiv.org/pdf/1808.03570v1,['cs.CL']
2001.09727v1,Scaling Up Online Speech Recognition Using ConvNets,"['Vineel Pratap', 'Qiantong Xu', 'Jacob Kahn', 'Gilad Avidov', 'Tatiana Likhomanenko', 'Awni Hannun', 'Vitaliy Liptchinsky', 'Gabriel Synnaeve', 'Ronan Collobert']","We design an online end-to-end speech recognition system based on Time-Depth
Separable (TDS) convolutions and Connectionist Temporal Classification (CTC).
We improve the core TDS architecture in order to limit the future context and
hence reduce latency while maintaining accuracy. The system has almost three
times the throughput of a well tuned hybrid ASR baseline while also having
lower latency and a better word error rate. Also important to the efficiency of
the recognizer is our highly optimized beam search decoder. To show the impact
of our design choices, we analyze throughput, latency, accuracy, and discuss
how these metrics can be tuned based on the user requirements.",2020-01-27T12:55:02Z,http://arxiv.org/pdf/2001.09727v1,"['cs.CL', 'cs.SD', 'eess.AS']"
2001.11360v1,BUT Opensat 2019 Speech Recognition System,"['Martin Karafiát', 'Murali Karthick Baskar', 'Igor Szöke', 'Hari Krishna Vydana', 'Karel Veselý', 'Jan ""Honza\'\' Černocký']","The paper describes the BUT Automatic Speech Recognition (ASR) systems
submitted for OpenSAT evaluations under two domain categories such as low
resourced languages and public safety communications. The first was challenging
due to lack of training data, therefore various architectures and multilingual
approaches were employed. The combination led to superior performance. The
second domain was challenging due to recording in extreme conditions such as
specific channel, speaker under stress and high levels of noise. Data
augmentation process was inevitable to get reasonably good performance.",2020-01-30T14:35:34Z,http://arxiv.org/pdf/2001.11360v1,"['eess.AS', 'cs.LG', 'cs.SD']"
2303.13559v1,Enhancing Unsupervised Speech Recognition with Diffusion GANs,['Xianchao Wu'],"We enhance the vanilla adversarial training method for unsupervised Automatic
Speech Recognition (ASR) by a diffusion-GAN. Our model (1) injects instance
noises of various intensities to the generator's output and unlabeled reference
text which are sampled from pretrained phoneme language models with a length
constraint, (2) asks diffusion timestep-dependent discriminators to separate
them, and (3) back-propagates the gradients to update the generator.
Word/phoneme error rate comparisons with wav2vec-U under Librispeech (3.1% for
test-clean and 5.6% for test-other), TIMIT and MLS datasets, show that our
enhancement strategies work effectively.",2023-03-23T02:54:00Z,http://arxiv.org/pdf/2303.13559v1,"['cs.CL', 'cs.LG', 'cs.SD', 'eess.AS']"
2306.03778v1,Streaming Speech-to-Confusion Network Speech Recognition,"['Denis Filimonov', 'Prabhat Pandey', 'Ariya Rastrow', 'Ankur Gandhe', 'Andreas Stolcke']","In interactive automatic speech recognition (ASR) systems, low-latency
requirements limit the amount of search space that can be explored during
decoding, particularly in end-to-end neural ASR. In this paper, we present a
novel streaming ASR architecture that outputs a confusion network while
maintaining limited latency, as needed for interactive applications. We show
that 1-best results of our model are on par with a comparable RNN-T system,
while the richer hypothesis set allows second-pass rescoring to achieve 10-20\%
lower word error rate on the LibriSpeech task. We also show that our model
outperforms a strong RNN-T baseline on a far-field voice assistant task.",2023-06-02T20:28:14Z,http://arxiv.org/pdf/2306.03778v1,"['eess.AS', 'cs.CL']"
2410.00822v2,VHASR: A Multimodal Speech Recognition System With Vision Hotwords,"['Jiliang Hu', 'Zuchao Li', 'Ping Wang', 'Haojun Ai', 'Lefei Zhang', 'Hai Zhao']","The image-based multimodal automatic speech recognition (ASR) model enhances
speech recognition performance by incorporating audio-related image. However,
some works suggest that introducing image information to model does not help
improving ASR performance. In this paper, we propose a novel approach
effectively utilizing audio-related image information and set up VHASR, a
multimodal speech recognition system that uses vision as hotwords to strengthen
the model's speech recognition capability. Our system utilizes a dual-stream
architecture, which firstly transcribes the text on the two streams separately,
and then combines the outputs. We evaluate the proposed model on four datasets:
Flickr8k, ADE20k, COCO, and OpenImages. The experimental results show that
VHASR can effectively utilize key information in images to enhance the model's
speech recognition ability. Its performance not only surpasses unimodal ASR,
but also achieves SOTA among existing image-based multimodal ASR.",2024-10-01T16:06:02Z,http://arxiv.org/pdf/2410.00822v2,"['cs.SD', 'cs.CL', 'eess.AS']"
2011.04547v1,"Data Augmentation For Children's Speech Recognition -- The ""Ethiopian""
  System For The SLT 2021 Children Speech Recognition Challenge","['Guoguo Chen', 'Xingyu Na', 'Yongqing Wang', 'Zhiyong Yan', 'Junbo Zhang', 'Sifan Ma', 'Yujun Wang']","This paper presents the ""Ethiopian"" system for the SLT 2021 Children Speech
Recognition Challenge. Various data processing and augmentation techniques are
proposed to tackle children's speech recognition problem, especially the lack
of the children's speech recognition training data issue. Detailed experiments
are designed and conducted to show the effectiveness of each technique, across
different speech recognition toolkits and model architectures. Step by step, we
explain how we come up with our final system, which provides the
state-of-the-art results in the SLT 2021 Children Speech Recognition Challenge,
with 21.66% CER on the Track 1 evaluation set (4th place overall), and 16.53%
CER on the Track 2 evaluation set (1st place overall). Post-challenge analysis
shows that our system actually achieves 18.82% CER on the Track 1 evaluation
set, but we submitted the wrong version to the challenge organizer for Track 1.",2020-11-09T16:44:47Z,http://arxiv.org/pdf/2011.04547v1,"['cs.SD', 'eess.AS']"
1811.05097v2,Exploring RNN-Transducer for Chinese Speech Recognition,"['Senmao Wang', 'Pan Zhou', 'Wei Chen', 'Jia Jia', 'Lei Xie']","End-to-end approaches have drawn much attention recently for significantly
simplifying the construction of an automatic speech recognition (ASR) system.
RNN transducer (RNN-T) is one of the popular end-to-end methods. Previous
studies have shown that RNN-T is difficult to train and a very complex training
process is needed for a reasonable performance. In this paper, we explore RNN-T
for a Chinese large vocabulary continuous speech recognition (LVCSR) task and
aim to simplify the training process while maintaining performance. First, a
new strategy of learning rate decay is proposed to accelerate the model
convergence. Second, we find that adding convolutional layers at the beginning
of the network and using ordered data can discard the pre-training process of
the encoder without loss of performance. Besides, we design experiments to find
a balance among the usage of GPU memory, training circle and model performance.
Finally, we achieve 16.9% character error rate (CER) on our test set which is
2% absolute improvement from a strong BLSTM CE system with language model
trained on the same text corpus.",2018-11-13T04:37:11Z,http://arxiv.org/pdf/1811.05097v2,"['cs.CL', 'cs.LG', 'cs.SD', 'eess.AS']"
1811.09678v1,Speech recognition with quaternion neural networks,"['Titouan Parcollet', 'Mirco Ravanelli', 'Mohamed Morchid', 'Georges Linarès', 'Renato De Mori']","Neural network architectures are at the core of powerful automatic speech
recognition systems (ASR). However, while recent researches focus on novel
model architectures, the acoustic input features remain almost unchanged.
Traditional ASR systems rely on multidimensional acoustic features such as the
Mel filter bank energies alongside with the first, and second order derivatives
to characterize time-frames that compose the signal sequence. Considering that
these components describe three different views of the same element, neural
networks have to learn both the internal relations that exist within these
features, and external or global dependencies that exist between the
time-frames. Quaternion-valued neural networks (QNN), recently received an
important interest from researchers to process and learn such relations in
multidimensional spaces. Indeed, quaternion numbers and QNNs have shown their
efficiency to process multidimensional inputs as entities, to encode internal
dependencies, and to solve many tasks with up to four times less learning
parameters than real-valued models. We propose to investigate modern
quaternion-valued models such as convolutional and recurrent quaternion neural
networks in the context of speech recognition with the TIMIT dataset. The
experiments show that QNNs always outperform real-valued equivalent models with
way less free parameters, leading to a more efficient, compact, and expressive
representation of the relevant information.",2018-11-21T10:27:02Z,http://arxiv.org/pdf/1811.09678v1,"['eess.AS', 'cs.SD', 'stat.ML']"
1908.10992v1,Two-Pass End-to-End Speech Recognition,"['Tara N. Sainath', 'Ruoming Pang', 'David Rybach', 'Yanzhang He', 'Rohit Prabhavalkar', 'Wei Li', 'Mirkó Visontai', 'Qiao Liang', 'Trevor Strohman', 'Yonghui Wu', 'Ian McGraw', 'Chung-Cheng Chiu']","The requirements for many applications of state-of-the-art speech recognition
systems include not only low word error rate (WER) but also low latency.
Specifically, for many use-cases, the system must be able to decode utterances
in a streaming fashion and faster than real-time. Recently, a streaming
recurrent neural network transducer (RNN-T) end-to-end (E2E) model has shown to
be a good candidate for on-device speech recognition, with improved WER and
latency metrics compared to conventional on-device models [1]. However, this
model still lags behind a large state-of-the-art conventional model in quality
[2]. On the other hand, a non-streaming E2E Listen, Attend and Spell (LAS)
model has shown comparable quality to large conventional models [3]. This work
aims to bring the quality of an E2E streaming model closer to that of a
conventional system by incorporating a LAS network as a second-pass component,
while still abiding by latency constraints. Our proposed two-pass model
achieves a 17%-22% relative reduction in WER compared to RNN-T alone and
increases latency by a small fraction over RNN-T.",2019-08-29T00:18:05Z,http://arxiv.org/pdf/1908.10992v1,"['cs.CL', 'cs.SD', 'eess.AS']"
2005.09684v2,Exploring Transformers for Large-Scale Speech Recognition,"['Liang Lu', 'Changliang Liu', 'Jinyu Li', 'Yifan Gong']","While recurrent neural networks still largely define state-of-the-art speech
recognition systems, the Transformer network has been proven to be a
competitive alternative, especially in the offline condition. Most studies with
Transformers have been constrained in a relatively small scale setting, and
some forms of data argumentation approaches are usually applied to combat the
data sparsity issue. In this paper, we aim at understanding the behaviors of
Transformers in the large-scale speech recognition setting, where we have used
around 65,000 hours of training data. We investigated various aspects on
scaling up Transformers, including model initialization, warmup training as
well as different Layer Normalization strategies. In the streaming condition,
we compared the widely used attention mask based future context lookahead
approach to the Transformer-XL network. From our experiments, we show that
Transformers can achieve around 6% relative word error rate (WER) reduction
compared to the BLSTM baseline in the offline fashion, while in the streaming
fashion, Transformer-XL is comparable to LC-BLSTM with 800 millisecond latency
constraint.",2020-05-19T18:07:14Z,http://arxiv.org/pdf/2005.09684v2,"['eess.AS', 'cs.CL', 'cs.SD']"
2202.01405v1,Joint Speech Recognition and Audio Captioning,"['Chaitanya Narisetty', 'Emiru Tsunoo', 'Xuankai Chang', 'Yosuke Kashiwagi', 'Michael Hentschel', 'Shinji Watanabe']","Speech samples recorded in both indoor and outdoor environments are often
contaminated with secondary audio sources. Most end-to-end monaural speech
recognition systems either remove these background sounds using speech
enhancement or train noise-robust models. For better model interpretability and
holistic understanding, we aim to bring together the growing field of automated
audio captioning (AAC) and the thoroughly studied automatic speech recognition
(ASR). The goal of AAC is to generate natural language descriptions of contents
in audio samples. We propose several approaches for end-to-end joint modeling
of ASR and AAC tasks and demonstrate their advantages over traditional
approaches, which model these tasks independently. A major hurdle in evaluating
our proposed approach is the lack of labeled audio datasets with both speech
transcriptions and audio captions. Therefore we also create a multi-task
dataset by mixing the clean speech Wall Street Journal corpus with multiple
levels of background noises chosen from the AudioCaps dataset. We also perform
extensive experimental evaluation and show improvements of our proposed methods
as compared to existing state-of-the-art ASR and AAC methods.",2022-02-03T04:42:43Z,http://arxiv.org/pdf/2202.01405v1,"['eess.AS', 'cs.CL', 'cs.SD']"
2010.02384v1,Fine-Grained Grounding for Multimodal Speech Recognition,"['Tejas Srinivasan', 'Ramon Sanabria', 'Florian Metze', 'Desmond Elliott']","Multimodal automatic speech recognition systems integrate information from
images to improve speech recognition quality, by grounding the speech in the
visual context. While visual signals have been shown to be useful for
recovering entities that have been masked in the audio, these models should be
capable of recovering a broader range of word types. Existing systems rely on
global visual features that represent the entire image, but localizing the
relevant regions of the image will make it possible to recover a larger set of
words, such as adjectives and verbs. In this paper, we propose a model that
uses finer-grained visual information from different parts of the image, using
automatic object proposals. In experiments on the Flickr8K Audio Captions
Corpus, we find that our model improves over approaches that use global visual
features, that the proposals enable the model to recover entities and other
related words, such as adjectives, and that improvements are due to the model's
ability to localize the correct proposals.",2020-10-05T23:06:24Z,http://arxiv.org/pdf/2010.02384v1,['cs.CL']
2011.15023v2,Transformer-Transducers for Code-Switched Speech Recognition,"['Siddharth Dalmia', 'Yuzong Liu', 'Srikanth Ronanki', 'Katrin Kirchhoff']","We live in a world where 60% of the population can speak two or more
languages fluently. Members of these communities constantly switch between
languages when having a conversation. As automatic speech recognition (ASR)
systems are being deployed to the real-world, there is a need for practical
systems that can handle multiple languages both within an utterance or across
utterances. In this paper, we present an end-to-end ASR system using a
transformer-transducer model architecture for code-switched speech recognition.
We propose three modifications over the vanilla model in order to handle
various aspects of code-switching. First, we introduce two auxiliary loss
functions to handle the low-resource scenario of code-switching. Second, we
propose a novel mask-based training strategy with language ID information to
improve the label encoder training towards intra-sentential code-switching.
Finally, we propose a multi-label/multi-audio encoder structure to leverage the
vast monolingual speech corpora towards code-switching. We demonstrate the
efficacy of our proposed approaches on the SEAME dataset, a public
Mandarin-English code-switching corpus, achieving a mixed error rate of 18.5%
and 26.3% on test_man and test_sge sets respectively.",2020-11-30T17:27:41Z,http://arxiv.org/pdf/2011.15023v2,"['cs.CL', 'eess.AS']"
1906.08043v1,Real to H-space Encoder for Speech Recognition,"['Titouan Parcollet', 'Mohamed Morchid', 'Georges Linarès', 'Renato De Mori']","Deep neural networks (DNNs) and more precisely recurrent neural networks
(RNNs) are at the core of modern automatic speech recognition systems, due to
their efficiency to process input sequences. Recently, it has been shown that
different input representations, based on multidimensional algebras, such as
complex and quaternion numbers, are able to bring to neural networks a more
natural, compressive and powerful representation of the input signal by
outperforming common real-valued NNs. Indeed, quaternion-valued neural networks
(QNNs) better learn both internal dependencies, such as the relation between
the Mel-filter-bank value of a specific time frame and its time derivatives,
and global dependencies, describing the relations that exist between time
frames. Nonetheless, QNNs are limited to quaternion-valued input signals, and
it is difficult to benefit from this powerful representation with real-valued
input data. This paper proposes to tackle this weakness by introducing a
real-to-quaternion encoder that allows QNNs to process any one dimensional
input features, such as traditional Mel-filter-banks for automatic speech
recognition.",2019-06-17T20:07:45Z,http://arxiv.org/pdf/1906.08043v1,"['eess.AS', 'cs.CL', 'cs.SD']"
1906.10834v1,Essence Knowledge Distillation for Speech Recognition,"['Zhenchuan Yang', 'Chun Zhang', 'Weibin Zhang', 'Jianxiu Jin', 'Dongpeng Chen']","It is well known that a speech recognition system that combines multiple
acoustic models trained on the same data significantly outperforms a
single-model system. Unfortunately, real time speech recognition using a whole
ensemble of models is too computationally expensive. In this paper, we propose
to distill the knowledge of essence in an ensemble of models (i.e. the teacher
model) to a single model (i.e. the student model) that needs much less
computation to deploy. Previously, all the soften outputs of the teacher model
are used to optimize the student model. We argue that not all the outputs of
the ensemble are necessary to be distilled. Some of the outputs may even
contain noisy information that is useless or even harmful to the training of
the student model. In addition, we propose to train the student model with a
multitask learning approach by utilizing both the soften outputs of the teacher
model and the correct hard labels. The proposed method achieves some surprising
results on the Switchboard data set. When the student model is trained together
with the correct labels and the essence knowledge from the teacher model, it
not only significantly outperforms another single model with the same
architecture that is trained only with the correct labels, but also
consistently outperforms the teacher model that is used to generate the soft
labels.",2019-06-26T03:58:29Z,http://arxiv.org/pdf/1906.10834v1,"['cs.CL', 'cs.SD', 'eess.AS']"
2203.11325v2,Enhancing Speech Recognition Decoding via Layer Aggregation,"['Tomer Wullach', 'Shlomo E. Chazan']","Recently proposed speech recognition systems are designed to predict using
representations generated by their top layers, employing greedy decoding which
isolates each timestep from the rest of the sequence. Aiming for improved
performance, a beam search algorithm is frequently utilized and a language
model is incorporated to assist with ranking the top candidates. In this work,
we experiment with several speech recognition models and find that logits
predicted using the top layers may hamper beam search from achieving optimal
results. Specifically, we show that fined-tuned Wav2Vec 2.0 and HuBERT yield
highly confident predictions, and hypothesize that the predictions are based on
local information and may not take full advantage of the information encoded in
intermediate layers. To this end, we perform a layer analysis to reveal and
visualize how predictions evolve throughout the inference flow. We then propose
a prediction method that aggregates the top M layers, potentially leveraging
useful information encoded in intermediate layers and relaxing model
confidence. We showcase the effectiveness of our approach via beam search
decoding, conducting our experiments on Librispeech test and dev sets and
achieving WER, and CER reduction of up to 10% and 22%, respectively.",2022-03-21T20:28:06Z,http://arxiv.org/pdf/2203.11325v2,"['cs.CL', 'cs.SD', 'eess.AS']"
2203.13687v3,Chain-based Discriminative Autoencoders for Speech Recognition,"['Hung-Shin Lee', 'Pin-Tuan Huang', 'Yao-Fei Cheng', 'Hsin-Min Wang']","In our previous work, we proposed a discriminative autoencoder (DcAE) for
speech recognition. DcAE combines two training schemes into one. First, since
DcAE aims to learn encoder-decoder mappings, the squared error between the
reconstructed speech and the input speech is minimized. Second, in the code
layer, frame-based phonetic embeddings are obtained by minimizing the
categorical cross-entropy between ground truth labels and predicted
triphone-state scores. DcAE is developed based on the Kaldi toolkit by treating
various TDNN models as encoders. In this paper, we further propose three new
versions of DcAE. First, a new objective function that considers both
categorical cross-entropy and mutual information between ground truth and
predicted triphone-state sequences is used. The resulting DcAE is called a
chain-based DcAE (c-DcAE). For application to robust speech recognition, we
further extend c-DcAE to hierarchical and parallel structures, resulting in
hc-DcAE and pc-DcAE. In these two models, both the error between the
reconstructed noisy speech and the input noisy speech and the error between the
enhanced speech and the reference clean speech are taken into the objective
function. Experimental results on the WSJ and Aurora-4 corpora show that our
DcAE models outperform baseline systems.",2022-03-25T14:51:48Z,http://arxiv.org/pdf/2203.13687v3,"['cs.SD', 'cs.AI', 'cs.CL', 'cs.LG', 'cs.MM', 'eess.AS']"
2210.16238v1,Contextual-Utterance Training for Automatic Speech Recognition,"['Alejandro Gomez-Alanis', 'Lukas Drude', 'Andreas Schwarz', 'Rupak Vignesh Swaminathan', 'Simon Wiesler']","Recent studies of streaming automatic speech recognition (ASR) recurrent
neural network transducer (RNN-T)-based systems have fed the encoder with past
contextual information in order to improve its word error rate (WER)
performance. In this paper, we first propose a contextual-utterance training
technique which makes use of the previous and future contextual utterances in
order to do an implicit adaptation to the speaker, topic and acoustic
environment. Also, we propose a dual-mode contextual-utterance training
technique for streaming automatic speech recognition (ASR) systems. This
proposed approach allows to make a better use of the available acoustic context
in streaming models by distilling ""in-place"" the knowledge of a teacher, which
is able to see both past and future contextual utterances, to the student which
can only see the current and past contextual utterances. The experimental
results show that a conformer-transducer system trained with the proposed
techniques outperforms the same system trained with the classical RNN-T loss.
Specifically, the proposed technique is able to reduce both the WER and the
average last token emission latency by more than 6% and 40ms relative,
respectively.",2022-10-27T08:10:44Z,http://arxiv.org/pdf/2210.16238v1,"['eess.AS', 'cs.LG', 'cs.SD', 'eess.SP']"
2404.13362v1,Semantically Corrected Amharic Automatic Speech Recognition,"['Samuael Adnew', 'Paul Pu Liang']","Automatic Speech Recognition (ASR) can play a crucial role in enhancing the
accessibility of spoken languages worldwide. In this paper, we build a set of
ASR tools for Amharic, a language spoken by more than 50 million people
primarily in eastern Africa. Amharic is written in the Ge'ez script, a sequence
of graphemes with spacings denoting word boundaries. This makes computational
processing of Amharic challenging since the location of spacings can
significantly impact the meaning of formed sentences. We find that existing
benchmarks for Amharic ASR do not account for these spacings and only measure
individual grapheme error rates, leading to significantly inflated measurements
of in-the-wild performance. In this paper, we first release corrected
transcriptions of existing Amharic ASR test datasets, enabling the community to
accurately evaluate progress. Furthermore, we introduce a post-processing
approach using a transformer encoder-decoder architecture to organize raw ASR
outputs into a grammatically complete and semantically meaningful Amharic
sentence. Through experiments on the corrected test dataset, our model enhances
the semantic correctness of Amharic speech recognition systems, achieving a
Character Error Rate (CER) of 5.5\% and a Word Error Rate (WER) of 23.3\%.",2024-04-20T12:08:00Z,http://arxiv.org/pdf/2404.13362v1,"['cs.CL', 'cs.AI', 'cs.LG', 'eess.AS']"
2504.07229v1,Visual-Aware Speech Recognition for Noisy Scenarios,"['Lakshmipathi Balaji', 'Karan Singla']","Humans have the ability to utilize visual cues, such as lip movements and
visual scenes, to enhance auditory perception, particularly in noisy
environments. However, current Automatic Speech Recognition (ASR) or
Audio-Visual Speech Recognition (AVSR) models often struggle in noisy
scenarios. To solve this task, we propose a model that improves transcription
by correlating noise sources to visual cues. Unlike works that rely on lip
motion and require the speaker's visibility, we exploit broader visual
information from the environment. This allows our model to naturally filter
speech from noise and improve transcription, much like humans do in noisy
scenarios. Our method re-purposes pretrained speech and visual encoders,
linking them with multi-headed attention. This approach enables the
transcription of speech and the prediction of noise labels in video inputs. We
introduce a scalable pipeline to develop audio-visual datasets, where visual
cues correlate to noise in the audio. We show significant improvements over
existing audio-only models in noisy scenarios. Results also highlight that
visual cues play a vital role in improved transcription accuracy.",2025-04-09T19:09:54Z,http://arxiv.org/pdf/2504.07229v1,"['cs.CL', 'eess.AS', 'eess.SP']"
0704.2083v1,Introduction to Arabic Speech Recognition Using CMUSphinx System,"['H. Satori', 'M. Harti', 'N. Chenfour']","In this paper Arabic was investigated from the speech recognition problem
point of view. We propose a novel approach to build an Arabic Automated Speech
Recognition System (ASR). This system is based on the open source CMU Sphinx-4,
from the Carnegie Mellon University. CMU Sphinx is a large-vocabulary;
speaker-independent, continuous speech recognition system based on discrete
Hidden Markov Models (HMMs). We build a model using utilities from the
OpenSource CMU Sphinx. We will demonstrate the possible adaptability of this
system to Arabic voice recognition.",2007-04-17T01:04:01Z,http://arxiv.org/pdf/0704.2083v1,"['cs.CL', 'cs.AI', 'I.2.7']"
2205.13674v1,"Global Normalization for Streaming Speech Recognition in a Modular
  Framework","['Ehsan Variani', 'Ke Wu', 'Michael Riley', 'David Rybach', 'Matt Shannon', 'Cyril Allauzen']","We introduce the Globally Normalized Autoregressive Transducer (GNAT) for
addressing the label bias problem in streaming speech recognition. Our solution
admits a tractable exact computation of the denominator for the sequence-level
normalization. Through theoretical and empirical results, we demonstrate that
by switching to a globally normalized model, the word error rate gap between
streaming and non-streaming speech-recognition models can be greatly reduced
(by more than 50\% on the Librispeech dataset). This model is developed in a
modular framework which encompasses all the common neural speech recognition
models. The modularity of this framework enables controlled comparison of
modelling choices and creation of new models.",2022-05-26T23:34:21Z,http://arxiv.org/pdf/2205.13674v1,"['cs.LG', 'cs.AI', 'cs.CL']"
2502.00583v1,"Data-Driven Mispronunciation Pattern Discovery for Robust Speech
  Recognition","['Anna Seo Gyeong Choi', 'Jonghyeon Park', 'Myungwoo Oh']","Recent advancements in machine learning have significantly improved speech
recognition, but recognizing speech from non-fluent or accented speakers
remains a challenge. Previous efforts, relying on rule-based pronunciation
patterns, have struggled to fully capture non-native errors. We propose two
data-driven approaches using speech corpora to automatically detect
mispronunciation patterns. By aligning non-native phones with their native
counterparts using attention maps, we achieved a 5.7% improvement in speech
recognition on native English datasets and a 12.8% improvement for non-native
English speakers, particularly Korean speakers. Our method offers practical
advancements for robust Automatic Speech Recognition (ASR) systems particularly
for situations where prior linguistic knowledge is not applicable.",2025-02-01T22:41:43Z,http://arxiv.org/pdf/2502.00583v1,"['cs.CL', 'cs.SD', 'eess.AS']"
1303.5778v1,Speech Recognition with Deep Recurrent Neural Networks,"['Alex Graves', 'Abdel-rahman Mohamed', 'Geoffrey Hinton']","Recurrent neural networks (RNNs) are a powerful model for sequential data.
End-to-end training methods such as Connectionist Temporal Classification make
it possible to train RNNs for sequence labelling problems where the
input-output alignment is unknown. The combination of these methods with the
Long Short-term Memory RNN architecture has proved particularly fruitful,
delivering state-of-the-art results in cursive handwriting recognition. However
RNN performance in speech recognition has so far been disappointing, with
better results returned by deep feedforward networks. This paper investigates
\emph{deep recurrent neural networks}, which combine the multiple levels of
representation that have proved so effective in deep networks with the flexible
use of long range context that empowers RNNs. When trained end-to-end with
suitable regularisation, we find that deep Long Short-term Memory RNNs achieve
a test set error of 17.7% on the TIMIT phoneme recognition benchmark, which to
our knowledge is the best recorded score.",2013-03-22T20:55:48Z,http://arxiv.org/pdf/1303.5778v1,"['cs.NE', 'cs.CL']"
1608.00929v1,Efficient Segmental Cascades for Speech Recognition,"['Hao Tang', 'Weiran Wang', 'Kevin Gimpel', 'Karen Livescu']","Discriminative segmental models offer a way to incorporate flexible feature
functions into speech recognition. However, their appeal has been limited by
their computational requirements, due to the large number of possible segments
to consider. Multi-pass cascades of segmental models introduce features of
increasing complexity in different passes, where in each pass a segmental model
rescores lattices produced by a previous (simpler) segmental model. In this
paper, we explore several ways of making segmental cascades efficient and
practical: reducing the feature set in the first pass, frame subsampling, and
various pruning approaches. In experiments on phonetic recognition, we find
that with a combination of such techniques, it is possible to maintain
competitive performance while greatly reducing decoding, pruning, and training
time.",2016-08-02T18:45:53Z,http://arxiv.org/pdf/1608.00929v1,['cs.CL']
1609.03528v2,The Microsoft 2016 Conversational Speech Recognition System,"['W. Xiong', 'J. Droppo', 'X. Huang', 'F. Seide', 'M. Seltzer', 'A. Stolcke', 'D. Yu', 'G. Zweig']","We describe Microsoft's conversational speech recognition system, in which we
combine recent developments in neural-network-based acoustic and language
modeling to advance the state of the art on the Switchboard recognition task.
Inspired by machine learning ensemble techniques, the system uses a range of
convolutional and recurrent neural networks. I-vector modeling and lattice-free
MMI training provide significant gains for all acoustic model architectures.
Language model rescoring with multiple forward and backward running RNNLMs, and
word posterior-based system combination provide a 20% boost. The best single
system uses a ResNet architecture acoustic model with RNNLM rescoring, and
achieves a word error rate of 6.9% on the NIST 2000 Switchboard task. The
combined system has an error rate of 6.2%, representing an improvement over
previously reported results on this benchmark task.",2016-09-12T18:59:29Z,http://arxiv.org/pdf/1609.03528v2,"['cs.CL', 'eess.AS']"
1710.01073v1,Resolution limits on visual speech recognition,"['Helen L. Bear', 'Richard Harvey', 'Barry-John Theobald', 'Yuxuan Lan']","Visual-only speech recognition is dependent upon a number of factors that can
be difficult to control, such as: lighting; identity; motion; emotion and
expression. But some factors, such as video resolution are controllable, so it
is surprising that there is not yet a systematic study of the effect of
resolution on lip-reading. Here we use a new data set, the Rosetta Raven data,
to train and test recognizers so we can measure the affect of video resolution
on recognition accuracy. We conclude that, contrary to common practice,
resolution need not be that great for automatic lip-reading. However it is
highly unlikely that automatic lip-reading can work reliably when the distance
between the bottom of the lower lip and the top of the upper lip is less than
four pixels at rest.",2017-10-03T11:07:06Z,http://arxiv.org/pdf/1710.01073v1,"['cs.CV', 'eess.IV']"
1804.09713v1,End-to-End Multimodal Speech Recognition,"['Shruti Palaskar', 'Ramon Sanabria', 'Florian Metze']","Transcription or sub-titling of open-domain videos is still a challenging
domain for Automatic Speech Recognition (ASR) due to the data's challenging
acoustics, variable signal processing and the essentially unrestricted domain
of the data. In previous work, we have shown that the visual channel --
specifically object and scene features -- can help to adapt the acoustic model
(AM) and language model (LM) of a recognizer, and we are now expanding this
work to end-to-end approaches. In the case of a Connectionist Temporal
Classification (CTC)-based approach, we retain the separation of AM and LM,
while for a sequence-to-sequence (S2S) approach, both information sources are
adapted together, in a single model. This paper also analyzes the behavior of
CTC and S2S models on noisy video data (How-To corpus), and compares it to
results on the clean Wall Street Journal (WSJ) corpus, providing insight into
the robustness of both approaches.",2018-04-25T22:54:06Z,http://arxiv.org/pdf/1804.09713v1,"['eess.AS', 'cs.CL', 'cs.LG']"
2004.14840v1,Multiresolution and Multimodal Speech Recognition with Transformers,"['Georgios Paraskevopoulos', 'Srinivas Parthasarathy', 'Aparna Khare', 'Shiva Sundaram']","This paper presents an audio visual automatic speech recognition (AV-ASR)
system using a Transformer-based architecture. We particularly focus on the
scene context provided by the visual information, to ground the ASR. We extract
representations for audio features in the encoder layers of the transformer and
fuse video features using an additional crossmodal multihead attention layer.
Additionally, we incorporate a multitask training criterion for multiresolution
ASR, where we train the model to generate both character and subword level
transcriptions.
  Experimental results on the How2 dataset, indicate that multiresolution
training can speed up convergence by around 50% and relatively improves word
error rate (WER) performance by upto 18% over subword prediction models.
Further, incorporating visual information improves performance with relative
gains upto 3.76% over audio only models.
  Our results are comparable to state-of-the-art Listen, Attend and Spell-based
architectures.",2020-04-29T09:32:11Z,http://arxiv.org/pdf/2004.14840v1,"['eess.AS', 'cs.CV', 'cs.LG', 'cs.SD', 'stat.ML']"
2103.15122v2,Quantifying Bias in Automatic Speech Recognition,"['Siyuan Feng', 'Olya Kudina', 'Bence Mark Halpern', 'Odette Scharenborg']","Automatic speech recognition (ASR) systems promise to deliver objective
interpretation of human speech. Practice and recent evidence suggests that the
state-of-the-art (SotA) ASRs struggle with the large variation in speech due to
e.g., gender, age, speech impairment, race, and accents. Many factors can cause
the bias of an ASR system. Our overarching goal is to uncover bias in ASR
systems to work towards proactive bias mitigation in ASR. This paper is a first
step towards this goal and systematically quantifies the bias of a Dutch SotA
ASR system against gender, age, regional accents and non-native accents. Word
error rates are compared, and an in-depth phoneme-level error analysis is
conducted to understand where bias is occurring. We primarily focus on bias due
to articulation differences in the dataset. Based on our findings, we suggest
bias mitigation strategies for ASR development.",2021-03-28T12:52:03Z,http://arxiv.org/pdf/2103.15122v2,"['eess.AS', 'cs.CL', 'cs.SD']"
2005.09267v2,Iterative Pseudo-Labeling for Speech Recognition,"['Qiantong Xu', 'Tatiana Likhomanenko', 'Jacob Kahn', 'Awni Hannun', 'Gabriel Synnaeve', 'Ronan Collobert']","Pseudo-labeling has recently shown promise in end-to-end automatic speech
recognition (ASR). We study Iterative Pseudo-Labeling (IPL), a semi-supervised
algorithm which efficiently performs multiple iterations of pseudo-labeling on
unlabeled data as the acoustic model evolves. In particular, IPL fine-tunes an
existing model at each iteration using both labeled data and a subset of
unlabeled data. We study the main components of IPL: decoding with a language
model and data augmentation. We then demonstrate the effectiveness of IPL by
achieving state-of-the-art word-error rate on the Librispeech test sets in both
standard and low-resource setting. We also study the effect of language models
trained on different corpora to show IPL can effectively utilize additional
text. Finally, we release a new large in-domain text corpus which does not
overlap with the Librispeech training transcriptions to foster research in
low-resource, semi-supervised ASR",2020-05-19T07:56:21Z,http://arxiv.org/pdf/2005.09267v2,"['cs.CL', 'cs.SD', 'eess.AS']"
2104.00766v1,Configurable Privacy-Preserving Automatic Speech Recognition,"['Ranya Aloufi', 'Hamed Haddadi', 'David Boyle']","Voice assistive technologies have given rise to far-reaching privacy and
security concerns. In this paper we investigate whether modular automatic
speech recognition (ASR) can improve privacy in voice assistive systems by
combining independently trained separation, recognition, and discretization
modules to design configurable privacy-preserving ASR systems. We evaluate
privacy concerns and the effects of applying various state-of-the-art
techniques at each stage of the system, and report results using task-specific
metrics (i.e. WER, ABX, and accuracy). We show that overlapping speech inputs
to ASR systems present further privacy concerns, and how these may be mitigated
using speech separation and optimization techniques. Our discretization module
is shown to minimize paralinguistics privacy leakage from ASR acoustic models
to levels commensurate with random guessing. We show that voice privacy can be
configurable, and argue this presents new opportunities for privacy-preserving
applications incorporating ASR.",2021-04-01T21:03:49Z,http://arxiv.org/pdf/2104.00766v1,['cs.CL']
1904.05862v4,wav2vec: Unsupervised Pre-training for Speech Recognition,"['Steffen Schneider', 'Alexei Baevski', 'Ronan Collobert', 'Michael Auli']","We explore unsupervised pre-training for speech recognition by learning
representations of raw audio. wav2vec is trained on large amounts of unlabeled
audio data and the resulting representations are then used to improve acoustic
model training. We pre-train a simple multi-layer convolutional neural network
optimized via a noise contrastive binary classification task. Our experiments
on WSJ reduce WER of a strong character-based log-mel filterbank baseline by up
to 36% when only a few hours of transcribed data is available. Our approach
achieves 2.43% WER on the nov92 test set. This outperforms Deep Speech 2, the
best reported character-based system in the literature while using two orders
of magnitude less labeled training data.",2019-04-11T17:29:30Z,http://arxiv.org/pdf/1904.05862v4,['cs.CL']
2010.08642v1,Multimodal Speech Recognition with Unstructured Audio Masking,"['Tejas Srinivasan', 'Ramon Sanabria', 'Florian Metze', 'Desmond Elliott']","Visual context has been shown to be useful for automatic speech recognition
(ASR) systems when the speech signal is noisy or corrupted. Previous work,
however, has only demonstrated the utility of visual context in an unrealistic
setting, where a fixed set of words are systematically masked in the audio. In
this paper, we simulate a more realistic masking scenario during model
training, called RandWordMask, where the masking can occur for any word
segment. Our experiments on the Flickr 8K Audio Captions Corpus show that
multimodal ASR can generalize to recover different types of masked words in
this unstructured masking setting. Moreover, our analysis shows that our models
are capable of attending to the visual signal when the audio signal is
corrupted. These results show that multimodal ASR systems can leverage the
visual signal in more generalized noisy scenarios.",2020-10-16T21:49:20Z,http://arxiv.org/pdf/2010.08642v1,['cs.CL']
2209.00260v1,Deep Sparse Conformer for Speech Recognition,['Xianchao Wu'],"Conformer has achieved impressive results in Automatic Speech Recognition
(ASR) by leveraging transformer's capturing of content-based global
interactions and convolutional neural network's exploiting of local features.
In Conformer, two macaron-like feed-forward layers with half-step residual
connections sandwich the multi-head self-attention and convolution modules
followed by a post layer normalization. We improve Conformer's long-sequence
representation ability in two directions, \emph{sparser} and \emph{deeper}. We
adapt a sparse self-attention mechanism with $\mathcal{O}(L\text{log}L)$ in
time complexity and memory usage. A deep normalization strategy is utilized
when performing residual connections to ensure our training of hundred-level
Conformer blocks. On the Japanese CSJ-500h dataset, this deep sparse Conformer
achieves respectively CERs of 5.52\%, 4.03\% and 4.50\% on the three evaluation
sets and 4.16\%, 2.84\% and 3.20\% when ensembling five deep sparse Conformer
variants from 12 to 16, 17, 50, and finally 100 encoder layers.",2022-09-01T06:56:11Z,http://arxiv.org/pdf/2209.00260v1,"['cs.CL', 'cs.LG', 'cs.SD', 'eess.AS']"
2305.15055v1,Iteratively Improving Speech Recognition and Voice Conversion,"['Mayank Kumar Singh', 'Naoya Takahashi', 'Onoe Naoyuki']","Many existing works on voice conversion (VC) tasks use automatic speech
recognition (ASR) models for ensuring linguistic consistency between source and
converted samples. However, for the low-data resource domains, training a
high-quality ASR remains to be a challenging task. In this work, we propose a
novel iterative way of improving both the ASR and VC models. We first train an
ASR model which is used to ensure content preservation while training a VC
model. In the next iteration, the VC model is used as a data augmentation
method to further fine-tune the ASR model and generalize it to diverse
speakers. By iteratively leveraging the improved ASR model to train VC model
and vice-versa, we experimentally show improvement in both the models. Our
proposed framework outperforms the ASR and one-shot VC baseline models on
English singing and Hindi speech domains in subjective and objective
evaluations in low-data resource settings.",2023-05-24T11:45:42Z,http://arxiv.org/pdf/2305.15055v1,"['cs.SD', 'cs.AI', 'eess.AS']"
2305.16619v1,2-bit Conformer quantization for automatic speech recognition,"['Oleg Rybakov', 'Phoenix Meadowlark', 'Shaojin Ding', 'David Qiu', 'Jian Li', 'David Rim', 'Yanzhang He']","Large speech models are rapidly gaining traction in research community. As a
result, model compression has become an important topic, so that these models
can fit in memory and be served with reduced cost. Practical approaches for
compressing automatic speech recognition (ASR) model use int8 or int4 weight
quantization. In this study, we propose to develop 2-bit ASR models. We explore
the impact of symmetric and asymmetric quantization combined with sub-channel
quantization and clipping on both LibriSpeech dataset and large-scale training
data. We obtain a lossless 2-bit Conformer model with 32% model size reduction
when compared to state of the art 4-bit Conformer model for LibriSpeech. With
the large-scale training data, we obtain a 2-bit Conformer model with over 40%
model size reduction against the 4-bit version at the cost of 17% relative word
error rate degradation",2023-05-26T04:26:42Z,http://arxiv.org/pdf/2305.16619v1,['eess.AS']
1603.03185v2,Personalized Speech recognition on mobile devices,"['Ian McGraw', 'Rohit Prabhavalkar', 'Raziel Alvarez', 'Montse Gonzalez Arenas', 'Kanishka Rao', 'David Rybach', 'Ouais Alsharif', 'Hasim Sak', 'Alexander Gruenstein', 'Francoise Beaufays', 'Carolina Parada']","We describe a large vocabulary speech recognition system that is accurate,
has low latency, and yet has a small enough memory and computational footprint
to run faster than real-time on a Nexus 5 Android smartphone. We employ a
quantized Long Short-Term Memory (LSTM) acoustic model trained with
connectionist temporal classification (CTC) to directly predict phoneme
targets, and further reduce its memory footprint using an SVD-based compression
scheme. Additionally, we minimize our memory footprint by using a single
language model for both dictation and voice command domains, constructed using
Bayesian interpolation. Finally, in order to properly handle device-specific
information, such as proper names and other context-dependent information, we
inject vocabulary items into the decoder graph and bias the language model
on-the-fly. Our system achieves 13.5% word error rate on an open-ended
dictation task, running with a median speed that is seven times faster than
real-time.",2016-03-10T08:51:51Z,http://arxiv.org/pdf/1603.03185v2,"['cs.CL', 'cs.LG', 'cs.SD']"
2008.05760v1,MASRI-HEADSET: A Maltese Corpus for Speech Recognition,"['Carlos Mena', 'Albert Gatt', 'Andrea DeMarco', 'Claudia Borg', 'Lonneke van der Plas', 'Amanda Muscat', 'Ian Padovani']","Maltese, the national language of Malta, is spoken by approximately 500,000
people. Speech processing for Maltese is still in its early stages of
development. In this paper, we present the first spoken Maltese corpus designed
purposely for Automatic Speech Recognition (ASR). The MASRI-HEADSET corpus was
developed by the MASRI project at the University of Malta. It consists of 8
hours of speech paired with text, recorded by using short text snippets in a
laboratory environment. The speakers were recruited from different geographical
locations all over the Maltese islands, and were roughly evenly distributed by
gender. This paper also presents some initial results achieved in baseline
experiments for Maltese ASR using Sphinx and Kaldi. The MASRI-HEADSET Corpus is
publicly available for research/academic purposes.",2020-08-13T08:57:16Z,http://arxiv.org/pdf/2008.05760v1,"['cs.CL', 'cs.LG']"
2102.04429v1,Federated Acoustic Modeling For Automatic Speech Recognition,"['Xiaodong Cui', 'Songtao Lu', 'Brian Kingsbury']","Data privacy and protection is a crucial issue for any automatic speech
recognition (ASR) service provider when dealing with clients. In this paper, we
investigate federated acoustic modeling using data from multiple clients. A
client's data is stored on a local data server and the clients communicate only
model parameters with a central server, and not their data. The communication
happens infrequently to reduce the communication cost. To mitigate the non-iid
issue, client adaptive federated training (CAFT) is proposed to canonicalize
data across clients. The experiments are carried out on 1,150 hours of speech
data from multiple domains. Hybrid LSTM acoustic models are trained via
federated learning and their performance is compared to traditional centralized
acoustic model training. The experimental results demonstrate the effectiveness
of the proposed federated acoustic modeling strategy. We also show that CAFT
can further improve the performance of the federated acoustic model.",2021-02-08T18:39:36Z,http://arxiv.org/pdf/2102.04429v1,"['cs.SD', 'cs.DC', 'eess.AS']"
2102.11531v1,Memory-efficient Speech Recognition on Smart Devices,"['Ganesh Venkatesh', 'Alagappan Valliappan', 'Jay Mahadeokar', 'Yuan Shangguan', 'Christian Fuegen', 'Michael L. Seltzer', 'Vikas Chandra']","Recurrent transducer models have emerged as a promising solution for speech
recognition on the current and next generation smart devices. The transducer
models provide competitive accuracy within a reasonable memory footprint
alleviating the memory capacity constraints in these devices. However, these
models access parameters from off-chip memory for every input time step which
adversely effects device battery life and limits their usability on low-power
devices.
  We address transducer model's memory access concerns by optimizing their
model architecture and designing novel recurrent cell designs. We demonstrate
that i) model's energy cost is dominated by accessing model weights from
off-chip memory, ii) transducer model architecture is pivotal in determining
the number of accesses to off-chip memory and just model size is not a good
proxy, iii) our transducer model optimizations and novel recurrent cell reduces
off-chip memory accesses by 4.5x and model size by 2x with minimal accuracy
impact.",2021-02-23T07:43:45Z,http://arxiv.org/pdf/2102.11531v1,"['cs.SD', 'cs.CL', 'eess.AS']"
2105.03010v1,Efficient Weight factorization for Multilingual Speech Recognition,"['Ngoc-Quan Pham', 'Tuan-Nam Nguyen', 'Sebastian Stueker', 'Alexander Waibel']","End-to-end multilingual speech recognition involves using a single model
training on a compositional speech corpus including many languages, resulting
in a single neural network to handle transcribing different languages. Due to
the fact that each language in the training data has different characteristics,
the shared network may struggle to optimize for all various languages
simultaneously. In this paper we propose a novel multilingual architecture that
targets the core operation in neural networks: linear transformation functions.
The key idea of the method is to assign fast weight matrices for each language
by decomposing each weight matrix into a shared component and a language
dependent component. The latter is then factorized into vectors using rank-1
assumptions to reduce the number of parameters per language. This efficient
factorization scheme is proved to be effective in two multilingual settings
with $7$ and $27$ languages, reducing the word error rates by $26\%$ and $27\%$
rel. for two popular architectures LSTM and Transformer, respectively.",2021-05-07T00:12:02Z,http://arxiv.org/pdf/2105.03010v1,"['cs.CL', 'cs.SD', 'eess.AS']"
2110.02791v1,Spell my name: keyword boosted speech recognition,"['Namkyu Jung', 'Geonmin Kim', 'Joon Son Chung']","Recognition of uncommon words such as names and technical terminology is
important to understanding conversations in context. However, the ability to
recognise such words remains a challenge in modern automatic speech recognition
(ASR) systems.
  In this paper, we propose a simple but powerful ASR decoding method that can
better recognise these uncommon keywords, which in turn enables better
readability of the results. The method boosts the probabilities of given
keywords in a beam search based on acoustic model predictions. The method does
not require any training in advance.
  We demonstrate the effectiveness of our method on the LibriSpeeech test sets
and also internal data of real-world conversations. Our method significantly
boosts keyword accuracy on the test sets, while maintaining the accuracy of the
other words, and as well as providing significant qualitative improvements.
This method is applicable to other tasks such as machine translation, or
wherever unseen and difficult keywords need to be recognised in beam search.",2021-10-06T14:16:57Z,http://arxiv.org/pdf/2110.02791v1,"['cs.SD', 'cs.CL', 'eess.AS']"
2110.10026v3,Private Language Model Adaptation for Speech Recognition,"['Zhe Liu', 'Ke Li', 'Shreyan Bakshi', 'Fuchun Peng']","Speech model adaptation is crucial to handle the discrepancy between
server-side proxy training data and actual data received on local devices of
users. With the use of federated learning (FL), we introduce an efficient
approach on continuously adapting neural network language models (NNLMs) on
private devices with applications on automatic speech recognition (ASR). To
address the potential speech transcription errors in the on-device training
corpus, we perform empirical studies on comparing various strategies of
leveraging token-level confidence scores to improve the NNLM quality in the FL
settings. Experiments show that compared with no model adaptation, the proposed
method achieves relative 2.6% and 10.8% word error rate (WER) reductions on two
speech evaluation datasets, respectively. We also provide analysis in
evaluating privacy guarantees of our presented procedure.",2021-09-28T00:15:43Z,http://arxiv.org/pdf/2110.10026v3,"['eess.AS', 'cs.CL', 'cs.LG', 'cs.SD']"
2205.12304v1,Adaptive multilingual speech recognition with pretrained models,"['Ngoc-Quan Pham', 'Alex Waibel', 'Jan Niehues']","Multilingual speech recognition with supervised learning has achieved great
results as reflected in recent research. With the development of pretraining
methods on audio and text data, it is imperative to transfer the knowledge from
unsupervised multilingual models to facilitate recognition, especially in many
languages with limited data. Our work investigated the effectiveness of using
two pretrained models for two modalities: wav2vec 2.0 for audio and MBART50 for
text, together with the adaptive weight techniques to massively improve the
recognition quality on the public datasets containing CommonVoice and Europarl.
Overall, we noticed an 44% improvement over purely supervised learning, and
more importantly, each technique provides a different reinforcement in
different languages. We also explore other possibilities to potentially obtain
the best model by slightly adding either depth or relative attention to the
architecture.",2022-05-24T18:29:07Z,http://arxiv.org/pdf/2205.12304v1,"['cs.CL', 'cs.SD', 'eess.AS']"
2210.00117v1,Blind Signal Dereverberation for Machine Speech Recognition,"['Samik Sadhu', 'Hynek Hermansky']","We present a method to remove unknown convolutive noise introduced to speech
by reverberations of recording environments, utilizing some amount of training
speech data from the reverberant environment, and any available non-reverberant
speech data. Using Fourier transform computed over long temporal windows, which
ideally cover the entire room impulse response, we convert room induced
convolution to additions in the log spectral domain. Next, we compute a
spectral normalization vector from statistics gathered over reverberated as
well as over clean speech in the log spectral domain. During operation, this
normalization vectors are used to alleviate reverberations from complex speech
spectra recorded under the same reverberant conditions . Such dereverberated
complex speech spectra are used to compute complex FDLP-spectrograms for use in
automatic speech recognition.",2022-09-30T22:15:31Z,http://arxiv.org/pdf/2210.00117v1,"['eess.AS', 'cs.CL', 'cs.SD']"
2210.14742v1,Monotonic segmental attention for automatic speech recognition,"['Albert Zeyer', 'Robin Schmitt', 'Wei Zhou', 'Ralf Schlüter', 'Hermann Ney']","We introduce a novel segmental-attention model for automatic speech
recognition. We restrict the decoder attention to segments to avoid quadratic
runtime of global attention, better generalize to long sequences, and
eventually enable streaming. We directly compare global-attention and different
segmental-attention modeling variants. We develop and compare two separate
time-synchronous decoders, one specifically taking the segmental nature into
account, yielding further improvements. Using time-synchronous decoding for
segmental models is novel and a step towards streaming applications. Our
experiments show the importance of a length model to predict the segment
boundaries. The final best segmental-attention model using segmental decoding
performs better than global-attention, in contrast to other monotonic attention
approaches in the literature. Further, we observe that the segmental model
generalizes much better to long sequences of up to several minutes.",2022-10-26T14:21:23Z,http://arxiv.org/pdf/2210.14742v1,"['cs.CL', 'cs.LG', 'cs.SD', 'eess.AS']"
2211.03541v2,Multi-blank Transducers for Speech Recognition,"['Hainan Xu', 'Fei Jia', 'Somshubra Majumdar', 'Shinji Watanabe', 'Boris Ginsburg']","This paper proposes a modification to RNN-Transducer (RNN-T) models for
automatic speech recognition (ASR). In standard RNN-T, the emission of a blank
symbol consumes exactly one input frame; in our proposed method, we introduce
additional blank symbols, which consume two or more input frames when emitted.
We refer to the added symbols as big blanks, and the method multi-blank RNN-T.
For training multi-blank RNN-Ts, we propose a novel logit under-normalization
method in order to prioritize emissions of big blanks. With experiments on
multiple languages and datasets, we show that multi-blank RNN-T methods could
bring relative speedups of over +90%/+139% to model inference for English
Librispeech and German Multilingual Librispeech datasets, respectively. The
multi-blank RNN-T method also improves ASR accuracy consistently. We will
release our implementation of the method in the NeMo
(https://github.com/NVIDIA/NeMo) toolkit.",2022-11-04T16:24:46Z,http://arxiv.org/pdf/2211.03541v2,"['eess.AS', 'cs.LG', 'cs.SD']"
2306.09452v1,Distillation Strategies for Discriminative Speech Recognition Rescoring,"['Prashanth Gurunath Shivakumar', 'Jari Kolehmainen', 'Yile Gu', 'Ankur Gandhe', 'Ariya Rastrow', 'Ivan Bulyko']","Second-pass rescoring is employed in most state-of-the-art speech recognition
systems. Recently, BERT based models have gained popularity for re-ranking the
n-best hypothesis by exploiting the knowledge from masked language model
pre-training. Further, fine-tuning with discriminative loss such as minimum
word error rate (MWER) has shown to perform better than likelihood-based loss.
Streaming applications with low latency requirements impose significant
constraints on the size of the models, thereby limiting the word error rate
(WER) performance gains. In this paper, we propose effective strategies for
distilling from large models discriminatively trained with the MWER objective.
We experiment on Librispeech and production scale internal dataset for
voice-assistant. Our results demonstrate relative improvements of upto 7% WER
over student models trained with MWER. We also show that the proposed
distillation can reduce the WER gap between the student and the teacher by 62%
upto 100%.",2023-06-15T19:15:14Z,http://arxiv.org/pdf/2306.09452v1,['eess.AS']
2308.02013v2,Federated Representation Learning for Automatic Speech Recognition,"['Guruprasad V Ramesh', 'Gopinath Chennupati', 'Milind Rao', 'Anit Kumar Sahu', 'Ariya Rastrow', 'Jasha Droppo']","Federated Learning (FL) is a privacy-preserving paradigm, allowing edge
devices to learn collaboratively without sharing data. Edge devices like Alexa
and Siri are prospective sources of unlabeled audio data that can be tapped to
learn robust audio representations. In this work, we bring Self-supervised
Learning (SSL) and FL together to learn representations for Automatic Speech
Recognition respecting data privacy constraints. We use the speaker and chapter
information in the unlabeled speech dataset, Libri-Light, to simulate non-IID
speaker-siloed data distributions and pre-train an LSTM encoder with the
Contrastive Predictive Coding framework with FedSGD. We show that the
pre-trained ASR encoder in FL performs as well as a centrally pre-trained model
and produces an improvement of 12-15% (WER) compared to no pre-training. We
further adapt the federated pre-trained models to a new language, French, and
show a 20% (WER) improvement over no pre-training.",2023-08-03T20:08:23Z,http://arxiv.org/pdf/2308.02013v2,"['cs.SD', 'cs.CL', 'cs.LG', 'eess.AS']"
2309.08150v2,Unimodal Aggregation for CTC-based Speech Recognition,"['Ying Fang', 'Xiaofei Li']","This paper works on non-autoregressive automatic speech recognition. A
unimodal aggregation (UMA) is proposed to segment and integrate the feature
frames that belong to the same text token, and thus to learn better feature
representations for text tokens. The frame-wise features and weights are both
derived from an encoder. Then, the feature frames with unimodal weights are
integrated and further processed by a decoder. Connectionist temporal
classification (CTC) loss is applied for training. Compared to the regular CTC,
the proposed method learns better feature representations and shortens the
sequence length, resulting in lower recognition error and computational
complexity. Experiments on three Mandarin datasets show that UMA demonstrates
superior or comparable performance to other advanced non-autoregressive
methods, such as self-conditioned CTC. Moreover, by integrating
self-conditioned CTC into the proposed framework, the performance can be
further noticeably improved.",2023-09-15T04:34:40Z,http://arxiv.org/pdf/2309.08150v2,"['cs.CL', 'cs.SD', 'eess.AS']"
2401.08916v1,Two-pass Endpoint Detection for Speech Recognition,"['Anirudh Raju', 'Aparna Khare', 'Di He', 'Ilya Sklyar', 'Long Chen', 'Sam Alptekin', 'Viet Anh Trinh', 'Zhe Zhang', 'Colin Vaz', 'Venkatesh Ravichandran', 'Roland Maas', 'Ariya Rastrow']","Endpoint (EP) detection is a key component of far-field speech recognition
systems that assist the user through voice commands. The endpoint detector has
to trade-off between accuracy and latency, since waiting longer reduces the
cases of users being cut-off early. We propose a novel two-pass solution for
endpointing, where the utterance endpoint detected from a first pass endpointer
is verified by a 2nd-pass model termed EP Arbitrator. Our method improves the
trade-off between early cut-offs and latency over a baseline endpointer, as
tested on datasets including voice-assistant transactional queries,
conversational speech, and the public SLURP corpus. We demonstrate that our
method shows improvements regardless of the first-pass EP model used.",2024-01-17T02:00:07Z,http://arxiv.org/pdf/2401.08916v1,"['eess.AS', 'cs.SD']"
2406.02649v1,Keyword-Guided Adaptation of Automatic Speech Recognition,"['Aviv Shamsian', 'Aviv Navon', 'Neta Glazer', 'Gill Hetz', 'Joseph Keshet']","Automatic Speech Recognition (ASR) technology has made significant progress
in recent years, providing accurate transcription across various domains.
However, some challenges remain, especially in noisy environments and
specialized jargon. In this paper, we propose a novel approach for improved
jargon word recognition by contextual biasing Whisper-based models. We employ a
keyword spotting model that leverages the Whisper encoder representation to
dynamically generate prompts for guiding the decoder during the transcription
process. We introduce two approaches to effectively steer the decoder towards
these prompts: KG-Whisper, which is aimed at fine-tuning the Whisper decoder,
and KG-Whisper-PT, which learns a prompt prefix. Our results show a significant
improvement in the recognition accuracy of specified keywords and in reducing
the overall word error rates. Specifically, in unseen language generalization,
we demonstrate an average WER improvement of 5.1% over Whisper.",2024-06-04T14:20:38Z,http://arxiv.org/pdf/2406.02649v1,"['eess.AS', 'cs.LG', 'cs.SD']"
2406.08380v2,Towards Unsupervised Speech Recognition Without Pronunciation Models,"['Junrui Ni', 'Liming Wang', 'Yang Zhang', 'Kaizhi Qian', 'Heting Gao', 'Mark Hasegawa-Johnson', 'Chang D. Yoo']","Recent advancements in supervised automatic speech recognition (ASR) have
achieved remarkable performance, largely due to the growing availability of
large transcribed speech corpora. However, most languages lack sufficient
paired speech and text data to effectively train these systems. In this
article, we tackle the challenge of developing ASR systems without paired
speech and text corpora by proposing the removal of reliance on a phoneme
lexicon. We explore a new research direction: word-level unsupervised ASR, and
experimentally demonstrate that an unsupervised speech recognizer can emerge
from joint speech-to-speech and text-to-text masked token-infilling. Using a
curated speech corpus containing a fixed number of English words, our system
iteratively refines the word segmentation structure and achieves a word error
rate of between 20-23%, depending on the vocabulary size, without parallel
transcripts, oracle word boundaries, or a pronunciation lexicon. This
innovative model surpasses the performance of previous unsupervised ASR models
under the lexicon-free setting.",2024-06-12T16:30:58Z,http://arxiv.org/pdf/2406.08380v2,"['cs.CL', 'cs.SD', 'eess.AS']"
2406.18373v1,Dynamic Data Pruning for Automatic Speech Recognition,"['Qiao Xiao', 'Pingchuan Ma', 'Adriana Fernandez-Lopez', 'Boqian Wu', 'Lu Yin', 'Stavros Petridis', 'Mykola Pechenizkiy', 'Maja Pantic', 'Decebal Constantin Mocanu', 'Shiwei Liu']","The recent success of Automatic Speech Recognition (ASR) is largely
attributed to the ever-growing amount of training data. However, this trend has
made model training prohibitively costly and imposed computational demands.
While data pruning has been proposed to mitigate this issue by identifying a
small subset of relevant data, its application in ASR has been barely explored,
and existing works often entail significant overhead to achieve meaningful
results. To fill this gap, this paper presents the first investigation of
dynamic data pruning for ASR, finding that we can reach the full-data
performance by dynamically selecting 70% of data. Furthermore, we introduce
Dynamic Data Pruning for ASR (DDP-ASR), which offers several fine-grained
pruning granularities specifically tailored for speech-related datasets, going
beyond the conventional pruning of entire time sequences. Our intensive
experiments show that DDP-ASR can save up to 1.6x training time with negligible
performance loss.",2024-06-26T14:17:36Z,http://arxiv.org/pdf/2406.18373v1,"['cs.CL', 'cs.SD', 'eess.AS']"
2408.00004v2,Handling Numeric Expressions in Automatic Speech Recognition,"['Christian Huber', 'Alexander Waibel']","This paper addresses the problem of correctly formatting numeric expressions
in automatic speech recognition (ASR) transcripts. This is challenging since
the expected transcript format depends on the context, e.g., 1945 (year) vs.
19:45 (timestamp). We compare cascaded and end-to-end approaches to recognize
and format numeric expressions such as years, timestamps, currency amounts, and
quantities. For the end-to-end approach, we employed a data generation strategy
using a large language model (LLM) together with a text to speech (TTS) model
to generate adaptation data. The results on our test data set show that while
approaches based on LLMs perform well in recognizing formatted numeric
expressions, adapted end-to-end models offer competitive performance with the
advantage of lower latency and inference cost.",2024-07-18T09:46:19Z,http://arxiv.org/pdf/2408.00004v2,"['eess.AS', 'cs.AI', 'cs.CL']"
2410.00940v1,Automatic Speech Recognition for the Ika Language,"['Uchenna Nzenwata', 'Daniel Ogbuigwe']","We present a cost-effective approach for developing Automatic Speech
Recognition (ASR) models for low-resource languages like Ika. We fine-tune the
pretrained wav2vec 2.0 Massively Multilingual Speech Models on a high-quality
speech dataset compiled from New Testament Bible translations in Ika. Our
results show that fine-tuning multilingual pretrained models achieves a Word
Error Rate (WER) of 0.5377 and Character Error Rate (CER) of 0.2651 with just
over 1 hour of training data. The larger 1 billion parameter model outperforms
the smaller 300 million parameter model due to its greater complexity and
ability to store richer speech representations. However, we observe overfitting
to the small training dataset, reducing generalizability. Our findings
demonstrate the potential of leveraging multilingual pretrained models for
low-resource languages. Future work should focus on expanding the dataset and
exploring techniques to mitigate overfitting.",2024-10-01T11:56:42Z,http://arxiv.org/pdf/2410.00940v1,['cs.CL']
2502.04834v1,Lightweight Operations for Visual Speech Recognition,"['Iason Ioannis Panagos', 'Giorgos Sfikas', 'Christophoros Nikou']","Visual speech recognition (VSR), which decodes spoken words from video data,
offers significant benefits, particularly when audio is unavailable. However,
the high dimensionality of video data leads to prohibitive computational costs
that demand powerful hardware, limiting VSR deployment on resource-constrained
devices. This work addresses this limitation by developing lightweight VSR
architectures. Leveraging efficient operation design paradigms, we create
compact yet powerful models with reduced resource requirements and minimal
accuracy loss. We train and evaluate our models on a large-scale public dataset
for recognition of words from video sequences, demonstrating their
effectiveness for practical applications. We also conduct an extensive array of
ablative experiments to thoroughly analyze the size and complexity of each
model. Code and trained models will be made publicly available.",2025-02-07T11:08:32Z,http://arxiv.org/pdf/2502.04834v1,"['cs.CV', 'cs.AI', 'cs.CL', 'cs.LG']"
2509.23550v1,Automatic Speech Recognition for Greek Medical Dictation,"['Vardis Georgilas', 'Themos Stafylakis']","Medical dictation systems are essential tools in modern healthcare, enabling
accurate and efficient conversion of speech into written medical documentation.
The main objective of this paper is to create a domain-specific system for
Greek medical speech transcriptions. The ultimate goal is to assist healthcare
professionals by reducing the overload of manual documentation and improving
workflow efficiency. Towards this goal, we develop a system that combines
automatic speech recognition techniques with text correction model, allowing
better handling of domain-specific terminology and linguistic variations in
Greek. Our approach leverages both acoustic and textual modeling to create more
realistic and reliable transcriptions. We focused on adapting existing language
and speech technologies to the Greek medical context, addressing challenges
such as complex medical terminology and linguistic inconsistencies. Through
domain-specific fine-tuning, our system achieves more accurate and coherent
transcriptions, contributing to the development of practical language
technologies for the Greek healthcare sector.",2025-09-28T01:15:47Z,http://arxiv.org/pdf/2509.23550v1,"['cs.CL', 'cs.AI']"
1507.04019v1,Feature Normalisation for Robust Speech Recognition,['D. S. Pavan Kumar'],"Speech recognition system performance degrades in noisy environments. If the
acoustic models are built using features of clean utterances, the features of a
noisy test utterance would be acoustically mismatched with the trained model.
This gives poor likelihoods and poor recognition accuracy. Model adaptation and
feature normalisation are two broad areas that address this problem. While the
former often gives better performance, the latter involves estimation of lesser
number of parameters, making the system feasible for practical implementations.
  This research focuses on the efficacies of various subspace, statistical and
stereo based feature normalisation techniques. A subspace projection based
method has been investigated as a standalone and adjunct technique involving
reconstruction of noisy speech features from a precomputed set of clean speech
building-blocks. The building blocks are learned using non-negative matrix
factorisation (NMF) on log-Mel filter bank coefficients, which form a basis for
the clean speech subspace. The work provides a detailed study on how the method
can be incorporated into the extraction process of Mel-frequency cepstral
coefficients. Experimental results show that the new features are robust to
noise, and achieve better results when combined with the existing techniques.
  The work also proposes a modification to the training process of SPLICE
algorithm for noise robust speech recognition. It is based on feature
correlations, and enables this stereo-based algorithm to improve the
performance in all noise conditions, especially in unseen cases. Further, the
modified framework is extended to work for non-stereo datasets where clean and
noisy training utterances, but not stereo counterparts, are required. An
MLLR-based computationally efficient run-time noise adaptation method in SPLICE
framework has been proposed.",2015-07-14T20:34:16Z,http://arxiv.org/pdf/1507.04019v1,"['cs.CL', 'cs.SD']"
1701.03577v1,Kernel Approximation Methods for Speech Recognition,"['Avner May', 'Alireza Bagheri Garakani', 'Zhiyun Lu', 'Dong Guo', 'Kuan Liu', 'Aurélien Bellet', 'Linxi Fan', 'Michael Collins', 'Daniel Hsu', 'Brian Kingsbury', 'Michael Picheny', 'Fei Sha']","We study large-scale kernel methods for acoustic modeling in speech
recognition and compare their performance to deep neural networks (DNNs). We
perform experiments on four speech recognition datasets, including the TIMIT
and Broadcast News benchmark tasks, and compare these two types of models on
frame-level performance metrics (accuracy, cross-entropy), as well as on
recognition metrics (word/character error rate). In order to scale kernel
methods to these large datasets, we use the random Fourier feature method of
Rahimi and Recht (2007). We propose two novel techniques for improving the
performance of kernel acoustic models. First, in order to reduce the number of
random features required by kernel models, we propose a simple but effective
method for feature selection. The method is able to explore a large number of
non-linear features while maintaining a compact model more efficiently than
existing approaches. Second, we present a number of frame-level metrics which
correlate very strongly with recognition performance when computed on the
heldout set; we take advantage of these correlations by monitoring these
metrics during training in order to decide when to stop learning. This
technique can noticeably improve the recognition performance of both DNN and
kernel models, while narrowing the gap between them. Additionally, we show that
the linear bottleneck method of Sainath et al. (2013) improves the performance
of our kernel models significantly, in addition to speeding up training and
making the models more compact. Together, these three methods dramatically
improve the performance of kernel acoustic models, making their performance
comparable to DNNs on the tasks we explored.",2017-01-13T07:24:18Z,http://arxiv.org/pdf/1701.03577v1,"['stat.ML', 'cs.AI', 'cs.CL', 'cs.LG']"
2507.05727v2,ContextASR-Bench: A Massive Contextual Speech Recognition Benchmark,"['He Wang', 'Linhan Ma', 'Dake Guo', 'Xiong Wang', 'Lei Xie', 'Jin Xu', 'Junyang Lin']","Automatic Speech Recognition (ASR) has been extensively investigated, yet
prior benchmarks have largely focused on assessing the acoustic robustness of
ASR models, leaving evaluations of their linguistic capabilities relatively
underexplored. This largely stems from the limited parameter sizes and training
corpora of conventional ASR models, leaving them with insufficient world
knowledge, which is crucial for accurately recognizing named entities across
diverse domains. For instance, drug and treatment names in medicine or
specialized technical terms in engineering. Recent breakthroughs in Large
Language Models (LLMs) and corresponding Large Audio Language Models (LALMs)
have markedly enhanced the visibility of advanced context modeling and general
artificial intelligence capabilities. Leveraging LLMs, we envision a unified
system capable of robust speech recognition across diverse real-world domains,
yet existing benchmarks are inadequate for evaluating this objective. To
address this gap, we propose ContextASR-Bench: a comprehensive, large-scale
benchmark designed to assess the linguistic competence of ASR systems using
corpora that feature numerous named entities across multiple domains. It
encompasses up to 40,000 data entries with more than 300,000 named entities
across over 10 domains. Beyond the audio and its transcription, each sample
provides the domain it belongs to and a list of named entities it contains,
which are referred to as the context. Based on this, we introduce three
evaluation modes to assess how effectively models can exploit such context to
improve ASR accuracy. Extensive evaluation on ContextASR-Bench highlights that
LALMs outperform conventional ASR models by a large margin thanks to the strong
world knowledge and context modeling of LLMs, yet there remains ample room for
further improvement. The dataset and evaluation code have been released.",2025-07-08T07:21:20Z,http://arxiv.org/pdf/2507.05727v2,"['eess.AS', 'cs.CL', 'cs.SD']"
2004.09249v2,"CHiME-6 Challenge:Tackling Multispeaker Speech Recognition for
  Unsegmented Recordings","['Shinji Watanabe', 'Michael Mandel', 'Jon Barker', 'Emmanuel Vincent', 'Ashish Arora', 'Xuankai Chang', 'Sanjeev Khudanpur', 'Vimal Manohar', 'Daniel Povey', 'Desh Raj', 'David Snyder', 'Aswin Shanmugam Subramanian', 'Jan Trmal', 'Bar Ben Yair', 'Christoph Boeddeker', 'Zhaoheng Ni', 'Yusuke Fujita', 'Shota Horiguchi', 'Naoyuki Kanda', 'Takuya Yoshioka', 'Neville Ryant']","Following the success of the 1st, 2nd, 3rd, 4th and 5th CHiME challenges we
organize the 6th CHiME Speech Separation and Recognition Challenge (CHiME-6).
The new challenge revisits the previous CHiME-5 challenge and further considers
the problem of distant multi-microphone conversational speech diarization and
recognition in everyday home environments. Speech material is the same as the
previous CHiME-5 recordings except for accurate array synchronization. The
material was elicited using a dinner party scenario with efforts taken to
capture data that is representative of natural conversational speech. This
paper provides a baseline description of the CHiME-6 challenge for both
segmented multispeaker speech recognition (Track 1) and unsegmented
multispeaker speech recognition (Track 2). Of note, Track 2 is the first
challenge activity in the community to tackle an unsegmented multispeaker
speech recognition scenario with a complete set of reproducible open source
baselines providing speech enhancement, speaker diarization, and speech
recognition modules.",2020-04-20T12:59:07Z,http://arxiv.org/pdf/2004.09249v2,"['cs.SD', 'cs.CL', 'eess.AS']"
2207.05071v1,Online Continual Learning of End-to-End Speech Recognition Models,"['Muqiao Yang', 'Ian Lane', 'Shinji Watanabe']","Continual Learning, also known as Lifelong Learning, aims to continually
learn from new data as it becomes available. While prior research on continual
learning in automatic speech recognition has focused on the adaptation of
models across multiple different speech recognition tasks, in this paper we
propose an experimental setting for \textit{online continual learning} for
automatic speech recognition of a single task. Specifically focusing on the
case where additional training data for the same task becomes available
incrementally over time, we demonstrate the effectiveness of performing
incremental model updates to end-to-end speech recognition models with an
online Gradient Episodic Memory (GEM) method. Moreover, we show that with
online continual learning and a selective sampling strategy, we can maintain an
accuracy that is similar to retraining a model from scratch while requiring
significantly lower computation costs. We have also verified our method with
self-supervised learning (SSL) features.",2022-07-11T05:35:06Z,http://arxiv.org/pdf/2207.05071v1,"['cs.LG', 'cs.AI', 'cs.SD', 'eess.AS']"
2404.17394v2,Child Speech Recognition in Human-Robot Interaction: Problem Solved?,"['Ruben Janssens', 'Eva Verhelst', 'Giulio Antonio Abbo', 'Qiaoqiao Ren', 'Maria Jose Pinto Bernal', 'Tony Belpaeme']","Automated Speech Recognition shows superhuman performance for adult English
speech on a range of benchmarks, but disappoints when fed children's speech.
This has long sat in the way of child-robot interaction. Recent evolutions in
data-driven speech recognition, including the availability of Transformer
architectures and unprecedented volumes of training data, might mean a
breakthrough for child speech recognition and social robot applications aimed
at children. We revisit a study on child speech recognition from 2017 and show
that indeed performance has increased, with newcomer OpenAI Whisper doing
markedly better than leading commercial cloud services. Performance improves
even more in highly structured interactions when priming models with specific
phrases. While transcription is not perfect yet, the best model recognises
60.3% of sentences correctly barring small grammatical differences, with
sub-second transcription time running on a local GPU, showing potential for
usable autonomous child-robot speech interactions.",2024-04-26T13:14:28Z,http://arxiv.org/pdf/2404.17394v2,"['cs.CL', 'cs.HC', 'cs.RO']"
2409.12370v1,Robust Audiovisual Speech Recognition Models with Mixture-of-Experts,"['Yihan Wu', 'Yifan Peng', 'Yichen Lu', 'Xuankai Chang', 'Ruihua Song', 'Shinji Watanabe']","Visual signals can enhance audiovisual speech recognition accuracy by
providing additional contextual information. Given the complexity of visual
signals, an audiovisual speech recognition model requires robust generalization
capabilities across diverse video scenarios, presenting a significant
challenge. In this paper, we introduce EVA, leveraging the mixture-of-Experts
for audioVisual ASR to perform robust speech recognition for ``in-the-wild''
videos. Specifically, we first encode visual information into visual tokens
sequence and map them into speech space by a lightweight projection. Then, we
build EVA upon a robust pretrained speech recognition model, ensuring its
generalization ability. Moreover, to incorporate visual information
effectively, we inject visual information into the ASR model through a
mixture-of-experts module. Experiments show our model achieves state-of-the-art
results on three benchmarks, which demonstrates the generalization ability of
EVA across diverse video domains.",2024-09-19T00:08:28Z,http://arxiv.org/pdf/2409.12370v1,"['eess.AS', 'cs.CL', 'cs.CV', 'cs.SD']"
2502.15264v1,Retrieval-Augmented Speech Recognition Approach for Domain Challenges,"['Peng Shen', 'Xugang Lu', 'Hisashi Kawai']","Speech recognition systems often face challenges due to domain mismatch,
particularly in real-world applications where domain-specific data is
unavailable because of data accessibility and confidentiality constraints.
Inspired by Retrieval-Augmented Generation (RAG) techniques for large language
models (LLMs), this paper introduces a LLM-based retrieval-augmented speech
recognition method that incorporates domain-specific textual data at the
inference stage to enhance recognition performance. Rather than relying on
domain-specific textual data during the training phase, our model is trained to
learn how to utilize textual information provided in prompts for LLM decoder to
improve speech recognition performance. Benefiting from the advantages of the
RAG retrieval mechanism, our approach efficiently accesses locally available
domain-specific documents, ensuring a convenient and effective process for
solving domain mismatch problems. Experiments conducted on the CSJ database
demonstrate that the proposed method significantly improves speech recognition
accuracy and achieves state-of-the-art results on the CSJ dataset, even without
relying on the full training data.",2025-02-21T07:47:50Z,http://arxiv.org/pdf/2502.15264v1,"['cs.CL', 'cs.SD', 'eess.AS']"
2509.22744v1,"Index-MSR: A high-efficiency multimodal fusion framework for speech
  recognition","['Jinming Chen', 'Lu Wang', 'Zheshu Song', 'Wei Deng']","Driven by large scale datasets and LLM based architectures, automatic speech
recognition (ASR) systems have achieved remarkable improvements in accuracy.
However, challenges persist for domain-specific terminology, and short
utterances lacking semantic coherence, where recognition performance often
degrades significantly. In this work, we present Index-MSR, an efficient
multimodal speech recognition framework. At its core is a novel Multimodal
Fusion Decoder (MFD), which effectively incorporates text-related information
from videos (e.g., subtitles and presentation slides) into the speech
recognition. This cross-modal integration not only enhances overall ASR
accuracy but also yields substantial reductions in substitution errors.
Extensive evaluations on both an in-house subtitle dataset and a public AVSR
dataset demonstrate that Index-MSR achieves sota accuracy, with substitution
errors reduced by 20,50%. These results demonstrate that our approach
efficiently exploits text-related cues from video to improve speech recognition
accuracy, showing strong potential in applications requiring strict audio text
synchronization, such as audio translation.",2025-09-26T03:47:15Z,http://arxiv.org/pdf/2509.22744v1,"['eess.AS', 'cs.AI', 'cs.MM', 'cs.SD']"
1805.10387v2,Mixed-Precision Training for NLP and Speech Recognition with OpenSeq2Seq,"['Oleksii Kuchaiev', 'Boris Ginsburg', 'Igor Gitman', 'Vitaly Lavrukhin', 'Jason Li', 'Huyen Nguyen', 'Carl Case', 'Paulius Micikevicius']","We present OpenSeq2Seq - a TensorFlow-based toolkit for training
sequence-to-sequence models that features distributed and mixed-precision
training. Benchmarks on machine translation and speech recognition tasks show
that models built using OpenSeq2Seq give state-of-the-art performance at 1.5-3x
less training time. OpenSeq2Seq currently provides building blocks for models
that solve a wide range of tasks including neural machine translation,
automatic speech recognition, and speech synthesis.",2018-05-25T22:54:38Z,http://arxiv.org/pdf/1805.10387v2,['cs.CL']
2008.06580v2,"Adaptation Algorithms for Neural Network-Based Speech Recognition: An
  Overview","['Peter Bell', 'Joachim Fainberg', 'Ondrej Klejch', 'Jinyu Li', 'Steve Renals', 'Pawel Swietojanski']","We present a structured overview of adaptation algorithms for neural
network-based speech recognition, considering both hybrid hidden Markov model /
neural network systems and end-to-end neural network systems, with a focus on
speaker adaptation, domain adaptation, and accent adaptation. The overview
characterizes adaptation algorithms as based on embeddings, model parameter
adaptation, or data augmentation. We present a meta-analysis of the performance
of speech recognition adaptation algorithms, based on relative error rate
reductions as reported in the literature.",2020-08-14T21:50:03Z,http://arxiv.org/pdf/2008.06580v2,"['eess.AS', 'cs.CL', 'cs.SD']"
2008.07621v1,Speech Recognition using EEG signals recorded using dry electrodes,"['Gautam Krishna', 'Co Tran', 'Mason Carnahan', 'Morgan M Hagood', 'Ahmed H Tewfik']","In this paper, we demonstrate speech recognition using electroencephalography
(EEG) signals obtained using dry electrodes on a limited English vocabulary
consisting of three vowels and one word using a deep learning model. We
demonstrate a test accuracy of 79.07 percent on a subset vocabulary consisting
of two English vowels. Our results demonstrate the feasibility of using EEG
signals recorded using dry electrodes for performing the task of speech
recognition.",2020-08-13T09:56:45Z,http://arxiv.org/pdf/2008.07621v1,"['eess.AS', 'cs.LG', 'cs.SD', 'eess.SP']"
2006.02902v1,"Constrained Variational Autoencoder for improving EEG based Speech
  Recognition Systems","['Gautam Krishna', 'Co Tran', 'Mason Carnahan', 'Ahmed Tewfik']","In this paper we introduce a recurrent neural network (RNN) based variational
autoencoder (VAE) model with a new constrained loss function that can generate
more meaningful electroencephalography (EEG) features from raw EEG features to
improve the performance of EEG based speech recognition systems. We demonstrate
that both continuous and isolated speech recognition systems trained and tested
using EEG features generated from raw EEG features using our VAE model results
in improved performance and we demonstrate our results for a limited English
vocabulary consisting of 30 unique sentences for continuous speech recognition
and for an English vocabulary consisting of 2 unique sentences for isolated
speech recognition. We compare our method with another recently introduced
method described by authors in [1] to improve the performance of EEG based
continuous speech recognition systems and we demonstrate that our method
outperforms their method as vocabulary size increases when trained and tested
using the same data set. Even though we demonstrate results only for automatic
speech recognition (ASR) experiments in this paper, the proposed VAE model with
constrained loss function can be extended to a variety of other EEG based brain
computer interface (BCI) applications.",2020-06-01T06:03:50Z,http://arxiv.org/pdf/2006.02902v1,"['eess.AS', 'cs.LG', 'cs.SD', 'eess.SP']"
1312.6849v2,Speech Recognition Front End Without Information Loss,"['Matthew Ager', 'Zoran Cvetkovic', 'Peter Sollich']","Speech representation and modelling in high-dimensional spaces of acoustic
waveforms, or a linear transformation thereof, is investigated with the aim of
improving the robustness of automatic speech recognition to additive noise. The
motivation behind this approach is twofold: (i) the information in acoustic
waveforms that is usually removed in the process of extracting low-dimensional
features might aid robust recognition by virtue of structured redundancy
analogous to channel coding, (ii) linear feature domains allow for exact noise
adaptation, as opposed to representations that involve non-linear processing
which makes noise adaptation challenging. Thus, we develop a generative
framework for phoneme modelling in high-dimensional linear feature domains, and
use it in phoneme classification and recognition tasks. Results show that
classification and recognition in this framework perform better than analogous
PLP and MFCC classifiers below 18 dB SNR. A combination of the high-dimensional
and MFCC features at the likelihood level performs uniformly better than either
of the individual representations across all noise levels.",2013-12-24T16:36:16Z,http://arxiv.org/pdf/1312.6849v2,"['cs.CL', 'cs.CV', 'cs.LG']"
1506.00799v1,Learning Speech Rate in Speech Recognition,"['Xiangyu Zeng', 'Shi Yin', 'Dong Wang']","A significant performance reduction is often observed in speech recognition
when the rate of speech (ROS) is too low or too high. Most of present
approaches to addressing the ROS variation focus on the change of speech
signals in dynamic properties caused by ROS, and accordingly modify the dynamic
model, e.g., the transition probabilities of the hidden Markov model (HMM).
However, an abnormal ROS changes not only the dynamic but also the static
property of speech signals, and thus can not be compensated for purely by
modifying the dynamic model. This paper proposes an ROS learning approach based
on deep neural networks (DNN), which involves an ROS feature as the input of
the DNN model and so the spectrum distortion caused by ROS can be learned and
compensated for. The experimental results show that this approach can deliver
better performance for too slow and too fast utterances, demonstrating our
conjecture that ROS impacts both the dynamic and the static property of speech.
In addition, the proposed approach can be combined with the conventional HMM
transition adaptation method, offering additional performance gains.",2015-06-02T08:59:47Z,http://arxiv.org/pdf/1506.00799v1,"['cs.CL', 'cs.LG']"
1506.07503v1,Attention-Based Models for Speech Recognition,"['Jan Chorowski', 'Dzmitry Bahdanau', 'Dmitriy Serdyuk', 'Kyunghyun Cho', 'Yoshua Bengio']","Recurrent sequence generators conditioned on input data through an attention
mechanism have recently shown very good performance on a range of tasks in-
cluding machine translation, handwriting synthesis and image caption gen-
eration. We extend the attention-mechanism with features needed for speech
recognition. We show that while an adaptation of the model used for machine
translation in reaches a competitive 18.7% phoneme error rate (PER) on the
TIMIT phoneme recognition task, it can only be applied to utterances which are
roughly as long as the ones it was trained on. We offer a qualitative
explanation of this failure and propose a novel and generic method of adding
location-awareness to the attention mechanism to alleviate this issue. The new
method yields a model that is robust to long inputs and achieves 18% PER in
single utterances and 20% in 10-times longer (repeated) utterances. Finally, we
propose a change to the at- tention mechanism that prevents it from
concentrating too much on single frames, which further reduces PER to 17.6%
level.",2015-06-24T19:10:33Z,http://arxiv.org/pdf/1506.07503v1,"['cs.CL', 'cs.LG', 'cs.NE', 'stat.ML']"
1612.01928v1,Invariant Representations for Noisy Speech Recognition,"['Dmitriy Serdyuk', 'Kartik Audhkhasi', 'Philémon Brakel', 'Bhuvana Ramabhadran', 'Samuel Thomas', 'Yoshua Bengio']","Modern automatic speech recognition (ASR) systems need to be robust under
acoustic variability arising from environmental, speaker, channel, and
recording conditions. Ensuring such robustness to variability is a challenge in
modern day neural network-based ASR systems, especially when all types of
variability are not seen during training. We attempt to address this problem by
encouraging the neural network acoustic model to learn invariant feature
representations. We use ideas from recent research on image generation using
Generative Adversarial Networks and domain adaptation ideas extending
adversarial gradient-based training. A recent work from Ganin et al. proposes
to use adversarial training for image domain adaptation by using an
intermediate representation from the main target classification network to
deteriorate the domain classifier performance through a separate neural
network. Our work focuses on investigating neural architectures which produce
representations invariant to noise conditions for ASR. We evaluate the proposed
architecture on the Aurora-4 task, a popular benchmark for noise robust ASR. We
show that our method generalizes better than the standard multi-condition
training especially when only a few noise categories are seen during training.",2016-11-27T22:20:51Z,http://arxiv.org/pdf/1612.01928v1,"['cs.CL', 'cs.CV', 'cs.LG', 'cs.SD', 'stat.ML']"
1712.00489v1,Visual Features for Context-Aware Speech Recognition,"['Abhinav Gupta', 'Yajie Miao', 'Leonardo Neves', 'Florian Metze']","Automatic transcriptions of consumer-generated multi-media content such as
""Youtube"" videos still exhibit high word error rates. Such data typically
occupies a very broad domain, has been recorded in challenging conditions, with
cheap hardware and a focus on the visual modality, and may have been
post-processed or edited. In this paper, we extend our earlier work on adapting
the acoustic model of a DNN-based speech recognition system to an RNN language
model and show how both can be adapted to the objects and scenes that can be
automatically detected in the video. We are working on a corpus of ""how-to""
videos from the web, and the idea is that an object that can be seen (""car""),
or a scene that is being detected (""kitchen"") can be used to condition both
models on the ""context"" of the recording, thereby reducing perplexity and
improving transcription. We achieve good improvements in both cases and compare
and analyze the respective reductions in word error rate. We expect that our
results can be used for any type of speech processing in which ""context""
information is available, for example in robotics, man-machine interaction, or
when indexing large audio-visual archives, and should ultimately help to bring
together the ""video-to-text"" and ""speech-to-text"" communities.",2017-12-01T20:56:31Z,http://arxiv.org/pdf/1712.00489v1,"['cs.CL', 'cs.AI', 'cs.CV', 'cs.LG', 'eess.AS']"
1712.06086v1,Deep Learning for Distant Speech Recognition,['Mirco Ravanelli'],"Deep learning is an emerging technology that is considered one of the most
promising directions for reaching higher levels of artificial intelligence.
Among the other achievements, building computers that understand speech
represents a crucial leap towards intelligent machines. Despite the great
efforts of the past decades, however, a natural and robust human-machine speech
interaction still appears to be out of reach, especially when users interact
with a distant microphone in noisy and reverberant environments. The latter
disturbances severely hamper the intelligibility of a speech signal, making
Distant Speech Recognition (DSR) one of the major open challenges in the field.
  This thesis addresses the latter scenario and proposes some novel techniques,
architectures, and algorithms to improve the robustness of distant-talking
acoustic models. We first elaborate on methodologies for realistic data
contamination, with a particular emphasis on DNN training with simulated data.
We then investigate on approaches for better exploiting speech contexts,
proposing some original methodologies for both feed-forward and recurrent
neural networks. Lastly, inspired by the idea that cooperation across different
DNNs could be the key for counteracting the harmful effects of noise and
reverberation, we propose a novel deep learning paradigm called network of deep
neural networks. The analysis of the original concepts were based on extensive
experimental validations conducted on both real and simulated data, considering
different corpora, microphone configurations, environments, noisy conditions,
and ASR tasks.",2017-12-17T10:29:15Z,http://arxiv.org/pdf/1712.06086v1,"['cs.CL', 'cs.SD', 'eess.AS']"
1712.09444v2,Letter-Based Speech Recognition with Gated ConvNets,"['Vitaliy Liptchinsky', 'Gabriel Synnaeve', 'Ronan Collobert']","In the recent literature, ""end-to-end"" speech systems often refer to
letter-based acoustic models trained in a sequence-to-sequence manner, either
via a recurrent model or via a structured output learning approach (such as
CTC). In contrast to traditional phone (or senone)-based approaches, these
""end-to-end'' approaches alleviate the need of word pronunciation modeling, and
do not require a ""forced alignment"" step at training time. Phone-based
approaches remain however state of the art on classical benchmarks. In this
paper, we propose a letter-based speech recognition system, leveraging a
ConvNet acoustic model. Key ingredients of the ConvNet are Gated Linear Units
and high dropout. The ConvNet is trained to map audio sequences to their
corresponding letter transcriptions, either via a classical CTC approach, or
via a recent variant called ASG. Coupled with a simple decoder at inference
time, our system matches the best existing letter-based systems on WSJ (in word
error rate), and shows near state of the art performance on LibriSpeech.",2017-12-22T17:42:15Z,http://arxiv.org/pdf/1712.09444v2,"['cs.CL', 'cs.AI']"
1804.05374v2,Twin Regularization for online speech recognition,"['Mirco Ravanelli', 'Dmitriy Serdyuk', 'Yoshua Bengio']","Online speech recognition is crucial for developing natural human-machine
interfaces. This modality, however, is significantly more challenging than
off-line ASR, since real-time/low-latency constraints inevitably hinder the use
of future information, that is known to be very helpful to perform robust
predictions. A popular solution to mitigate this issue consists of feeding
neural acoustic models with context windows that gather some future frames.
This introduces a latency which depends on the number of employed look-ahead
features. This paper explores a different approach, based on estimating the
future rather than waiting for it. Our technique encourages the hidden
representations of a unidirectional recurrent network to embed some useful
information about the future. Inspired by a recently proposed technique called
Twin Networks, we add a regularization term that forces forward hidden states
to be as close as possible to cotemporal backward ones, computed by a ""twin""
neural network running backwards in time. The experiments, conducted on a
number of datasets, recurrent architectures, input features, and acoustic
conditions, have shown the effectiveness of this approach. One important
advantage is that our method does not introduce any additional computation at
test time if compared to standard unidirectional recurrent networks.",2018-04-15T15:52:16Z,http://arxiv.org/pdf/1804.05374v2,"['eess.AS', 'cs.AI', 'cs.CL', 'cs.LG', 'cs.NE']"
1811.07453v2,The PyTorch-Kaldi Speech Recognition Toolkit,"['Mirco Ravanelli', 'Titouan Parcollet', 'Yoshua Bengio']","The availability of open-source software is playing a remarkable role in the
popularization of speech recognition and deep learning. Kaldi, for instance, is
nowadays an established framework used to develop state-of-the-art speech
recognizers. PyTorch is used to build neural networks with the Python language
and has recently spawn tremendous interest within the machine learning
community thanks to its simplicity and flexibility.
  The PyTorch-Kaldi project aims to bridge the gap between these popular
toolkits, trying to inherit the efficiency of Kaldi and the flexibility of
PyTorch. PyTorch-Kaldi is not only a simple interface between these software,
but it embeds several useful features for developing modern speech recognizers.
For instance, the code is specifically designed to naturally plug-in
user-defined acoustic models. As an alternative, users can exploit several
pre-implemented neural networks that can be customized using intuitive
configuration files. PyTorch-Kaldi supports multiple feature and label streams
as well as combinations of neural networks, enabling the use of complex neural
architectures. The toolkit is publicly-released along with a rich documentation
and is designed to properly work locally or on HPC clusters.
  Experiments, that are conducted on several datasets and tasks, show that
PyTorch-Kaldi can effectively be used to develop modern state-of-the-art speech
recognizers.",2018-11-19T01:57:05Z,http://arxiv.org/pdf/1811.07453v2,"['eess.AS', 'cs.CL', 'cs.LG', 'cs.NE']"
1905.05605v1,Encrypted Speech Recognition using Deep Polynomial Networks,"['Shi-Xiong Zhang', 'Yifan Gong', 'Dong Yu']","The cloud-based speech recognition/API provides developers or enterprises an
easy way to create speech-enabled features in their applications. However,
sending audios about personal or company internal information to the cloud,
raises concerns about the privacy and security issues. The recognition results
generated in cloud may also reveal some sensitive information. This paper
proposes a deep polynomial network (DPN) that can be applied to the encrypted
speech as an acoustic model. It allows clients to send their data in an
encrypted form to the cloud to ensure that their data remains confidential, at
mean while the DPN can still make frame-level predictions over the encrypted
speech and return them in encrypted form. One good property of the DPN is that
it can be trained on unencrypted speech features in the traditional way. To
keep the cloud away from the raw audio and recognition results, a cloud-local
joint decoding framework is also proposed. We demonstrate the effectiveness of
model and framework on the Switchboard and Cortana voice assistant tasks with
small performance degradation and latency increased comparing with the
traditional cloud-based DNNs.",2019-05-11T00:14:09Z,http://arxiv.org/pdf/1905.05605v1,"['cs.CR', 'cs.CL', 'cs.SD', 'eess.AS', 'stat.ML']"
1908.01060v1,Multilingual Speech Recognition with Corpus Relatedness Sampling,"['Xinjian Li', 'Siddharth Dalmia', 'Alan W. Black', 'Florian Metze']","Multilingual acoustic models have been successfully applied to low-resource
speech recognition. Most existing works have combined many small corpora
together and pretrained a multilingual model by sampling from each corpus
uniformly. The model is eventually fine-tuned on each target corpus. This
approach, however, fails to exploit the relatedness and similarity among
corpora in the training set. For example, the target corpus might benefit more
from a corpus in the same domain or a corpus from a close language. In this
work, we propose a simple but useful sampling strategy to take advantage of
this relatedness. We first compute the corpus-level embeddings and estimate the
similarity between each corpus. Next, we start training the multilingual model
with uniform-sampling from each corpus at first, then we gradually increase the
probability to sample from related corpora based on its similarity with the
target corpus. Finally, the model would be fine-tuned automatically on the
target corpus. Our sampling strategy outperforms the baseline multilingual
model on 16 low-resource tasks. Additionally, we demonstrate that our corpus
embeddings capture the language and domain information of each corpus.",2019-08-02T21:08:13Z,http://arxiv.org/pdf/1908.01060v1,"['cs.CL', 'cs.SD', 'eess.AS']"
2004.04438v1,Improving Readability for Automatic Speech Recognition Transcription,"['Junwei Liao', 'Sefik Emre Eskimez', 'Liyang Lu', 'Yu Shi', 'Ming Gong', 'Linjun Shou', 'Hong Qu', 'Michael Zeng']","Modern Automatic Speech Recognition (ASR) systems can achieve high
performance in terms of recognition accuracy. However, a perfectly accurate
transcript still can be challenging to read due to grammatical errors,
disfluency, and other errata common in spoken communication. Many downstream
tasks and human readers rely on the output of the ASR system; therefore, errors
introduced by the speaker and ASR system alike will be propagated to the next
task in the pipeline. In this work, we propose a novel NLP task called ASR
post-processing for readability (APR) that aims to transform the noisy ASR
output into a readable text for humans and downstream tasks while maintaining
the semantic meaning of the speaker. In addition, we describe a method to
address the lack of task-specific data by synthesizing examples for the APR
task using the datasets collected for Grammatical Error Correction (GEC)
followed by text-to-speech (TTS) and ASR. Furthermore, we propose metrics
borrowed from similar tasks to evaluate performance on the APR task. We compare
fine-tuned models based on several open-sourced and adapted pre-trained models
with the traditional pipeline method. Our results suggest that finetuned models
improve the performance on the APR task significantly, hinting at the potential
benefits of using APR systems. We hope that the read, understand, and rewrite
approach of our work can serve as a basis that many NLP tasks and human readers
can benefit from.",2020-04-09T09:26:42Z,http://arxiv.org/pdf/2004.04438v1,['cs.CL']
2009.09615v2,End-to-End Bengali Speech Recognition,"['Sayan Mandal', 'Sarthak Yadav', 'Atul Rai']","Bengali is a prominent language of the Indian subcontinent. However, while
many state-of-the-art acoustic models exist for prominent languages spoken in
the region, research and resources for Bengali are few and far between. In this
work, we apply CTC based CNN-RNN networks, a prominent deep learning based
end-to-end automatic speech recognition technique, to the Bengali ASR task. We
also propose and evaluate the applicability and efficacy of small 7x3 and 3x3
convolution kernels which are prominently used in the computer vision domain
primarily because of their FLOPs and parameter efficient nature. We propose two
CNN blocks, 2-layer Block A and 4-layer Block B, with the first layer
comprising of 7x3 kernel and the subsequent layers comprising solely of 3x3
kernels. Using the publicly available Large Bengali ASR Training data set, we
benchmark and evaluate the performance of seven deep neural network
configurations of varying complexities and depth on the Bengali ASR task. Our
best model, with Block B, has a WER of 13.67, having an absolute reduction of
1.39% over comparable model with larger convolution kernels of size 41x11 and
21x11.",2020-09-21T05:08:07Z,http://arxiv.org/pdf/2009.09615v2,"['eess.AS', 'cs.SD']"
2108.00899v1,Adversarial Data Augmentation for Disordered Speech Recognition,"['Zengrui Jin', 'Mengzhe Geng', 'Xurong Xie', 'Jianwei Yu', 'Shansong Liu', 'Xunying Liu', 'Helen Meng']","Automatic recognition of disordered speech remains a highly challenging task
to date. The underlying neuro-motor conditions, often compounded with
co-occurring physical disabilities, lead to the difficulty in collecting large
quantities of impaired speech required for ASR system development. To this end,
data augmentation techniques play a vital role in current disordered speech
recognition systems. In contrast to existing data augmentation techniques only
modifying the speaking rate or overall shape of spectral contour, fine-grained
spectro-temporal differences between disordered and normal speech are modelled
using deep convolutional generative adversarial networks (DCGAN) during data
augmentation to modify normal speech spectra into those closer to disordered
speech. Experiments conducted on the UASpeech corpus suggest the proposed
adversarial data augmentation approach consistently outperformed the baseline
augmentation methods using tempo or speed perturbation on a state-of-the-art
hybrid DNN system. An overall word error rate (WER) reduction up to 3.05\%
(9.7\% relative) was obtained over the baseline system using no data
augmentation. The final learning hidden unit contribution (LHUC) speaker
adapted system using the best adversarial augmentation approach gives an
overall WER of 25.89% on the UASpeech test set of 16 dysarthric speakers.",2021-08-02T13:44:36Z,http://arxiv.org/pdf/2108.00899v1,"['eess.AS', 'cs.SD']"
2005.08497v1,Attention-based Transducer for Online Speech Recognition,"['Bin Wang', 'Yan Yin', 'Hui Lin']","Recent studies reveal the potential of recurrent neural network transducer
(RNN-T) for end-to-end (E2E) speech recognition. Among some most popular E2E
systems including RNN-T, Attention Encoder-Decoder (AED), and Connectionist
Temporal Classification (CTC), RNN-T has some clear advantages given that it
supports streaming recognition and does not have frame-independency assumption.
Although significant progresses have been made for RNN-T research, it is still
facing performance challenges in terms of training speed and accuracy. We
propose attention-based transducer with modification over RNN-T in two aspects.
First, we introduce chunk-wise attention in the joint network. Second,
self-attention is introduced in the encoder. Our proposed model outperforms
RNN-T for both training speed and accuracy. For training, we achieves over 1.7x
speedup. With 500 hours LAIX non-native English training data, attention-based
transducer yields ~10.6% WER reduction over baseline RNN-T. Trained with full
set of over 10K hours data, our final system achieves ~5.5% WER reduction over
that trained with the best Kaldi TDNN-f recipe. After 8-bit weight quantization
without WER degradation, RTF and latency drop to 0.34~0.36 and 268~409
milliseconds respectively on a single CPU core of a production server.",2020-05-18T07:26:33Z,http://arxiv.org/pdf/2005.08497v1,"['eess.AS', 'cs.CL', 'cs.SD']"
2104.04627v1,Accented Speech Recognition Inspired by Human Perception,"['Xiangyun Chu', 'Elizabeth Combs', 'Amber Wang', 'Michael Picheny']","While improvements have been made in automatic speech recognition performance
over the last several years, machines continue to have significantly lower
performance on accented speech than humans. In addition, the most significant
improvements on accented speech primarily arise by overwhelming the problem
with hundreds or even thousands of hours of data. Humans typically require much
less data to adapt to a new accent. This paper explores methods that are
inspired by human perception to evaluate possible performance improvements for
recognition of accented speech, with a specific focus on recognizing speech
with a novel accent relative to that of the training data. Our experiments are
run on small, accessible datasets that are available to the research community.
We explore four methodologies: pre-exposure to multiple accents, grapheme and
phoneme-based pronunciations, dropout (to improve generalization to a novel
accent), and the identification of the layers in the neural network that can
specifically be associated with accent modeling. Our results indicate that
methods based on human perception are promising in reducing WER and
understanding how accented speech is modeled in neural networks for novel
accents.",2021-04-09T22:35:09Z,http://arxiv.org/pdf/2104.04627v1,"['eess.AS', 'cs.CL', 'cs.LG', 'cs.SD']"
2202.01094v3,RescoreBERT: Discriminative Speech Recognition Rescoring with BERT,"['Liyan Xu', 'Yile Gu', 'Jari Kolehmainen', 'Haidar Khan', 'Ankur Gandhe', 'Ariya Rastrow', 'Andreas Stolcke', 'Ivan Bulyko']","Second-pass rescoring is an important component in automatic speech
recognition (ASR) systems that is used to improve the outputs from a first-pass
decoder by implementing a lattice rescoring or $n$-best re-ranking. While
pretraining with a masked language model (MLM) objective has received great
success in various natural language understanding (NLU) tasks, it has not
gained traction as a rescoring model for ASR. Specifically, training a
bidirectional model like BERT on a discriminative objective such as minimum WER
(MWER) has not been explored. Here we show how to train a BERT-based rescoring
model with MWER loss, to incorporate the improvements of a discriminative loss
into fine-tuning of deep bidirectional pretrained models for ASR. Specifically,
we propose a fusion strategy that incorporates the MLM into the discriminative
training process to effectively distill knowledge from a pretrained model. We
further propose an alternative discriminative loss. This approach, which we
call RescoreBERT, reduces WER by 6.6%/3.4% relative on the LibriSpeech
clean/other test sets over a BERT baseline without discriminative objective. We
also evaluate our method on an internal dataset from a conversational agent and
find that it reduces both latency and WER (by 3 to 8% relative) over an LSTM
rescoring model.",2022-02-02T15:45:26Z,http://arxiv.org/pdf/2202.01094v3,"['eess.AS', 'cs.CL', 'cs.LG', 'cs.SD']"
1802.06424v2,End-to-end Audiovisual Speech Recognition,"['Stavros Petridis', 'Themos Stafylakis', 'Pingchuan Ma', 'Feipeng Cai', 'Georgios Tzimiropoulos', 'Maja Pantic']","Several end-to-end deep learning approaches have been recently presented
which extract either audio or visual features from the input images or audio
signals and perform speech recognition. However, research on end-to-end
audiovisual models is very limited. In this work, we present an end-to-end
audiovisual model based on residual networks and Bidirectional Gated Recurrent
Units (BGRUs). To the best of our knowledge, this is the first audiovisual
fusion model which simultaneously learns to extract features directly from the
image pixels and audio waveforms and performs within-context word recognition
on a large publicly available dataset (LRW). The model consists of two streams,
one for each modality, which extract features directly from mouth regions and
raw waveforms. The temporal dynamics in each stream/modality are modeled by a
2-layer BGRU and the fusion of multiple streams/modalities takes place via
another 2-layer BGRU. A slight improvement in the classification rate over an
end-to-end audio-only and MFCC-based model is reported in clean audio
conditions and low levels of noise. In presence of high levels of noise, the
end-to-end audiovisual model significantly outperforms both audio-only models.",2018-02-18T19:07:31Z,http://arxiv.org/pdf/1802.06424v2,['cs.CV']
1807.10311v1,Open Source Automatic Speech Recognition for German,"['Benjamin Milde', 'Arne Köhn']","High quality Automatic Speech Recognition (ASR) is a prerequisite for
speech-based applications and research. While state-of-the-art ASR software is
freely available, the language dependent acoustic models are lacking for
languages other than English, due to the limited amount of freely available
training data. We train acoustic models for German with Kaldi on two datasets,
which are both distributed under a Creative Commons license. The resulting
model is freely redistributable, lowering the cost of entry for German ASR. The
models are trained on a total of 412 hours of German read speech data and we
achieve a relative word error reduction of 26% by adding data from the Spoken
Wikipedia Corpus to the previously best freely available German acoustic model
recipe and dataset. Our best model achieves a word error rate of 14.38 on the
Tuda-De test set. Due to the large amount of speakers and the diversity of
topics included in the training data, our model is robust against speaker
variation and topic shift.",2018-07-26T18:31:08Z,http://arxiv.org/pdf/1807.10311v1,['cs.CL']
2209.00261v1,Attention Enhanced Citrinet for Speech Recognition,['Xianchao Wu'],"Citrinet is an end-to-end convolutional Connectionist Temporal Classification
(CTC) based automatic speech recognition (ASR) model. To capture local and
global contextual information, 1D time-channel separable convolutions combined
with sub-word encoding and squeeze-and-excitation (SE) are used in Citrinet,
making the whole architecture to be as deep as including 23 blocks with 235
convolution layers and 46 linear layers. This pure convolutional and deep
architecture makes Critrinet relatively slow at convergence. In this paper, we
propose to introduce multi-head attentions together with feed-forward networks
in the convolution module in Citrinet blocks while keeping the SE module and
residual module unchanged. For speeding up, we remove 8 convolution layers in
each attention-enhanced Citrinet block and reduce 23 blocks to 13. Experiments
on the Japanese CSJ-500h and Magic-1600h dataset show that the
attention-enhanced Citrinet with less layers and blocks and converges faster
with lower character error rates than (1) Citrinet with 80\% training time and
(2) Conformer with 40\% training time and 29.8\% model size.",2022-09-01T06:59:50Z,http://arxiv.org/pdf/2209.00261v1,"['cs.CL', 'cs.LG', 'cs.SD', 'eess.AS']"
2305.02081v1,Considerations for Ethical Speech Recognition Datasets,"['Orestis Papakyriakopoulos', 'Alice Xiang']","Speech AI Technologies are largely trained on publicly available datasets or
by the massive web-crawling of speech. In both cases, data acquisition focuses
on minimizing collection effort, without necessarily taking the data subjects'
protection or user needs into consideration. This results to models that are
not robust when used on users who deviate from the dominant demographics in the
training set, discriminating individuals having different dialects, accents,
speaking styles, and disfluencies. In this talk, we use automatic speech
recognition as a case study and examine the properties that ethical speech
datasets should possess towards responsible AI applications. We showcase
diversity issues, inclusion practices, and necessary considerations that can
improve trained models, while facilitating model explainability and protecting
users and data subjects. We argue for the legal & privacy protection of data
subjects, targeted data sampling corresponding to user demographics & needs,
appropriate meta data that ensure explainability & accountability in cases of
model failure, and the sociotechnical \& situated model design. We hope this
talk can inspire researchers \& practitioners to design and use more
human-centric datasets in speech technologies and other domains, in ways that
empower and respect users, while improving machine learning models' robustness
and utility.",2023-05-03T12:38:14Z,http://arxiv.org/pdf/2305.02081v1,"['cs.CY', 'cs.CL', 'cs.SD', 'eess.AS']"
1801.00059v2,The CAPIO 2017 Conversational Speech Recognition System,"['Kyu J. Han', 'Akshay Chandrashekaran', 'Jungsuk Kim', 'Ian Lane']","In this paper we show how we have achieved the state-of-the-art performance
on the industry-standard NIST 2000 Hub5 English evaluation set. We explore
densely connected LSTMs, inspired by the densely connected convolutional
networks recently introduced for image classification tasks. We also propose an
acoustic model adaptation scheme that simply averages the parameters of a seed
neural network acoustic model and its adapted version. This method was applied
with the CallHome training corpus and improved individual system performances
by on average 6.1% (relative) against the CallHome portion of the evaluation
set with no performance loss on the Switchboard portion. With RNN-LM rescoring
and lattice combination on the 5 systems trained across three different phone
sets, our 2017 speech recognition system has obtained 5.0% and 9.1% on
Switchboard and CallHome, respectively, both of which are the best word error
rates reported thus far. According to IBM in their latest work to compare human
and machine transcriptions, our reported Switchboard word error rate can be
considered to surpass the human parity (5.1%) of transcribing conversational
telephone speech.",2017-12-29T23:31:05Z,http://arxiv.org/pdf/1801.00059v2,['cs.CL']
1902.02383v1,End-to-end Anchored Speech Recognition,"['Yiming Wang', 'Xing Fan', 'I-Fan Chen', 'Yuzong Liu', 'Tongfei Chen', 'Björn Hoffmeister']","Voice-controlled house-hold devices, like Amazon Echo or Google Home, face
the problem of performing speech recognition of device-directed speech in the
presence of interfering background speech, i.e., background noise and
interfering speech from another person or media device in proximity need to be
ignored. We propose two end-to-end models to tackle this problem with
information extracted from the ""anchored segment"". The anchored segment refers
to the wake-up word part of an audio stream, which contains valuable speaker
information that can be used to suppress interfering speech and background
noise. The first method is called ""Multi-source Attention"" where the attention
mechanism takes both the speaker information and decoder state into
consideration. The second method directly learns a frame-level mask on top of
the encoder output. We also explore a multi-task learning setup where we use
the ground truth of the mask to guide the learner. Given that audio data with
interfering speech is rare in our training data set, we also propose a way to
synthesize ""noisy"" speech from ""clean"" speech to mitigate the mismatch between
training and test data. Our proposed methods show up to 15% relative reduction
in WER for Amazon Alexa live data with interfering background speech without
significantly degrading on clean speech.",2019-02-06T19:50:23Z,http://arxiv.org/pdf/1902.02383v1,"['cs.CL', 'cs.LG', 'cs.SD', 'eess.AS']"
1906.08041v2,Multi-Stream End-to-End Speech Recognition,"['Ruizhi Li', 'Xiaofei Wang', 'Sri Harish Mallidi', 'Shinji Watanabe', 'Takaaki Hori', 'Hynek Hermansky']","Attention-based methods and Connectionist Temporal Classification (CTC)
network have been promising research directions for end-to-end (E2E) Automatic
Speech Recognition (ASR). The joint CTC/Attention model has achieved great
success by utilizing both architectures during multi-task training and joint
decoding. In this work, we present a multi-stream framework based on joint
CTC/Attention E2E ASR with parallel streams represented by separate encoders
aiming to capture diverse information. On top of the regular attention
networks, the Hierarchical Attention Network (HAN) is introduced to steer the
decoder toward the most informative encoders. A separate CTC network is
assigned to each stream to force monotonic alignments. Two representative
framework have been proposed and discussed, which are Multi-Encoder
Multi-Resolution (MEM-Res) framework and Multi-Encoder Multi-Array (MEM-Array)
framework, respectively. In MEM-Res framework, two heterogeneous encoders with
different architectures, temporal resolutions and separate CTC networks work in
parallel to extract complimentary information from same acoustics. Experiments
are conducted on Wall Street Journal (WSJ) and CHiME-4, resulting in relative
Word Error Rate (WER) reduction of 18.0-32.1% and the best WER of 3.6% in the
WSJ eval92 test set. The MEM-Array framework aims at improving the far-field
ASR robustness using multiple microphone arrays which are activated by separate
encoders. Compared with the best single-array results, the proposed framework
has achieved relative WER reduction of 3.7% and 9.7% in AMI and DIRHA
multi-array corpora, respectively, which also outperforms conventional fusion
strategies.",2019-06-17T23:00:15Z,http://arxiv.org/pdf/1906.08041v2,"['eess.AS', 'cs.CL', 'cs.SD']"
2008.04481v1,Transformer with Bidirectional Decoder for Speech Recognition,"['Xi Chen', 'Songyang Zhang', 'Dandan Song', 'Peng Ouyang', 'Shouyi Yin']","Attention-based models have made tremendous progress on end-to-end automatic
speech recognition(ASR) recently. However, the conventional transformer-based
approaches usually generate the sequence results token by token from left to
right, leaving the right-to-left contexts unexploited. In this work, we
introduce a bidirectional speech transformer to utilize the different
directional contexts simultaneously. Specifically, the outputs of our proposed
transformer include a left-to-right target, and a right-to-left target. In
inference stage, we use the introduced bidirectional beam search method, which
can not only generate left-to-right candidates but also generate right-to-left
candidates, and determine the best hypothesis by the score.
  To demonstrate our proposed speech transformer with a bidirectional
decoder(STBD), we conduct extensive experiments on the AISHELL-1 dataset. The
results of experiments show that STBD achieves a 3.6\% relative CER
reduction(CERR) over the unidirectional speech transformer baseline. Besides,
the strongest model in this paper called STBD-Big can achieve 6.64\% CER on the
test set, without language model rescoring and any extra data augmentation
strategies.",2020-08-11T02:12:42Z,http://arxiv.org/pdf/2008.04481v1,"['eess.AS', 'cs.CL', 'cs.LG', 'cs.SD']"
2008.12048v1,End-to-end Music-mixed Speech Recognition,"['Jeongwoo Woo', 'Masato Mimura', 'Kazuyoshi Yoshii', 'Tatsuya Kawahara']","Automatic speech recognition (ASR) in multimedia content is one of the
promising applications, but speech data in this kind of content are frequently
mixed with background music, which is harmful for the performance of ASR. In
this study, we propose a method for improving ASR with background music based
on time-domain source separation. We utilize Conv-TasNet as a separation
network, which has achieved state-of-the-art performance for multi-speaker
source separation, to extract the speech signal from a speech-music mixture in
the waveform domain. We also propose joint fine-tuning of a pre-trained
Conv-TasNet front-end with an attention-based ASR back-end using both
separation and ASR objectives. We evaluated our method through ASR experiments
using speech data mixed with background music from a wide variety of Japanese
animations. We show that time-domain speech-music separation drastically
improves ASR performance of the back-end model trained with mixture data, and
the joint optimization yielded a further significant WER reduction. The
time-domain separation method outperformed a frequency-domain separation
method, which reuses the phase information of the input mixture signal, both in
simple cascading and joint training settings. We also demonstrate that our
method works robustly for music interference from classical, jazz and popular
genres.",2020-08-27T10:51:26Z,http://arxiv.org/pdf/2008.12048v1,['eess.AS']
2106.07803v1,SynthASR: Unlocking Synthetic Data for Speech Recognition,"['Amin Fazel', 'Wei Yang', 'Yulan Liu', 'Roberto Barra-Chicote', 'Yixiong Meng', 'Roland Maas', 'Jasha Droppo']","End-to-end (E2E) automatic speech recognition (ASR) models have recently
demonstrated superior performance over the traditional hybrid ASR models.
Training an E2E ASR model requires a large amount of data which is not only
expensive but may also raise dependency on production data. At the same time,
synthetic speech generated by the state-of-the-art text-to-speech (TTS) engines
has advanced to near-human naturalness. In this work, we propose to utilize
synthetic speech for ASR training (SynthASR) in applications where data is
sparse or hard to get for ASR model training. In addition, we apply continual
learning with a novel multi-stage training strategy to address catastrophic
forgetting, achieved by a mix of weighted multi-style training, data
augmentation, encoder freezing, and parameter regularization. In our
experiments conducted on in-house datasets for a new application of recognizing
medication names, training ASR RNN-T models with synthetic audio via the
proposed multi-stage training improved the recognition performance on new
application by more than 65% relative, without degradation on existing general
applications. Our observations show that SynthASR holds great promise in
training the state-of-the-art large-scale E2E ASR models for new applications
while reducing the costs and dependency on production data.",2021-06-14T23:26:44Z,http://arxiv.org/pdf/2106.07803v1,"['cs.LG', 'cs.SD', 'eess.AS']"
2110.03509v5,Analyzing the Robustness of Unsupervised Speech Recognition,"['Guan-Ting Lin', 'Chan-Jan Hsu', 'Da-Rong Liu', 'Hung-Yi Lee', 'Yu Tsao']","Unsupervised speech recognition (unsupervised ASR) aims to learn the ASR
system with non-parallel speech and text corpus only. Wav2vec-U has shown
promising results in unsupervised ASR by self-supervised speech representations
coupled with Generative Adversarial Network (GAN) training, but the robustness
of the unsupervised ASR framework is unknown. In this work, we further analyze
the training robustness of unsupervised ASR on the domain mismatch scenarios in
which the domains of unpaired speech and text are different. Three domain
mismatch scenarios include: (1) using speech and text from different datasets,
(2) utilizing noisy/spontaneous speech, and (3) adjusting the amount of speech
and text data. We also quantify the degree of the domain mismatch by
calculating the JS-divergence of phoneme n-gram between the transcription of
speech and text. This metric correlates with the performance highly.
Experimental results show that domain mismatch leads to inferior performance,
but a self-supervised model pre-trained on the targeted speech domain can
extract better representation to alleviate the performance drop.",2021-10-07T14:46:10Z,http://arxiv.org/pdf/2110.03509v5,['eess.AS']
2111.03250v1,Context-Aware Transformer Transducer for Speech Recognition,"['Feng-Ju Chang', 'Jing Liu', 'Martin Radfar', 'Athanasios Mouchtaris', 'Maurizio Omologo', 'Ariya Rastrow', 'Siegfried Kunzmann']","End-to-end (E2E) automatic speech recognition (ASR) systems often have
difficulty recognizing uncommon words, that appear infrequently in the training
data. One promising method, to improve the recognition accuracy on such rare
words, is to latch onto personalized/contextual information at inference. In
this work, we present a novel context-aware transformer transducer (CATT)
network that improves the state-of-the-art transformer-based ASR system by
taking advantage of such contextual signals. Specifically, we propose a
multi-head attention-based context-biasing network, which is jointly trained
with the rest of the ASR sub-networks. We explore different techniques to
encode contextual data and to create the final attention context vectors. We
also leverage both BLSTM and pretrained BERT based models to encode contextual
data and guide the network training. Using an in-house far-field dataset, we
show that CATT, using a BERT based context encoder, improves the word error
rate of the baseline transformer transducer and outperforms an existing deep
contextual model by 24.2% and 19.4% respectively.",2021-11-05T04:14:35Z,http://arxiv.org/pdf/2111.03250v1,"['cs.CL', 'cs.LG', 'cs.SD', 'eess.AS']"
2211.01458v2,Towards Zero-Shot Code-Switched Speech Recognition,"['Brian Yan', 'Matthew Wiesner', 'Ondrej Klejch', 'Preethi Jyothi', 'Shinji Watanabe']","In this work, we seek to build effective code-switched (CS) automatic speech
recognition systems (ASR) under the zero-shot setting where no transcribed CS
speech data is available for training. Previously proposed frameworks which
conditionally factorize the bilingual task into its constituent monolingual
parts are a promising starting point for leveraging monolingual data
efficiently. However, these methods require the monolingual modules to perform
language segmentation. That is, each monolingual module has to simultaneously
detect CS points and transcribe speech segments of one language while ignoring
those of other languages -- not a trivial task. We propose to simplify each
monolingual module by allowing them to transcribe all speech segments
indiscriminately with a monolingual script (i.e. transliteration). This simple
modification passes the responsibility of CS point detection to subsequent
bilingual modules which determine the final output by considering multiple
monolingual transliterations along with external language model information. We
apply this transliteration-based approach in an end-to-end differentiable
neural network and demonstrate its efficacy for zero-shot CS ASR on
Mandarin-English SEAME test sets.",2022-11-02T19:52:54Z,http://arxiv.org/pdf/2211.01458v2,"['cs.CL', 'cs.SD', 'eess.AS']"
2303.03329v1,End-to-End Speech Recognition: A Survey,"['Rohit Prabhavalkar', 'Takaaki Hori', 'Tara N. Sainath', 'Ralf Schlüter', 'Shinji Watanabe']","In the last decade of automatic speech recognition (ASR) research, the
introduction of deep learning brought considerable reductions in word error
rate of more than 50% relative, compared to modeling without deep learning. In
the wake of this transition, a number of all-neural ASR architectures were
introduced. These so-called end-to-end (E2E) models provide highly integrated,
completely neural ASR models, which rely strongly on general machine learning
knowledge, learn more consistently from data, while depending less on ASR
domain-specific experience. The success and enthusiastic adoption of deep
learning accompanied by more generic model architectures lead to E2E models now
becoming the prominent ASR approach. The goal of this survey is to provide a
taxonomy of E2E ASR models and corresponding improvements, and to discuss their
properties and their relation to the classical hidden Markov model (HMM) based
ASR architecture. All relevant aspects of E2E ASR are covered in this work:
modeling, training, decoding, and external language model integration,
accompanied by discussions of performance and deployment opportunities, as well
as an outlook into potential future developments.",2023-03-03T01:46:41Z,http://arxiv.org/pdf/2303.03329v1,"['eess.AS', 'cs.CL', 'cs.SD']"
2308.11589v1,Indonesian Automatic Speech Recognition with XLSR-53,"['Panji Arisaputra', 'Amalia Zahra']","This study focuses on the development of Indonesian Automatic Speech
Recognition (ASR) using the XLSR-53 pre-trained model, the XLSR stands for
cross-lingual speech representations. The use of this XLSR-53 pre-trained model
is to significantly reduce the amount of training data in non-English languages
required to achieve a competitive Word Error Rate (WER). The total amount of
data used in this study is 24 hours, 18 minutes, and 1 second: (1) TITML-IDN 14
hours and 31 minutes; (2) Magic Data 3 hours and 33 minutes; and (3) Common
Voice 6 hours, 14 minutes, and 1 second. With a WER of 20%, the model built in
this study can compete with similar models using the Common Voice dataset split
test. WER can be decreased by around 8% using a language model, resulted in WER
from 20% to 12%. Thus, the results of this study have succeeded in perfecting
previous research in contributing to the creation of a better Indonesian ASR
with a smaller amount of data.",2023-08-20T09:59:40Z,http://arxiv.org/pdf/2308.11589v1,"['cs.CL', 'cs.SD', 'eess.AS']"
2310.15970v3,Accented Speech Recognition With Accent-specific Codebooks,"['Darshan Prabhu', 'Preethi Jyothi', 'Sriram Ganapathy', 'Vinit Unni']","Speech accents pose a significant challenge to state-of-the-art automatic
speech recognition (ASR) systems. Degradation in performance across
underrepresented accents is a severe deterrent to the inclusive adoption of
ASR. In this work, we propose a novel accent adaptation approach for end-to-end
ASR systems using cross-attention with a trainable set of codebooks. These
learnable codebooks capture accent-specific information and are integrated
within the ASR encoder layers. The model is trained on accented English speech,
while the test data also contained accents which were not seen during training.
On the Mozilla Common Voice multi-accented dataset, we show that our proposed
approach yields significant performance gains not only on the seen English
accents (up to $37\%$ relative improvement in word error rate) but also on the
unseen accents (up to $5\%$ relative improvement in WER). Further, we
illustrate benefits for a zero-shot transfer setup on the L2Artic dataset. We
also compare the performance with other approaches based on accent adversarial
training.",2023-10-24T16:10:58Z,http://arxiv.org/pdf/2310.15970v3,"['cs.CL', 'cs.AI', 'cs.LG']"
2312.14020v1,BANSpEmo: A Bangla Emotional Speech Recognition Dataset,"['Md Gulzar Hussain', 'Mahmuda Rahman', 'Babe Sultana', 'Ye Shiren']","In the field of audio and speech analysis, the ability to identify emotions
from acoustic signals is essential. Human-computer interaction (HCI) and
behavioural analysis are only a few of the many areas where the capacity to
distinguish emotions from speech signals has an extensive range of
applications. Here, we are introducing BanSpEmo, a corpus of emotional speech
that only consists of audio recordings and has been created specifically for
the Bangla language. This corpus contains 792 audio recordings over a duration
of more than 1 hour and 23 minutes. 22 native speakers took part in the
recording of two sets of sentences that represent the six desired emotions. The
data set consists of 12 Bangla sentences which are uttered in 6 emotions as
Disgust, Happy, Sad, Surprised, Anger, and Fear. This corpus is not also gender
balanced. Ten individuals who either have experience in related field or have
acting experience took part in the assessment of this corpus. It has a balanced
number of audio recordings in each emotion class. BanSpEmo can be considered as
a useful resource to promote emotion and speech recognition research and
related applications in the Bangla language. The dataset can be found here:
https://data.mendeley.com/datasets/rdwn4bs5ky and might be employed for
academic research.",2023-12-21T16:52:41Z,http://arxiv.org/pdf/2312.14020v1,"['cs.HC', 'cs.LG', 'cs.SD', 'eess.AS']"
2405.13344v2,Contextualized Automatic Speech Recognition with Dynamic Vocabulary,"['Yui Sudo', 'Yosuke Fukumoto', 'Muhammad Shakeel', 'Yifan Peng', 'Shinji Watanabe']","Deep biasing (DB) enhances the performance of end-to-end automatic speech
recognition (E2E-ASR) models for rare words or contextual phrases using a bias
list. However, most existing methods treat bias phrases as sequences of
subwords in a predefined static vocabulary. This naive sequence decomposition
produces unnatural token patterns, significantly lowering their occurrence
probability. More advanced techniques address this problem by expanding the
vocabulary with additional modules, including the external language model
shallow fusion or rescoring. However, they result in increasing the workload
due to the additional modules. This paper proposes a dynamic vocabulary where
bias tokens can be added during inference. Each entry in a bias list is
represented as a single token, unlike a sequence of existing subword tokens.
This approach eliminates the need to learn subword dependencies within the bias
phrases. This method is easily applied to various architectures because it only
expands the embedding and output layers in common E2E-ASR architectures.
Experimental results demonstrate that the proposed method improves the bias
phrase WER on English and Japanese datasets by 3.1 -- 4.9 points compared with
the conventional DB method.",2024-05-22T05:03:39Z,http://arxiv.org/pdf/2405.13344v2,"['eess.AS', 'cs.CL', 'cs.SD']"
2011.00721v1,"Robust Raw Waveform Speech Recognition Using Relevance Weighted
  Representations","['Purvi Agrawal', 'Sriram Ganapathy']","Speech recognition in noisy and channel distorted scenarios is often
challenging as the current acoustic modeling schemes are not adaptive to the
changes in the signal distribution in the presence of noise. In this work, we
develop a novel acoustic modeling framework for noise robust speech recognition
based on relevance weighting mechanism. The relevance weighting is achieved
using a sub-network approach that performs feature selection. A relevance
sub-network is applied on the output of first layer of a convolutional network
model operating on raw speech signals while a second relevance sub-network is
applied on the second convolutional layer output. The relevance weights for the
first layer correspond to an acoustic filterbank selection while the relevance
weights in the second layer perform modulation filter selection. The model is
trained for a speech recognition task on noisy and reverberant speech. The
speech recognition experiments on multiple datasets (Aurora-4, CHiME-3, VOiCES)
reveal that the incorporation of relevance weighting in the neural network
architecture improves the speech recognition word error rates significantly
(average relative improvements of 10% over the baseline systems)",2020-10-29T19:32:50Z,http://arxiv.org/pdf/2011.00721v1,"['eess.AS', 'cs.SD']"
2201.05845v2,Recent Progress in the CUHK Dysarthric Speech Recognition System,"['Shansong Liu', 'Mengzhe Geng', 'Shoukang Hu', 'Xurong Xie', 'Mingyu Cui', 'Jianwei Yu', 'Xunying Liu', 'Helen Meng']","Despite the rapid progress of automatic speech recognition (ASR) technologies
in the past few decades, recognition of disordered speech remains a highly
challenging task to date. Disordered speech presents a wide spectrum of
challenges to current data intensive deep neural networks (DNNs) based ASR
technologies that predominantly target normal speech. This paper presents
recent research efforts at the Chinese University of Hong Kong (CUHK) to
improve the performance of disordered speech recognition systems on the largest
publicly available UASpeech dysarthric speech corpus. A set of novel modelling
techniques including neural architectural search, data augmentation using
spectra-temporal perturbation, model based speaker adaptation and cross-domain
generation of visual features within an audio-visual speech recognition (AVSR)
system framework were employed to address the above challenges. The combination
of these techniques produced the lowest published word error rate (WER) of
25.21% on the UASpeech test set 16 dysarthric speakers, and an overall WER
reduction of 5.4% absolute (17.6% relative) over the CUHK 2018 dysarthric
speech recognition system featuring a 6-way DNN system combination and cross
adaptation of out-of-domain normal speech data trained systems. Bayesian model
adaptation further allows rapid adaptation to individual dysarthric speakers to
be performed using as little as 3.06 seconds of speech. The efficacy of these
techniques were further demonstrated on a CUDYS Cantonese dysarthric speech
recognition task.",2022-01-15T13:02:40Z,http://arxiv.org/pdf/2201.05845v2,"['eess.AS', 'cs.AI', 'cs.LG', 'cs.SD']"
2407.21211v2,"Leveraging Self-Supervised Models for Automatic Whispered Speech
  Recognition","['Aref Farhadipour', 'Homa Asadi', 'Volker Dellwo']","In automatic speech recognition, any factor that alters the acoustic
properties of speech can pose a challenge to the system's performance. This
paper presents a novel approach for automatic whispered speech recognition in
the Irish dialect using the self-supervised WavLM model. Conventional automatic
speech recognition systems often fail to accurately recognise whispered speech
due to its distinct acoustic properties and the scarcity of relevant training
data. To address this challenge, we utilized a pre-trained WavLM model,
fine-tuned with a combination of whispered and normal speech data from the
wTIMIT and CHAINS datasets, which include the English language in Singaporean
and Irish dialects, respectively. Our baseline evaluation with the OpenAI
Whisper model highlighted its limitations, achieving a Word Error Rate (WER) of
18.8% and a Character Error Rate (CER) of 4.24% on whispered speech. In
contrast, the proposed WavLM-based system significantly improved performance,
achieving a WER of 9.22% and a CER of 2.59%. These results demonstrate the
efficacy of our approach in recognising whispered speech and underscore the
importance of tailored acoustic modeling for robust automatic speech
recognition systems. This study provides valuable insights into developing
effective automatic speech recognition solutions for challenging speech
affected by whisper and dialect. The source codes for this paper are freely
available.",2024-07-30T21:45:37Z,http://arxiv.org/pdf/2407.21211v2,"['eess.AS', 'cs.SD']"
2412.19005v1,"Enhancing Audiovisual Speech Recognition through Bifocal Preference
  Optimization","['Yihan Wu', 'Yichen Lu', 'Yifan Peng', 'Xihua Wang', 'Ruihua Song', 'Shinji Watanabe']","Audiovisual Automatic Speech Recognition (AV-ASR) aims to improve speech
recognition accuracy by leveraging visual signals. It is particularly
challenging in unconstrained real-world scenarios across various domains due to
noisy acoustic environments, spontaneous speech, and the uncertain use of
visual information. Most previous works fine-tune audio-only ASR models on
audiovisual datasets, optimizing them for conventional ASR objectives. However,
they often neglect visual features and common errors in unconstrained video
scenarios. In this paper, we propose using a preference optimization strategy
to improve speech recognition accuracy for real-world videos. First, we create
preference data via simulating common errors that occurred in AV-ASR from two
focals: manipulating the audio or vision input and rewriting the output
transcript. Second, we propose BPO-AVASR, a Bifocal Preference Optimization
method to improve AV-ASR models by leveraging both input-side and output-side
preference. Extensive experiments demonstrate that our approach significantly
improves speech recognition accuracy across various domains, outperforming
previous state-of-the-art models on real-world video speech recognition.",2024-12-26T00:26:45Z,http://arxiv.org/pdf/2412.19005v1,"['eess.AS', 'cs.AI']"
