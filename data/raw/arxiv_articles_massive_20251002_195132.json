[
  {
    "arxiv_id": "1311.0716v1",
    "title": "Artificial Intelligence in Humans",
    "authors": [
      "Michael Swan Laufer"
    ],
    "abstract": "In this paper, I put forward that in many instances, thinking mechanisms are\nequivalent to artificial intelligence modules programmed into the human mind.",
    "published": "2013-10-30T14:19:49Z",
    "pdf_url": "http://arxiv.org/pdf/1311.0716v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1903.04442v1",
    "title": "Physics Enhanced Artificial Intelligence",
    "authors": [
      "Patrick O'Driscoll",
      "Jaehoon Lee",
      "Bo Fu"
    ],
    "abstract": "We propose that intelligently combining models from the domains of Artificial\nIntelligence or Machine Learning with Physical and Expert models will yield a\nmore \"trustworthy\" model than any one model from a single domain, given a\ncomplex and narrow enough problem. Based on mean-variance portfolio theory and\nbias-variance trade-off analysis, we prove combining models from various\ndomains produces a model that has lower risk, increasing user trust. We call\nsuch combined models - physics enhanced artificial intelligence (PEAI), and\nsuggest use cases for PEAI.",
    "published": "2019-03-11T17:03:19Z",
    "pdf_url": "http://arxiv.org/pdf/1903.04442v1",
    "categories": [
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1606.08514v4",
    "title": "Towards Verified Artificial Intelligence",
    "authors": [
      "Sanjit A. Seshia",
      "Dorsa Sadigh",
      "S. Shankar Sastry"
    ],
    "abstract": "Verified artificial intelligence (AI) is the goal of designing AI-based\nsystems that that have strong, ideally provable, assurances of correctness with\nrespect to mathematically-specified requirements. This paper considers Verified\nAI from a formal methods perspective. We describe five challenges for achieving\nVerified AI, and five corresponding principles for addressing these challenges.",
    "published": "2016-06-27T23:51:04Z",
    "pdf_url": "http://arxiv.org/pdf/1606.08514v4",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1812.04814v1",
    "title": "Linking Artificial Intelligence Principles",
    "authors": [
      "Yi Zeng",
      "Enmeng Lu",
      "Cunqing Huangfu"
    ],
    "abstract": "Artificial Intelligence principles define social and ethical considerations\nto develop future AI. They come from research institutes, government\norganizations and industries. All versions of AI principles are with different\nconsiderations covering different perspectives and making different emphasis.\nNone of them can be considered as complete and can cover the rest AI principle\nproposals. Here we introduce LAIP, an effort and platform for linking and\nanalyzing different Artificial Intelligence Principles. We want to explicitly\nestablish the common topics and links among AI Principles proposed by different\norganizations and investigate on their uniqueness. Based on these efforts, for\nthe long-term future of AI, instead of directly adopting any of the AI\nprinciples, we argue for the necessity of incorporating various AI Principles\ninto a comprehensive framework and focusing on how they can interact and\ncomplete each other.",
    "published": "2018-12-12T05:43:57Z",
    "pdf_url": "http://arxiv.org/pdf/1812.04814v1",
    "categories": [
      "cs.AI",
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "2407.16314v1",
    "title": "Capital as Artificial Intelligence",
    "authors": [
      "Cesare Carissimo",
      "Marcin Korecki"
    ],
    "abstract": "We gather many perspectives on Capital and synthesize their commonalities. We\nprovide a characterization of Capital as a historical agential system and\npropose a model of Capital using tools from computer science. Our model\nconsists of propositions which, if satisfied by a specific grounding,\nconstitute a valid model of Capital. We clarify the manners in which Capital\ncan evolve. We claim that, when its evolution is driven by quantitative\noptimization processes, Capital can possess qualities of Artificial\nIntelligence. We find that Capital may not uniquely represent meaning, in the\nsame way that optimization is not intentionally meaningful. We find that\nArtificial Intelligences like modern day Large Language Models are a part of\nCapital. We link our readers to a web-interface where they can interact with a\npart of Capital.",
    "published": "2024-07-23T09:05:33Z",
    "pdf_url": "http://arxiv.org/pdf/2407.16314v1",
    "categories": [
      "cs.CY",
      "econ.TH"
    ]
  },
  {
    "arxiv_id": "2001.00627v1",
    "title": "Artificial Intelligence in Surgery",
    "authors": [
      "Xiao-Yun Zhou",
      "Yao Guo",
      "Mali Shen",
      "Guang-Zhong Yang"
    ],
    "abstract": "Artificial Intelligence (AI) is gradually changing the practice of surgery\nwith the advanced technological development of imaging, navigation and robotic\nintervention. In this article, the recent successful and influential\napplications of AI in surgery are reviewed from pre-operative planning and\nintra-operative guidance to the integration of surgical robots. We end with\nsummarizing the current state, emerging trends and major challenges in the\nfuture development of AI in surgery.",
    "published": "2019-12-23T12:39:04Z",
    "pdf_url": "http://arxiv.org/pdf/2001.00627v1",
    "categories": [
      "physics.med-ph",
      "cs.AI",
      "eess.IV"
    ]
  },
  {
    "arxiv_id": "1908.10345v1",
    "title": "Artificial Intelligence Approaches",
    "authors": [
      "Yingjie Hu",
      "Wenwen Li",
      "Dawn Wright",
      "Orhun Aydin",
      "Daniel Wilson",
      "Omar Maher",
      "Mansour Raad"
    ],
    "abstract": "Artificial Intelligence (AI) has received tremendous attention from academia,\nindustry, and the general public in recent years. The integration of geography\nand AI, or GeoAI, provides novel approaches for addressing a variety of\nproblems in the natural environment and our human society. This entry briefly\nreviews the recent development of AI with a focus on machine learning and deep\nlearning approaches. We discuss the integration of AI with geography and\nparticularly geographic information science, and present a number of GeoAI\napplications and possible future directions.",
    "published": "2019-08-27T17:36:27Z",
    "pdf_url": "http://arxiv.org/pdf/1908.10345v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2212.11854v4",
    "title": "Data-Centric Artificial Intelligence",
    "authors": [
      "Johannes Jakubik",
      "Michael Vössing",
      "Niklas Kühl",
      "Jannis Walk",
      "Gerhard Satzger"
    ],
    "abstract": "Data-centric artificial intelligence (data-centric AI) represents an emerging\nparadigm emphasizing that the systematic design and engineering of data is\nessential for building effective and efficient AI-based systems. The objective\nof this article is to introduce practitioners and researchers from the field of\nInformation Systems (IS) to data-centric AI. We define relevant terms, provide\nkey characteristics to contrast the data-centric paradigm to the model-centric\none, and introduce a framework for data-centric AI. We distinguish data-centric\nAI from related concepts and discuss its longer-term implications for the IS\ncommunity.",
    "published": "2022-12-22T16:41:03Z",
    "pdf_url": "http://arxiv.org/pdf/2212.11854v4",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2202.09859v1",
    "title": "Cooperative Artificial Intelligence",
    "authors": [
      "Tobias Baumann"
    ],
    "abstract": "In the future, artificial learning agents are likely to become increasingly\nwidespread in our society. They will interact with both other learning agents\nand humans in a variety of complex settings including social dilemmas. We argue\nthat there is a need for research on the intersection between game theory and\nartificial intelligence, with the goal of achieving cooperative artificial\nintelligence that can navigate social dilemmas well. We consider the problem of\nhow an external agent can promote cooperation between artificial learners by\ndistributing additional rewards and punishments based on observing the actions\nof the learners. We propose a rule for automatically learning how to create the\nright incentives by considering the anticipated parameter updates of each\nagent. Using this learning rule leads to cooperation with high social welfare\nin matrix games in which the agents would otherwise learn to defect with high\nprobability. We show that the resulting cooperative outcome is stable in\ncertain games even if the planning agent is turned off after a given number of\nepisodes, while other games require ongoing intervention to maintain mutual\ncooperation. Finally, we reflect on what the goals of multi-agent reinforcement\nlearning should be in the first place, and discuss the necessary building\nblocks towards the goal of building cooperative AI.",
    "published": "2022-02-20T16:50:37Z",
    "pdf_url": "http://arxiv.org/pdf/2202.09859v1",
    "categories": [
      "cs.AI",
      "cs.GT",
      "cs.MA"
    ]
  },
  {
    "arxiv_id": "1802.04451v2",
    "title": "Blockchain and Artificial Intelligence",
    "authors": [
      "Tshilidzi Marwala",
      "Bo Xing"
    ],
    "abstract": "It is undeniable that artificial intelligence (AI) and blockchain concepts\nare spreading at a phenomenal rate. Both technologies have distinct degree of\ntechnological complexity and multi-dimensional business implications. However,\na common misunderstanding about blockchain concept, in particular, is that\nblockchain is decentralized and is not controlled by anyone. But the underlying\ndevelopment of a blockchain system is still attributed to a cluster of core\ndevelopers. Take smart contract as an example, it is essentially a collection\nof codes (or functions) and data (or states) that are programmed and deployed\non a blockchain (say, Ethereum) by different human programmers. It is thus,\nunfortunately, less likely to be free of loopholes and flaws. In this article,\nthrough a brief overview about how artificial intelligence could be used to\ndeliver bug-free smart contract so as to achieve the goal of blockchain 2.0, we\nto emphasize that the blockchain implementation can be assisted or enhanced via\nvarious AI techniques. The alliance of AI and blockchain is expected to create\nnumerous possibilities.",
    "published": "2018-02-13T03:10:59Z",
    "pdf_url": "http://arxiv.org/pdf/1802.04451v2",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2502.05244v1",
    "title": "Probabilistic Artificial Intelligence",
    "authors": [
      "Andreas Krause",
      "Jonas Hübotter"
    ],
    "abstract": "Artificial intelligence commonly refers to the science and engineering of\nartificial systems that can carry out tasks generally associated with requiring\naspects of human intelligence, such as playing games, translating languages,\nand driving cars. In recent years, there have been exciting advances in\nlearning-based, data-driven approaches towards AI, and machine learning and\ndeep learning have enabled computer systems to perceive the world in\nunprecedented ways. Reinforcement learning has enabled breakthroughs in complex\ngames such as Go and challenging robotics tasks such as quadrupedal locomotion.\n  A key aspect of intelligence is to not only make predictions, but reason\nabout the uncertainty in these predictions, and to consider this uncertainty\nwhen making decisions. This is what this manuscript on \"Probabilistic\nArtificial Intelligence\" is about. The first part covers probabilistic\napproaches to machine learning. We discuss the differentiation between\n\"epistemic\" uncertainty due to lack of data and \"aleatoric\" uncertainty, which\nis irreducible and stems, e.g., from noisy observations and outcomes. We\ndiscuss concrete approaches towards probabilistic inference and modern\napproaches to efficient approximate inference.\n  The second part of the manuscript is about taking uncertainty into account in\nsequential decision tasks. We consider active learning and Bayesian\noptimization -- approaches that collect data by proposing experiments that are\ninformative for reducing the epistemic uncertainty. We then consider\nreinforcement learning and modern deep RL approaches that use neural network\nfunction approximation. We close by discussing modern approaches in model-based\nRL, which harness epistemic and aleatoric uncertainty to guide exploration,\nwhile also reasoning about safety.",
    "published": "2025-02-07T14:29:07Z",
    "pdf_url": "http://arxiv.org/pdf/2502.05244v1",
    "categories": [
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1712.03779v1",
    "title": "Artificial Intelligence and Statistics",
    "authors": [
      "Bin Yu",
      "Karl Kumbier"
    ],
    "abstract": "Artificial intelligence (AI) is intrinsically data-driven. It calls for the\napplication of statistical concepts through human-machine collaboration during\ngeneration of data, development of algorithms, and evaluation of results. This\npaper discusses how such human-machine collaboration can be approached through\nthe statistical concepts of population, question of interest,\nrepresentativeness of training data, and scrutiny of results (PQRS). The PQRS\nworkflow provides a conceptual framework for integrating statistical ideas with\nhuman input into AI products and research. These ideas include experimental\ndesign principles of randomization and local control as well as the principle\nof stability to gain reproducibility and interpretability of algorithms and\ndata results. We discuss the use of these principles in the contexts of\nself-driving cars, automated medical diagnoses, and examples from the authors'\ncollaborative research.",
    "published": "2017-12-08T02:18:43Z",
    "pdf_url": "http://arxiv.org/pdf/1712.03779v1",
    "categories": [
      "stat.ML",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1908.02150v3",
    "title": "Industrial Artificial Intelligence",
    "authors": [
      "Jay Lee",
      "Jaskaran Singh",
      "Moslem Azamfar"
    ],
    "abstract": "Artificial Intelligence (AI) is a cognitive science to enables human to\nexplore many intelligent ways to model our sensing and reasoning processes.\nIndustrial AI is a systematic discipline to enable engineers to systematically\ndevelop and deploy AI algorithms with repeating and consistent successes. In\nthis paper, the key enablers for this transformative technology along with\ntheir significant advantages are discussed. In addition, this research explains\nLighthouse Factories as an emerging status applying to the top manufacturers\nthat have implemented Industrial AI in their manufacturing ecosystem and gained\nsignificant financial benefits. It is believed that this research will work as\na guideline and roadmap for researchers and industries towards the real-world\nimplementation of Industrial AI.",
    "published": "2019-08-04T05:19:43Z",
    "pdf_url": "http://arxiv.org/pdf/1908.02150v3",
    "categories": [
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "2006.12362v1",
    "title": "Artificial intelligence in space",
    "authors": [
      "George Anthony Gal",
      "Cristiana Santos",
      "Lucien Rapp",
      "Réeka Markovich",
      "Leendert van der Torre"
    ],
    "abstract": "In the next coming years, space activities are expected to undergo a radical\ntransformation with the emergence of new satellite systems or new services\nwhich will incorporate the contributions of artificial intelligence and machine\nlearning defined as covering a wide range of innovations from autonomous\nobjects with their own decision-making power to increasingly sophisticated\nservices exploiting very large volumes of information from space. This chapter\nidentifies some of the legal and ethical challenges linked to its use. These\nlegal and ethical challenges call for solutions which the international\ntreaties in force are not sufficient to determine and implement. For this\nreason, a legal methodology must be developed that makes it possible to link\nintelligent systems and services to a system of rules applicable thereto. It\ndiscusses existing legal AI-based tools amenable for making space law\nactionable, interoperable and machine readable for future compliance tools.",
    "published": "2020-06-22T16:00:44Z",
    "pdf_url": "http://arxiv.org/pdf/2006.12362v1",
    "categories": [
      "cs.CY",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2101.06573v1",
    "title": "Understanding in Artificial Intelligence",
    "authors": [
      "Stefan Maetschke",
      "David Martinez Iraola",
      "Pieter Barnard",
      "Elaheh ShafieiBavani",
      "Peter Zhong",
      "Ying Xu",
      "Antonio Jimeno Yepes"
    ],
    "abstract": "Current Artificial Intelligence (AI) methods, most based on deep learning,\nhave facilitated progress in several fields, including computer vision and\nnatural language understanding. The progress of these AI methods is measured\nusing benchmarks designed to solve challenging tasks, such as visual question\nanswering. A question remains of how much understanding is leveraged by these\nmethods and how appropriate are the current benchmarks to measure understanding\ncapabilities. To answer these questions, we have analysed existing benchmarks\nand their understanding capabilities, defined by a set of understanding\ncapabilities, and current research streams. We show how progress has been made\nin benchmark development to measure understanding capabilities of AI methods\nand we review as well how current methods develop understanding capabilities.",
    "published": "2021-01-17T02:29:50Z",
    "pdf_url": "http://arxiv.org/pdf/2101.06573v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2301.10823v3",
    "title": "Reflective Artificial Intelligence",
    "authors": [
      "Peter R. Lewis",
      "Stefan Sarkadi"
    ],
    "abstract": "Artificial Intelligence (AI) is about making computers that do the sorts of\nthings that minds can do, and as we progress towards this goal, we tend to\nincreasingly delegate human tasks to machines. However, AI systems usually do\nthese tasks with an unusual imbalance of insight and understanding: new, deeper\ninsights are present, yet many important qualities that a human mind would have\npreviously brought to the activity are utterly absent. Therefore, it is crucial\nto ask which features of minds have we replicated, which are missing, and if\nthat matters. One core feature that humans bring to tasks, when dealing with\nthe ambiguity, emergent knowledge, and social context presented by the world,\nis reflection. Yet this capability is utterly missing from current mainstream\nAI. In this paper we ask what reflective AI might look like. Then, drawing on\nnotions of reflection in complex systems, cognitive science, and agents, we\nsketch an architecture for reflective AI agents, and highlight ways forward.",
    "published": "2023-01-25T20:50:26Z",
    "pdf_url": "http://arxiv.org/pdf/2301.10823v3",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2308.02435v1",
    "title": "Designing Fiduciary Artificial Intelligence",
    "authors": [
      "Sebastian Benthall",
      "David Shekman"
    ],
    "abstract": "A fiduciary is a trusted agent that has the legal duty to act with loyalty\nand care towards a principal that employs them. When fiduciary organizations\ninteract with users through a digital interface, or otherwise automate their\noperations with artificial intelligence, they will need to design these AI\nsystems to be compliant with their duties. This article synthesizes recent work\nin computer science and law to develop a procedure for designing and auditing\nFiduciary AI. The designer of a Fiduciary AI should understand the context of\nthe system, identify its principals, and assess the best interests of those\nprincipals. Then the designer must be loyal with respect to those interests,\nand careful in an contextually appropriate way. We connect the steps in this\nprocedure to dimensions of Trustworthy AI, such as privacy and alignment.\nFiduciary AI is a promising means to address the incompleteness of data\nsubject's consent when interacting with complex technical systems.",
    "published": "2023-07-27T15:35:32Z",
    "pdf_url": "http://arxiv.org/pdf/2308.02435v1",
    "categories": [
      "cs.CY",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2504.15125v3",
    "title": "Contemplative Artificial Intelligence",
    "authors": [
      "Ruben Laukkonen",
      "Fionn Inglis",
      "Shamil Chandaria",
      "Lars Sandved-Smith",
      "Edmundo Lopez-Sola",
      "Jakob Hohwy",
      "Jonathan Gold",
      "Adam Elwood"
    ],
    "abstract": "As artificial intelligence (AI) improves, traditional alignment strategies\nmay falter in the face of unpredictable self-improvement, hidden subgoals, and\nthe sheer complexity of intelligent systems. Inspired by contemplative wisdom\ntraditions, we show how four axiomatic principles can instil a resilient Wise\nWorld Model in AI systems. First, mindfulness enables self-monitoring and\nrecalibration of emergent subgoals. Second, emptiness forestalls dogmatic goal\nfixation and relaxes rigid priors. Third, non-duality dissolves adversarial\nself-other boundaries. Fourth, boundless care motivates the universal reduction\nof suffering. We find that prompting AI to reflect on these principles improves\nperformance on the AILuminate Benchmark (d=.96) and boosts cooperation and\njoint-reward on the Prisoner's Dilemma task (d=7+). We offer detailed\nimplementation strategies at the level of architectures, constitutions, and\nreinforcement on chain-of-thought. For future systems, active inference may\noffer the self-organizing and dynamic coupling capabilities needed to enact\nContemplative AI in embodied agents.",
    "published": "2025-04-21T14:20:49Z",
    "pdf_url": "http://arxiv.org/pdf/2504.15125v3",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1701.03868v1",
    "title": "Minimally Naturalistic Artificial Intelligence",
    "authors": [
      "Steven Stenberg Hansen"
    ],
    "abstract": "The rapid advancement of machine learning techniques has re-energized\nresearch into general artificial intelligence. While the idea of\ndomain-agnostic meta-learning is appealing, this emerging field must come to\nterms with its relationship to human cognition and the statistics and structure\nof the tasks humans perform. The position of this article is that only by\naligning our agents' abilities and environments with those of humans do we\nstand a chance at developing general artificial intelligence (GAI). A broad\nreading of the famous 'No Free Lunch' theorem is that there is no universally\noptimal inductive bias or, equivalently, bias-free learning is impossible. This\nfollows from the fact that there are an infinite number of ways to extrapolate\ndata, any of which might be the one used by the data generating environment; an\ninductive bias prefers some of these extrapolations to others, which lowers\nperformance in environments using these adversarial extrapolations. We may\nposit that the optimal GAI is the one that maximally exploits the statistics of\nits environment to create its inductive bias; accepting the fact that this\nagent is guaranteed to be extremely sub-optimal for some alternative\nenvironments. This trade-off appears benign when thinking about the environment\nas being the physical universe, as performance on any fictive universe is\nobviously irrelevant. But, we should expect a sharper inductive bias if we\nfurther constrain our environment. Indeed, we implicitly do so by defining GAI\nin terms of accomplishing that humans consider useful. One common version of\nthis is need the for 'common-sense reasoning', which implicitly appeals to the\nstatistics of physical universe as perceived by humans.",
    "published": "2017-01-14T01:57:31Z",
    "pdf_url": "http://arxiv.org/pdf/1701.03868v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2202.07446v1",
    "title": "Relational Artificial Intelligence",
    "authors": [
      "Virginia Dignum"
    ],
    "abstract": "The impact of Artificial Intelligence does not depend only on fundamental\nresearch and technological developments, but for a large part on how these\nsystems are introduced into society and used in everyday situations. Even\nthough AI is traditionally associated with rational decision making,\nunderstanding and shaping the societal impact of AI in all its facets requires\na relational perspective. A rational approach to AI, where computational\nalgorithms drive decision making independent of human intervention, insights\nand emotions, has shown to result in bias and exclusion, laying bare societal\nvulnerabilities and insecurities. A relational approach, that focus on the\nrelational nature of things, is needed to deal with the ethical, legal,\nsocietal, cultural, and environmental implications of AI. A relational approach\nto AI recognises that objective and rational reasoning cannot does not always\nresult in the 'right' way to proceed because what is 'right' depends on the\ndynamics of the situation in which the decision is taken, and that rather than\nsolving ethical problems the focus of design and use of AI must be on asking\nthe ethical question. In this position paper, I start with a general discussion\nof current conceptualisations of AI followed by an overview of existing\napproaches to governance and responsible development and use of AI. Then, I\nreflect over what should be the bases of a social paradigm for AI and how this\nshould be embedded in relational, feminist and non-Western philosophies, in\nparticular the Ubuntu philosophy.",
    "published": "2022-02-04T15:29:57Z",
    "pdf_url": "http://arxiv.org/pdf/2202.07446v1",
    "categories": [
      "cs.CY",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1411.1373v9",
    "title": "Ethical Artificial Intelligence",
    "authors": [
      "Bill Hibbard"
    ],
    "abstract": "This book-length article combines several peer reviewed papers and new\nmaterial to analyze the issues of ethical artificial intelligence (AI). The\nbehavior of future AI systems can be described by mathematical equations, which\nare adapted to analyze possible unintended AI behaviors and ways that AI\ndesigns can avoid them. This article makes the case for utility-maximizing\nagents and for avoiding infinite sets in agent definitions. It shows how to\navoid agent self-delusion using model-based utility functions and how to avoid\nagents that corrupt their reward generators (sometimes called \"perverse\ninstantiation\") using utility functions that evaluate outcomes at one point in\ntime from the perspective of humans at a different point in time. It argues\nthat agents can avoid unintended instrumental actions (sometimes called \"basic\nAI drives\" or \"instrumental goals\") by accurately learning human values. This\narticle defines a self-modeling agent framework and shows how it can avoid\nproblems of resource limits, being predicted by other agents, and inconsistency\nbetween the agent's utility function and its definition (one version of this\nproblem is sometimes called \"motivated value selection\"). This article also\ndiscusses how future AI will differ from current AI, the politics of AI, and\nthe ultimate use of AI to help understand the nature of the universe and our\nplace in it.",
    "published": "2014-11-05T19:40:02Z",
    "pdf_url": "http://arxiv.org/pdf/1411.1373v9",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2203.03715v1",
    "title": "Needs and Artificial Intelligence",
    "authors": [
      "Soheil Human",
      "Ryan Watkins"
    ],
    "abstract": "Throughout their history, homo sapiens have used technologies to better\nsatisfy their needs. The relation between needs and technology is so\nfundamental that the US National Research Council defined the distinguishing\ncharacteristic of technology as its goal \"to make modifications in the world to\nmeet human needs\". Artificial intelligence (AI) is one of the most promising\nemerging technologies of our time. Similar to other technologies, AI is\nexpected \"to meet [human] needs\". In this article, we reflect on the\nrelationship between needs and AI, and call for the realisation of needs-aware\nAI systems. We argue that re-thinking needs for, through, and by AI can be a\nvery useful means towards the development of realistic approaches for\nSustainable, Human-centric, Accountable, Lawful, and Ethical (HALE) AI systems.\nWe discuss some of the most critical gaps, barriers, enablers, and drivers of\nco-creating future AI-based socio-technical systems in which [human] needs are\nwell considered and met. Finally, we provide an overview of potential threats\nand HALE considerations that should be carefully taken into account, and call\nfor joint, immediate, and interdisciplinary efforts and collaborations.",
    "published": "2022-02-18T15:16:22Z",
    "pdf_url": "http://arxiv.org/pdf/2203.03715v1",
    "categories": [
      "cs.CY",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2309.06029v1",
    "title": "Artificially Intelligent Opinion Polling",
    "authors": [
      "Roberto Cerina",
      "Raymond Duch"
    ],
    "abstract": "We seek to democratise public-opinion research by providing practitioners\nwith a general methodology to make representative inference from cheap,\nhigh-frequency, highly unrepresentative samples. We focus specifically on\nsamples which are readily available in moderate sizes. To this end, we provide\ntwo major contributions: 1) we introduce a general sample-selection process\nwhich we name online selection, and show it is a special-case of selection on\nthe dependent variable. We improve MrP for severely biased samples by\nintroducing a bias-correction term in the style of King and Zeng to the\nlogistic-regression framework. We show this bias-corrected model outperforms\ntraditional MrP under online selection, and achieves performance similar to\nrandom-sampling in a vast array of scenarios; 2) we present a protocol to use\nLarge Language Models (LLMs) to extract structured, survey-like data from\nsocial-media. We provide a prompt-style that can be easily adapted to a variety\nof survey designs. We show that LLMs agree with human raters with respect to\nthe demographic, socio-economic and political characteristics of these online\nusers. The end-to-end implementation takes unrepresentative, unsrtuctured\nsocial media data as inputs, and produces timely high-quality area-level\nestimates as outputs. This is Artificially Intelligent Opinion Polling. We show\nthat our AI polling estimates of the 2020 election are highly accurate, on-par\nwith estimates produced by state-level polling aggregators such as\nFiveThirtyEight, or from MrP models fit to extremely expensive high-quality\nsamples.",
    "published": "2023-09-12T08:03:02Z",
    "pdf_url": "http://arxiv.org/pdf/2309.06029v1",
    "categories": [
      "stat.ME"
    ]
  },
  {
    "arxiv_id": "2508.16658v1",
    "title": "Ethics of Artificial Intelligence",
    "authors": [
      "Vincent C. Müller"
    ],
    "abstract": "Artificial intelligence (AI) is a digital technology that will be of major\nimportance for the development of humanity in the near future. AI has raised\nfundamental questions about what we should do with such systems, what the\nsystems themselves should do, what risks they involve and how we can control\nthese. - After the background to the field (1), this article introduces the\nmain debates (2), first on ethical issues that arise with AI systems as\nobjects, i.e. tools made and used by humans; here, the main sections are\nprivacy (2.1), manipulation (2.2), opacity (2.3), bias (2.4), autonomy &\nresponsibility (2.6) and the singularity (2.7). Then we look at AI systems as\nsubjects, i.e. when ethics is for the AI systems themselves in machine ethics\n(2.8.) and artificial moral agency (2.9). Finally we look at future\ndevelopments and the concept of AI (3). For each section within these themes,\nwe provide a general explanation of the ethical issues, we outline existing\npositions and arguments, then we analyse how this plays out with current\ntechnologies and finally what policy consequences may be drawn.",
    "published": "2025-08-20T10:22:19Z",
    "pdf_url": "http://arxiv.org/pdf/2508.16658v1",
    "categories": [
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "1811.06526v3",
    "title": "Artificial Intelligence for Interstellar Travel",
    "authors": [
      "Andreas M. Hein",
      "Stephen Baxter"
    ],
    "abstract": "The large distances involved in interstellar travel require a high degree of\nspacecraft autonomy, realized by artificial intelligence. The breadth of tasks\nartificial intelligence could perform on such spacecraft involves maintenance,\ndata collection, designing and constructing an infrastructure using in-situ\nresources. Despite its importance, existing publications on artificial\nintelligence and interstellar travel are limited to cursory descriptions where\nlittle detail is given about the nature of the artificial intelligence. This\narticle explores the role of artificial intelligence for interstellar travel by\ncompiling use cases, exploring capabilities, and proposing typologies, system\nand mission architectures. Estimations for the required intelligence level for\nspecific types of interstellar probes are given, along with potential system\nand mission architectures, covering those proposed in the literature but also\npresenting novel ones. Finally, a generic design for interstellar probes with\nan AI payload is proposed. Given current levels of increase in computational\npower, a spacecraft with a similar computational power as the human brain would\nhave a mass from dozens to hundreds of tons in a 2050-2060 timeframe. Given\nthat the advent of the first interstellar missions and artificial general\nintelligence are estimated to be by the mid-21st century, a more in-depth\nexploration of the relationship between the two should be attempted, focusing\non neglected areas such as protecting the artificial intelligence payload from\nradiation in interstellar space and the role of artificial intelligence in\nself-replication.",
    "published": "2018-11-15T18:49:16Z",
    "pdf_url": "http://arxiv.org/pdf/1811.06526v3",
    "categories": [
      "physics.pop-ph",
      "physics.space-ph"
    ]
  },
  {
    "arxiv_id": "1610.07862v2",
    "title": "Intelligence in Artificial Intelligence",
    "authors": [
      "Shoumen Palit Austin Datta"
    ],
    "abstract": "The elusive quest for intelligence in artificial intelligence prompts us to\nconsider that instituting human-level intelligence in systems may be (still) in\nthe realm of utopia. In about a quarter century, we have witnessed the winter\nof AI (1990) being transformed and transported to the zenith of tabloid fodder\nabout AI (2015). The discussion at hand is about the elements that constitute\nthe canonical idea of intelligence. The delivery of intelligence as a\npay-per-use-service, popping out of an app or from a shrink-wrapped software\ndefined point solution, is in contrast to the bio-inspired view of intelligence\nas an outcome, perhaps formed from a tapestry of events, cross-pollinated by\ninstances, each with its own microcosm of experiences and learning, which may\nnot be discrete all-or-none functions but continuous, over space and time. The\nenterprise world may not require, aspire or desire such an engaged solution to\nimprove its services for enabling digital transformation through the deployment\nof digital twins, for example. One might ask whether the \"work-flow on\nsteroids\" version of decision support may suffice for intelligence? Are we\nharking back to the era of rule based expert systems? The image conjured by the\npublicity machines offers deep solutions with human-level AI and preposterous\nclaims about capturing the \"brain in a box\" by 2020. Even emulating insects may\nbe difficult in terms of real progress. Perhaps we can try to focus on worms\n(Caenorhabditis elegans) which may be better suited for what business needs to\nquench its thirst for so-called intelligence in AI.",
    "published": "2016-10-24T02:15:46Z",
    "pdf_url": "http://arxiv.org/pdf/1610.07862v2",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2012.06034v1",
    "title": "Artificial Intelligence & Cooperation",
    "authors": [
      "Elisa Bertino",
      "Finale Doshi-Velez",
      "Maria Gini",
      "Daniel Lopresti",
      "David Parkes"
    ],
    "abstract": "The rise of Artificial Intelligence (AI) will bring with it an\never-increasing willingness to cede decision-making to machines. But rather\nthan just giving machines the power to make decisions that affect us, we need\nways to work cooperatively with AI systems. There is a vital need for research\nin \"AI and Cooperation\" that seeks to understand the ways in which systems of\nAIs and systems of AIs with people can engender cooperative behavior. Trust in\nAI is also key: trust that is intrinsic and trust that can only be earned over\ntime. Here we use the term \"AI\" in its broadest sense, as employed by the\nrecent 20-Year Community Roadmap for AI Research (Gil and Selman, 2019),\nincluding but certainly not limited to, recent advances in deep learning.\n  With success, cooperation between humans and AIs can build society just as\nhuman-human cooperation has. Whether coming from an intrinsic willingness to be\nhelpful, or driven through self-interest, human societies have grown strong and\nthe human species has found success through cooperation. We cooperate \"in the\nsmall\" -- as family units, with neighbors, with co-workers, with strangers --\nand \"in the large\" as a global community that seeks cooperative outcomes around\nquestions of commerce, climate change, and disarmament. Cooperation has evolved\nin nature also, in cells and among animals. While many cases involving\ncooperation between humans and AIs will be asymmetric, with the human\nultimately in control, AI systems are growing so complex that, even today, it\nis impossible for the human to fully comprehend their reasoning,\nrecommendations, and actions when functioning simply as passive observers.",
    "published": "2020-12-10T23:54:31Z",
    "pdf_url": "http://arxiv.org/pdf/2012.06034v1",
    "categories": [
      "cs.CY",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2212.03412v1",
    "title": "Artificial Intelligence Security Competition (AISC)",
    "authors": [
      "Yinpeng Dong",
      "Peng Chen",
      "Senyou Deng",
      "Lianji L",
      "Yi Sun",
      "Hanyu Zhao",
      "Jiaxing Li",
      "Yunteng Tan",
      "Xinyu Liu",
      "Yangyi Dong",
      "Enhui Xu",
      "Jincai Xu",
      "Shu Xu",
      "Xuelin Fu",
      "Changfeng Sun",
      "Haoliang Han",
      "Xuchong Zhang",
      "Shen Chen",
      "Zhimin Sun",
      "Junyi Cao",
      "Taiping Yao",
      "Shouhong Ding",
      "Yu Wu",
      "Jian Lin",
      "Tianpeng Wu",
      "Ye Wang",
      "Yu Fu",
      "Lin Feng",
      "Kangkang Gao",
      "Zeyu Liu",
      "Yuanzhe Pang",
      "Chengqi Duan",
      "Huipeng Zhou",
      "Yajie Wang",
      "Yuhang Zhao",
      "Shangbo Wu",
      "Haoran Lyu",
      "Zhiyu Lin",
      "Yifei Gao",
      "Shuang Li",
      "Haonan Wang",
      "Jitao Sang",
      "Chen Ma",
      "Junhao Zheng",
      "Yijia Li",
      "Chao Shen",
      "Chenhao Lin",
      "Zhichao Cui",
      "Guoshuai Liu",
      "Huafeng Shi",
      "Kun Hu",
      "Mengxin Zhang"
    ],
    "abstract": "The security of artificial intelligence (AI) is an important research area\ntowards safe, reliable, and trustworthy AI systems. To accelerate the research\non AI security, the Artificial Intelligence Security Competition (AISC) was\norganized by the Zhongguancun Laboratory, China Industrial Control Systems\nCyber Emergency Response Team, Institute for Artificial Intelligence, Tsinghua\nUniversity, and RealAI as part of the Zhongguancun International Frontier\nTechnology Innovation Competition (https://www.zgc-aisc.com/en). The\ncompetition consists of three tracks, including Deepfake Security Competition,\nAutonomous Driving Security Competition, and Face Recognition Security\nCompetition. This report will introduce the competition rules of these three\ntracks and the solutions of top-ranking teams in each track.",
    "published": "2022-12-07T02:45:27Z",
    "pdf_url": "http://arxiv.org/pdf/2212.03412v1",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2304.02924v1",
    "title": "The Governance of Physical Artificial Intelligence",
    "authors": [
      "Yingbo Li",
      "Anamaria-Beatrice Spulber",
      "Yucong Duan"
    ],
    "abstract": "Physical artificial intelligence can prove to be one of the most important\nchallenges of the artificial intelligence. The governance of physical\nartificial intelligence would define its responsible intelligent application in\nthe society.",
    "published": "2023-04-06T08:26:38Z",
    "pdf_url": "http://arxiv.org/pdf/2304.02924v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1703.06597v1",
    "title": "Artificial Intelligence and Economic Theories",
    "authors": [
      "Tshilidzi Marwala",
      "Evan Hurwitz"
    ],
    "abstract": "The advent of artificial intelligence has changed many disciplines such as\nengineering, social science and economics. Artificial intelligence is a\ncomputational technique which is inspired by natural intelligence such as the\nswarming of birds, the working of the brain and the pathfinding of the ants.\nThese techniques have impact on economic theories. This book studies the impact\nof artificial intelligence on economic theories, a subject that has not been\nextensively studied. The theories that are considered are: demand and supply,\nasymmetrical information, pricing, rational choice, rational expectation, game\ntheory, efficient market hypotheses, mechanism design, prospect, bounded\nrationality, portfolio theory, rational counterfactual and causality. The\nbenefit of this book is that it evaluates existing theories of economics and\nupdate them based on the developments in artificial intelligence field.",
    "published": "2017-03-20T04:47:14Z",
    "pdf_url": "http://arxiv.org/pdf/1703.06597v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2203.08890v1",
    "title": "The Mathematics of Artificial Intelligence",
    "authors": [
      "Gitta Kutyniok"
    ],
    "abstract": "We currently witness the spectacular success of artificial intelligence in\nboth science and public life. However, the development of a rigorous\nmathematical foundation is still at an early stage. In this survey article,\nwhich is based on an invited lecture at the International Congress of\nMathematicians 2022, we will in particular focus on the current \"workhorse\" of\nartificial intelligence, namely deep neural networks. We will present the main\ntheoretical directions along with several exemplary results and discuss key\nopen problems.",
    "published": "2022-03-16T19:04:53Z",
    "pdf_url": "http://arxiv.org/pdf/2203.08890v1",
    "categories": [
      "cs.LG",
      "math.HO",
      "stat.ML",
      "Primary 68T07, Secondary 41A25, 42C15, 35C20, 65D18"
    ]
  },
  {
    "arxiv_id": "1704.08716v1",
    "title": "Artificial Intelligence Based Malware Analysis",
    "authors": [
      "Avi Pfeffer",
      "Brian Ruttenberg",
      "Lee Kellogg",
      "Michael Howard",
      "Catherine Call",
      "Alison O'Connor",
      "Glenn Takata",
      "Scott Neal Reilly",
      "Terry Patten",
      "Jason Taylor",
      "Robert Hall",
      "Arun Lakhotia",
      "Craig Miles",
      "Dan Scofield",
      "Jared Frank"
    ],
    "abstract": "Artificial intelligence methods have often been applied to perform specific\nfunctions or tasks in the cyber-defense realm. However, as adversary methods\nbecome more complex and difficult to divine, piecemeal efforts to understand\ncyber-attacks, and malware-based attacks in particular, are not providing\nsufficient means for malware analysts to understand the past, present and\nfuture characteristics of malware.\n  In this paper, we present the Malware Analysis and Attributed using Genetic\nInformation (MAAGI) system. The underlying idea behind the MAAGI system is that\nthere are strong similarities between malware behavior and biological organism\nbehavior, and applying biologically inspired methods to corpora of malware can\nhelp analysts better understand the ecosystem of malware attacks. Due to the\nsophistication of the malware and the analysis, the MAAGI system relies heavily\non artificial intelligence techniques to provide this capability. It has\nalready yielded promising results over its development life, and will hopefully\ninspire more integration between the artificial intelligence and cyber--defense\ncommunities.",
    "published": "2017-04-27T18:53:37Z",
    "pdf_url": "http://arxiv.org/pdf/1704.08716v1",
    "categories": [
      "cs.CR",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1901.05406v1",
    "title": "Artificial Intelligence for Social Good",
    "authors": [
      "Gregory D. Hager",
      "Ann Drobnis",
      "Fei Fang",
      "Rayid Ghani",
      "Amy Greenwald",
      "Terah Lyons",
      "David C. Parkes",
      "Jason Schultz",
      "Suchi Saria",
      "Stephen F. Smith",
      "Milind Tambe"
    ],
    "abstract": "The Computing Community Consortium (CCC), along with the White House Office\nof Science and Technology Policy (OSTP), and the Association for the\nAdvancement of Artificial Intelligence (AAAI), co-sponsored a public workshop\non Artificial Intelligence for Social Good on June 7th, 2016 in Washington, DC.\nThis was one of five workshops that OSTP co-sponsored and held around the\ncountry to spur public dialogue on artificial intelligence, machine learning,\nand to identify challenges and opportunities related to AI. In the AI for\nSocial Good workshop, the successful deployments and the potential use of AI in\nvarious topics that are essential for social good were discussed, including but\nnot limited to urban computing, health, environmental sustainability, and\npublic welfare. This report highlights each of these as well as a number of\ncrosscutting issues.",
    "published": "2019-01-16T17:42:43Z",
    "pdf_url": "http://arxiv.org/pdf/1901.05406v1",
    "categories": [
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "2309.00135v1",
    "title": "Construction Grammar and Artificial Intelligence",
    "authors": [
      "Katrien Beuls",
      "Paul Van Eecke"
    ],
    "abstract": "In this chapter, we argue that it is highly beneficial for the contemporary\nconstruction grammarian to have a thorough understanding of the strong\nrelationship between the research fields of construction grammar and artificial\nintelligence. We start by unravelling the historical links between the two\nfields, showing that their relationship is rooted in a common attitude towards\nhuman communication and language. We then discuss the first direction of\ninfluence, focussing in particular on how insights and techniques from the\nfield of artificial intelligence play an important role in operationalising,\nvalidating and scaling constructionist approaches to language. We then proceed\nto the second direction of influence, highlighting the relevance of\nconstruction grammar insights and analyses to the artificial intelligence\nendeavour of building truly intelligent agents. We support our case with a\nvariety of illustrative examples and conclude that the further elaboration of\nthis relationship will play a key role in shaping the future of the field of\nconstruction grammar.",
    "published": "2023-08-31T21:15:06Z",
    "pdf_url": "http://arxiv.org/pdf/2309.00135v1",
    "categories": [
      "cs.AI",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2412.00330v1",
    "title": "Ethics and Artificial Intelligence Adoption",
    "authors": [
      "Martim Veiga",
      "Carlos J. Costa"
    ],
    "abstract": "In recent years, we have witnessed a marked development and growth in\nArtificial Intelligence. The growth of the data volume generated by sensors and\nmachines, combined with the information flow resulting from the user actions on\nthe Internet, with high investments of the governments and the companies in\nthis area, provided the practice and developed the algorithms of the Artificial\nIntelligence However, the people, in general, started to feel a particular fear\nregarding the security and privacy of their data and the theme of the\nArtificial Intelligence Ethics began to be discussed more regularly. The\ninvestigation aim of this work is to understand the possibility of adopting\nArtificial Intelligence nowadays in our society, having, as a mandatory\nassumption, Ethics and respect towards data and people's privacy. With that\npurpose in mind, a model has been created, mainly supported by the theories\nthat were used to create the model. The suggested model has been tested and\nvalidated through Structural equation modeling based on data taken back from\nthe respondents' answers to the questionnaire online: 237 answers, mainly from\nthe Investigation Technologies area. The results obtained enabled the\nvalidation of seven of the nine investigation hypotheses of the proposed model.\nIt was impossible to confirm any association between the Social Influence\nconstruct and the variables of Behavioral Intention and the Use of Artificial\nIntelligence. The aim of this work was accomplished once the investigation\ntheme was validated and proved that it is possible to adopt Artificial\nIntelligence in our society, using the Attitude Towards Ethical Behavioral\nconstruct as the mainstay of the model.",
    "published": "2024-11-30T03:08:15Z",
    "pdf_url": "http://arxiv.org/pdf/2412.00330v1",
    "categories": [
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "1703.10098v1",
    "title": "Rational Choice and Artificial Intelligence",
    "authors": [
      "Tshilidzi Marwala"
    ],
    "abstract": "The theory of rational choice assumes that when people make decisions they do\nso in order to maximize their utility. In order to achieve this goal they ought\nto use all the information available and consider all the choices available to\nchoose an optimal choice. This paper investigates what happens when decisions\nare made by artificially intelligent machines in the market rather than human\nbeings. Firstly, the expectations of the future are more consistent if they are\nmade by an artificially intelligent machine and the decisions are more rational\nand thus marketplace becomes more rational.",
    "published": "2017-03-29T15:30:40Z",
    "pdf_url": "http://arxiv.org/pdf/1703.10098v1",
    "categories": [
      "cs.AI",
      "q-fin.GN"
    ]
  },
  {
    "arxiv_id": "2302.01570v1",
    "title": "Witgenstein's influence on artificial intelligence",
    "authors": [
      "Piero Molino",
      "Jacopo Tagliabue"
    ],
    "abstract": "We examine how much of the contemporary progress in artificial intelligence\n(and, specifically, in natural language processing), can be, more or less\ndirectly, traced back to the seminal work and ideas of the Austrian-British\nphilosopher Ludwig Wittgenstein, with particular focus on his late views.\nDiscussing Wittgenstein's original theses will give us the chance to survey the\nstate of artificial intelligence, and comment on both its strengths and\nweaknesses. A similar text appeared first in Spanish as a chapter of CENTENARIO\nDEL SILENCIO (2021), a book celebrating 100 years since the publication of the\nTractatus.",
    "published": "2023-02-03T06:47:20Z",
    "pdf_url": "http://arxiv.org/pdf/2302.01570v1",
    "categories": [
      "cs.AI",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "1801.05667v1",
    "title": "Innateness, AlphaZero, and Artificial Intelligence",
    "authors": [
      "Gary Marcus"
    ],
    "abstract": "The concept of innateness is rarely discussed in the context of artificial\nintelligence. When it is discussed, or hinted at, it is often the context of\ntrying to reduce the amount of innate machinery in a given system. In this\npaper, I consider as a test case a recent series of papers by Silver et al\n(Silver et al., 2017a) on AlphaGo and its successors that have been presented\nas an argument that a \"even in the most challenging of domains: it is possible\nto train to superhuman level, without human examples or guidance\", \"starting\ntabula rasa.\"\n  I argue that these claims are overstated, for multiple reasons. I close by\narguing that artificial intelligence needs greater attention to innateness, and\nI point to some proposals about what that innateness might look like.",
    "published": "2018-01-17T14:05:21Z",
    "pdf_url": "http://arxiv.org/pdf/1801.05667v1",
    "categories": [
      "cs.AI",
      "97R40",
      "I.2.0; I.2.6"
    ]
  },
  {
    "arxiv_id": "2406.18620v1",
    "title": "Documentation Practices of Artificial Intelligence",
    "authors": [
      "Stefan Arnold",
      "Dilara Yesilbas",
      "Rene Gröbner",
      "Dominik Riedelbauch",
      "Maik Horn",
      "Sven Weinzierl"
    ],
    "abstract": "Artificial Intelligence (AI) faces persistent challenges in terms of\ntransparency and accountability, which requires rigorous documentation. Through\na literature review on documentation practices, we provide an overview of\nprevailing trends, persistent issues, and the multifaceted interplay of factors\ninfluencing the documentation. Our examination of key characteristics such as\nscope, target audiences, support for multimodality, and level of automation,\nhighlights a dynamic evolution in documentation practices, underscored by a\nshift towards a more holistic, engaging, and automated documentation.",
    "published": "2024-06-26T08:33:52Z",
    "pdf_url": "http://arxiv.org/pdf/2406.18620v1",
    "categories": [
      "cs.DL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2101.04255v6",
    "title": "Quantum Mathematics in Artificial Intelligence",
    "authors": [
      "Dominic Widdows",
      "Kirsty Kitto",
      "Trevor Cohen"
    ],
    "abstract": "In the decade since 2010, successes in artificial intelligence have been at\nthe forefront of computer science and technology, and vector space models have\nsolidified a position at the forefront of artificial intelligence. At the same\ntime, quantum computers have become much more powerful, and announcements of\nmajor advances are frequently in the news.\n  The mathematical techniques underlying both these areas have more in common\nthan is sometimes realized. Vector spaces took a position at the axiomatic\nheart of quantum mechanics in the 1930s, and this adoption was a key motivation\nfor the derivation of logic and probability from the linear geometry of vector\nspaces. Quantum interactions between particles are modelled using the tensor\nproduct, which is also used to express objects and operations in artificial\nneural networks.\n  This paper describes some of these common mathematical areas, including\nexamples of how they are used in artificial intelligence (AI), particularly in\nautomated reasoning and natural language processing (NLP). Techniques discussed\ninclude vector spaces, scalar products, subspaces and implication, orthogonal\nprojection and negation, dual vectors, density matrices, positive operators,\nand tensor products. Application areas include information retrieval,\ncategorization and implication, modelling word-senses and disambiguation,\ninference in knowledge bases, and semantic composition.\n  Some of these approaches can potentially be implemented on quantum hardware.\nMany of the practical steps in this implementation are in early stages, and\nsome are already realized. Explaining some of the common mathematical tools can\nhelp researchers in both AI and quantum computing further exploit these\noverlaps, recognizing and exploring new directions along the way.",
    "published": "2021-01-12T01:35:56Z",
    "pdf_url": "http://arxiv.org/pdf/2101.04255v6",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ]
  },
  {
    "arxiv_id": "2209.11618v2",
    "title": "Artificial Intelligence and Advanced Materials",
    "authors": [
      "Cefe López"
    ],
    "abstract": "Artificial intelligence is gaining strength and materials science can both\ncontribute to and profit from it. In a simultaneous progress race, new\nmaterials, systems and processes can be devised and optimized thanks to machine\nlearning techniques and such progress can be turned into in-novative computing\nplatforms. Future materials scientists will profit from understanding how\nmachine learning can boost the conception of advanced materials. This review\ncovers aspects of computation from the fundamentals to directions taken and\nrepercussions produced by compu-tation to account for the origins, procedures\nand applications of artificial intelligence. Machine learning and its methods\nare reviewed to provide basic knowledge on its implementation and its\npotential. The materials and systems used to implement artificial intelligence\nwith electric charges are finding serious competition from other information\ncarrying and processing agents. The impact these techniques are having on the\ninception of new advanced materials is so deep that a new paradigm is\ndeveloping where implicit knowledge is being mined to conceive materi-als and\nsystems for functions instead of finding applications to found materials. How\nfar this trend can be carried is hard to fathom as exemplified by the power to\ndiscover unheard of mate-rials or physical laws buried in data.",
    "published": "2022-09-23T14:39:59Z",
    "pdf_url": "http://arxiv.org/pdf/2209.11618v2",
    "categories": [
      "cond-mat.mtrl-sci"
    ]
  },
  {
    "arxiv_id": "1509.01213v1",
    "title": "Impact of Artificial Intelligence on Economic Theory",
    "authors": [
      "Tshilidzi Marwala"
    ],
    "abstract": "Artificial intelligence has impacted many aspects of human life. This paper\nstudies the impact of artificial intelligence on economic theory. In particular\nwe study the impact of artificial intelligence on the theory of bounded\nrationality, efficient market hypothesis and prospect theory.",
    "published": "2015-07-01T16:26:21Z",
    "pdf_url": "http://arxiv.org/pdf/1509.01213v1",
    "categories": [
      "q-fin.GN"
    ]
  },
  {
    "arxiv_id": "1701.07769v1",
    "title": "Ethical Considerations in Artificial Intelligence Courses",
    "authors": [
      "Emanuelle Burton",
      "Judy Goldsmith",
      "Sven Koenig",
      "Benjamin Kuipers",
      "Nicholas Mattei",
      "Toby Walsh"
    ],
    "abstract": "The recent surge in interest in ethics in artificial intelligence may leave\nmany educators wondering how to address moral, ethical, and philosophical\nissues in their AI courses. As instructors we want to develop curriculum that\nnot only prepares students to be artificial intelligence practitioners, but\nalso to understand the moral, ethical, and philosophical impacts that\nartificial intelligence will have on society. In this article we provide\npractical case studies and links to resources for use by AI educators. We also\nprovide concrete suggestions on how to integrate AI ethics into a general\nartificial intelligence course and how to teach a stand-alone artificial\nintelligence ethics course.",
    "published": "2017-01-26T16:52:22Z",
    "pdf_url": "http://arxiv.org/pdf/1701.07769v1",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.GL",
      "K.3.2; K.4.1; K.7.m"
    ]
  },
  {
    "arxiv_id": "1210.1568v1",
    "title": "A Definition of Artificial Intelligence",
    "authors": [
      "Dimiter Dobrev"
    ],
    "abstract": "In this paper we offer a formal definition of Artificial Intelligence and\nthis directly gives us an algorithm for construction of this object. Really,\nthis algorithm is useless due to the combinatory explosion.\n  The main innovation in our definition is that it does not include the\nknowledge as a part of the intelligence. So according to our definition a newly\nborn baby also is an Intellect. Here we differs with Turing's definition which\nsuggests that an Intellect is a person with knowledge gained through the years.",
    "published": "2012-10-03T20:46:10Z",
    "pdf_url": "http://arxiv.org/pdf/1210.1568v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1608.08196v1",
    "title": "Smart Policies for Artificial Intelligence",
    "authors": [
      "Miles Brundage",
      "Joanna Bryson"
    ],
    "abstract": "We argue that there already exists de facto artificial intelligence policy -\na patchwork of policies impacting the field of AI's development in myriad ways.\nThe key question related to AI policy, then, is not whether AI should be\ngoverned at all, but how it is currently being governed, and how that\ngovernance might become more informed, integrated, effective, and anticipatory.\nWe describe the main components of de facto AI policy and make some\nrecommendations for how AI policy can be improved, drawing on lessons from\nother scientific and technological domains.",
    "published": "2016-08-29T19:50:30Z",
    "pdf_url": "http://arxiv.org/pdf/1608.08196v1",
    "categories": [
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "1803.06563v1",
    "title": "Viewpoint: Artificial Intelligence and Labour",
    "authors": [
      "Spyridon Samothrakis"
    ],
    "abstract": "The welfare of modern societies has been intrinsically linked to wage labour.\nWith some exceptions, the modern human has to sell her labour-power to be able\nreproduce biologically and socially. Thus, a lingering fear of technological\nunemployment features predominately as a theme among Artificial Intelligence\nresearchers. In this short paper we show that, if past trends are anything to\ngo by, this fear is irrational. On the contrary, we argue that the main problem\nhumanity will be facing is the normalisation of extremely long working hours.",
    "published": "2018-03-17T20:08:49Z",
    "pdf_url": "http://arxiv.org/pdf/1803.06563v1",
    "categories": [
      "cs.CY",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2107.03912v1",
    "title": "Artificial intelligence across company borders",
    "authors": [
      "Olga Fink",
      "Torbjørn Netland",
      "Stefan Feuerriegel"
    ],
    "abstract": "Artificial intelligence (AI) has become a valued technology in many\ncompanies. At the same time, a substantial potential for utilizing AI\n\\emph{across} company borders has remained largely untapped. An inhibiting\nfactor concerns disclosure of data to external parties, which raises legitimate\nconcerns about intellectual property rights, privacy issues, and cybersecurity\nrisks. Combining federated learning with domain adaptation can provide a\nsolution to this problem by enabling effective cross-company AI without data\ndisclosure. In this Viewpoint, we discuss the use, value, and implications of\nthis approach in a cross-company setting.",
    "published": "2021-06-21T11:56:41Z",
    "pdf_url": "http://arxiv.org/pdf/2107.03912v1",
    "categories": [
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "1707.08476v1",
    "title": "Guidelines for Artificial Intelligence Containment",
    "authors": [
      "James Babcock",
      "Janos Kramar",
      "Roman V. Yampolskiy"
    ],
    "abstract": "With almost daily improvements in capabilities of artificial intelligence it\nis more important than ever to develop safety software for use by the AI\nresearch community. Building on our previous work on AI Containment Problem we\npropose a number of guidelines which should help AI safety researchers to\ndevelop reliable sandboxing software for intelligent programs of all levels.\nSuch safety container software will make it possible to study and analyze\nintelligent artificial agent while maintaining certain level of safety against\ninformation leakage, social engineering attacks and cyberattacks from within\nthe container.",
    "published": "2017-07-24T18:33:18Z",
    "pdf_url": "http://arxiv.org/pdf/1707.08476v1",
    "categories": [
      "cs.AI",
      "cs.CR"
    ]
  },
  {
    "arxiv_id": "2202.05947v1",
    "title": "Artificial Intelligence and Auction Design",
    "authors": [
      "Martino Banchio",
      "Andrzej Skrzypacz"
    ],
    "abstract": "Motivated by online advertising auctions, we study auction design in repeated\nauctions played by simple Artificial Intelligence algorithms (Q-learning). We\nfind that first-price auctions with no additional feedback lead to\ntacit-collusive outcomes (bids lower than values), while second-price auctions\ndo not. We show that the difference is driven by the incentive in first-price\nauctions to outbid opponents by just one bid increment. This facilitates\nre-coordination on low bids after a phase of experimentation. We also show that\nproviding information about lowest bid to win, as introduced by Google at the\ntime of switch to first-price auctions, increases competitiveness of auctions.",
    "published": "2022-02-12T00:54:40Z",
    "pdf_url": "http://arxiv.org/pdf/2202.05947v1",
    "categories": [
      "econ.TH",
      "cs.AI",
      "cs.GT"
    ]
  },
  {
    "arxiv_id": "1802.07782v1",
    "title": "Artificial Intelligence and Legal Liability",
    "authors": [
      "John Kingston"
    ],
    "abstract": "A recent issue of a popular computing journal asked which laws would apply if\na self-driving car killed a pedestrian. This paper considers the question of\nlegal liability for artificially intelligent computer systems. It discusses\nwhether criminal liability could ever apply; to whom it might apply; and, under\ncivil law, whether an AI program is a product that is subject to product design\nlegislation or a service to which the tort of negligence applies. The issue of\nsales warranties is also considered. A discussion of some of the practical\nlimitations that AI systems are subject to is also included.",
    "published": "2018-02-21T20:11:28Z",
    "pdf_url": "http://arxiv.org/pdf/1802.07782v1",
    "categories": [
      "cs.AI",
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "1806.04915v1",
    "title": "The IQ of Artificial Intelligence",
    "authors": [
      "Dimiter Dobrev"
    ],
    "abstract": "All it takes to identify the computer programs which are Artificial\nIntelligence is to give them a test and award AI to those that pass the test.\nLet us say that the scores they earn at the test will be called IQ. We cannot\npinpoint a minimum IQ threshold that a program has to cover in order to be AI,\nhowever, we will choose a certain value. Thus, our definition for AI will be\nany program the IQ of which is above the chosen value. While this idea has\nalready been implemented in [3], here we will revisit this construct in order\nto introduce certain improvements.",
    "published": "2018-06-13T09:29:42Z",
    "pdf_url": "http://arxiv.org/pdf/1806.04915v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2407.17048v3",
    "title": "Artificial intelligence and financial crises",
    "authors": [
      "Jon Danielsson",
      "Andreas Uthemann"
    ],
    "abstract": "The rapid adoption of artificial intelligence (AI) poses new and poorly\nunderstood threats to financial stability. We use a game-theoretic model to\nanalyse the stability impact of AI, finding that it amplifies existing\nfinancial system vulnerabilities - leverage, liquidity stress and opacity -\nthrough superior information processing, common data, speed and strategic\ncomplementarities. The consequence is crises become faster and more severe,\nwhere the likelihood of a crisis is directly affected by how effectively the\nauthorities engage with AI. In response, we propose that the financial\nauthorities develop their own AI systems and expertise, establish direct\nAI-to-AI communication, implement automated crisis facilities and monitor AI\nuse.",
    "published": "2024-07-24T07:15:21Z",
    "pdf_url": "http://arxiv.org/pdf/2407.17048v3",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ]
  },
  {
    "arxiv_id": "1904.08796v1",
    "title": "Artificial Intelligence for Pediatric Ophthalmology",
    "authors": [
      "Julia E. Reid",
      "Eric Eaton"
    ],
    "abstract": "PURPOSE OF REVIEW: Despite the impressive results of recent artificial\nintelligence (AI) applications to general ophthalmology, comparatively less\nprogress has been made toward solving problems in pediatric ophthalmology using\nsimilar techniques. This article discusses the unique needs of pediatric\nophthalmology patients and how AI techniques can address these challenges,\nsurveys recent applications of AI to pediatric ophthalmology, and discusses\nfuture directions in the field.\n  RECENT FINDINGS: The most significant advances involve the automated\ndetection of retinopathy of prematurity (ROP), yielding results that rival\nexperts. Machine learning (ML) has also been successfully applied to the\nclassification of pediatric cataracts, prediction of post-operative\ncomplications following cataract surgery, detection of strabismus and\nrefractive error, prediction of future high myopia, and diagnosis of reading\ndisability via eye tracking. In addition, ML techniques have been used for the\nstudy of visual development, vessel segmentation in pediatric fundus images,\nand ophthalmic image synthesis.\n  SUMMARY: AI applications could significantly benefit clinical care for\npediatric ophthalmology patients by optimizing disease detection and grading,\nbroadening access to care, furthering scientific discovery, and improving\nclinical efficiency. These methods need to match or surpass physician\nperformance in clinical trials before deployment with patients. Due to\nwidespread use of closed-access data sets and software implementations, it is\ndifficult to directly compare the performance of these approaches, and\nreproducibility is poor. Open-access data sets and software implementations\ncould alleviate these issues, and encourage further AI applications to\npediatric ophthalmology.\n  KEYWORDS: pediatric ophthalmology, machine learning, artificial intelligence,\ndeep learning",
    "published": "2019-04-06T01:47:47Z",
    "pdf_url": "http://arxiv.org/pdf/1904.08796v1",
    "categories": [
      "physics.med-ph",
      "cs.CV",
      "cs.LG",
      "eess.IV"
    ]
  },
  {
    "arxiv_id": "1907.04659v3",
    "title": "Artificial Intelligence: A Child's Play",
    "authors": [
      "Ravi Kashyap"
    ],
    "abstract": "We discuss the objectives of any endeavor in creating artificial\nintelligence, AI, and provide a possible alternative. Intelligence might be an\nunintended consequence of curiosity left to roam free, best exemplified by a\nfrolicking infant. This suggests that our attempts at AI could have been\nmisguided. What we actually need to strive for can be termed artificial\ncuriosity, AC, and intelligence happens as a consequence of those efforts. For\nthis unintentional yet welcome aftereffect to set in a foundational list of\nguiding principles needs to be present. We start with the intuition for this\nline of reasoning and formalize it with a series of definitions, assumptions,\ningredients, models and iterative improvements that will be necessary to make\nthe incubation of intelligence a reality. Our discussion provides conceptual\nmodifications to the Turing Test and to Searle's Chinese room argument. We\ndiscuss the future implications for society as AI becomes an integral part of\nlife.\n  We provide a road-map for creating intelligence with the technical parts\nrelegated to the appendix so that the article is accessible to a wide audience.\nThe central techniques in our formal approach to creating intelligence draw\nupon tools and concepts widely used in physics, cognitive science, psychology,\nevolutionary biology, statistics, linguistics, communication systems, pattern\nrecognition, marketing, economics, finance, information science and\ncomputational theory highlighting that solutions for creating artificial\nintelligence have to transcend the artificial barriers between various fields\nand be highly multi-disciplinary.",
    "published": "2019-07-01T04:46:07Z",
    "pdf_url": "http://arxiv.org/pdf/1907.04659v3",
    "categories": [
      "cs.AI",
      "68Q32 Computational learning theory, 68T05 Learning & adaptive\n  systems, 97R40 Artificial intelligence, 91E10 Cognitive psychology, 60J60\n  Diffusion processes",
      "I.2.0; I.2.6; I.2.8; F.4.3; G.3"
    ]
  },
  {
    "arxiv_id": "2011.04105v1",
    "title": "Evolution of Artificial Intelligent Plane",
    "authors": [
      "Puneet Kumar"
    ],
    "abstract": "With the growth of the internet, it is becoming hard to manage, configure and\nmonitor networks. Recent trends to control and operate them is artificial\nintelligence based automation to minimize human intervention. Albeit this\nconcept has been introduced since a decade with several different names, but\nthe underlying goal remains the same, which is to make network intelligent\nenough to assemble, reassemble if configuration changes, and detect a problem\non its own and fix it. As a result, in addition to Data Plane, Control Plane\nand Management Plane, a new plane called Artificial Intelligence (AI) Plane is\nintroduced. Our main objective is to analyze all major AI plane techniques,\nframeworks and algorithms proposed in various types of networks. We propose a\ncomprehensive and network independent framework to cover all aspects of AI\nplane, in particular we provide a systematically means of comparison. In\nconjunction to make AI plane understand simpler, this framework highlights\nrelevant challenges and design considerations for future research. To the best\nof our knowledge this is the first survey report which represents a complete\ncomparison of AI planes with their investigation issues in several types of\nnetworks.",
    "published": "2020-11-08T23:33:12Z",
    "pdf_url": "http://arxiv.org/pdf/2011.04105v1",
    "categories": [
      "cs.AI",
      "cs.NI"
    ]
  },
  {
    "arxiv_id": "2211.13069v1",
    "title": "Cultural Incongruencies in Artificial Intelligence",
    "authors": [
      "Vinodkumar Prabhakaran",
      "Rida Qadri",
      "Ben Hutchinson"
    ],
    "abstract": "Artificial intelligence (AI) systems attempt to imitate human behavior. How\nwell they do this imitation is often used to assess their utility and to\nattribute human-like (or artificial) intelligence to them. However, most work\non AI refers to and relies on human intelligence without accounting for the\nfact that human behavior is inherently shaped by the cultural contexts they are\nembedded in, the values and beliefs they hold, and the social practices they\nfollow. Additionally, since AI technologies are mostly conceived and developed\nin just a handful of countries, they embed the cultural values and practices of\nthese countries. Similarly, the data that is used to train the models also\nfails to equitably represent global cultural diversity. Problems therefore\narise when these technologies interact with globally diverse societies and\ncultures, with different values and interpretive practices. In this position\npaper, we describe a set of cultural dependencies and incongruencies in the\ncontext of AI-based language and vision technologies, and reflect on the\npossibilities of and potential strategies towards addressing these\nincongruencies.",
    "published": "2022-11-19T18:45:02Z",
    "pdf_url": "http://arxiv.org/pdf/2211.13069v1",
    "categories": [
      "cs.CY",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2405.19522v1",
    "title": "Artificial Intelligence Index Report 2024",
    "authors": [
      "Nestor Maslej",
      "Loredana Fattorini",
      "Raymond Perrault",
      "Vanessa Parli",
      "Anka Reuel",
      "Erik Brynjolfsson",
      "John Etchemendy",
      "Katrina Ligett",
      "Terah Lyons",
      "James Manyika",
      "Juan Carlos Niebles",
      "Yoav Shoham",
      "Russell Wald",
      "Jack Clark"
    ],
    "abstract": "The 2024 Index is our most comprehensive to date and arrives at an important\nmoment when AI's influence on society has never been more pronounced. This\nyear, we have broadened our scope to more extensively cover essential trends\nsuch as technical advancements in AI, public perceptions of the technology, and\nthe geopolitical dynamics surrounding its development. Featuring more original\ndata than ever before, this edition introduces new estimates on AI training\ncosts, detailed analyses of the responsible AI landscape, and an entirely new\nchapter dedicated to AI's impact on science and medicine. The AI Index report\ntracks, collates, distills, and visualizes data related to artificial\nintelligence (AI). Our mission is to provide unbiased, rigorously vetted,\nbroadly sourced data in order for policymakers, researchers, executives,\njournalists, and the general public to develop a more thorough and nuanced\nunderstanding of the complex field of AI. The AI Index is recognized globally\nas one of the most credible and authoritative sources for data and insights on\nartificial intelligence. Previous editions have been cited in major newspapers,\nincluding the The New York Times, Bloomberg, and The Guardian, have amassed\nhundreds of academic citations, and been referenced by high-level policymakers\nin the United States, the United Kingdom, and the European Union, among other\nplaces. This year's edition surpasses all previous ones in size, scale, and\nscope, reflecting the growing significance that AI is coming to hold in all of\nour lives.",
    "published": "2024-05-29T20:59:57Z",
    "pdf_url": "http://arxiv.org/pdf/2405.19522v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1304.3429v1",
    "title": "Probability Judgement in Artificial Intelligence",
    "authors": [
      "Glenn Shafer"
    ],
    "abstract": "This paper is concerned with two theories of probability judgment: the\nBayesian theory and the theory of belief functions. It illustrates these\ntheories with some simple examples and discusses some of the issues that arise\nwhen we try to implement them in expert systems. The Bayesian theory is well\nknown; its main ideas go back to the work of Thomas Bayes (1702-1761). The\ntheory of belief functions, often called the Dempster-Shafer theory in the\nartificial intelligence community, is less well known, but it has even older\nantecedents; belief-function arguments appear in the work of George Hooper\n(16401723) and James Bernoulli (1654-1705). For elementary expositions of the\ntheory of belief functions, see Shafer (1976, 1985).",
    "published": "2013-03-27T19:56:37Z",
    "pdf_url": "http://arxiv.org/pdf/1304.3429v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1812.02953v1",
    "title": "Building Ethics into Artificial Intelligence",
    "authors": [
      "Han Yu",
      "Zhiqi Shen",
      "Chunyan Miao",
      "Cyril Leung",
      "Victor R. Lesser",
      "Qiang Yang"
    ],
    "abstract": "As artificial intelligence (AI) systems become increasingly ubiquitous, the\ntopic of AI governance for ethical decision-making by AI has captured public\nimagination. Within the AI research community, this topic remains less familiar\nto many researchers. In this paper, we complement existing surveys, which\nlargely focused on the psychological, social and legal discussions of the\ntopic, with an analysis of recent advances in technical solutions for AI\ngovernance. By reviewing publications in leading AI conferences including AAAI,\nAAMAS, ECAI and IJCAI, we propose a taxonomy which divides the field into four\nareas: 1) exploring ethical dilemmas; 2) individual ethical decision\nframeworks; 3) collective ethical decision frameworks; and 4) ethics in\nhuman-AI interactions. We highlight the intuitions and key techniques used in\neach approach, and discuss promising future research directions towards\nsuccessful integration of ethical AI systems into human societies.",
    "published": "2018-12-07T09:18:01Z",
    "pdf_url": "http://arxiv.org/pdf/1812.02953v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2101.02991v1",
    "title": "Artificial Intelligence enabled Smart Learning",
    "authors": [
      "Faisal Khan",
      "Debdeep Bose"
    ],
    "abstract": "Artificial Intelligence (AI) is a discipline of computer science that deals\nwith machine intelligence. It is essential to bring AI into the context of\nlearning because it helps in analysing the enormous amounts of data that is\ncollected from individual students, teachers and academic staff. The major\npriorities of implementing AI in education are making innovative use of\nexisting digital technologies for learning, and teaching practices that\nsignificantly improve traditional educational methods. The main problem with\ntraditional learning is that it cannot be suited to every student in class.\nSome students may grasp the concepts well, while some may have difficulties in\nunderstanding them and some may be more auditory or visual learners. The World\nBank report on education has indicated that the learning gap created by this\nproblem causes many students to drop out (World Development Report, 2018).\nPersonalised learning has been able to solve this grave problem.",
    "published": "2021-01-08T12:49:33Z",
    "pdf_url": "http://arxiv.org/pdf/2101.02991v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1504.05696v2",
    "title": "Ascribing Consciousness to Artificial Intelligence",
    "authors": [
      "Murray Shanahan"
    ],
    "abstract": "This paper critically assesses the anti-functionalist stance on consciousness\nadopted by certain advocates of integrated information theory (IIT), a\ncorollary of which is that human-level artificial intelligence implemented on\nconventional computing hardware is necessarily not conscious. The critique\ndraws on variations of a well-known gradual neuronal replacement thought\nexperiment, as well as bringing out tensions in IIT's treatment of\nself-knowledge. The aim, though, is neither to reject IIT outright nor to\nchampion functionalism in particular. Rather, it is suggested that both ideas\nhave something to offer a scientific understanding of consciousness, as long as\nthey are not dressed up as solutions to illusory metaphysical problems. As for\nhuman-level AI, we must await its development before we can decide whether or\nnot to ascribe consciousness to it.",
    "published": "2015-04-22T08:50:16Z",
    "pdf_url": "http://arxiv.org/pdf/1504.05696v2",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2206.00225v1",
    "title": "Can Artificial Intelligence Transform DevOps?",
    "authors": [
      "Mamdouh Alenezi",
      "Mohammad Zarour",
      "Mohammad Akour"
    ],
    "abstract": "DevOps and Artificial Intelligence (AI) are interconnected with each other.\nDevOps is a business-driven approach to providing quickly delivered quality\nsoftware, and AI is the technology that can be used in the system to enhance\nits functionality. So, DevOps teams can use AI to test, code, release, monitor,\nand improve the system. Through AI, the automation process delivered by DevOps\ncould be improved efficiently. This study aims to explore how AI can transform\nDevOps. The research is useful in terms of facilitating software developers and\nbusinesses to assess the importance of AI in DevOps. The study has practical\nimplications as it elaborates on how AI transforms DevOps and in what way it\ncan support businesses in their business.",
    "published": "2022-06-01T04:21:39Z",
    "pdf_url": "http://arxiv.org/pdf/2206.00225v1",
    "categories": [
      "cs.SE"
    ]
  },
  {
    "arxiv_id": "2303.12350v2",
    "title": "Artificial Intelligence and Dual Contract",
    "authors": [
      "Qian Qi"
    ],
    "abstract": "This paper explores the capacity of artificial intelligence (AI) algorithms\nto autonomously design incentive-compatible contracts in dual-principal-agent\nsettings, a relatively unexplored aspect of algorithmic mechanism design. We\ndevelop a dynamic model where two principals, each equipped with independent\nQ-learning algorithms, interact with a single agent. Our findings reveal that\nthe strategic behavior of AI principals (cooperation vs. competition) hinges\ncrucially on the alignment of their profits. Notably, greater profit alignment\nfosters collusive strategies, yielding higher principal profits at the expense\nof agent incentives. This emergent behavior persists across varying degrees of\nprincipal heterogeneity, multiple principals, and environments with\nuncertainty. Our study underscores the potential of AI for contract automation\nwhile raising critical concerns regarding strategic manipulation and the\nemergence of unintended collusion in AI-driven systems, particularly in the\ncontext of the broader AI alignment problem.",
    "published": "2023-03-22T07:31:44Z",
    "pdf_url": "http://arxiv.org/pdf/2303.12350v2",
    "categories": [
      "cs.AI",
      "cs.CY",
      "econ.GN",
      "q-fin.EC"
    ]
  },
  {
    "arxiv_id": "2308.07457v1",
    "title": "Artificial Intelligence for Smart Transportation",
    "authors": [
      "Michael Wilbur",
      "Amutheezan Sivagnanam",
      "Afiya Ayman",
      "Samitha Samaranayeke",
      "Abhishek Dubey",
      "Aron Laszka"
    ],
    "abstract": "There are more than 7,000 public transit agencies in the U.S. (and many more\nprivate agencies), and together, they are responsible for serving 60 billion\npassenger miles each year. A well-functioning transit system fosters the growth\nand expansion of businesses, distributes social and economic benefits, and\nlinks the capabilities of community members, thereby enhancing what they can\naccomplish as a society. Since affordable public transit services are the\nbackbones of many communities, this work investigates ways in which Artificial\nIntelligence (AI) can improve efficiency and increase utilization from the\nperspective of transit agencies. This book chapter discusses the primary\nrequirements, objectives, and challenges related to the design of AI-driven\nsmart transportation systems. We focus on three major topics. First, we discuss\ndata sources and data. Second, we provide an overview of how AI can aid\ndecision-making with a focus on transportation. Lastly, we discuss\ncomputational problems in the transportation domain and AI approaches to these\nproblems.",
    "published": "2023-08-14T21:01:00Z",
    "pdf_url": "http://arxiv.org/pdf/2308.07457v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2310.03715v1",
    "title": "Artificial Intelligence Index Report 2023",
    "authors": [
      "Nestor Maslej",
      "Loredana Fattorini",
      "Erik Brynjolfsson",
      "John Etchemendy",
      "Katrina Ligett",
      "Terah Lyons",
      "James Manyika",
      "Helen Ngo",
      "Juan Carlos Niebles",
      "Vanessa Parli",
      "Yoav Shoham",
      "Russell Wald",
      "Jack Clark",
      "Raymond Perrault"
    ],
    "abstract": "Welcome to the sixth edition of the AI Index Report. This year, the report\nintroduces more original data than any previous edition, including a new\nchapter on AI public opinion, a more thorough technical performance chapter,\noriginal analysis about large language and multimodal models, detailed trends\nin global AI legislation records, a study of the environmental impact of AI\nsystems, and more. The AI Index Report tracks, collates, distills, and\nvisualizes data related to artificial intelligence. Our mission is to provide\nunbiased, rigorously vetted, broadly sourced data in order for policymakers,\nresearchers, executives, journalists, and the general public to develop a more\nthorough and nuanced understanding of the complex field of AI. The report aims\nto be the world's most credible and authoritative source for data and insights\nabout AI.",
    "published": "2023-10-05T17:37:58Z",
    "pdf_url": "http://arxiv.org/pdf/2310.03715v1",
    "categories": [
      "cs.AI",
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "2411.09131v1",
    "title": "Artificial Intelligence for Quantum Computing",
    "authors": [
      "Yuri Alexeev",
      "Marwa H. Farag",
      "Taylor L. Patti",
      "Mark E. Wolf",
      "Natalia Ares",
      "Alán Aspuru-Guzik",
      "Simon C. Benjamin",
      "Zhenyu Cai",
      "Zohim Chandani",
      "Federico Fedele",
      "Nicholas Harrigan",
      "Jin-Sung Kim",
      "Elica Kyoseva",
      "Justin G. Lietz",
      "Tom Lubowe",
      "Alexander McCaskey",
      "Roger G. Melko",
      "Kouhei Nakaji",
      "Alberto Peruzzo",
      "Sam Stanwyck",
      "Norm M. Tubman",
      "Hanrui Wang",
      "Timothy Costa"
    ],
    "abstract": "Artificial intelligence (AI) advancements over the past few years have had an\nunprecedented and revolutionary impact across everyday application areas. Its\nsignificance also extends to technical challenges within science and\nengineering, including the nascent field of quantum computing (QC). The\ncounterintuitive nature and high-dimensional mathematics of QC make it a prime\ncandidate for AI's data-driven learning capabilities, and in fact, many of QC's\nbiggest scaling challenges may ultimately rest on developments in AI. However,\nbringing leading techniques from AI to QC requires drawing on disparate\nexpertise from arguably two of the most advanced and esoteric areas of computer\nscience. Here we aim to encourage this cross-pollination by reviewing how\nstate-of-the-art AI techniques are already advancing challenges across the\nhardware and software stack needed to develop useful QC - from device design to\napplications. We then close by examining its future opportunities and obstacles\nin this space.",
    "published": "2024-11-14T02:11:16Z",
    "pdf_url": "http://arxiv.org/pdf/2411.09131v1",
    "categories": [
      "quant-ph"
    ]
  },
  {
    "arxiv_id": "2411.13717v2",
    "title": "Hardware Accelerators for Artificial Intelligence",
    "authors": [
      "S M Mojahidul Ahsan",
      "Anurag Dhungel",
      "Mrittika Chowdhury",
      "Md Sakib Hasan",
      "Tamzidul Hoque"
    ],
    "abstract": "In this chapter, we aim to explore an in-depth exploration of the specialized\nhardware accelerators designed to enhance Artificial Intelligence (AI)\napplications, focusing on their necessity, development, and impact on the field\nof AI. It covers the transition from traditional computing systems to advanced\nAI-specific hardware, addressing the growing demands of AI algorithms and the\ninefficiencies of conventional architectures. The discussion extends to various\ntypes of accelerators, including GPUs, FPGAs, and ASICs, and their roles in\noptimizing AI workloads. Additionally, it touches on the challenges and\nconsiderations in designing and implementing these accelerators, along with\nfuture prospects in the evolution of AI hardware. This comprehensive overview\naims to equip readers with a clear understanding of the current landscape and\nfuture directions in AI hardware development, making it accessible to both\nexperts and newcomers to the field.",
    "published": "2024-11-20T21:33:21Z",
    "pdf_url": "http://arxiv.org/pdf/2411.13717v2",
    "categories": [
      "cs.AR",
      "cs.ET"
    ]
  },
  {
    "arxiv_id": "2501.10465v1",
    "title": "The Mathematics of Artificial Intelligence",
    "authors": [
      "Gabriel Peyré"
    ],
    "abstract": "This overview article highlights the critical role of mathematics in\nartificial intelligence (AI), emphasizing that mathematics provides tools to\nbetter understand and enhance AI systems. Conversely, AI raises new problems\nand drives the development of new mathematics at the intersection of various\nfields. This article focuses on the application of analytical and probabilistic\ntools to model neural network architectures and better understand their\noptimization. Statistical questions (particularly the generalization capacity\nof these networks) are intentionally set aside, though they are of crucial\nimportance. We also shed light on the evolution of ideas that have enabled\nsignificant advances in AI through architectures tailored to specific tasks,\neach echoing distinct mathematical techniques. The goal is to encourage more\nmathematicians to take an interest in and contribute to this exciting field.",
    "published": "2025-01-15T15:00:23Z",
    "pdf_url": "http://arxiv.org/pdf/2501.10465v1",
    "categories": [
      "math.OC",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2504.07139v2",
    "title": "Artificial Intelligence Index Report 2025",
    "authors": [
      "Nestor Maslej",
      "Loredana Fattorini",
      "Raymond Perrault",
      "Yolanda Gil",
      "Vanessa Parli",
      "Njenga Kariuki",
      "Emily Capstick",
      "Anka Reuel",
      "Erik Brynjolfsson",
      "John Etchemendy",
      "Katrina Ligett",
      "Terah Lyons",
      "James Manyika",
      "Juan Carlos Niebles",
      "Yoav Shoham",
      "Russell Wald",
      "Tobi Walsh",
      "Armin Hamrah",
      "Lapo Santarlasci",
      "Julia Betts Lotufo",
      "Alexandra Rome",
      "Andrew Shi",
      "Sukrut Oak"
    ],
    "abstract": "Welcome to the eighth edition of the AI Index report. The 2025 Index is our\nmost comprehensive to date and arrives at an important moment, as AI's\ninfluence across society, the economy, and global governance continues to\nintensify. New in this year's report are in-depth analyses of the evolving\nlandscape of AI hardware, novel estimates of inference costs, and new analyses\nof AI publication and patenting trends. We also introduce fresh data on\ncorporate adoption of responsible AI practices, along with expanded coverage of\nAI's growing role in science and medicine. Since its founding in 2017 as an\noffshoot of the One Hundred Year Study of Artificial Intelligence, the AI Index\nhas been committed to equipping policymakers, journalists, executives,\nresearchers, and the public with accurate, rigorously validated, and globally\nsourced data. Our mission has always been to help these stakeholders make\nbetter-informed decisions about the development and deployment of AI. In a\nworld where AI is discussed everywhere - from boardrooms to kitchen tables -\nthis mission has never been more essential. The AI Index continues to lead in\ntracking and interpreting the most critical trends shaping the field - from the\nshifting geopolitical landscape and the rapid evolution of underlying\ntechnologies, to AI's expanding role in business, policymaking, and public\nlife. Longitudinal tracking remains at the heart of our mission. In a domain\nadvancing at breakneck speed, the Index provides essential context - helping us\nunderstand where AI stands today, how it got here, and where it may be headed\nnext. Recognized globally as one of the most authoritative resources on\nartificial intelligence, the AI Index has been cited in major media outlets\nsuch as The New York Times, Bloomberg, and The Guardian; referenced in hundreds\nof academic papers; and used by policymakers and government agencies around the\nworld.",
    "published": "2025-04-08T02:01:37Z",
    "pdf_url": "http://arxiv.org/pdf/2504.07139v2",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2106.15306v1",
    "title": "Artificial Intelligence in Minimally Invasive Interventional Treatment",
    "authors": [
      "Daniel Ruijters"
    ],
    "abstract": "Minimally invasive image guided treatment procedures often employ advanced\nimage processing algorithms. The recent developments of artificial intelligence\nalgorithms harbor potential to further enhance this domain. In this article we\nexplore several application areas within the minimally invasive treatment space\nand discuss the deployment of artificial intelligence within these areas.",
    "published": "2021-06-08T14:57:25Z",
    "pdf_url": "http://arxiv.org/pdf/2106.15306v1",
    "categories": [
      "cs.CV",
      "cs.GR",
      "cs.LG",
      "eess.IV",
      "I.2.1; I.2.10; I.4.9"
    ]
  },
  {
    "arxiv_id": "2205.00322v2",
    "title": "Artificial Intelligence and Medicine: A literature review",
    "authors": [
      "Chottiwatt Jittprasong"
    ],
    "abstract": "In practically every industry today, artificial intelligence is one of the\nmost effective ways for machines to assist humans. Since its inception, a large\nnumber of researchers throughout the globe have been pioneering the application\nof artificial intelligence in medicine. Although artificial intelligence may\nseem to be a 21st-century concept, Alan Turing pioneered the first foundation\nconcept in the 1940s. Artificial intelligence in medicine has a huge variety of\napplications that researchers are continually exploring. The tremendous\nincrease in computer and human resources has hastened progress in the 21st\ncentury, and it will continue to do so for many years to come. This review of\nthe literature will highlight the emerging field of artificial intelligence in\nmedicine and its current level of development.",
    "published": "2022-04-30T18:39:00Z",
    "pdf_url": "http://arxiv.org/pdf/2205.00322v2",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "I.2"
    ]
  },
  {
    "arxiv_id": "1009.4964v1",
    "title": "Text Classification using Artificial Intelligence",
    "authors": [
      "S. M. Kamruzzaman"
    ],
    "abstract": "Text classification is the process of classifying documents into predefined\ncategories based on their content. It is the automated assignment of natural\nlanguage texts to predefined categories. Text classification is the primary\nrequirement of text retrieval systems, which retrieve texts in response to a\nuser query, and text understanding systems, which transform text in some way\nsuch as producing summaries, answering questions or extracting data. Existing\nsupervised learning algorithms for classifying text need sufficient documents\nto learn accurately. This paper presents a new algorithm for text\nclassification using artificial intelligence technique that requires fewer\ndocuments for training. Instead of using words, word relation i.e. association\nrules from these words is used to derive feature set from pre-classified text\ndocuments. The concept of na\\\"ive Bayes classifier is then used on derived\nfeatures and finally only a single concept of genetic algorithm has been added\nfor final classification. A system based on the proposed algorithm has been\nimplemented and tested. The experimental results show that the proposed system\nworks as a successful text classifier.",
    "published": "2010-09-25T01:08:27Z",
    "pdf_url": "http://arxiv.org/pdf/1009.4964v1",
    "categories": [
      "cs.IR"
    ]
  },
  {
    "arxiv_id": "2108.03793v1",
    "title": "Toward Human-Level Artificial Intelligence",
    "authors": [
      "Deokgun Park"
    ],
    "abstract": "In this paper, we present our research on programming human-level artificial\nintelligence (HLAI), including 1) a definition of HLAI, 2) an environment to\ndevelop and test HLAI, and 3) a cognitive architecture for HLAI. The term AI is\nused in a broad meaning, and HLAI is not clearly defined. I claim that the\nessence of Human-Level Intelligence to be the capability to learn from others'\nexperiences via language. The key is that the event described by language has\nthe same effect as if the agent experiences it firsthand for the update of the\nbehavior policy. To develop and test models with such a capability, we are\ndeveloping a simulated environment called SEDRo. There is a 3D Home, and a\nmother character takes care of the baby (the learning agent) and teaches\nlanguages. The environment provides comparable experiences to that of a human\nbaby from birth to one year. Finally, I propose a cognitive architecture of\nHLAI called Modulated Heterarchical Prediction Memory (mHPM). In mHPM, there\nare three components: a universal module that learns to predict the next vector\ngiven the sequence of vector signals, a heterarchical network of those modules,\nand a reward-based modulation of learning. mHPM models the workings of the\nneocortex but the innate auxiliary units such hippocampus, reward system,\ninstincts, and amygdala play critical roles, too.",
    "published": "2021-08-09T03:39:39Z",
    "pdf_url": "http://arxiv.org/pdf/2108.03793v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2202.09292v1",
    "title": "System Safety and Artificial Intelligence",
    "authors": [
      "Roel I. J. Dobbe"
    ],
    "abstract": "This chapter formulates seven lessons for preventing harm in artificial\nintelligence (AI) systems based on insights from the field of system safety for\nsoftware-based automation in safety-critical domains. New applications of AI\nacross societal domains and public organizations and infrastructures come with\nnew hazards, which lead to new forms of harm, both grave and pernicious. The\ntext addresses the lack of consensus for diagnosing and eliminating new AI\nsystem hazards. For decades, the field of system safety has dealt with\naccidents and harm in safety-critical systems governed by varying degrees of\nsoftware-based automation and decision-making. This field embraces the core\nassumption of systems and control that AI systems cannot be safeguarded by\ntechnical design choices on the model or algorithm alone, instead requiring an\nend-to-end hazard analysis and design frame that includes the context of use,\nimpacted stakeholders and the formal and informal institutional environment in\nwhich the system operates. Safety and other values are then inherently\nsocio-technical and emergent system properties that require design and control\nmeasures to instantiate these across the technical, social and institutional\ncomponents of a system. This chapter honors system safety pioneer Nancy\nLeveson, by situating her core lessons for today's AI system safety challenges.\nFor every lesson, concrete tools are offered for rethinking and reorganizing\nthe safety management of AI systems, both in design and governance. This\nhistory tells us that effective AI safety management requires transdisciplinary\napproaches and a shared language that allows involvement of all levels of\nsociety.",
    "published": "2022-02-18T16:37:54Z",
    "pdf_url": "http://arxiv.org/pdf/2202.09292v1",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "cs.SE",
      "cs.SY"
    ]
  },
  {
    "arxiv_id": "2011.10672v3",
    "title": "Artificial Intelligence Governance for Businesses",
    "authors": [
      "Johannes Schneider",
      "Rene Abraham",
      "Christian Meske",
      "Jan vom Brocke"
    ],
    "abstract": "Artificial Intelligence (AI) governance regulates the exercise of authority\nand control over the management of AI. It aims at leveraging AI through\neffective use of data and minimization of AI-related cost and risk. While\ntopics such as AI governance and AI ethics are thoroughly discussed on a\ntheoretical, philosophical, societal and regulatory level, there is limited\nwork on AI governance targeted to companies and corporations. This work views\nAI products as systems, where key functionality is delivered by machine\nlearning (ML) models leveraging (training) data. We derive a conceptual\nframework by synthesizing literature on AI and related fields such as ML. Our\nframework decomposes AI governance into governance of data, (ML) models and\n(AI) systems along four dimensions. It relates to existing IT and data\ngovernance frameworks and practices. It can be adopted by practitioners and\nacademics alike. For practitioners the synthesis of mainly research papers, but\nalso practitioner publications and publications of regulatory bodies provides a\nvaluable starting point to implement AI governance, while for academics the\npaper highlights a number of areas of AI governance that deserve more\nattention.",
    "published": "2020-11-20T22:31:37Z",
    "pdf_url": "http://arxiv.org/pdf/2011.10672v3",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2012.05410v1",
    "title": "Artificial Intelligence at the Edge",
    "authors": [
      "Elisa Bertino",
      "Sujata Banerjee"
    ],
    "abstract": "The Internet of Things (IoT) and edge computing applications aim to support a\nvariety of societal needs, including the global pandemic situation that the\nentire world is currently experiencing and responses to natural disasters.\n  The need for real-time interactive applications such as immersive video\nconferencing, augmented/virtual reality, and autonomous vehicles, in education,\nhealthcare, disaster recovery and other domains, has never been higher. At the\nsame time, there have been recent technological breakthroughs in highly\nrelevant fields such as artificial intelligence (AI)/machine learning (ML),\nadvanced communication systems (5G and beyond), privacy-preserving\ncomputations, and hardware accelerators. 5G mobile communication networks\nincrease communication capacity, reduce transmission latency and error, and\nsave energy -- capabilities that are essential for new applications. The\nenvisioned future 6G technology will integrate many more technologies,\nincluding for example visible light communication, to support groundbreaking\napplications, such as holographic communications and high precision\nmanufacturing. Many of these applications require computations and analytics\nclose to application end-points: that is, at the edge of the network, rather\nthan in a centralized cloud. AI techniques applied at the edge have tremendous\npotential both to power new applications and to need more efficient operation\nof edge infrastructure. However, it is critical to understand where to deploy\nAI systems within complex ecosystems consisting of advanced applications and\nthe specific real-time requirements towards AI systems.",
    "published": "2020-12-10T02:08:47Z",
    "pdf_url": "http://arxiv.org/pdf/2012.05410v1",
    "categories": [
      "cs.CY",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2102.03406v2",
    "title": "Symbolic Behaviour in Artificial Intelligence",
    "authors": [
      "Adam Santoro",
      "Andrew Lampinen",
      "Kory Mathewson",
      "Timothy Lillicrap",
      "David Raposo"
    ],
    "abstract": "The ability to use symbols is the pinnacle of human intelligence, but has yet\nto be fully replicated in machines. Here we argue that the path towards\nsymbolically fluent artificial intelligence (AI) begins with a reinterpretation\nof what symbols are, how they come to exist, and how a system behaves when it\nuses them. We begin by offering an interpretation of symbols as entities whose\nmeaning is established by convention. But crucially, something is a symbol only\nfor those who demonstrably and actively participate in this convention. We then\noutline how this interpretation thematically unifies the behavioural traits\nhumans exhibit when they use symbols. This motivates our proposal that the\nfield place a greater emphasis on symbolic behaviour rather than particular\ncomputational mechanisms inspired by more restrictive interpretations of\nsymbols. Finally, we suggest that AI research explore social and cultural\nengagement as a tool to develop the cognitive machinery necessary for symbolic\nbehaviour to emerge. This approach will allow for AI to interpret something as\nsymbolic on its own rather than simply manipulate things that are only symbols\nto human onlookers, and thus will ultimately lead to AI with more human-like\nsymbolic fluency.",
    "published": "2021-02-05T20:07:14Z",
    "pdf_url": "http://arxiv.org/pdf/2102.03406v2",
    "categories": [
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2106.11022v1",
    "title": "Hard Choices in Artificial Intelligence",
    "authors": [
      "Roel Dobbe",
      "Thomas Krendl Gilbert",
      "Yonatan Mintz"
    ],
    "abstract": "As AI systems are integrated into high stakes social domains, researchers now\nexamine how to design and operate them in a safe and ethical manner. However,\nthe criteria for identifying and diagnosing safety risks in complex social\ncontexts remain unclear and contested. In this paper, we examine the vagueness\nin debates about the safety and ethical behavior of AI systems. We show how\nthis vagueness cannot be resolved through mathematical formalism alone, instead\nrequiring deliberation about the politics of development as well as the context\nof deployment. Drawing from a new sociotechnical lexicon, we redefine vagueness\nin terms of distinct design challenges at key stages in AI system development.\nThe resulting framework of Hard Choices in Artificial Intelligence (HCAI)\nempowers developers by 1) identifying points of overlap between design\ndecisions and major sociotechnical challenges; 2) motivating the creation of\nstakeholder feedback channels so that safety issues can be exhaustively\naddressed. As such, HCAI contributes to a timely debate about the status of AI\ndevelopment in democratic societies, arguing that deliberation should be the\ngoal of AI Safety, not just the procedure by which it is ensured.",
    "published": "2021-06-10T09:49:34Z",
    "pdf_url": "http://arxiv.org/pdf/2106.11022v1",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.SY",
      "eess.SY",
      "I.2; K.4"
    ]
  },
  {
    "arxiv_id": "2211.00065v1",
    "title": "Artificial Intelligence and Arms Control",
    "authors": [
      "Paul Scharre",
      "Megan Lamberth"
    ],
    "abstract": "Potential advancements in artificial intelligence (AI) could have profound\nimplications for how countries research and develop weapons systems, and how\nmilitaries deploy those systems on the battlefield. The idea of AI-enabled\nmilitary systems has motivated some activists to call for restrictions or bans\non some weapon systems, while others have argued that AI may be too diffuse to\ncontrol. This paper argues that while a ban on all military applications of AI\nis likely infeasible, there may be specific cases where arms control is\npossible. Throughout history, the international community has attempted to ban\nor regulate weapons or military systems for a variety of reasons. This paper\nanalyzes both successes and failures and offers several criteria that seem to\ninfluence why arms control works in some cases and not others. We argue that\nsuccess or failure depends on the desirability (i.e., a weapon's military value\nversus its perceived horribleness) and feasibility (i.e., sociopolitical\nfactors that influence its success) of arms control. Based on these criteria,\nand the historical record of past attempts at arms control, we analyze the\npotential for AI arms control in the future and offer recommendations for what\npolicymakers can do today.",
    "published": "2022-10-22T16:09:41Z",
    "pdf_url": "http://arxiv.org/pdf/2211.00065v1",
    "categories": [
      "cs.CY",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2403.08425v3",
    "title": "Specification Overfitting in Artificial Intelligence",
    "authors": [
      "Benjamin Roth",
      "Pedro Henrique Luz de Araujo",
      "Yuxi Xia",
      "Saskia Kaltenbrunner",
      "Christoph Korab"
    ],
    "abstract": "Machine learning (ML) and artificial intelligence (AI) approaches are often\ncriticized for their inherent bias and for their lack of control,\naccountability, and transparency. Consequently, regulatory bodies struggle with\ncontaining this technology's potential negative side effects. High-level\nrequirements such as fairness and robustness need to be formalized into\nconcrete specification metrics, imperfect proxies that capture isolated aspects\nof the underlying requirements. Given possible trade-offs between different\nmetrics and their vulnerability to over-optimization, integrating specification\nmetrics in system development processes is not trivial. This paper defines\nspecification overfitting, a scenario where systems focus excessively on\nspecified metrics to the detriment of high-level requirements and task\nperformance. We present an extensive literature survey to categorize how\nresearchers propose, measure, and optimize specification metrics in several AI\nfields (e.g., natural language processing, computer vision, reinforcement\nlearning). Using a keyword-based search on papers from major AI conferences and\njournals between 2018 and mid-2023, we identify and analyze 74 papers that\npropose or optimize specification metrics. We find that although most papers\nimplicitly address specification overfitting (e.g., by reporting more than one\nspecification metric), they rarely discuss which role specification metrics\nshould play in system development or explicitly define the scope and\nassumptions behind metric formulations.",
    "published": "2024-03-13T11:20:34Z",
    "pdf_url": "http://arxiv.org/pdf/2403.08425v3",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2502.10434v1",
    "title": "Agency in Artificial Intelligence Systems",
    "authors": [
      "Parashar Das"
    ],
    "abstract": "There is a general concern that present developments in artificial\nintelligence (AI) research will lead to sentient AI systems, and these may pose\nan existential threat to humanity. But why cannot sentient AI systems benefit\nhumanity instead? This paper endeavours to put this question in a tractable\nmanner. I ask whether a putative AI system will develop an altruistic or a\nmalicious disposition towards our society, or what would be the nature of its\nagency? Given that AI systems are being developed into formidable problem\nsolvers, we can reasonably expect these systems to preferentially take on\nconscious aspects of human problem solving. I identify the relevant phenomenal\naspects of agency in human problem solving. The functional aspects of conscious\nagency can be monitored using tools provided by functionalist theories of\nconsciousness. A recent expert report (Butlin et al. 2023) has identified\nfunctionalist indicators of agency based on these theories. I show how to use\nthe Integrated Information Theory (IIT) of consciousness, to monitor the\nphenomenal nature of this agency. If we are able to monitor the agency of AI\nsystems as they develop, then we can dissuade them from becoming a menace to\nsociety while encouraging them to be an aid.",
    "published": "2025-02-09T02:21:14Z",
    "pdf_url": "http://arxiv.org/pdf/2502.10434v1",
    "categories": [
      "cs.AI",
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "1912.06485v3",
    "title": "Blockchain Intelligence: When Blockchain Meets Artificial Intelligence",
    "authors": [
      "Zibin Zheng",
      "Hong-Ning Dai",
      "Jiajing Wu"
    ],
    "abstract": "Blockchain is gaining extensive attention due to its provision of secure and\ndecentralized resource sharing manner. However, the incumbent blockchain\nsystems also suffer from a number of challenges in operational maintenance,\nquality assurance of smart contracts and malicious behaviour detection of\nblockchain data. The recent advances in artificial intelligence bring the\nopportunities in overcoming the above challenges. The integration of blockchain\nwith artificial intelligence can be beneficial to enhance current blockchain\nsystems. This article presents an introduction of the convergence of blockchain\nand artificial intelligence (namely blockchain intelligence). This article also\ngives a case study to further demonstrate the feasibility of blockchain\nintelligence and point out the future directions.",
    "published": "2019-12-11T02:56:45Z",
    "pdf_url": "http://arxiv.org/pdf/1912.06485v3",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.DC",
      "cs.SE"
    ]
  },
  {
    "arxiv_id": "2202.06869v3",
    "title": "CLAS12 Track Reconstruction with Artificial Intelligence",
    "authors": [
      "Gagik Gavalian",
      "Polykarpos Thomadakis",
      "Angelos Angelopoulos",
      "Nikos Chrisochoides",
      "Raffaella De Vita",
      "Veronique Ziegler"
    ],
    "abstract": "In this article we describe the implementation of Artificial Intelligence\nmodels in track reconstruction software for the CLAS12 detector at Jefferson\nLab. The Artificial Intelligence based approach resulted in improved track\nreconstruction efficiency in high luminosity experimental conditions. The track\nreconstruction efficiency increased by $10-12\\%$ for single particle, and\nstatistics in multi-particle physics reactions increased by $15\\%-35\\%$\ndepending on the number of particles in the reaction. The implementation of\nartificial intelligence in the workflow also resulted in a speedup of the\ntracking by $35\\%$.",
    "published": "2022-02-14T16:56:51Z",
    "pdf_url": "http://arxiv.org/pdf/2202.06869v3",
    "categories": [
      "physics.data-an",
      "nucl-ex"
    ]
  },
  {
    "arxiv_id": "1901.11184v1",
    "title": "Human-Centered Artificial Intelligence and Machine Learning",
    "authors": [
      "Mark O. Riedl"
    ],
    "abstract": "Humans are increasingly coming into contact with artificial intelligence and\nmachine learning systems. Human-centered artificial intelligence is a\nperspective on AI and ML that algorithms must be designed with awareness that\nthey are part of a larger system consisting of humans. We lay forth an argument\nthat human-centered artificial intelligence can be broken down into two\naspects: (1) AI systems that understand humans from a sociocultural\nperspective, and (2) AI systems that help humans understand them. We further\nargue that issues of social responsibility such as fairness, accountability,\ninterpretability, and transparency.",
    "published": "2019-01-31T02:47:16Z",
    "pdf_url": "http://arxiv.org/pdf/1901.11184v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2111.11295v1",
    "title": "Artificial Intelligence Technology analysis using Artificial\n  Intelligence patent through Deep Learning model and vector space model",
    "authors": [
      "Yongmin Yoo",
      "Dongjin Lim",
      "Kyungsun Kim"
    ],
    "abstract": "Thanks to rapid development of artificial intelligence technology in recent\nyears, the current artificial intelligence technology is contributing to many\npart of society. Education, environment, medical care, military, tourism,\neconomy, politics, etc. are having a very large impact on society as a whole.\nFor example, in the field of education, there is an artificial intelligence\ntutoring system that automatically assigns tutors based on student's level. In\nthe field of economics, there are quantitative investment methods that\nautomatically analyze large amounts of data to find investment laws to create\ninvestment models or predict changes in financial markets. As such, artificial\nintelligence technology is being used in various fields. So, it is very\nimportant to know exactly what factors have an important influence on each\nfield of artificial intelligence technology and how the relationship between\neach field is connected. Therefore, it is necessary to analyze artificial\nintelligence technology in each field. In this paper, we analyze patent\ndocuments related to artificial intelligence technology. We propose a method\nfor keyword analysis within factors using artificial intelligence patent data\nsets for artificial intelligence technology analysis. This is a model that\nrelies on feature engineering based on deep learning model named KeyBERT, and\nusing vector space model. A case study of collecting and analyzing artificial\nintelligence patent data was conducted to show how the proposed model can be\napplied to real world problems.",
    "published": "2021-11-08T00:10:49Z",
    "pdf_url": "http://arxiv.org/pdf/2111.11295v1",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "0412215v1",
    "title": "Quantization of Games: Towards Quantum Artificial Intelligence",
    "authors": [
      "Katarzyna Miakisz",
      "Edward W. Piotrowski",
      "Jan Sladkowski"
    ],
    "abstract": "On grounds of the discussed material, we reason about possible future\ndevelopment of quantum game theory and its impact on information processing and\nthe emerging information society. The idea of quantum artificial intelligence\nis explained.",
    "published": "2004-12-30T14:20:22Z",
    "pdf_url": "http://arxiv.org/pdf/quant-ph/0412215v1",
    "categories": [
      "quant-ph"
    ]
  },
  {
    "arxiv_id": "2101.09163v6",
    "title": "The Next Decade of Telecommunications Artificial Intelligence",
    "authors": [
      "Ye Ouyang",
      "Lilei Wang",
      "Aidong Yang",
      "Maulik Shah",
      "David Belanger",
      "Tongqing Gao",
      "Leping Wei",
      "Yaqin Zhang"
    ],
    "abstract": "It has been an exciting journey since the mobile communications and\nartificial intelligence were conceived 37 years and 64 years ago. While both\nfields evolved independently and profoundly changed communications and\ncomputing industries, the rapid convergence of 5G and deep learning is\nbeginning to significantly transform the core communication infrastructure,\nnetwork management and vertical applications. The paper first outlines the\nindividual roadmaps of mobile communications and artificial intelligence in the\nearly stage, with a concentration to review the era from 3G to 5G when AI and\nmobile communications started to converge. With regard to telecommunications\nartificial intelligence, the paper further introduces in detail the progress of\nartificial intelligence in the ecosystem of mobile communications. The paper\nthen summarizes the classifications of AI in telecom ecosystems along with its\nevolution paths specified by various international telecommunications\nstandardization bodies. Towards the next decade, the paper forecasts the\nprospective roadmap of telecommunications artificial intelligence. In line with\n3GPP and ITU-R timeline of 5G & 6G, the paper further explores the network\nintelligence following 3GPP and ORAN routes respectively, experience and\nintention driven network management and operation, network AI signalling\nsystem, intelligent middle-office based BSS, intelligent customer experience\nmanagement and policy control driven by BSS and OSS convergence, evolution from\nSLA to ELA, and intelligent private network for verticals. The paper is\nconcluded with the vision that AI will reshape the future B5G or 6G landscape\nand we need pivot our R&D, standardizations, and ecosystem to fully take the\nunprecedented opportunities.",
    "published": "2021-01-19T07:33:44Z",
    "pdf_url": "http://arxiv.org/pdf/2101.09163v6",
    "categories": [
      "cs.NI",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2305.08112v1",
    "title": "Quantum Operation of Affective Artificial Intelligence",
    "authors": [
      "V. I. Yukalov"
    ],
    "abstract": "The review analyzes the fundamental principles which Artificial Intelligence\nshould be based on in order to imitate the realistic process of taking\ndecisions by humans experiencing emotions. Two approaches are compared, one\nbased on quantum theory and the other employing classical terms. Both these\napproaches have a number of similarities, being principally probabilistic. The\nanalogies between quantum measurements under intrinsic noise and affective\ndecision making are elucidated. It is shown that cognitive processes have many\nfeatures that are formally similar to quantum measurements. This, however, in\nno way means that for the imitation of human decision making Affective\nArtificial Intelligence has necessarily to rely on the functioning of quantum\nsystems. Appreciating the common features between quantum measurements and\ndecision making helps for the formulation of an axiomatic approach employing\nonly classical notions. Artificial Intelligence, following this approach,\noperates similarly to humans, by taking into account the utility of the\nconsidered alternatives as well as their emotional attractiveness. Affective\nArtificial Intelligence, whose operation takes account of the cognition-emotion\nduality, avoids numerous behavioural paradoxes of traditional decision making.\nA society of intelligent agents, interacting through the repeated multistep\nexchange of information, forms a network accomplishing dynamic decision making.\nThe considered intelligent networks can characterize the operation of either a\nhuman society of affective decision makers, or the brain composed of neurons,\nor a typical probabilistic network of an artificial intelligence.",
    "published": "2023-05-14T09:40:13Z",
    "pdf_url": "http://arxiv.org/pdf/2305.08112v1",
    "categories": [
      "cs.AI",
      "q-bio.NC",
      "quant-ph"
    ]
  },
  {
    "arxiv_id": "0811.1711v1",
    "title": "Artificial Intelligence Techniques for Steam Generator Modelling",
    "authors": [
      "Sarah Wright",
      "Tshilidzi Marwala"
    ],
    "abstract": "This paper investigates the use of different Artificial Intelligence methods\nto predict the values of several continuous variables from a Steam Generator.\nThe objective was to determine how the different artificial intelligence\nmethods performed in making predictions on the given dataset. The artificial\nintelligence methods evaluated were Neural Networks, Support Vector Machines,\nand Adaptive Neuro-Fuzzy Inference Systems. The types of neural networks\ninvestigated were Multi-Layer Perceptions, and Radial Basis Function. Bayesian\nand committee techniques were applied to these neural networks. Each of the AI\nmethods considered was simulated in Matlab. The results of the simulations\nshowed that all the AI methods were capable of predicting the Steam Generator\ndata reasonably accurately. However, the Adaptive Neuro-Fuzzy Inference system\nout performed the other methods in terms of accuracy and ease of\nimplementation, while still achieving a fast execution time as well as a\nreasonable training time.",
    "published": "2008-11-11T14:09:36Z",
    "pdf_url": "http://arxiv.org/pdf/0811.1711v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1410.1054v1",
    "title": "Experimental Realization of Quantum Artificial Intelligence",
    "authors": [
      "Li Zhaokai",
      "Liu Xiaomei",
      "Xu Nanyang",
      "Du jiangfeng"
    ],
    "abstract": "Machines are possible to have some artificial intelligence like human beings\nowing to particular algorithms or software. Such machines could learn knowledge\nfrom what people taught them and do works according to the knowledge. In\npractical learning cases, the data is often extremely complicated and large,\nthus classical learning machines often need huge computational resources.\nQuantum machine learning algorithm, on the other hand, could be exponentially\nfaster than classical machines using quantum parallelism. Here, we demonstrate\na quantum machine learning algorithm on a four-qubit NMR test bench to solve an\noptical character recognition problem, also known as the handwriting\nrecognition. The quantum machine learns standard character fonts and then\nrecognize handwritten characters from a set with two candidates. To our best\nknowledge, this is the first artificial intelligence realized on a quantum\nprocessor. Due to the widespreading importance of artificial intelligence and\nits tremendous consuming of computational resources, quantum speedup would be\nextremely attractive against the challenges from the Big Data.",
    "published": "2014-10-04T15:55:56Z",
    "pdf_url": "http://arxiv.org/pdf/1410.1054v1",
    "categories": [
      "quant-ph"
    ]
  },
  {
    "arxiv_id": "2407.10305v1",
    "title": "Elements Of Legislation For Artificial Intelligence Systems",
    "authors": [
      "Anna Romanova"
    ],
    "abstract": "The significant part of the operational context for autonomous company\nmanagement systems is the regulatory and legal environment in which\ncorporations operate. In order to create a dedicated operational context for\nautonomous artificial intelligence systems, the wording of local regulatory\ndocuments can be simultaneously presented in two versions: for use by people\nand for use by autonomous systems. In this case, the artificial intelligence\nsystem will get a well-defined operational context that allows such a system to\nperform functions within the required standards. Local regulations that provide\nbasis for the joint work of individuals and autonomous artificial intelligence\nsystems can form the grounds for the relevant legislation governing the\ndevelopment and implementation of autonomous systems.",
    "published": "2024-05-05T11:01:31Z",
    "pdf_url": "http://arxiv.org/pdf/2407.10305v1",
    "categories": [
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "2404.15633v3",
    "title": "Artificial Intelligence for Multi-Unit Auction design",
    "authors": [
      "Peyman Khezr",
      "Kendall Taylor"
    ],
    "abstract": "Understanding bidding behavior in multi-unit auctions remains an ongoing\nchallenge for researchers. Despite their widespread use, theoretical insights\ninto the bidding behavior, revenue ranking, and efficiency of commonly used\nmulti-unit auctions are limited. This paper utilizes artificial intelligence,\nspecifically reinforcement learning, as a model free learning approach to\nsimulate bidding in three prominent multi-unit auctions employed in practice.\nWe introduce six algorithms that are suitable for learning and bidding in\nmulti-unit auctions and compare them using an illustrative example. This paper\nunderscores the significance of using artificial intelligence in auction\ndesign, particularly in enhancing the design of multi-unit auctions.",
    "published": "2024-04-24T03:51:26Z",
    "pdf_url": "http://arxiv.org/pdf/2404.15633v3",
    "categories": [
      "cs.GT",
      "cs.AI",
      "econ.TH"
    ]
  },
  {
    "arxiv_id": "1510.02867v3",
    "title": "Artificial Intelligence and Asymmetric Information Theory",
    "authors": [
      "Tshilidzi Marwala",
      "Evan Hurwitz"
    ],
    "abstract": "When human agents come together to make decisions, it is often the case that\none human agent has more information than the other. This phenomenon is called\ninformation asymmetry and this distorts the market. Often if one human agent\nintends to manipulate a decision in its favor the human agent can signal wrong\nor right information. Alternatively, one human agent can screen for information\nto reduce the impact of asymmetric information on decisions. With the advent of\nartificial intelligence, signaling and screening have been made easier. This\npaper studies the impact of artificial intelligence on the theory of asymmetric\ninformation. It is surmised that artificial intelligent agents reduce the\ndegree of information asymmetry and thus the market where these agents are\ndeployed become more efficient. It is also postulated that the more artificial\nintelligent agents there are deployed in the market the less is the volume of\ntrades in the market. This is because for many trades to happen the asymmetry\nof information on goods and services to be traded should exist, creating a\nsense of arbitrage.",
    "published": "2015-10-10T03:07:10Z",
    "pdf_url": "http://arxiv.org/pdf/1510.02867v3",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1710.08191v1",
    "title": "Human-in-the-loop Artificial Intelligence",
    "authors": [
      "Fabio Massimo Zanzotto"
    ],
    "abstract": "Little by little, newspapers are revealing the bright future that Artificial\nIntelligence (AI) is building. Intelligent machines will help everywhere.\nHowever, this bright future has a dark side: a dramatic job market contraction\nbefore its unpredictable transformation. Hence, in a near future, large numbers\nof job seekers will need financial support while catching up with these novel\nunpredictable jobs. This possible job market crisis has an antidote inside. In\nfact, the rise of AI is sustained by the biggest knowledge theft of the recent\nyears. Learning AI machines are extracting knowledge from unaware skilled or\nunskilled workers by analyzing their interactions. By passionately doing their\njobs, these workers are digging their own graves.\n  In this paper, we propose Human-in-the-loop Artificial Intelligence (HIT-AI)\nas a fairer paradigm for Artificial Intelligence systems. HIT-AI will reward\naware and unaware knowledge producers with a different scheme: decisions of AI\nsystems generating revenues will repay the legitimate owners of the knowledge\nused for taking those decisions. As modern Robin Hoods, HIT-AI researchers\nshould fight for a fairer Artificial Intelligence that gives back what it\nsteals.",
    "published": "2017-10-23T10:37:50Z",
    "pdf_url": "http://arxiv.org/pdf/1710.08191v1",
    "categories": [
      "cs.AI",
      "I.2; I.2.6"
    ]
  },
  {
    "arxiv_id": "1701.07103v1",
    "title": "Artificial Intelligence Approaches To UCAV Autonomy",
    "authors": [
      "Amir Husain",
      "Bruce Porter"
    ],
    "abstract": "This paper covers a number of approaches that leverage Artificial\nIntelligence algorithms and techniques to aid Unmanned Combat Aerial Vehicle\n(UCAV) autonomy. An analysis of current approaches to autonomous control is\nprovided followed by an exploration of how these techniques can be extended and\nenriched with AI techniques including Artificial Neural Networks (ANN),\nEnsembling and Reinforcement Learning (RL) to evolve control strategies for\nUCAVs.",
    "published": "2017-01-24T23:11:15Z",
    "pdf_url": "http://arxiv.org/pdf/1701.07103v1",
    "categories": [
      "cs.AI",
      "cs.RO"
    ]
  },
  {
    "arxiv_id": "2105.05330v2",
    "title": "Neuro-Symbolic Artificial Intelligence: Current Trends",
    "authors": [
      "Md Kamruzzaman Sarker",
      "Lu Zhou",
      "Aaron Eberhart",
      "Pascal Hitzler"
    ],
    "abstract": "Neuro-Symbolic Artificial Intelligence -- the combination of symbolic methods\nwith methods that are based on artificial neural networks -- has a\nlong-standing history. In this article, we provide a structured overview of\ncurrent trends, by means of categorizing recent publications from key\nconferences. The article is meant to serve as a convenient starting point for\nresearch on the general topic.",
    "published": "2021-05-11T20:11:57Z",
    "pdf_url": "http://arxiv.org/pdf/2105.05330v2",
    "categories": [
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2404.02611v3",
    "title": "X-SHIELD: Regularization for eXplainable Artificial Intelligence",
    "authors": [
      "Iván Sevillano-García",
      "Julián Luengo",
      "Francisco Herrera"
    ],
    "abstract": "As artificial intelligence systems become integral across domains, the demand\nfor explainability grows, the called eXplainable artificial intelligence (XAI).\nExisting efforts primarily focus on generating and evaluating explanations for\nblack-box models while a critical gap in directly enhancing models remains\nthrough these evaluations. It is important to consider the potential of this\nexplanation process to improve model quality with a feedback on training as\nwell. XAI may be used to improve model performance while boosting its\nexplainability. Under this view, this paper introduces Transformation -\nSelective Hidden Input Evaluation for Learning Dynamics (T-SHIELD), a\nregularization family designed to improve model quality by hiding features of\ninput, forcing the model to generalize without those features. Within this\nfamily, we propose the XAI - SHIELD(X-SHIELD), a regularization for explainable\nartificial intelligence, which uses explanations to select specific features to\nhide. In contrast to conventional approaches, X-SHIELD regularization\nseamlessly integrates into the objective function enhancing model\nexplainability while also improving performance. Experimental validation on\nbenchmark datasets underscores X-SHIELD's effectiveness in improving\nperformance and overall explainability. The improvement is validated through\nexperiments comparing models with and without the X-SHIELD regularization, with\nfurther analysis exploring the rationale behind its design choices. This\nestablishes X-SHIELD regularization as a promising pathway for developing\nreliable artificial intelligence regularization.",
    "published": "2024-04-03T09:56:38Z",
    "pdf_url": "http://arxiv.org/pdf/2404.02611v3",
    "categories": [
      "cs.AI",
      "I.2.6"
    ]
  },
  {
    "arxiv_id": "1602.07259v1",
    "title": "Philosophical Fictionalism and Problem of Artificial Intelligence",
    "authors": [
      "Sergey B. Kulikov"
    ],
    "abstract": "The artificial intelligence received broad interpretation as a literary\nimage. This approach did not have unambiguous refering to the scopes of logical\nstudies and mathematical investigations. An author applied methods peculiar to\nthe semiotic approach, offered by Boris Uspensky and Yury Lotman. In addition,\nthe article presented the criticism of modern versions of educational\ntechnologies, which led to the unconditional expectations for possibilities of\ninformation and telecommunication technologies. Methodological culture's\ngrowth, which was described on the base of semiotics and functional approach to\nword formation of new meanings for the description of the studied subjects,\nprovided the development of pupils' thought. As a result, the research opened\nnew prospects on understanding of artificial intelligence within educational\npractice.",
    "published": "2016-02-23T18:32:41Z",
    "pdf_url": "http://arxiv.org/pdf/1602.07259v1",
    "categories": [
      "cs.OH",
      "00A30"
    ]
  },
  {
    "arxiv_id": "1912.11945v1",
    "title": "On the Morality of Artificial Intelligence",
    "authors": [
      "Alexandra Luccioni",
      "Yoshua Bengio"
    ],
    "abstract": "Much of the existing research on the social and ethical impact of Artificial\nIntelligence has been focused on defining ethical principles and guidelines\nsurrounding Machine Learning (ML) and other Artificial Intelligence (AI)\nalgorithms [IEEE, 2017, Jobin et al., 2019]. While this is extremely useful for\nhelping define the appropriate social norms of AI, we believe that it is\nequally important to discuss both the potential and risks of ML and to inspire\nthe community to use ML for beneficial objectives. In the present article,\nwhich is specifically aimed at ML practitioners, we thus focus more on the\nlatter, carrying out an overview of existing high-level ethical frameworks and\nguidelines, but above all proposing both conceptual and practical principles\nand guidelines for ML research and deployment, insisting on concrete actions\nthat can be taken by practitioners to pursue a more ethical and moral practice\nof ML aimed at using AI for social good.",
    "published": "2019-12-26T23:06:54Z",
    "pdf_url": "http://arxiv.org/pdf/1912.11945v1",
    "categories": [
      "cs.CY",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2001.01818v1",
    "title": "Artificial Intelligence for Social Good: A Survey",
    "authors": [
      "Zheyuan Ryan Shi",
      "Claire Wang",
      "Fei Fang"
    ],
    "abstract": "Artificial intelligence for social good (AI4SG) is a research theme that aims\nto use and advance artificial intelligence to address societal issues and\nimprove the well-being of the world. AI4SG has received lots of attention from\nthe research community in the past decade with several successful applications.\nBuilding on the most comprehensive collection of the AI4SG literature to date\nwith over 1000 contributed papers, we provide a detailed account and analysis\nof the work under the theme in the following ways. (1) We quantitatively\nanalyze the distribution and trend of the AI4SG literature in terms of\napplication domains and AI techniques used. (2) We propose three conceptual\nmethods to systematically group the existing literature and analyze the eight\nAI4SG application domains in a unified framework. (3) We distill five research\ntopics that represent the common challenges in AI4SG across various application\ndomains. (4) We discuss five issues that, we hope, can shed light on the future\ndevelopment of the AI4SG research.",
    "published": "2020-01-07T00:16:28Z",
    "pdf_url": "http://arxiv.org/pdf/2001.01818v1",
    "categories": [
      "cs.CY",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2011.00111v2",
    "title": "Photonics for artificial intelligence and neuromorphic computing",
    "authors": [
      "Bhavin J. Shastri",
      "Alexander N. Tait",
      "Thomas Ferreira de Lima",
      "Wolfram H. P. Pernice",
      "Harish Bhaskaran",
      "C. David Wright",
      "Paul R. Prucnal"
    ],
    "abstract": "Research in photonic computing has flourished due to the proliferation of\noptoelectronic components on photonic integration platforms. Photonic\nintegrated circuits have enabled ultrafast artificial neural networks,\nproviding a framework for a new class of information processing machines.\nAlgorithms running on such hardware have the potential to address the growing\ndemand for machine learning and artificial intelligence, in areas such as\nmedical diagnosis, telecommunications, and high-performance and scientific\ncomputing. In parallel, the development of neuromorphic electronics has\nhighlighted challenges in that domain, in particular, related to processor\nlatency. Neuromorphic photonics offers sub-nanosecond latencies, providing a\ncomplementary opportunity to extend the domain of artificial intelligence.\nHere, we review recent advances in integrated photonic neuromorphic systems,\ndiscuss current and future challenges, and outline the advances in science and\ntechnology needed to meet those challenges.",
    "published": "2020-10-30T21:41:44Z",
    "pdf_url": "http://arxiv.org/pdf/2011.00111v2",
    "categories": [
      "physics.optics",
      "cs.NE",
      "physics.app-ph"
    ]
  },
  {
    "arxiv_id": "2003.00260v1",
    "title": "On Safety Assessment of Artificial Intelligence",
    "authors": [
      "Jens Braband",
      "Hendrik Schäbe"
    ],
    "abstract": "In this paper we discuss how systems with Artificial Intelligence (AI) can\nundergo safety assessment. This is relevant, if AI is used in safety related\napplications. Taking a deeper look into AI models, we show, that many models of\nartificial intelligence, in particular machine learning, are statistical\nmodels. Safety assessment would then have t o concentrate on the model that is\nused in AI, besides the normal assessment procedure. Part of the budget of\ndangerous random failures for the relevant safety integrity level needs to be\nused for the probabilistic faulty behavior of the AI system. We demonstrate our\nthoughts with a simple example and propose a research challenge that may be\ndecisive for the use of AI in safety related systems.",
    "published": "2020-02-29T14:05:28Z",
    "pdf_url": "http://arxiv.org/pdf/2003.00260v1",
    "categories": [
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2012.10232v1",
    "title": "Artificial Intelligence ordered 3D vertex importance",
    "authors": [
      "Iva Vasic",
      "Bata Vasic",
      "Zorica Nikolic"
    ],
    "abstract": "Ranking vertices of multidimensional networks is crucial in many areas of\nresearch, including selecting and determining the importance of decisions. Some\ndecisions are significantly more important than others, and their weight\ncategorization is also imortant. This paper defines a completely new method for\ndetermining the weight decisions using artificial intelligence for importance\nranking of three-dimensional network vertices, improving the existing Ordered\nStatistics Vertex Extraction and Tracking Algorithm (OSVETA) based on\nmodulation of quantized indices (QIM) and error correction codes. The technique\nwe propose in this paper offers significant improvements the efficiency of\ndetermination the importance of network vertices in relation to statistical\nOSVETA criteria, replacing heuristic methods with methods of precise prediction\nof modern neural networks. The new artificial intelligence technique enables a\nsignificantly better definition of the 3D meshes and a better assessment of\ntheir topological features. The new method contributions result in a greater\nprecision in defining stable vertices, significantly reducing the probability\nof deleting mesh vertices.",
    "published": "2020-12-17T06:54:59Z",
    "pdf_url": "http://arxiv.org/pdf/2012.10232v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2102.03061v1",
    "title": "Applications of Artificial Intelligence in Particle Radiotherapy",
    "authors": [
      "Chao Wu",
      "Dan Nguyen",
      "Jan Schuemann",
      "Andrea Mairani",
      "Yuehu Pu",
      "Steve Jiang"
    ],
    "abstract": "Radiotherapy, due to its technology-intensive nature and reliance on digital\ndata and human-machine interactions, is particularly suited to benefit from\nartificial intelligence (AI) to improve the accuracy and efficiency of its\nclinical workflow. Recently, various artificial intelligence (AI) methods have\nbeen successfully developed to exploit the benefit of the inherent physical\nproperties of particle therapy. Many reviews about AI applications in\nradiotherapy have already been published, but none were specifically dedicated\nto particle therapy. In this article, we present a comprehensive review of the\nrecent published works on AI applications in particle therapy, which can be\nclassified into particle therapy treatment planning, adaptive particle therapy,\nrange and dose verification and other applications in particle therapy.\nAlthough promising results reported in these works demonstrate how AI-based\nmethods can help exploit the intrinsic physic advantages of particle therapy,\nchallenges remained to be address before AI applications in particle therapy\nenjoy widespread implementation in clinical practice.",
    "published": "2021-02-05T08:54:38Z",
    "pdf_url": "http://arxiv.org/pdf/2102.03061v1",
    "categories": [
      "physics.med-ph"
    ]
  },
  {
    "arxiv_id": "2105.09484v1",
    "title": "Federated Artificial Intelligence for Unified Credit Assessment",
    "authors": [
      "Minh-Duc Hoang",
      "Linh Le",
      "Anh-Tuan Nguyen",
      "Trang Le",
      "Hoang D. Nguyen"
    ],
    "abstract": "With the rapid adoption of Internet technologies, digital footprints have\nbecome ubiquitous and versatile to revolutionise the financial industry in\ndigital transformation. This paper takes initiatives to investigate a new\nparadigm of the unified credit assessment with the use of federated artificial\nintelligence. We conceptualised digital human representation which consists of\nsocial, contextual, financial and technological dimensions to assess the\ncommercial creditworthiness and social reputation of both banked and unbanked\nindividuals. A federated artificial intelligence platform is proposed with a\ncomprehensive set of system design for efficient and effective credit scoring.\nThe study considerably contributes to the cumulative development of financial\nintelligence and social computing. It also provides a number of implications\nfor academic bodies, practitioners, and developers of financial technologies.",
    "published": "2021-05-20T03:05:42Z",
    "pdf_url": "http://arxiv.org/pdf/2105.09484v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2312.12936v1",
    "title": "Concept-based Explainable Artificial Intelligence: A Survey",
    "authors": [
      "Eleonora Poeta",
      "Gabriele Ciravegna",
      "Eliana Pastor",
      "Tania Cerquitelli",
      "Elena Baralis"
    ],
    "abstract": "The field of explainable artificial intelligence emerged in response to the\ngrowing need for more transparent and reliable models. However, using raw\nfeatures to provide explanations has been disputed in several works lately,\nadvocating for more user-understandable explanations. To address this issue, a\nwide range of papers proposing Concept-based eXplainable Artificial\nIntelligence (C-XAI) methods have arisen in recent years. Nevertheless, a\nunified categorization and precise field definition are still missing. This\npaper fills the gap by offering a thorough review of C-XAI approaches. We\ndefine and identify different concepts and explanation types. We provide a\ntaxonomy identifying nine categories and propose guidelines for selecting a\nsuitable category based on the development context. Additionally, we report\ncommon evaluation strategies including metrics, human evaluations and dataset\nemployed, aiming to assist the development of future methods. We believe this\nsurvey will serve researchers, practitioners, and domain experts in\ncomprehending and advancing this innovative field.",
    "published": "2023-12-20T11:27:21Z",
    "pdf_url": "http://arxiv.org/pdf/2312.12936v1",
    "categories": [
      "cs.AI",
      "cs.HC"
    ]
  },
  {
    "arxiv_id": "2401.06148v1",
    "title": "Artificial Intelligence for Digital and Computational Pathology",
    "authors": [
      "Andrew H. Song",
      "Guillaume Jaume",
      "Drew F. K. Williamson",
      "Ming Y. Lu",
      "Anurag Vaidya",
      "Tiffany R. Miller",
      "Faisal Mahmood"
    ],
    "abstract": "Advances in digitizing tissue slides and the fast-paced progress in\nartificial intelligence, including deep learning, have boosted the field of\ncomputational pathology. This field holds tremendous potential to automate\nclinical diagnosis, predict patient prognosis and response to therapy, and\ndiscover new morphological biomarkers from tissue images. Some of these\nartificial intelligence-based systems are now getting approved to assist\nclinical diagnosis; however, technical barriers remain for their widespread\nclinical adoption and integration as a research tool. This Review consolidates\nrecent methodological advances in computational pathology for predicting\nclinical end points in whole-slide images and highlights how these developments\nenable the automation of clinical practice and the discovery of new biomarkers.\nWe then provide future perspectives as the field expands into a broader range\nof clinical and research tasks with increasingly diverse modalities of clinical\ndata.",
    "published": "2023-12-13T00:22:52Z",
    "pdf_url": "http://arxiv.org/pdf/2401.06148v1",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "q-bio.QM"
    ]
  },
  {
    "arxiv_id": "2402.15011v2",
    "title": "A Conversational Brain-Artificial Intelligence Interface",
    "authors": [
      "Anja Meunier",
      "Michal Robert Žák",
      "Lucas Munz",
      "Sofiya Garkot",
      "Manuel Eder",
      "Jiachen Xu",
      "Moritz Grosse-Wentrup"
    ],
    "abstract": "We introduce Brain-Artificial Intelligence Interfaces (BAIs) as a new class\nof Brain-Computer Interfaces (BCIs). Unlike conventional BCIs, which rely on\nintact cognitive capabilities, BAIs leverage the power of artificial\nintelligence to replace parts of the neuro-cognitive processing pipeline. BAIs\nallow users to accomplish complex tasks by providing high-level intentions,\nwhile a pre-trained AI agent determines low-level details. This approach\nenlarges the target audience of BCIs to individuals with cognitive impairments,\na population often excluded from the benefits of conventional BCIs. We present\nthe general concept of BAIs and illustrate the potential of this new approach\nwith a Conversational BAI based on EEG. In particular, we show in an experiment\nwith simulated phone conversations that the Conversational BAI enables complex\ncommunication without the need to generate language. Our work thus\ndemonstrates, for the first time, the ability of a speech neuroprosthesis to\nenable fluent communication in realistic scenarios with non-invasive\ntechnologies.",
    "published": "2024-02-22T23:11:12Z",
    "pdf_url": "http://arxiv.org/pdf/2402.15011v2",
    "categories": [
      "cs.HC",
      "cs.AI",
      "eess.SP"
    ]
  },
  {
    "arxiv_id": "2408.14811v1",
    "title": "Brain-inspired Artificial Intelligence: A Comprehensive Review",
    "authors": [
      "Jing Ren",
      "Feng Xia"
    ],
    "abstract": "Current artificial intelligence (AI) models often focus on enhancing\nperformance through meticulous parameter tuning and optimization techniques.\nHowever, the fundamental design principles behind these models receive\ncomparatively less attention, which can limit our understanding of their\npotential and constraints. This comprehensive review explores the diverse\ndesign inspirations that have shaped modern AI models, i.e., brain-inspired\nartificial intelligence (BIAI). We present a classification framework that\ncategorizes BIAI approaches into physical structure-inspired and human\nbehavior-inspired models. We also examine the real-world applications where\ndifferent BIAI models excel, highlighting their practical benefits and\ndeployment challenges. By delving into these areas, we provide new insights and\npropose future research directions to drive innovation and address current gaps\nin the field. This review offers researchers and practitioners a comprehensive\noverview of the BIAI landscape, helping them harness its potential and expedite\nadvancements in AI development.",
    "published": "2024-08-27T06:49:50Z",
    "pdf_url": "http://arxiv.org/pdf/2408.14811v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1911.01156v2",
    "title": "AAAI FSS-19: Artificial Intelligence in Government and Public Sector\n  Proceedings",
    "authors": [
      "Frank Stein",
      "Alun Preece"
    ],
    "abstract": "Proceedings of the AAAI Fall Symposium on Artificial Intelligence in\nGovernment and Public Sector, Arlington, Virginia, USA, November 7-8, 2019",
    "published": "2019-11-04T12:26:51Z",
    "pdf_url": "http://arxiv.org/pdf/1911.01156v2",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2112.05614v1",
    "title": "AAAI FSS-21: Artificial Intelligence in Government and Public Sector\n  Proceedings",
    "authors": [
      "Mihai Boicu",
      "Erik Blasch",
      "Alun Preece"
    ],
    "abstract": "Proceedings of the AAAI Fall Symposium on Artificial Intelligence in\nGovernment and Public Sector, Washington, DC, USA, November 4-6, 2021",
    "published": "2021-12-10T15:48:31Z",
    "pdf_url": "http://arxiv.org/pdf/2112.05614v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "0705.3360v1",
    "title": "The Road to Quantum Artificial Intelligence",
    "authors": [
      "Kyriakos N. Sgarbas"
    ],
    "abstract": "This paper overviews the basic principles and recent advances in the emerging\nfield of Quantum Computation (QC), highlighting its potential application to\nArtificial Intelligence (AI). The paper provides a very brief introduction to\nbasic QC issues like quantum registers, quantum gates and quantum algorithms\nand then it presents references, ideas and research guidelines on how QC can be\nused to deal with some basic AI problems, such as search and pattern matching,\nas soon as quantum computers become widely available.",
    "published": "2007-05-23T12:31:47Z",
    "pdf_url": "http://arxiv.org/pdf/0705.3360v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1907.07771v1",
    "title": "Classification Schemas for Artificial Intelligence Failures",
    "authors": [
      "Peter J. Scott",
      "Roman V. Yampolskiy"
    ],
    "abstract": "In this paper we examine historical failures of artificial intelligence (AI)\nand propose a classification scheme for categorizing future failures. By doing\nso we hope that (a) the responses to future failures can be improved through\napplying a systematic classification that can be used to simplify the choice of\nresponse and (b) future failures can be reduced through augmenting development\nlifecycles with targeted risk assessments.",
    "published": "2019-07-15T16:05:44Z",
    "pdf_url": "http://arxiv.org/pdf/1907.07771v1",
    "categories": [
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "2305.12728v1",
    "title": "Diversity and Inclusion in Artificial Intelligence",
    "authors": [
      "Didar Zowghi",
      "Francesca da Rimini"
    ],
    "abstract": "To date, there has been little concrete practical advice about how to ensure\nthat diversity and inclusion considerations should be embedded within both\nspecific Artificial Intelligence (AI) systems and the larger global AI\necosystem. In this chapter, we present a clear definition of diversity and\ninclusion in AI, one which positions this concept within an evolving and\nholistic ecosystem. We use this definition and conceptual framing to present a\nset of practical guidelines primarily aimed at AI technologists, data\nscientists and project leaders.",
    "published": "2023-05-22T05:33:34Z",
    "pdf_url": "http://arxiv.org/pdf/2305.12728v1",
    "categories": [
      "cs.AI",
      "cs.SE"
    ]
  },
  {
    "arxiv_id": "1806.10518v2",
    "title": "Autonomous Wireless Systems with Artificial Intelligence",
    "authors": [
      "Haris Gacanin"
    ],
    "abstract": "This paper discusses technology and opportunities to embrace artificial\nintelligence (AI) in the design of autonomous wireless systems. We aim to\nprovide readers with motivation and general AI methodology of autonomous agents\nin the context of self-organization in real time by unifying knowledge\nmanagement with sensing, reasoning and active learning. We highlight\ndifferences between training-based methods for matching problems and\ntraining-free methods for environment-specific problems. Finally, we\nconceptually introduce the functions of an autonomous agent with knowledge\nmanagement.",
    "published": "2018-06-27T15:02:08Z",
    "pdf_url": "http://arxiv.org/pdf/1806.10518v2",
    "categories": [
      "cs.NI",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2111.02001v1",
    "title": "Certifiable Artificial Intelligence Through Data Fusion",
    "authors": [
      "Erik Blasch",
      "Junchi Bin",
      "Zheng Liu"
    ],
    "abstract": "This paper reviews and proposes concerns in adopting, fielding, and\nmaintaining artificial intelligence (AI) systems. While the AI community has\nmade rapid progress, there are challenges in certifying AI systems. Using\nprocedures from design and operational test and evaluation, there are\nopportunities towards determining performance bounds to manage expectations of\nintended use. A notional use case is presented with image data fusion to\nsupport AI object recognition certifiability considering precision versus\ndistance.",
    "published": "2021-11-03T03:34:19Z",
    "pdf_url": "http://arxiv.org/pdf/2111.02001v1",
    "categories": [
      "cs.AI",
      "eess.IV"
    ]
  },
  {
    "arxiv_id": "2111.09437v1",
    "title": "Sustainable Artificial Intelligence through Continual Learning",
    "authors": [
      "Andrea Cossu",
      "Marta Ziosi",
      "Vincenzo Lomonaco"
    ],
    "abstract": "The increasing attention on Artificial Intelligence (AI) regulation has led\nto the definition of a set of ethical principles grouped into the Sustainable\nAI framework. In this article, we identify Continual Learning, an active area\nof AI research, as a promising approach towards the design of systems compliant\nwith the Sustainable AI principles. While Sustainable AI outlines general\ndesiderata for ethical applications, Continual Learning provides means to put\nsuch desiderata into practice.",
    "published": "2021-11-17T22:43:13Z",
    "pdf_url": "http://arxiv.org/pdf/2111.09437v1",
    "categories": [
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2204.05579v1",
    "title": "Enriching Artificial Intelligence Explanations with Knowledge Fragments",
    "authors": [
      "Jože M. Rožanec",
      "Elena Trajkova",
      "Inna Novalija",
      "Patrik Zajec",
      "Klemen Kenda",
      "Blaž Fortuna",
      "Dunja Mladenić"
    ],
    "abstract": "Artificial Intelligence models are increasingly used in manufacturing to\ninform decision-making. Responsible decision-making requires accurate forecasts\nand an understanding of the models' behavior. Furthermore, the insights into\nmodels' rationale can be enriched with domain knowledge. This research builds\nexplanations considering feature rankings for a particular forecast, enriching\nthem with media news entries, datasets' metadata, and entries from the Google\nKnowledge Graph. We compare two approaches (embeddings-based and\nsemantic-based) on a real-world use case regarding demand forecasting.",
    "published": "2022-04-12T07:19:30Z",
    "pdf_url": "http://arxiv.org/pdf/2204.05579v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2307.13705v1",
    "title": "Control and Monitoring of Artificial Intelligence Algorithms",
    "authors": [
      "Carlos Mario Braga Ortuño",
      "Blanca Martinez Donoso",
      "Belén Muñiz Villanueva"
    ],
    "abstract": "This paper elucidates the importance of governing an artificial intelligence\nmodel post-deployment and overseeing potential fluctuations in the distribution\nof present data in contrast to the training data. The concepts of data drift\nand concept drift are explicated, along with their respective foundational\ndistributions. Furthermore, a range of metrics is introduced, which can be\nutilized to scrutinize the model's performance concerning potential temporal\nvariations.",
    "published": "2023-07-24T10:16:11Z",
    "pdf_url": "http://arxiv.org/pdf/2307.13705v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "62-01",
      "G.3"
    ]
  },
  {
    "arxiv_id": "2405.13462v1",
    "title": "Blockchain and Artificial Intelligence: Synergies and Conflicts",
    "authors": [
      "Leon Witt",
      "Armando Teles Fortes",
      "Kentaroh Toyoda",
      "Wojciech Samek",
      "Dan Li"
    ],
    "abstract": "Blockchain technology and Artificial Intelligence (AI) have emerged as\ntransformative forces in their respective domains. This paper explores\nsynergies and challenges between these two technologies. Our research analyses\nthe biggest projects combining blockchain and AI, based on market\ncapitalization, and derives a novel framework to categorize contemporary and\nfuture use cases. Despite the theoretical compatibility, current real-world\napplications combining blockchain and AI remain in their infancy.",
    "published": "2024-05-22T09:04:52Z",
    "pdf_url": "http://arxiv.org/pdf/2405.13462v1",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.DC"
    ]
  },
  {
    "arxiv_id": "2505.17882v1",
    "title": "Formalizing Embeddedness Failures in Universal Artificial Intelligence",
    "authors": [
      "Cole Wyeth",
      "Marcus Hutter"
    ],
    "abstract": "We rigorously discuss the commonly asserted failures of the AIXI\nreinforcement learning agent as a model of embedded agency. We attempt to\nformalize these failure modes and prove that they occur within the framework of\nuniversal artificial intelligence, focusing on a variant of AIXI that models\nthe joint action/percept history as drawn from the universal distribution. We\nalso evaluate the progress that has been made towards a successful theory of\nembedded agency based on variants of the AIXI agent.",
    "published": "2025-05-23T13:31:28Z",
    "pdf_url": "http://arxiv.org/pdf/2505.17882v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2506.14576v1",
    "title": "SoK: Privacy-Enhancing Technologies in Artificial Intelligence",
    "authors": [
      "Nouha Oualha"
    ],
    "abstract": "As artificial intelligence (AI) continues to permeate various sectors,\nsafeguarding personal and sensitive data has become increasingly crucial. To\naddress these concerns, privacy-enhancing technologies (PETs) have emerged as a\nsuite of digital tools that enable data collection and processing while\npreserving privacy. This paper explores the current landscape of data privacy\nin the context of AI, reviews the integration of PETs within AI systems, and\nassesses both their achievements and the challenges that remain.",
    "published": "2025-06-17T14:32:01Z",
    "pdf_url": "http://arxiv.org/pdf/2506.14576v1",
    "categories": [
      "cs.CR"
    ]
  },
  {
    "arxiv_id": "2507.17020v1",
    "title": "Ethics through the Facets of Artificial Intelligence",
    "authors": [
      "Flavio Soares Correa da Silva"
    ],
    "abstract": "Artificial Intelligence (AI) has received unprecedented attention in recent\nyears, raising ethical concerns about the development and use of AI technology.\nIn the present article, we advocate that these concerns stem from a blurred\nunderstanding of AI, how it can be used, and how it has been interpreted in\nsociety. We explore the concept of AI based on three descriptive facets and\nconsider ethical issues related to each facet. Finally, we propose a framework\nfor the ethical assessment of the use of AI.",
    "published": "2025-07-22T21:21:37Z",
    "pdf_url": "http://arxiv.org/pdf/2507.17020v1",
    "categories": [
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "1706.01040v1",
    "title": "Brain Intelligence: Go Beyond Artificial Intelligence",
    "authors": [
      "Huimin Lu",
      "Yujie Li",
      "Min Chen",
      "Hyoungseop Kim",
      "Seiichi Serikawa"
    ],
    "abstract": "Artificial intelligence (AI) is an important technology that supports daily\nsocial life and economic activities. It contributes greatly to the sustainable\ngrowth of Japan's economy and solves various social problems. In recent years,\nAI has attracted attention as a key for growth in developed countries such as\nEurope and the United States and developing countries such as China and India.\nThe attention has been focused mainly on developing new artificial intelligence\ninformation communication technology (ICT) and robot technology (RT). Although\nrecently developed AI technology certainly excels in extracting certain\npatterns, there are many limitations. Most ICT models are overly dependent on\nbig data, lack a self-idea function, and are complicated. In this paper, rather\nthan merely developing next-generation artificial intelligence technology, we\naim to develop a new concept of general-purpose intelligence cognition\ntechnology called Beyond AI. Specifically, we plan to develop an intelligent\nlearning model called Brain Intelligence (BI) that generates new ideas about\nevents without having experienced them by using artificial life with an imagine\nfunction. We will also conduct demonstrations of the developed BI intelligence\nlearning model on automatic driving, precision medical care, and industrial\nrobots.",
    "published": "2017-06-04T08:16:03Z",
    "pdf_url": "http://arxiv.org/pdf/1706.01040v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1709.01547v2",
    "title": "Knowledge Transfer Between Artificial Intelligence Systems",
    "authors": [
      "Ivan Y. Tyukin",
      "Alexander N. Gorban",
      "Konstantin Sofeikov",
      "Ilya Romanenko"
    ],
    "abstract": "We consider the fundamental question: how a legacy \"student\" Artificial\nIntelligent (AI) system could learn from a legacy \"teacher\" AI system or a\nhuman expert without complete re-training and, most importantly, without\nrequiring significant computational resources. Here \"learning\" is understood as\nan ability of one system to mimic responses of the other and vice-versa. We\ncall such learning an Artificial Intelligence knowledge transfer. We show that\nif internal variables of the \"student\" Artificial Intelligent system have the\nstructure of an $n$-dimensional topological vector space and $n$ is\nsufficiently high then, with probability close to one, the required knowledge\ntransfer can be implemented by simple cascades of linear functionals. In\nparticular, for $n$ sufficiently large, with probability close to one, the\n\"student\" system can successfully and non-iteratively learn $k\\ll n$ new\nexamples from the \"teacher\" (or correct the same number of mistakes) at the\ncost of two additional inner products. The concept is illustrated with an\nexample of knowledge transfer from a pre-trained convolutional neural network\nto a simple linear classifier with HOG features.",
    "published": "2017-09-05T18:38:07Z",
    "pdf_url": "http://arxiv.org/pdf/1709.01547v2",
    "categories": [
      "cs.AI",
      "68T05, 68T30"
    ]
  },
  {
    "arxiv_id": "2111.00992v1",
    "title": "Artificial Intelligence, Surveillance, and Big Data",
    "authors": [
      "David Karpa",
      "Torben Klarl",
      "Michael Rochlitz"
    ],
    "abstract": "The most important resource to improve technologies in the field of\nartificial intelligence is data. Two types of policies are crucial in this\nrespect: privacy and data-sharing regulations, and the use of surveillance\ntechnologies for policing. Both types of policies vary substantially across\ncountries and political regimes. In this chapter, we examine how authoritarian\nand democratic political institutions can influence the quality of research in\nartificial intelligence, and the availability of large-scale datasets to\nimprove and train deep learning algorithms. We focus mainly on the Chinese\ncase, and find that -- ceteris paribus -- authoritarian political institutions\ncontinue to have a negative effect on innovation. They can, however, have a\npositive effect on research in deep learning, via the availability of\nlarge-scale datasets that have been obtained through government surveillance.\nWe propose a research agenda to study which of the two effects might dominate\nin a race for leadership in artificial intelligence between countries with\ndifferent political institutions, such as the United States and China.",
    "published": "2021-11-01T14:57:13Z",
    "pdf_url": "http://arxiv.org/pdf/2111.00992v1",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ]
  },
  {
    "arxiv_id": "2404.03499v1",
    "title": "Comprehensible Artificial Intelligence on Knowledge Graphs: A survey",
    "authors": [
      "Simon Schramm",
      "Christoph Wehner",
      "Ute Schmid"
    ],
    "abstract": "Artificial Intelligence applications gradually move outside the safe walls of\nresearch labs and invade our daily lives. This is also true for Machine\nLearning methods on Knowledge Graphs, which has led to a steady increase in\ntheir application since the beginning of the 21st century. However, in many\napplications, users require an explanation of the Artificial Intelligences\ndecision. This led to increased demand for Comprehensible Artificial\nIntelligence. Knowledge Graphs epitomize fertile soil for Comprehensible\nArtificial Intelligence, due to their ability to display connected data, i.e.\nknowledge, in a human- as well as machine-readable way. This survey gives a\nshort history to Comprehensible Artificial Intelligence on Knowledge Graphs.\nFurthermore, we contribute by arguing that the concept Explainable Artificial\nIntelligence is overloaded and overlapping with Interpretable Machine Learning.\nBy introducing the parent concept Comprehensible Artificial Intelligence, we\nprovide a clear-cut distinction of both concepts while accounting for their\nsimilarities. Thus, we provide in this survey a case for Comprehensible\nArtificial Intelligence on Knowledge Graphs consisting of Interpretable Machine\nLearning on Knowledge Graphs and Explainable Artificial Intelligence on\nKnowledge Graphs. This leads to the introduction of a novel taxonomy for\nComprehensible Artificial Intelligence on Knowledge Graphs. In addition, a\ncomprehensive overview of the research on Comprehensible Artificial\nIntelligence on Knowledge Graphs is presented and put into the context of the\ntaxonomy. Finally, research gaps in the field of Comprehensible Artificial\nIntelligence on Knowledge Graphs are identified for future research.",
    "published": "2024-04-04T14:57:32Z",
    "pdf_url": "http://arxiv.org/pdf/2404.03499v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2108.04770v1",
    "title": "Examining correlation between trust and transparency with explainable\n  artificial intelligence",
    "authors": [
      "Arnav Kartikeya"
    ],
    "abstract": "Trust between humans and artificial intelligence(AI) is an issue which has\nimplications in many fields of human computer interaction. The current issue\nwith artificial intelligence is a lack of transparency into its decision\nmaking, and literature shows that increasing transparency increases trust.\nExplainable artificial intelligence has the ability to increase transparency of\nAI, which could potentially increase trust for humans. This paper attempts to\nuse the task of predicting yelp review star ratings with assistance from an\nexplainable and non explainable artificial intelligence to see if trust is\nincreased with increased transparency. Results show that for these tasks,\nexplainable artificial intelligence provided significant increase in trust as a\nmeasure of influence.",
    "published": "2021-08-10T16:24:30Z",
    "pdf_url": "http://arxiv.org/pdf/2108.04770v1",
    "categories": [
      "cs.HC"
    ]
  },
  {
    "arxiv_id": "2105.06564v2",
    "title": "Physical Artificial Intelligence: The Concept Expansion of\n  Next-Generation Artificial Intelligence",
    "authors": [
      "Yingbo Li",
      "Yucong Duan",
      "Anamaria-Beatrice Spulber",
      "Haoyang Che",
      "Zakaria Maamar",
      "Zhao Li",
      "Chen Yang",
      "Yu lei"
    ],
    "abstract": "Artificial Intelligence has been a growth catalyst to our society and is\ncosidered across all idustries as a fundamental technology. However, its\ndevelopment has been limited to the signal processing domain that relies on the\ngenerated and collected data from other sensors. In recent research, concepts\nof Digital Artificial Intelligence and Physicial Artifical Intelligence have\nemerged and this can be considered a big step in the theoretical development of\nArtifical Intelligence. In this paper we explore the concept of Physicial\nArtifical Intelligence and propose two subdomains: Integrated Physicial\nArtifical Intelligence and Distributed Physicial Artifical Intelligence. The\npaper will also examine the trend and governance of Physicial Artifical\nIntelligence.",
    "published": "2021-05-13T21:46:46Z",
    "pdf_url": "http://arxiv.org/pdf/2105.06564v2",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1705.00594v2",
    "title": "A System for Accessible Artificial Intelligence",
    "authors": [
      "Randal S. Olson",
      "Moshe Sipper",
      "William La Cava",
      "Sharon Tartarone",
      "Steven Vitale",
      "Weixuan Fu",
      "Patryk Orzechowski",
      "Ryan J. Urbanowicz",
      "John H. Holmes",
      "Jason H. Moore"
    ],
    "abstract": "While artificial intelligence (AI) has become widespread, many commercial AI\nsystems are not yet accessible to individual researchers nor the general public\ndue to the deep knowledge of the systems required to use them. We believe that\nAI has matured to the point where it should be an accessible technology for\neveryone. We present an ongoing project whose ultimate goal is to deliver an\nopen source, user-friendly AI system that is specialized for machine learning\nanalysis of complex data in the biomedical and health care domains. We discuss\nhow genetic programming can aid in this endeavor, and highlight specific\nexamples where genetic programming has automated machine learning analyses in\nprevious projects.",
    "published": "2017-05-01T17:11:48Z",
    "pdf_url": "http://arxiv.org/pdf/1705.00594v2",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "1811.08792v2",
    "title": "Artificial Intelligence-Defined 5G Radio Access Networks",
    "authors": [
      "Miao Yao",
      "Munawwar Sohul",
      "Vuk Marojevic",
      "Jeffrey H. Reed"
    ],
    "abstract": "Massive multiple-input multiple-output antenna systems, millimeter wave\ncommunications, and ultra-dense networks have been widely perceived as the\nthree key enablers that facilitate the development and deployment of 5G\nsystems. This article discusses the intelligent agent in 5G base station which\ncombines sensing, learning, understanding and optimizing to facilitate these\nenablers. We present a flexible, rapidly deployable, and cross-layer artificial\nintelligence (AI)-based framework to enable the imminent and future demands on\n5G and beyond infrastructure. We present example AI-enabled 5G use cases that\naccommodate important 5G-specific capabilities and discuss the value of AI for\nenabling beyond 5G network evolution.",
    "published": "2018-11-21T15:44:10Z",
    "pdf_url": "http://arxiv.org/pdf/1811.08792v2",
    "categories": [
      "eess.SP",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2006.00093v4",
    "title": "Explainable Artificial Intelligence: a Systematic Review",
    "authors": [
      "Giulia Vilone",
      "Luca Longo"
    ],
    "abstract": "Explainable Artificial Intelligence (XAI) has experienced a significant\ngrowth over the last few years. This is due to the widespread application of\nmachine learning, particularly deep learning, that has led to the development\nof highly accurate models but lack explainability and interpretability. A\nplethora of methods to tackle this problem have been proposed, developed and\ntested. This systematic review contributes to the body of knowledge by\nclustering these methods with a hierarchical classification system with four\nmain clusters: review articles, theories and notions, methods and their\nevaluation. It also summarises the state-of-the-art in XAI and recommends\nfuture research directions.",
    "published": "2020-05-29T21:41:12Z",
    "pdf_url": "http://arxiv.org/pdf/2006.00093v4",
    "categories": [
      "cs.AI",
      "cs.LG",
      "I.2.0; I.2.6; I.2.m"
    ]
  },
  {
    "arxiv_id": "1809.07842v1",
    "title": "Bias Amplification in Artificial Intelligence Systems",
    "authors": [
      "Kirsten Lloyd"
    ],
    "abstract": "As Artificial Intelligence (AI) technologies proliferate, concern has\ncentered around the long-term dangers of job loss or threats of machines\ncausing harm to humans. All of this concern, however, detracts from the more\npertinent and already existing threats posed by AI today: its ability to\namplify bias found in training datasets, and swiftly impact marginalized\npopulations at scale. Government and public sector institutions have a\nresponsibility to citizens to establish a dialogue with technology developers\nand release thoughtful policy around data standards to ensure diverse\nrepresentation in datasets to prevent bias amplification and ensure that AI\nsystems are built with inclusion in mind.",
    "published": "2018-09-20T20:29:56Z",
    "pdf_url": "http://arxiv.org/pdf/1809.07842v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2010.14376v1",
    "title": "The DigitalTwin from an Artificial Intelligence Perspective",
    "authors": [
      "Oliver Niggemann",
      "Alexander Diedrich",
      "Christian Kuehnert",
      "Erik Pfannstiel",
      "Joshua Schraven"
    ],
    "abstract": "Services for Cyber-Physical Systems based on Artificial Intelligence and\nMachine Learning require a virtual representation of the physical. To reduce\nmodeling efforts and to synchronize results, for each system, a common and\nunique virtual representation used by all services during the whole system\nlife-cycle is needed, i.e. a DigitalTwin. In this paper such a DigitalTwin,\nnamely the AI reference model AITwin, is defined. This reference model is\nverified by using a running example from process industry and by analyzing the\nwork done in recent projects.",
    "published": "2020-10-27T15:40:36Z",
    "pdf_url": "http://arxiv.org/pdf/2010.14376v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2011.13464v1",
    "title": "Meta-learning in natural and artificial intelligence",
    "authors": [
      "Jane X. Wang"
    ],
    "abstract": "Meta-learning, or learning to learn, has gained renewed interest in recent\nyears within the artificial intelligence community. However, meta-learning is\nincredibly prevalent within nature, has deep roots in cognitive science and\npsychology, and is currently studied in various forms within neuroscience. The\naim of this review is to recast previous lines of research in the study of\nbiological intelligence within the lens of meta-learning, placing these works\ninto a common framework. More recent points of interaction between AI and\nneuroscience will be discussed, as well as interesting new directions that\narise under this perspective.",
    "published": "2020-11-26T20:21:39Z",
    "pdf_url": "http://arxiv.org/pdf/2011.13464v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2305.05092v1",
    "title": "Artificial Intelligence in 3GPP 5G-Advanced: A Survey",
    "authors": [
      "Xingqin Lin"
    ],
    "abstract": "Industries worldwide are being transformed by artificial intelligence (AI),\nand the telecom industry is no different. Standardization is critical for\nindustry alignment to achieve widespread adoption of AI in telecom. The 3rd\ngeneration partnership project (3GPP) Release 18 is the first release of\n5G-Advanced, which includes a diverse set of study and work items dedicated to\nAI. This article provides a holistic overview of the state of the art in the\n3GPP work on AI in 5G-Advanced, by presenting the various 3GPP Release-18\nactivities on AI as an organic whole, explaining in detail the design aspects,\nand sharing various design rationales influencing standardization.",
    "published": "2023-05-08T23:32:23Z",
    "pdf_url": "http://arxiv.org/pdf/2305.05092v1",
    "categories": [
      "cs.NI",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1902.02441v1",
    "title": "Artificial Intelligence for Prosthetics - challenge solutions",
    "authors": [
      "Łukasz Kidziński",
      "Carmichael Ong",
      "Sharada Prasanna Mohanty",
      "Jennifer Hicks",
      "Sean F. Carroll",
      "Bo Zhou",
      "Hongsheng Zeng",
      "Fan Wang",
      "Rongzhong Lian",
      "Hao Tian",
      "Wojciech Jaśkowski",
      "Garrett Andersen",
      "Odd Rune Lykkebø",
      "Nihat Engin Toklu",
      "Pranav Shyam",
      "Rupesh Kumar Srivastava",
      "Sergey Kolesnikov",
      "Oleksii Hrinchuk",
      "Anton Pechenko",
      "Mattias Ljungström",
      "Zhen Wang",
      "Xu Hu",
      "Zehong Hu",
      "Minghui Qiu",
      "Jun Huang",
      "Aleksei Shpilman",
      "Ivan Sosin",
      "Oleg Svidchenko",
      "Aleksandra Malysheva",
      "Daniel Kudenko",
      "Lance Rane",
      "Aditya Bhatt",
      "Zhengfei Wang",
      "Penghui Qi",
      "Zeyang Yu",
      "Peng Peng",
      "Quan Yuan",
      "Wenxin Li",
      "Yunsheng Tian",
      "Ruihan Yang",
      "Pingchuan Ma",
      "Shauharda Khadka",
      "Somdeb Majumdar",
      "Zach Dwiel",
      "Yinyin Liu",
      "Evren Tumer",
      "Jeremy Watson",
      "Marcel Salathé",
      "Sergey Levine",
      "Scott Delp"
    ],
    "abstract": "In the NeurIPS 2018 Artificial Intelligence for Prosthetics challenge,\nparticipants were tasked with building a controller for a musculoskeletal model\nwith a goal of matching a given time-varying velocity vector. Top participants\nwere invited to describe their algorithms. In this work, we describe the\nchallenge and present thirteen solutions that used deep reinforcement learning\napproaches. Many solutions use similar relaxations and heuristics, such as\nreward shaping, frame skipping, discretization of the action space, symmetry,\nand policy blending. However, each team implemented different modifications of\nthe known algorithms by, for example, dividing the task into subtasks, learning\nlow-level control, or by incorporating expert knowledge and using imitation\nlearning.",
    "published": "2019-02-07T01:17:17Z",
    "pdf_url": "http://arxiv.org/pdf/1902.02441v1",
    "categories": [
      "cs.LG",
      "cs.RO",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1906.05270v1",
    "title": "Artificial Intelligence Enabled Material Behavior Prediction",
    "authors": [
      "Timothy Hanlon",
      "Johan Reimann",
      "Monica A. Soare",
      "Anjali Singhal",
      "James Grande",
      "Marc Edgar",
      "Kareem S. Aggour",
      "Joseph Vinciquerra"
    ],
    "abstract": "Artificial Intelligence and Machine Learning algorithms have considerable\npotential to influence the prediction of material properties. Additive\nmaterials have a unique property prediction challenge in the form of surface\nroughness effects on fatigue behavior of structural components. Traditional\napproaches using finite element methods to calculate stress risers associated\nwith additively built surfaces have been challenging due to the computational\nresources required, often taking over a day to calculate a single sample\nprediction. To address this performance challenge, Deep Learning has been\nemployed to enable low cycle fatigue life prediction in additive materials in a\nmatter of seconds.",
    "published": "2019-06-12T17:52:30Z",
    "pdf_url": "http://arxiv.org/pdf/1906.05270v1",
    "categories": [
      "cs.LG",
      "physics.app-ph"
    ]
  },
  {
    "arxiv_id": "2007.00523v2",
    "title": "Drug discovery with explainable artificial intelligence",
    "authors": [
      "José Jiménez-Luna",
      "Francesca Grisoni",
      "Gisbert Schneider"
    ],
    "abstract": "Deep learning bears promise for drug discovery, including advanced image\nanalysis, prediction of molecular structure and function, and automated\ngeneration of innovative chemical entities with bespoke properties. Despite the\ngrowing number of successful prospective applications, the underlying\nmathematical models often remain elusive to interpretation by the human mind.\nThere is a demand for 'explainable' deep learning methods to address the need\nfor a new narrative of the machine language of the molecular sciences. This\nreview summarizes the most prominent algorithmic concepts of explainable\nartificial intelligence, and dares a forecast of the future opportunities,\npotential applications, and remaining challenges.",
    "published": "2020-07-01T14:36:23Z",
    "pdf_url": "http://arxiv.org/pdf/2007.00523v2",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2208.09500v2",
    "title": "Causality-Inspired Taxonomy for Explainable Artificial Intelligence",
    "authors": [
      "Pedro C. Neto",
      "Tiago Gonçalves",
      "João Ribeiro Pinto",
      "Wilson Silva",
      "Ana F. Sequeira",
      "Arun Ross",
      "Jaime S. Cardoso"
    ],
    "abstract": "As two sides of the same coin, causality and explainable artificial\nintelligence (xAI) were initially proposed and developed with different goals.\nHowever, the latter can only be complete when seen through the lens of the\ncausality framework. As such, we propose a novel causality-inspired framework\nfor xAI that creates an environment for the development of xAI approaches. To\nshow its applicability, biometrics was used as case study. For this, we have\nanalysed 81 research papers on a myriad of biometric modalities and different\ntasks. We have categorised each of these methods according to our novel xAI\nLadder and discussed the future directions of the field.",
    "published": "2022-08-19T18:26:35Z",
    "pdf_url": "http://arxiv.org/pdf/2208.09500v2",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2301.04751v1",
    "title": "Artificial Intelligence Generated Coins for Size Comparison",
    "authors": [
      "Gerald Artner"
    ],
    "abstract": "Authors of scientific articles use coins in photographs as a size reference\nfor objects. For this purpose, coins are placed next to objects when taking the\nphoto. In this letter we propose a novel method that uses artificial\nintelligence (AI) generated images of coins to provide a size reference in\nphotos. The newest generation is able to quickly generate realistic\nhigh-quality images from textual descriptions. With the proposed method no\nphysical coin is required while taking photos. Coins can be added to photos\nthat contain none. Furthermore, we show how the coin motif can be matched to\nthe object.",
    "published": "2023-01-11T23:10:38Z",
    "pdf_url": "http://arxiv.org/pdf/2301.04751v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2302.07081v2",
    "title": "Integrating Artificial Intelligence and Humanities in Healthcare",
    "authors": [
      "Zohaib Tariq"
    ],
    "abstract": "Artificial Intelligence (AI) and Medical Humanities have become two of the\nmost crucial and rapidly growing fields in the current world. AI has made\nsubstantial advancements in recent years, enabling the development of\nalgorithms and systems that can perform tasks traditionally done by humans.\nMedical Humanities, on the other hand, is the intersection of medical sciences,\nhumanities, and the social sciences, and deals with the cultural, historical,\nphilosophical, ethical, and social aspects of health, illness, and medicine.\nThe integration of AI and Medical Humanities can offer innovative solutions to\nsome of the pressing issues in the medical field.",
    "published": "2023-02-13T10:48:48Z",
    "pdf_url": "http://arxiv.org/pdf/2302.07081v2",
    "categories": [
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "2308.02558v1",
    "title": "The Paradigm Shifts in Artificial Intelligence",
    "authors": [
      "Vasant Dhar"
    ],
    "abstract": "Kuhn's framework of scientific progress (Kuhn, 1962) provides a useful\nframing of the paradigm shifts that have occurred in Artificial Intelligence\nover the last 60 years. The framework is also useful in understanding what is\narguably a new paradigm shift in AI, signaled by the emergence of large\npre-trained systems such as GPT-3, on which conversational agents such as\nChatGPT are based. Such systems make intelligence a commoditized general\npurpose technology that is configurable to applications. In this paper, I\nsummarize the forces that led to the rise and fall of each paradigm, and\ndiscuss the pressing issues and risks associated with the current paradigm\nshift in AI.",
    "published": "2023-08-02T19:38:24Z",
    "pdf_url": "http://arxiv.org/pdf/2308.02558v1",
    "categories": [
      "cs.AI",
      "I.2.0"
    ]
  },
  {
    "arxiv_id": "2308.10921v1",
    "title": "Artificial intelligence-driven antimicrobial peptide discovery",
    "authors": [
      "Paulina Szymczak",
      "Ewa Szczurek"
    ],
    "abstract": "Antimicrobial peptides (AMPs) emerge as promising agents against\nantimicrobial resistance, providing an alternative to conventional antibiotics.\nArtificial intelligence (AI) revolutionized AMP discovery through both\ndiscrimination and generation approaches. The discriminators aid the\nidentification of promising candidates by predicting key peptide properties\nsuch as activity and toxicity, while the generators learn the distribution over\npeptides and enable sampling novel AMP candidates, either de novo, or as\nanalogues of a prototype peptide. Moreover, the controlled generation of AMPs\nwith desired properties is achieved by discriminator-guided filtering,\npositive-only learning, latent space sampling, as well as conditional and\noptimized generation. Here we review recent achievements in AI-driven AMP\ndiscovery, highlighting the most exciting directions.",
    "published": "2023-08-21T14:02:14Z",
    "pdf_url": "http://arxiv.org/pdf/2308.10921v1",
    "categories": [
      "q-bio.BM",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2308.16377v1",
    "title": "Science Communications for Explainable Artificial Intelligence",
    "authors": [
      "Simon Hudson",
      "Matija Franklin"
    ],
    "abstract": "Artificial Intelligence (AI) has a communication problem. XAI methods have\nbeen used to make AI more understandable and helped resolve some of the\ntransparency issues that inhibit AI's broader usability. However, user\nevaluation studies reveal that the often numerical explanations provided by XAI\nmethods have not always been effective for many types of users of AI systems.\nThis article aims to adapt the major communications models from Science\nCommunications into a framework for practitioners to understand, influence, and\nintegrate the context of audiences both for their communications supporting AI\nliteracy in the public and in designing XAI systems that are more adaptive to\ndifferent users.",
    "published": "2023-08-31T00:39:33Z",
    "pdf_url": "http://arxiv.org/pdf/2308.16377v1",
    "categories": [
      "cs.HC"
    ]
  },
  {
    "arxiv_id": "2311.09255v1",
    "title": "Artificial intelligence and the skill premium",
    "authors": [
      "David E. Bloom",
      "Klaus Prettner",
      "Jamel Saadaoui",
      "Mario Veruete"
    ],
    "abstract": "What will likely be the effect of the emergence of ChatGPT and other forms of\nartificial intelligence (AI) on the skill premium? To address this question, we\ndevelop a nested constant elasticity of substitution production function that\ndistinguishes between industrial robots and AI. Industrial robots predominantly\nsubstitute for low-skill workers, whereas AI mainly helps to perform the tasks\nof high-skill workers. We show that AI reduces the skill premium as long as it\nis more substitutable for high-skill workers than low-skill workers are for\nhigh-skill workers.",
    "published": "2023-11-14T20:16:55Z",
    "pdf_url": "http://arxiv.org/pdf/2311.09255v1",
    "categories": [
      "econ.TH",
      "cs.AI",
      "34C60 (Primary)"
    ]
  },
  {
    "arxiv_id": "2312.05481v12",
    "title": "Artificial Intelligence in the Knowledge Economy",
    "authors": [
      "Enrique Ide",
      "Eduard Talamas"
    ],
    "abstract": "Artificial Intelligence (AI) can transform the knowledge economy by\nautomating non-codifiable work. To analyze this transformation, we incorporate\nAI into an economy where humans form hierarchical organizations: Less\nknowledgeable individuals become \"workers\" doing routine work, while others\nbecome \"solvers\" handling exceptions. We model AI as a technology that converts\ncomputational resources into \"AI agents\" that operate autonomously (as\nco-workers and solvers/co-pilots) or non-autonomously (solely as co-pilots).\nAutonomous AI primarily benefits the most knowledgeable individuals;\nnon-autonomous AI benefits the least knowledgeable. However, output is higher\nwith autonomous AI. These findings reconcile contradictory empirical evidence\nand reveal tradeoffs when regulating AI autonomy.",
    "published": "2023-12-09T06:59:55Z",
    "pdf_url": "http://arxiv.org/pdf/2312.05481v12",
    "categories": [
      "econ.TH"
    ]
  },
  {
    "arxiv_id": "2402.13272v1",
    "title": "Spontaneous Theory of Mind for Artificial Intelligence",
    "authors": [
      "Nikolos Gurney",
      "David V. Pynadath",
      "Volkan Ustun"
    ],
    "abstract": "Existing approaches to Theory of Mind (ToM) in Artificial Intelligence (AI)\noveremphasize prompted, or cue-based, ToM, which may limit our collective\nability to develop Artificial Social Intelligence (ASI). Drawing from research\nin computer science, cognitive science, and related disciplines, we contrast\nprompted ToM with what we call spontaneous ToM -- reasoning about others'\nmental states that is grounded in unintentional, possibly uncontrollable\ncognitive functions. We argue for a principled approach to studying and\ndeveloping AI ToM and suggest that a robust, or general, ASI will respond to\nprompts \\textit{and} spontaneously engage in social reasoning.",
    "published": "2024-02-16T22:41:13Z",
    "pdf_url": "http://arxiv.org/pdf/2402.13272v1",
    "categories": [
      "cs.AI",
      "cs.HC"
    ]
  },
  {
    "arxiv_id": "2408.04609v1",
    "title": "Criticizing Ethics According to Artificial Intelligence",
    "authors": [
      "Irina Spiegel"
    ],
    "abstract": "This article presents a critique of ethics in the context of artificial\nintelligence (AI). It argues for the need to question established patterns of\nthought and traditional authorities, including core concepts such as autonomy,\nmorality, and ethics. These concepts are increasingly inadequate to deal with\nthe complexities introduced by emerging AI and autonomous agents. This critique\nhas several key components: clarifying conceptual ambiguities, honestly\naddressing epistemic issues, and thoroughly exploring fundamental normative\nproblems. The ultimate goal is to reevaluate and possibly redefine some\ntraditional ethical concepts to better address the challenges posed by AI.",
    "published": "2024-08-08T17:28:24Z",
    "pdf_url": "http://arxiv.org/pdf/2408.04609v1",
    "categories": [
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "2408.10726v1",
    "title": "Quantum Artificial Intelligence: A Brief Survey",
    "authors": [
      "Matthias Klusch",
      "Jörg Lässig",
      "Daniel Müssig",
      "Antonio Macaluso",
      "Frank K. Wilhelm"
    ],
    "abstract": "Quantum Artificial Intelligence (QAI) is the intersection of quantum\ncomputing and AI, a technological synergy with expected significant benefits\nfor both. In this paper, we provide a brief overview of what has been achieved\nin QAI so far and point to some open questions for future research. In\nparticular, we summarize some major key findings on the feasability and the\npotential of using quantum computing for solving computationally hard problems\nin various subfields of AI, and vice versa, the leveraging of AI methods for\nbuilding and operating quantum computing devices.",
    "published": "2024-08-20T10:55:17Z",
    "pdf_url": "http://arxiv.org/pdf/2408.10726v1",
    "categories": [
      "quant-ph",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2409.15903v1",
    "title": "Five questions and answers about artificial intelligence",
    "authors": [
      "Alberto Prieto",
      "Beatriz Prieto"
    ],
    "abstract": "Rapid advances in Artificial Intelligence (AI) are generating much\ncontroversy in society, often without scientific basis. As occurred the\ndevelopment of other emerging technologies, such as the introduction of\nelectricity in the early 20th century, AI causes both fascination and fear.\nFollowing the advice of the philosopher R.W. Emerson's: advice the knowledge is\nthe antidote to fear; this paper seeks to contribute to the dissemination of\nknowledge about AI. To this end, it reflects on the following questions: the\norigins of AI, its possible future evolution, its ability to show feelings, the\nassociated threats and dangers, and the concept of AI singularity.",
    "published": "2024-09-24T09:19:55Z",
    "pdf_url": "http://arxiv.org/pdf/2409.15903v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2507.05587v1",
    "title": "Towards Measurement Theory for Artificial Intelligence",
    "authors": [
      "Elija Perrier"
    ],
    "abstract": "We motivate and outline a programme for a formal theory of measurement of\nartificial intelligence. We argue that formalising measurement for AI will\nallow researchers, practitioners, and regulators to: (i) make comparisons\nbetween systems and the evaluation methods applied to them; (ii) connect\nfrontier AI evaluations with established quantitative risk analysis techniques\ndrawn from engineering and safety science; and (iii) foreground how what counts\nas AI capability is contingent upon the measurement operations and scales we\nelect to use. We sketch a layered measurement stack, distinguish direct from\nindirect observables, and signpost how these ingredients provide a pathway\ntoward a unified, calibratable taxonomy of AI phenomena.",
    "published": "2025-07-08T01:52:37Z",
    "pdf_url": "http://arxiv.org/pdf/2507.05587v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2508.11694v1",
    "title": "Music and Artificial Intelligence: Artistic Trends",
    "authors": [
      "Jordi Pons",
      "Zack Zukowski",
      "Julian D. Parker",
      "CJ Carr",
      "Josiah Taylor",
      "Zach Evans"
    ],
    "abstract": "We study how musicians use artificial intelligence (AI) across formats like\nsingles, albums, performances, installations, voices, ballets, operas, or\nsoundtracks. We collect 337 music artworks and categorize them based on AI\nusage: AI composition, co-composition, sound design, lyrics generation, and\ntranslation. We find that AI is employed as a co-creative tool, as an artistic\nmedium, and in live performances and installations. Innovative uses of AI\ninclude exploring uncanny aesthetics, multilingual and multigenre song\nreleases, and new formats such as online installations. This research provides\na comprehensive overview of current AI music practices, offering insights into\nemerging artistic trends and the challenges faced by AI musicians.",
    "published": "2025-08-12T18:12:02Z",
    "pdf_url": "http://arxiv.org/pdf/2508.11694v1",
    "categories": [
      "cs.CY",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2509.14907v1",
    "title": "Artificial Intelligence and Market Entrant Game Developers",
    "authors": [
      "Seonbin Jo",
      "Woo-Sung Jung",
      "Jisung Yoon",
      "Hyunuk Kim"
    ],
    "abstract": "Artificial Intelligence (AI) is increasingly being used for generating\ndigital assets, such as programming codes and images. Games composed of various\ndigital assets are thus expected to be influenced significantly by AI.\nLeveraging public data and AI disclosure statements of games, this paper shows\nthat relatively more independent developers entered the market when generative\nAI became more publicly accessible, but their purposes of using AI are similar\nwith non-independent developers. Game features associated with AI hint nuanced\nimpacts of AI on independent developers.",
    "published": "2025-09-18T12:35:19Z",
    "pdf_url": "http://arxiv.org/pdf/2509.14907v1",
    "categories": [
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "1202.6153v1",
    "title": "One Decade of Universal Artificial Intelligence",
    "authors": [
      "Marcus Hutter"
    ],
    "abstract": "The first decade of this century has seen the nascency of the first\nmathematical theory of general artificial intelligence. This theory of\nUniversal Artificial Intelligence (UAI) has made significant contributions to\nmany theoretical, philosophical, and practical AI questions. In a series of\npapers culminating in book (Hutter, 2005), an exciting sound and complete\nmathematical model for a super intelligent agent (AIXI) has been developed and\nrigorously analyzed. While nowadays most AI researchers avoid discussing\nintelligence, the award-winning PhD thesis (Legg, 2008) provided the\nphilosophical embedding and investigated the UAI-based universal measure of\nrational intelligence, which is formal, objective and non-anthropocentric.\nRecently, effective approximations of AIXI have been derived and experimentally\ninvestigated in JAIR paper (Veness et al. 2011). This practical breakthrough\nhas resulted in some impressive applications, finally muting earlier critique\nthat UAI is only a theory. For the first time, without providing any domain\nknowledge, the same agent is able to self-adapt to a diverse range of\ninteractive environments. For instance, AIXI is able to learn from scratch to\nplay TicTacToe, Pacman, Kuhn Poker, and other games by trial and error, without\neven providing the rules of the games.\n  These achievements give new hope that the grand goal of Artificial General\nIntelligence is not elusive.\n  This article provides an informal overview of UAI in context. It attempts to\ngently introduce a very theoretical, formal, and mathematical subject, and\ndiscusses philosophical and technical ingredients, traits of intelligence, some\nsocial questions, and the past and future of UAI.",
    "published": "2012-02-28T09:19:32Z",
    "pdf_url": "http://arxiv.org/pdf/1202.6153v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1810.02688v2",
    "title": "Wikistat 2.0: Educational Resources for Artificial Intelligence",
    "authors": [
      "Philippe Besse",
      "Brendan Guillouet",
      "Béatrice Laurent"
    ],
    "abstract": "Big data, data science, deep learning, artificial intelligence are the key\nwords of intense hype related with a job market in full evolution, that impose\nto adapt the contents of our university professional trainings. Which\nartificial intelligence is mostly concerned by the job offers? Which\nmethodologies and technologies should be favored in the training programs?\nWhich objectives, tools and educational resources do we needed to put in place\nto meet these pressing needs? We answer these questions in describing the\ncontents and operational resources in the Data Science orientation of the\nspecialty Applied Mathematics at INSA Toulouse. We focus on basic mathematics\ntraining (Optimization, Probability, Statistics), associated with the practical\nimplementation of the most performing statistical learning algorithms, with the\nmost appropriate technologies and on real examples. Considering the huge\nvolatility of the technologies, it is imperative to train students in\nseft-training, this will be their technological watch tool when they will be in\nprofessional activity. This explains the structuring of the educational site\ngithub.com/wikistat into a set of tutorials. Finally, to motivate the thorough\npractice of these tutorials, a serious game is organized each year in the form\nof a prediction contest between students of Master degrees in Applied\nMathematics for IA.",
    "published": "2018-09-28T08:27:59Z",
    "pdf_url": "http://arxiv.org/pdf/1810.02688v2",
    "categories": [
      "cs.CY",
      "cs.AI",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ]
  },
  {
    "arxiv_id": "2101.03613v1",
    "title": "Explainable Artificial Intelligence (XAI): An Engineering Perspective",
    "authors": [
      "F. Hussain",
      "R. Hussain",
      "E. Hossain"
    ],
    "abstract": "The remarkable advancements in Deep Learning (DL) algorithms have fueled\nenthusiasm for using Artificial Intelligence (AI) technologies in almost every\ndomain; however, the opaqueness of these algorithms put a question mark on\ntheir applications in safety-critical systems. In this regard, the\n`explainability' dimension is not only essential to both explain the inner\nworkings of black-box algorithms, but it also adds accountability and\ntransparency dimensions that are of prime importance for regulators, consumers,\nand service providers. eXplainable Artificial Intelligence (XAI) is the set of\ntechniques and methods to convert the so-called black-box AI algorithms to\nwhite-box algorithms, where the results achieved by these algorithms and the\nvariables, parameters, and steps taken by the algorithm to reach the obtained\nresults, are transparent and explainable. To complement the existing literature\non XAI, in this paper, we take an `engineering' approach to illustrate the\nconcepts of XAI. We discuss the stakeholders in XAI and describe the\nmathematical contours of XAI from engineering perspective. Then we take the\nautonomous car as a use-case and discuss the applications of XAI for its\ndifferent components such as object detection, perception, control, action\ndecision, and so on. This work is an exploratory study to identify new avenues\nof research in the field of XAI.",
    "published": "2021-01-10T19:49:12Z",
    "pdf_url": "http://arxiv.org/pdf/2101.03613v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2101.09429v1",
    "title": "Explainable Artificial Intelligence Approaches: A Survey",
    "authors": [
      "Sheikh Rabiul Islam",
      "William Eberle",
      "Sheikh Khaled Ghafoor",
      "Mohiuddin Ahmed"
    ],
    "abstract": "The lack of explainability of a decision from an Artificial Intelligence (AI)\nbased \"black box\" system/model, despite its superiority in many real-world\napplications, is a key stumbling block for adopting AI in many high stakes\napplications of different domain or industry. While many popular Explainable\nArtificial Intelligence (XAI) methods or approaches are available to facilitate\na human-friendly explanation of the decision, each has its own merits and\ndemerits, with a plethora of open challenges. We demonstrate popular XAI\nmethods with a mutual case study/task (i.e., credit default prediction),\nanalyze for competitive advantages from multiple perspectives (e.g., local,\nglobal), provide meaningful insight on quantifying explainability, and\nrecommend paths towards responsible or human-centered AI using XAI as a medium.\nPractitioners can use this work as a catalog to understand, compare, and\ncorrelate competitive advantages of popular XAI methods. In addition, this\nsurvey elicits future research directions towards responsible or human-centric\nAI systems, which is crucial to adopt AI in high stakes applications.",
    "published": "2021-01-23T06:15:34Z",
    "pdf_url": "http://arxiv.org/pdf/2101.09429v1",
    "categories": [
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1809.04797v1",
    "title": "Focus Group on Artificial Intelligence for Health",
    "authors": [
      "Marcel Salathé",
      "Thomas Wiegand",
      "Markus Wenzel"
    ],
    "abstract": "Artificial Intelligence (AI) - the phenomenon of machines being able to solve\nproblems that require human intelligence - has in the past decade seen an\nenormous rise of interest due to significant advances in effectiveness and use.\nThe health sector, one of the most important sectors for societies and\neconomies worldwide, is particularly interesting for AI applications, given the\nongoing digitalisation of all types of health information. The potential for AI\nassistance in the health domain is immense, because AI can support medical\ndecision making at reduced costs, everywhere. However, due to the complexity of\nAI algorithms, it is difficult to distinguish good from bad AI-based solutions\nand to understand their strengths and weaknesses, which is crucial for\nclarifying responsibilities and for building trust. For this reason, the\nInternational Telecommunication Union (ITU) has established a new Focus Group\non \"Artificial Intelligence for Health\" (FG-AI4H) in partnership with the World\nHealth Organization (WHO). Health and care services are usually the\nresponsibility of a government - even when provided through private insurance\nsystems - and thus under the responsibility of WHO/ITU member states. FG-AI4H\nwill identify opportunities for international standardization, which will\nfoster the application of AI to health issues on a global scale. In particular,\nit will establish a standardized assessment framework with open benchmarks for\nthe evaluation of AI-based methods for health, such as AI-based diagnosis,\ntriage or treatment decisions.",
    "published": "2018-09-13T06:46:34Z",
    "pdf_url": "http://arxiv.org/pdf/1809.04797v1",
    "categories": [
      "cs.AI",
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "1912.00747v3",
    "title": "The Transformative Potential of Artificial Intelligence",
    "authors": [
      "Ross Gruetzemacher",
      "Jess Whittlestone"
    ],
    "abstract": "The terms 'human-level artificial intelligence' and 'artificial general\nintelligence' are widely used to refer to the possibility of advanced\nartificial intelligence (AI) with potentially extreme impacts on society. These\nterms are poorly defined and do not necessarily indicate what is most important\nwith respect to future societal impacts. We suggest that the term\n'transformative AI' is a helpful alternative, reflecting the possibility that\nadvanced AI systems could have very large impacts on society without reaching\nhuman-level cognitive abilities. To be most useful, however, more analysis of\nwhat it means for AI to be 'transformative' is needed. In this paper, we\npropose three different levels on which AI might be said to be transformative,\nassociated with different levels of societal change. We suggest that these\ndistinctions would improve conversations between policy makers and decision\nmakers concerning the mid- to long-term impacts of advances in AI. Further, we\nfeel this would have a positive effect on strategic foresight efforts involving\nadvanced AI, which we expect to illuminate paths to alternative futures. We\nconclude with a discussion of the benefits of our new framework and by\nhighlighting directions for future work in this area.",
    "published": "2019-11-27T09:37:58Z",
    "pdf_url": "http://arxiv.org/pdf/1912.00747v3",
    "categories": [
      "cs.CY",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1912.06796v1",
    "title": "Artificial Intelligence Techniques for Security Vulnerability Prevention",
    "authors": [
      "Steve Kommrusch"
    ],
    "abstract": "Computer security has been a concern for decades and artificial intelligence\ntechniques have been applied to the area for nearly as long. Most of the\ntechniques are being applied to the detection of attacks to running systems,\nbut recent improvements in machine learning (for example, in natural language\nprocessing) have enabled the opportunity to process software and specifications\nto detect vulnerabilities in a system before it is deployed. This paper\npresents a survey of artificial intelligence techniques (including machine\nlearning) to detect or repair security vulnerabilities before product\nintroduction. In the surveyed papers, techniques are presented for using NLP to\nanalyze requirements documents for security standard completeness, performing\nneural fuzz testing of software, generating exploits to detect risk, and more.\nWe categorize current techniques into 3 groups: vulnerability detection,\nvulnerability repair, and specification analysis. Generally, while AI\ntechniques have become quite useful in this area, we show that AI techniques\nstill tend to be limited in scope, providing a collection of tools which can\naugment but not replace careful system development to reduce vulnerability\nrisks.",
    "published": "2019-12-14T07:01:44Z",
    "pdf_url": "http://arxiv.org/pdf/1912.06796v1",
    "categories": [
      "cs.CR"
    ]
  },
  {
    "arxiv_id": "2008.12629v1",
    "title": "Optical oxygen sensing with artificial intelligence",
    "authors": [
      "Umberto Michelucci",
      "Michael Baumgartner",
      "Francesca Venturini"
    ],
    "abstract": "Luminescence-based sensors for measuring oxygen concentration are widely used\nboth in industry and research due to the practical advantages and sensitivity\nof this type of sensing. The measuring principle is the luminescence quenching\nby oxygen molecules, which results in a change of the luminescence decay time\nand intensity. In the classical approach, this change is related to an oxygen\nconcentration using the Stern-Volmer equation. This equation, which in most of\nthe cases is non-linear, is parametrized through device-specific constants.\nTherefore, to determine these parameters every sensor needs to be precisely\ncalibrated at one or more known concentrations. This work explores an entirely\nnew artificial intelligence approach and demonstrates the feasibility of oxygen\nsensing through machine learning. The specifically developed neural network\nlearns very efficiently to relate the input quantities to the oxygen\nconcentration. The results show a mean deviation of the predicted from the\nmeasured concentration of 0.5 percent air, comparable to many commercial and\nlow-cost sensors. Since the network was trained using synthetically generated\ndata, the accuracy of the model predictions is limited by the ability of the\ngenerated data to describe the measured data, opening up future possibilities\nfor significant improvement by using a large number of experimental\nmeasurements for training. The approach described in this work demonstrates the\napplicability of artificial intelligence to sensing of sensors.",
    "published": "2020-07-27T20:59:38Z",
    "pdf_url": "http://arxiv.org/pdf/2008.12629v1",
    "categories": [
      "eess.SP",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2204.05146v1",
    "title": "Artificial Intelligence Enabled Spectral Reconfigurable Fiber Laser",
    "authors": [
      "Yanli Zhang",
      "Shanshan Wang",
      "Mingzhu She",
      "Weili Zhang"
    ],
    "abstract": "The combinations of artificial intelligence and lasers provide powerful ways\nto form smart light sources with ground-breaking functions. Here, a Raman fiber\nlaser (RFL) with reconfigurable and programmable spectra in an ultra-wide\nbandwidth is developed based on spectral-spatial manipulation of light in\nmultimode fiber (MMF). The proposed fiber laser uses nonlinear gain from\ncascaded stimulated Raman scattering, random distributed feedback from Rayleigh\nscattering, and point feedback from an MMF-based smart spectral filter. Through\nwavefront shaping controlled by a genetic algorithm, light of selective\nwavelength(s) can be focused in the MMF, forming the filter that, together with\nthe active part of the laser, actively shape the output spectrum with a high\ndegree of freedom. We achieved arbitrary spectral shaping of the cascaded RFL\n(e.g., continuously tunable single-wavelength and multi-wavelength laser with\ncustomizable linewidth, mode separation, and power distribution) from the 1st-\nto the 3rd-order Stokes emission by adjusting the pump power and\nauto-optimization of the smart filter. Our research uses\nartificial-intelligence controlled light manipulation in a fiber platform with\nmulti-eigenmodes and nonlinear gain, mapping the spatial control into the\nspectral domain as well as extending the linear control of light in MMF to\nactive light emission, which is of great significance for applications in\noptical communication, sensing, and spectroscopy.",
    "published": "2022-04-11T14:27:01Z",
    "pdf_url": "http://arxiv.org/pdf/2204.05146v1",
    "categories": [
      "physics.optics",
      "cs.SY",
      "eess.SY",
      "physics.app-ph"
    ]
  },
  {
    "arxiv_id": "2208.12120v1",
    "title": "Towards Benchmarking Explainable Artificial Intelligence Methods",
    "authors": [
      "Lars Holmberg"
    ],
    "abstract": "The currently dominating artificial intelligence and machine learning\ntechnology, neural networks, builds on inductive statistical learning. Neural\nnetworks of today are information processing systems void of understanding and\nreasoning capabilities, consequently, they cannot explain promoted decisions in\na humanly valid form. In this work, we revisit and use fundamental philosophy\nof science theories as an analytical lens with the goal of revealing, what can\nbe expected, and more importantly, not expected, from methods that aim to\nexplain decisions promoted by a neural network. By conducting a case study we\ninvestigate a selection of explainability method's performance over two mundane\ndomains, animals and headgear. Through our study, we lay bare that the\nusefulness of these methods relies on human domain knowledge and our ability to\nunderstand, generalise and reason. The explainability methods can be useful\nwhen the goal is to gain further insights into a trained neural network's\nstrengths and weaknesses. If our aim instead is to use these explainability\nmethods to promote actionable decisions or build trust in ML-models they need\nto be less ambiguous than they are today. In this work, we conclude from our\nstudy, that benchmarking explainability methods, is a central quest towards\ntrustworthy artificial intelligence and machine learning.",
    "published": "2022-08-25T14:28:30Z",
    "pdf_url": "http://arxiv.org/pdf/2208.12120v1",
    "categories": [
      "cs.AI",
      "cs.LG",
      "I.2.6; I.2.4"
    ]
  },
  {
    "arxiv_id": "2310.13192v3",
    "title": "The Opaque Law of Artificial Intelligence",
    "authors": [
      "Vincenzo Calderonio"
    ],
    "abstract": "The purpose of this paper is to analyse the opacity of algorithms,\ncontextualized in the open debate on responsibility for artificial intelligence\ncausation; with an experimental approach by which, applying the proposed\nconversational methodology of the Turing Test, we expect to evaluate the\nperformance of one of the best existing NLP model of generative AI (Chat-GPT)\nto see how far it can go right now and how the shape of a legal regulation of\nit could be. The analysis of the problem will be supported by a comment of\nItalian classical law categories such as causality, intent and fault to\nunderstand the problem of the usage of AI, focusing in particular on the\nhuman-machine interaction. On the computer science side, for a technical point\nof view of the logic used to craft these algorithms, in the second chapter will\nbe proposed a practical interrogation of Chat-GPT aimed at finding some\ncritical points of the functioning of AI. The end of the paper will concentrate\non some existing legal solutions which can be applied to the problem, plus a\nbrief description of the approach proposed by EU Artificial Intelligence act.",
    "published": "2023-10-19T23:02:46Z",
    "pdf_url": "http://arxiv.org/pdf/2310.13192v3",
    "categories": [
      "cs.AI",
      "F.0; I.2; J.4; K.4; K.5"
    ]
  },
  {
    "arxiv_id": "2402.18784v2",
    "title": "Brain-inspired and Self-based Artificial Intelligence",
    "authors": [
      "Yi Zeng",
      "Feifei Zhao",
      "Yuxuan Zhao",
      "Dongcheng Zhao",
      "Enmeng Lu",
      "Qian Zhang",
      "Yuwei Wang",
      "Hui Feng",
      "Zhuoya Zhao",
      "Jihang Wang",
      "Qingqun Kong",
      "Yinqian Sun",
      "Yang Li",
      "Guobin Shen",
      "Bing Han",
      "Yiting Dong",
      "Wenxuan Pan",
      "Xiang He",
      "Aorigele Bao",
      "Jin Wang"
    ],
    "abstract": "The question \"Can machines think?\" and the Turing Test to assess whether\nmachines could achieve human-level intelligence is one of the roots of AI. With\nthe philosophical argument \"I think, therefore I am\", this paper challenge the\nidea of a \"thinking machine\" supported by current AIs since there is no sense\nof self in them. Current artificial intelligence is only seemingly intelligent\ninformation processing and does not truly understand or be subjectively aware\nof oneself and perceive the world with the self as human intelligence does. In\nthis paper, we introduce a Brain-inspired and Self-based Artificial\nIntelligence (BriSe AI) paradigm. This BriSe AI paradigm is dedicated to\ncoordinating various cognitive functions and learning strategies in a\nself-organized manner to build human-level AI models and robotic applications.\nSpecifically, BriSe AI emphasizes the crucial role of the Self in shaping the\nfuture AI, rooted with a practical hierarchical Self framework, including\nPerception and Learning, Bodily Self, Autonomous Self, Social Self, and\nConceptual Self. The hierarchical framework of the Self highlights self-based\nenvironment perception, self-bodily modeling, autonomous interaction with the\nenvironment, social interaction and collaboration with others, and even more\nabstract understanding of the Self. Furthermore, the positive mutual promotion\nand support among multiple levels of Self, as well as between Self and\nlearning, enhance the BriSe AI's conscious understanding of information and\nflexible adaptation to complex environments, serving as a driving force\npropelling BriSe AI towards real Artificial General Intelligence.",
    "published": "2024-02-29T01:15:17Z",
    "pdf_url": "http://arxiv.org/pdf/2402.18784v2",
    "categories": [
      "cs.AI",
      "q-bio.NC"
    ]
  },
  {
    "arxiv_id": "2408.04999v1",
    "title": "MathPartner: An Artificial Intelligence Cloud Service",
    "authors": [
      "Gennadi Malaschonok",
      "Alexandr Seliverstov"
    ],
    "abstract": "In a broad sense, artificial intelligence is a service to find a solution to\ncomplex intellectual problems. In this sense, the MathPartner service provides\nartificial intelligence that allows us to formulate questions and receive\nanswers to questions formulated in a mathematical language. For mathematicians\nand physicists today, such a language is \\LaTeX. The MathPartner service uses a\ndialect of \\LaTeX, which is called Mathpar. The service is a cloud-based\ncomputer algebra system and provides users with the opportunity to solve many\nmathematical problems. In this publication, we focus only on a small class of\nextremum problems, which are widely applied in economics, management,\nlogistics, and in many engineering fields. In particular, we consider the\nshortest path problem and discuss an algorithm that is based on the tropical\nmathematics. The ability to work with many types of classical and tropical\nalgebras, which are freely available to users, is an important distinguishing\nfeature of this intelligent tool for symbolic-numerical calculations. We also\nconsider the use of the simplex algorithm for solving optimization problems.",
    "published": "2024-08-09T11:19:01Z",
    "pdf_url": "http://arxiv.org/pdf/2408.04999v1",
    "categories": [
      "cs.SC",
      "68T01",
      "F.4.1; F.2.2"
    ]
  },
  {
    "arxiv_id": "2410.19998v1",
    "title": "Artificial Intelligence of Things: A Survey",
    "authors": [
      "Shakhrul Iman Siam",
      "Hyunho Ahn",
      "Li Liu",
      "Samiul Alam",
      "Hui Shen",
      "Zhichao Cao",
      "Ness Shroff",
      "Bhaskar Krishnamachari",
      "Mani Srivastava",
      "Mi Zhang"
    ],
    "abstract": "The integration of the Internet of Things (IoT) and modern Artificial\nIntelligence (AI) has given rise to a new paradigm known as the Artificial\nIntelligence of Things (AIoT). In this survey, we provide a systematic and\ncomprehensive review of AIoT research. We examine AIoT literature related to\nsensing, computing, and networking & communication, which form the three key\ncomponents of AIoT. In addition to advancements in these areas, we review\ndomain-specific AIoT systems that are designed for various important\napplication domains. We have also created an accompanying GitHub repository,\nwhere we compile the papers included in this survey:\nhttps://github.com/AIoT-MLSys-Lab/AIoT-Survey. This repository will be actively\nmaintained and updated with new research as it becomes available. As both IoT\nand AI become increasingly critical to our society, we believe AIoT is emerging\nas an essential research field at the intersection of IoT and modern AI. We\nhope this survey will serve as a valuable resource for those engaged in AIoT\nresearch and act as a catalyst for future explorations to bridge gaps and drive\nadvancements in this exciting field.",
    "published": "2024-10-25T22:45:58Z",
    "pdf_url": "http://arxiv.org/pdf/2410.19998v1",
    "categories": [
      "cs.NI",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2304.13269v4",
    "title": "Games for Artificial Intelligence Research: A Review and Perspectives",
    "authors": [
      "Chengpeng Hu",
      "Yunlong Zhao",
      "Ziqi Wang",
      "Haocheng Du",
      "Jialin Liu"
    ],
    "abstract": "Games have been the perfect test-beds for artificial intelligence research\nfor the characteristics that widely exist in real-world scenarios. Learning and\noptimisation, decision making in dynamic and uncertain environments, game\ntheory, planning and scheduling, design and education are common research areas\nshared between games and real-world problems. Numerous open-source games or\ngame-based environments have been implemented for studying artificial\nintelligence. In addition to single- or multi-player, collaborative or\nadversarial games, there has also been growing interest in implementing\nplatforms for creative design in recent years. Those platforms provide ideal\nbenchmarks for exploring and comparing artificial intelligence ideas and\ntechniques. This paper reviews the games and game-based platforms for\nartificial intelligence research, provides guidance on matching particular\ntypes of artificial intelligence with suitable games for testing and matching\nparticular needs in games with suitable artificial intelligence techniques,\ndiscusses the research trend induced by the evolution of those games and\nplatforms, and gives an outlook.",
    "published": "2023-04-26T03:42:31Z",
    "pdf_url": "http://arxiv.org/pdf/2304.13269v4",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1810.06018v1",
    "title": "AAAI FSS-18: Artificial Intelligence in Government and Public Sector\n  Proceedings",
    "authors": [
      "Frank Stein",
      "Alun Preece",
      "Mihai Boicu"
    ],
    "abstract": "Proceedings of the AAAI Fall Symposium on Artificial Intelligence in\nGovernment and Public Sector, Arlington, Virginia, USA, October 18-20, 2018",
    "published": "2018-10-14T11:40:30Z",
    "pdf_url": "http://arxiv.org/pdf/1810.06018v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2011.04527v2",
    "title": "AAAI FSS-20: Artificial Intelligence in Government and Public Sector\n  Proceedings",
    "authors": [
      "Frank Stein",
      "Alun Preece"
    ],
    "abstract": "Proceedings of the AAAI Fall Symposium on Artificial Intelligence in\nGovernment and Public Sector, Washington, DC, USA, November 13-14, 2020",
    "published": "2020-11-09T16:08:42Z",
    "pdf_url": "http://arxiv.org/pdf/2011.04527v2",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1301.6359v2",
    "title": "Subjective Reality and Strong Artificial Intelligence",
    "authors": [
      "Alexander Serov"
    ],
    "abstract": "The main prospective aim of modern research related to Artificial\nIntelligence is the creation of technical systems that implement the idea of\nStrong Intelligence. According our point of view the path to the development of\nsuch systems comes through the research in the field related to perceptions.\nHere we formulate the model of the perception of external world which may be\nused for the description of perceptual activity of intelligent beings. We\nconsider a number of issues related to the development of the set of patterns\nwhich will be used by the intelligent system when interacting with environment.\nThe key idea of the presented perception model is the idea of subjective\nreality. The principle of the relativity of perceived world is formulated. It\nis shown that this principle is the immediate consequence of the idea of\nsubjective reality. In this paper we show how the methodology of subjective\nreality may be used for the creation of different types of Strong AI systems.",
    "published": "2013-01-27T14:29:04Z",
    "pdf_url": "http://arxiv.org/pdf/1301.6359v2",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1409.0813v2",
    "title": "Friendly Artificial Intelligence: the Physics Challenge",
    "authors": [
      "Max Tegmark"
    ],
    "abstract": "Relentless progress in artificial intelligence (AI) is increasingly raising\nconcerns that machines will replace humans on the job market, and perhaps\naltogether. Eliezer Yudkowski and others have explored the possibility that a\npromising future for humankind could be guaranteed by a superintelligent\n\"Friendly AI\", designed to safeguard humanity and its values. I argue that,\nfrom a physics perspective where everything is simply an arrangement of\nelementary particles, this might be even harder than it appears. Indeed, it may\nrequire thinking rigorously about the meaning of life: What is \"meaning\" in a\nparticle arrangement? What is \"life\"? What is the ultimate ethical imperative,\ni.e., how should we strive to rearrange the particles of our Universe and shape\nits future? If we fail to answer the last question rigorously, this future is\nunlikely to contain humans.",
    "published": "2014-09-02T18:20:28Z",
    "pdf_url": "http://arxiv.org/pdf/1409.0813v2",
    "categories": [
      "cs.CY",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1606.00652v1",
    "title": "Death and Suicide in Universal Artificial Intelligence",
    "authors": [
      "Jarryd Martin",
      "Tom Everitt",
      "Marcus Hutter"
    ],
    "abstract": "Reinforcement learning (RL) is a general paradigm for studying intelligent\nbehaviour, with applications ranging from artificial intelligence to psychology\nand economics. AIXI is a universal solution to the RL problem; it can learn any\ncomputable environment. A technical subtlety of AIXI is that it is defined\nusing a mixture over semimeasures that need not sum to 1, rather than over\nproper probability measures. In this work we argue that the shortfall of a\nsemimeasure can naturally be interpreted as the agent's estimate of the\nprobability of its death. We formally define death for generally intelligent\nagents like AIXI, and prove a number of related theorems about their behaviour.\nNotable discoveries include that agent behaviour can change radically under\npositive linear transformations of the reward signal (from suicidal to\ndogmatically self-preserving), and that the agent's posterior belief that it\nwill survive increases over time.",
    "published": "2016-06-02T12:48:39Z",
    "pdf_url": "http://arxiv.org/pdf/1606.00652v1",
    "categories": [
      "cs.AI",
      "I.2.0; I.2.6"
    ]
  },
  {
    "arxiv_id": "1706.03021v1",
    "title": "Ethical Artificial Intelligence - An Open Question",
    "authors": [
      "Alice Pavaloiu",
      "Utku Kose"
    ],
    "abstract": "Artificial Intelligence (AI) is an effective science which employs strong\nenough approaches, methods, and techniques to solve unsolvable real world based\nproblems. Because of its unstoppable rise towards the future, there are also\nsome discussions about its ethics and safety. Shaping an AI friendly\nenvironment for people and a people friendly environment for AI can be a\npossible answer for finding a shared context of values for both humans and\nrobots. In this context, objective of this paper is to address the ethical\nissues of AI and explore the moral dilemmas that arise from ethical algorithms,\nfrom pre set or acquired values. In addition, the paper will also focus on the\nsubject of AI safety. As general, the paper will briefly analyze the concerns\nand potential solutions to solving the ethical issues presented and increase\nreaders awareness on AI safety as another related research interest.",
    "published": "2017-05-16T20:57:36Z",
    "pdf_url": "http://arxiv.org/pdf/1706.03021v1",
    "categories": [
      "cs.AI",
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "1803.09992v1",
    "title": "Applications of Artificial Intelligence to Network Security",
    "authors": [
      "Alberto Perez Veiga"
    ],
    "abstract": "Attacks to networks are becoming more complex and sophisticated every day.\nBeyond the so-called script-kiddies and hacking newbies, there is a myriad of\nprofessional attackers seeking to make serious profits infiltrating in\ncorporate networks. Either hostile governments, big corporations or mafias are\nconstantly increasing their resources and skills in cybercrime in order to spy,\nsteal or cause damage more effectively. traditional approaches to Network\nSecurity seem to start hitting their limits and it is being recognized the need\nfor a smarter approach to threat detections. This paper provides an\nintroduction on the need for evolution of Cyber Security techniques and how\nArtificial Intelligence could be of application to help solving some of the\nproblems. It provides also, a high-level overview of some state of the art AI\nNetwork Security techniques, to finish analysing what is the foreseeable future\nof the application of AI to Network Security.",
    "published": "2018-03-27T09:54:30Z",
    "pdf_url": "http://arxiv.org/pdf/1803.09992v1",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "1812.11509v2",
    "title": "AIR5: Five Pillars of Artificial Intelligence Research",
    "authors": [
      "Yew-Soon Ong",
      "Abhishek Gupta"
    ],
    "abstract": "In this article, we provide and overview of what we consider to be some of\nthe most pressing research questions facing the fields of artificial\nintelligence (AI) and computational intelligence (CI); with the latter focusing\non algorithms that are inspired by various natural phenomena. We demarcate\nthese questions using five unique Rs - namely, (i) rationalizability, (ii)\nresilience, (iii) reproducibility, (iv) realism, and (v) responsibility.\nNotably, just as air serves as the basic element of biological life, the term\nAIR5 - cumulatively referring to the five aforementioned Rs - is introduced\nherein to mark some of the basic elements of artificial life (supporting the\nsustained growth of AI and CI). A brief summary of each of the Rs is presented,\nhighlighting their relevance as pillars of future research in this arena.",
    "published": "2018-12-30T11:00:48Z",
    "pdf_url": "http://arxiv.org/pdf/1812.11509v2",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2107.03721v4",
    "title": "Demystifying the Draft EU Artificial Intelligence Act",
    "authors": [
      "Michael Veale",
      "Frederik Zuiderveen Borgesius"
    ],
    "abstract": "In April 2021, the European Commission proposed a Regulation on Artificial\nIntelligence, known as the AI Act. We present an overview of the Act and\nanalyse its implications, drawing on scholarship ranging from the study of\ncontemporary AI practices to the structure of EU product safety regimes over\nthe last four decades. Aspects of the AI Act, such as different rules for\ndifferent risk-levels of AI, make sense. But we also find that some provisions\nof the Draft AI Act have surprising legal implications, whilst others may be\nlargely ineffective at achieving their stated goals. Several overarching\naspects, including the enforcement regime and the risks of maximum\nharmonisation pre-empting legitimate national AI policy, engender significant\nconcern. These issues should be addressed as a priority in the legislative\nprocess.",
    "published": "2021-07-08T10:04:07Z",
    "pdf_url": "http://arxiv.org/pdf/2107.03721v4",
    "categories": [
      "cs.CY",
      "cs.AI",
      "K.5.0; K.5.1"
    ]
  },
  {
    "arxiv_id": "2107.06747v1",
    "title": "Artificial Intelligence in PET: an Industry Perspective",
    "authors": [
      "Arkadiusz Sitek",
      "Sangtae Ahn",
      "Evren Asma",
      "Adam Chandler",
      "Alvin Ihsani",
      "Sven Prevrhal",
      "Arman Rahmim",
      "Babak Saboury",
      "Kris Thielemans"
    ],
    "abstract": "Artificial intelligence (AI) has significant potential to positively impact\nand advance medical imaging, including positron emission tomography (PET)\nimaging applications. AI has the ability to enhance and optimize all aspects of\nthe PET imaging chain from patient scheduling, patient setup, protocoling, data\nacquisition, detector signal processing, reconstruction, image processing and\ninterpretation. AI poses industry-specific challenges which will need to be\naddressed and overcome to maximize the future potentials of AI in PET. This\npaper provides an overview of these industry-specific challenges for the\ndevelopment, standardization, commercialization, and clinical adoption of AI,\nand explores the potential enhancements to PET imaging brought on by AI in the\nnear future. In particular, the combination of on-demand image reconstruction,\nAI, and custom designed data processing workflows may open new possibilities\nfor innovation which would positively impact the industry and ultimately\npatients.",
    "published": "2021-07-14T14:47:24Z",
    "pdf_url": "http://arxiv.org/pdf/2107.06747v1",
    "categories": [
      "cs.CV",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2107.13454v1",
    "title": "Artificial Intelligence in Healthcare: Lost In Translation?",
    "authors": [
      "Vince I. Madai",
      "David C. Higgins"
    ],
    "abstract": "Artificial intelligence (AI) in healthcare is a potentially revolutionary\ntool to achieve improved healthcare outcomes while reducing overall health\ncosts. While many exploratory results hit the headlines in recent years there\nare only few certified and even fewer clinically validated products available\nin the clinical setting. This is a clear indication of failing translation due\nto shortcomings of the current approach to AI in healthcare. In this work, we\nhighlight the major areas, where we observe current challenges for translation\nin AI in healthcare, namely precision medicine, reproducible science, data\nissues and algorithms, causality, and product development. For each field, we\noutline possible solutions for these challenges. Our work will lead to improved\ntranslation of AI in healthcare products into the clinical setting",
    "published": "2021-07-28T16:10:40Z",
    "pdf_url": "http://arxiv.org/pdf/2107.13454v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2001.07038v4",
    "title": "Measuring Diversity of Artificial Intelligence Conferences",
    "authors": [
      "Ana Freire",
      "Lorenzo Porcaro",
      "Emilia Gómez"
    ],
    "abstract": "The lack of diversity of the Artificial Intelligence (AI) field is nowadays a\nconcern, and several initiatives such as funding schemes and mentoring programs\nhave been designed to overcome it. However, there is no indication on how these\ninitiatives actually impact AI diversity in the short and long term. This work\nstudies the concept of diversity in this particular context and proposes a\nsmall set of diversity indicators (i.e. indexes) of AI scientific events. These\nindicators are designed to quantify the diversity of the AI field and monitor\nits evolution. We consider diversity in terms of gender, geographical location\nand business (understood as the presence of academia versus industry). We\ncompute these indicators for the different communities of a conference:\nauthors, keynote speakers and organizing committee. From these components we\ncompute a summarized diversity indicator for each AI event. We evaluate the\nproposed indexes for a set of recent major AI conferences and we discuss their\nvalues and limitations.",
    "published": "2020-01-20T10:09:50Z",
    "pdf_url": "http://arxiv.org/pdf/2001.07038v4",
    "categories": [
      "cs.DL",
      "cs.AI",
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "2104.13180v1",
    "title": "Controlling earthquake-like instabilities using artificial intelligence",
    "authors": [
      "Efthymios Papachristos",
      "Ioannis Stefanou"
    ],
    "abstract": "Earthquakes are lethal and costly. This study aims at avoiding these\ncatastrophic events by the application of injection policies retrieved through\nreinforcement learning. With the rapid growth of artificial intelligence,\nprediction-control problems are all the more tackled by function approximation\nmodels that learn how to control a specific task, even for systems with\nunmodeled/unknown dynamics and important uncertainties. Here, we show for the\nfirst time the possibility of controlling earthquake-like instabilities using\nstate-of-the-art deep reinforcement learning techniques. The controller is\ntrained using a reduced model of the physical system, i.e, the spring-slider\nmodel, which embodies the main dynamics of the physical problem for a given\nearthquake magnitude. Its robustness to unmodeled dynamics is explored through\na parametric study. Our study is a first step towards minimizing seismicity in\nindustrial projects (geothermal energy, hydrocarbons production, CO2\nsequestration) while, in a second step for inspiring techniques for natural\nearthquakes control and prevention.",
    "published": "2021-04-27T13:39:58Z",
    "pdf_url": "http://arxiv.org/pdf/2104.13180v1",
    "categories": [
      "physics.geo-ph",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1907.03848v1",
    "title": "Artificial Intelligence Governance and Ethics: Global Perspectives",
    "authors": [
      "Angela Daly",
      "Thilo Hagendorff",
      "Li Hui",
      "Monique Mann",
      "Vidushi Marda",
      "Ben Wagner",
      "Wei Wang",
      "Saskia Witteborn"
    ],
    "abstract": "Artificial intelligence (AI) is a technology which is increasingly being\nutilised in society and the economy worldwide, and its implementation is\nplanned to become more prevalent in coming years. AI is increasingly being\nembedded in our lives, supplementing our pervasive use of digital technologies.\nBut this is being accompanied by disquiet over problematic and dangerous\nimplementations of AI, or indeed, even AI itself deciding to do dangerous and\nproblematic actions, especially in fields such as the military, medicine and\ncriminal justice. These developments have led to concerns about whether and how\nAI systems adhere, and will adhere to ethical standards. These concerns have\nstimulated a global conversation on AI ethics, and have resulted in various\nactors from different countries and sectors issuing ethics and governance\ninitiatives and guidelines for AI. Such developments form the basis for our\nresearch in this report, combining our international and interdisciplinary\nexpertise to give an insight into what is happening in Australia, China,\nEurope, India and the US.",
    "published": "2019-06-28T07:42:48Z",
    "pdf_url": "http://arxiv.org/pdf/1907.03848v1",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1909.12063v1",
    "title": "Artificial Intelligence BlockCloud (AIBC) Technical Whitepaper",
    "authors": [
      "Qi Deng"
    ],
    "abstract": "The AIBC is an Artificial Intelligence and blockchain technology based\nlarge-scale decentralized ecosystem that allows system-wide low-cost sharing of\ncomputing and storage resources. The AIBC consists of four layers: a\nfundamental layer, a resource layer, an application layer, and an ecosystem\nlayer. The AIBC implements a two-consensus scheme to enforce upper-layer\neconomic policies and achieve fundamental layer performance and robustness: the\nDPoEV incentive consensus on the application and resource layers, and the DABFT\ndistributed consensus on the fundamental layer. The DABFT uses deep learning\ntechniques to predict and select the most suitable BFT algorithm in order to\nachieve the best balance of performance, robustness, and security. The DPoEV\nuses the knowledge map algorithm to accurately assess the economic value of\ndigital assets.",
    "published": "2019-09-26T12:49:50Z",
    "pdf_url": "http://arxiv.org/pdf/1909.12063v1",
    "categories": [
      "cs.AI",
      "cs.LG",
      "q-fin.ST",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2002.04087v2",
    "title": "Human-Centered Artificial Intelligence: Reliable, Safe & Trustworthy",
    "authors": [
      "Ben Shneiderman"
    ],
    "abstract": "Well-designed technologies that offer high levels of human control and high\nlevels of computer automation can increase human performance, leading to wider\nadoption. The Human-Centered Artificial Intelligence (HCAI) framework clarifies\nhow to (1) design for high levels of human control and high levels of computer\nautomation so as to increase human performance, (2) understand the situations\nin which full human control or full computer control are necessary, and (3)\navoid the dangers of excessive human control or excessive computer control. The\nmethods of HCAI are more likely to produce designs that are Reliable, Safe &\nTrustworthy (RST). Achieving these goals will dramatically increase human\nperformance, while supporting human self-efficacy, mastery, creativity, and\nresponsibility.",
    "published": "2020-02-10T21:02:48Z",
    "pdf_url": "http://arxiv.org/pdf/2002.04087v2",
    "categories": [
      "cs.HC",
      "cs.AI",
      "H.5.0"
    ]
  },
  {
    "arxiv_id": "2209.12618v1",
    "title": "Survey on Applications of Neurosymbolic Artificial Intelligence",
    "authors": [
      "Djallel Bouneffouf",
      "Charu C. Aggarwal"
    ],
    "abstract": "In recent years, the Neurosymbolic framework has attracted a lot of attention\nin various applications, from recommender systems and information retrieval to\nhealthcare and finance. This success is due to its stellar performance combined\nwith attractive properties, such as learning and reasoning. The new emerging\nNeurosymbolic field is currently experiencing a renaissance, as novel\nframeworks and algorithms motivated by various practical applications are being\nintroduced, building on top of the classical neural and reasoning problem\nsetting. This article aims to provide a comprehensive review of significant\nrecent developments in real-world applications of Neurosymbolic Artificial\nIntelligence. Specifically, we introduce a taxonomy of common Neurosymbolic\napplications and summarize the state-of-the-art for each of those domains.\nFurthermore, we identify important current trends and provide new perspectives\npertaining to the future of this burgeoning field.",
    "published": "2022-09-08T18:18:41Z",
    "pdf_url": "http://arxiv.org/pdf/2209.12618v1",
    "categories": [
      "cs.AI",
      "cs.SC"
    ]
  },
  {
    "arxiv_id": "2305.11897v2",
    "title": "Critical Appraisal of Artificial Intelligence-Mediated Communication",
    "authors": [
      "Dara Tafazoli"
    ],
    "abstract": "Over the last two decades, technology use in language learning and teaching\nhas significantly advanced and is now referred to as Computer-Assisted Language\nLearning (CALL). Recently, the integration of Artificial Intelligence (AI) into\nCALL has brought about a significant shift in the traditional approach to\nlanguage education both inside and outside the classroom. In line with this\nbook's scope, I explore the advantages and disadvantages of AI-mediated\ncommunication in language education. I begin with a brief review of AI in\neducation. I then introduce the ICALL and give a critical appraisal of the\npotential of AI-powered automatic speech recognition (ASR), Machine Translation\n(MT), Intelligent Tutoring Systems (ITSs), AI-powered chatbots, and Extended\nReality (XR). In conclusion, I argue that it is crucial for language teachers\nto engage in CALL teacher education and professional development to keep up\nwith the ever-evolving technology landscape and improve their teaching\neffectiveness.",
    "published": "2023-05-15T02:35:40Z",
    "pdf_url": "http://arxiv.org/pdf/2305.11897v2",
    "categories": [
      "cs.HC",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2008.07341v1",
    "title": "Data, Power and Bias in Artificial Intelligence",
    "authors": [
      "Susan Leavy",
      "Barry O'Sullivan",
      "Eugenia Siapera"
    ],
    "abstract": "Artificial Intelligence has the potential to exacerbate societal bias and set\nback decades of advances in equal rights and civil liberty. Data used to train\nmachine learning algorithms may capture social injustices, inequality or\ndiscriminatory attitudes that may be learned and perpetuated in society.\nAttempts to address this issue are rapidly emerging from different perspectives\ninvolving technical solutions, social justice and data governance measures.\nWhile each of these approaches are essential to the development of a\ncomprehensive solution, often discourse associated with each seems disparate.\nThis paper reviews ongoing work to ensure data justice, fairness and bias\nmitigation in AI systems from different domains exploring the interrelated\ndynamics of each and examining whether the inevitability of bias in AI training\ndata may in fact be used for social good. We highlight the complexity\nassociated with defining policies for dealing with bias. We also consider\ntechnical challenges in addressing issues of societal bias.",
    "published": "2020-07-28T16:17:40Z",
    "pdf_url": "http://arxiv.org/pdf/2008.07341v1",
    "categories": [
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "2105.10866v1",
    "title": "Towards Artificial Intelligence Enabled Financial Crime Detection",
    "authors": [
      "Zeinab Rouhollahi"
    ],
    "abstract": "Recently, financial institutes have been dealing with an increase in\nfinancial crimes. In this context, financial services firms started to improve\ntheir vigilance and use new technologies and approaches to identify and predict\nfinancial fraud and crime possibilities. This task is challenging as\ninstitutions need to upgrade their data and analytics capabilities to enable\nnew technologies such as Artificial Intelligence (AI) to predict and detect\nfinancial crimes. In this paper, we put a step towards AI-enabled financial\ncrime detection in general and money laundering detection in particular to\naddress this challenge. We study and analyse the recent works done in financial\ncrime detection and present a novel model to detect money laundering cases with\nminimum human intervention needs.",
    "published": "2021-05-23T06:57:25Z",
    "pdf_url": "http://arxiv.org/pdf/2105.10866v1",
    "categories": [
      "cs.LG",
      "cs.IR",
      "q-fin.ST"
    ]
  },
  {
    "arxiv_id": "2110.02007v3",
    "title": "Empowering Local Communities Using Artificial Intelligence",
    "authors": [
      "Yen-Chia Hsu",
      "Ting-Hao 'Kenneth' Huang",
      "Himanshu Verma",
      "Andrea Mauri",
      "Illah Nourbakhsh",
      "Alessandro Bozzon"
    ],
    "abstract": "Artificial Intelligence (AI) is increasingly used to analyze large amounts of\ndata in various practices, such as object recognition. We are specifically\ninterested in using AI-powered systems to engage local communities in\ndeveloping plans or solutions for pressing societal and environmental concerns.\nSuch local contexts often involve multiple stakeholders with different and even\ncontradictory agendas, resulting in mismatched expectations of these systems'\nbehaviors and desired outcomes. There is a need to investigate if AI models and\npipelines can work as expected in different contexts through co-creation and\nfield deployment. Based on case studies in co-creating AI-powered systems with\nlocal people, we explain challenges that require more attention and provide\nviable paths to bridge AI research with citizen needs. We advocate for\ndeveloping new collaboration approaches and mindsets that are needed to\nco-create AI-powered systems in multi-stakeholder contexts to address local\nconcerns.",
    "published": "2021-10-05T12:51:11Z",
    "pdf_url": "http://arxiv.org/pdf/2110.02007v3",
    "categories": [
      "cs.AI",
      "cs.HC"
    ]
  },
  {
    "arxiv_id": "2112.09325v2",
    "title": "Dilemma of the Artificial Intelligence Regulatory Landscape",
    "authors": [
      "Weiyue Wu",
      "Shaoshan Liu"
    ],
    "abstract": "As a startup company in the autonomous driving space, we have undergone four\nyears of painful experiences dealing with a broad spectrum of regulatory\nrequirements. Compared to the software industry norm, which spends 13% of their\noverall budget on compliances, we were forced to spend 42% of our budget on\ncompliances. Our situation is not alone and, in a way, reflects the dilemma of\nthe artificial intelligence (AI) regulatory landscape. The root cause is the\nlack of AI expertise in the legislative and executive branches, leading to a\nlack of standardization for the industry to follow. In this article, we share\nour first-hand experiences and advocate for the establishment of an FDA-like\nagency to regulate AI properly.",
    "published": "2021-12-17T05:10:31Z",
    "pdf_url": "http://arxiv.org/pdf/2112.09325v2",
    "categories": [
      "cs.CY",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2201.08789v1",
    "title": "AiTLAS: Artificial Intelligence Toolbox for Earth Observation",
    "authors": [
      "Ivica Dimitrovski",
      "Ivan Kitanovski",
      "Panče Panov",
      "Nikola Simidjievski",
      "Dragi Kocev"
    ],
    "abstract": "The AiTLAS toolbox (Artificial Intelligence Toolbox for Earth Observation)\nincludes state-of-the-art machine learning methods for exploratory and\npredictive analysis of satellite imagery as well as repository of AI-ready\nEarth Observation (EO) datasets. It can be easily applied for a variety of\nEarth Observation tasks, such as land use and cover classification, crop type\nprediction, localization of specific objects (semantic segmentation), etc. The\nmain goal of AiTLAS is to facilitate better usability and adoption of novel AI\nmethods (and models) by EO experts, while offering easy access and standardized\nformat of EO datasets to AI experts which further allows benchmarking of\nvarious existing and novel AI methods tailored for EO data.",
    "published": "2022-01-21T17:10:14Z",
    "pdf_url": "http://arxiv.org/pdf/2201.08789v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2206.11187v1",
    "title": "Automated Compliance Blueprint Optimization with Artificial Intelligence",
    "authors": [
      "Abdulhamid Adebayo",
      "Daby Sow",
      "Muhammed Fatih Bulut"
    ],
    "abstract": "For highly regulated industries such as banking and healthcare, one of the\nmajor hindrances to the adoption of cloud computing is compliance with\nregulatory standards. This is a complex problem due to many regulatory and\ntechnical specification (techspec) documents that the companies need to comply\nwith. The critical problem is to establish the mapping between techspecs and\nregulation controls so that from day one, companies can comply with regulations\nwith minimal effort. We demonstrate the practicality of an approach to\nautomatically analyze regulatory standards using Artificial Intelligence (AI)\ntechniques. We present early results to identify the mapping between techspecs\nand regulation controls, and discuss challenges that must be overcome for this\nsolution to be fully practical.",
    "published": "2022-06-22T15:59:16Z",
    "pdf_url": "http://arxiv.org/pdf/2206.11187v1",
    "categories": [
      "cs.AI",
      "cs.CR"
    ]
  },
  {
    "arxiv_id": "2210.05103v1",
    "title": "Leveraging Artificial Intelligence on Binary Code Comprehension",
    "authors": [
      "Yifan Zhang"
    ],
    "abstract": "Understanding binary code is an essential but complex software engineering\ntask for reverse engineering, malware analysis, and compiler optimization.\nUnlike source code, binary code has limited semantic information, which makes\nit challenging for human comprehension. At the same time, compiling source to\nbinary code, or transpiling among different programming languages (PLs) can\nprovide a way to introduce external knowledge into binary comprehension. We\npropose to develop Artificial Intelligence (AI) models that aid human\ncomprehension of binary code. Specifically, we propose to incorporate domain\nknowledge from large corpora of source code (e.g., variable names, comments) to\nbuild AI models that capture a generalizable representation of binary code.\nLastly, we will investigate metrics to assess the performance of models that\napply to binary code by using human studies of comprehension.",
    "published": "2022-10-11T02:39:29Z",
    "pdf_url": "http://arxiv.org/pdf/2210.05103v1",
    "categories": [
      "cs.SE",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2301.05864v1",
    "title": "Recent advances in artificial intelligence for retrosynthesis",
    "authors": [
      "Zipeng Zhong",
      "Jie Song",
      "Zunlei Feng",
      "Tiantao Liu",
      "Lingxiang Jia",
      "Shaolun Yao",
      "Tingjun Hou",
      "Mingli Song"
    ],
    "abstract": "Retrosynthesis is the cornerstone of organic chemistry, providing chemists in\nmaterial and drug manufacturing access to poorly available and brand-new\nmolecules. Conventional rule-based or expert-based computer-aided synthesis has\nobvious limitations, such as high labor costs and limited search space. In\nrecent years, dramatic breakthroughs driven by artificial intelligence have\nrevolutionized retrosynthesis. Here we aim to present a comprehensive review of\nrecent advances in AI-based retrosynthesis. For single-step and multi-step\nretrosynthesis both, we first list their goal and provide a thorough taxonomy\nof existing methods. Afterwards, we analyze these methods in terms of their\nmechanism and performance, and introduce popular evaluation metrics for them,\nin which we also provide a detailed comparison among representative methods on\nseveral public datasets. In the next part we introduce popular databases and\nestablished platforms for retrosynthesis. Finally, this review concludes with a\ndiscussion about promising research directions in this field.",
    "published": "2023-01-14T09:29:39Z",
    "pdf_url": "http://arxiv.org/pdf/2301.05864v1",
    "categories": [
      "cs.LG",
      "physics.chem-ph",
      "q-bio.BM"
    ]
  },
  {
    "arxiv_id": "2303.12732v1",
    "title": "Unfinished Architectures: A Perspective from Artificial Intelligence",
    "authors": [
      "Elena Merino-Gómez",
      "Pedro Reviriego",
      "Fernando Moral"
    ],
    "abstract": "Unfinished buildings are a constant throughout the history of architecture\nand have given rise to intense debates on the opportuneness of their\ncompletion, in addition to offering alibis for theorizing about the\ncompositional possibilities in coherence with the finished parts. The\ndevelopment of Artificial Intelligence (AI) opens new avenues for the proposal\nof possibilities for the completion of unfinished architectures. Specifically,\nwith the recent appearance of tools such as DALL-E, capable of completing\nimages guided by a textual description, it is possible to count on the help of\nAI for architectural design tasks. In this article we explore the use of these\nnew AI tools for the completion of unfinished facades of historical temples and\nanalyse the still germinal stadium in the field of architectural graphic\ncomposition.",
    "published": "2023-03-03T13:05:10Z",
    "pdf_url": "http://arxiv.org/pdf/2303.12732v1",
    "categories": [
      "cs.CV",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2306.01495v1",
    "title": "Accelerating science with human-aware artificial intelligence",
    "authors": [
      "Jamshid Sourati",
      "James Evans"
    ],
    "abstract": "Artificial intelligence (AI) models trained on published scientific findings\nhave been used to invent valuable materials and targeted therapies, but they\ntypically ignore the human scientists who continually alter the landscape of\ndiscovery. Here we show that incorporating the distribution of human expertise\nby training unsupervised models on simulated inferences cognitively accessible\nto experts dramatically improves (up to 400%) AI prediction of future\ndiscoveries beyond those focused on research content alone, especially when\nrelevant literature is sparse. These models succeed by predicting human\npredictions and the scientists who will make them. By tuning human-aware AI to\navoid the crowd, we can generate scientifically promising \"alien\" hypotheses\nunlikely to be imagined or pursued without intervention until the distant\nfuture, which hold promise to punctuate scientific advance beyond questions\ncurrently pursued. Accelerating human discovery or probing its blind spots,\nhuman-aware AI enables us to move toward and beyond the contemporary scientific\nfrontier.",
    "published": "2023-06-02T12:43:23Z",
    "pdf_url": "http://arxiv.org/pdf/2306.01495v1",
    "categories": [
      "cs.AI",
      "cs.SI"
    ]
  },
  {
    "arxiv_id": "2310.20474v1",
    "title": "Critical Role of Artificially Intelligent Conversational Chatbot",
    "authors": [
      "Seraj A. M. Mostafa",
      "Md Z. Islam",
      "Mohammad Z. Islam",
      "Fairose Jeehan",
      "Saujanna Jafreen",
      "Raihan U. Islam"
    ],
    "abstract": "Artificially intelligent chatbot, such as ChatGPT, represents a recent and\npowerful advancement in the AI domain. Users prefer them for obtaining quick\nand precise answers, avoiding the usual hassle of clicking through multiple\nlinks in traditional searches. ChatGPT's conversational approach makes it\ncomfortable and accessible for finding answers quickly and in an organized\nmanner. However, it is important to note that these chatbots have limitations,\nespecially in terms of providing accurate answers as well as ethical concerns.\nIn this study, we explore various scenarios involving ChatGPT's ethical\nimplications within academic contexts, its limitations, and the potential\nmisuse by specific user groups. To address these challenges, we propose\narchitectural solutions aimed at preventing inappropriate use and promoting\nresponsible AI interactions.",
    "published": "2023-10-31T14:08:07Z",
    "pdf_url": "http://arxiv.org/pdf/2310.20474v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2403.08802v4",
    "title": "Governance of Generative Artificial Intelligence for Companies",
    "authors": [
      "Johannes Schneider",
      "Pauline Kuss",
      "Rene Abraham",
      "Christian Meske"
    ],
    "abstract": "Generative Artificial Intelligence (GenAI), specifically large language\nmodels(LLMs) like ChatGPT, has swiftly entered organizations without adequate\ngovernance, posing both opportunities and risks. Despite extensive debates on\nGenAI's transformative nature and regulatory measures, limited research\naddresses organizational governance, encompassing technical and business\nperspectives. Although numerous frameworks for governance of AI exist, it is\nnot clear to what extent they apply to GenAI. Our review paper fills this gap\nby surveying recent works with the purpose of better understanding fundamental\ncharacteristics of GenAI and adjusting prior frameworks specifically towards\nGenAI governance within companies. To do so, it extends Nickerson's framework\ndevelopment processes to include prior conceptualizations. Our framework\noutlines the scope, objectives, and governance mechanisms tailored to harness\nbusiness opportunities as well as mitigate risks associated with GenAI\nintegration. Our research contributes a focused approach to GenAI governance,\noffering practical insights for companies navigating the challenges of GenAI\nadoption and highlighting research gaps.",
    "published": "2024-02-05T14:20:19Z",
    "pdf_url": "http://arxiv.org/pdf/2403.08802v4",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "I.2.m"
    ]
  },
  {
    "arxiv_id": "2406.10653v1",
    "title": "Justice in Healthcare Artificial Intelligence in Africa",
    "authors": [
      "Aloysius Ochasi",
      "Abdoul Jalil Djiberou Mahamadou",
      "Russ B. Altman"
    ],
    "abstract": "There is an ongoing debate on balancing the benefits and risks of artificial\nintelligence (AI) as AI is becoming critical to improving healthcare delivery\nand patient outcomes. Such improvements are essential in resource-constrained\nsettings where millions lack access to adequate healthcare services, such as in\nAfrica. AI in such a context can potentially improve the effectiveness,\nefficiency, and accessibility of healthcare services. Nevertheless, the\ndevelopment and use of AI-driven healthcare systems raise numerous ethical,\nlegal, and socio-economic issues. Justice is a major concern in AI that has\nimplications for amplifying social inequities. This paper discusses these\nimplications and related justice concepts such as solidarity, Common Good,\nsustainability, AI bias, and fairness. For Africa to effectively benefit from\nAI, these principles should align with the local context while balancing the\nrisks. Compared to mainstream ethical debates on justice, this perspective\noffers context-specific considerations for equitable healthcare AI development\nin Africa.",
    "published": "2024-06-15T14:47:03Z",
    "pdf_url": "http://arxiv.org/pdf/2406.10653v1",
    "categories": [
      "cs.CY",
      "cs.AI",
      "I.2.0"
    ]
  },
  {
    "arxiv_id": "2007.14206v1",
    "title": "Machine Learning Potential Repository",
    "authors": [
      "Atsuto Seko"
    ],
    "abstract": "This paper introduces a machine learning potential repository that includes\nPareto optimal machine learning potentials. It also shows the systematic\ndevelopment of accurate and fast machine learning potentials for a wide range\nof elemental systems. As a result, many Pareto optimal machine learning\npotentials are available in the repository from a website. Therefore, the\nrepository will help many scientists to perform accurate and fast atomistic\nsimulations.",
    "published": "2020-07-27T14:30:23Z",
    "pdf_url": "http://arxiv.org/pdf/2007.14206v1",
    "categories": [
      "physics.comp-ph",
      "cond-mat.mtrl-sci",
      "physics.chem-ph",
      "physics.data-an"
    ]
  },
  {
    "arxiv_id": "2201.09345v2",
    "title": "Machine Learning Symmetry",
    "authors": [
      "Shailesh Lal"
    ],
    "abstract": "We review recent work in machine learning aspects of conformal field theory\nand Lie algebra representation theory using neural networks.",
    "published": "2022-01-23T19:09:22Z",
    "pdf_url": "http://arxiv.org/pdf/2201.09345v2",
    "categories": [
      "hep-th",
      "math-ph",
      "math.MP",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1807.01477v2",
    "title": "Diversity in Machine Learning",
    "authors": [
      "Zhiqiang Gong",
      "Ping Zhong",
      "Weidong Hu"
    ],
    "abstract": "Machine learning methods have achieved good performance and been widely\napplied in various real-world applications. They can learn the model adaptively\nand be better fit for special requirements of different tasks. Generally, a\ngood machine learning system is composed of plentiful training data, a good\nmodel training process, and an accurate inference. Many factors can affect the\nperformance of the machine learning process, among which the diversity of the\nmachine learning process is an important one. The diversity can help each\nprocedure to guarantee a total good machine learning: diversity of the training\ndata ensures that the training data can provide more discriminative information\nfor the model, diversity of the learned model (diversity in parameters of each\nmodel or diversity among different base models) makes each parameter/model\ncapture unique or complement information and the diversity in inference can\nprovide multiple choices each of which corresponds to a specific plausible\nlocal optimal result. Even though the diversity plays an important role in\nmachine learning process, there is no systematical analysis of the\ndiversification in machine learning system. In this paper, we systematically\nsummarize the methods to make data diversification, model diversification, and\ninference diversification in the machine learning process, respectively. In\naddition, the typical applications where the diversity technology improved the\nmachine learning performance have been surveyed, including the remote sensing\nimaging tasks, machine translation, camera relocalization, image segmentation,\nobject detection, topic modeling, and others. Finally, we discuss some\nchallenges of the diversity technology in machine learning and point out some\ndirections in future work.",
    "published": "2018-07-04T08:25:17Z",
    "pdf_url": "http://arxiv.org/pdf/1807.01477v2",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1903.06334v2",
    "title": "Machine Learning Risk Models",
    "authors": [
      "Zura Kakushadze",
      "Willie Yu"
    ],
    "abstract": "We give an explicit algorithm and source code for constructing risk models\nbased on machine learning techniques. The resultant covariance matrices are not\nfactor models. Based on empirical backtests, we compare the performance of\nthese machine learning risk models to other constructions, including\nstatistical risk models, risk models based on fundamental industry\nclassifications, and also those utilizing multilevel clustering based industry\nclassifications.",
    "published": "2019-03-15T02:47:21Z",
    "pdf_url": "http://arxiv.org/pdf/1903.06334v2",
    "categories": [
      "q-fin.PM",
      "q-fin.RM"
    ]
  },
  {
    "arxiv_id": "2107.01238v1",
    "title": "Solving Machine Learning Problems",
    "authors": [
      "Sunny Tran",
      "Pranav Krishna",
      "Ishan Pakuwal",
      "Prabhakar Kafle",
      "Nikhil Singh",
      "Jayson Lynch",
      "Iddo Drori"
    ],
    "abstract": "Can a machine learn Machine Learning? This work trains a machine learning\nmodel to solve machine learning problems from a University undergraduate level\ncourse. We generate a new training set of questions and answers consisting of\ncourse exercises, homework, and quiz questions from MIT's 6.036 Introduction to\nMachine Learning course and train a machine learning model to answer these\nquestions. Our system demonstrates an overall accuracy of 96% for open-response\nquestions and 97% for multiple-choice questions, compared with MIT students'\naverage of 93%, achieving grade A performance in the course, all in real-time.\nQuestions cover all 12 topics taught in the course, excluding coding questions\nor questions with images. Topics include: (i) basic machine learning\nprinciples; (ii) perceptrons; (iii) feature extraction and selection; (iv)\nlogistic regression; (v) regression; (vi) neural networks; (vii) advanced\nneural networks; (viii) convolutional neural networks; (ix) recurrent neural\nnetworks; (x) state machines and MDPs; (xi) reinforcement learning; and (xii)\ndecision trees. Our system uses Transformer models within an encoder-decoder\narchitecture with graph and tree representations. An important aspect of our\napproach is a data-augmentation scheme for generating new example problems. We\nalso train a machine learning model to generate problem hints. Thus, our system\nautomatically generates new questions across topics, answers both open-response\nquestions and multiple-choice questions, classifies problems, and generates\nproblem hints, pushing the envelope of AI for STEM education.",
    "published": "2021-07-02T18:52:50Z",
    "pdf_url": "http://arxiv.org/pdf/2107.01238v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2110.12773v1",
    "title": "Scientific Machine Learning Benchmarks",
    "authors": [
      "Jeyan Thiyagalingam",
      "Mallikarjun Shankar",
      "Geoffrey Fox",
      "Tony Hey"
    ],
    "abstract": "The breakthrough in Deep Learning neural networks has transformed the use of\nAI and machine learning technologies for the analysis of very large\nexperimental datasets. These datasets are typically generated by large-scale\nexperimental facilities at national laboratories. In the context of science,\nscientific machine learning focuses on training machines to identify patterns,\ntrends, and anomalies to extract meaningful scientific insights from such\ndatasets. With a new generation of experimental facilities, the rate of data\ngeneration and the scale of data volumes will increasingly require the use of\nmore automated data analysis. At present, identifying the most appropriate\nmachine learning algorithm for the analysis of any given scientific dataset is\nstill a challenge for scientists. This is due to many different machine\nlearning frameworks, computer architectures, and machine learning models.\nHistorically, for modelling and simulation on HPC systems such problems have\nbeen addressed through benchmarking computer applications, algorithms, and\narchitectures. Extending such a benchmarking approach and identifying metrics\nfor the application of machine learning methods to scientific datasets is a new\nchallenge for both scientists and computer scientists. In this paper, we\ndescribe our approach to the development of scientific machine learning\nbenchmarks and review other approaches to benchmarking scientific machine\nlearning.",
    "published": "2021-10-25T10:05:11Z",
    "pdf_url": "http://arxiv.org/pdf/2110.12773v1",
    "categories": [
      "cs.LG",
      "physics.comp-ph",
      "I.2"
    ]
  },
  {
    "arxiv_id": "2206.00423v2",
    "title": "Open-environment Machine Learning",
    "authors": [
      "Zhi-Hua Zhou"
    ],
    "abstract": "Conventional machine learning studies generally assume close-environment\nscenarios where important factors of the learning process hold invariant. With\nthe great success of machine learning, nowadays, more and more practical tasks,\nparticularly those involving open-environment scenarios where important factors\nare subject to change, called open-environment machine learning (Open ML) in\nthis article, are present to the community. Evidently it is a grand challenge\nfor machine learning turning from close environment to open environment. It\nbecomes even more challenging since, in various big data tasks, data are\nusually accumulated with time, like streams, while it is hard to train the\nmachine learning model after collecting all data as in conventional studies.\nThis article briefly introduces some advances in this line of research,\nfocusing on techniques concerning emerging new classes, decremental/incremental\nfeatures, changing data distributions, varied learning objectives, and\ndiscusses some theoretical issues.",
    "published": "2022-06-01T11:57:56Z",
    "pdf_url": "http://arxiv.org/pdf/2206.00423v2",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1601.03642v1",
    "title": "Creativity in Machine Learning",
    "authors": [
      "Martin Thoma"
    ],
    "abstract": "Recent machine learning techniques can be modified to produce creative\nresults. Those results did not exist before; it is not a trivial combination of\nthe data which was fed into the machine learning system. The obtained results\ncome in multiple forms: As images, as text and as audio.\n  This paper gives a high level overview of how they are created and gives some\nexamples. It is meant to be a summary of the current work and give people who\nare new to machine learning some starting points.",
    "published": "2016-01-12T23:28:07Z",
    "pdf_url": "http://arxiv.org/pdf/1601.03642v1",
    "categories": [
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1611.09347v2",
    "title": "Quantum Machine Learning",
    "authors": [
      "Jacob Biamonte",
      "Peter Wittek",
      "Nicola Pancotti",
      "Patrick Rebentrost",
      "Nathan Wiebe",
      "Seth Lloyd"
    ],
    "abstract": "Fuelled by increasing computer power and algorithmic advances, machine\nlearning techniques have become powerful tools for finding patterns in data.\nSince quantum systems produce counter-intuitive patterns believed not to be\nefficiently produced by classical systems, it is reasonable to postulate that\nquantum computers may outperform classical computers on machine learning tasks.\nThe field of quantum machine learning explores how to devise and implement\nconcrete quantum software that offers such advantages. Recent work has made\nclear that the hardware and software challenges are still considerable but has\nalso opened paths towards solutions.",
    "published": "2016-11-28T20:59:46Z",
    "pdf_url": "http://arxiv.org/pdf/1611.09347v2",
    "categories": [
      "quant-ph",
      "cond-mat.str-el",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2003.00656v5",
    "title": "Machine Learning Portfolio Allocation",
    "authors": [
      "Michael Pinelis",
      "David Ruppert"
    ],
    "abstract": "We find economically and statistically significant gains when using machine\nlearning for portfolio allocation between the market index and risk-free asset.\nOptimal portfolio rules for time-varying expected returns and volatility are\nimplemented with two Random Forest models. One model is employed in forecasting\nthe sign probabilities of the excess return with payout yields. The second is\nused to construct an optimized volatility estimate. Reward-risk timing with\nmachine learning provides substantial improvements over the buy-and-hold in\nutility, risk-adjusted returns, and maximum drawdowns. This paper presents a\nnew theoretical basis and unifying framework for machine learning applied to\nboth return- and volatility-timing.",
    "published": "2020-03-02T04:45:16Z",
    "pdf_url": "http://arxiv.org/pdf/2003.00656v5",
    "categories": [
      "q-fin.PM",
      "q-fin.GN",
      "q-fin.PR",
      "q-fin.RM",
      "q-fin.ST"
    ]
  },
  {
    "arxiv_id": "2203.08056v1",
    "title": "Machine Learning and Cosmology",
    "authors": [
      "Cora Dvorkin",
      "Siddharth Mishra-Sharma",
      "Brian Nord",
      "V. Ashley Villar",
      "Camille Avestruz",
      "Keith Bechtol",
      "Aleksandra Ćiprijanović",
      "Andrew J. Connolly",
      "Lehman H. Garrison",
      "Gautham Narayan",
      "Francisco Villaescusa-Navarro"
    ],
    "abstract": "Methods based on machine learning have recently made substantial inroads in\nmany corners of cosmology. Through this process, new computational tools, new\nperspectives on data collection, model development, analysis, and discovery, as\nwell as new communities and educational pathways have emerged. Despite rapid\nprogress, substantial potential at the intersection of cosmology and machine\nlearning remains untapped. In this white paper, we summarize current and\nongoing developments relating to the application of machine learning within\ncosmology and provide a set of recommendations aimed at maximizing the\nscientific impact of these burgeoning tools over the coming decade through both\ntechnical development as well as the fostering of emerging communities.",
    "published": "2022-03-15T16:50:46Z",
    "pdf_url": "http://arxiv.org/pdf/2203.08056v1",
    "categories": [
      "hep-ph",
      "astro-ph.CO",
      "astro-ph.IM",
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1903.09731v3",
    "title": "Expert-Augmented Machine Learning",
    "authors": [
      "E. D. Gennatas",
      "J. H. Friedman",
      "L. H. Ungar",
      "R. Pirracchio",
      "E. Eaton",
      "L. Reichman",
      "Y. Interian",
      "C. B. Simone",
      "A. Auerbach",
      "E. Delgado",
      "M. J. Van der Laan",
      "T. D. Solberg",
      "G. Valdes"
    ],
    "abstract": "Machine Learning is proving invaluable across disciplines. However, its\nsuccess is often limited by the quality and quantity of available data, while\nits adoption by the level of trust that models afford users. Human vs. machine\nperformance is commonly compared empirically to decide whether a certain task\nshould be performed by a computer or an expert. In reality, the optimal\nlearning strategy may involve combining the complementary strengths of man and\nmachine. Here we present Expert-Augmented Machine Learning (EAML), an automated\nmethod that guides the extraction of expert knowledge and its integration into\nmachine-learned models. We use a large dataset of intensive care patient data\nto predict mortality and show that we can extract expert knowledge using an\nonline platform, help reveal hidden confounders, improve generalizability on a\ndifferent population and learn using less data. EAML presents a novel framework\nfor high performance and dependable machine learning in critical applications.",
    "published": "2019-03-22T23:32:22Z",
    "pdf_url": "http://arxiv.org/pdf/1903.09731v3",
    "categories": [
      "stat.ML",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1610.08251v1",
    "title": "Quantum-enhanced machine learning",
    "authors": [
      "Vedran Dunjko",
      "Jacob M. Taylor",
      "Hans J. Briegel"
    ],
    "abstract": "The emerging field of quantum machine learning has the potential to\nsubstantially aid in the problems and scope of artificial intelligence. This is\nonly enhanced by recent successes in the field of classical machine learning.\nIn this work we propose an approach for the systematic treatment of machine\nlearning, from the perspective of quantum information. Our approach is general\nand covers all three main branches of machine learning: supervised,\nunsupervised and reinforcement learning. While quantum improvements in\nsupervised and unsupervised learning have been reported, reinforcement learning\nhas received much less attention. Within our approach, we tackle the problem of\nquantum enhancements in reinforcement learning as well, and propose a\nsystematic scheme for providing improvements. As an example, we show that\nquadratic improvements in learning efficiency, and exponential improvements in\nperformance over limited time periods, can be obtained for a broad class of\nlearning problems.",
    "published": "2016-10-26T09:35:11Z",
    "pdf_url": "http://arxiv.org/pdf/1610.08251v1",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2102.00753v2",
    "title": "Quantum Fair Machine Learning",
    "authors": [
      "Elija Perrier"
    ],
    "abstract": "In this paper, we inaugurate the field of quantum fair machine learning. We\nundertake a comparative analysis of differences and similarities between\nclassical and quantum fair machine learning algorithms, specifying how the\nunique features of quantum computation alter measures, metrics and remediation\nstrategies when quantum algorithms are subject to fairness constraints. We\npresent the first results in quantum fair machine learning by demonstrating the\nuse of Grover's search algorithm to satisfy statistical parity constraints\nimposed on quantum algorithms. We provide lower-bounds on iterations needed to\nachieve such statistical parity within $\\epsilon$-tolerance. We extend\ncanonical Lipschitz-conditioned individual fairness criteria to the quantum\nsetting using quantum metrics. We examine the consequences for typical measures\nof fairness in machine learning context when quantum information processing and\nquantum data are involved. Finally, we propose open questions and research\nprogrammes for this new field of interest to researchers in computer science,\nethics and quantum computation.",
    "published": "2021-02-01T10:36:46Z",
    "pdf_url": "http://arxiv.org/pdf/2102.00753v2",
    "categories": [
      "cs.LG",
      "quant-ph"
    ]
  },
  {
    "arxiv_id": "2507.17931v1",
    "title": "Quantum Machine Learning Playground",
    "authors": [
      "Pascal Debus",
      "Sebastian Issel",
      "Kilian Tscharke"
    ],
    "abstract": "This article introduces an innovative interactive visualization tool designed\nto demystify quantum machine learning (QML) algorithms. Our work is inspired by\nthe success of classical machine learning visualization tools, such as\nTensorFlow Playground, and aims to bridge the gap in visualization resources\nspecifically for the field of QML. The article includes a comprehensive\noverview of relevant visualization metaphors from both quantum computing and\nclassical machine learning, the development of an algorithm visualization\nconcept, and the design of a concrete implementation as an interactive web\napplication. By combining common visualization metaphors for the so-called data\nre-uploading universal quantum classifier as a representative QML model, this\narticle aims to lower the entry barrier to quantum computing and encourage\nfurther innovation in the field. The accompanying interactive application is a\nproposal for the first version of a quantum machine learning playground for\nlearning and exploring QML models.",
    "published": "2025-07-23T21:08:29Z",
    "pdf_url": "http://arxiv.org/pdf/2507.17931v1",
    "categories": [
      "quant-ph",
      "cs.GR",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1202.6548v2",
    "title": "mlpy: Machine Learning Python",
    "authors": [
      "Davide Albanese",
      "Roberto Visintainer",
      "Stefano Merler",
      "Samantha Riccadonna",
      "Giuseppe Jurman",
      "Cesare Furlanello"
    ],
    "abstract": "mlpy is a Python Open Source Machine Learning library built on top of\nNumPy/SciPy and the GNU Scientific Libraries. mlpy provides a wide range of\nstate-of-the-art machine learning methods for supervised and unsupervised\nproblems and it is aimed at finding a reasonable compromise among modularity,\nmaintainability, reproducibility, usability and efficiency. mlpy is\nmultiplatform, it works with Python 2 and 3 and it is distributed under GPL3 at\nthe website http://mlpy.fbk.eu.",
    "published": "2012-02-29T13:49:10Z",
    "pdf_url": "http://arxiv.org/pdf/1202.6548v2",
    "categories": [
      "cs.MS",
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1911.10500v2",
    "title": "Causality for Machine Learning",
    "authors": [
      "Bernhard Schölkopf"
    ],
    "abstract": "Graphical causal inference as pioneered by Judea Pearl arose from research on\nartificial intelligence (AI), and for a long time had little connection to the\nfield of machine learning.\n  This article discusses where links have been and should be established,\nintroducing key concepts along the way. It argues that the hard open problems\nof machine learning and AI are intrinsically related to causality, and explains\nhow the field is beginning to understand them.",
    "published": "2019-11-24T11:04:56Z",
    "pdf_url": "http://arxiv.org/pdf/1911.10500v2",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML",
      "I.2, I.5, K.4",
      "I.2; I.5; K.4"
    ]
  },
  {
    "arxiv_id": "2001.00030v1",
    "title": "Quantum Adversarial Machine Learning",
    "authors": [
      "Sirui Lu",
      "Lu-Ming Duan",
      "Dong-Ling Deng"
    ],
    "abstract": "Adversarial machine learning is an emerging field that focuses on studying\nvulnerabilities of machine learning approaches in adversarial settings and\ndeveloping techniques accordingly to make learning robust to adversarial\nmanipulations. It plays a vital role in various machine learning applications\nand has attracted tremendous attention across different communities recently.\nIn this paper, we explore different adversarial scenarios in the context of\nquantum machine learning. We find that, similar to traditional classifiers\nbased on classical neural networks, quantum learning systems are likewise\nvulnerable to crafted adversarial examples, independent of whether the input\ndata is classical or quantum. In particular, we find that a quantum classifier\nthat achieves nearly the state-of-the-art accuracy can be conclusively deceived\nby adversarial examples obtained via adding imperceptible perturbations to the\noriginal legitimate samples. This is explicitly demonstrated with quantum\nadversarial learning in different scenarios, including classifying real-life\nimages (e.g., handwritten digit images in the dataset MNIST), learning phases\nof matter (such as, ferromagnetic/paramagnetic orders and symmetry protected\ntopological phases), and classifying quantum data. Furthermore, we show that\nbased on the information of the adversarial examples at hand, practical defense\nstrategies can be designed to fight against a number of different attacks. Our\nresults uncover the notable vulnerability of quantum machine learning systems\nto adversarial perturbations, which not only reveals a novel perspective in\nbridging machine learning and quantum physics in theory but also provides\nvaluable guidance for practical applications of quantum classifiers based on\nboth near-term and future quantum technologies.",
    "published": "2019-12-31T19:00:12Z",
    "pdf_url": "http://arxiv.org/pdf/2001.00030v1",
    "categories": [
      "quant-ph",
      "cond-mat.dis-nn",
      "cond-mat.str-el",
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2410.23724v1",
    "title": "Argumentation and Machine Learning",
    "authors": [
      "Antonio Rago",
      "Kristijonas Čyras",
      "Jack Mumford",
      "Oana Cocarascu"
    ],
    "abstract": "This chapter provides an overview of research works that present approaches\nwith some degree of cross-fertilisation between Computational Argumentation and\nMachine Learning. Our review of the literature identified two broad themes\nrepresenting the purpose of the interaction between these two areas:\nargumentation for machine learning and machine learning for argumentation.\nAcross these two themes, we systematically evaluate the spectrum of works\nacross various dimensions, including the type of learning and the form of\nargumentation framework used. Further, we identify three types of interaction\nbetween these two areas: synergistic approaches, where the Argumentation and\nMachine Learning components are tightly integrated; segmented approaches, where\nthe two are interleaved such that the outputs of one are the inputs of the\nother; and approximated approaches, where one component shadows the other at a\nchosen level of detail. We draw conclusions about the suitability of certain\nforms of Argumentation for supporting certain types of Machine Learning, and\nvice versa, with clear patterns emerging from the review. Whilst the reviewed\nworks provide inspiration for successfully combining the two fields of\nresearch, we also identify and discuss limitations and challenges that ought to\nbe addressed in order to ensure that they remain a fruitful pairing as AI\nadvances.",
    "published": "2024-10-31T08:19:58Z",
    "pdf_url": "http://arxiv.org/pdf/2410.23724v1",
    "categories": [
      "cs.AI",
      "F.4.1; I.2.4"
    ]
  },
  {
    "arxiv_id": "1106.4509v1",
    "title": "Machine Learning Markets",
    "authors": [
      "Amos Storkey"
    ],
    "abstract": "Prediction markets show considerable promise for developing flexible\nmechanisms for machine learning. Here, machine learning markets for\nmultivariate systems are defined, and a utility-based framework is established\nfor their analysis. This differs from the usual approach of defining static\nbetting functions. It is shown that such markets can implement model\ncombination methods used in machine learning, such as product of expert and\nmixture of expert approaches as equilibrium pricing models, by varying agent\nutility functions. They can also implement models composed of local potentials,\nand message passing methods. Prediction markets also allow for more flexible\ncombinations, by combining multiple different utility functions. Conversely,\nthe market mechanisms implement inference in the relevant probabilistic models.\nThis means that market mechanism can be utilized for implementing parallelized\nmodel building and inference for probabilistic modelling.",
    "published": "2011-06-22T17:12:42Z",
    "pdf_url": "http://arxiv.org/pdf/1106.4509v1",
    "categories": [
      "cs.AI",
      "cs.MA",
      "cs.NE",
      "q-fin.TR",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1904.02773v1",
    "title": "Adaptive Sequential Machine Learning",
    "authors": [
      "Craig Wilson",
      "Yuheng Bu",
      "Venugopal Veeravalli"
    ],
    "abstract": "A framework previously introduced in [3] for solving a sequence of stochastic\noptimization problems with bounded changes in the minimizers is extended and\napplied to machine learning problems such as regression and classification. The\nstochastic optimization problems arising in these machine learning problems is\nsolved using algorithms such as stochastic gradient descent (SGD). A method\nbased on estimates of the change in the minimizers and properties of the\noptimization algorithm is introduced for adaptively selecting the number of\nsamples at each time step to ensure that the excess risk, i.e., the expected\ngap between the loss achieved by the approximate minimizer produced by the\noptimization algorithm and the exact minimizer, does not exceed a target level.\nA bound is developed to show that the estimate of the change in the minimizers\nis non-trivial provided that the excess risk is small enough. Extensions\nrelevant to the machine learning setting are considered, including a cost-based\napproach to select the number of samples with a cost budget over a fixed\nhorizon, and an approach to applying cross-validation for model selection.\nFinally, experiments with synthetic and real data are used to validate the\nalgorithms.",
    "published": "2019-04-04T20:03:46Z",
    "pdf_url": "http://arxiv.org/pdf/1904.02773v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2111.03731v1",
    "title": "Frugal Machine Learning",
    "authors": [
      "Mikhail Evchenko",
      "Joaquin Vanschoren",
      "Holger H. Hoos",
      "Marc Schoenauer",
      "Michèle Sebag"
    ],
    "abstract": "Machine learning, already at the core of increasingly many systems and\napplications, is set to become even more ubiquitous with the rapid rise of\nwearable devices and the Internet of Things. In most machine learning\napplications, the main focus is on the quality of the results achieved (e.g.,\nprediction accuracy), and hence vast amounts of data are being collected,\nrequiring significant computational resources to build models. In many\nscenarios, however, it is infeasible or impractical to set up large centralized\ndata repositories. In personal health, for instance, privacy issues may inhibit\nthe sharing of detailed personal data. In such cases, machine learning should\nideally be performed on wearable devices themselves, which raises major\ncomputational limitations such as the battery capacity of smartwatches. This\npaper thus investigates frugal learning, aimed to build the most accurate\npossible models using the least amount of resources. A wide range of learning\nalgorithms is examined through a frugal lens, analyzing their accuracy/runtime\nperformance on a wide range of data sets. The most promising algorithms are\nthereafter assessed in a real-world scenario by implementing them in a\nsmartwatch and letting them learn activity recognition models on the watch\nitself.",
    "published": "2021-11-05T21:27:55Z",
    "pdf_url": "http://arxiv.org/pdf/2111.03731v1",
    "categories": [
      "cs.LG",
      "eess.SP"
    ]
  },
  {
    "arxiv_id": "2201.01289v2",
    "title": "Self-directed Machine Learning",
    "authors": [
      "Wenwu Zhu",
      "Xin Wang",
      "Pengtao Xie"
    ],
    "abstract": "Conventional machine learning (ML) relies heavily on manual design from\nmachine learning experts to decide learning tasks, data, models, optimization\nalgorithms, and evaluation metrics, which is labor-intensive, time-consuming,\nand cannot learn autonomously like humans. In education science, self-directed\nlearning, where human learners select learning tasks and materials on their own\nwithout requiring hands-on guidance, has been shown to be more effective than\npassive teacher-guided learning. Inspired by the concept of self-directed human\nlearning, we introduce the principal concept of Self-directed Machine Learning\n(SDML) and propose a framework for SDML. Specifically, we design SDML as a\nself-directed learning process guided by self-awareness, including internal\nawareness and external awareness. Our proposed SDML process benefits from self\ntask selection, self data selection, self model selection, self optimization\nstrategy selection and self evaluation metric selection through self-awareness\nwithout human guidance. Meanwhile, the learning performance of the SDML process\nserves as feedback to further improve self-awareness. We propose a mathematical\nformulation for SDML based on multi-level optimization. Furthermore, we present\ncase studies together with potential applications of SDML, followed by\ndiscussing future research directions. We expect that SDML could enable\nmachines to conduct human-like self-directed learning and provide a new\nperspective towards artificial general intelligence.",
    "published": "2022-01-04T18:32:06Z",
    "pdf_url": "http://arxiv.org/pdf/2201.01289v2",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2206.03266v1",
    "title": "Machine Learning Sensors",
    "authors": [
      "Pete Warden",
      "Matthew Stewart",
      "Brian Plancher",
      "Colby Banbury",
      "Shvetank Prakash",
      "Emma Chen",
      "Zain Asgar",
      "Sachin Katti",
      "Vijay Janapa Reddi"
    ],
    "abstract": "Machine learning sensors represent a paradigm shift for the future of\nembedded machine learning applications. Current instantiations of embedded\nmachine learning (ML) suffer from complex integration, lack of modularity, and\nprivacy and security concerns from data movement. This article proposes a more\ndata-centric paradigm for embedding sensor intelligence on edge devices to\ncombat these challenges. Our vision for \"sensor 2.0\" entails segregating sensor\ninput data and ML processing from the wider system at the hardware level and\nproviding a thin interface that mimics traditional sensors in functionality.\nThis separation leads to a modular and easy-to-use ML sensor device. We discuss\nchallenges presented by the standard approach of building ML processing into\nthe software stack of the controlling microprocessor on an embedded system and\nhow the modularity of ML sensors alleviates these problems. ML sensors increase\nprivacy and accuracy while making it easier for system builders to integrate ML\ninto their products as a simple component. We provide examples of prospective\nML sensors and an illustrative datasheet as a demonstration and hope that this\nwill build a dialogue to progress us towards sensor 2.0.",
    "published": "2022-06-07T13:22:13Z",
    "pdf_url": "http://arxiv.org/pdf/2206.03266v1",
    "categories": [
      "cs.LG",
      "cs.AR",
      "eess.SP"
    ]
  },
  {
    "arxiv_id": "2310.08215v1",
    "title": "Trustworthy Machine Learning",
    "authors": [
      "Bálint Mucsányi",
      "Michael Kirchhof",
      "Elisa Nguyen",
      "Alexander Rubinstein",
      "Seong Joon Oh"
    ],
    "abstract": "As machine learning technology gets applied to actual products and solutions,\nnew challenges have emerged. Models unexpectedly fail to generalize to small\nchanges in the distribution, tend to be confident on novel data they have never\nseen, or cannot communicate the rationale behind their decisions effectively\nwith the end users. Collectively, we face a trustworthiness issue with the\ncurrent machine learning technology. This textbook on Trustworthy Machine\nLearning (TML) covers a theoretical and technical background of four key topics\nin TML: Out-of-Distribution Generalization, Explainability, Uncertainty\nQuantification, and Evaluation of Trustworthiness. We discuss important\nclassical and contemporary research papers of the aforementioned fields and\nuncover and connect their underlying intuitions. The book evolved from the\nhomonymous course at the University of T\\\"ubingen, first offered in the Winter\nSemester of 2022/23. It is meant to be a stand-alone product accompanied by\ncode snippets and various pointers to further sources on topics of TML. The\ndedicated website of the book is https://trustworthyml.io/.",
    "published": "2023-10-12T11:04:17Z",
    "pdf_url": "http://arxiv.org/pdf/2310.08215v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.0"
    ]
  },
  {
    "arxiv_id": "2404.19032v2",
    "title": "Fermionic Machine Learning",
    "authors": [
      "Jérémie Gince",
      "Jean-Michel Pagé",
      "Marco Armenta",
      "Ayana Sarkar",
      "Stefanos Kourtis"
    ],
    "abstract": "We introduce fermionic machine learning (FermiML), a machine learning\nframework based on fermionic quantum computation. FermiML models are expressed\nin terms of parameterized matchgate circuits, a restricted class of quantum\ncircuits that map exactly to systems of free Majorana fermions. The FermiML\nframework allows for building fermionic counterparts of any quantum machine\nlearning (QML) model based on parameterized quantum circuits, including models\nthat produce highly entangled quantum states. Importantly, matchgate circuits\nare efficiently simulable classically, thus rendering FermiML a flexible\nframework for utility benchmarks of QML methods on large real-world datasets.\nWe initiate the exploration of FermiML by benchmarking it against unrestricted\nPQCs in the context of classification with random quantum kernels. Through\nexperiments on standard datasets (Digits and Wisconsin Breast Cancer), we\ndemonstrate that FermiML kernels are on-par with unrestricted PQC kernels in\nclassification tasks using support-vector machines. Furthermore, we find that\nFermiML kernels outperform their unrestricted candidates on multi-class\nclassification, including on datasets with several tens of relevant features.\nWe thus show how FermiML enables us to explore regimes previously inaccessible\nto QML methods.",
    "published": "2024-04-29T18:16:52Z",
    "pdf_url": "http://arxiv.org/pdf/2404.19032v2",
    "categories": [
      "quant-ph",
      "cond-mat.dis-nn"
    ]
  },
  {
    "arxiv_id": "2405.10198v2",
    "title": "Comprehensive Causal Machine Learning",
    "authors": [
      "Michael Lechner",
      "Jana Mareckova"
    ],
    "abstract": "Uncovering causal effects in multiple treatment setting at various levels of\ngranularity provides substantial value to decision makers. Comprehensive\nmachine learning approaches to causal effect estimation allow to use a single\ncausal machine learning approach for estimation and inference of causal mean\neffects for all levels of granularity. Focusing on selection-on-observables,\nthis paper compares three such approaches, the modified causal forest (mcf),\nthe generalized random forest (grf), and double machine learning (dml). It also\ncompares the theoretical properties of the approaches and provides proven\ntheoretical guarantees for the mcf. The findings indicate that dml-based\nmethods excel for average treatment effects at the population level (ATE) and\ngroup level (GATE) with few groups, when selection into treatment is not too\nstrong. However, for finer causal heterogeneity, explicitly outcome-centred\nforest-based approaches are superior. The mcf has three additional benefits:\n(i) It is the most robust estimator in cases when dml-based approaches\nunderperform because of substantial selection into treatment; (ii) it is the\nbest estimator for GATEs when the number of groups gets larger; and (iii), it\nis the only estimator that is internally consistent, in the sense that\nlow-dimensional causal ATEs and GATEs are obtained as aggregates of\nfiner-grained causal parameters.",
    "published": "2024-05-16T15:39:09Z",
    "pdf_url": "http://arxiv.org/pdf/2405.10198v2",
    "categories": [
      "econ.EM"
    ]
  },
  {
    "arxiv_id": "2506.12292v1",
    "title": "Quantum Machine Learning",
    "authors": [
      "Muhammad Usman"
    ],
    "abstract": "The meteoric rise of artificial intelligence in recent years has seen machine\nlearning methods become ubiquitous in modern science, technology, and industry.\nConcurrently, the emergence of programmable quantum computers, coupled with the\nexpectation that large-scale fault-tolerant machines will follow in the near to\nmedium-term future, has led to much speculation about the prospect of quantum\nmachine learning (QML), namely machine learning (ML) solutions which take\nadvantage of quantum properties to outperform their classical counterparts.\nIndeed, QML is widely considered as one of the front-running use cases for\nquantum computing. In recent years, research in QML has gained significant\nglobal momentum. In this chapter, we introduce the fundamentals of QML and\nprovide a brief overview of the recent progress and future trends in the field\nof QML. We highlight key opportunities for achieving quantum advantage in ML\ntasks, as well as describe some open challenges currently facing the field of\nQML. Specifically in the context of cybersecurity, we introduce the potential\nfor QML in defence and security-sensitive applications, where it has been\npredicted that the seamless integration of quantum computing into ML will\nherald the development of robust and reliable QML systems, resilient against\nsophisticated threats arising from data manipulation and poisoning.",
    "published": "2025-06-14T00:58:54Z",
    "pdf_url": "http://arxiv.org/pdf/2506.12292v1",
    "categories": [
      "quant-ph"
    ]
  },
  {
    "arxiv_id": "2205.00210v1",
    "title": "Software Testing for Machine Learning",
    "authors": [
      "Dusica Marijan",
      "Arnaud Gotlieb"
    ],
    "abstract": "Machine learning has become prevalent across a wide variety of applications.\nUnfortunately, machine learning has also shown to be susceptible to deception,\nleading to errors, and even fatal failures. This circumstance calls into\nquestion the widespread use of machine learning, especially in safety-critical\napplications, unless we are able to assure its correctness and trustworthiness\nproperties. Software verification and testing are established technique for\nassuring such properties, for example by detecting errors. However, software\ntesting challenges for machine learning are vast and profuse - yet critical to\naddress. This summary talk discusses the current state-of-the-art of software\ntesting for machine learning. More specifically, it discusses six key challenge\nareas for software testing of machine learning systems, examines current\napproaches to these challenges and highlights their limitations. The paper\nprovides a research agenda with elaborated directions for making progress\ntoward advancing the state-of-the-art on testing of machine learning.",
    "published": "2022-04-30T08:47:10Z",
    "pdf_url": "http://arxiv.org/pdf/2205.00210v1",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2101.08928v1",
    "title": "Machine Learning Percolation Model",
    "authors": [
      "Shu Cheng",
      "Fei He",
      "Huai Zhang",
      "Ka-Di Zhu",
      "Yaolin Shi"
    ],
    "abstract": "Recent advances in machine learning have become increasingly popular in the\napplications of phase transitions and critical phenomena. By machine learning\napproaches, we try to identify the physical characteristics in the\ntwo-dimensional percolation model. To achieve this, we adopt Monte Carlo\nsimulation to generate dataset at first, and then we employ several approaches\nto analyze the dataset. Four kinds of convolutional neural networks (CNNs), one\nvariational autoencoder (VAE), one convolutional VAE (cVAE), one principal\ncomponent analysis (PCA), and one $k$-means are used for identifying order\nparameter, the permeability, and the critical transition point. The former\nthree kinds of CNNs can simulate the two order parameters and the permeability\nwith high accuracy, and good extrapolating performance. The former two kinds of\nCNNs have high anti-noise ability. To validate the robustness of the former\nthree kinds of CNNs, we also use the VAE and the cVAE to generate new\npercolating configurations to add perturbations into the raw configurations. We\nfind that there is no difference by using the raw or the perturbed\nconfigurations to identify the physical characteristics, under the prerequisite\nof corresponding labels. In the case of lacking labels, we use unsupervised\nlearning to detect the physical characteristics. The PCA, a classical\nunsupervised learning, performs well when identifying the permeability but\nfails to deduce order parameter. Hence, we apply the fourth kinds of CNNs with\ndifferent preset thresholds, and identify a new order parameter and the\ncritical transition point. Our findings indicate that the effectiveness of\nmachine learning still needs to be evaluated in the applications of phase\ntransitions and critical phenomena.",
    "published": "2021-01-22T03:24:52Z",
    "pdf_url": "http://arxiv.org/pdf/2101.08928v1",
    "categories": [
      "cond-mat.dis-nn"
    ]
  },
  {
    "arxiv_id": "1109.0325v1",
    "title": "Quantum adiabatic machine learning",
    "authors": [
      "Kristen L. Pudenz",
      "Daniel A. Lidar"
    ],
    "abstract": "We develop an approach to machine learning and anomaly detection via quantum\nadiabatic evolution. In the training phase we identify an optimal set of weak\nclassifiers, to form a single strong classifier. In the testing phase we\nadiabatically evolve one or more strong classifiers on a superposition of\ninputs in order to find certain anomalous elements in the classification space.\nBoth the training and testing phases are executed via quantum adiabatic\nevolution. We apply and illustrate this approach in detail to the problem of\nsoftware verification and validation.",
    "published": "2011-09-01T23:10:31Z",
    "pdf_url": "http://arxiv.org/pdf/1109.0325v1",
    "categories": [
      "quant-ph",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1206.4656v1",
    "title": "Machine Learning that Matters",
    "authors": [
      "Kiri Wagstaff"
    ],
    "abstract": "Much of current machine learning (ML) research has lost its connection to\nproblems of import to the larger world of science and society. From this\nperspective, there exist glaring limitations in the data sets we investigate,\nthe metrics we employ for evaluation, and the degree to which results are\ncommunicated back to their originating domains. What changes are needed to how\nwe conduct research to increase the impact that ML has? We present six Impact\nChallenges to explicitly focus the field?s energy and attention, and we discuss\nexisting obstacles that must be addressed. We aim to inspire ongoing discussion\nand focus on ML that matters.",
    "published": "2012-06-18T15:26:13Z",
    "pdf_url": "http://arxiv.org/pdf/1206.4656v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2202.09480v1",
    "title": "Reciprocity in Machine Learning",
    "authors": [
      "Mukund Sundararajan",
      "Walid Krichene"
    ],
    "abstract": "Machine learning is pervasive. It powers recommender systems such as Spotify,\nInstagram and YouTube, and health-care systems via models that predict sleep\npatterns, or the risk of disease. Individuals contribute data to these models\nand benefit from them. Are these contributions (outflows of influence) and\nbenefits (inflows of influence) reciprocal? We propose measures of outflows,\ninflows and reciprocity building on previously proposed measures of training\ndata influence. Our initial theoretical and empirical results indicate that\nunder certain distributional assumptions, some classes of models are\napproximately reciprocal. We conclude with several open directions.",
    "published": "2022-02-19T00:25:03Z",
    "pdf_url": "http://arxiv.org/pdf/2202.09480v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "econ.GN",
      "q-fin.EC"
    ]
  },
  {
    "arxiv_id": "2011.08958v1",
    "title": "Machine-Learning Number Fields",
    "authors": [
      "Yang-Hui He",
      "Kyu-Hwan Lee",
      "Thomas Oliver"
    ],
    "abstract": "We show that standard machine-learning algorithms may be trained to predict\ncertain invariants of algebraic number fields to high accuracy. A random-forest\nclassifier that is trained on finitely many Dedekind zeta coefficients is able\nto distinguish between real quadratic fields with class number 1 and 2, to 0.96\nprecision. Furthermore, the classifier is able to extrapolate to fields with\ndiscriminant outside the range of the training data. When trained on the\ncoefficients of defining polynomials for Galois extensions of degrees 2, 6, and\n8, a logistic regression classifier can distinguish between Galois groups and\npredict the ranks of unit groups with precision >0.97.",
    "published": "2020-11-17T21:40:40Z",
    "pdf_url": "http://arxiv.org/pdf/2011.08958v1",
    "categories": [
      "math.NT",
      "hep-th",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2003.05095v1",
    "title": "Machine Learning Treasury Yields",
    "authors": [
      "Zura Kakushadze",
      "Willie Yu"
    ],
    "abstract": "We give explicit algorithms and source code for extracting factors underlying\nTreasury yields using (unsupervised) machine learning (ML) techniques, such as\nnonnegative matrix factorization (NMF) and (statistically deterministic)\nclustering. NMF is a popular ML algorithm (used in computer vision,\nbioinformatics/computational biology, document classification, etc.), but is\noften misconstrued and misused. We discuss how to properly apply NMF to\nTreasury yields. We analyze the factors based on NMF and clustering and their\ninterpretation. We discuss their implications for forecasting Treasury yields\nin the context of out-of-sample ML stability issues.",
    "published": "2020-03-11T03:15:18Z",
    "pdf_url": "http://arxiv.org/pdf/2003.05095v1",
    "categories": [
      "stat.ME",
      "q-fin.CP",
      "q-fin.PR"
    ]
  },
  {
    "arxiv_id": "2310.11340v1",
    "title": "Contextualized Machine Learning",
    "authors": [
      "Benjamin Lengerich",
      "Caleb N. Ellington",
      "Andrea Rubbi",
      "Manolis Kellis",
      "Eric P. Xing"
    ],
    "abstract": "We examine Contextualized Machine Learning (ML), a paradigm for learning\nheterogeneous and context-dependent effects. Contextualized ML estimates\nheterogeneous functions by applying deep learning to the meta-relationship\nbetween contextual information and context-specific parametric models. This is\na form of varying-coefficient modeling that unifies existing frameworks\nincluding cluster analysis and cohort modeling by introducing two reusable\nconcepts: a context encoder which translates sample context into model\nparameters, and sample-specific model which operates on sample predictors. We\nreview the process of developing contextualized models, nonparametric inference\nfrom contextualized models, and identifiability conditions of contextualized\nmodels. Finally, we present the open-source PyTorch package ContextualizedML.",
    "published": "2023-10-17T15:23:00Z",
    "pdf_url": "http://arxiv.org/pdf/2310.11340v1",
    "categories": [
      "stat.ML",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2407.00183v2",
    "title": "Top-philic Machine Learning",
    "authors": [
      "Rahool Kumar Barman",
      "Sumit Biswas"
    ],
    "abstract": "In this article, we review the application of modern machine-learning (ML)\ntechniques to boost the search for processes involving the top quarks at the\nLHC. We revisit the formalism of Convolutional Neural Networks (CNNs), Graph\nNeural Networks (GNNs), and Attention Mechanisms. Based on recent studies, we\nexplore their applications in designing improved top taggers, top\nreconstruction, and event classification tasks. We also examine the ML-based\nlikelihood-free inference approach and generative unfolding models, focusing on\ntheir applications to scenarios involving top quarks.",
    "published": "2024-06-28T18:38:30Z",
    "pdf_url": "http://arxiv.org/pdf/2407.00183v2",
    "categories": [
      "hep-ph",
      "hep-ex"
    ]
  },
  {
    "arxiv_id": "2509.20370v1",
    "title": "Philosophy-informed Machine Learning",
    "authors": [
      "MZ Naser"
    ],
    "abstract": "Philosophy-informed machine learning (PhIML) directly infuses core ideas from\nanalytic philosophy into ML model architectures, objectives, and evaluation\nprotocols. Therefore, PhIML promises new capabilities through models that\nrespect philosophical concepts and values by design. From this lens, this paper\nreviews conceptual foundations to demonstrate philosophical gains and\nalignment. In addition, we present case studies on how ML users/designers can\nadopt PhIML as an agnostic post-hoc tool or intrinsically build it into ML\nmodel architectures. Finally, this paper sheds light on open technical barriers\nalongside philosophical, practical, and governance challenges and outlines a\nresearch roadmap toward safe, philosophy-aware, and ethically responsible\nPhIML.",
    "published": "2025-09-18T21:51:21Z",
    "pdf_url": "http://arxiv.org/pdf/2509.20370v1",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1609.09060v2",
    "title": "Machine Learning Topological States",
    "authors": [
      "Dong-Ling Deng",
      "Xiaopeng Li",
      "S. Das Sarma"
    ],
    "abstract": "Artificial neural networks and machine learning have now reached a new era\nafter several decades of improvement where applications are to explode in many\nfields of science, industry, and technology. Here, we use artificial neural\nnetworks to study an intriguing phenomenon in quantum physics--- the\ntopological phases of matter. We find that certain topological states, either\nsymmetry-protected or with intrinsic topological order, can be represented with\nclassical artificial neural networks. This is demonstrated by using three\nconcrete spin systems, the one-dimensional (1D) symmetry-protected topological\ncluster state and the 2D and 3D toric code states with intrinsic topological\norders. For all three cases we show rigorously that the topological ground\nstates can be represented by short-range neural networks in an \\textit{exact}\nand \\textit{efficient} fashion---the required number of hidden neurons is as\nsmall as the number of physical spins and the number of parameters scales only\n\\textit{linearly} with the system size. For the 2D toric-code model, we find\nthat the proposed short-range neural networks can describe the excited states\nwith abelain anyons and their nontrivial mutual statistics as well. In\naddition, by using reinforcement learning we show that neural networks are\ncapable of finding the topological ground states of non-integrable Hamiltonians\nwith strong interactions and studying their topological phase transitions. Our\nresults demonstrate explicitly the exceptional power of neural networks in\ndescribing topological quantum states, and at the same time provide valuable\nguidance to machine learning of topological phases in generic lattice models.",
    "published": "2016-09-28T19:59:56Z",
    "pdf_url": "http://arxiv.org/pdf/1609.09060v2",
    "categories": [
      "cond-mat.dis-nn",
      "cond-mat.stat-mech",
      "cond-mat.str-el",
      "quant-ph"
    ]
  },
  {
    "arxiv_id": "1511.07883v1",
    "title": "Machine Learning Exciton Dynamics",
    "authors": [
      "Florian Häse",
      "Stéphanie Valleau",
      "Edward Pyzer-Knapp",
      "Alán Aspuru-Guzik"
    ],
    "abstract": "Obtaining the exciton dynamics of large photosynthetic complexes by using\nmixed quantum mechanics/molecular mechanics (QM/MM) is computationally\ndemanding. We propose a machine learning technique, multi-layer perceptrons, as\na tool to reduce the time required to compute excited state energies. With this\napproach we predict time-dependent density functional theory (TDDFT) excited\nstate energies of bacteriochlorophylls in the Fenna-Matthews-Olson (FMO)\ncomplex. Additionally we compute spectral densities and exciton populations\nfrom the predictions. Different methods to determine multi-layer perceptron\ntraining sets are introduced, leading to several initial data selections. In\naddition, we compute spectral densities and exciton populations. Once\nmulti-layer perceptrons are trained, predicting excited state energies was\nfound to be significantly faster than the corresponding QM/MM calculations. We\nshowed that multi-layer perceptrons can successfully reproduce the energies of\nQM/MM calculations to a high degree of accuracy with prediction errors\ncontained within 0.01 eV (0.5%). Spectral densities and exciton dynamics are\nalso in agreement with the TDDFT results. The acceleration and accurate\nprediction of dynamics strongly encourage the combination of machine learning\ntechniques with ab-initio methods.",
    "published": "2015-11-24T21:01:01Z",
    "pdf_url": "http://arxiv.org/pdf/1511.07883v1",
    "categories": [
      "physics.chem-ph",
      "physics.comp-ph"
    ]
  },
  {
    "arxiv_id": "2012.15816v1",
    "title": "Fairness in Machine Learning",
    "authors": [
      "Luca Oneto",
      "Silvia Chiappa"
    ],
    "abstract": "Machine learning based systems are reaching society at large and in many\naspects of everyday life. This phenomenon has been accompanied by concerns\nabout the ethical issues that may arise from the adoption of these\ntechnologies. ML fairness is a recently established area of machine learning\nthat studies how to ensure that biases in the data and model inaccuracies do\nnot lead to models that treat individuals unfavorably on the basis of\ncharacteristics such as e.g. race, gender, disabilities, and sexual or\npolitical orientation. In this manuscript, we discuss some of the limitations\npresent in the current reasoning about fairness and in methods that deal with\nit, and describe some work done by the authors to address them. More\nspecifically, we show how causal Bayesian networks can play an important role\nto reason about and deal with fairness, especially in complex unfairness\nscenarios. We describe how optimal transport theory can be used to develop\nmethods that impose constraints on the full shapes of distributions\ncorresponding to different sensitive attributes, overcoming the limitation of\nmost approaches that approximate fairness desiderata by imposing constraints on\nthe lower order moments or other functions of those distributions. We present a\nunified framework that encompasses methods that can deal with different\nsettings and fairness criteria, and that enjoys strong theoretical guarantees.\nWe introduce an approach to learn fair representations that can generalize to\nunseen tasks. Finally, we describe a technique that accounts for legal\nrestrictions about the use of sensitive attributes.",
    "published": "2020-12-31T18:38:58Z",
    "pdf_url": "http://arxiv.org/pdf/2012.15816v1",
    "categories": [
      "cs.LG",
      "cs.CY",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2303.05911v2",
    "title": "Lifelong Machine Learning Potentials",
    "authors": [
      "Marco Eckhoff",
      "Markus Reiher"
    ],
    "abstract": "Machine learning potentials (MLPs) trained on accurate quantum chemical data\ncan retain the high accuracy, while inflicting little computational demands. On\nthe downside, they need to be trained for each individual system. In recent\nyears, a vast number of MLPs has been trained from scratch because learning\nadditional data typically requires to train again on all data to not forget\npreviously acquired knowledge. Additionally, most common structural descriptors\nof MLPs cannot represent efficiently a large number of different chemical\nelements. In this work, we tackle these problems by introducing\nelement-embracing atom-centered symmetry functions (eeACSFs) which combine\nstructural properties and element information from the periodic table. These\neeACSFs are a key for our development of a lifelong machine learning potential\n(lMLP). Uncertainty quantification can be exploited to transgress a fixed,\npre-trained MLP to arrive at a continuously adapting lMLP, because a predefined\nlevel of accuracy can be ensured. To extend the applicability of an lMLP to new\nsystems, we apply continual learning strategies to enable autonomous and\non-the-fly training on a continuous stream of new data. For the training of\ndeep neural networks, we propose the continual resilient (CoRe) optimizer and\nincremental learning strategies relying on rehearsal of data, regularization of\nparameters, and the architecture of the model.",
    "published": "2023-03-10T13:38:36Z",
    "pdf_url": "http://arxiv.org/pdf/2303.05911v2",
    "categories": [
      "cs.LG",
      "cond-mat.dis-nn",
      "physics.chem-ph",
      "physics.comp-ph"
    ]
  },
  {
    "arxiv_id": "2009.14596v1",
    "title": "Machine Learning and Computational Mathematics",
    "authors": [
      "Weinan E"
    ],
    "abstract": "Neural network-based machine learning is capable of approximating functions\nin very high dimension with unprecedented efficiency and accuracy. This has\nopened up many exciting new possibilities, not just in traditional areas of\nartificial intelligence, but also in scientific computing and computational\nscience. At the same time, machine learning has also acquired the reputation of\nbeing a set of \"black box\" type of tricks, without fundamental principles. This\nhas been a real obstacle for making further progress in machine learning. In\nthis article, we try to address the following two very important questions: (1)\nHow machine learning has already impacted and will further impact computational\nmathematics, scientific computing and computational science? (2) How\ncomputational mathematics, particularly numerical analysis, {can} impact\nmachine learning? We describe some of the most important progress that has been\nmade on these issues. Our hope is to put things into a perspective that will\nhelp to integrate machine learning with computational mathematics.",
    "published": "2020-09-23T23:16:46Z",
    "pdf_url": "http://arxiv.org/pdf/2009.14596v1",
    "categories": [
      "math.NA",
      "cs.LG",
      "cs.NA",
      "stat.ML",
      "68T07, 46E15, 26B35, 26B40"
    ]
  },
  {
    "arxiv_id": "2104.05314v2",
    "title": "Machine learning and deep learning",
    "authors": [
      "Christian Janiesch",
      "Patrick Zschech",
      "Kai Heinrich"
    ],
    "abstract": "Today, intelligent systems that offer artificial intelligence capabilities\noften rely on machine learning. Machine learning describes the capacity of\nsystems to learn from problem-specific training data to automate the process of\nanalytical model building and solve associated tasks. Deep learning is a\nmachine learning concept based on artificial neural networks. For many\napplications, deep learning models outperform shallow machine learning models\nand traditional data analysis approaches. In this article, we summarize the\nfundamentals of machine learning and deep learning to generate a broader\nunderstanding of the methodical underpinning of current intelligent systems. In\nparticular, we provide a conceptual distinction between relevant terms and\nconcepts, explain the process of automated analytical model building through\nmachine learning and deep learning, and discuss the challenges that arise when\nimplementing such intelligent systems in the field of electronic markets and\nnetworked business. These naturally go beyond technological aspects and\nhighlight issues in human-machine interaction and artificial intelligence\nservitization.",
    "published": "2021-04-12T09:54:12Z",
    "pdf_url": "http://arxiv.org/pdf/2104.05314v2",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1301.1575v1",
    "title": "BigDB: Automatic Machine Learning Optimizer",
    "authors": [
      "Anna Pyayt",
      "Michael Gubanov"
    ],
    "abstract": "In this short vision paper, we introduce a machine learning optimizer for\ndata management and describe its architecture and main functionality.",
    "published": "2013-01-06T04:03:29Z",
    "pdf_url": "http://arxiv.org/pdf/1301.1575v1",
    "categories": [
      "cs.DB"
    ]
  },
  {
    "arxiv_id": "1808.00033v3",
    "title": "Techniques for Interpretable Machine Learning",
    "authors": [
      "Mengnan Du",
      "Ninghao Liu",
      "Xia Hu"
    ],
    "abstract": "Interpretable machine learning tackles the important problem that humans\ncannot understand the behaviors of complex machine learning models and how\nthese models arrive at a particular decision. Although many approaches have\nbeen proposed, a comprehensive understanding of the achievements and challenges\nis still lacking. We provide a survey covering existing techniques to increase\nthe interpretability of machine learning models. We also discuss crucial issues\nthat the community should consider in future work such as designing\nuser-friendly explanations and developing comprehensive evaluation metrics to\nfurther push forward the area of interpretable machine learning.",
    "published": "2018-07-31T19:14:39Z",
    "pdf_url": "http://arxiv.org/pdf/1808.00033v3",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2007.07981v1",
    "title": "Differential Replication in Machine Learning",
    "authors": [
      "Irene Unceta",
      "Jordi Nin",
      "Oriol Pujol"
    ],
    "abstract": "When deployed in the wild, machine learning models are usually confronted\nwith data and requirements that constantly vary, either because of changes in\nthe generating distribution or because external constraints change the\nenvironment where the model operates. To survive in such an ecosystem, machine\nlearning models need to adapt to new conditions by evolving over time. The idea\nof model adaptability has been studied from different perspectives. In this\npaper, we propose a solution based on reusing the knowledge acquired by the\nalready deployed machine learning models and leveraging it to train future\ngenerations. This is the idea behind differential replication of machine\nlearning models.",
    "published": "2020-07-15T20:26:49Z",
    "pdf_url": "http://arxiv.org/pdf/2007.07981v1",
    "categories": [
      "cs.LG",
      "stat.ML",
      "cs.LG, stat.ML"
    ]
  },
  {
    "arxiv_id": "2201.06921v1",
    "title": "Can Machine Learning be Moral?",
    "authors": [
      "Miguel Sicart",
      "Irina Shklovski",
      "Mirabelle Jones"
    ],
    "abstract": "The ethics of Machine Learning has become an unavoidable topic in the AI\nCommunity. The deployment of machine learning systems in multiple social\ncontexts has resulted in a closer ethical scrutiny of the design, development,\nand application of these systems. The AI/ML community has come to terms with\nthe imperative to think about the ethical implications of machine learning, not\nonly as a product but also as a practice (Birhane, 2021; Shen et al. 2021). The\ncritical question that is troubling many debates is what can constitute an\nethically accountable machine learning system. In this paper we explore\npossibilities for ethical evaluation of machine learning methodologies. We\nscrutinize techniques, methods and technical practices in machine learning from\na relational ethics perspective, taking into consideration how machine learning\nsystems are part of the world and how they relate to different forms of agency.\nTaking a page from Phil Agre (1997) we use the notion of a critical technical\npractice as a means of analysis of machine learning approaches. Our radical\nproposal is that supervised learning appears to be the only machine learning\nmethod that is ethically defensible.",
    "published": "2021-12-13T07:20:50Z",
    "pdf_url": "http://arxiv.org/pdf/2201.06921v1",
    "categories": [
      "cs.CY",
      "cs.HC"
    ]
  },
  {
    "arxiv_id": "1708.06992v2",
    "title": "Econométrie et Machine Learning",
    "authors": [
      "Arthur Charpentier",
      "Emmanuel Flachaire",
      "Antoine Ly"
    ],
    "abstract": "Econometrics and machine learning seem to have one common goal: to construct\na predictive model, for a variable of interest, using explanatory variables (or\nfeatures). However, these two fields developed in parallel, thus creating two\ndifferent cultures, to paraphrase Breiman (2001). The first was to build\nprobabilistic models to describe economic phenomena. The second uses algorithms\nthat will learn from their mistakes, with the aim, most often to classify\n(sounds, images, etc.). Recently, however, learning models have proven to be\nmore effective than traditional econometric techniques (with a price to pay\nless explanatory power), and above all, they manage to manage much larger data.\nIn this context, it becomes necessary for econometricians to understand what\nthese two cultures are, what opposes them and especially what brings them\ncloser together, in order to appropriate tools developed by the statistical\nlearning community to integrate them into Econometric models.",
    "published": "2017-07-26T21:12:42Z",
    "pdf_url": "http://arxiv.org/pdf/1708.06992v2",
    "categories": [
      "stat.OT",
      "econ.EM"
    ]
  },
  {
    "arxiv_id": "1808.05787v1",
    "title": "Machine Learning Configuration Interaction",
    "authors": [
      "J. P. Coe"
    ],
    "abstract": "We propose the concept of machine learning configuration interaction (MLCI)\nwhereby an artificial neural network is trained on-the-fly to predict important\nnew configurations in an iterative selected configuration interaction\nprocedure. We demonstrate that the neural network can discriminate between\nimportant and unimportant configurations, that it has not been trained on, much\nbetter than by chance. MLCI is then used to find compact wavefunctions for\ncarbon monoxide at both stretched and equilibrium geometries. We also consider\nthe multireference problem of the water molecule with elongated bonds. Results\nare contrasted with those from other ways of selecting configurations:\nfirst-order perturbation, random selection and Monte Carlo configuration\ninteraction. Compared with these other serial calculations, this prototype MLCI\nis competitive in its accuracy, converges in significantly fewer iterations\nthan the stochastic approaches, and requires less time for the higher-accuracy\ncomputations.",
    "published": "2018-08-17T08:10:36Z",
    "pdf_url": "http://arxiv.org/pdf/1808.05787v1",
    "categories": [
      "physics.chem-ph",
      "physics.comp-ph",
      "quant-ph"
    ]
  },
  {
    "arxiv_id": "1903.01879v2",
    "title": "Copying Machine Learning Classifiers",
    "authors": [
      "Irene Unceta",
      "Jordi Nin",
      "Oriol Pujol"
    ],
    "abstract": "We study model-agnostic copies of machine learning classifiers. We develop\nthe theory behind the problem of copying, highlighting its differences with\nthat of learning, and propose a framework to copy the functionality of any\nclassifier using no prior knowledge of its parameters or training data\ndistribution. We identify the different sources of loss and provide guidelines\non how best to generate synthetic sets for the copying process. We further\nintroduce a set of metrics to evaluate copies in practice. We validate our\nframework through extensive experiments using data from a series of well-known\nproblems. We demonstrate the value of copies in use cases where desiderata such\nas interpretability, fairness or productivization constrains need to be\naddressed. Results show that copies can be exploited to enhance existing\nsolutions and improve them adding new features and characteristics.",
    "published": "2019-03-05T15:03:37Z",
    "pdf_url": "http://arxiv.org/pdf/1903.01879v2",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2004.03865v1",
    "title": "Manipulation-Proof Machine Learning",
    "authors": [
      "Daniel Björkegren",
      "Joshua E. Blumenstock",
      "Samsun Knight"
    ],
    "abstract": "An increasing number of decisions are guided by machine learning algorithms.\nIn many settings, from consumer credit to criminal justice, those decisions are\nmade by applying an estimator to data on an individual's observed behavior. But\nwhen consequential decisions are encoded in rules, individuals may\nstrategically alter their behavior to achieve desired outcomes. This paper\ndevelops a new class of estimator that is stable under manipulation, even when\nthe decision rule is fully transparent. We explicitly model the costs of\nmanipulating different behaviors, and identify decision rules that are stable\nin equilibrium. Through a large field experiment in Kenya, we show that\ndecision rules estimated with our strategy-robust method outperform those based\non standard supervised learning approaches.",
    "published": "2020-04-08T08:04:01Z",
    "pdf_url": "http://arxiv.org/pdf/2004.03865v1",
    "categories": [
      "econ.TH",
      "cs.LG",
      "econ.EM"
    ]
  },
  {
    "arxiv_id": "2006.00123v1",
    "title": "Machine Learning Fund Categorizations",
    "authors": [
      "Dhagash Mehta",
      "Dhruv Desai",
      "Jithin Pradeep"
    ],
    "abstract": "Given the surge in popularity of mutual funds (including exchange-traded\nfunds (ETFs)) as a diversified financial investment, a vast variety of mutual\nfunds from various investment management firms and diversification strategies\nhave become available in the market. Identifying similar mutual funds among\nsuch a wide landscape of mutual funds has become more important than ever\nbecause of many applications ranging from sales and marketing to portfolio\nreplication, portfolio diversification and tax loss harvesting. The current\nbest method is data-vendor provided categorization which usually relies on\ncuration by human experts with the help of available data. In this work, we\nestablish that an industry wide well-regarded categorization system is\nlearnable using machine learning and largely reproducible, and in turn\nconstructing a truly data-driven categorization. We discuss the intellectual\nchallenges in learning this man-made system, our results and their\nimplications.",
    "published": "2020-05-29T23:26:14Z",
    "pdf_url": "http://arxiv.org/pdf/2006.00123v1",
    "categories": [
      "q-fin.ST",
      "cs.LG",
      "q-fin.CP",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2002.04640v1",
    "title": "Debugging Machine Learning Pipelines",
    "authors": [
      "Raoni Lourenço",
      "Juliana Freire",
      "Dennis Shasha"
    ],
    "abstract": "Machine learning tasks entail the use of complex computational pipelines to\nreach quantitative and qualitative conclusions. If some of the activities in a\npipeline produce erroneous or uninformative outputs, the pipeline may fail or\nproduce incorrect results. Inferring the root cause of failures and unexpected\nbehavior is challenging, usually requiring much human thought, and is both\ntime-consuming and error-prone. We propose a new approach that makes use of\niteration and provenance to automatically infer the root causes and derive\nsuccinct explanations of failures. Through a detailed experimental evaluation,\nwe assess the cost, precision, and recall of our approach compared to the state\nof the art. Our source code and experimental data will be available for\nreproducibility and enhancement.",
    "published": "2020-02-11T19:13:12Z",
    "pdf_url": "http://arxiv.org/pdf/2002.04640v1",
    "categories": [
      "cs.LG",
      "cs.DB",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1806.03121v3",
    "title": "Machine Learning CICY Threefolds",
    "authors": [
      "Kieran Bull",
      "Yang-Hui He",
      "Vishnu Jejjala",
      "Challenger Mishra"
    ],
    "abstract": "The latest techniques from Neural Networks and Support Vector Machines (SVM)\nare used to investigate geometric properties of Complete Intersection\nCalabi-Yau (CICY) threefolds, a class of manifolds that facilitate string model\nbuilding. An advanced neural network classifier and SVM are employed to (1)\nlearn Hodge numbers and report a remarkable improvement over previous efforts,\n(2) query for favourability, and (3) predict discrete symmetries, a highly\nimbalanced problem to which both Synthetic Minority Oversampling Technique\n(SMOTE) and permutations of the CICY matrix are used to decrease the class\nimbalance and improve performance. In each case study, we employ a genetic\nalgorithm to optimise the hyperparameters of the neural network. We demonstrate\nthat our approach provides quick diagnostic tools capable of shortlisting\nquasi-realistic string models based on compactification over smooth CICYs and\nfurther supports the paradigm that classes of problems in algebraic geometry\ncan be machine learned.",
    "published": "2018-06-08T12:40:04Z",
    "pdf_url": "http://arxiv.org/pdf/1806.03121v3",
    "categories": [
      "hep-th",
      "hep-ph",
      "math.AG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2008.13492v3",
    "title": "Wireless for Machine Learning",
    "authors": [
      "Henrik Hellström",
      "José Mairton B. da Silva Jr",
      "Mohammad Mohammadi Amiri",
      "Mingzhe Chen",
      "Viktoria Fodor",
      "H. Vincent Poor",
      "Carlo Fischione"
    ],
    "abstract": "As data generation increasingly takes place on devices without a wired\nconnection, machine learning (ML) related traffic will be ubiquitous in\nwireless networks. Many studies have shown that traditional wireless protocols\nare highly inefficient or unsustainable to support ML, which creates the need\nfor new wireless communication methods. In this survey, we give an exhaustive\nreview of the state-of-the-art wireless methods that are specifically designed\nto support ML services over distributed datasets. Currently, there are two\nclear themes within the literature, analog over-the-air computation and digital\nradio resource management optimized for ML. This survey gives a comprehensive\nintroduction to these methods, reviews the most important works, highlights\nopen problems, and discusses application scenarios.",
    "published": "2020-08-31T11:09:49Z",
    "pdf_url": "http://arxiv.org/pdf/2008.13492v3",
    "categories": [
      "eess.SP",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2111.14514v1",
    "title": "Naive Automated Machine Learning",
    "authors": [
      "Felix Mohr",
      "Marcel Wever"
    ],
    "abstract": "An essential task of Automated Machine Learning (AutoML) is the problem of\nautomatically finding the pipeline with the best generalization performance on\na given dataset. This problem has been addressed with sophisticated black-box\noptimization techniques such as Bayesian Optimization, Grammar-Based Genetic\nAlgorithms, and tree search algorithms. Most of the current approaches are\nmotivated by the assumption that optimizing the components of a pipeline in\nisolation may yield sub-optimal results. We present Naive AutoML, an approach\nthat does precisely this: It optimizes the different algorithms of a\npre-defined pipeline scheme in isolation. The finally returned pipeline is\nobtained by just taking the best algorithm of each slot. The isolated\noptimization leads to substantially reduced search spaces, and, surprisingly,\nthis approach yields comparable and sometimes even better performance than\ncurrent state-of-the-art optimizers.",
    "published": "2021-11-29T13:12:54Z",
    "pdf_url": "http://arxiv.org/pdf/2111.14514v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2112.08440v5",
    "title": "Climate-Invariant Machine Learning",
    "authors": [
      "Tom Beucler",
      "Pierre Gentine",
      "Janni Yuval",
      "Ankitesh Gupta",
      "Liran Peng",
      "Jerry Lin",
      "Sungduk Yu",
      "Stephan Rasp",
      "Fiaz Ahmed",
      "Paul A. O'Gorman",
      "J. David Neelin",
      "Nicholas J. Lutsko",
      "Michael Pritchard"
    ],
    "abstract": "Projecting climate change is a generalization problem: we extrapolate the\nrecent past using physical models across past, present, and future climates.\nCurrent climate models require representations of processes that occur at\nscales smaller than model grid size, which have been the main source of model\nprojection uncertainty. Recent machine learning (ML) algorithms hold promise to\nimprove such process representations, but tend to extrapolate poorly to climate\nregimes they were not trained on. To get the best of the physical and\nstatistical worlds, we propose a new framework - termed \"climate-invariant\" ML\n- incorporating knowledge of climate processes into ML algorithms, and show\nthat it can maintain high offline accuracy across a wide range of climate\nconditions and configurations in three distinct atmospheric models. Our results\nsuggest that explicitly incorporating physical knowledge into data-driven\nmodels of Earth system processes can improve their consistency, data\nefficiency, and generalizability across climate regimes.",
    "published": "2021-12-14T07:02:57Z",
    "pdf_url": "http://arxiv.org/pdf/2112.08440v5",
    "categories": [
      "cs.LG",
      "physics.ao-ph",
      "physics.comp-ph"
    ]
  },
  {
    "arxiv_id": "2206.00885v1",
    "title": "Coordinated Double Machine Learning",
    "authors": [
      "Nitai Fingerhut",
      "Matteo Sesia",
      "Yaniv Romano"
    ],
    "abstract": "Double machine learning is a statistical method for leveraging complex\nblack-box models to construct approximately unbiased treatment effect estimates\ngiven observational data with high-dimensional covariates, under the assumption\nof a partially linear model. The idea is to first fit on a subset of the\nsamples two non-linear predictive models, one for the continuous outcome of\ninterest and one for the observed treatment, and then to estimate a linear\ncoefficient for the treatment using the remaining samples through a simple\northogonalized regression. While this methodology is flexible and can\naccommodate arbitrary predictive models, typically trained independently of one\nanother, this paper argues that a carefully coordinated learning algorithm for\ndeep neural networks may reduce the estimation bias. The improved empirical\nperformance of the proposed method is demonstrated through numerical\nexperiments on both simulated and real data.",
    "published": "2022-06-02T05:56:21Z",
    "pdf_url": "http://arxiv.org/pdf/2206.00885v1",
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ]
  },
  {
    "arxiv_id": "2306.04734v1",
    "title": "Machine-Learning Kronecker Coefficients",
    "authors": [
      "Kyu-Hwan Lee"
    ],
    "abstract": "The Kronecker coefficients are the decomposition multiplicities of the tensor\nproduct of two irreducible representations of the symmetric group. Unlike the\nLittlewood--Richardson coefficients, which are the analogues for the general\nlinear group, there is no known combinatorial description of the Kronecker\ncoefficients, and it is an NP-hard problem to decide whether a given Kronecker\ncoefficient is zero or not. In this paper, we show that standard\nmachine-learning algorithms such as Nearest Neighbors, Convolutional Neural\nNetworks and Gradient Boosting Decision Trees may be trained to predict whether\na given Kronecker coefficient is zero or not. Our results show that a trained\nmachine can efficiently perform this binary classification with high accuracy\n($\\approx 0.98$).",
    "published": "2023-06-07T19:10:44Z",
    "pdf_url": "http://arxiv.org/pdf/2306.04734v1",
    "categories": [
      "math.RT",
      "math.CO",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2412.11526v3",
    "title": "Probabilities-Informed Machine Learning",
    "authors": [
      "Mohsen Rashki"
    ],
    "abstract": "Machine learning (ML) has emerged as a powerful tool for tackling complex\nregression and classification tasks, yet its success often hinges on the\nquality of training data. This study introduces an ML paradigm inspired by\ndomain knowledge of the structure of output function, akin to physics-informed\nML, but rooted in probabilistic principles rather than physical laws. The\nproposed approach integrates the probabilistic structure of the target variable\n(such as its cumulative distribution function) into the training process. This\nprobabilistic information is obtained from historical data or estimated using\nstructural reliability methods during experimental design. By embedding\ndomain-specific probabilistic insights into the learning process, the technique\nenhances model accuracy and mitigates risks of overfitting and underfitting.\nApplications in regression, image denoising, and classification demonstrate the\napproach's effectiveness in addressing real-world problems.",
    "published": "2024-12-16T08:01:22Z",
    "pdf_url": "http://arxiv.org/pdf/2412.11526v3",
    "categories": [
      "cs.LG",
      "math.PR"
    ]
  },
  {
    "arxiv_id": "2507.10363v1",
    "title": "Machine-Learning to Trust",
    "authors": [
      "Ran Spiegler"
    ],
    "abstract": "Can players sustain long-run trust when their equilibrium beliefs are shaped\nby machine-learning methods that penalize complexity? I study a game in which\nan infinite sequence of agents with one-period recall decides whether to place\ntrust in their immediate successor. The cost of trusting is state-dependent.\nEach player's best response is based on a belief about others' behavior, which\nis a coarse fit of the true population strategy with respect to a partition of\nrelevant contingencies. In equilibrium, this partition minimizes the sum of the\nmean squared prediction error and a complexity penalty proportional to its\nsize. Relative to symmetric mixed-strategy Nash equilibrium, this solution\nconcept significantly narrows the scope for trust.",
    "published": "2025-07-14T15:03:50Z",
    "pdf_url": "http://arxiv.org/pdf/2507.10363v1",
    "categories": [
      "econ.TH"
    ]
  },
  {
    "arxiv_id": "1802.05688v4",
    "title": "Simulation assisted machine learning",
    "authors": [
      "Timo M. Deist",
      "Andrew Patti",
      "Zhaoqi Wang",
      "David Krane",
      "Taylor Sorenson",
      "David Craft"
    ],
    "abstract": "Motivation: In a predictive modeling setting, if sufficient details of the\nsystem behavior are known, one can build and use a simulation for making\npredictions. When sufficient system details are not known, one typically turns\nto machine learning, which builds a black-box model of the system using a large\ndataset of input sample features and outputs. We consider a setting which is\nbetween these two extremes: some details of the system mechanics are known but\nnot enough for creating simulations that can be used to make high quality\npredictions. In this context we propose using approximate simulations to build\na kernel for use in kernelized machine learning methods, such as support vector\nmachines. The results of multiple simulations (under various uncertainty\nscenarios) are used to compute similarity measures between every pair of\nsamples: sample pairs are given a high similarity score if they behave\nsimilarly under a wide range of simulation parameters. These similarity values,\nrather than the original high dimensional feature data, are used to build the\nkernel.\n  Results: We demonstrate and explore the simulation based kernel (SimKern)\nconcept using four synthetic complex systems--three biologically inspired\nmodels and one network flow optimization model. We show that, when the number\nof training samples is small compared to the number of features, the SimKern\napproach dominates over no-prior-knowledge methods. This approach should be\napplicable in all disciplines where predictive models are sought and\ninformative yet approximate simulations are available.\n  Availability: The Python SimKern software, the demonstration models (in\nMATLAB, R), and the datasets are available at\nhttps://github.com/davidcraft/SimKern.",
    "published": "2018-02-15T18:04:34Z",
    "pdf_url": "http://arxiv.org/pdf/1802.05688v4",
    "categories": [
      "stat.ML",
      "cs.LG",
      "q-bio.QM"
    ]
  },
  {
    "arxiv_id": "2409.18397v2",
    "title": "Scientific Machine Learning Seismology",
    "authors": [
      "Tomohisa Okazaki"
    ],
    "abstract": "Scientific machine learning (SciML) is an interdisciplinary research field\nthat integrates machine learning, particularly deep learning, with physics\ntheory to understand and predict complex natural phenomena. By incorporating\nphysical knowledge, SciML reduces the dependency on observational data, which\nis often limited in the natural sciences. In this article, the fundamental\nconcepts of SciML, its applications in seismology, and prospects are described.\nSpecifically, two popular methods are mainly discussed: physics-informed neural\nnetworks (PINNs) and neural operators (NOs). PINNs can address both forward and\ninverse problems by incorporating governing laws into the loss functions. The\nuse of PINNs is expanding into areas such as simultaneous solutions of\ndifferential equations, inference in underdetermined systems, and\nregularization based on physics. These research directions would broaden the\nscope of deep learning in natural sciences. NOs are models designed for\noperator learning, which deals with relationships between infinite-dimensional\nspaces. NOs show promise in modeling the time evolution of complex systems\nbased on observational or simulation data. Since large amounts of data are\noften required, combining NOs with physics-informed learning holds significant\npotential. Finally, SciML is considered from a broader perspective beyond deep\nlearning: statistical (or mathematical) frameworks that integrate observational\ndata with physical principles to model natural phenomena. In seismology,\nmathematically rigorous Bayesian statistics has been developed over the past\ndecades, whereas more flexible and scalable deep learning has only emerged\nrecently. Both approaches can be considered as part of SciML in a broad sense.\nTheoretical and practical insights in both directions would advance SciML\nmethodologies and thereby deepen our understanding of earthquake phenomena.",
    "published": "2024-09-27T02:27:42Z",
    "pdf_url": "http://arxiv.org/pdf/2409.18397v2",
    "categories": [
      "physics.geo-ph",
      "cs.LG",
      "physics.comp-ph"
    ]
  },
  {
    "arxiv_id": "1803.09103v1",
    "title": "Machine Learning and Applied Linguistics",
    "authors": [
      "Sowmya Vajjala"
    ],
    "abstract": "This entry introduces the topic of machine learning and provides an overview\nof its relevance for applied linguistics and language learning. The discussion\nwill focus on giving an introduction to the methods and applications of machine\nlearning in applied linguistics, and will provide references for further study.",
    "published": "2018-03-24T13:08:56Z",
    "pdf_url": "http://arxiv.org/pdf/1803.09103v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2112.02309v2",
    "title": "Machine Learning in Nuclear Physics",
    "authors": [
      "Amber Boehnlein",
      "Markus Diefenthaler",
      "Cristiano Fanelli",
      "Morten Hjorth-Jensen",
      "Tanja Horn",
      "Michelle P. Kuchera",
      "Dean Lee",
      "Witold Nazarewicz",
      "Kostas Orginos",
      "Peter Ostroumov",
      "Long-Gang Pang",
      "Alan Poon",
      "Nobuo Sato",
      "Malachi Schram",
      "Alexander Scheinker",
      "Michael S. Smith",
      "Xin-Nian Wang",
      "Veronique Ziegler"
    ],
    "abstract": "Advances in machine learning methods provide tools that have broad\napplicability in scientific research. These techniques are being applied across\nthe diversity of nuclear physics research topics, leading to advances that will\nfacilitate scientific discoveries and societal applications.\n  This Review gives a snapshot of nuclear physics research which has been\ntransformed by machine learning techniques.",
    "published": "2021-12-04T11:26:00Z",
    "pdf_url": "http://arxiv.org/pdf/2112.02309v2",
    "categories": [
      "nucl-th",
      "cs.LG",
      "hep-ex",
      "nucl-ex"
    ]
  },
  {
    "arxiv_id": "1905.11075v3",
    "title": "Machine Learning for Fluid Mechanics",
    "authors": [
      "Steven Brunton",
      "Bernd Noack",
      "Petros Koumoutsakos"
    ],
    "abstract": "The field of fluid mechanics is rapidly advancing, driven by unprecedented\nvolumes of data from field measurements, experiments and large-scale\nsimulations at multiple spatiotemporal scales. Machine learning offers a wealth\nof techniques to extract information from data that could be translated into\nknowledge about the underlying fluid mechanics. Moreover, machine learning\nalgorithms can augment domain knowledge and automate tasks related to flow\ncontrol and optimization. This article presents an overview of past history,\ncurrent developments, and emerging opportunities of machine learning for fluid\nmechanics. It outlines fundamental machine learning methodologies and discusses\ntheir uses for understanding, modeling, optimizing, and controlling fluid\nflows. The strengths and limitations of these methods are addressed from the\nperspective of scientific inquiry that considers data as an inherent part of\nmodeling, experimentation, and simulation. Machine learning provides a powerful\ninformation processing framework that can enrich, and possibly even transform,\ncurrent lines of fluid mechanics research and industrial applications.",
    "published": "2019-05-27T09:26:17Z",
    "pdf_url": "http://arxiv.org/pdf/1905.11075v3",
    "categories": [
      "physics.flu-dyn",
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1909.01866v1",
    "title": "Understanding Bias in Machine Learning",
    "authors": [
      "Jindong Gu",
      "Daniela Oelke"
    ],
    "abstract": "Bias is known to be an impediment to fair decisions in many domains such as\nhuman resources, the public sector, health care etc. Recently, hope has been\nexpressed that the use of machine learning methods for taking such decisions\nwould diminish or even resolve the problem. At the same time, machine learning\nexperts warn that machine learning models can be biased as well. In this\narticle, our goal is to explain the issue of bias in machine learning from a\ntechnical perspective and to illustrate the impact that biased data can have on\na machine learning model. To reach such a goal, we develop interactive plots to\nvisualizing the bias learned from synthetic data.",
    "published": "2019-09-02T20:36:19Z",
    "pdf_url": "http://arxiv.org/pdf/1909.01866v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2205.08824v1",
    "title": "Automating In-Network Machine Learning",
    "authors": [
      "Changgang Zheng",
      "Mingyuan Zang",
      "Xinpeng Hong",
      "Riyad Bensoussane",
      "Shay Vargaftik",
      "Yaniv Ben-Itzhak",
      "Noa Zilberman"
    ],
    "abstract": "Using programmable network devices to aid in-network machine learning has\nbeen the focus of significant research. However, most of the research was of a\nlimited scope, providing a proof of concept or describing a closed-source\nalgorithm. To date, no general solution has been provided for mapping machine\nlearning algorithms to programmable network devices. In this paper, we present\nPlanter, an open-source, modular framework for mapping trained machine learning\nmodels to programmable devices. Planter supports a wide range of machine\nlearning models, multiple targets and can be easily extended. The evaluation of\nPlanter compares different mapping approaches, and demonstrates the\nfeasibility, performance, and resource efficiency for applications such as\nanomaly detection, financial transactions, and quality of experience.\n  The results show that Planter-based in-network machine learning algorithms\ncan run at line rate, have a negligible effect on latency, coexist with\nstandard switching functionality, and have no or minor accuracy trade-offs.",
    "published": "2022-05-18T09:42:22Z",
    "pdf_url": "http://arxiv.org/pdf/2205.08824v1",
    "categories": [
      "cs.NI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2407.19890v1",
    "title": "Quantum Dynamics of Machine Learning",
    "authors": [
      "Peng Wang",
      "Maimaitiniyazi Maimaitiabudula"
    ],
    "abstract": "The quantum dynamic equation (QDE) of machine learning is obtained based on\nSchr\\\"odinger equation and potential energy equivalence relationship. Through\nWick rotation, the relationship between quantum dynamics and thermodynamics is\nalso established in this paper. This equation reformulates the iterative\nprocess of machine learning into a time-dependent partial differential equation\nwith a clear mathematical structure, offering a theoretical framework for\ninvestigating machine learning iterations through quantum and mathematical\ntheories. Within this framework, the fundamental iterative process, the\ndiffusion model, and the Softmax and Sigmoid functions are examined, validating\nthe proposed quantum dynamics equations. This approach not only presents a\nrigorous theoretical foundation for machine learning but also holds promise for\nsupporting the implementation of machine learning algorithms on quantum\ncomputers.",
    "published": "2024-07-07T16:30:46Z",
    "pdf_url": "http://arxiv.org/pdf/2407.19890v1",
    "categories": [
      "quant-ph",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1803.05252v2",
    "title": "Algebraic Machine Learning",
    "authors": [
      "Fernando Martin-Maroto",
      "Gonzalo G. de Polavieja"
    ],
    "abstract": "Machine learning algorithms use error function minimization to fit a large\nset of parameters in a preexisting model. However, error minimization\neventually leads to a memorization of the training dataset, losing the ability\nto generalize to other datasets. To achieve generalization something else is\nneeded, for example a regularization method or stopping the training when error\nin a validation dataset is minimal. Here we propose a different approach to\nlearning and generalization that is parameter-free, fully discrete and that\ndoes not use function minimization. We use the training data to find an\nalgebraic representation with minimal size and maximal freedom, explicitly\nexpressed as a product of irreducible components. This algebraic representation\nis shown to directly generalize, giving high accuracy in test data, more so the\nsmaller the representation. We prove that the number of generalizing\nrepresentations can be very large and the algebra only needs to find one. We\nalso derive and test a relationship between compression and error rate. We give\nresults for a simple problem solved step by step, hand-written character\nrecognition, and the Queens Completion problem as an example of unsupervised\nlearning. As an alternative to statistical learning, algebraic learning may\noffer advantages in combining bottom-up and top-down information, formal\nconcept derivation from data and large-scale parallelization.",
    "published": "2018-03-14T13:09:35Z",
    "pdf_url": "http://arxiv.org/pdf/1803.05252v2",
    "categories": [
      "cs.LG",
      "cs.DM",
      "math.AC",
      "math.RA"
    ]
  },
  {
    "arxiv_id": "2010.07067v2",
    "title": "Machine Learning Force Fields",
    "authors": [
      "Oliver T. Unke",
      "Stefan Chmiela",
      "Huziel E. Sauceda",
      "Michael Gastegger",
      "Igor Poltavsky",
      "Kristof T. Schütt",
      "Alexandre Tkatchenko",
      "Klaus-Robert Müller"
    ],
    "abstract": "In recent years, the use of Machine Learning (ML) in computational chemistry\nhas enabled numerous advances previously out of reach due to the computational\ncomplexity of traditional electronic-structure methods. One of the most\npromising applications is the construction of ML-based force fields (FFs), with\nthe aim to narrow the gap between the accuracy of ab initio methods and the\nefficiency of classical FFs. The key idea is to learn the statistical relation\nbetween chemical structure and potential energy without relying on a\npreconceived notion of fixed chemical bonds or knowledge about the relevant\ninteractions. Such universal ML approximations are in principle only limited by\nthe quality and quantity of the reference data used to train them. This review\ngives an overview of applications of ML-FFs and the chemical insights that can\nbe obtained from them. The core concepts underlying ML-FFs are described in\ndetail and a step-by-step guide for constructing and testing them from scratch\nis given. The text concludes with a discussion of the challenges that remain to\nbe overcome by the next generation of ML-FFs.",
    "published": "2020-10-14T13:14:14Z",
    "pdf_url": "http://arxiv.org/pdf/2010.07067v2",
    "categories": [
      "physics.chem-ph",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2007.14870v2",
    "title": "Decoding machine learning benchmarks",
    "authors": [
      "Lucas F. F. Cardoso",
      "Vitor C. A. Santos",
      "Regiane S. K. Francês",
      "Ricardo B. C. Prudêncio",
      "Ronnie C. O. Alves"
    ],
    "abstract": "Despite the availability of benchmark machine learning (ML) repositories\n(e.g., UCI, OpenML), there is no standard evaluation strategy yet capable of\npointing out which is the best set of datasets to serve as gold standard to\ntest different ML algorithms. In recent studies, Item Response Theory (IRT) has\nemerged as a new approach to elucidate what should be a good ML benchmark. This\nwork applied IRT to explore the well-known OpenML-CC18 benchmark to identify\nhow suitable it is on the evaluation of classifiers. Several classifiers\nranging from classical to ensembles ones were evaluated using IRT models, which\ncould simultaneously estimate dataset difficulty and classifiers' ability. The\nGlicko-2 rating system was applied on the top of IRT to summarize the innate\nability and aptitude of classifiers. It was observed that not all datasets from\nOpenML-CC18 are really useful to evaluate classifiers. Most datasets evaluated\nin this work (84%) contain easy instances in general (e.g., around 10% of\ndifficult instances only). Also, 80% of the instances in half of this benchmark\nare very discriminating ones, which can be of great use for pairwise algorithm\ncomparison, but not useful to push classifiers abilities. This paper presents\nthis new evaluation methodology based on IRT as well as the tool decodIRT,\ndeveloped to guide IRT estimation over ML benchmarks.",
    "published": "2020-07-29T14:39:41Z",
    "pdf_url": "http://arxiv.org/pdf/2007.14870v2",
    "categories": [
      "cs.LG",
      "stat.ML",
      "I.2.6"
    ]
  },
  {
    "arxiv_id": "2109.10870v1",
    "title": "SoK: Machine Learning Governance",
    "authors": [
      "Varun Chandrasekaran",
      "Hengrui Jia",
      "Anvith Thudi",
      "Adelin Travers",
      "Mohammad Yaghini",
      "Nicolas Papernot"
    ],
    "abstract": "The application of machine learning (ML) in computer systems introduces not\nonly many benefits but also risks to society. In this paper, we develop the\nconcept of ML governance to balance such benefits and risks, with the aim of\nachieving responsible applications of ML. Our approach first systematizes\nresearch towards ascertaining ownership of data and models, thus fostering a\nnotion of identity specific to ML systems. Building on this foundation, we use\nidentities to hold principals accountable for failures of ML systems through\nboth attribution and auditing. To increase trust in ML systems, we then survey\ntechniques for developing assurance, i.e., confidence that the system meets its\nsecurity requirements and does not exhibit certain known failures. This leads\nus to highlight the need for techniques that allow a model owner to manage the\nlife cycle of their system, e.g., to patch or retire their ML system. Put\naltogether, our systematization of knowledge standardizes the interactions\nbetween principals involved in the deployment of ML throughout its life cycle.\nWe highlight opportunities for future work, e.g., to formalize the resulting\ngame between ML principals.",
    "published": "2021-09-20T17:56:22Z",
    "pdf_url": "http://arxiv.org/pdf/2109.10870v1",
    "categories": [
      "cs.CR",
      "cs.LG",
      "cs.SE"
    ]
  },
  {
    "arxiv_id": "2211.14142v2",
    "title": "Machine learning cosmic inflation",
    "authors": [
      "Ahana Kamerkar",
      "Savvas Nesseris",
      "Lucas Pinol"
    ],
    "abstract": "We present a machine-learning approach, based on the genetic algorithms (GA),\nthat can be used to reconstruct the inflationary potential directly from\ncosmological data. We create a pipeline consisting of the GA, a primordial code\nand a Boltzmann code used to calculate the theoretical predictions, and Cosmic\nMicrowave Background (CMB) data. As a proof of concept, we apply our\nmethodology to the Planck CMB data and explore the functional space of\nsingle-field inflationary potentials in a non-parametric, yet analytical way.\nWe show that the algorithm easily improves upon the vanilla model of quadratic\ninflation and proposes slow-roll potentials better suited to the data, while we\nconfirm the robustness of the Starobinsky inflation model (and other\nsmall-field models). Moreover, using unbinned CMB data, we perform a first\nconcrete application of the GA by searching for oscillatory features in the\npotential in an agnostic way, and find very significant improvements upon the\nbest featureless potentials, $\\Delta \\chi^2 < -20$. These encouraging\npreliminary results motivate the search for resonant features in the primordial\npower spectrum with a multimodal distribution of frequencies. We stress that\nour pipeline is modular and can easily be extended to other CMB data sets and\ninflationary scenarios, like multifield inflation or theories with higher-order\nderivatives.",
    "published": "2022-11-25T14:42:55Z",
    "pdf_url": "http://arxiv.org/pdf/2211.14142v2",
    "categories": [
      "astro-ph.CO",
      "gr-qc",
      "hep-ph"
    ]
  },
  {
    "arxiv_id": "2409.02668v2",
    "title": "Introduction to Machine Learning",
    "authors": [
      "Laurent Younes"
    ],
    "abstract": "This book introduces the mathematical foundations and techniques that lead to\nthe development and analysis of many of the algorithms that are used in machine\nlearning. It starts with an introductory chapter that describes notation used\nthroughout the book and serve at a reminder of basic concepts in calculus,\nlinear algebra and probability and also introduces some measure theoretic\nterminology, which can be used as a reading guide for the sections that use\nthese tools. The introductory chapters also provide background material on\nmatrix analysis and optimization. The latter chapter provides theoretical\nsupport to many algorithms that are used in the book, including stochastic\ngradient descent, proximal methods, etc. After discussing basic concepts for\nstatistical prediction, the book includes an introduction to reproducing kernel\ntheory and Hilbert space techniques, which are used in many places, before\naddressing the description of various algorithms for supervised statistical\nlearning, including linear methods, support vector machines, decision trees,\nboosting, or neural networks. The subject then switches to generative methods,\nstarting with a chapter that presents sampling methods and an introduction to\nthe theory of Markov chains. The following chapter describe the theory of\ngraphical models, an introduction to variational methods for models with latent\nvariables, and to deep-learning based generative models. The next chapters\nfocus on unsupervised learning methods, for clustering, factor analysis and\nmanifold learning. The final chapter of the book is theory-oriented and\ndiscusses concentration inequalities and generalization bounds.",
    "published": "2024-09-04T12:51:41Z",
    "pdf_url": "http://arxiv.org/pdf/2409.02668v2",
    "categories": [
      "stat.ML",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2411.00093v3",
    "title": "Machine Learning Electroweakino Production",
    "authors": [
      "Rafał Masełek",
      "Mihoko M. Nojiri",
      "Kazuki Sakurai"
    ],
    "abstract": "The system of light electroweakinos and heavy squarks gives rise to one of\nthe most challenging signatures to detect at the LHC. It consists of missing\ntransverse energy recoiled against a few hadronic jets originating either from\nQCD radiation or squark decays. The analysis generally suffers from the large\nirreducible Z + jets $(Z \\to \\nu \\bar \\nu)$ background. In this study, we\nexplore Machine Learning (ML) methods for efficient signal/background\ndiscrimination. Our best attempt uses both reconstructed (jets, missing\ntransverse energy, etc.) and low-level (particle-flow) objects. We find that\nthe discrimination performance improves as the pT threshold for soft particles\nis lowered from 10 GeV to 1 GeV, at the expense of larger systematic\nuncertainty. In many cases, the ML method provides a factor two enhancement in\n$S/\\sqrt{(S + B)}$ from a simple kinematical selection. The sensitivity on the\nsquark-elecroweakino mass plane is derived with this method, assuming the Run-3\nand HL-LHC luminosities. Moreover, we investigate the relations between input\nfeatures and the network's classification performance to reveal the physical\ninformation used in the background/signal discrimination process.",
    "published": "2024-10-31T18:00:01Z",
    "pdf_url": "http://arxiv.org/pdf/2411.00093v3",
    "categories": [
      "hep-ph",
      "hep-ex"
    ]
  },
  {
    "arxiv_id": "2111.11537v1",
    "title": "Machine Learning for Mars Exploration",
    "authors": [
      "Ali Momennasab"
    ],
    "abstract": "Risk to human astronauts and interplanetary distance causing slow and limited\ncommunication drives scientists to pursue an autonomous approach to exploring\ndistant planets, such as Mars. A portion of exploration of Mars has been\nconducted through the autonomous collection and analysis of Martian data by\nspacecraft such as the Mars rovers and the Mars Express Orbiter. The autonomy\nused on these Mars exploration spacecraft and on Earth to analyze data\ncollected by these vehicles mainly consist of machine learning, a field of\nartificial intelligence where algorithms collect data and self-improve with the\ndata. Additional applications of machine learning techniques for Mars\nexploration have potential to resolve communication limitations and human risks\nof interplanetary exploration. In addition, analyzing Mars data with machine\nlearning has the potential to provide a greater understanding of Mars in\nnumerous domains such as its climate, atmosphere, and potential future\nhabitation. To explore further utilizations of machine learning techniques for\nMars exploration, this paper will first summarize the general features and\nphenomena of Mars to provide a general overview of the planet, elaborate upon\nuncertainties of Mars that would be beneficial to explore and understand,\nsummarize every current or previous usage of machine learning techniques in the\nexploration of Mars, explore implementations of machine learning that will be\nutilized in future Mars exploration missions, and explore machine learning\ntechniques used in Earthly domains to provide solutions to the previously\ndescribed uncertainties of Mars.",
    "published": "2021-11-22T21:11:42Z",
    "pdf_url": "http://arxiv.org/pdf/2111.11537v1",
    "categories": [
      "astro-ph.EP",
      "astro-ph.IM",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1805.03441v1",
    "title": "Machine Learning in Compiler Optimisation",
    "authors": [
      "Zheng Wang",
      "Michael O'Boyle"
    ],
    "abstract": "In the last decade, machine learning based compilation has moved from an an\nobscure research niche to a mainstream activity. In this article, we describe\nthe relationship between machine learning and compiler optimisation and\nintroduce the main concepts of features, models, training and deployment. We\nthen provide a comprehensive survey and provide a road map for the wide variety\nof different research areas. We conclude with a discussion on open issues in\nthe area and potential research directions. This paper provides both an\naccessible introduction to the fast moving area of machine learning based\ncompilation and a detailed bibliography of its main achievements.",
    "published": "2018-05-09T10:04:28Z",
    "pdf_url": "http://arxiv.org/pdf/1805.03441v1",
    "categories": [
      "cs.PL",
      "cs.DC",
      "cs.LG",
      "cs.SE"
    ]
  },
  {
    "arxiv_id": "1812.10422v1",
    "title": "Machine Learning in Official Statistics",
    "authors": [
      "Martin Beck",
      "Florian Dumpert",
      "Joerg Feuerhake"
    ],
    "abstract": "In the first half of 2018, the Federal Statistical Office of Germany\n(Destatis) carried out a \"Proof of Concept Machine Learning\" as part of its\nDigital Agenda. A major component of this was surveys on the use of machine\nlearning methods in official statistics, which were conducted at selected\nnational and international statistical institutions and among the divisions of\nDestatis. It was of particular interest to find out in which statistical areas\nand for which tasks machine learning is used and which methods are applied.\nThis paper is intended to make the results of the surveys publicly accessible.",
    "published": "2018-12-13T11:02:01Z",
    "pdf_url": "http://arxiv.org/pdf/1812.10422v1",
    "categories": [
      "cs.CY",
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2102.05639v1",
    "title": "Energy-Harvesting Distributed Machine Learning",
    "authors": [
      "Basak Guler",
      "Aylin Yener"
    ],
    "abstract": "This paper provides a first study of utilizing energy harvesting for\nsustainable machine learning in distributed networks. We consider a distributed\nlearning setup in which a machine learning model is trained over a large number\nof devices that can harvest energy from the ambient environment, and develop a\npractical learning framework with theoretical convergence guarantees. We\ndemonstrate through numerical experiments that the proposed framework can\nsignificantly outperform energy-agnostic benchmarks. Our framework is scalable,\nrequires only local estimation of the energy statistics, and can be applied to\na wide range of distributed training settings, including machine learning in\nwireless networks, edge computing, and mobile internet of things.",
    "published": "2021-02-10T18:53:51Z",
    "pdf_url": "http://arxiv.org/pdf/2102.05639v1",
    "categories": [
      "cs.LG",
      "cs.IT",
      "math.IT",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1805.05052v17",
    "title": "Machine Learning: The Basics",
    "authors": [
      "Alexander Jung"
    ],
    "abstract": "Machine learning (ML) has become a commodity in our every-day lives. We\nroutinely ask ML empowered smartphones to suggest lovely food places or to\nguide us through a strange place. ML methods have also become standard tools in\nmany fields of science and engineering. A plethora of ML applications transform\nhuman lives at unprecedented pace and scale. This book portrays ML as the\ncombination of three basic components: data, model and loss. ML methods combine\nthese three components within computationally efficient implementations of the\nbasic scientific principle \"trial and error\". This principle consists of the\ncontinuous adaptation of a hypothesis about a phenomenon that generates data.\nML methods use a hypothesis to compute predictions for future events. We\nbelieve that thinking about ML as combinations of three components given by\ndata, model, and loss helps to navigate the steadily growing offer for\nready-to-use ML methods. Our three-component picture of ML allows a unified\ntreatment of a wide range of concepts and techniques which seem quite unrelated\nat first sight. The regularization effect of early stopping in iterative\nmethods is due to the shrinking of the effective hypothesis space.\nPrivacy-preserving ML is obtained by particular choices for the features of\ndata points. Explainable ML methods are characterized by particular choices for\nthe hypothesis space. To make good use of ML tools it is instrumental to\nunderstand its underlying principles at different levels of detail. On a lower\nlevel, this tutorial helps ML engineers to choose suitable methods for the\napplication at hand. The book also offers a higher-level view on the\nimplementation of ML methods which is typically required to manage a team of ML\nengineers and data scientists.",
    "published": "2018-05-14T08:08:33Z",
    "pdf_url": "http://arxiv.org/pdf/1805.05052v17",
    "categories": [
      "cs.LG",
      "stat.ML",
      "97K80, 65Fxx",
      "A.1; I.2; I.5; G.3; G.1"
    ]
  },
  {
    "arxiv_id": "2107.08148v1",
    "title": "Declarative Machine Learning Systems",
    "authors": [
      "Piero Molino",
      "Christopher Ré"
    ],
    "abstract": "In the last years machine learning (ML) has moved from a academic endeavor to\na pervasive technology adopted in almost every aspect of computing. ML-powered\nproducts are now embedded in our digital lives: from recommendations of what to\nwatch, to divining our search intent, to powering virtual assistants in\nconsumer and enterprise settings. Recent successes in applying ML in natural\nsciences revealed that ML can be used to tackle some of the hardest real-world\nproblems humanity faces today. For these reasons ML has become central in the\nstrategy of tech companies and has gathered even more attention from academia\nthan ever before. Despite these successes, what we have witnessed so far is\njust the beginning. Right now the people training and using ML models are\nexpert developers working within large organizations, but we believe the next\nwave of ML systems will allow a larger amount of people, potentially without\ncoding skills, to perform the same tasks. These new ML systems will not require\nusers to fully understand all the details of how models are trained and\nutilized for obtaining predictions. Declarative interfaces are well suited for\nthis goal, by hiding complexity and favouring separation of interests, and can\nlead to increased productivity. We worked on such abstract interfaces by\ndeveloping two declarative ML systems, Overton and Ludwig, that require users\nto declare only their data schema (names and types of inputs) and tasks rather\nthen writing low level ML code. In this article we will describe how ML systems\nare currently structured, highlight important factors for their success and\nadoption, what are the issues current ML systems are facing and how the systems\nwe developed addressed them. Finally we will talk about learnings from the\ndevelopment of ML systems throughout the years and how we believe the next\ngeneration of ML systems will look like.",
    "published": "2021-07-16T23:57:57Z",
    "pdf_url": "http://arxiv.org/pdf/2107.08148v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SE"
    ]
  },
  {
    "arxiv_id": "2010.10981v1",
    "title": "Amnesiac Machine Learning",
    "authors": [
      "Laura Graves",
      "Vineel Nagisetty",
      "Vijay Ganesh"
    ],
    "abstract": "The Right to be Forgotten is part of the recently enacted General Data\nProtection Regulation (GDPR) law that affects any data holder that has data on\nEuropean Union residents. It gives EU residents the ability to request deletion\nof their personal data, including training records used to train machine\nlearning models. Unfortunately, Deep Neural Network models are vulnerable to\ninformation leaking attacks such as model inversion attacks which extract class\ninformation from a trained model and membership inference attacks which\ndetermine the presence of an example in a model's training data. If a malicious\nparty can mount an attack and learn private information that was meant to be\nremoved, then it implies that the model owner has not properly protected their\nuser's rights and their models may not be compliant with the GDPR law. In this\npaper, we present two efficient methods that address this question of how a\nmodel owner or data holder may delete personal data from models in such a way\nthat they may not be vulnerable to model inversion and membership inference\nattacks while maintaining model efficacy. We start by presenting a real-world\nthreat model that shows that simply removing training data is insufficient to\nprotect users. We follow that up with two data removal methods, namely\nUnlearning and Amnesiac Unlearning, that enable model owners to protect\nthemselves against such attacks while being compliant with regulations. We\nprovide extensive empirical analysis that show that these methods are indeed\nefficient, safe to apply, effectively remove learned information about\nsensitive data from trained models while maintaining model efficacy.",
    "published": "2020-10-21T13:14:17Z",
    "pdf_url": "http://arxiv.org/pdf/2010.10981v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ]
  },
  {
    "arxiv_id": "1901.03415v2",
    "title": "Context Aware Machine Learning",
    "authors": [
      "Yun Zeng"
    ],
    "abstract": "We propose a principle for exploring context in machine learning models.\nStarting with a simple assumption that each observation may or may not depend\non its context, a conditional probability distribution is decomposed into two\nparts: context-free and context-sensitive. Then by employing the log-linear\nword production model for relating random variables to their embedding space\nrepresentation and making use of the convexity of natural exponential function,\nwe show that the embedding of an observation can also be decomposed into a\nweighted sum of two vectors, representing its context-free and\ncontext-sensitive parts, respectively. This simple treatment of context\nprovides a unified view of many existing deep learning models, leading to\nrevisions of these models able to achieve significant performance boost.\nSpecifically, our upgraded version of a recent sentence embedding model not\nonly outperforms the original one by a large margin, but also leads to a new,\nprincipled approach for compositing the embeddings of bag-of-words features, as\nwell as a new architecture for modeling attention in deep neural networks. More\nsurprisingly, our new principle provides a novel understanding of the gates and\nequations defined by the long short term memory model, which also leads to a\nnew model that is able to converge significantly faster and achieve much lower\nprediction errors. Furthermore, our principle also inspires a new type of\ngeneric neural network layer that better resembles real biological neurons than\nthe traditional linear mapping plus nonlinear activation based architecture.\nIts multi-layer extension provides a new principle for deep neural networks\nwhich subsumes residual network (ResNet) as its special case, and its extension\nto convolutional neutral network model accounts for irrelevant input (e.g.,\nbackground in an image) in addition to filtering.",
    "published": "2019-01-10T22:12:24Z",
    "pdf_url": "http://arxiv.org/pdf/1901.03415v2",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2007.13086v3",
    "title": "Anonymizing Machine Learning Models",
    "authors": [
      "Abigail Goldsteen",
      "Gilad Ezov",
      "Ron Shmelkin",
      "Micha Moffie",
      "Ariel Farkash"
    ],
    "abstract": "There is a known tension between the need to analyze personal data to drive\nbusiness and privacy concerns. Many data protection regulations, including the\nEU General Data Protection Regulation (GDPR) and the California Consumer\nProtection Act (CCPA), set out strict restrictions and obligations on the\ncollection and processing of personal data. Moreover, machine learning models\nthemselves can be used to derive personal information, as demonstrated by\nrecent membership and attribute inference attacks. Anonymized data, however, is\nexempt from the obligations set out in these regulations. It is therefore\ndesirable to be able to create models that are anonymized, thus also exempting\nthem from those obligations, in addition to providing better protection against\nattacks.\n  Learning on anonymized data typically results in significant degradation in\naccuracy. In this work, we propose a method that is able to achieve better\nmodel accuracy by using the knowledge encoded within the trained model, and\nguiding our anonymization process to minimize the impact on the model's\naccuracy, a process we call accuracy-guided anonymization. We demonstrate that\nby focusing on the model's accuracy rather than generic information loss\nmeasures, our method outperforms state of the art k-anonymity methods in terms\nof the achieved utility, in particular with high values of k and large numbers\nof quasi-identifiers.\n  We also demonstrate that our approach has a similar, and sometimes even\nbetter ability to prevent membership inference attacks as approaches based on\ndifferential privacy, while averting some of their drawbacks such as\ncomplexity, performance overhead and model-specific implementations. This makes\nmodel-guided anonymization a legitimate substitute for such methods and a\npractical approach to creating privacy-preserving models.",
    "published": "2020-07-26T09:29:03Z",
    "pdf_url": "http://arxiv.org/pdf/2007.13086v3",
    "categories": [
      "cs.CR",
      "cs.LG",
      "I.2.6; K.6.5"
    ]
  },
  {
    "arxiv_id": "1712.07143v2",
    "title": "Machine Learning for Vehicular Networks",
    "authors": [
      "Hao Ye",
      "Le Liang",
      "Geoffrey Ye Li",
      "JoonBeom Kim",
      "Lu Lu",
      "May Wu"
    ],
    "abstract": "The emerging vehicular networks are expected to make everyday vehicular\noperation safer, greener, and more efficient, and pave the path to autonomous\ndriving in the advent of the fifth generation (5G) cellular system. Machine\nlearning, as a major branch of artificial intelligence, has been recently\napplied to wireless networks to provide a data-driven approach to solve\ntraditionally challenging problems. In this article, we review recent advances\nin applying machine learning in vehicular networks and attempt to bring more\nattention to this emerging area. After a brief overview of the major concept of\nmachine learning, we present some application examples of machine learning in\nsolving problems arising in vehicular networks. We finally discuss and\nhighlight several open issues that warrant further research.",
    "published": "2017-12-19T19:03:41Z",
    "pdf_url": "http://arxiv.org/pdf/1712.07143v2",
    "categories": [
      "cs.IT",
      "math.IT"
    ]
  },
  {
    "arxiv_id": "1712.09208v1",
    "title": "Machine Learning Cosmic Expansion History",
    "authors": [
      "Deng Wang",
      "Wei Zhang"
    ],
    "abstract": "We use the machine learning techniques, for the first time, to study the\nbackground evolution of the universe in light of 30 cosmic chronometers. From 7\nmachine learning algorithms, using the principle of mean squared error\nminimization on testing set, we find that Bayesian ridge regression is the\noptimal method to extract the information from cosmic chronometers. By use of a\npower-law polynomial expansion, we obtain the first Hubble constant estimation\n$H_0=65.95^{+6.98}_{-6.36}$ km s$^{-1}$ Mpc$^{-1}$ from machine learning. From\nthe view of machine learning, we may rule out a large number of cosmological\nmodels, the number of physical parameters of which containing $H_0$ is larger\nthan 3. Very importantly and interestingly, we find that the parameter spaces\nof 3 specific cosmological models can all be clearly compressed by considering\nboth their explanation and generalization abilities.",
    "published": "2017-12-26T08:37:39Z",
    "pdf_url": "http://arxiv.org/pdf/1712.09208v1",
    "categories": [
      "astro-ph.CO",
      "astro-ph.HE",
      "gr-qc"
    ]
  },
  {
    "arxiv_id": "2006.05604v1",
    "title": "Machine Learning and Control Theory",
    "authors": [
      "Alain Bensoussan",
      "Yiqun Li",
      "Dinh Phan Cao Nguyen",
      "Minh-Binh Tran",
      "Sheung Chi Phillip Yam",
      "Xiang Zhou"
    ],
    "abstract": "We survey in this article the connections between Machine Learning and\nControl Theory. Control Theory provide useful concepts and tools for Machine\nLearning. Conversely Machine Learning can be used to solve large control\nproblems. In the first part of the paper, we develop the connections between\nreinforcement learning and Markov Decision Processes, which are discrete time\ncontrol problems. In the second part, we review the concept of supervised\nlearning and the relation with static optimization. Deep learning which extends\nsupervised learning, can be viewed as a control problem. In the third part, we\npresent the links between stochastic gradient descent and mean-field theory.\nConversely, in the fourth and fifth parts, we review machine learning\napproaches to stochastic control problems, and focus on the deterministic case,\nto explain, more easily, the numerical algorithms.",
    "published": "2020-06-10T01:47:34Z",
    "pdf_url": "http://arxiv.org/pdf/2006.05604v1",
    "categories": [
      "cs.LG",
      "math.OC",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1802.05351v3",
    "title": "Stealing Hyperparameters in Machine Learning",
    "authors": [
      "Binghui Wang",
      "Neil Zhenqiang Gong"
    ],
    "abstract": "Hyperparameters are critical in machine learning, as different\nhyperparameters often result in models with significantly different\nperformance. Hyperparameters may be deemed confidential because of their\ncommercial value and the confidentiality of the proprietary algorithms that the\nlearner uses to learn them. In this work, we propose attacks on stealing the\nhyperparameters that are learned by a learner. We call our attacks\nhyperparameter stealing attacks. Our attacks are applicable to a variety of\npopular machine learning algorithms such as ridge regression, logistic\nregression, support vector machine, and neural network. We evaluate the\neffectiveness of our attacks both theoretically and empirically. For instance,\nwe evaluate our attacks on Amazon Machine Learning. Our results demonstrate\nthat our attacks can accurately steal hyperparameters. We also study\ncountermeasures. Our results highlight the need for new defenses against our\nhyperparameter stealing attacks for certain machine learning algorithms.",
    "published": "2018-02-14T22:58:31Z",
    "pdf_url": "http://arxiv.org/pdf/1802.05351v3",
    "categories": [
      "cs.CR",
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1807.04162v3",
    "title": "TherML: Thermodynamics of Machine Learning",
    "authors": [
      "Alexander A. Alemi",
      "Ian Fischer"
    ],
    "abstract": "In this work we offer a framework for reasoning about a wide class of\nexisting objectives in machine learning. We develop a formal correspondence\nbetween this work and thermodynamics and discuss its implications.",
    "published": "2018-07-11T14:39:17Z",
    "pdf_url": "http://arxiv.org/pdf/1807.04162v3",
    "categories": [
      "cs.LG",
      "cond-mat.stat-mech",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1907.08908v1",
    "title": "Techniques for Automated Machine Learning",
    "authors": [
      "Yi-Wei Chen",
      "Qingquan Song",
      "Xia Hu"
    ],
    "abstract": "Automated machine learning (AutoML) aims to find optimal machine learning\nsolutions automatically given a machine learning problem. It could release the\nburden of data scientists from the multifarious manual tuning process and\nenable the access of domain experts to the off-the-shelf machine learning\nsolutions without extensive experience. In this paper, we review the current\ndevelopments of AutoML in terms of three categories, automated feature\nengineering (AutoFE), automated model and hyperparameter learning (AutoMHL),\nand automated deep learning (AutoDL). State-of-the-art techniques adopted in\nthe three categories are presented, including Bayesian optimization,\nreinforcement learning, evolutionary algorithm, and gradient-based approaches.\nWe summarize popular AutoML frameworks and conclude with current open\nchallenges of AutoML.",
    "published": "2019-07-21T04:03:36Z",
    "pdf_url": "http://arxiv.org/pdf/1907.08908v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1910.08605v2",
    "title": "Machine learning Calabi-Yau metrics",
    "authors": [
      "Anthony Ashmore",
      "Yang-Hui He",
      "Burt Ovrut"
    ],
    "abstract": "We apply machine learning to the problem of finding numerical Calabi-Yau\nmetrics. Building on Donaldson's algorithm for calculating balanced metrics on\nK\\\"ahler manifolds, we combine conventional curve fitting and machine-learning\ntechniques to numerically approximate Ricci-flat metrics. We show that machine\nlearning is able to predict the Calabi-Yau metric and quantities associated\nwith it, such as its determinant, having seen only a small sample of training\ndata. Using this in conjunction with a straightforward curve fitting routine,\nwe demonstrate that it is possible to find highly accurate numerical metrics\nmuch more quickly than by using Donaldson's algorithm alone, with our new\nmachine-learning algorithm decreasing the time required by between one and two\norders of magnitude.",
    "published": "2019-10-18T19:53:34Z",
    "pdf_url": "http://arxiv.org/pdf/1910.08605v2",
    "categories": [
      "hep-th",
      "math.AG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2007.01503v1",
    "title": "Mathematical Perspective of Machine Learning",
    "authors": [
      "Yarema Boryshchak"
    ],
    "abstract": "We take a closer look at some theoretical challenges of Machine Learning as a\nfunction approximation, gradient descent as the default optimization algorithm,\nlimitations of fixed length and width networks and a different approach to RNNs\nfrom a mathematical perspective.",
    "published": "2020-07-03T05:26:02Z",
    "pdf_url": "http://arxiv.org/pdf/2007.01503v1",
    "categories": [
      "cs.LG",
      "stat.ML",
      "68T07"
    ]
  },
  {
    "arxiv_id": "1805.03362v3",
    "title": "Attractor Reconstruction by Machine Learning",
    "authors": [
      "Zhixin Lu",
      "Brian R. Hunt",
      "Edward Ott"
    ],
    "abstract": "A machine-learning approach called \"reservoir computing\" has been used\nsuccessfully for short-term prediction and attractor reconstruction of chaotic\ndynamical systems from time series data. We present a theoretical framework\nthat describes conditions under which reservoir computing can create an\nempirical model capable of skillful short-term forecasts and accurate long-term\nergodic behavior. We illustrate this theory through numerical experiments. We\nalso argue that the theory applies to certain other machine learning methods\nfor time series prediction.",
    "published": "2018-05-09T03:44:13Z",
    "pdf_url": "http://arxiv.org/pdf/1805.03362v3",
    "categories": [
      "nlin.CD"
    ]
  },
  {
    "arxiv_id": "2202.02414v2",
    "title": "OMLT: Optimization & Machine Learning Toolkit",
    "authors": [
      "Francesco Ceccon",
      "Jordan Jalving",
      "Joshua Haddad",
      "Alexander Thebelt",
      "Calvin Tsay",
      "Carl D. Laird",
      "Ruth Misener"
    ],
    "abstract": "The optimization and machine learning toolkit (OMLT) is an open-source\nsoftware package incorporating neural network and gradient-boosted tree\nsurrogate models, which have been trained using machine learning, into larger\noptimization problems. We discuss the advances in optimization technology that\nmade OMLT possible and show how OMLT seamlessly integrates with the algebraic\nmodeling language Pyomo. We demonstrate how to use OMLT for solving\ndecision-making problems in both computer science and engineering.",
    "published": "2022-02-04T22:23:45Z",
    "pdf_url": "http://arxiv.org/pdf/2202.02414v2",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "math.OC"
    ]
  },
  {
    "arxiv_id": "1502.02127v2",
    "title": "Hyperparameter Search in Machine Learning",
    "authors": [
      "Marc Claesen",
      "Bart De Moor"
    ],
    "abstract": "We introduce the hyperparameter search problem in the field of machine\nlearning and discuss its main challenges from an optimization perspective.\nMachine learning methods attempt to build models that capture some element of\ninterest based on given data. Most common learning algorithms feature a set of\nhyperparameters that must be determined before training commences. The choice\nof hyperparameters can significantly affect the resulting model's performance,\nbut determining good values can be complex; hence a disciplined, theoretically\nsound search strategy is essential.",
    "published": "2015-02-07T11:46:22Z",
    "pdf_url": "http://arxiv.org/pdf/1502.02127v2",
    "categories": [
      "cs.LG",
      "stat.ML",
      "G.1.6; I.2.6; I.2.8; I.5"
    ]
  },
  {
    "arxiv_id": "2106.07032v1",
    "title": "Category Theory in Machine Learning",
    "authors": [
      "Dan Shiebler",
      "Bruno Gavranović",
      "Paul Wilson"
    ],
    "abstract": "Over the past two decades machine learning has permeated almost every realm\nof technology. At the same time, many researchers have begun using category\ntheory as a unifying language, facilitating communication between different\nscientific disciplines. It is therefore unsurprising that there is a burgeoning\ninterest in applying category theory to machine learning. We aim to document\nthe motivations, goals and common themes across these applications. We touch on\ngradient-based learning, probability, and equivariant learning.",
    "published": "2021-06-13T15:58:13Z",
    "pdf_url": "http://arxiv.org/pdf/2106.07032v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2111.02508v1",
    "title": "AlphaD3M: Machine Learning Pipeline Synthesis",
    "authors": [
      "Iddo Drori",
      "Yamuna Krishnamurthy",
      "Remi Rampin",
      "Raoni de Paula Lourenco",
      "Jorge Piazentin Ono",
      "Kyunghyun Cho",
      "Claudio Silva",
      "Juliana Freire"
    ],
    "abstract": "We introduce AlphaD3M, an automatic machine learning (AutoML) system based on\nmeta reinforcement learning using sequence models with self play. AlphaD3M is\nbased on edit operations performed over machine learning pipeline primitives\nproviding explainability. We compare AlphaD3M with state-of-the-art AutoML\nsystems: Autosklearn, Autostacker, and TPOT, on OpenML datasets. AlphaD3M\nachieves competitive performance while being an order of magnitude faster,\nreducing computation time from hours to minutes, and is explainable by design.",
    "published": "2021-11-03T20:18:48Z",
    "pdf_url": "http://arxiv.org/pdf/2111.02508v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2412.20588v2",
    "title": "Kryptonite-N: Machine Learning Strikes Back",
    "authors": [
      "Albus Li",
      "Nathan Bailey",
      "Will Sumerfield",
      "Kira Kim"
    ],
    "abstract": "Quinn et al propose challenge datasets in their work called ``Kryptonite-N\".\nThese datasets aim to counter the universal function approximation argument of\nmachine learning, breaking the notation that machine learning can ``approximate\nany continuous function\" \\cite{original_paper}. Our work refutes this claim and\nshows that universal function approximations can be applied successfully; the\nKryptonite datasets are constructed predictably, allowing logistic regression\nwith sufficient polynomial expansion and L1 regularization to solve for any\ndimension N.",
    "published": "2024-12-29T21:23:09Z",
    "pdf_url": "http://arxiv.org/pdf/2412.20588v2",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2009.10050v2",
    "title": "Measuring justice in machine learning",
    "authors": [
      "Alan Lundgard"
    ],
    "abstract": "How can we build more just machine learning systems? To answer this question,\nwe need to know both what justice is and how to tell whether one system is more\nor less just than another. That is, we need both a definition and a measure of\njustice. Theories of distributive justice hold that justice can be measured (in\npart) in terms of the fair distribution of benefits and burdens across people\nin society. Recently, the field known as fair machine learning has turned to\nJohn Rawls's theory of distributive justice for inspiration and\noperationalization. However, philosophers known as capability theorists have\nlong argued that Rawls's theory uses the wrong measure of justice, thereby\nencoding biases against people with disabilities. If these theorists are right,\nis it possible to operationalize Rawls's theory in machine learning systems\nwithout also encoding its biases? In this paper, I draw on examples from fair\nmachine learning to suggest that the answer to this question is no: the\ncapability theorists' arguments against Rawls's theory carry over into machine\nlearning systems. But capability theorists don't only argue that Rawls's theory\nuses the wrong measure, they also offer an alternative measure. Which measure\nof justice is right? And has fair machine learning been using the wrong one?",
    "published": "2020-09-21T17:46:11Z",
    "pdf_url": "http://arxiv.org/pdf/2009.10050v2",
    "categories": [
      "cs.CY",
      "I.2.0; K.4.1; J.1.0"
    ]
  },
  {
    "arxiv_id": "2507.23455v1",
    "title": "Machine learning and machine learned prediction in chest X-ray images",
    "authors": [
      "Shereiff Garrett",
      "Abhinav Adhikari",
      "Sarina Gautam",
      "DaShawn Marquis Morris",
      "Chandra Mani Adhikari"
    ],
    "abstract": "Machine learning and artificial intelligence are fast-growing fields of\nresearch in which data is used to train algorithms, learn patterns, and make\npredictions. This approach helps to solve seemingly intricate problems with\nsignificant accuracy without explicit programming by recognizing complex\nrelationships in data. Taking an example of 5824 chest X-ray images, we\nimplement two machine learning algorithms, namely, a baseline convolutional\nneural network (CNN) and a DenseNet-121, and present our analysis in making\nmachine-learned predictions in predicting patients with ailments. Both baseline\nCNN and DenseNet-121 perform very well in the binary classification problem\npresented in this work. Gradient-weighted class activation mapping shows that\nDenseNet-121 correctly focuses on essential parts of the input chest X-ray\nimages in its decision-making more than the baseline CNN.",
    "published": "2025-07-31T11:31:25Z",
    "pdf_url": "http://arxiv.org/pdf/2507.23455v1",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2102.12712v1",
    "title": "Machine Learning for Scientific Discovery",
    "authors": [
      "Shraddha Surana",
      "Yogesh Wadadekar",
      "Divya Oberoi"
    ],
    "abstract": "Machine Learning algorithms are good tools for both classification and\nprediction purposes. These algorithms can further be used for scientific\ndiscoveries from the enormous data being collected in our era. We present ways\nof discovering and understanding astronomical phenomena by applying machine\nlearning algorithms to data collected with radio telescopes. We discuss the use\nof supervised machine learning algorithms to predict the free parameters of\nstar formation histories and also better understand the relations between the\ndifferent input and output parameters. We made use of Deep Learning to capture\nthe non-linearity in the parameters. Our models are able to predict with low\nerror rates and give the advantage of predicting in real time once the model\nhas been trained. The other class of machine learning algorithms viz.\nunsupervised learning can prove to be very useful in finding patterns in the\ndata. We explore how we use such unsupervised techniques on solar radio data to\nidentify patterns and variations, and also link such findings to theories,\nwhich help to better understand the nature of the system being studied. We\nhighlight the challenges faced in terms of data size, availability, features,\nprocessing ability and importantly, the interpretability of results. As our\nability to capture and store data increases, increased use of machine learning\nto understand the underlying physics in the information captured seems\ninevitable.",
    "published": "2021-02-25T07:22:33Z",
    "pdf_url": "http://arxiv.org/pdf/2102.12712v1",
    "categories": [
      "astro-ph.IM"
    ]
  },
  {
    "arxiv_id": "2301.13724v2",
    "title": "Towards fully covariant machine learning",
    "authors": [
      "Soledad Villar",
      "David W. Hogg",
      "Weichi Yao",
      "George A. Kevrekidis",
      "Bernhard Schölkopf"
    ],
    "abstract": "Any representation of data involves arbitrary investigator choices. Because\nthose choices are external to the data-generating process, each choice leads to\nan exact symmetry, corresponding to the group of transformations that takes one\npossible representation to another. These are the passive symmetries; they\ninclude coordinate freedom, gauge symmetry, and units covariance, all of which\nhave led to important results in physics. In machine learning, the most visible\npassive symmetry is the relabeling or permutation symmetry of graphs. Our goal\nis to understand the implications for machine learning of the many passive\nsymmetries in play. We discuss dos and don'ts for machine learning practice if\npassive symmetries are to be respected. We discuss links to causal modeling,\nand argue that the implementation of passive symmetries is particularly\nvaluable when the goal of the learning problem is to generalize out of sample.\nThis paper is conceptual: It translates among the languages of physics,\nmathematics, and machine-learning. We believe that consideration and\nimplementation of passive symmetries might help machine learning in the same\nways that it transformed physics in the twentieth century.",
    "published": "2023-01-31T16:01:12Z",
    "pdf_url": "http://arxiv.org/pdf/2301.13724v2",
    "categories": [
      "stat.ML",
      "astro-ph.IM",
      "cs.LG",
      "math-ph",
      "math.MP",
      "physics.data-an"
    ]
  },
  {
    "arxiv_id": "2306.00061v2",
    "title": "Shadows of quantum machine learning",
    "authors": [
      "Sofiene Jerbi",
      "Casper Gyurik",
      "Simon C. Marshall",
      "Riccardo Molteni",
      "Vedran Dunjko"
    ],
    "abstract": "Quantum machine learning is often highlighted as one of the most promising\npractical applications for which quantum computers could provide a\ncomputational advantage. However, a major obstacle to the widespread use of\nquantum machine learning models in practice is that these models, even once\ntrained, still require access to a quantum computer in order to be evaluated on\nnew data. To solve this issue, we introduce a new class of quantum models where\nquantum resources are only required during training, while the deployment of\nthe trained model is classical. Specifically, the training phase of our models\nends with the generation of a 'shadow model' from which the classical\ndeployment becomes possible. We prove that: i) this class of models is\nuniversal for classically-deployed quantum machine learning; ii) it does have\nrestricted learning capacities compared to 'fully quantum' models, but\nnonetheless iii) it achieves a provable learning advantage over fully classical\nlearners, contingent on widely-believed assumptions in complexity theory. These\nresults provide compelling evidence that quantum machine learning can confer\nlearning advantages across a substantially broader range of scenarios, where\nquantum computers are exclusively employed during the training phase. By\nenabling classical deployment, our approach facilitates the implementation of\nquantum machine learning models in various practical contexts.",
    "published": "2023-05-31T18:00:02Z",
    "pdf_url": "http://arxiv.org/pdf/2306.00061v2",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1303.2739v1",
    "title": "Machine Learning for Bioclimatic Modelling",
    "authors": [
      "Maumita Bhattacharya"
    ],
    "abstract": "Many machine learning (ML) approaches are widely used to generate bioclimatic\nmodels for prediction of geographic range of organism as a function of climate.\nApplications such as prediction of range shift in organism, range of invasive\nspecies influenced by climate change are important parameters in understanding\nthe impact of climate change. However, success of machine learning-based\napproaches depends on a number of factors. While it can be safely said that no\nparticular ML technique can be effective in all applications and success of a\ntechnique is predominantly dependent on the application or the type of the\nproblem, it is useful to understand their behavior to ensure informed choice of\ntechniques. This paper presents a comprehensive review of machine\nlearning-based bioclimatic model generation and analyses the factors\ninfluencing success of such models. Considering the wide use of statistical\ntechniques, in our discussion we also include conventional statistical\ntechniques used in bioclimatic modelling.",
    "published": "2013-03-12T01:13:44Z",
    "pdf_url": "http://arxiv.org/pdf/1303.2739v1",
    "categories": [
      "cs.LG",
      "stat.AP",
      "97R30"
    ]
  },
  {
    "arxiv_id": "1607.01224v1",
    "title": "Machine Learning for Antimicrobial Resistance",
    "authors": [
      "John W. Santerre",
      "James J. Davis",
      "Fangfang Xia",
      "Rick Stevens"
    ],
    "abstract": "Biological datasets amenable to applied machine learning are more available\ntoday than ever before, yet they lack adequate representation in the\nData-for-Good community. Here we present a work in progress case study\nperforming analysis on antimicrobial resistance (AMR) using standard ensemble\nmachine learning techniques and note the successes and pitfalls such work\nentails. Broadly, applied machine learning (AML) techniques are well suited to\nAMR, with classification accuracies ranging from mid-90% to low- 80% depending\non sample size. Additionally, these techniques prove successful at identifying\ngene regions known to be associated with the AMR phenotype. We believe that the\nextensive amount of biological data available, the plethora of problems\npresented, and the global impact of such work merits the consideration of the\nData- for-Good community.",
    "published": "2016-07-05T12:42:01Z",
    "pdf_url": "http://arxiv.org/pdf/1607.01224v1",
    "categories": [
      "stat.ML",
      "q-bio.QM"
    ]
  },
  {
    "arxiv_id": "1708.00909v4",
    "title": "Machine learning for neural decoding",
    "authors": [
      "Joshua I. Glaser",
      "Ari S. Benjamin",
      "Raeed H. Chowdhury",
      "Matthew G. Perich",
      "Lee E. Miller",
      "Konrad P. Kording"
    ],
    "abstract": "Despite rapid advances in machine learning tools, the majority of neural\ndecoding approaches still use traditional methods. Modern machine learning\ntools, which are versatile and easy to use, have the potential to significantly\nimprove decoding performance. This tutorial describes how to effectively apply\nthese algorithms for typical decoding problems. We provide descriptions, best\npractices, and code for applying common machine learning methods, including\nneural networks and gradient boosting. We also provide detailed comparisons of\nthe performance of various methods at the task of decoding spiking activity in\nmotor cortex, somatosensory cortex, and hippocampus. Modern methods,\nparticularly neural networks and ensembles, significantly outperform\ntraditional approaches, such as Wiener and Kalman filters. Improving the\nperformance of neural decoding algorithms allows neuroscientists to better\nunderstand the information contained in a neural population and can help\nadvance engineering applications such as brain machine interfaces.",
    "published": "2017-08-02T19:53:22Z",
    "pdf_url": "http://arxiv.org/pdf/1708.00909v4",
    "categories": [
      "q-bio.NC",
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2101.00755v1",
    "title": "Machine Learning for Robotic Manipulation",
    "authors": [
      "Quan Vuong"
    ],
    "abstract": "The past decade has witnessed the tremendous successes of machine learning\ntechniques in the supervised learning paradigm, where there is a clear\ndemarcation between training and testing. In the supervised learning paradigm,\nlearning is inherently passive, seeking to distill human-provided supervision\nin large-scale datasets into high capacity models. Following these successes,\nmachine learning researchers have looked beyond this paradigm and became\ninterested in tasks that are more dynamic. To them, robotics serve as an\nexcellent test-bed, for the challenges of robotics break many of the\nassumptions that made supervised learning successful. Out of the many different\nareas within robotics, robotic manipulation has become a favorite area for\nresearchers to demonstrate new algorithms because of the vast numbers of\npossible applications and its highly dynamical and complex nature. This\ndocument surveys recent robotics conferences and identifies the major trends\nwith which machine learning techniques have been applied to the challenges of\nrobotic manipulation.",
    "published": "2021-01-04T03:42:07Z",
    "pdf_url": "http://arxiv.org/pdf/2101.00755v1",
    "categories": [
      "cs.RO"
    ]
  },
  {
    "arxiv_id": "1911.02792v1",
    "title": "Machine learning for molecular simulation",
    "authors": [
      "Frank Noé",
      "Alexandre Tkatchenko",
      "Klaus-Robert Müller",
      "Cecilia Clementi"
    ],
    "abstract": "Machine learning (ML) is transforming all areas of science. The complex and\ntime-consuming calculations in molecular simulations are particularly suitable\nfor a machine learning revolution and have already been profoundly impacted by\nthe application of existing ML methods. Here we review recent ML methods for\nmolecular simulation, with particular focus on (deep) neural networks for the\nprediction of quantum-mechanical energies and forces, coarse-grained molecular\ndynamics, the extraction of free energy surfaces and kinetics and generative\nnetwork approaches to sample molecular equilibrium structures and compute\nthermodynamics. To explain these methods and illustrate open methodological\nproblems, we review some important principles of molecular physics and describe\nhow they can be incorporated into machine learning structures. Finally, we\nidentify and describe a list of open challenges for the interface between ML\nand molecular simulation.",
    "published": "2019-11-07T08:14:18Z",
    "pdf_url": "http://arxiv.org/pdf/1911.02792v1",
    "categories": [
      "physics.chem-ph",
      "cs.LG",
      "physics.comp-ph",
      "quant-ph"
    ]
  },
  {
    "arxiv_id": "2002.05648v3",
    "title": "Politics of Adversarial Machine Learning",
    "authors": [
      "Kendra Albert",
      "Jonathon Penney",
      "Bruce Schneier",
      "Ram Shankar Siva Kumar"
    ],
    "abstract": "In addition to their security properties, adversarial machine-learning\nattacks and defenses have political dimensions. They enable or foreclose\ncertain options for both the subjects of the machine learning systems and for\nthose who deploy them, creating risks for civil liberties and human rights. In\nthis paper, we draw on insights from science and technology studies,\nanthropology, and human rights literature, to inform how defenses against\nadversarial attacks can be used to suppress dissent and limit attempts to\ninvestigate machine learning systems. To make this concrete, we use real-world\nexamples of how attacks such as perturbation, model inversion, or membership\ninference can be used for socially desirable ends. Although the predictions of\nthis analysis may seem dire, there is hope. Efforts to address human rights\nconcerns in the commercial spyware industry provide guidance for similar\nmeasures to ensure ML systems serve democratic, not authoritarian ends",
    "published": "2020-02-01T01:15:39Z",
    "pdf_url": "http://arxiv.org/pdf/2002.05648v3",
    "categories": [
      "cs.CY",
      "cs.CR",
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1806.10920v1",
    "title": "Machine Learning for Mathematical Software",
    "authors": [
      "M. England"
    ],
    "abstract": "While there has been some discussion on how Symbolic Computation could be\nused for AI there is little literature on applications in the other direction.\nHowever, recent results for quantifier elimination suggest that, given enough\nexample problems, there is scope for machine learning tools like Support Vector\nMachines to improve the performance of Computer Algebra Systems. We survey the\nauthors own work and similar applications for other mathematical software.\n  It may seem that the inherently probabilistic nature of machine learning\ntools would invalidate the exact results prized by mathematical software.\nHowever, algorithms and implementations often come with a range of choices\nwhich have no effect on the mathematical correctness of the end result but a\ngreat effect on the resources required to find it, and thus here, machine\nlearning can have a significant impact.",
    "published": "2018-06-28T12:35:47Z",
    "pdf_url": "http://arxiv.org/pdf/1806.10920v1",
    "categories": [
      "cs.SC",
      "68T05, 68W30",
      "I.2.6; I.1.0"
    ]
  },
  {
    "arxiv_id": "2003.11040v2",
    "title": "Machine Learning for Quantum Matter",
    "authors": [
      "Juan Carrasquilla"
    ],
    "abstract": "Quantum matter, the research field studying phases of matter whose properties\nare intrinsically quantum mechanical, draws from areas as diverse as hard\ncondensed matter physics, materials science, statistical mechanics, quantum\ninformation, quantum gravity, and large-scale numerical simulations. Recently,\nresearchers interested quantum matter and strongly correlated quantum systems\nhave turned their attention to the algorithms underlying modern machine\nlearning with an eye on making progress in their fields. Here we provide a\nshort review on the recent development and adaptation of machine learning ideas\nfor the purpose advancing research in quantum matter, including ideas ranging\nfrom algorithms that recognize conventional and topological states of matter in\nsynthetic an experimental data, to representations of quantum states in terms\nof neural networks and their applications to the simulation and control of\nquantum systems. We discuss the outlook for future developments in areas at the\nintersection between machine learning and quantum many-body physics.",
    "published": "2020-03-24T18:00:30Z",
    "pdf_url": "http://arxiv.org/pdf/2003.11040v2",
    "categories": [
      "physics.comp-ph",
      "cond-mat.str-el",
      "quant-ph"
    ]
  },
  {
    "arxiv_id": "2102.09449v2",
    "title": "Quantum field-theoretic machine learning",
    "authors": [
      "Dimitrios Bachtis",
      "Gert Aarts",
      "Biagio Lucini"
    ],
    "abstract": "We derive machine learning algorithms from discretized Euclidean field\ntheories, making inference and learning possible within dynamics described by\nquantum field theory. Specifically, we demonstrate that the $\\phi^{4}$ scalar\nfield theory satisfies the Hammersley-Clifford theorem, therefore recasting it\nas a machine learning algorithm within the mathematically rigorous framework of\nMarkov random fields. We illustrate the concepts by minimizing an asymmetric\ndistance between the probability distribution of the $\\phi^{4}$ theory and that\nof target distributions, by quantifying the overlap of statistical ensembles\nbetween probability distributions and through reweighting to complex-valued\nactions with longer-range interactions. Neural network architectures are\nadditionally derived from the $\\phi^{4}$ theory which can be viewed as\ngeneralizations of conventional neural networks and applications are presented.\nWe conclude by discussing how the proposal opens up a new research avenue, that\nof developing a mathematical and computational framework of machine learning\nwithin quantum field theory.",
    "published": "2021-02-18T16:12:51Z",
    "pdf_url": "http://arxiv.org/pdf/2102.09449v2",
    "categories": [
      "hep-lat",
      "cond-mat.dis-nn",
      "cond-mat.stat-mech",
      "cs.LG",
      "hep-th"
    ]
  },
  {
    "arxiv_id": "2210.09084v1",
    "title": "Multi-Agent Automated Machine Learning",
    "authors": [
      "Zhaozhi Wang",
      "Kefan Su",
      "Jian Zhang",
      "Huizhu Jia",
      "Qixiang Ye",
      "Xiaodong Xie",
      "Zongqing Lu"
    ],
    "abstract": "In this paper, we propose multi-agent automated machine learning (MA2ML) with\nthe aim to effectively handle joint optimization of modules in automated\nmachine learning (AutoML). MA2ML takes each machine learning module, such as\ndata augmentation (AUG), neural architecture search (NAS), or hyper-parameters\n(HPO), as an agent and the final performance as the reward, to formulate a\nmulti-agent reinforcement learning problem. MA2ML explicitly assigns credit to\neach agent according to its marginal contribution to enhance cooperation among\nmodules, and incorporates off-policy learning to improve search efficiency.\nTheoretically, MA2ML guarantees monotonic improvement of joint optimization.\nExtensive experiments show that MA2ML yields the state-of-the-art top-1\naccuracy on ImageNet under constraints of computational cost, e.g.,\n$79.7\\%/80.5\\%$ with FLOPs fewer than 600M/800M. Extensive ablation studies\nverify the benefits of credit assignment and off-policy learning of MA2ML.",
    "published": "2022-10-17T13:32:59Z",
    "pdf_url": "http://arxiv.org/pdf/2210.09084v1",
    "categories": [
      "cs.LG",
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2302.10298v1",
    "title": "Quantum Machine Learning hyperparameter search",
    "authors": [
      "S. Consul-Pacareu",
      "R. Montaño",
      "Kevin Rodriguez-Fernandez",
      "Àlex Corretgé",
      "Esteve Vilella-Moreno",
      "Daniel Casado-Faulí",
      "Parfait Atchade-Adelomou"
    ],
    "abstract": "This paper presents a quantum-based Fourier-regression approach for machine\nlearning hyperparameter optimization applied to a benchmark of models trained\non a dataset related to a forecast problem in the airline industry. Our\napproach utilizes the Fourier series method to represent the hyperparameter\nsearch space, which is then optimized using quantum algorithms to find the\noptimal set of hyperparameters for a given machine learning model. Our study\nevaluates the proposed method on a benchmark of models trained to predict a\nforecast problem in the airline industry using a standard HyperParameter\nOptimizer (HPO). The results show that our approach outperforms traditional\nhyperparameter optimization methods in terms of accuracy and convergence speed\nfor the given search space. Our study provides a new direction for future\nresearch in quantum-based machine learning hyperparameter optimization.",
    "published": "2023-02-20T20:41:31Z",
    "pdf_url": "http://arxiv.org/pdf/2302.10298v1",
    "categories": [
      "cs.LG",
      "quant-ph"
    ]
  },
  {
    "arxiv_id": "2306.15308v1",
    "title": "Machine learning in solar physics",
    "authors": [
      "A. Asensio Ramos",
      "M. C. M. Cheung",
      "I. Chifu",
      "R. Gafeira"
    ],
    "abstract": "The application of machine learning in solar physics has the potential to\ngreatly enhance our understanding of the complex processes that take place in\nthe atmosphere of the Sun. By using techniques such as deep learning, we are\nnow in the position to analyze large amounts of data from solar observations\nand identify patterns and trends that may not have been apparent using\ntraditional methods. This can help us improve our understanding of explosive\nevents like solar flares, which can have a strong effect on the Earth\nenvironment. Predicting hazardous events on Earth becomes crucial for our\ntechnological society. Machine learning can also improve our understanding of\nthe inner workings of the sun itself by allowing us to go deeper into the data\nand to propose more complex models to explain them. Additionally, the use of\nmachine learning can help to automate the analysis of solar data, reducing the\nneed for manual labor and increasing the efficiency of research in this field.",
    "published": "2023-06-27T08:55:20Z",
    "pdf_url": "http://arxiv.org/pdf/2306.15308v1",
    "categories": [
      "astro-ph.SR",
      "astro-ph.IM",
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2402.01415v1",
    "title": "SMLP: Symbolic Machine Learning Prover",
    "authors": [
      "Franz Brauße",
      "Zurab Khasidashvili",
      "Konstantin Korovin"
    ],
    "abstract": "Symbolic Machine Learning Prover (SMLP) is a tool and a library for system\nexploration based on data samples obtained by simulating or executing the\nsystem on a number of input vectors. SMLP aims at exploring the system based on\nthis data by taking a grey-box approach: SMLP combines statistical methods of\ndata exploration with building and exploring machine learning models in close\nfeedback loop with the system's response, and exploring these models by\ncombining probabilistic and formal methods. SMLP has been applied in industrial\nsetting at Intel for analyzing and optimizing hardware designs at the analog\nlevel. SMLP is a general purpose tool and can be applied to systems that can be\nsampled and modeled by machine learning models.",
    "published": "2024-02-02T13:53:29Z",
    "pdf_url": "http://arxiv.org/pdf/2402.01415v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.LO",
      "cs.SC",
      "math.OC"
    ]
  },
  {
    "arxiv_id": "2505.03861v1",
    "title": "Machine Learning: a Lecture Note",
    "authors": [
      "Kyunghyun Cho"
    ],
    "abstract": "This lecture note is intended to prepare early-year master's and PhD students\nin data science or a related discipline with foundational ideas in machine\nlearning. It starts with basic ideas in modern machine learning with\nclassification as a main target task. These basic ideas include loss\nformulation, backpropagation, stochastic gradient descent, generalization,\nmodel selection as well as fundamental blocks of artificial neural networks.\nBased on these basic ideas, the lecture note explores in depth the probablistic\napproach to unsupervised learning, covering directed latent variable models,\nproduct of experts, generative adversarial networks and autoregressive models.\nFinally, the note ends by covering a diverse set of further topics, such as\nreinforcement learning, ensemble methods and meta-learning. After reading this\nlecture note, a student should be ready to embark on studying and researching\nmore advanced topics in machine learning and more broadly artificial\nintelligence.",
    "published": "2025-05-06T16:03:41Z",
    "pdf_url": "http://arxiv.org/pdf/2505.03861v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1201.0490v4",
    "title": "Scikit-learn: Machine Learning in Python",
    "authors": [
      "Fabian Pedregosa",
      "Gaël Varoquaux",
      "Alexandre Gramfort",
      "Vincent Michel",
      "Bertrand Thirion",
      "Olivier Grisel",
      "Mathieu Blondel",
      "Andreas Müller",
      "Joel Nothman",
      "Gilles Louppe",
      "Peter Prettenhofer",
      "Ron Weiss",
      "Vincent Dubourg",
      "Jake Vanderplas",
      "Alexandre Passos",
      "David Cournapeau",
      "Matthieu Brucher",
      "Matthieu Perrot",
      "Édouard Duchesnay"
    ],
    "abstract": "Scikit-learn is a Python module integrating a wide range of state-of-the-art\nmachine learning algorithms for medium-scale supervised and unsupervised\nproblems. This package focuses on bringing machine learning to non-specialists\nusing a general-purpose high-level language. Emphasis is put on ease of use,\nperformance, documentation, and API consistency. It has minimal dependencies\nand is distributed under the simplified BSD license, encouraging its use in\nboth academic and commercial settings. Source code, binaries, and documentation\ncan be downloaded from http://scikit-learn.org.",
    "published": "2012-01-02T16:42:40Z",
    "pdf_url": "http://arxiv.org/pdf/1201.0490v4",
    "categories": [
      "cs.LG",
      "cs.MS"
    ]
  },
  {
    "arxiv_id": "1810.10731v3",
    "title": "Law and Adversarial Machine Learning",
    "authors": [
      "Ram Shankar Siva Kumar",
      "David R. O'Brien",
      "Kendra Albert",
      "Salome Vilojen"
    ],
    "abstract": "When machine learning systems fail because of adversarial manipulation, how\nshould society expect the law to respond? Through scenarios grounded in\nadversarial ML literature, we explore how some aspects of computer crime,\ncopyright, and tort law interface with perturbation, poisoning, model stealing\nand model inversion attacks to show how some attacks are more likely to result\nin liability than others. We end with a call for action to ML researchers to\ninvest in transparent benchmarks of attacks and defenses; architect ML systems\nwith forensics in mind and finally, think more about adversarial machine\nlearning in the context of civil liberties. The paper is targeted towards ML\nresearchers who have no legal background.",
    "published": "2018-10-25T06:17:34Z",
    "pdf_url": "http://arxiv.org/pdf/1810.10731v3",
    "categories": [
      "cs.LG",
      "cs.CR",
      "cs.CY",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1912.02590v1",
    "title": "Machine Learning on sWeighted Data",
    "authors": [
      "Maxim Borisyak",
      "Nikita Kazeev"
    ],
    "abstract": "Data analysis in high energy physics has to deal with data samples produced\nfrom different sources. One of the most widely used ways to unfold their\ncontributions is the sPlot technique. It uses the results of a maximum\nlikelihood fit to assign weights to events. Some weights produced by sPlot are\nby design negative. Negative weights make it difficult to apply machine\nlearning methods. The loss function becomes unbounded. This leads to divergent\nneural network training. In this paper we propose a mathematically rigorous way\nto transform the weights obtained by sPlot into class probabilities conditioned\non observables, thus enabling to apply any machine learning algorithm\nout-of-the-box.",
    "published": "2019-10-17T17:06:11Z",
    "pdf_url": "http://arxiv.org/pdf/1912.02590v1",
    "categories": [
      "hep-ex",
      "cs.LG",
      "physics.data-an",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2305.16634v1",
    "title": "Machine Learning for Protein Engineering",
    "authors": [
      "Kadina E. Johnston",
      "Clara Fannjiang",
      "Bruce J. Wittmann",
      "Brian L. Hie",
      "Kevin K. Yang",
      "Zachary Wu"
    ],
    "abstract": "Directed evolution of proteins has been the most effective method for protein\nengineering. However, a new paradigm is emerging, fusing the library generation\nand screening approaches of traditional directed evolution with computation\nthrough the training of machine learning models on protein sequence fitness\ndata. This chapter highlights successful applications of machine learning to\nprotein engineering and directed evolution, organized by the improvements that\nhave been made with respect to each step of the directed evolution cycle.\nAdditionally, we provide an outlook for the future based on the current\ndirection of the field, namely in the development of calibrated models and in\nincorporating other modalities, such as protein structure.",
    "published": "2023-05-26T05:19:17Z",
    "pdf_url": "http://arxiv.org/pdf/2305.16634v1",
    "categories": [
      "q-bio.BM"
    ]
  },
  {
    "arxiv_id": "1801.06566v1",
    "title": "Model Theory and Machine Learning",
    "authors": [
      "Hunter Chase",
      "James Freitag"
    ],
    "abstract": "About 25 years ago, it came to light that a single combinatorial property\ndetermines both an important dividing line in model theory (NIP) and machine\nlearning (PAC-learnability). The following years saw a fruitful exchange of\nideas between PAC learning and the model theory of NIP structures. In this\narticle, we point out a new and similar connection between model theory and\nmachine learning, this time developing a correspondence between\n\\emph{stability} and learnability in various settings of \\emph{online\nlearning.} In particular, this gives many new examples of mathematically\ninteresting classes which are learnable in the online setting.",
    "published": "2018-01-19T20:31:32Z",
    "pdf_url": "http://arxiv.org/pdf/1801.06566v1",
    "categories": [
      "math.LO",
      "03C95, 03C98, 03C45"
    ]
  },
  {
    "arxiv_id": "2111.08507v1",
    "title": "Machine Learning for Genomic Data",
    "authors": [
      "Akankshita Dash"
    ],
    "abstract": "This report explores the application of machine learning techniques on short\ntimeseries gene expression data. Although standard machine learning algorithms\nwork well on longer time-series', they often fail to find meaningful insights\nfrom fewer timepoints. In this report, we explore model-based clustering\ntechniques. We combine popular unsupervised learning techniques like K-Means,\nGaussian Mixture Models, Bayesian Networks, Hidden Markov Models with the\nwell-known Expectation Maximization algorithm. K-Means and Gaussian Mixture\nModels are fairly standard, while Hidden Markov Model and Bayesian Networks\nclustering are more novel ideas that suit time-series gene expression data.",
    "published": "2021-11-15T14:34:20Z",
    "pdf_url": "http://arxiv.org/pdf/2111.08507v1",
    "categories": [
      "q-bio.GN",
      "cs.LG",
      "62F15",
      "G.3"
    ]
  },
  {
    "arxiv_id": "2303.15794v2",
    "title": "Machine Learning for Observational Cosmology",
    "authors": [
      "Kana Moriwaki",
      "Takahiro Nishimichi",
      "Naoki Yoshida"
    ],
    "abstract": "An array of large observational programs using ground-based and space-borne\ntelescopes is planned in the next decade. The forthcoming wide-field sky\nsurveys are expected to deliver a sheer volume of data exceeding an exabyte.\nProcessing the large amount of multiplex astronomical data is technically\nchallenging, and fully automated technologies based on machine learning and\nartificial intelligence are urgently needed. Maximizing scientific returns from\nthe big data requires community-wide efforts. We summarize recent progress in\nmachine learning applications in observational cosmology. We also address\ncrucial issues in high-performance computing that are needed for the data\nprocessing and statistical analysis.",
    "published": "2023-03-28T07:59:04Z",
    "pdf_url": "http://arxiv.org/pdf/2303.15794v2",
    "categories": [
      "astro-ph.IM",
      "astro-ph.CO",
      "astro-ph.GA",
      "astro-ph.HE"
    ]
  },
  {
    "arxiv_id": "2311.16172v1",
    "title": "Evolutionary Machine Learning and Games",
    "authors": [
      "Julian Togelius",
      "Ahmed Khalifa",
      "Sam Earle",
      "Michael Cerny Green",
      "Lisa Soros"
    ],
    "abstract": "Evolutionary machine learning (EML) has been applied to games in multiple\nways, and for multiple different purposes. Importantly, AI research in games is\nnot only about playing games; it is also about generating game content,\nmodeling players, and many other applications. Many of these applications pose\ninteresting problems for EML. We will structure this chapter on EML for games\nbased on whether evolution is used to augment machine learning (ML) or ML is\nused to augment evolution. For completeness, we also briefly discuss the usage\nof ML and evolution separately in games.",
    "published": "2023-11-20T13:21:39Z",
    "pdf_url": "http://arxiv.org/pdf/2311.16172v1",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2407.05520v1",
    "title": "A Theory of Machine Learning",
    "authors": [
      "Jinsook Kim",
      "Jinho Kang"
    ],
    "abstract": "We critically review three major theories of machine learning and provide a\nnew theory according to which machines learn a function when the machines\nsuccessfully compute it. We show that this theory challenges common assumptions\nin the statistical and the computational learning theories, for it implies that\nlearning true probabilities is equivalent neither to obtaining a correct\ncalculation of the true probabilities nor to obtaining an almost-sure\nconvergence to them. We also briefly discuss some case studies from natural\nlanguage processing and macroeconomics from the perspective of the new theory.",
    "published": "2024-07-07T23:57:10Z",
    "pdf_url": "http://arxiv.org/pdf/2407.05520v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1601.04126v1",
    "title": "Engineering Safety in Machine Learning",
    "authors": [
      "Kush R. Varshney"
    ],
    "abstract": "Machine learning algorithms are increasingly influencing our decisions and\ninteracting with us in all parts of our daily lives. Therefore, just like for\npower plants, highways, and myriad other engineered sociotechnical systems, we\nmust consider the safety of systems involving machine learning. In this paper,\nwe first discuss the definition of safety in terms of risk, epistemic\nuncertainty, and the harm incurred by unwanted outcomes. Then we examine\ndimensions, such as the choice of cost function and the appropriateness of\nminimizing the empirical average training cost, along which certain real-world\napplications may not be completely amenable to the foundational principle of\nmodern statistical machine learning: empirical risk minimization. In\nparticular, we note an emerging dichotomy of applications: ones in which safety\nis important and risk minimization is not the complete story (we name these\nType A applications), and ones in which safety is not so critical and risk\nminimization is sufficient (we name these Type B applications). Finally, we\ndiscuss how four different strategies for achieving safety in engineering\n(inherently safe design, safety reserves, safe fail, and procedural safeguards)\ncan be mapped to the machine learning context through interpretability and\ncausality of predictive models, objectives beyond expected prediction accuracy,\nhuman involvement for labeling difficult or rare examples, and user experience\ndesign of software.",
    "published": "2016-01-16T05:46:57Z",
    "pdf_url": "http://arxiv.org/pdf/1601.04126v1",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1805.12153v3",
    "title": "Machine learning for bounce calculation",
    "authors": [
      "Ryusuke Jinno"
    ],
    "abstract": "We study the possibility of using machine learning for the calculation of the\nbounce action in quantum tunneling. Adopting supervised learning, we train\nneural network to give the bounce action from a given potential. It is found\nthat, for one-dimensional tunneling, even a simple neural network performs at a\npercent level.",
    "published": "2018-05-30T18:00:35Z",
    "pdf_url": "http://arxiv.org/pdf/1805.12153v3",
    "categories": [
      "hep-th",
      "hep-ph"
    ]
  },
  {
    "arxiv_id": "2001.11956v1",
    "title": "Documentation of Machine Learning Software",
    "authors": [
      "Yalda Hashemi",
      "Maleknaz Nayebi",
      "Giuliano Antoniol"
    ],
    "abstract": "Machine Learning software documentation is different from most of the\ndocumentations that were studied in software engineering research. Often, the\nusers of these documentations are not software experts. The increasing interest\nin using data science and in particular, machine learning in different fields\nattracted scientists and engineers with various levels of knowledge about\nprogramming and software engineering. Our ultimate goal is automated generation\nand adaptation of machine learning software documents for users with different\nlevels of expertise. We are interested in understanding the nature and triggers\nof the problems and the impact of the users' levels of expertise in the process\nof documentation evolution. We will investigate the Stack Overflow Q/As and\nclassify the documentation related Q/As within the machine learning domain to\nunderstand the types and triggers of the problems as well as the potential\nchange requests to the documentation. We intend to use the results for building\non top of the state of the art techniques for automatic documentation\ngeneration and extending on the adoption, summarization, and explanation of\nsoftware functionalities.",
    "published": "2020-01-30T00:01:28Z",
    "pdf_url": "http://arxiv.org/pdf/2001.11956v1",
    "categories": [
      "cs.SE",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2207.02851v1",
    "title": "Tensor networks in machine learning",
    "authors": [
      "Richik Sengupta",
      "Soumik Adhikary",
      "Ivan Oseledets",
      "Jacob Biamonte"
    ],
    "abstract": "A tensor network is a type of decomposition used to express and approximate\nlarge arrays of data. A given data-set, quantum state or higher dimensional\nmulti-linear map is factored and approximated by a composition of smaller\nmulti-linear maps. This is reminiscent to how a Boolean function might be\ndecomposed into a gate array: this represents a special case of tensor\ndecomposition, in which the tensor entries are replaced by 0, 1 and the\nfactorisation becomes exact. The collection of associated techniques are\ncalled, tensor network methods: the subject developed independently in several\ndistinct fields of study, which have more recently become interrelated through\nthe language of tensor networks. The tantamount questions in the field relate\nto expressability of tensor networks and the reduction of computational\noverheads. A merger of tensor networks with machine learning is natural. On the\none hand, machine learning can aid in determining a factorization of a tensor\nnetwork approximating a data set. On the other hand, a given tensor network\nstructure can be viewed as a machine learning model. Herein the tensor network\nparameters are adjusted to learn or classify a data-set. In this survey we\nrecover the basics of tensor networks and explain the ongoing effort to develop\nthe theory of tensor networks in machine learning.",
    "published": "2022-07-06T18:00:00Z",
    "pdf_url": "http://arxiv.org/pdf/2207.02851v1",
    "categories": [
      "quant-ph",
      "cond-mat.dis-nn",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1402.6013v1",
    "title": "Open science in machine learning",
    "authors": [
      "Joaquin Vanschoren",
      "Mikio L. Braun",
      "Cheng Soon Ong"
    ],
    "abstract": "We present OpenML and mldata, open science platforms that provides easy\naccess to machine learning data, software and results to encourage further\nstudy and application. They go beyond the more traditional repositories for\ndata sets and software packages in that they allow researchers to also easily\nshare the results they obtained in experiments and to compare their solutions\nwith those of others.",
    "published": "2014-02-24T23:12:42Z",
    "pdf_url": "http://arxiv.org/pdf/1402.6013v1",
    "categories": [
      "cs.LG",
      "cs.DL"
    ]
  },
  {
    "arxiv_id": "2110.12483v1",
    "title": "Machine Learning Line Bundle Connections",
    "authors": [
      "Anthony Ashmore",
      "Rehan Deen",
      "Yang-Hui He",
      "Burt A. Ovrut"
    ],
    "abstract": "We study the use of machine learning for finding numerical hermitian\nYang-Mills connections on line bundles over Calabi-Yau manifolds. Defining an\nappropriate loss function and focusing on the examples of an elliptic curve, a\nK3 surface and a quintic threefold, we show that neural networks can be trained\nto give a close approximation to hermitian Yang-Mills connections.",
    "published": "2021-10-24T16:31:46Z",
    "pdf_url": "http://arxiv.org/pdf/2110.12483v1",
    "categories": [
      "hep-th"
    ]
  },
  {
    "arxiv_id": "2203.06073v1",
    "title": "Machine Learning for Hilbert Series",
    "authors": [
      "Edward Hirst"
    ],
    "abstract": "Hilbert series are a standard tool in algebraic geometry, and more recently\nare finding many uses in theoretical physics. This summary reviews work\napplying machine learning to databases of them; and was prepared for the\nproceedings of the Nankai Symposium on Mathematical Dialogues, 2021.",
    "published": "2022-03-11T16:52:42Z",
    "pdf_url": "http://arxiv.org/pdf/2203.06073v1",
    "categories": [
      "hep-th",
      "math.AG"
    ]
  },
  {
    "arxiv_id": "2206.01749v1",
    "title": "Uncertainty Estimation in Machine Learning",
    "authors": [
      "Valentin Arkov"
    ],
    "abstract": "Most machine learning techniques are based upon statistical learning theory,\noften simplified for the sake of computing speed. This paper is focused on the\nuncertainty aspect of mathematical modeling in machine learning. Regression\nanalysis is chosen to further investigate the evaluation aspect of uncertainty\nin model coefficients and, more importantly, in the output feature value\npredictions. A survey demonstrates major stages in the conventional least\nsquares approach to the creation of the regression model, along with its\nuncertainty estimation. On the other hand, it is shown that in machine learning\nthe model complexity and severe nonlinearity become serious obstacles to\nuncertainty evaluation. Furthermore, the process of machine model training\ndemands high computing power, not available at the level of personal computers.\nThis is why so-called pre-trained models are widely used in such areas of\nmachine learning as natural language processing. The latest example of a\npre-trained model is the Generative Pre-trained Transformer 3 with hundreds of\nbillions of parameters and a half-terabyte training dataset. Similarly,\nmathematical models built from real data are growing in complexity which is\naccompanied by the growing amount of training data. However, when machine\nmodels and their predictions are used in decision-making, one needs to estimate\nuncertainty and evaluate accompanying risks. This problem could be resolved\nwith non-parametric techniques at the expense of greater demand for computing\npower, which can be offered by modern supercomputers available, including those\nutilizing graphical and tensor processing units along with the conventional\ncentral processors.",
    "published": "2022-06-03T16:11:11Z",
    "pdf_url": "http://arxiv.org/pdf/2206.01749v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "60H99",
      "I.2.6"
    ]
  },
  {
    "arxiv_id": "2208.06680v3",
    "title": "Locating disparities in machine learning",
    "authors": [
      "Moritz von Zahn",
      "Oliver Hinz",
      "Stefan Feuerriegel"
    ],
    "abstract": "Machine learning can provide predictions with disparate outcomes, in which\nsubgroups of the population (e.g., defined by age, gender, or other sensitive\nattributes) are systematically disadvantaged. In order to comply with upcoming\nlegislation, practitioners need to locate such disparate outcomes. However,\nprevious literature typically detects disparities through statistical\nprocedures for when the sensitive attribute is specified a priori. This limits\napplicability in real-world settings where datasets are high dimensional and,\non top of that, sensitive attributes may be unknown. As a remedy, we propose a\ndata-driven framework called Automatic Location of Disparities (ALD) which aims\nat locating disparities in machine learning. ALD meets several demands from\nindustry: ALD (1) is applicable to arbitrary machine learning classifiers; (2)\noperates on different definitions of disparities (e.g., statistical parity or\nequalized odds); and (3) deals with both categorical and continuous predictors\neven if disparities arise from complex and multi-way interactions known as\nintersectionality (e. g., age above 60 and female). ALD produces interpretable\naudit reports as output. We demonstrate the effectiveness of ALD based on both\nsynthetic and real-world datasets. As a result, we empower practitioners to\neffectively locate and mitigate disparities in machine learning algorithms,\nconduct algorithmic audits, and protect individuals from discrimination.",
    "published": "2022-08-13T16:39:51Z",
    "pdf_url": "http://arxiv.org/pdf/2208.06680v3",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2402.19254v1",
    "title": "Machine learning for modular multiplication",
    "authors": [
      "Kristin Lauter",
      "Cathy Yuanchen Li",
      "Krystal Maughan",
      "Rachel Newton",
      "Megha Srivastava"
    ],
    "abstract": "Motivated by cryptographic applications, we investigate two machine learning\napproaches to modular multiplication: namely circular regression and a\nsequence-to-sequence transformer model. The limited success of both methods\ndemonstrated in our results gives evidence for the hardness of tasks involving\nmodular multiplication upon which cryptosystems are based.",
    "published": "2024-02-29T15:26:03Z",
    "pdf_url": "http://arxiv.org/pdf/2402.19254v1",
    "categories": [
      "cs.LG",
      "cs.CR"
    ]
  },
  {
    "arxiv_id": "2209.06529v1",
    "title": "Data Privacy and Trustworthy Machine Learning",
    "authors": [
      "Martin Strobel",
      "Reza Shokri"
    ],
    "abstract": "The privacy risks of machine learning models is a major concern when training\nthem on sensitive and personal data. We discuss the tradeoffs between data\nprivacy and the remaining goals of trustworthy machine learning (notably,\nfairness, robustness, and explainability).",
    "published": "2022-09-14T10:07:44Z",
    "pdf_url": "http://arxiv.org/pdf/2209.06529v1",
    "categories": [
      "cs.LG",
      "cs.CR"
    ]
  },
  {
    "arxiv_id": "1405.1304v1",
    "title": "Application of Machine Learning Techniques in Aquaculture",
    "authors": [
      "Akhlaqur Rahman",
      "Sumaira Tasnim"
    ],
    "abstract": "In this paper we present applications of different machine learning\nalgorithms in aquaculture. Machine learning algorithms learn models from\nhistorical data. In aquaculture historical data are obtained from farm\npractices, yields, and environmental data sources. Associations between these\ndifferent variables can be obtained by applying machine learning algorithms to\nhistorical data. In this paper we present applications of different machine\nlearning algorithms in aquaculture applications.",
    "published": "2014-05-03T14:26:42Z",
    "pdf_url": "http://arxiv.org/pdf/1405.1304v1",
    "categories": [
      "cs.CE",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2111.04439v1",
    "title": "Addressing Privacy Threats from Machine Learning",
    "authors": [
      "Mary Anne Smart"
    ],
    "abstract": "Every year at NeurIPS, machine learning researchers gather and discuss\nexciting applications of machine learning in areas such as public health,\ndisaster response, climate change, education, and more. However, many of these\nsame researchers are expressing growing concern about applications of machine\nlearning for surveillance (Nanayakkara et al., 2021). This paper presents a\nbrief overview of strategies for resisting these surveillance technologies and\ncalls for greater collaboration between machine learning and human-computer\ninteraction researchers to address the threats that these technologies pose.",
    "published": "2021-10-25T03:40:25Z",
    "pdf_url": "http://arxiv.org/pdf/2111.04439v1",
    "categories": [
      "cs.CY",
      "cs.CR",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2412.18979v1",
    "title": "Quantum memristors for neuromorphic quantum machine learning",
    "authors": [
      "Lucas Lamata"
    ],
    "abstract": "Quantum machine learning may permit to realize more efficient machine\nlearning calculations with near-term quantum devices. Among the diverse quantum\nmachine learning paradigms which are currently being considered, quantum\nmemristors are promising as a way of combining, in the same quantum hardware, a\nunitary evolution with the nonlinearity provided by the measurement and\nfeedforward. Thus, an efficient way of deploying neuromorphic quantum computing\nfor quantum machine learning may be enabled.",
    "published": "2024-12-25T20:21:24Z",
    "pdf_url": "http://arxiv.org/pdf/2412.18979v1",
    "categories": [
      "quant-ph",
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "1311.5250v1",
    "title": "Attractor Control Using Machine Learning",
    "authors": [
      "Thomas Duriez",
      "Vladimir Parezanovic",
      "Bernd R. Noack",
      "Laurent Cordier",
      "Marc Segond",
      "Markus Abel"
    ],
    "abstract": "We propose a general strategy for feedback control design of complex\ndynamical systems exploiting the nonlinear mechanisms in a systematic\nunsupervised manner. These dynamical systems can have a state space of\narbitrary dimension with finite number of actuators (multiple inputs) and\nsensors (multiple outputs). The control law maps outputs into inputs and is\noptimized with respect to a cost function, containing physics via the dynamical\nor statistical properties of the attractor to be controlled. Thus, we are\ncapable of exploiting nonlinear mechanisms, e.g. chaos or frequency cross-talk,\nserving the control objective. This optimization is based on genetic\nprogramming, a branch of machine learning. This machine learning control is\nsuccessfully applied to the stabilization of nonlinearly coupled oscillators\nand maximization of Lyapunov exponent of a forced Lorenz system. We foresee\npotential applications to most nonlinear multiple inputs/multiple outputs\ncontrol problems, particulary in experiments.",
    "published": "2013-11-20T22:30:23Z",
    "pdf_url": "http://arxiv.org/pdf/1311.5250v1",
    "categories": [
      "nlin.CD",
      "physics.flu-dyn"
    ]
  },
  {
    "arxiv_id": "1605.01735v1",
    "title": "Machine learning phases of matter",
    "authors": [
      "Juan Carrasquilla",
      "Roger G. Melko"
    ],
    "abstract": "Neural networks can be used to identify phases and phase transitions in\ncondensed matter systems via supervised machine learning. Readily programmable\nthrough modern software libraries, we show that a standard feed-forward neural\nnetwork can be trained to detect multiple types of order parameter directly\nfrom raw state configurations sampled with Monte Carlo. In addition, they can\ndetect highly non-trivial states such as Coulomb phases, and if modified to a\nconvolutional neural network, topological phases with no conventional order\nparameter. We show that this classification occurs within the neural network\nwithout knowledge of the Hamiltonian or even the general locality of\ninteractions. These results demonstrate the power of machine learning as a\nbasic research tool in the field of condensed matter and statistical physics.",
    "published": "2016-05-05T20:00:04Z",
    "pdf_url": "http://arxiv.org/pdf/1605.01735v1",
    "categories": [
      "cond-mat.str-el"
    ]
  },
  {
    "arxiv_id": "1702.05774v1",
    "title": "Machine Learning Predicts Laboratory Earthquakes",
    "authors": [
      "Bertrand Rouet-Leduc",
      "Claudia Hulbert",
      "Nicholas Lubbers",
      "Kipton Barros",
      "Colin Humphreys",
      "Paul A. Johnson"
    ],
    "abstract": "Forecasting fault failure is a fundamental but elusive goal in earthquake\nscience. Here we show that by listening to the acoustic signal emitted by a\nlaboratory fault, machine learning can predict the time remaining before it\nfails with great accuracy. These predictions are based solely on the\ninstantaneous physical characteristics of the acoustical signal, and do not\nmake use of its history. Surprisingly, machine learning identifies a signal\nemitted from the fault zone previously thought to be low-amplitude noise that\nenables failure forecasting throughout the laboratory quake cycle. We\nhypothesize that applying this approach to continuous seismic data may lead to\nsignificant advances in identifying currently unknown signals, in providing new\ninsights into fault physics, and in placing bounds on fault failure times.",
    "published": "2017-02-19T17:57:10Z",
    "pdf_url": "http://arxiv.org/pdf/1702.05774v1",
    "categories": [
      "physics.geo-ph"
    ]
  },
  {
    "arxiv_id": "1803.08066v2",
    "title": "Jet Charge and Machine Learning",
    "authors": [
      "Katherine Fraser",
      "Matthew D. Schwartz"
    ],
    "abstract": "Modern machine learning techniques, such as convolutional, recurrent and\nrecursive neural networks, have shown promise for jet substructure at the Large\nHadron Collider. For example, they have demonstrated effectiveness at boosted\ntop or W boson identification or for quark/gluon discrimination. We explore\nthese methods for the purpose of classifying jets according to their electric\ncharge. We find that both neural networks that incorporate distance within the\njet as an input and boosted decision trees including radial distance\ninformation can provide significant improvement in jet charge extraction over\ncurrent methods. Specifically, convolutional, recurrent, and recursive networks\ncan provide the largest improvement over traditional methods, in part by\neffectively utilizing distance within the jet or clustering history. The\nadvantages of using a fixed-size input representation (as with the CNN) or a\nsmall input representation (as with the RNN) suggest that both convolutional\nand recurrent networks will be essential to the future of modern machine\nlearning at colliders.",
    "published": "2018-03-21T18:02:02Z",
    "pdf_url": "http://arxiv.org/pdf/1803.08066v2",
    "categories": [
      "hep-ph",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1808.07069v1",
    "title": "Machine learning non-local correlations",
    "authors": [
      "Askery Canabarro",
      "Samuraí Brito",
      "Rafael Chaves"
    ],
    "abstract": "The ability to witness non-local correlations lies at the core of\nfoundational aspects of quantum mechanics and its application in the processing\nof information. Commonly, this is achieved via the violation of Bell\ninequalities. Unfortunately, however, their systematic derivation quickly\nbecomes unfeasible as the scenario of interest grows in complexity. To cope\nwith that, we propose here a machine learning approach for the detection and\nquantification of non-locality. It consists of an ensemble of multilayer\nperceptrons blended with genetic algorithms achieving a high performance in a\nnumber of relevant Bell scenarios. Our results offer a novel method and a\nproof-of-principle for the relevance of machine learning for understanding\nnon-locality.",
    "published": "2018-08-21T18:03:36Z",
    "pdf_url": "http://arxiv.org/pdf/1808.07069v1",
    "categories": [
      "quant-ph",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2006.03626v2",
    "title": "LGML: Logic Guided Machine Learning",
    "authors": [
      "Joseph Scott",
      "Maysum Panju",
      "Vijay Ganesh"
    ],
    "abstract": "We introduce Logic Guided Machine Learning (LGML), a novel approach that\nsymbiotically combines machine learning (ML) and logic solvers with the goal of\nlearning mathematical functions from data. LGML consists of two phases, namely\na learning-phase and a logic-phase with a corrective feedback loop, such that,\nthe learning-phase learns symbolic expressions from input data, and the\nlogic-phase cross verifies the consistency of the learned expression with known\nauxiliary truths. If inconsistent, the logic-phase feeds back \"counterexamples\"\nto the learning-phase. This process is repeated until the learned expression is\nconsistent with auxiliary truth. Using LGML, we were able to learn expressions\nthat correspond to the Pythagorean theorem and the sine function, with several\norders of magnitude improvements in data efficiency compared to an approach\nbased on an out-of-the-box multi-layered perceptron (MLP).",
    "published": "2020-06-05T18:42:08Z",
    "pdf_url": "http://arxiv.org/pdf/2006.03626v2",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2108.07380v2",
    "title": "InfoGram and Admissible Machine Learning",
    "authors": [
      "Subhadeep Mukhopadhyay"
    ],
    "abstract": "We have entered a new era of machine learning (ML), where the most accurate\nalgorithm with superior predictive power may not even be deployable, unless it\nis admissible under the regulatory constraints. This has led to great interest\nin developing fair, transparent and trustworthy ML methods. The purpose of this\narticle is to introduce a new information-theoretic learning framework\n(admissible machine learning) and algorithmic risk-management tools (InfoGram,\nL-features, ALFA-testing) that can guide an analyst to redesign off-the-shelf\nML methods to be regulatory compliant, while maintaining good prediction\naccuracy. We have illustrated our approach using several real-data examples\nfrom financial sectors, biomedical research, marketing campaigns, and the\ncriminal justice system.",
    "published": "2021-08-17T00:04:38Z",
    "pdf_url": "http://arxiv.org/pdf/2108.07380v2",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "econ.EM"
    ]
  },
  {
    "arxiv_id": "1912.05665v2",
    "title": "Managing Machine Learning Workflow Components",
    "authors": [
      "Marcio Moreno",
      "Vítor Lourenço",
      "Sandro Rama Fiorini",
      "Polyana Costa",
      "Rafael Brandão",
      "Daniel Civitarese",
      "Renato Cerqueira"
    ],
    "abstract": "Machine Learning Workflows (MLWfs) have become essential and a disruptive\napproach in problem-solving over several industries. However, the development\nprocess of MLWfs may be complicated, hard to achieve, time-consuming, and\nerror-prone. To handle this problem, in this paper, we introduce machine\nlearning workflow management (MLWfM) as a technique to aid the development and\nreuse of MLWfs and their components through three aspects: representation,\nexecution, and creation. More precisely, we discuss our approach to structure\nthe MLWfs' components and their metadata to aid retrieval and reuse of\ncomponents in new MLWfs. Also, we consider the execution of these components\nwithin a tool. The hybrid knowledge representation, called Hyperknowledge,\nframes our methodology, supporting the three MLWfM's aspects. To validate our\napproach, we show a practical use case in the Oil & Gas industry.",
    "published": "2019-12-10T00:44:06Z",
    "pdf_url": "http://arxiv.org/pdf/1912.05665v2",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2001.10794v1",
    "title": "Software Logging for Machine Learning",
    "authors": [
      "Nathan Bosch",
      "Jan Bosch"
    ],
    "abstract": "System logs perform a critical function in software-intensive systems as logs\nrecord the state of the system and significant events in the system at\nimportant points in time. Unfortunately, log entries are typically created in\nan ad-hoc, unstructured and uncoordinated fashion, limiting their usefulness\nfor analytics and machine learning. In this paper, we present the main\nchallenges of contemporary approaches to generating and storing system logs\ndata for large, complex, software-intensive systems based on an in-depth case\nstudy at a world-leading telecommunications company. Second, we present a\nsystematic and structured approach for generating log data that does not suffer\nfrom the aforementioned challenges and is optimized for use in machine\nlearning. Third, we provide validation of the approach based on expert\ninterviews that confirms that the approach addresses the identified challenges\nand problems.",
    "published": "2020-01-24T13:44:08Z",
    "pdf_url": "http://arxiv.org/pdf/2001.10794v1",
    "categories": [
      "cs.SE"
    ]
  },
  {
    "arxiv_id": "2104.12733v1",
    "title": "Invariant polynomials and machine learning",
    "authors": [
      "Ward Haddadin"
    ],
    "abstract": "We present an application of invariant polynomials in machine learning. Using\nthe methods developed in previous work, we obtain two types of generators of\nthe Lorentz- and permutation-invariant polynomials in particle momenta; minimal\nalgebra generators and Hironaka decompositions. We discuss and prove some\napproximation theorems to make use of these invariant generators in machine\nlearning algorithms in general and in neural networks specifically. By\nimplementing these generators in neural networks applied to regression tasks,\nwe test the improvements in performance under a wide range of hyperparameter\nchoices and find a reduction of the loss on training data and a significant\nreduction of the loss on validation data. For a different approach on\nquantifying the performance of these neural networks, we treat the problem from\na Bayesian inference perspective and employ nested sampling techniques to\nperform model comparison. Beyond a certain network size, we find that networks\nutilising Hironaka decompositions perform the best.",
    "published": "2021-04-26T17:24:29Z",
    "pdf_url": "http://arxiv.org/pdf/2104.12733v1",
    "categories": [
      "hep-ph",
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1909.06342v4",
    "title": "Explainable Machine Learning in Deployment",
    "authors": [
      "Umang Bhatt",
      "Alice Xiang",
      "Shubham Sharma",
      "Adrian Weller",
      "Ankur Taly",
      "Yunhan Jia",
      "Joydeep Ghosh",
      "Ruchir Puri",
      "José M. F. Moura",
      "Peter Eckersley"
    ],
    "abstract": "Explainable machine learning offers the potential to provide stakeholders\nwith insights into model behavior by using various methods such as feature\nimportance scores, counterfactual explanations, or influential training data.\nYet there is little understanding of how organizations use these methods in\npractice. This study explores how organizations view and use explainability for\nstakeholder consumption. We find that, currently, the majority of deployments\nare not for end users affected by the model but rather for machine learning\nengineers, who use explainability to debug the model itself. There is thus a\ngap between explainability in practice and the goal of transparency, since\nexplanations primarily serve internal stakeholders rather than external ones.\nOur study synthesizes the limitations of current explainability techniques that\nhamper their use for end users. To facilitate end user interaction, we develop\na framework for establishing clear goals for explainability. We end by\ndiscussing concerns raised regarding explainability.",
    "published": "2019-09-13T17:35:53Z",
    "pdf_url": "http://arxiv.org/pdf/1909.06342v4",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2209.14991v3",
    "title": "Machine learning and invariant theory",
    "authors": [
      "Ben Blum-Smith",
      "Soledad Villar"
    ],
    "abstract": "Inspired by constraints from physical law, equivariant machine learning\nrestricts the learning to a hypothesis class where all the functions are\nequivariant with respect to some group action. Irreducible representations or\ninvariant theory are typically used to parameterize the space of such\nfunctions. In this article, we introduce the topic and explain a couple of\nmethods to explicitly parameterize equivariant functions that are being used in\nmachine learning applications. In particular, we explicate a general procedure,\nattributed to Malgrange, to express all polynomial maps between linear spaces\nthat are equivariant under the action of a group $G$, given a characterization\nof the invariant polynomials on a bigger space. The method also parametrizes\nsmooth equivariant maps in the case that $G$ is a compact Lie group.",
    "published": "2022-09-29T17:52:17Z",
    "pdf_url": "http://arxiv.org/pdf/2209.14991v3",
    "categories": [
      "stat.ML",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2206.05985v2",
    "title": "Modeling the Machine Learning Multiverse",
    "authors": [
      "Samuel J. Bell",
      "Onno P. Kampman",
      "Jesse Dodge",
      "Neil D. Lawrence"
    ],
    "abstract": "Amid mounting concern about the reliability and credibility of machine\nlearning research, we present a principled framework for making robust and\ngeneralizable claims: the multiverse analysis. Our framework builds upon the\nmultiverse analysis (Steegen et al., 2016) introduced in response to\npsychology's own reproducibility crisis. To efficiently explore\nhigh-dimensional and often continuous ML search spaces, we model the multiverse\nwith a Gaussian Process surrogate and apply Bayesian experimental design. Our\nframework is designed to facilitate drawing robust scientific conclusions about\nmodel performance, and thus our approach focuses on exploration rather than\nconventional optimization. In the first of two case studies, we investigate\ndisputed claims about the relative merit of adaptive optimizers. Second, we\nsynthesize conflicting research on the effect of learning rate on the large\nbatch training generalization gap. For the machine learning community, the\nmultiverse analysis is a simple and effective technique for identifying robust\nclaims, for increasing transparency, and a step toward improved\nreproducibility.",
    "published": "2022-06-13T09:11:48Z",
    "pdf_url": "http://arxiv.org/pdf/2206.05985v2",
    "categories": [
      "cs.LG",
      "stat.ME"
    ]
  },
  {
    "arxiv_id": "2210.00954v3",
    "title": "Machine Learning-Powered Course Allocation",
    "authors": [
      "Ermis Soumalias",
      "Behnoosh Zamanlooy",
      "Jakob Weissteiner",
      "Sven Seuken"
    ],
    "abstract": "We study the course allocation problem, where universities assign course\nschedules to students. The current state-of-the-art mechanism, Course Match,\nhas one major shortcoming: students make significant mistakes when reporting\ntheir preferences, which negatively affects welfare and fairness. To address\nthis issue, we introduce a new mechanism, Machine Learning-powered Course Match\n(MLCM). At the core of MLCM is a machine learning-powered preference\nelicitation module that iteratively asks personalized pairwise comparison\nqueries to alleviate students' reporting mistakes. Extensive computational\nexperiments, grounded in real-world data, demonstrate that MLCM, with only ten\ncomparison queries, significantly increases both average and minimum student\nutility by 7%-11% and 17%-29%, respectively. Finally, we highlight MLCM's\nrobustness to changes in the environment and show how our design minimizes the\nrisk of upgrading to MLCM while making the upgrade process simple for\nuniversities and seamless for their students.",
    "published": "2022-10-03T14:11:33Z",
    "pdf_url": "http://arxiv.org/pdf/2210.00954v3",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2302.06716v3",
    "title": "Machine Learning Model Attribution Challenge",
    "authors": [
      "Elizabeth Merkhofer",
      "Deepesh Chaudhari",
      "Hyrum S. Anderson",
      "Keith Manville",
      "Lily Wong",
      "João Gante"
    ],
    "abstract": "We present the findings of the Machine Learning Model Attribution Challenge.\nFine-tuned machine learning models may derive from other trained models without\nobvious attribution characteristics. In this challenge, participants identify\nthe publicly-available base models that underlie a set of anonymous, fine-tuned\nlarge language models (LLMs) using only textual output of the models.\nContestants aim to correctly attribute the most fine-tuned models, with ties\nbroken in the favor of contestants whose solutions use fewer calls to the\nfine-tuned models' API. The most successful approaches were manual, as\nparticipants observed similarities between model outputs and developed\nattribution heuristics based on public documentation of the base models, though\nseveral teams also submitted automated, statistical solutions.",
    "published": "2023-02-13T22:05:27Z",
    "pdf_url": "http://arxiv.org/pdf/2302.06716v3",
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.CR"
    ]
  },
  {
    "arxiv_id": "1512.02900v1",
    "title": "Advances in quantum machine learning",
    "authors": [
      "Jeremy Adcock",
      "Euan Allen",
      "Matthew Day",
      "Stefan Frick",
      "Janna Hinchliff",
      "Mack Johnson",
      "Sam Morley-Short",
      "Sam Pallister",
      "Alasdair Price",
      "Stasja Stanisic"
    ],
    "abstract": "Here we discuss advances in the field of quantum machine learning. The\nfollowing document offers a hybrid discussion; both reviewing the field as it\nis currently, and suggesting directions for further research. We include both\nalgorithms and experimental implementations in the discussion. The field's\noutlook is generally positive, showing significant promise. However, we believe\nthere are appreciable hurdles to overcome before one can claim that it is a\nprimary application of quantum computation.",
    "published": "2015-12-09T15:32:39Z",
    "pdf_url": "http://arxiv.org/pdf/1512.02900v1",
    "categories": [
      "quant-ph"
    ]
  },
  {
    "arxiv_id": "2103.03122v1",
    "title": "Machine Learning using Stata/Python",
    "authors": [
      "Giovanni Cerulli"
    ],
    "abstract": "We present two related Stata modules, r_ml_stata and c_ml_stata, for fitting\npopular Machine Learning (ML) methods both in regression and classification\nsettings. Using the recent Stata/Python integration platform (sfi) of Stata 16,\nthese commands provide hyper-parameters' optimal tuning via K-fold\ncross-validation using greed search. More specifically, they make use of the\nPython Scikit-learn API to carry out both cross-validation and outcome/label\nprediction.",
    "published": "2021-03-03T10:31:44Z",
    "pdf_url": "http://arxiv.org/pdf/2103.03122v1",
    "categories": [
      "stat.CO",
      "cs.LG",
      "cs.MS"
    ]
  },
  {
    "arxiv_id": "2207.00108v1",
    "title": "Discrimination in machine learning algorithms",
    "authors": [
      "Roberta Pappadà",
      "Francesco Pauli"
    ],
    "abstract": "Machine learning algorithms are routinely used for business decisions that\nmay directly affect individuals, for example, because a credit scoring\nalgorithm refuses them a loan. It is then relevant from an ethical (and legal)\npoint of view to ensure that these algorithms do not discriminate based on\nsensitive attributes (like sex or race), which may occur unwittingly and\nunknowingly by the operator and the management. Statistical tools and methods\nare then required to detect and eliminate such potential biases.",
    "published": "2022-06-30T21:35:42Z",
    "pdf_url": "http://arxiv.org/pdf/2207.00108v1",
    "categories": [
      "stat.ML",
      "cs.CY",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1909.08027v1",
    "title": "Machine Learning Potential Energy Surfaces",
    "authors": [
      "Oliver T. Unke",
      "Markus Meuwly"
    ],
    "abstract": "Machine Learning techniques can be used to represent high-dimensional\npotential energy surfaces for reactive chemical systems. Two such methods are\nbased on a reproducing kernel Hilbert space representation or on deep neural\nnetworks. They can achieve a sub-1 kcal/mol accuracy with respect to reference\ndata and can be used in studies of chemical dynamics. Their construction and a\nfew typical examples are briefly summarized in the present contribution.",
    "published": "2019-09-17T18:52:54Z",
    "pdf_url": "http://arxiv.org/pdf/1909.08027v1",
    "categories": [
      "physics.chem-ph"
    ]
  },
  {
    "arxiv_id": "2205.11473v1",
    "title": "Rethinking Streaming Machine Learning Evaluation",
    "authors": [
      "Shreya Shankar",
      "Bernease Herman",
      "Aditya G. Parameswaran"
    ],
    "abstract": "While most work on evaluating machine learning (ML) models focuses on\ncomputing accuracy on batches of data, tracking accuracy alone in a streaming\nsetting (i.e., unbounded, timestamp-ordered datasets) fails to appropriately\nidentify when models are performing unexpectedly. In this position paper, we\ndiscuss how the nature of streaming ML problems introduces new real-world\nchallenges (e.g., delayed arrival of labels) and recommend additional metrics\nto assess streaming ML performance.",
    "published": "2022-05-23T17:21:43Z",
    "pdf_url": "http://arxiv.org/pdf/2205.11473v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2311.02278v1",
    "title": "Machine learning's own Industrial Revolution",
    "authors": [
      "Yuan Luo",
      "Song Han",
      "Jingjing Liu"
    ],
    "abstract": "Machine learning is expected to enable the next Industrial Revolution.\nHowever, lacking standardized and automated assembly networks, ML faces\nsignificant challenges to meet ever-growing enterprise demands and empower\nbroad industries. In the Perspective, we argue that ML needs to first complete\nits own Industrial Revolution, elaborate on how to best achieve its goals, and\ndiscuss new opportunities to enable rapid translation from ML's innovation\nfrontier to mass production and utilization.",
    "published": "2023-11-04T00:00:13Z",
    "pdf_url": "http://arxiv.org/pdf/2311.02278v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2401.07929v1",
    "title": "Machine Learning Based Object Tracking",
    "authors": [
      "Md Rakibul Karim Akanda",
      "Joshua Reynolds",
      "Treylin Jackson",
      "Milijah Gray"
    ],
    "abstract": "Machine learning based object detection as well as tracking that object have\nbeen performed in this paper. The authors were able to set a range of interest\n(ROI) around an object using Open Computer Vision, better known as OpenCV. Next\na tracking algorithm has been used to maintain tracking on an object while\nsimultaneously operating two servo motors to keep the object centered in the\nframe. Detailed procedure and code are included in this paper.",
    "published": "2024-01-15T19:46:05Z",
    "pdf_url": "http://arxiv.org/pdf/2401.07929v1",
    "categories": [
      "cs.CV",
      "physics.app-ph"
    ]
  },
  {
    "arxiv_id": "2506.00572v1",
    "title": "Machine-learning Growth at Risk",
    "authors": [
      "Tobias Adrian",
      "Hongqi Chen",
      "Max-Sebastian Dovì",
      "Ji Hyung Lee"
    ],
    "abstract": "We analyse growth vulnerabilities in the US using quantile partial\ncorrelation regression, a selection-based machine-learning method that achieves\nmodel selection consistency under time series. We find that downside risk is\nprimarily driven by financial, labour-market, and housing variables, with their\nimportance changing over time. Decomposing downside risk into its individual\ncomponents, we construct sector-specific indices that predict it, while\ncontrolling for information from other sectors, thereby isolating the downside\nrisks emanating from each sector.",
    "published": "2025-05-31T14:06:53Z",
    "pdf_url": "http://arxiv.org/pdf/2506.00572v1",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ]
  },
  {
    "arxiv_id": "0611011v1",
    "title": "Hedging predictions in machine learning",
    "authors": [
      "Alexander Gammerman",
      "Vladimir Vovk"
    ],
    "abstract": "Recent advances in machine learning make it possible to design efficient\nprediction algorithms for data sets with huge numbers of parameters. This paper\ndescribes a new technique for \"hedging\" the predictions output by many such\nalgorithms, including support vector machines, kernel ridge regression, kernel\nnearest neighbours, and by many other state-of-the-art methods. The hedged\npredictions for the labels of new objects include quantitative measures of\ntheir own accuracy and reliability. These measures are provably valid under the\nassumption of randomness, traditional in machine learning: the objects and\ntheir labels are assumed to be generated independently from the same\nprobability distribution. In particular, it becomes possible to control (up to\nstatistical fluctuations) the number of erroneous predictions by selecting a\nsuitable confidence level. Validity being achieved automatically, the remaining\ngoal of hedged prediction is efficiency: taking full account of the new\nobjects' features and other available information to produce as accurate\npredictions as possible. This can be done successfully using the powerful\nmachinery of modern machine learning.",
    "published": "2006-11-02T18:44:49Z",
    "pdf_url": "http://arxiv.org/pdf/cs/0611011v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1808.03794v1",
    "title": "Magnetic microstructure machine learning analysis",
    "authors": [
      "Lukas Exl",
      "Johann Fischbacher",
      "Alexander Kovacs",
      "Harald Oezelt",
      "Markus Gusenbauer",
      "Kazuya Yokota",
      "Tetsuya Shoji",
      "Gino Hrkac",
      "Thomas Schrefl"
    ],
    "abstract": "We use a machine learning approach to identify the importance of\nmicrostructure characteristics in causing magnetization reversal in ideally\nstructured large-grained Nd$_2$Fe$_{14}$B permanent magnets. The embedded\nStoner-Wohlfarth method is used as a reduced order model for determining local\nswitching field maps which guide the data-driven learning procedure. The\npredictor model is a random forest classifier which we validate by comparing\nwith full micromagnetic simulations in the case of small granular test\nstructures. In the course of the machine learning microstructure analysis the\nmost important features explaining magnetization reversal were found to be the\nmisorientation and the position of the grain within the magnet. The lowest\nswitching fields occur near the top and bottom edges of the magnet. While the\ndependence of the local switching field on the grain orientation is known from\ntheory, the influence of the position of the grain on the local coercive field\nstrength is less obvious. As a direct result of our findings of the machine\nlearning analysis we show that edge hardening via Dy-diffusion leads to higher\ncoercive fields.",
    "published": "2018-08-11T12:25:36Z",
    "pdf_url": "http://arxiv.org/pdf/1808.03794v1",
    "categories": [
      "cond-mat.mtrl-sci",
      "physics.comp-ph",
      "physics.data-an"
    ]
  },
  {
    "arxiv_id": "1811.11668v1",
    "title": "Racial categories in machine learning",
    "authors": [
      "Sebastian Benthall",
      "Bruce D. Haynes"
    ],
    "abstract": "Controversies around race and machine learning have sparked debate among\ncomputer scientists over how to design machine learning systems that guarantee\nfairness. These debates rarely engage with how racial identity is embedded in\nour social experience, making for sociological and psychological complexity.\nThis complexity challenges the paradigm of considering fairness to be a formal\nproperty of supervised learning with respect to protected personal attributes.\nRacial identity is not simply a personal subjective quality. For people labeled\n\"Black\" it is an ascribed political category that has consequences for social\ndifferentiation embedded in systemic patterns of social inequality achieved\nthrough both social and spatial segregation. In the United States, racial\nclassification can best be understood as a system of inherently unequal status\ncategories that places whites as the most privileged category while signifying\nthe Negro/black category as stigmatized. Social stigma is reinforced through\nthe unequal distribution of societal rewards and goods along racial lines that\nis reinforced by state, corporate, and civic institutions and practices. This\ncreates a dilemma for society and designers: be blind to racial group\ndisparities and thereby reify racialized social inequality by no longer\nmeasuring systemic inequality, or be conscious of racial categories in a way\nthat itself reifies race. We propose a third option. By preceding group\nfairness interventions with unsupervised learning to dynamically detect\npatterns of segregation, machine learning systems can mitigate the root cause\nof social disparities, social segregation and stratification, without further\nanchoring status categories of disadvantage.",
    "published": "2018-11-28T16:47:36Z",
    "pdf_url": "http://arxiv.org/pdf/1811.11668v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2004.01496v2",
    "title": "Company classification using machine learning",
    "authors": [
      "Sven Husmann",
      "Antoniya Shivarova",
      "Rick Steinert"
    ],
    "abstract": "The recent advancements in computational power and machine learning\nalgorithms have led to vast improvements in manifold areas of research.\nEspecially in finance, the application of machine learning enables both\nresearchers and practitioners to gain new insights into financial data and\nwell-studied areas such as company classification. In our paper, we demonstrate\nthat unsupervised machine learning algorithms can be used to visualize and\nclassify company data in an economically meaningful and effective way. In\nparticular, we implement the data-driven dimension reduction and visualization\ntool t-distributed stochastic neighbor embedding (t-SNE) in combination with\nspectral clustering. The resulting company groups can then be utilized by\nexperts in the field for empirical analysis and optimal decision making. By\nproviding an exemplary out-of-sample study within a portfolio optimization\nframework, we show that the application of t-SNE and spectral clustering\nimproves the overall portfolio performance. Therefore, we introduce our\napproach to the financial community as a valuable technique in the context of\ndata analysis and company classification.",
    "published": "2020-03-31T23:36:27Z",
    "pdf_url": "http://arxiv.org/pdf/2004.01496v2",
    "categories": [
      "q-fin.ST",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2103.13358v1",
    "title": "Anticipating synchronization with machine learning",
    "authors": [
      "Huawei Fan",
      "Ling-Wei Kong",
      "Ying-Cheng Lai",
      "Xingang Wang"
    ],
    "abstract": "In applications of dynamical systems, situations can arise where it is\ndesired to predict the onset of synchronization as it can lead to\ncharacteristic and significant changes in the system performance and behaviors,\nfor better or worse. In experimental and real settings, the system equations\nare often unknown, raising the need to develop a prediction framework that is\nmodel free and fully data driven. We contemplate that this challenging problem\ncan be addressed with machine learning. In particular, exploiting reservoir\ncomputing or echo state networks, we devise a \"parameter-aware\" scheme to train\nthe neural machine using asynchronous time series, i.e., in the parameter\nregime prior to the onset of synchronization. A properly trained machine will\npossess the power to predict the synchronization transition in that, with a\ngiven amount of parameter drift, whether the system would remain asynchronous\nor exhibit synchronous dynamics can be accurately anticipated. We demonstrate\nthe machine-learning based framework using representative chaotic models and\nsmall network systems that exhibit continuous (second-order) or abrupt\n(first-order) transitions. A remarkable feature is that, for a network system\nexhibiting an explosive (first-order) transition and a hysteresis loop in\nsynchronization, the machine learning scheme is capable of accurately\npredicting these features, including the precise locations of the transition\npoints associated with the forward and backward transition paths.",
    "published": "2021-03-13T03:51:48Z",
    "pdf_url": "http://arxiv.org/pdf/2103.13358v1",
    "categories": [
      "nlin.AO",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2011.14135v2",
    "title": "Exoplanet Detection using Machine Learning",
    "authors": [
      "Abhishek Malik",
      "Benjamin P. Moster",
      "Christian Obermeier"
    ],
    "abstract": "We introduce a new machine learning based technique to detect exoplanets\nusing the transit method. Machine learning and deep learning techniques have\nproven to be broadly applicable in various scientific research areas. We aim to\nexploit some of these methods to improve the conventional algorithm based\napproaches presently used in astrophysics to detect exoplanets. Using the\ntime-series analysis library TSFresh to analyse light curves, we extracted 789\nfeatures from each curve, which capture the information about the\ncharacteristics of a light curve. We then used these features to train a\ngradient boosting classifier using the machine learning tool lightgbm. This\napproach was tested on simulated data, which showed that is more effective than\nthe conventional box least squares fitting (BLS) method. We further found that\nour method produced comparable results to existing state-of-the-art deep\nlearning models, while being much more computationally efficient and without\nneeding folded and secondary views of the light curves. For Kepler data, the\nmethod is able to predict a planet with an AUC of 0.948, so that 94.8 per cent\nof the true planet signals are ranked higher than non-planet signals. The\nresulting recall is 0.96, so that 96 per cent of real planets are classified as\nplanets. For the Transiting Exoplanet Survey Satellite (TESS) data, we found\nour method can classify light curves with an accuracy of 0.98, and is able to\nidentify planets with a recall of 0.82 at a precision of 0.63.",
    "published": "2020-11-28T14:06:39Z",
    "pdf_url": "http://arxiv.org/pdf/2011.14135v2",
    "categories": [
      "astro-ph.EP",
      "astro-ph.IM",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1603.09035v1",
    "title": "Towards Geo-Distributed Machine Learning",
    "authors": [
      "Ignacio Cano",
      "Markus Weimer",
      "Dhruv Mahajan",
      "Carlo Curino",
      "Giovanni Matteo Fumarola"
    ],
    "abstract": "Latency to end-users and regulatory requirements push large companies to\nbuild data centers all around the world. The resulting data is \"born\"\ngeographically distributed. On the other hand, many machine learning\napplications require a global view of such data in order to achieve the best\nresults. These types of applications form a new class of learning problems,\nwhich we call Geo-Distributed Machine Learning (GDML). Such applications need\nto cope with: 1) scarce and expensive cross-data center bandwidth, and 2)\ngrowing privacy concerns that are pushing for stricter data sovereignty\nregulations. Current solutions to learning from geo-distributed data sources\nrevolve around the idea of first centralizing the data in one data center, and\nthen training locally. As machine learning algorithms are\ncommunication-intensive, the cost of centralizing the data is thought to be\noffset by the lower cost of intra-data center communication during training. In\nthis work, we show that the current centralized practice can be far from\noptimal, and propose a system for doing geo-distributed training. Furthermore,\nwe argue that the geo-distributed approach is structurally more amenable to\ndealing with regulatory constraints, as raw data never leaves the source data\ncenter. Our empirical evaluation on three real datasets confirms the general\nvalidity of our approach, and shows that GDML is not only possible but also\nadvisable in many scenarios.",
    "published": "2016-03-30T04:05:29Z",
    "pdf_url": "http://arxiv.org/pdf/1603.09035v1",
    "categories": [
      "cs.LG",
      "cs.DC",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1901.03678v1",
    "title": "Machine Learning Automation Toolbox (MLaut)",
    "authors": [
      "Viktor Kazakov",
      "Franz J. Király"
    ],
    "abstract": "In this paper we present MLaut (Machine Learning AUtomation Toolbox) for the\npython data science ecosystem. MLaut automates large-scale evaluation and\nbenchmarking of machine learning algorithms on a large number of datasets.\nMLaut provides a high-level workflow interface to machine algorithm algorithms,\nimplements a local back-end to a database of dataset collections, trained\nalgorithms, and experimental results, and provides easy-to-use interfaces to\nthe scikit-learn and keras modelling libraries. Experiments are easy to set up\nwith default settings in a few lines of code, while remaining fully\ncustomizable to the level of hyper-parameter tuning, pipeline composition, or\ndeep learning architecture.\n  As a principal test case for MLaut, we conducted a large-scale supervised\nclassification study in order to benchmark the performance of a number of\nmachine learning algorithms - to our knowledge also the first larger-scale\nstudy on standard supervised learning data sets to include deep learning\nalgorithms. While corroborating a number of previous findings in literature, we\nfound (within the limitations of our study) that deep neural networks do not\nperform well on basic supervised learning, i.e., outside the more specialized,\nimage-, audio-, or text-based tasks.",
    "published": "2019-01-11T18:06:05Z",
    "pdf_url": "http://arxiv.org/pdf/1901.03678v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2410.22854v2",
    "title": "Hyperparameter Optimization in Machine Learning",
    "authors": [
      "Luca Franceschi",
      "Michele Donini",
      "Valerio Perrone",
      "Aaron Klein",
      "Cédric Archambeau",
      "Matthias Seeger",
      "Massimiliano Pontil",
      "Paolo Frasconi"
    ],
    "abstract": "Hyperparameters are configuration variables controlling the behavior of\nmachine learning algorithms. They are ubiquitous in machine learning and\nartificial intelligence and the choice of their values determines the\neffectiveness of systems based on these technologies. Manual hyperparameter\nsearch is often unsatisfactory and becomes infeasible when the number of\nhyperparameters is large. Automating the search is an important step towards\nadvancing, streamlining, and systematizing machine learning, freeing\nresearchers and practitioners alike from the burden of finding a good set of\nhyperparameters by trial and error. In this survey, we present a unified\ntreatment of hyperparameter optimization, providing the reader with examples,\ninsights into the state-of-the-art, and numerous links to further reading. We\ncover the main families of techniques to automate hyperparameter search, often\nreferred to as hyperparameter optimization or tuning, including random and\nquasi-random search, bandit-, model-, population-, and gradient-based\napproaches. We further discuss extensions, including online, constrained, and\nmulti-objective formulations, touch upon connections with other fields such as\nmeta-learning and neural architecture search, and conclude with open questions\nand future research directions.",
    "published": "2024-10-30T09:39:22Z",
    "pdf_url": "http://arxiv.org/pdf/2410.22854v2",
    "categories": [
      "stat.ML",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2411.10744v1",
    "title": "Digital-Analog Quantum Machine Learning",
    "authors": [
      "Lucas Lamata"
    ],
    "abstract": "Machine Learning algorithms are extensively used in an increasing number of\nsystems, applications, technologies, and products, both in industry and in\nsociety as a whole. They enable computing devices to learn from previous\nexperience and therefore improve their performance in a certain context or\nenvironment. In this way, many useful possibilities have been made accessible.\nHowever, dealing with an increasing amount of data poses difficulties for\nclassical devices. Quantum systems may offer a way forward, possibly enabling\nto scale up machine learning calculations in certain contexts. On the other\nhand, quantum systems themselves are also hard to scale up, due to decoherence\nand the fragility of quantum superpositions. In the short and mid term, it has\nbeen evidenced that a quantum paradigm that combines evolution under large\nanalog blocks with discrete quantum gates, may be fruitful to achieve new\nknowledge of classical and quantum systems with no need of having a\nfault-tolerant quantum computer. In this Perspective, we review some recent\nworks that employ this digital-analog quantum paradigm to carry out efficient\nmachine learning calculations with current quantum devices.",
    "published": "2024-11-16T08:54:52Z",
    "pdf_url": "http://arxiv.org/pdf/2411.10744v1",
    "categories": [
      "quant-ph",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2103.11249v1",
    "title": "SELM: Software Engineering of Machine Learning Models",
    "authors": [
      "Nafiseh Jafari",
      "Mohammad Reza Besharati",
      "Mohammad Izadi",
      "Maryam Hourali"
    ],
    "abstract": "One of the pillars of any machine learning model is its concepts. Using\nsoftware engineering, we can engineer these concepts and then develop and\nexpand them. In this article, we present a SELM framework for Software\nEngineering of machine Learning Models. We then evaluate this framework through\na case study. Using the SELM framework, we can improve a machine learning\nprocess efficiency and provide more accuracy in learning with less processing\nhardware resources and a smaller training dataset. This issue highlights the\nimportance of an interdisciplinary approach to machine learning. Therefore, in\nthis article, we have provided interdisciplinary teams' proposals for machine\nlearning.",
    "published": "2021-03-20T21:43:24Z",
    "pdf_url": "http://arxiv.org/pdf/2103.11249v1",
    "categories": [
      "cs.SE",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2306.14624v2",
    "title": "Insights From Insurance for Fair Machine Learning",
    "authors": [
      "Christian Fröhlich",
      "Robert C. Williamson"
    ],
    "abstract": "We argue that insurance can act as an analogon for the social situatedness of\nmachine learning systems, hence allowing machine learning scholars to take\ninsights from the rich and interdisciplinary insurance literature. Tracing the\ninteraction of uncertainty, fairness and responsibility in insurance provides a\nfresh perspective on fairness in machine learning. We link insurance fairness\nconceptions to their machine learning relatives, and use this bridge to\nproblematize fairness as calibration. In this process, we bring to the\nforefront two themes that have been largely overlooked in the machine learning\nliterature: responsibility and aggregate-individual tensions.",
    "published": "2023-06-26T11:56:00Z",
    "pdf_url": "http://arxiv.org/pdf/2306.14624v2",
    "categories": [
      "cs.LG",
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "2403.17381v1",
    "title": "Application-Driven Innovation in Machine Learning",
    "authors": [
      "David Rolnick",
      "Alan Aspuru-Guzik",
      "Sara Beery",
      "Bistra Dilkina",
      "Priya L. Donti",
      "Marzyeh Ghassemi",
      "Hannah Kerner",
      "Claire Monteleoni",
      "Esther Rolf",
      "Milind Tambe",
      "Adam White"
    ],
    "abstract": "As applications of machine learning proliferate, innovative algorithms\ninspired by specific real-world challenges have become increasingly important.\nSuch work offers the potential for significant impact not merely in domains of\napplication but also in machine learning itself. In this paper, we describe the\nparadigm of application-driven research in machine learning, contrasting it\nwith the more standard paradigm of methods-driven research. We illustrate the\nbenefits of application-driven machine learning and how this approach can\nproductively synergize with methods-driven work. Despite these benefits, we\nfind that reviewing, hiring, and teaching practices in machine learning often\nhold back application-driven innovation. We outline how these processes may be\nimproved.",
    "published": "2024-03-26T04:59:27Z",
    "pdf_url": "http://arxiv.org/pdf/2403.17381v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2108.07915v1",
    "title": "Data Pricing in Machine Learning Pipelines",
    "authors": [
      "Zicun Cong",
      "Xuan Luo",
      "Pei Jian",
      "Feida Zhu",
      "Yong Zhang"
    ],
    "abstract": "Machine learning is disruptive. At the same time, machine learning can only\nsucceed by collaboration among many parties in multiple steps naturally as\npipelines in an eco-system, such as collecting data for possible machine\nlearning applications, collaboratively training models by multiple parties and\ndelivering machine learning services to end users. Data is critical and\npenetrating in the whole machine learning pipelines. As machine learning\npipelines involve many parties and, in order to be successful, have to form a\nconstructive and dynamic eco-system, marketplaces and data pricing are\nfundamental in connecting and facilitating those many parties. In this article,\nwe survey the principles and the latest research development of data pricing in\nmachine learning pipelines. We start with a brief review of data marketplaces\nand pricing desiderata. Then, we focus on pricing in three important steps in\nmachine learning pipelines. To understand pricing in the step of training data\ncollection, we review pricing raw data sets and data labels. We also\ninvestigate pricing in the step of collaborative training of machine learning\nmodels, and overview pricing machine learning models for end users in the step\nof machine learning deployment. We also discuss a series of possible future\ndirections.",
    "published": "2021-08-18T00:57:06Z",
    "pdf_url": "http://arxiv.org/pdf/2108.07915v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2103.00366v2",
    "title": "Confronting Machine Learning With Financial Research",
    "authors": [
      "Kristof Lommers",
      "Ouns El Harzli",
      "Jack Kim"
    ],
    "abstract": "This study aims to examine the challenges and applications of machine\nlearning for financial research. Machine learning algorithms have been\ndeveloped for certain data environments which substantially differ from the one\nwe encounter in finance. Not only do difficulties arise due to some of the\nidiosyncrasies of financial markets, there is a fundamental tension between the\nunderlying paradigm of machine learning and the research philosophy in\nfinancial economics. Given the peculiar features of financial markets and the\nempirical framework within social science, various adjustments have to be made\nto the conventional machine learning methodology. We discuss some of the main\nchallenges of machine learning in finance and examine how these could be\naccounted for. Despite some of the challenges, we argue that machine learning\ncould be unified with financial research to become a robust complement to the\neconometrician's toolbox. Moreover, we discuss the various applications of\nmachine learning in the research process such as estimation, empirical\ndiscovery, testing, causal inference and prediction.",
    "published": "2021-02-28T01:10:09Z",
    "pdf_url": "http://arxiv.org/pdf/2103.00366v2",
    "categories": [
      "q-fin.ST",
      "cs.LG",
      "econ.EM"
    ]
  },
  {
    "arxiv_id": "1707.03184v1",
    "title": "A Survey on Resilient Machine Learning",
    "authors": [
      "Atul Kumar",
      "Sameep Mehta"
    ],
    "abstract": "Machine learning based system are increasingly being used for sensitive tasks\nsuch as security surveillance, guiding autonomous vehicle, taking investment\ndecisions, detecting and blocking network intrusion and malware etc. However,\nrecent research has shown that machine learning models are venerable to attacks\nby adversaries at all phases of machine learning (eg, training data collection,\ntraining, operation). All model classes of machine learning systems can be\nmisled by providing carefully crafted inputs making them wrongly classify\ninputs. Maliciously created input samples can affect the learning process of a\nML system by either slowing down the learning process, or affecting the\nperformance of the learned mode, or causing the system make error(s) only in\nattacker's planned scenario. Because of these developments, understanding\nsecurity of machine learning algorithms and systems is emerging as an important\nresearch area among computer security and machine learning researchers and\npractitioners. We present a survey of this emerging area in machine learning.",
    "published": "2017-07-11T09:15:46Z",
    "pdf_url": "http://arxiv.org/pdf/1707.03184v1",
    "categories": [
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2011.04328v1",
    "title": "Risk Assessment for Machine Learning Models",
    "authors": [
      "Paul Schwerdtner",
      "Florens Greßner",
      "Nikhil Kapoor",
      "Felix Assion",
      "René Sass",
      "Wiebke Günther",
      "Fabian Hüger",
      "Peter Schlicht"
    ],
    "abstract": "In this paper we propose a framework for assessing the risk associated with\ndeploying a machine learning model in a specified environment. For that we\ncarry over the risk definition from decision theory to machine learning. We\ndevelop and implement a method that allows to define deployment scenarios, test\nthe machine learning model under the conditions specified in each scenario, and\nestimate the damage associated with the output of the machine learning model\nunder test. Using the likelihood of each scenario together with the estimated\ndamage we define \\emph{key risk indicators} of a machine learning model.\n  The definition of scenarios and weighting by their likelihood allows for\nstandardized risk assessment in machine learning throughout multiple domains of\napplication. In particular, in our framework, the robustness of a machine\nlearning model to random input corruptions, distributional shifts caused by a\nchanging environment, and adversarial perturbations can be assessed.",
    "published": "2020-11-09T10:50:50Z",
    "pdf_url": "http://arxiv.org/pdf/2011.04328v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2406.04344v3",
    "title": "Verbalized Machine Learning: Revisiting Machine Learning with Language\n  Models",
    "authors": [
      "Tim Z. Xiao",
      "Robert Bamler",
      "Bernhard Schölkopf",
      "Weiyang Liu"
    ],
    "abstract": "Motivated by the progress made by large language models (LLMs), we introduce\nthe framework of verbalized machine learning (VML). In contrast to conventional\nmachine learning (ML) models that are typically optimized over a continuous\nparameter space, VML constrains the parameter space to be human-interpretable\nnatural language. Such a constraint leads to a new perspective of function\napproximation, where an LLM with a text prompt can be viewed as a function\nparameterized by the text prompt. Guided by this perspective, we revisit\nclassical ML problems, such as regression and classification, and find that\nthese problems can be solved by an LLM-parameterized learner and optimizer. The\nmajor advantages of VML include (1) easy encoding of inductive bias: prior\nknowledge about the problem and hypothesis class can be encoded in natural\nlanguage and fed into the LLM-parameterized learner; (2) automatic model class\nselection: the optimizer can automatically select a model class based on data\nand verbalized prior knowledge, and it can update the model class during\ntraining; and (3) interpretable learner updates: the LLM-parameterized\noptimizer can provide explanations for why an update is performed. We\nempirically verify the effectiveness of VML, and hope that VML can serve as a\nstepping stone to stronger interpretability.",
    "published": "2024-06-06T17:59:56Z",
    "pdf_url": "http://arxiv.org/pdf/2406.04344v3",
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1905.03853v2",
    "title": "Genuinely Distributed Byzantine Machine Learning",
    "authors": [
      "El-Mahdi El-Mhamdi",
      "Rachid Guerraoui",
      "Arsany Guirguis",
      "Lê Nguyên Hoang",
      "Sébastien Rouault"
    ],
    "abstract": "Machine Learning (ML) solutions are nowadays distributed, according to the\nso-called server/worker architecture. One server holds the model parameters\nwhile several workers train the model. Clearly, such architecture is prone to\nvarious types of component failures, which can be all encompassed within the\nspectrum of a Byzantine behavior. Several approaches have been proposed\nrecently to tolerate Byzantine workers. Yet all require trusting a central\nparameter server. We initiate in this paper the study of the ``general''\nByzantine-resilient distributed machine learning problem where no individual\ncomponent is trusted.\n  We show that this problem can be solved in an asynchronous system, despite\nthe presence of $\\frac{1}{3}$ Byzantine parameter servers and $\\frac{1}{3}$\nByzantine workers (which is optimal). We present a new algorithm, ByzSGD, which\nsolves the general Byzantine-resilient distributed machine learning problem by\nrelying on three major schemes. The first, Scatter/Gather, is a communication\nscheme whose goal is to bound the maximum drift among models on correct\nservers. The second, Distributed Median Contraction (DMC), leverages the\ngeometric properties of the median in high dimensional spaces to bring\nparameters within the correct servers back close to each other, ensuring\nlearning convergence. The third, Minimum-Diameter Averaging (MDA), is a\nstatistically-robust gradient aggregation rule whose goal is to tolerate\nByzantine workers. MDA requires loose bound on the variance of non-Byzantine\ngradient estimates, compared to existing alternatives (e.g., Krum).\nInterestingly, ByzSGD ensures Byzantine resilience without adding communication\nrounds (on a normal path), compared to vanilla non-Byzantine alternatives.\nByzSGD requires, however, a larger number of messages which, we show, can be\nreduced if we assume synchrony.",
    "published": "2019-05-05T16:14:30Z",
    "pdf_url": "http://arxiv.org/pdf/1905.03853v2",
    "categories": [
      "cs.DC",
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1603.02021v1",
    "title": "Machine Learning for Protein Function",
    "authors": [
      "Dan Ofer"
    ],
    "abstract": "Systematic identification of protein function is a key problem in current\nbiology. Most traditional methods fail to identify functionally equivalent\nproteins if they lack similar sequences, structural data or extensive manual\nannotations. In this thesis, I focused on feature engineering and machine\nlearning methods for identifying diverse classes of proteins that share\nfunctional relatedness but little sequence or structural similarity, notably,\nNeuropeptide Precursors (NPPs).\n  I aim to identify functional protein classes solely using unannotated protein\nprimary sequences from any organism. This thesis focuses on feature\nrepresentations of whole protein sequences, sequence derived engineered\nfeatures, their extraction, frameworks for their usage by machine learning (ML)\nmodels, and the application of ML models to biological tasks, focusing on high\nlevel protein functions. I implemented the ideas of feature engineering to\ndevelop a platform (called NeuroPID) that extracts meaningful features for\nclassification of overlooked NPPs. The platform allows mass discovery of new\nNPs and NPPs. It was expanded as a webserver.\n  I expanded our approach towards other challenging protein classes. This is\nimplemented as a novel bioinformatics toolkit called ProFET (Protein Feature\nEngineering Toolkit). ProFET extracts hundreds of biophysical and sequence\nderived attributes, allowing the application of machine learning methods to\nproteins. ProFET was applied on many protein benchmark datasets with state of\nthe art performance. The success of ProFET applies to a wide range of\nhigh-level functions such as metagenomic analysis, subcellular localization,\nstructure and unique functional properties (e.g. thermophiles, nucleic acid\nbinding).\n  These methods and frameworks represent a valuable resource for using ML and\ndata science methods on proteins.",
    "published": "2016-03-07T12:04:10Z",
    "pdf_url": "http://arxiv.org/pdf/1603.02021v1",
    "categories": [
      "q-bio.GN"
    ]
  },
  {
    "arxiv_id": "0701907v3",
    "title": "Kernel methods in machine learning",
    "authors": [
      "Thomas Hofmann",
      "Bernhard Schölkopf",
      "Alexander J. Smola"
    ],
    "abstract": "We review machine learning methods employing positive definite kernels. These\nmethods formulate learning and estimation problems in a reproducing kernel\nHilbert space (RKHS) of functions defined on the data domain, expanded in terms\nof a kernel. Working in linear spaces of function has the benefit of\nfacilitating the construction and analysis of learning algorithms while at the\nsame time allowing large classes of functions. The latter include nonlinear\nfunctions as well as functions defined on nonvectorial data. We cover a wide\nrange of methods, ranging from binary classifiers to sophisticated methods for\nestimation with structured data.",
    "published": "2007-01-31T03:42:40Z",
    "pdf_url": "http://arxiv.org/pdf/math/0701907v3",
    "categories": [
      "math.ST",
      "math.PR",
      "stat.TH",
      "30C40 (Primary) 68T05 (Secondary)"
    ]
  },
  {
    "arxiv_id": "1103.1003v1",
    "title": "Teraflop-scale Incremental Machine Learning",
    "authors": [
      "Eray Özkural"
    ],
    "abstract": "We propose a long-term memory design for artificial general intelligence\nbased on Solomonoff's incremental machine learning methods. We use R5RS Scheme\nand its standard library with a few omissions as the reference machine. We\nintroduce a Levin Search variant based on Stochastic Context Free Grammar\ntogether with four synergistic update algorithms that use the same grammar as a\nguiding probability distribution of programs. The update algorithms include\nadjusting production probabilities, re-using previous solutions, learning\nprogramming idioms and discovery of frequent subprograms. Experiments with two\ntraining sequences demonstrate that our approach to incremental learning is\neffective.",
    "published": "2011-03-05T03:41:30Z",
    "pdf_url": "http://arxiv.org/pdf/1103.1003v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1107.4340v1",
    "title": "Spectral approximations in machine learning",
    "authors": [
      "Darren Homrighausen",
      "Daniel J. McDonald"
    ],
    "abstract": "In many areas of machine learning, it becomes necessary to find the\neigenvector decompositions of large matrices. We discuss two methods for\nreducing the computational burden of spectral decompositions: the more\nvenerable Nystom extension and a newly introduced algorithm based on random\nprojections. Previous work has centered on the ability to reconstruct the\noriginal matrix. We argue that a more interesting and relevant comparison is\ntheir relative performance in clustering and classification tasks using the\napproximate eigenvectors as features. We demonstrate that performance is task\nspecific and depends on the rank of the approximation.",
    "published": "2011-07-21T18:44:51Z",
    "pdf_url": "http://arxiv.org/pdf/1107.4340v1",
    "categories": [
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1404.1333v2",
    "title": "Understanding Machine-learned Density Functionals",
    "authors": [
      "Li Li",
      "John C. Snyder",
      "Isabelle M. Pelaschier",
      "Jessica Huang",
      "Uma-Naresh Niranjan",
      "Paul Duncan",
      "Matthias Rupp",
      "Klaus-Robert Müller",
      "Kieron Burke"
    ],
    "abstract": "Kernel ridge regression is used to approximate the kinetic energy of\nnon-interacting fermions in a one-dimensional box as a functional of their\ndensity. The properties of different kernels and methods of cross-validation\nare explored, and highly accurate energies are achieved. Accurate {\\em\nconstrained optimal densities} are found via a modified Euler-Lagrange\nconstrained minimization of the total energy. A projected gradient descent\nalgorithm is derived using local principal component analysis. Additionally, a\nsparse grid representation of the density can be used without degrading the\nperformance of the methods. The implications for machine-learned density\nfunctional approximations are discussed.",
    "published": "2014-04-04T18:20:23Z",
    "pdf_url": "http://arxiv.org/pdf/1404.1333v2",
    "categories": [
      "physics.chem-ph",
      "cs.LG",
      "physics.comp-ph",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1708.06615v3",
    "title": "Exploring supersymmetry with machine learning",
    "authors": [
      "Jie Ren",
      "Lei Wu",
      "Jin Min Yang",
      "Jun Zhao"
    ],
    "abstract": "Investigation of well-motivated parameter space in the theories of Beyond the\nStandard Model (BSM) plays an important role in new physics discoveries.\nHowever, a large-scale exploration of models with multi-parameter or equivalent\nsolutions with a finite separation, such as supersymmetric models, is typically\na time-consuming and challenging task. In this paper, we propose a\nself-exploration method, named Machine Learning Scan (MLS), to achieve an\nefficient test of models. As a proof-of-concept, we apply MLS to investigate\nthe subspace of MSSM and CMSSM and find that such a method can reduce the\ncomputational cost and may be helpful for accelerating the exploration of\nsupersymmetry.",
    "published": "2017-08-22T13:56:48Z",
    "pdf_url": "http://arxiv.org/pdf/1708.06615v3",
    "categories": [
      "hep-ph"
    ]
  },
  {
    "arxiv_id": "1808.06492v1",
    "title": "Benchmarking Automatic Machine Learning Frameworks",
    "authors": [
      "Adithya Balaji",
      "Alexander Allen"
    ],
    "abstract": "AutoML serves as the bridge between varying levels of expertise when\ndesigning machine learning systems and expedites the data science process. A\nwide range of techniques is taken to address this, however there does not exist\nan objective comparison of these techniques. We present a benchmark of current\nopen source AutoML solutions using open source datasets. We test auto-sklearn,\nTPOT, auto_ml, and H2O's AutoML solution against a compiled set of regression\nand classification datasets sourced from OpenML and find that auto-sklearn\nperforms the best across classification datasets and TPOT performs the best\nacross regression datasets.",
    "published": "2018-08-17T02:15:39Z",
    "pdf_url": "http://arxiv.org/pdf/1808.06492v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2006.04747v2",
    "title": "Secure Byzantine-Robust Machine Learning",
    "authors": [
      "Lie He",
      "Sai Praneeth Karimireddy",
      "Martin Jaggi"
    ],
    "abstract": "Increasingly machine learning systems are being deployed to edge servers and\ndevices (e.g. mobile phones) and trained in a collaborative manner. Such\ndistributed/federated/decentralized training raises a number of concerns about\nthe robustness, privacy, and security of the procedure. While extensive work\nhas been done in tackling with robustness, privacy, or security individually,\ntheir combination has rarely been studied. In this paper, we propose a secure\ntwo-server protocol that offers both input privacy and Byzantine-robustness. In\naddition, this protocol is communication-efficient, fault-tolerant and enjoys\nlocal differential privacy.",
    "published": "2020-06-08T16:55:15Z",
    "pdf_url": "http://arxiv.org/pdf/2006.04747v2",
    "categories": [
      "cs.LG",
      "cs.CR",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2101.01759v2",
    "title": "Machine Learning and Quantum Devices",
    "authors": [
      "Florian Marquardt"
    ],
    "abstract": "These brief lecture notes cover the basics of neural networks and deep\nlearning as well as their applications in the quantum domain, for physicists\nwithout prior knowledge. In the first part, we describe training using\nbackpropagation, image classification, convolutional networks and autoencoders.\nThe second part is about advanced techniques like reinforcement learning (for\ndiscovering control strategies), recurrent neural networks (for analyzing time\ntraces), and Boltzmann machines (for learning probability distributions). In\nthe third lecture, we discuss first recent applications to quantum physics,\nwith an emphasis on quantum information processing machines. Finally, the\nfourth lecture is devoted to the promise of using quantum effects to accelerate\nmachine learning.",
    "published": "2021-01-05T19:48:24Z",
    "pdf_url": "http://arxiv.org/pdf/2101.01759v2",
    "categories": [
      "quant-ph"
    ]
  },
  {
    "arxiv_id": "1912.03354v1",
    "title": "Bilinear Models for Machine Learning",
    "authors": [
      "Tayssir Doghri",
      "Leszek Szczecinski",
      "Jacob Benesty",
      "Amar Mitiche"
    ],
    "abstract": "In this work we define and analyze the bilinear models which replace the\nconventional linear operation used in many building blocks of machine learning\n(ML). The main idea is to devise the ML algorithms which are adapted to the\nobjects they treat. In the case of monochromatic images, we show that the\nbilinear operation exploits better the structure of the image than the\nconventional linear operation which ignores the spatial relationship between\nthe pixels. This translates into significantly smaller number of parameters\nrequired to yield the same performance. We show numerical examples of\nclassification in the MNIST data set.",
    "published": "2019-12-06T21:59:59Z",
    "pdf_url": "http://arxiv.org/pdf/1912.03354v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1807.07260v1",
    "title": "Machine Learning Based Featureless Signalling",
    "authors": [
      "Ismail Shakeel"
    ],
    "abstract": "Direct-sequence spread-spectrum (DSSS) is commonly used to mitigate the\neffect of jamming and to operate under an adversary receiver's thermal noise\nfloor in order to avoid signal detection. Unfortunately, the discrete nature\nand unique distribution of DSSS spreading sequences make it relatively easy to\ndetect the resulting transmitted signals. To overcome this issue, this paper\nproposes a machine learning based scheme that generates featureless,\nnon-repetitive noise-like spread signals. The proposed scheme provides several\nbenefits over the standard DSSS system including the ability to generate\nsignals with low probabilities of detection/intercept, additional processing\ngain and also an uncoordinated synchronisation method.",
    "published": "2018-07-19T06:59:33Z",
    "pdf_url": "http://arxiv.org/pdf/1807.07260v1",
    "categories": [
      "eess.SP"
    ]
  },
  {
    "arxiv_id": "2209.01091v2",
    "title": "Machine Learning Post-Minkowskian Integrals",
    "authors": [
      "Ryusuke Jinno",
      "Gregor Kälin",
      "Zhengwen Liu",
      "Henrique Rubira"
    ],
    "abstract": "We study a neural network framework for the numerical evaluation of Feynman\nloop integrals that are fundamental building blocks for perturbative\ncomputations of physical observables in gauge and gravity theories. We show\nthat such a machine learning approach improves the convergence of the Monte\nCarlo algorithm for high-precision evaluation of multi-dimensional integrals\ncompared to traditional algorithms. In particular, we use a neural network to\nimprove the importance sampling. For a set of representative integrals\nappearing in the computation of the conservative dynamics for a compact binary\nsystem in General Relativity, we perform a quantitative comparison between the\nMonte Carlo integrators VEGAS and i-flow, an integrator based on neural network\nsampling.",
    "published": "2022-09-02T14:44:21Z",
    "pdf_url": "http://arxiv.org/pdf/2209.01091v2",
    "categories": [
      "hep-th",
      "gr-qc",
      "hep-ph"
    ]
  },
  {
    "arxiv_id": "2003.13339v1",
    "title": "Machine Learning String Standard Models",
    "authors": [
      "Rehan Deen",
      "Yang-Hui He",
      "Seung-Joo Lee",
      "Andre Lukas"
    ],
    "abstract": "We study machine learning of phenomenologically relevant properties of string\ncompactifications, which arise in the context of heterotic line bundle models.\nBoth supervised and unsupervised learning are considered. We find that, for a\nfixed compactification manifold, relatively small neural networks are capable\nof distinguishing consistent line bundle models with the correct gauge group\nand the correct chiral asymmetry from random models without these properties.\nThe same distinction can also be achieved in the context of unsupervised\nlearning, using an auto-encoder. Learning non-topological properties,\nspecifically the number of Higgs multiplets, turns out to be more difficult,\nbut is possible using sizeable networks and feature-enhanced data sets.",
    "published": "2020-03-30T11:14:14Z",
    "pdf_url": "http://arxiv.org/pdf/2003.13339v1",
    "categories": [
      "hep-th",
      "math.AG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2109.04298v1",
    "title": "Quantum Machine Learning for Finance",
    "authors": [
      "Marco Pistoia",
      "Syed Farhan Ahmad",
      "Akshay Ajagekar",
      "Alexander Buts",
      "Shouvanik Chakrabarti",
      "Dylan Herman",
      "Shaohan Hu",
      "Andrew Jena",
      "Pierre Minssen",
      "Pradeep Niroula",
      "Arthur Rattew",
      "Yue Sun",
      "Romina Yalovetzky"
    ],
    "abstract": "Quantum computers are expected to surpass the computational capabilities of\nclassical computers during this decade, and achieve disruptive impact on\nnumerous industry sectors, particularly finance. In fact, finance is estimated\nto be the first industry sector to benefit from Quantum Computing not only in\nthe medium and long terms, but even in the short term. This review paper\npresents the state of the art of quantum algorithms for financial applications,\nwith particular focus to those use cases that can be solved via Machine\nLearning.",
    "published": "2021-09-09T14:20:10Z",
    "pdf_url": "http://arxiv.org/pdf/2109.04298v1",
    "categories": [
      "quant-ph",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2112.06350v2",
    "title": "Machine Learning Calabi-Yau Hypersurfaces",
    "authors": [
      "David S. Berman",
      "Yang-Hui He",
      "Edward Hirst"
    ],
    "abstract": "We revisit the classic database of weighted-P4s which admit Calabi-Yau 3-fold\nhypersurfaces equipped with a diverse set of tools from the machine-learning\ntoolbox. Unsupervised techniques identify an unanticipated almost linear\ndependence of the topological data on the weights. This then allows us to\nidentify a previously unnoticed clustering in the Calabi-Yau data. Supervised\ntechniques are successful in predicting the topological parameters of the\nhypersurface from its weights with an accuracy of R^2 > 95%. Supervised\nlearning also allows us to identify weighted-P4s which admit Calabi-Yau\nhypersurfaces to 100% accuracy by making use of partitioning supported by the\nclustering behaviour.",
    "published": "2021-12-12T23:17:31Z",
    "pdf_url": "http://arxiv.org/pdf/2112.06350v2",
    "categories": [
      "hep-th",
      "math.AG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2203.04983v1",
    "title": "Modeling hadronization using machine learning",
    "authors": [
      "Phil Ilten",
      "Tony Menzo",
      "Ahmed Youssef",
      "Jure Zupan"
    ],
    "abstract": "We present the first steps in the development of a new class of hadronization\nmodels utilizing machine learning techniques. We successfully implement,\nvalidate, and train a conditional sliced-Wasserstein autoencoder to replicate\nthe Pythia generated kinematic distributions of first-hadron emissions, when\nthe Lund string model of hadronization implemented in Pythia is restricted to\nthe emissions of pions only. The trained models are then used to generate the\nfull hadronization chains, with an IR cutoff energy imposed externally. The\nhadron multiplicities and cumulative kinematic distributions are shown to match\nthe Pythia generated ones. We also discuss possible future generalizations of\nour results.",
    "published": "2022-03-09T19:00:02Z",
    "pdf_url": "http://arxiv.org/pdf/2203.04983v1",
    "categories": [
      "hep-ph"
    ]
  },
  {
    "arxiv_id": "1807.07987v2",
    "title": "Deep Learning",
    "authors": [
      "Nicholas G. Polson",
      "Vadim O. Sokolov"
    ],
    "abstract": "Deep learning (DL) is a high dimensional data reduction technique for\nconstructing high-dimensional predictors in input-output models. DL is a form\nof machine learning that uses hierarchical layers of latent features. In this\narticle, we review the state-of-the-art of deep learning from a modeling and\nalgorithmic perspective. We provide a list of successful areas of applications\nin Artificial Intelligence (AI), Image Processing, Robotics and Automation.\nDeep learning is predictive in its nature rather then inferential and can be\nviewed as a black-box methodology for high-dimensional function estimation.",
    "published": "2018-07-20T18:20:34Z",
    "pdf_url": "http://arxiv.org/pdf/1807.07987v2",
    "categories": [
      "stat.ML",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1806.01756v1",
    "title": "Concept-Oriented Deep Learning",
    "authors": [
      "Daniel T Chang"
    ],
    "abstract": "Concepts are the foundation of human deep learning, understanding, and\nknowledge integration and transfer. We propose concept-oriented deep learning\n(CODL) which extends (machine) deep learning with concept representations and\nconceptual understanding capability. CODL addresses some of the major\nlimitations of deep learning: interpretability, transferability, contextual\nadaptation, and requirement for lots of labeled training data. We discuss the\nmajor aspects of CODL including concept graph, concept representations, concept\nexemplars, and concept representation learning systems supporting incremental\nand continual learning.",
    "published": "2018-06-05T15:50:30Z",
    "pdf_url": "http://arxiv.org/pdf/1806.01756v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1808.08618v2",
    "title": "Deep Learning: Computational Aspects",
    "authors": [
      "Nicholas Polson",
      "Vadim Sokolov"
    ],
    "abstract": "In this article we review computational aspects of Deep Learning (DL). Deep\nlearning uses network architectures consisting of hierarchical layers of latent\nvariables to construct predictors for high-dimensional input-output models.\nTraining a deep learning architecture is computationally intensive, and\nefficient linear algebra libraries is the key for training and inference.\nStochastic gradient descent (SGD) optimization and batch sampling are used to\nlearn from massive data sets.",
    "published": "2018-08-26T20:26:11Z",
    "pdf_url": "http://arxiv.org/pdf/1808.08618v2",
    "categories": [
      "cs.LG",
      "stat.CO",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1710.05468v9",
    "title": "Generalization in Deep Learning",
    "authors": [
      "Kenji Kawaguchi",
      "Leslie Pack Kaelbling",
      "Yoshua Bengio"
    ],
    "abstract": "This paper provides theoretical insights into why and how deep learning can\ngeneralize well, despite its large capacity, complexity, possible algorithmic\ninstability, nonrobustness, and sharp minima, responding to an open question in\nthe literature. We also discuss approaches to provide non-vacuous\ngeneralization guarantees for deep learning. Based on theoretical observations,\nwe propose new open problems and discuss the limitations of our results.",
    "published": "2017-10-16T02:21:24Z",
    "pdf_url": "http://arxiv.org/pdf/1710.05468v9",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "2006.03364v1",
    "title": "Structure preserving deep learning",
    "authors": [
      "Elena Celledoni",
      "Matthias J. Ehrhardt",
      "Christian Etmann",
      "Robert I McLachlan",
      "Brynjulf Owren",
      "Carola-Bibiane Schönlieb",
      "Ferdia Sherry"
    ],
    "abstract": "Over the past few years, deep learning has risen to the foreground as a topic\nof massive interest, mainly as a result of successes obtained in solving\nlarge-scale image processing tasks. There are multiple challenging mathematical\nproblems involved in applying deep learning: most deep learning methods require\nthe solution of hard optimisation problems, and a good understanding of the\ntradeoff between computational effort, amount of data and model complexity is\nrequired to successfully design a deep learning approach for a given problem. A\nlarge amount of progress made in deep learning has been based on heuristic\nexplorations, but there is a growing effort to mathematically understand the\nstructure in existing deep learning methods and to systematically design new\ndeep learning methods to preserve certain types of structure in deep learning.\nIn this article, we review a number of these directions: some deep neural\nnetworks can be understood as discretisations of dynamical systems, neural\nnetworks can be designed to have desirable properties such as invertibility or\ngroup equivariance, and new algorithmic frameworks based on conformal\nHamiltonian systems and Riemannian manifolds to solve the optimisation problems\nhave been proposed. We conclude our review of each of these topics by\ndiscussing some open problems that we consider to be interesting directions for\nfuture research.",
    "published": "2020-06-05T10:59:09Z",
    "pdf_url": "http://arxiv.org/pdf/2006.03364v1",
    "categories": [
      "cs.LG",
      "cs.NA",
      "math.NA",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1804.01653v2",
    "title": "Review of Deep Learning",
    "authors": [
      "Rong Zhang",
      "Weiping Li",
      "Tong Mo"
    ],
    "abstract": "In recent years, China, the United States and other countries, Google and\nother high-tech companies have increased investment in artificial intelligence.\nDeep learning is one of the current artificial intelligence research's key\nareas. This paper analyzes and summarizes the latest progress and future\nresearch directions of deep learning. Firstly, three basic models of deep\nlearning are outlined, including multilayer perceptrons, convolutional neural\nnetworks, and recurrent neural networks. On this basis, we further analyze the\nemerging new models of convolution neural networks and recurrent neural\nnetworks. This paper then summarizes deep learning's applications in many areas\nof artificial intelligence, including speech processing, computer vision,\nnatural language processing and so on. Finally, this paper discusses the\nexisting problems of deep learning and gives the corresponding possible\nsolutions.",
    "published": "2018-04-05T02:23:59Z",
    "pdf_url": "http://arxiv.org/pdf/1804.01653v2",
    "categories": [
      "cs.LG",
      "cs.CV",
      "cs.NE",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2006.10027v2",
    "title": "Deep Learning Meets SAR",
    "authors": [
      "Xiao Xiang Zhu",
      "Sina Montazeri",
      "Mohsin Ali",
      "Yuansheng Hua",
      "Yuanyuan Wang",
      "Lichao Mou",
      "Yilei Shi",
      "Feng Xu",
      "Richard Bamler"
    ],
    "abstract": "Deep learning in remote sensing has become an international hype, but it is\nmostly limited to the evaluation of optical data. Although deep learning has\nbeen introduced in Synthetic Aperture Radar (SAR) data processing, despite\nsuccessful first attempts, its huge potential remains locked. In this paper, we\nprovide an introduction to the most relevant deep learning models and concepts,\npoint out possible pitfalls by analyzing special characteristics of SAR data,\nreview the state-of-the-art of deep learning applied to SAR in depth, summarize\navailable benchmarks, and recommend some important future research directions.\nWith this effort, we hope to stimulate more research in this interesting yet\nunder-exploited research field and to pave the way for use of deep learning in\nbig SAR data processing workflows.",
    "published": "2020-06-17T17:46:36Z",
    "pdf_url": "http://arxiv.org/pdf/2006.10027v2",
    "categories": [
      "eess.IV",
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1808.09772v2",
    "title": "Notes on Deep Learning for NLP",
    "authors": [
      "Antoine J. -P. Tixier"
    ],
    "abstract": "My notes on Deep Learning for NLP.",
    "published": "2018-08-29T12:58:45Z",
    "pdf_url": "http://arxiv.org/pdf/1808.09772v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "1602.06561v3",
    "title": "Deep Learning in Finance",
    "authors": [
      "J. B. Heaton",
      "N. G. Polson",
      "J. H. Witte"
    ],
    "abstract": "We explore the use of deep learning hierarchical models for problems in\nfinancial prediction and classification. Financial prediction problems -- such\nas those presented in designing and pricing securities, constructing\nportfolios, and risk management -- often involve large data sets with complex\ndata interactions that currently are difficult or impossible to specify in a\nfull economic model. Applying deep learning methods to these problems can\nproduce more useful results than standard methods in finance. In particular,\ndeep learning can detect and exploit interactions in the data that are, at\nleast currently, invisible to any existing financial economic theory.",
    "published": "2016-02-21T18:19:56Z",
    "pdf_url": "http://arxiv.org/pdf/1602.06561v3",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1902.11122v5",
    "title": "Deep Learning in Cardiology",
    "authors": [
      "Paschalis Bizopoulos",
      "Dimitrios Koutsouris"
    ],
    "abstract": "The medical field is creating large amount of data that physicians are unable\nto decipher and use efficiently. Moreover, rule-based expert systems are\ninefficient in solving complicated medical tasks or for creating insights using\nbig data. Deep learning has emerged as a more accurate and effective technology\nin a wide range of medical problems such as diagnosis, prediction and\nintervention. Deep learning is a representation learning method that consists\nof layers that transform the data non-linearly, thus, revealing hierarchical\nrelationships and structures. In this review we survey deep learning\napplication papers that use structured data, signal and imaging modalities from\ncardiology. We discuss the advantages and limitations of applying deep learning\nin cardiology that also apply in medicine in general, while proposing certain\ndirections as the most viable for clinical use.",
    "published": "2019-02-22T10:09:11Z",
    "pdf_url": "http://arxiv.org/pdf/1902.11122v5",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1908.06315v4",
    "title": "Implicit Deep Learning",
    "authors": [
      "Laurent El Ghaoui",
      "Fangda Gu",
      "Bertrand Travacca",
      "Armin Askari",
      "Alicia Y. Tsai"
    ],
    "abstract": "Implicit deep learning prediction rules generalize the recursive rules of\nfeedforward neural networks. Such rules are based on the solution of a\nfixed-point equation involving a single vector of hidden features, which is\nthus only implicitly defined. The implicit framework greatly simplifies the\nnotation of deep learning, and opens up many new possibilities, in terms of\nnovel architectures and algorithms, robustness analysis and design,\ninterpretability, sparsity, and network architecture optimization.",
    "published": "2019-08-17T15:36:37Z",
    "pdf_url": "http://arxiv.org/pdf/1908.06315v4",
    "categories": [
      "cs.LG",
      "math.OC",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1603.06430v5",
    "title": "Deep Learning in Bioinformatics",
    "authors": [
      "Seonwoo Min",
      "Byunghan Lee",
      "Sungroh Yoon"
    ],
    "abstract": "In the era of big data, transformation of biomedical big data into valuable\nknowledge has been one of the most important challenges in bioinformatics. Deep\nlearning has advanced rapidly since the early 2000s and now demonstrates\nstate-of-the-art performance in various fields. Accordingly, application of\ndeep learning in bioinformatics to gain insight from data has been emphasized\nin both academia and industry. Here, we review deep learning in bioinformatics,\npresenting examples of current research. To provide a useful and comprehensive\nperspective, we categorize research both by the bioinformatics domain (i.e.,\nomics, biomedical imaging, biomedical signal processing) and deep learning\narchitecture (i.e., deep neural networks, convolutional neural networks,\nrecurrent neural networks, emergent architectures) and present brief\ndescriptions of each study. Additionally, we discuss theoretical and practical\nissues of deep learning in bioinformatics and suggest future research\ndirections. We believe that this review will provide valuable insights and\nserve as a starting point for researchers to apply deep learning approaches in\ntheir bioinformatics studies.",
    "published": "2016-03-21T13:55:02Z",
    "pdf_url": "http://arxiv.org/pdf/1603.06430v5",
    "categories": [
      "cs.LG",
      "q-bio.GN"
    ]
  },
  {
    "arxiv_id": "1805.04825v1",
    "title": "Deep Learning in Software Engineering",
    "authors": [
      "Xiaochen Li",
      "He Jiang",
      "Zhilei Ren",
      "Ge Li",
      "Jingxuan Zhang"
    ],
    "abstract": "Recent years, deep learning is increasingly prevalent in the field of\nSoftware Engineering (SE). However, many open issues still remain to be\ninvestigated. How do researchers integrate deep learning into SE problems?\nWhich SE phases are facilitated by deep learning? Do practitioners benefit from\ndeep learning? The answers help practitioners and researchers develop practical\ndeep learning models for SE tasks. To answer these questions, we conduct a\nbibliography analysis on 98 research papers in SE that use deep learning\ntechniques. We find that 41 SE tasks in all SE phases have been facilitated by\ndeep learning integrated solutions. In which, 84.7% papers only use standard\ndeep learning models and their variants to solve SE problems. The\npracticability becomes a concern in utilizing deep learning techniques. How to\nimprove the effectiveness, efficiency, understandability, and testability of\ndeep learning based solutions may attract more SE researchers in the future.",
    "published": "2018-05-13T06:01:39Z",
    "pdf_url": "http://arxiv.org/pdf/1805.04825v1",
    "categories": [
      "cs.SE"
    ]
  },
  {
    "arxiv_id": "2306.04469v1",
    "title": "Model-Based Deep Learning",
    "authors": [
      "Nir Shlezinger",
      "Yonina C. Eldar"
    ],
    "abstract": "Signal processing traditionally relies on classical statistical modeling\ntechniques. Such model-based methods utilize mathematical formulations that\nrepresent the underlying physics, prior information and additional domain\nknowledge. Simple classical models are useful but sensitive to inaccuracies and\nmay lead to poor performance when real systems display complex or dynamic\nbehavior. More recently, deep learning approaches that use deep neural networks\nare becoming increasingly popular. Deep learning systems do not rely on\nmathematical modeling, and learn their mapping from data, which allows them to\noperate in complex environments. However, they lack the interpretability and\nreliability of model-based methods, typically require large training sets to\nobtain good performance, and tend to be computationally complex. Model-based\nsignal processing methods and data-centric deep learning each have their pros\nand cons. These paradigms can be characterized as edges of a continuous\nspectrum varying in specificity and parameterization. The methodologies that\nlie in the middle ground of this spectrum, thus integrating model-based signal\nprocessing with deep learning, are referred to as model-based deep learning,\nand are the focus here. This monograph provides a tutorial style presentation\nof model-based deep learning methodologies. These are families of algorithms\nthat combine principled mathematical models with data-driven systems to benefit\nfrom the advantages of both approaches. Such model-based deep learning methods\nexploit both partial domain knowledge, via mathematical structures designed for\nspecific problems, as well as learning from limited data. We accompany our\npresentation with running examples, in super-resolution, dynamic systems, and\narray processing. We show how they are expressed using the provided\ncharacterization and specialized in each of the detailed methodologies.",
    "published": "2023-06-05T03:17:07Z",
    "pdf_url": "http://arxiv.org/pdf/2306.04469v1",
    "categories": [
      "eess.SP"
    ]
  },
  {
    "arxiv_id": "1709.05871v1",
    "title": "IBM Deep Learning Service",
    "authors": [
      "Bishwaranjan Bhattacharjee",
      "Scott Boag",
      "Chandani Doshi",
      "Parijat Dube",
      "Ben Herta",
      "Vatche Ishakian",
      "K. R. Jayaram",
      "Rania Khalaf",
      "Avesh Krishna",
      "Yu Bo Li",
      "Vinod Muthusamy",
      "Ruchir Puri",
      "Yufei Ren",
      "Florian Rosenberg",
      "Seetharami R. Seelam",
      "Yandong Wang",
      "Jian Ming Zhang",
      "Li Zhang"
    ],
    "abstract": "Deep learning driven by large neural network models is overtaking traditional\nmachine learning methods for understanding unstructured and perceptual data\ndomains such as speech, text, and vision. At the same time, the\n\"as-a-Service\"-based business model on the cloud is fundamentally transforming\nthe information technology industry. These two trends: deep learning, and\n\"as-a-service\" are colliding to give rise to a new business model for cognitive\napplication delivery: deep learning as a service in the cloud. In this paper,\nwe will discuss the details of the software architecture behind IBM's deep\nlearning as a service (DLaaS). DLaaS provides developers the flexibility to use\npopular deep learning libraries such as Caffe, Torch and TensorFlow, in the\ncloud in a scalable and resilient manner with minimal effort. The platform uses\na distribution and orchestration layer that facilitates learning from a large\namount of data in a reasonable amount of time across compute nodes. A resource\nprovisioning layer enables flexible job management on heterogeneous resources,\nsuch as graphics processing units (GPUs) and central processing units (CPUs),\nin an infrastructure as a service (IaaS) cloud.",
    "published": "2017-09-18T11:40:48Z",
    "pdf_url": "http://arxiv.org/pdf/1709.05871v1",
    "categories": [
      "cs.DC"
    ]
  },
  {
    "arxiv_id": "2212.00911v1",
    "title": "Navigating causal deep learning",
    "authors": [
      "Jeroen Berrevoets",
      "Krzysztof Kacprzyk",
      "Zhaozhi Qian",
      "Mihaela van der Schaar"
    ],
    "abstract": "Causal deep learning (CDL) is a new and important research area in the larger\nfield of machine learning. With CDL, researchers aim to structure and encode\ncausal knowledge in the extremely flexible representation space of deep\nlearning models. Doing so will lead to more informed, robust, and general\npredictions and inference -- which is important! However, CDL is still in its\ninfancy. For example, it is not clear how we ought to compare different methods\nas they are so different in their output, the way they encode causal knowledge,\nor even how they represent this knowledge. This is a living paper that\ncategorises methods in causal deep learning beyond Pearl's ladder of causation.\nWe refine the rungs in Pearl's ladder, while also adding a separate dimension\nthat categorises the parametric assumptions of both input and representation,\narriving at the map of causal deep learning. Our map covers machine learning\ndisciplines such as supervised learning, reinforcement learning, generative\nmodelling and beyond. Our paradigm is a tool which helps researchers to: find\nbenchmarks, compare methods, and most importantly: identify research gaps. With\nthis work we aim to structure the avalanche of papers being published on causal\ndeep learning. While papers on the topic are being published daily, our map\nremains fixed. We open-source our map for others to use as they see fit:\nperhaps to offer guidance in a related works section, or to better highlight\nthe contribution of their paper.",
    "published": "2022-12-01T23:44:23Z",
    "pdf_url": "http://arxiv.org/pdf/2212.00911v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2104.05569v1",
    "title": "Deep Learning for IoT",
    "authors": [
      "Tao Lin"
    ],
    "abstract": "Deep learning and other machine learning approaches are deployed to many\nsystems related to Internet of Things or IoT. However, it faces challenges that\nadversaries can take loopholes to hack these systems through tampering history\ndata. This paper first presents overall points of adversarial machine learning.\nThen, we illustrate traditional methods, such as Petri Net cannot solve this\nnew question efficiently. To help IoT data analysis more efficient, we propose\na retrieval method based on deep learning (recurrent neural network). Besides,\nthis paper presents a research on data retrieval solution to avoid hacking by\nadversaries in the fields of adversary machine leaning. It further directs the\nnew approaches in terms of how to implementing this framework in IoT settings\nbased on adversarial deep learning.",
    "published": "2021-04-12T15:39:30Z",
    "pdf_url": "http://arxiv.org/pdf/2104.05569v1",
    "categories": [
      "cs.LG",
      "cs.NI"
    ]
  },
  {
    "arxiv_id": "2504.08489v1",
    "title": "Statistically guided deep learning",
    "authors": [
      "Michael Kohler",
      "Adam Krzyzak"
    ],
    "abstract": "We present a theoretically well-founded deep learning algorithm for\nnonparametric regression. It uses over-parametrized deep neural networks with\nlogistic activation function, which are fitted to the given data via gradient\ndescent. We propose a special topology of these networks, a special random\ninitialization of the weights, and a data-dependent choice of the learning rate\nand the number of gradient descent steps. We prove a theoretical bound on the\nexpected $L_2$ error of this estimate, and illustrate its finite sample size\nperformance by applying it to simulated data. Our results show that a\ntheoretical analysis of deep learning which takes into account simultaneously\noptimization, generalization and approximation can result in a new deep\nlearning estimate which has an improved finite sample performance.",
    "published": "2025-04-11T12:36:06Z",
    "pdf_url": "http://arxiv.org/pdf/2504.08489v1",
    "categories": [
      "math.ST",
      "cs.LG",
      "stat.ML",
      "stat.TH"
    ]
  },
  {
    "arxiv_id": "1412.3489v2",
    "title": "Quantum Deep Learning",
    "authors": [
      "Nathan Wiebe",
      "Ashish Kapoor",
      "Krysta M. Svore"
    ],
    "abstract": "In recent years, deep learning has had a profound impact on machine learning\nand artificial intelligence. At the same time, algorithms for quantum computers\nhave been shown to efficiently solve some problems that are intractable on\nconventional, classical computers. We show that quantum computing not only\nreduces the time required to train a deep restricted Boltzmann machine, but\nalso provides a richer and more comprehensive framework for deep learning than\nclassical computing and leads to significant improvements in the optimization\nof the underlying objective function. Our quantum methods also permit efficient\ntraining of full Boltzmann machines and multi-layer, fully connected models and\ndo not have well known classical counterparts.",
    "published": "2014-12-10T23:05:16Z",
    "pdf_url": "http://arxiv.org/pdf/1412.3489v2",
    "categories": [
      "quant-ph",
      "cs.LG",
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "2302.12027v1",
    "title": "Forecasting with Deep Learning",
    "authors": [
      "Gissel Velarde"
    ],
    "abstract": "This paper presents a method for time series forecasting with deep learning\nand its assessment on two datasets. The method starts with data preparation,\nfollowed by model training and evaluation. The final step is a visual\ninspection. Experimental work demonstrates that a single time series can be\nused to train deep learning networks if time series in a dataset contain\npatterns that repeat even with a certain variation. However, for less\nstructured time series such as stock market closing prices, the networks\nperform just like a baseline that repeats the last observed value. The\nimplementation of the method as well as the experiments are open-source.",
    "published": "2023-02-17T10:09:22Z",
    "pdf_url": "http://arxiv.org/pdf/2302.12027v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2310.06251v1",
    "title": "Deep Learning: A Tutorial",
    "authors": [
      "Nick Polson",
      "Vadim Sokolov"
    ],
    "abstract": "Our goal is to provide a review of deep learning methods which provide\ninsight into structured high-dimensional data. Rather than using shallow\nadditive architectures common to most statistical models, deep learning uses\nlayers of semi-affine input transformations to provide a predictive rule.\nApplying these layers of transformations leads to a set of attributes (or,\nfeatures) to which probabilistic statistical methods can be applied. Thus, the\nbest of both worlds can be achieved: scalable prediction rules fortified with\nuncertainty quantification, where sparse regularization finds the features.",
    "published": "2023-10-10T01:55:22Z",
    "pdf_url": "http://arxiv.org/pdf/2310.06251v1",
    "categories": [
      "stat.ML",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1810.11614v2",
    "title": "Deep learning for denoising",
    "authors": [
      "Siwei Yu",
      "Jianwei Ma",
      "Wenlong Wang"
    ],
    "abstract": "Compared with traditional seismic noise attenuation algorithms that depend on\nsignal models and their corresponding prior assumptions, removing noise with a\ndeep neural network is trained based on a large training set, where the inputs\nare the raw datasets and the corresponding outputs are the desired clean data.\nAfter the completion of training, the deep learning method achieves adaptive\ndenoising with no requirements of (i) accurate modelings of the signal and\nnoise, or (ii) optimal parameters tuning. We call this intelligent denoising.\nWe use a convolutional neural network as the basic tool for deep learning. In\nrandom and linear noise attenuation, the training set is generated with\nartificially added noise. In the multiple attenuation step, the training set is\ngenerated with acoustic wave equation. Stochastic gradient descent is used to\nsolve the optimal parameters for the convolutional neural network. The runtime\nof deep learning on a graphics processing unit for denoising has the same order\nas the $f-x$ deconvolution method. Synthetic and field results show the\npotential applications of deep learning in automatic attenuation of random\nnoise (with unknown variance), linear noise, and multiples.",
    "published": "2018-10-27T07:39:09Z",
    "pdf_url": "http://arxiv.org/pdf/1810.11614v2",
    "categories": [
      "physics.geo-ph",
      "cs.LG",
      "eess.SP",
      "86A15"
    ]
  },
  {
    "arxiv_id": "2003.03253v1",
    "title": "Introduction to deep learning",
    "authors": [
      "Lihi Shiloh-Perl",
      "Raja Giryes"
    ],
    "abstract": "Deep Learning (DL) has made a major impact on data science in the last\ndecade. This chapter introduces the basic concepts of this field. It includes\nboth the basic structures used to design deep neural networks and a brief\nsurvey of some of its popular use cases.",
    "published": "2020-02-29T14:52:28Z",
    "pdf_url": "http://arxiv.org/pdf/2003.03253v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2211.16350v4",
    "title": "On \"Deep Learning\" Misconduct",
    "authors": [
      "Juyang Weng"
    ],
    "abstract": "This is a theoretical paper, as a companion paper of the plenary talk for the\nsame conference ISAIC 2022. In contrast to the author's plenary talk in the\nsame conference, conscious learning (Weng, 2022b; Weng, 2022c) which develops a\nsingle network for a life (many tasks), \"Deep Learning\" trains multiple\nnetworks for each task. Although \"Deep Learning\" may use different learning\nmodes, including supervised, reinforcement and adversarial modes, almost all\n\"Deep Learning\" projects apparently suffer from the same misconduct, called\n\"data deletion\" and \"test on training data\". This paper establishes a theorem\nthat a simple method called Pure-Guess Nearest Neighbor (PGNN) reaches any\nrequired errors on validation data set and test data set, including zero-error\nrequirements, through the same misconduct, as long as the test data set is in\nthe possession of the authors and both the amount of storage space and the time\nof training are finite but unbounded. The misconduct violates well-known\nprotocols called transparency and cross-validation. The nature of the\nmisconduct is fatal, because in the absence of any disjoint test, \"Deep\nLearning\" is clearly not generalizable.",
    "published": "2022-11-23T17:04:42Z",
    "pdf_url": "http://arxiv.org/pdf/2211.16350v4",
    "categories": [
      "cs.LG",
      "I.3"
    ]
  },
  {
    "arxiv_id": "2303.02186v2",
    "title": "Causal Deep Learning",
    "authors": [
      "Jeroen Berrevoets",
      "Krzysztof Kacprzyk",
      "Zhaozhi Qian",
      "Mihaela van der Schaar"
    ],
    "abstract": "Causality has the potential to truly transform the way we solve a large\nnumber of real-world problems. Yet, so far, its potential largely remains to be\nunlocked as causality often requires crucial assumptions which cannot be tested\nin practice. To address this challenge, we propose a new way of thinking about\ncausality -- we call this causal deep learning. Our causal deep learning\nframework spans three dimensions: (1) a structural dimension, which\nincorporates partial yet testable causal knowledge rather than assuming either\ncomplete or no causal knowledge among the variables of interest; (2) a\nparametric dimension, which encompasses parametric forms that capture the type\nof relationships among the variables of interest; and (3) a temporal dimension,\nwhich captures exposure times or how the variables of interest interact\n(possibly causally) over time. Causal deep learning enables us to make progress\non a variety of real-world problems by leveraging partial causal knowledge\n(including independencies among variables) and quantitatively characterising\ncausal relationships among variables of interest (possibly over time). Our\nframework clearly identifies which assumptions are testable and which ones are\nnot, such that the resulting solutions can be judiciously adopted in practice.\nUsing our formulation we can combine or chain together causal representations\nto solve specific problems without losing track of which assumptions are\nrequired to build these solutions, pushing real-world impact in healthcare,\neconomics and business, environmental sciences and education, through causal\ndeep learning.",
    "published": "2023-03-03T19:19:18Z",
    "pdf_url": "http://arxiv.org/pdf/2303.02186v2",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2201.13380v1",
    "title": "Deep Learning Macroeconomics",
    "authors": [
      "Rafael R. S. Guimaraes"
    ],
    "abstract": "Limited datasets and complex nonlinear relationships are among the challenges\nthat may emerge when applying econometrics to macroeconomic problems. This\nresearch proposes deep learning as an approach to transfer learning in the\nformer case and to map relationships between variables in the latter case.\nAlthough macroeconomists already apply transfer learning when assuming a given\na priori distribution in a Bayesian context, estimating a structural VAR with\nsignal restriction and calibrating parameters based on results observed in\nother models, to name a few examples, advance in a more systematic transfer\nlearning strategy in applied macroeconomics is the innovation we are\nintroducing. We explore the proposed strategy empirically, showing that data\nfrom different but related domains, a type of transfer learning, helps identify\nthe business cycle phases when there is no business cycle dating committee and\nto quick estimate a economic-based output gap. Next, since deep learning\nmethods are a way of learning representations, those that are formed by the\ncomposition of multiple non-linear transformations, to yield more abstract\nrepresentations, we apply deep learning for mapping low-frequency from\nhigh-frequency variables. The results obtained show the suitability of deep\nlearning models applied to macroeconomic problems. First, models learned to\nclassify United States business cycles correctly. Then, applying transfer\nlearning, they were able to identify the business cycles of out-of-sample\nBrazilian and European data. Along the same lines, the models learned to\nestimate the output gap based on the U.S. data and obtained good performance\nwhen faced with Brazilian data. Additionally, deep learning proved adequate for\nmapping low-frequency variables from high-frequency data to interpolate,\ndistribute, and extrapolate time series by related series.",
    "published": "2022-01-31T17:43:43Z",
    "pdf_url": "http://arxiv.org/pdf/2201.13380v1",
    "categories": [
      "econ.EM",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1705.05750v2",
    "title": "Holography as deep learning",
    "authors": [
      "Wen-Cong Gan",
      "Fu-Wen Shu"
    ],
    "abstract": "Quantum many-body problem with exponentially large degrees of freedom can be\nreduced to a tractable computational form by neural network method \\cite{CT}.\nThe power of deep neural network (DNN) based on deep learning is clarified by\nmapping it to renormalization group (RG), which may shed lights on holographic\nprinciple by identifying a sequence of RG transformations to the AdS geometry.\nIn this essay, we show that any network which reflects RG process has intrinsic\nhyperbolic geometry, and discuss the structure of entanglement encoded in the\ngraph of DNN. We find the entanglement structure of deep neural network is of\nRyu-Takayanagi form. Based on these facts, we argue that the emergence of\nholographic gravitational theory is related to deep learning process of the\nquantum field theory.",
    "published": "2017-05-16T14:57:22Z",
    "pdf_url": "http://arxiv.org/pdf/1705.05750v2",
    "categories": [
      "gr-qc",
      "hep-th",
      "quant-ph"
    ]
  },
  {
    "arxiv_id": "1803.06111v1",
    "title": "Vulnerability of Deep Learning",
    "authors": [
      "Richard Kenway"
    ],
    "abstract": "The Renormalisation Group (RG) provides a framework in which it is possible\nto assess whether a deep-learning network is sensitive to small changes in the\ninput data and hence prone to error, or susceptible to adversarial attack.\nDistinct classification outputs are associated with different RG fixed points\nand sensitivity to small changes in the input data is due to the presence of\nrelevant operators at a fixed point. A numerical scheme, based on Monte Carlo\nRG ideas, is proposed for identifying the existence of relevant operators and\nthe corresponding directions of greatest sensitivity in the input data. Thus, a\ntrained deep-learning network may be tested for its robustness and, if it is\nvulnerable to attack, dangerous perturbations of the input data identified.",
    "published": "2018-03-16T08:52:04Z",
    "pdf_url": "http://arxiv.org/pdf/1803.06111v1",
    "categories": [
      "stat.ML",
      "cond-mat.dis-nn",
      "cond-mat.stat-mech",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2006.08256v5",
    "title": "Markov-Lipschitz Deep Learning",
    "authors": [
      "Stan Z. Li",
      "Zelin Zang",
      "Lirong Wu"
    ],
    "abstract": "We propose a novel framework, called Markov-Lipschitz deep learning (MLDL),\nto tackle geometric deterioration caused by collapse, twisting, or crossing in\nvector-based neural network transformations for manifold-based representation\nlearning and manifold data generation. A prior constraint, called locally\nisometric smoothness (LIS), is imposed across-layers and encoded into a Markov\nrandom field (MRF)-Gibbs distribution. This leads to the best possible\nsolutions for local geometry preservation and robustness as measured by locally\ngeometric distortion and locally bi-Lipschitz continuity. Consequently, the\nlayer-wise vector transformations are enhanced into well-behaved,\nLIS-constrained metric homeomorphisms. Extensive experiments, comparisons, and\nablation study demonstrate significant advantages of MLDL for manifold learning\nand manifold data generation. MLDL is general enough to enhance any vector\ntransformation-based networks. The code is available at\nhttps://github.com/westlake-cairi/Markov-Lipschitz-Deep-Learning.",
    "published": "2020-06-15T09:46:42Z",
    "pdf_url": "http://arxiv.org/pdf/2006.08256v5",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2110.15829v5",
    "title": "Holistic Deep Learning",
    "authors": [
      "Dimitris Bertsimas",
      "Kimberly Villalobos Carballo",
      "Léonard Boussioux",
      "Michael Lingzhi Li",
      "Alex Paskov",
      "Ivan Paskov"
    ],
    "abstract": "This paper presents a novel holistic deep learning framework that\nsimultaneously addresses the challenges of vulnerability to input\nperturbations, overparametrization, and performance instability from different\ntrain-validation splits. The proposed framework holistically improves accuracy,\nrobustness, sparsity, and stability over standard deep learning models, as\ndemonstrated by extensive experiments on both tabular and image data sets. The\nresults are further validated by ablation experiments and SHAP value analysis,\nwhich reveal the interactions and trade-offs between the different evaluation\nmetrics. To support practitioners applying our framework, we provide a\nprescriptive approach that offers recommendations for selecting an appropriate\ntraining loss function based on their specific objectives. All the code to\nreproduce the results can be found at https://github.com/kimvc7/HDL.",
    "published": "2021-10-29T14:46:32Z",
    "pdf_url": "http://arxiv.org/pdf/2110.15829v5",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2211.09639v2",
    "title": "Why Deep Learning Generalizes",
    "authors": [
      "Benjamin L. Badger"
    ],
    "abstract": "Very large deep learning models trained using gradient descent are remarkably\nresistant to memorization given their huge capacity, but are at the same time\ncapable of fitting large datasets of pure noise. Here methods are introduced by\nwhich models may be trained to memorize datasets that normally are generalized.\nWe find that memorization is difficult relative to generalization, but that\nadding noise makes memorization easier. Increasing the dataset size exaggerates\nthe characteristics of that dataset: model access to more training samples\nmakes overfitting easier for random data, but somewhat harder for natural\nimages. The bias of deep learning towards generalization is explored\ntheoretically, and we show that generalization results from a model's\nparameters being attracted to points of maximal stability with respect to that\nmodel's inputs during gradient descent.",
    "published": "2022-11-17T16:39:43Z",
    "pdf_url": "http://arxiv.org/pdf/2211.09639v2",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2403.03385v1",
    "title": "Multi-modal Deep Learning",
    "authors": [
      "Chen Yuhua"
    ],
    "abstract": "This article investigates deep learning methodologies for single-modality\nclinical data analysis, as a crucial precursor to multi-modal medical research.\nBuilding on Guo JingYuan's work, the study refines clinical data processing\nthrough Compact Convolutional Transformer (CCT), Patch Up, and the innovative\nCamCenterLoss technique, establishing a foundation for future multimodal\ninvestigations. The proposed methodology demonstrates improved prediction\naccuracy and at tentiveness to critically ill patients compared to Guo\nJingYuan's ResNet and StageNet approaches. Novelty that using image-pretrained\nvision transformer backbone to perform transfer learning time-series clinical\ndata.The study highlights the potential of CCT, Patch Up, and novel\nCamCenterLoss in processing single modality clinical data within deep learning\nframeworks, paving the way for future multimodal medical research and promoting\nprecision and personalized healthcare",
    "published": "2024-03-06T00:36:05Z",
    "pdf_url": "http://arxiv.org/pdf/2403.03385v1",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2407.15339v3",
    "title": "Deep Learning for Economists",
    "authors": [
      "Melissa Dell"
    ],
    "abstract": "Deep learning provides powerful methods to impute structured information from\nlarge-scale, unstructured text and image datasets. For example, economists\nmight wish to detect the presence of economic activity in satellite images, or\nto measure the topics or entities mentioned in social media, the congressional\nrecord, or firm filings. This review introduces deep neural networks, covering\nmethods such as classifiers, regression models, generative AI, and embedding\nmodels. Applications include classification, document digitization, record\nlinkage, and methods for data exploration in massive scale text and image\ncorpora. When suitable methods are used, deep learning models can be cheap to\ntune and can scale affordably to problems involving millions or billions of\ndata points.. The review is accompanied by a companion website, EconDL, with\nuser-friendly demo notebooks, software resources, and a knowledge base that\nprovides technical details and additional applications.",
    "published": "2024-07-22T02:53:18Z",
    "pdf_url": "http://arxiv.org/pdf/2407.15339v3",
    "categories": [
      "econ.GN",
      "cs.CL",
      "cs.CV",
      "q-fin.EC"
    ]
  },
  {
    "arxiv_id": "2012.08405v3",
    "title": "Model-Based Deep Learning",
    "authors": [
      "Nir Shlezinger",
      "Jay Whang",
      "Yonina C. Eldar",
      "Alexandros G. Dimakis"
    ],
    "abstract": "Signal processing, communications, and control have traditionally relied on\nclassical statistical modeling techniques. Such model-based methods utilize\nmathematical formulations that represent the underlying physics, prior\ninformation and additional domain knowledge. Simple classical models are useful\nbut sensitive to inaccuracies and may lead to poor performance when real\nsystems display complex or dynamic behavior. On the other hand, purely\ndata-driven approaches that are model-agnostic are becoming increasingly\npopular as datasets become abundant and the power of modern deep learning\npipelines increases. Deep neural networks (DNNs) use generic architectures\nwhich learn to operate from data, and demonstrate excellent performance,\nespecially for supervised problems. However, DNNs typically require massive\namounts of data and immense computational resources, limiting their\napplicability for some signal processing scenarios. We are interested in hybrid\ntechniques that combine principled mathematical models with data-driven systems\nto benefit from the advantages of both approaches. Such model-based deep\nlearning methods exploit both partial domain knowledge, via mathematical\nstructures designed for specific problems, as well as learning from limited\ndata. In this article we survey the leading approaches for studying and\ndesigning model-based deep learning systems. We divide hybrid\nmodel-based/data-driven systems into categories based on their inference\nmechanism. We provide a comprehensive review of the leading approaches for\ncombining model-based algorithms with deep learning in a systematic manner,\nalong with concrete guidelines and detailed signal processing oriented examples\nfrom recent literature. Our aim is to facilitate the design and study of future\nsystems on the intersection of signal processing and machine learning that\nincorporate the advantages of both domains.",
    "published": "2020-12-15T16:29:49Z",
    "pdf_url": "http://arxiv.org/pdf/2012.08405v3",
    "categories": [
      "eess.SP",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2304.08457v2",
    "title": "Deep Learning Criminal Networks",
    "authors": [
      "Haroldo V. Ribeiro",
      "Diego D. Lopes",
      "Arthur A. B. Pessa",
      "Alvaro F. Martins",
      "Bruno R. da Cunha",
      "Sebastian Goncalves",
      "Ervin K. Lenzi",
      "Quentin S. Hanley",
      "Matjaz Perc"
    ],
    "abstract": "Recent advances in deep learning methods have enabled researchers to develop\nand apply algorithms for the analysis and modeling of complex networks. These\nadvances have sparked a surge of interest at the interface between network\nscience and machine learning. Despite this, the use of machine learning methods\nto investigate criminal networks remains surprisingly scarce. Here, we explore\nthe potential of graph convolutional networks to learn patterns among networked\ncriminals and to predict various properties of criminal networks. Using\nempirical data from political corruption, criminal police intelligence, and\ncriminal financial networks, we develop a series of deep learning models based\non the GraphSAGE framework that are able to recover missing criminal\npartnerships, distinguish among types of associations, predict the amount of\nmoney exchanged among criminal agents, and even anticipate partnerships and\nrecidivism of criminals during the growth dynamics of corruption networks, all\nwith impressive accuracy. Our deep learning models significantly outperform\nprevious shallow learning approaches and produce high-quality embeddings for\nnode and edge properties. Moreover, these models inherit all the advantages of\nthe GraphSAGE framework, including the generalization to unseen nodes and\nscaling up to large graph structures.",
    "published": "2023-04-17T17:33:30Z",
    "pdf_url": "http://arxiv.org/pdf/2304.08457v2",
    "categories": [
      "physics.soc-ph",
      "cs.SI",
      "physics.data-an"
    ]
  },
  {
    "arxiv_id": "2307.10991v2",
    "title": "Dense Sample Deep Learning",
    "authors": [
      "Stephen Josè Hanson",
      "Vivek Yadav",
      "Catherine Hanson"
    ],
    "abstract": "Deep Learning (DL) , a variant of the neural network algorithms originally\nproposed in the 1980s, has made surprising progress in Artificial Intelligence\n(AI), ranging from language translation, protein folding, autonomous cars, and\nmore recently human-like language models (CHATbots), all that seemed\nintractable until very recently. Despite the growing use of Deep Learning (DL)\nnetworks, little is actually understood about the learning mechanisms and\nrepresentations that makes these networks effective across such a diverse range\nof applications. Part of the answer must be the huge scale of the architecture\nand of course the large scale of the data, since not much has changed since\n1987. But the nature of deep learned representations remain largely unknown.\nUnfortunately training sets with millions or billions of tokens have unknown\ncombinatorics and Networks with millions or billions of hidden units cannot\neasily be visualized and their mechanisms cannot be easily revealed. In this\npaper, we explore these questions with a large (1.24M weights; VGG) DL in a\nnovel high density sample task (5 unique tokens with at minimum 500 exemplars\nper token) which allows us to more carefully follow the emergence of category\nstructure and feature construction. We use various visualization methods for\nfollowing the emergence of the classification and the development of the\ncoupling of feature detectors and structures that provide a type of graphical\nbootstrapping, From these results we harvest some basic observations of the\nlearning dynamics of DL and propose a new theory of complex feature\nconstruction based on our results.",
    "published": "2023-07-20T16:21:14Z",
    "pdf_url": "http://arxiv.org/pdf/2307.10991v2",
    "categories": [
      "cs.AI",
      "q-bio.NC",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1803.08993v1",
    "title": "Deep Learning Phase Segregation",
    "authors": [
      "Amir Barati Farimani",
      "Joseph Gomes",
      "Rishi Sharma",
      "Franklin L. Lee",
      "Vijay S. Pande"
    ],
    "abstract": "Phase segregation, the process by which the components of a binary mixture\nspontaneously separate, is a key process in the evolution and design of many\nchemical, mechanical, and biological systems. In this work, we present a\ndata-driven approach for the learning, modeling, and prediction of phase\nsegregation. A direct mapping between an initially dispersed, immiscible binary\nfluid and the equilibrium concentration field is learned by conditional\ngenerative convolutional neural networks. Concentration field predictions by\nthe deep learning model conserve phase fraction, correctly predict phase\ntransition, and reproduce area, perimeter, and total free energy distributions\nup to 98% accuracy.",
    "published": "2018-03-23T21:59:01Z",
    "pdf_url": "http://arxiv.org/pdf/1803.08993v1",
    "categories": [
      "cs.LG",
      "physics.comp-ph",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1909.02803v3",
    "title": "Personalization of Deep Learning",
    "authors": [
      "Johannes Schneider",
      "Michail Vlachos"
    ],
    "abstract": "We discuss training techniques, objectives and metrics toward personalization\nof deep learning models. In machine learning, personalization addresses the\ngoal of a trained model to target a particular individual by optimizing one or\nmore performance metrics, while conforming to certain constraints. To\npersonalize, we investigate three methods of ``curriculum learning`` and two\napproaches for data grouping, i.e., augmenting the data of an individual by\nadding similar data identified with an auto-encoder. We show that both\n``curriculuum learning'' and ``personalized'' data augmentation lead to\nimproved performance on data of an individual. Mostly, this comes at the cost\nof reduced performance on a more general, broader dataset.",
    "published": "2019-09-06T10:17:25Z",
    "pdf_url": "http://arxiv.org/pdf/1909.02803v3",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2305.15239v2",
    "title": "Deep Learning and Ethics",
    "authors": [
      "Travis LaCroix",
      "Simon J. D. Prince"
    ],
    "abstract": "This article appears as chapter 21 of Prince (2023, Understanding Deep\nLearning); a complete draft of the textbook is available here:\nhttp://udlbook.com. This chapter considers potential harms arising from the\ndesign and use of AI systems. These include algorithmic bias, lack of\nexplainability, data privacy violations, militarization, fraud, and\nenvironmental concerns. The aim is not to provide advice on being more ethical.\nInstead, the goal is to express ideas and start conversations in key areas that\nhave received attention in philosophy, political science, and the broader\nsocial sciences.",
    "published": "2023-05-24T15:24:19Z",
    "pdf_url": "http://arxiv.org/pdf/2305.15239v2",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2109.05237v4",
    "title": "Physics-based Deep Learning",
    "authors": [
      "N. Thuerey",
      "B. Holzschuh",
      "P. Holl",
      "G. Kohl",
      "M. Lino",
      "Q. Liu",
      "P. Schnell",
      "F. Trost"
    ],
    "abstract": "This document is a hands-on, comprehensive guide to deep learning in the\nrealm of physical simulations. Rather than just theory, we emphasize practical\napplication: every concept is paired with interactive Jupyter notebooks to get\nyou up and running quickly. Beyond traditional supervised learning, we dive\ninto physical loss-constraints, differentiable simulations, diffusion-based\napproaches for probabilistic generative AI, as well as reinforcement learning\nand advanced neural network architectures. These foundations are paving the way\nfor the next generation of scientific foundation models. We are living in an\nera of rapid transformation. These methods have the potential to redefine\nwhat's possible in computational science.",
    "published": "2021-09-11T09:38:02Z",
    "pdf_url": "http://arxiv.org/pdf/2109.05237v4",
    "categories": [
      "cs.LG",
      "physics.comp-ph"
    ]
  },
  {
    "arxiv_id": "1611.03777v1",
    "title": "Tricks from Deep Learning",
    "authors": [
      "Atılım Güneş Baydin",
      "Barak A. Pearlmutter",
      "Jeffrey Mark Siskind"
    ],
    "abstract": "The deep learning community has devised a diverse set of methods to make\ngradient optimization, using large datasets, of large and highly complex models\nwith deeply cascaded nonlinearities, practical. Taken as a whole, these methods\nconstitute a breakthrough, allowing computational structures which are quite\nwide, very deep, and with an enormous number and variety of free parameters to\nbe effectively optimized. The result now dominates much of practical machine\nlearning, with applications in machine translation, computer vision, and speech\nrecognition. Many of these methods, viewed through the lens of algorithmic\ndifferentiation (AD), can be seen as either addressing issues with the gradient\nitself, or finding ways of achieving increased efficiency using tricks that are\nAD-related, but not provided by current AD systems.\n  The goal of this paper is to explain not just those methods of most relevance\nto AD, but also the technical constraints and mindset which led to their\ndiscovery. After explaining this context, we present a \"laundry list\" of\nmethods developed by the deep learning community. Two of these are discussed in\nfurther mathematical detail: a way to dramatically reduce the size of the tape\nwhen performing reverse-mode AD on a (theoretically) time-reversible process\nlike an ODE integrator; and a new mathematical insight that allows for the\nimplementation of a stochastic Newton's method.",
    "published": "2016-11-10T17:57:19Z",
    "pdf_url": "http://arxiv.org/pdf/1611.03777v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1805.04513v1",
    "title": "Laconic Deep Learning Computing",
    "authors": [
      "Sayeh Sharify",
      "Mostafa Mahmoud",
      "Alberto Delmas Lascorz",
      "Milos Nikolic",
      "Andreas Moshovos"
    ],
    "abstract": "We motivate a method for transparently identifying ineffectual computations\nin unmodified Deep Learning models and without affecting accuracy.\nSpecifically, we show that if we decompose multiplications down to the bit\nlevel the amount of work performed during inference for image classification\nmodels can be consistently reduced by two orders of magnitude. In the best case\nstudied of a sparse variant of AlexNet, this approach can ideally reduce\ncomputation work by more than 500x. We present Laconic a hardware accelerator\nthat implements this approach to improve execution time, and energy efficiency\nfor inference with Deep Learning Networks. Laconic judiciously gives up some of\nthe work reduction potential to yield a low-cost, simple, and energy efficient\ndesign that outperforms other state-of-the-art accelerators. For example, a\nLaconic configuration that uses a weight memory interface with just 128 wires\noutperforms a conventional accelerator with a 2K-wire weight memory interface\nby 2.3x on average while being 2.13x more energy efficient on average. A\nLaconic configuration that uses a 1K-wire weight memory interface, outperforms\nthe 2K-wire conventional accelerator by 15.4x and is 1.95x more energy\nefficient. Laconic does not require but rewards advances in model design such\nas a reduction in precision, the use of alternate numeric representations that\nreduce the number of bits that are \"1\", or an increase in weight or activation\nsparsity.",
    "published": "2018-05-10T18:14:08Z",
    "pdf_url": "http://arxiv.org/pdf/1805.04513v1",
    "categories": [
      "cs.NE",
      "cs.AR",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1912.13122v8",
    "title": "Towards Regulated Deep Learning",
    "authors": [
      "Andrés García-Camino"
    ],
    "abstract": "Regulation of Multi-Agent Systems (MAS) and Declarative Electronic\nInstitutions (DEIs) was a multidisciplinary research topic of the past decade\ninvolving (Physical and Software) Agents and Law since the beginning, but\nrecently evolved towards News-claimed Robot Lawyer since 2016. One of these\nfirst proposals of restricting the behaviour of Software Agents was Electronic\nInstitutions. However, with the recent reformulation of Artificial Neural\nNetworks (ANNs) as Deep Learning (DL), Security, Privacy,Ethical and Legal\nissues regarding the use of DL has raised concerns in the Artificial\nIntelligence (AI) Community. Now that the Regulation of MAS is almost correctly\naddressed, we propose the Regulation of Artificial Neural Networks as\nAgent-based Training of a special type of regulated Artificial Neural Network\nthat we call Institutional Neural Network (INN).The main purpose of this paper\nis to bring attention to Artificial Teaching (AT) and to give a tentative\nanswer showing a proof-of-concept implementation of Regulated Deep Learning\n(RDL). This paper introduces the former concept and provide $I^*$, a language\npreviously used to model declaratively and extend Electronic Institutions, as a\nmeans to regulate the execution of Artificial Neural Networks and their\ninteractions with Artificial Teachers (ATs)",
    "published": "2019-12-31T00:10:50Z",
    "pdf_url": "http://arxiv.org/pdf/1912.13122v8",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.LO",
      "cs.MA",
      "cs.PL"
    ]
  },
  {
    "arxiv_id": "2002.02664v1",
    "title": "Short sighted deep learning",
    "authors": [
      "Ellen de Melllo Koch",
      "Anita de Mello Koch",
      "Nicholas Kastanos",
      "Ling Cheng"
    ],
    "abstract": "A theory explaining how deep learning works is yet to be developed. Previous\nwork suggests that deep learning performs a coarse graining, similar in spirit\nto the renormalization group (RG). This idea has been explored in the setting\nof a local (nearest neighbor interactions) Ising spin lattice. We extend the\ndiscussion to the setting of a long range spin lattice. Markov Chain Monte\nCarlo (MCMC) simulations determine both the critical temperature and scaling\ndimensions of the system. The model is used to train both a single RBM\n(restricted Boltzmann machine) network, as well as a stacked RBM network.\nFollowing earlier Ising model studies, the trained weights of a single layer\nRBM network define a flow of lattice models. In contrast to results for nearest\nneighbor Ising, the RBM flow for the long ranged model does not converge to the\ncorrect values for the spin and energy scaling dimension. Further, correlation\nfunctions between visible and hidden nodes exhibit key differences between the\nstacked RBM and RG flows. The stacked RBM flow appears to move towards low\ntemperatures whereas the RG flow moves towards high temperature. This again\ndiffers from results obtained for nearest neighbor Ising.",
    "published": "2020-02-07T08:33:07Z",
    "pdf_url": "http://arxiv.org/pdf/2002.02664v1",
    "categories": [
      "cs.LG",
      "cond-mat.stat-mech",
      "physics.comp-ph",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2306.15065v1",
    "title": "Molecular geometric deep learning",
    "authors": [
      "Cong Shen",
      "Jiawei Luo",
      "Kelin Xia"
    ],
    "abstract": "Geometric deep learning (GDL) has demonstrated huge power and enormous\npotential in molecular data analysis. However, a great challenge still remains\nfor highly efficient molecular representations. Currently, covalent-bond-based\nmolecular graphs are the de facto standard for representing molecular topology\nat the atomic level. Here we demonstrate, for the first time, that molecular\ngraphs constructed only from non-covalent bonds can achieve similar or even\nbetter results than covalent-bond-based models in molecular property\nprediction. This demonstrates the great potential of novel molecular\nrepresentations beyond the de facto standard of covalent-bond-based molecular\ngraphs. Based on the finding, we propose molecular geometric deep learning\n(Mol-GDL). The essential idea is to incorporate a more general molecular\nrepresentation into GDL models. In our Mol-GDL, molecular topology is modeled\nas a series of molecular graphs, each focusing on a different scale of atomic\ninteractions. In this way, both covalent interactions and non-covalent\ninteractions are incorporated into the molecular representation on an equal\nfooting. We systematically test Mol-GDL on fourteen commonly-used benchmark\ndatasets. The results show that our Mol-GDL can achieve a better performance\nthan state-of-the-art (SOTA) methods. Source code and data are available at\nhttps://github.com/CS-BIO/Mol-GDL.",
    "published": "2023-06-22T14:25:08Z",
    "pdf_url": "http://arxiv.org/pdf/2306.15065v1",
    "categories": [
      "physics.comp-ph",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1807.04739v1",
    "title": "When deep learning meets security",
    "authors": [
      "Majd Latah"
    ],
    "abstract": "Deep learning is an emerging research field that has proven its effectiveness\ntowards deploying more efficient intelligent systems. Security, on the other\nhand, is one of the most essential issues in modern communication systems.\nRecently many papers have shown that using deep learning models can achieve\npromising results when applied to the security domain. In this work, we provide\nan overview for the recent studies that apply deep learning techniques to the\nfield of security.",
    "published": "2018-07-12T17:44:42Z",
    "pdf_url": "http://arxiv.org/pdf/1807.04739v1",
    "categories": [
      "cs.CR",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2209.12014v1",
    "title": "Asset Pricing and Deep Learning",
    "authors": [
      "Chen Zhang"
    ],
    "abstract": "Traditional machine learning methods have been widely studied in financial\ninnovation. My study focuses on the application of deep learning methods on\nasset pricing. I investigate various deep learning methods for asset pricing,\nespecially for risk premia measurement. All models take the same set of\npredictive signals (firm characteristics, systematic risks and macroeconomics).\nI demonstrate high performance of all kinds of state-of-the-art (SOTA) deep\nlearning methods, and figure out that RNNs with memory mechanism and attention\nhave the best performance in terms of predictivity. Furthermore, I demonstrate\nlarge economic gains to investors using deep learning forecasts. The results of\nmy comparative experiments highlight the importance of domain knowledge and\nfinancial theory when designing deep learning models. I also show return\nprediction tasks bring new challenges to deep learning. The time varying\ndistribution causes distribution shift problem, which is essential for\nfinancial time series prediction. I demonstrate that deep learning methods can\nimprove asset risk premium measurement. Due to the booming deep learning\nstudies, they can constantly promote the study of underlying financial\nmechanisms behind asset pricing. I also propose a promising research method\nthat learning from data and figuring out the underlying economic mechanisms\nthrough explainable artificial intelligence (AI) methods. My findings not only\njustify the value of deep learning in blooming fintech development, but also\nhighlight their prospects and advantages over traditional machine learning\nmethods.",
    "published": "2022-09-24T14:18:07Z",
    "pdf_url": "http://arxiv.org/pdf/2209.12014v1",
    "categories": [
      "q-fin.ST",
      "cs.LG",
      "q-fin.PR"
    ]
  },
  {
    "arxiv_id": "1801.00631v1",
    "title": "Deep Learning: A Critical Appraisal",
    "authors": [
      "Gary Marcus"
    ],
    "abstract": "Although deep learning has historical roots going back decades, neither the\nterm \"deep learning\" nor the approach was popular just over five years ago,\nwhen the field was reignited by papers such as Krizhevsky, Sutskever and\nHinton's now classic (2012) deep network model of Imagenet. What has the field\ndiscovered in the five subsequent years? Against a background of considerable\nprogress in areas such as speech recognition, image recognition, and game\nplaying, and considerable enthusiasm in the popular press, I present ten\nconcerns for deep learning, and suggest that deep learning must be supplemented\nby other techniques if we are to reach artificial general intelligence.",
    "published": "2018-01-02T12:49:35Z",
    "pdf_url": "http://arxiv.org/pdf/1801.00631v1",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML",
      "97R40",
      "I.2.0; I.2.6"
    ]
  },
  {
    "arxiv_id": "2105.11046v1",
    "title": "Deep learning in biomedical optics",
    "authors": [
      "Lei Tian",
      "Brady Hunt",
      "Muyinatu A. Lediju Bell",
      "Ji Yi",
      "Jason T. Smith",
      "Marien Ochoa",
      "Xavier Intes",
      "Nicholas J. Durr"
    ],
    "abstract": "This article reviews deep learning applications in biomedical optics with a\nparticular emphasis on image formation. The review is organized by imaging\ndomains within biomedical optics and includes microscopy, fluorescence lifetime\nimaging, in vivo microscopy, widefield endoscopy, optical coherence tomography,\nphotoacoustic imaging, diffuse tomography, and functional optical brain\nimaging. For each of these domains, we summarize how deep learning has been\napplied and highlight methods by which deep learning can enable new\ncapabilities for optics in medicine. Challenges and opportunities to improve\ntranslation and adoption of deep learning in biomedical optics are also\nsummarized.",
    "published": "2021-05-23T23:49:22Z",
    "pdf_url": "http://arxiv.org/pdf/2105.11046v1",
    "categories": [
      "physics.optics",
      "physics.bio-ph"
    ]
  },
  {
    "arxiv_id": "1705.03921v1",
    "title": "Why & When Deep Learning Works: Looking Inside Deep Learnings",
    "authors": [
      "Ronny Ronen"
    ],
    "abstract": "The Intel Collaborative Research Institute for Computational Intelligence\n(ICRI-CI) has been heavily supporting Machine Learning and Deep Learning\nresearch from its foundation in 2012. We have asked six leading ICRI-CI Deep\nLearning researchers to address the challenge of \"Why & When Deep Learning\nworks\", with the goal of looking inside Deep Learning, providing insights on\nhow deep networks function, and uncovering key observations on their\nexpressiveness, limitations, and potential. The output of this challenge\nresulted in five papers that address different facets of deep learning. These\ndifferent facets include a high-level understating of why and when deep\nnetworks work (and do not work), the impact of geometry on the expressiveness\nof deep networks, and making deep networks interpretable.",
    "published": "2017-05-10T18:52:26Z",
    "pdf_url": "http://arxiv.org/pdf/1705.03921v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1706.02714v3",
    "title": "Deep-Learning the Landscape",
    "authors": [
      "Yang-Hui He"
    ],
    "abstract": "We propose a paradigm to deep-learn the ever-expanding databases which have\nemerged in mathematical physics and particle phenomenology, as diverse as the\nstatistics of string vacua or combinatorial and algebraic geometry. As concrete\nexamples, we establish multi-layer neural networks as both classifiers and\npredictors and train them with a host of available data ranging from Calabi-Yau\nmanifolds and vector bundles, to quiver representations for gauge theories. We\nfind that even a relatively simple neural network can learn many significant\nquantities to astounding accuracy in a matter of minutes and can also predict\nhithertofore unencountered results. This paradigm should prove a valuable tool\nin various investigations in landscapes in physics as well as pure mathematics.",
    "published": "2017-06-08T18:01:02Z",
    "pdf_url": "http://arxiv.org/pdf/1706.02714v3",
    "categories": [
      "hep-th",
      "hep-ph",
      "math.AG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2106.11342v5",
    "title": "Dive into Deep Learning",
    "authors": [
      "Aston Zhang",
      "Zachary C. Lipton",
      "Mu Li",
      "Alexander J. Smola"
    ],
    "abstract": "This open-source book represents our attempt to make deep learning\napproachable, teaching readers the concepts, the context, and the code. The\nentire book is drafted in Jupyter notebooks, seamlessly integrating exposition\nfigures, math, and interactive examples with self-contained code. Our goal is\nto offer a resource that could (i) be freely available for everyone; (ii) offer\nsufficient technical depth to provide a starting point on the path to actually\nbecoming an applied machine learning scientist; (iii) include runnable code,\nshowing readers how to solve problems in practice; (iv) allow for rapid\nupdates, both by us and also by the community at large; (v) be complemented by\na forum for interactive discussion of technical details and to answer\nquestions.",
    "published": "2021-06-21T18:19:46Z",
    "pdf_url": "http://arxiv.org/pdf/2106.11342v5",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2206.07609v1",
    "title": "Epistemic Deep Learning",
    "authors": [
      "Shireen Kudukkil Manchingal",
      "Fabio Cuzzolin"
    ],
    "abstract": "The belief function approach to uncertainty quantification as proposed in the\nDemspter-Shafer theory of evidence is established upon the general mathematical\nmodels for set-valued observations, called random sets. Set-valued predictions\nare the most natural representations of uncertainty in machine learning. In\nthis paper, we introduce a concept called epistemic deep learning based on the\nrandom-set interpretation of belief functions to model epistemic learning in\ndeep neural networks. We propose a novel random-set convolutional neural\nnetwork for classification that produces scores for sets of classes by learning\nset-valued ground truth representations. We evaluate different formulations of\nentropy and distance measures for belief functions as viable loss functions for\nthese random-set networks. We also discuss methods for evaluating the quality\nof epistemic predictions and the performance of epistemic random-set neural\nnetworks. We demonstrate through experiments that the epistemic approach\nproduces better performance results when compared to traditional approaches of\nestimating uncertainty.",
    "published": "2022-06-15T15:39:52Z",
    "pdf_url": "http://arxiv.org/pdf/2206.07609v1",
    "categories": [
      "cs.LG",
      "cs.NE",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2212.04297v1",
    "title": "Approximations in Deep Learning",
    "authors": [
      "Etienne Dupuis",
      "Silviu-Ioan Filip",
      "Olivier Sentieys",
      "David Novo",
      "Ian O'Connor",
      "Alberto Bosio"
    ],
    "abstract": "The design and implementation of Deep Learning (DL) models is currently\nreceiving a lot of attention from both industrials and academics. However, the\ncomputational workload associated with DL is often out of reach for low-power\nembedded devices and is still costly when run on datacenters. By relaxing the\nneed for fully precise operations, Approximate Computing (AxC) substantially\nimproves performance and energy efficiency. DL is extremely relevant in this\ncontext, since playing with the accuracy needed to do adequate computations\nwill significantly enhance performance, while keeping the quality of results in\na user-constrained range. This chapter will explore how AxC can improve the\nperformance and energy efficiency of hardware accelerators in DL applications\nduring inference and training.",
    "published": "2022-12-08T14:39:01Z",
    "pdf_url": "http://arxiv.org/pdf/2212.04297v1",
    "categories": [
      "cs.AR",
      "eess.SP"
    ]
  },
  {
    "arxiv_id": "2301.04856v1",
    "title": "Multimodal Deep Learning",
    "authors": [
      "Cem Akkus",
      "Luyang Chu",
      "Vladana Djakovic",
      "Steffen Jauch-Walser",
      "Philipp Koch",
      "Giacomo Loss",
      "Christopher Marquardt",
      "Marco Moldovan",
      "Nadja Sauter",
      "Maximilian Schneider",
      "Rickmer Schulte",
      "Karol Urbanczyk",
      "Jann Goschenhofer",
      "Christian Heumann",
      "Rasmus Hvingelby",
      "Daniel Schalk",
      "Matthias Aßenmacher"
    ],
    "abstract": "This book is the result of a seminar in which we reviewed multimodal\napproaches and attempted to create a solid overview of the field, starting with\nthe current state-of-the-art approaches in the two subfields of Deep Learning\nindividually. Further, modeling frameworks are discussed where one modality is\ntransformed into the other, as well as models in which one modality is utilized\nto enhance representation learning for the other. To conclude the second part,\narchitectures with a focus on handling both modalities simultaneously are\nintroduced. Finally, we also cover other modalities as well as general-purpose\nmulti-modal models, which are able to handle different tasks on different\nmodalities within one unified architecture. One interesting application\n(Generative Art) eventually caps off this booklet.",
    "published": "2023-01-12T07:42:36Z",
    "pdf_url": "http://arxiv.org/pdf/2301.04856v1",
    "categories": [
      "cs.CL",
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2410.07081v3",
    "title": "JPEG Inspired Deep Learning",
    "authors": [
      "Ahmed H. Salamah",
      "Kaixiang Zheng",
      "Yiwen Liu",
      "En-Hui Yang"
    ],
    "abstract": "Although it is traditionally believed that lossy image compression, such as\nJPEG compression, has a negative impact on the performance of deep neural\nnetworks (DNNs), it is shown by recent works that well-crafted JPEG compression\ncan actually improve the performance of deep learning (DL). Inspired by this,\nwe propose JPEG-DL, a novel DL framework that prepends any underlying DNN\narchitecture with a trainable JPEG compression layer. To make the quantization\noperation in JPEG compression trainable, a new differentiable soft quantizer is\nemployed at the JPEG layer, and then the quantization operation and underlying\nDNN are jointly trained. Extensive experiments show that in comparison with the\nstandard DL, JPEG-DL delivers significant accuracy improvements across various\ndatasets and model architectures while enhancing robustness against adversarial\nattacks. Particularly, on some fine-grained image classification datasets,\nJPEG-DL can increase prediction accuracy by as much as 20.9%. Our code is\navailable on https://github.com/AhmedHussKhalifa/JPEG-Inspired-DL.git.",
    "published": "2024-10-09T17:23:54Z",
    "pdf_url": "http://arxiv.org/pdf/2410.07081v3",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1612.05596v2",
    "title": "Neuromorphic Deep Learning Machines",
    "authors": [
      "Emre Neftci",
      "Charles Augustine",
      "Somnath Paul",
      "Georgios Detorakis"
    ],
    "abstract": "An ongoing challenge in neuromorphic computing is to devise general and\ncomputationally efficient models of inference and learning which are compatible\nwith the spatial and temporal constraints of the brain. One increasingly\npopular and successful approach is to take inspiration from inference and\nlearning algorithms used in deep neural networks. However, the workhorse of\ndeep learning, the gradient descent Back Propagation (BP) rule, often relies on\nthe immediate availability of network-wide information stored with\nhigh-precision memory, and precise operations that are difficult to realize in\nneuromorphic hardware. Remarkably, recent work showed that exact backpropagated\nweights are not essential for learning deep representations. Random BP replaces\nfeedback weights with random ones and encourages the network to adjust its\nfeed-forward weights to learn pseudo-inverses of the (random) feedback weights.\nBuilding on these results, we demonstrate an event-driven random BP (eRBP) rule\nthat uses an error-modulated synaptic plasticity for learning deep\nrepresentations in neuromorphic computing hardware. The rule requires only one\naddition and two comparisons for each synaptic weight using a two-compartment\nleaky Integrate & Fire (I&F) neuron, making it very suitable for implementation\nin digital or mixed-signal neuromorphic hardware. Our results show that using\neRBP, deep representations are rapidly learned, achieving nearly identical\nclassification accuracies compared to artificial neural network simulations on\nGPUs, while being robust to neural and synaptic state quantizations during\nlearning.",
    "published": "2016-12-16T19:06:35Z",
    "pdf_url": "http://arxiv.org/pdf/1612.05596v2",
    "categories": [
      "cs.NE",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1705.04709v1",
    "title": "Deep Learning Microscopy",
    "authors": [
      "Yair Rivenson",
      "Zoltan Gorocs",
      "Harun Gunaydin",
      "Yibo Zhang",
      "Hongda Wang",
      "Aydogan Ozcan"
    ],
    "abstract": "We demonstrate that a deep neural network can significantly improve optical\nmicroscopy, enhancing its spatial resolution over a large field-of-view and\ndepth-of-field. After its training, the only input to this network is an image\nacquired using a regular optical microscope, without any changes to its design.\nWe blindly tested this deep learning approach using various tissue samples that\nare imaged with low-resolution and wide-field systems, where the network\nrapidly outputs an image with remarkably better resolution, matching the\nperformance of higher numerical aperture lenses, also significantly surpassing\ntheir limited field-of-view and depth-of-field. These results are\ntransformative for various fields that use microscopy tools, including e.g.,\nlife sciences, where optical microscopy is considered as one of the most widely\nused and deployed techniques. Beyond such applications, our presented approach\nis broadly applicable to other imaging modalities, also spanning different\nparts of the electromagnetic spectrum, and can be used to design computational\nimagers that get better and better as they continue to image specimen and\nestablish new transformations among different modes of imaging.",
    "published": "2017-05-12T18:22:54Z",
    "pdf_url": "http://arxiv.org/pdf/1705.04709v1",
    "categories": [
      "cs.LG",
      "cs.CV",
      "physics.optics",
      "68T01, 68T05, 68U10, 62M45, 78M32, 92C50, 92C55, 94A08",
      "I.2; I.2.1; I.2.6; I.2.10; I.3; I.3.3; I.4.3; I.4.4; I.4.9; J.3"
    ]
  },
  {
    "arxiv_id": "1804.07045v2",
    "title": "Semantic Adversarial Deep Learning",
    "authors": [
      "Tommaso Dreossi",
      "Somesh Jha",
      "Sanjit A. Seshia"
    ],
    "abstract": "Fueled by massive amounts of data, models produced by machine-learning (ML)\nalgorithms, especially deep neural networks, are being used in diverse domains\nwhere trustworthiness is a concern, including automotive systems, finance,\nhealth care, natural language processing, and malware detection. Of particular\nconcern is the use of ML algorithms in cyber-physical systems (CPS), such as\nself-driving cars and aviation, where an adversary can cause serious\nconsequences. However, existing approaches to generating adversarial examples\nand devising robust ML algorithms mostly ignore the semantics and context of\nthe overall system containing the ML component. For example, in an autonomous\nvehicle using deep learning for perception, not every adversarial example for\nthe neural network might lead to a harmful consequence. Moreover, one may want\nto prioritize the search for adversarial examples towards those that\nsignificantly modify the desired semantics of the overall system. Along the\nsame lines, existing algorithms for constructing robust ML algorithms ignore\nthe specification of the overall system. In this paper, we argue that the\nsemantics and specification of the overall system has a crucial role to play in\nthis line of research. We present preliminary research results that support\nthis claim.",
    "published": "2018-04-19T09:15:58Z",
    "pdf_url": "http://arxiv.org/pdf/1804.07045v2",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1811.07598v1",
    "title": "Self-Referenced Deep Learning",
    "authors": [
      "Xu Lan",
      "Xiatian Zhu",
      "Shaogang Gong"
    ],
    "abstract": "Knowledge distillation is an effective approach to transferring knowledge\nfrom a teacher neural network to a student target network for satisfying the\nlow-memory and fast running requirements in practice use. Whilst being able to\ncreate stronger target networks compared to the vanilla non-teacher based\nlearning strategy, this scheme needs to train additionally a large teacher\nmodel with expensive computational cost. In this work, we present a\nSelf-Referenced Deep Learning (SRDL) strategy. Unlike both vanilla optimisation\nand existing knowledge distillation, SRDL distils the knowledge discovered by\nthe in-training target model back to itself to regularise the subsequent\nlearning procedure therefore eliminating the need for training a large teacher\nmodel. SRDL improves the model generalisation performance compared to vanilla\nlearning and conventional knowledge distillation approaches with negligible\nextra computational cost. Extensive evaluations show that a variety of deep\nnetworks benefit from SRDL resulting in enhanced deployment performance on both\ncoarse-grained object categorisation tasks (CIFAR10, CIFAR100, Tiny ImageNet,\nand ImageNet) and fine-grained person instance identification tasks\n(Market-1501).",
    "published": "2018-11-19T10:41:17Z",
    "pdf_url": "http://arxiv.org/pdf/1811.07598v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2009.01575v2",
    "title": "Deep Learning in Science",
    "authors": [
      "Stefano Bianchini",
      "Moritz Müller",
      "Pierre Pelletier"
    ],
    "abstract": "Much of the recent success of Artificial Intelligence (AI) has been spurred\non by impressive achievements within a broader family of machine learning\nmethods, commonly referred to as Deep Learning (DL). This paper provides\ninsights on the diffusion and impact of DL in science. Through a Natural\nLanguage Processing (NLP) approach on the arXiv.org publication corpus, we\ndelineate the emerging DL technology and identify a list of relevant search\nterms. These search terms allow us to retrieve DL-related publications from Web\nof Science across all sciences. Based on that sample, we document the DL\ndiffusion process in the scientific system. We find i) an exponential growth in\nthe adoption of DL as a research tool across all sciences and all over the\nworld, ii) regional differentiation in DL application domains, and iii) a\ntransition from interdisciplinary DL applications to disciplinary research\nwithin application domains. In a second step, we investigate how the adoption\nof DL methods affects scientific development. Therefore, we empirically assess\nhow DL adoption relates to re-combinatorial novelty and scientific impact in\nthe health sciences. We find that DL adoption is negatively correlated with\nre-combinatorial novelty, but positively correlated with expectation as well as\nvariance of citation performance. Our findings suggest that DL does not (yet?)\nwork as an autopilot to navigate complex knowledge landscapes and overthrow\ntheir structure. However, the 'DL principle' qualifies for its versatility as\nthe nucleus of a general scientific method that advances science in a\nmeasurable way.",
    "published": "2020-09-03T10:41:29Z",
    "pdf_url": "http://arxiv.org/pdf/2009.01575v2",
    "categories": [
      "cs.CY",
      "econ.EM"
    ]
  },
  {
    "arxiv_id": "1709.01779v2",
    "title": "Deep learning from crowds",
    "authors": [
      "Filipe Rodrigues",
      "Francisco Pereira"
    ],
    "abstract": "Over the last few years, deep learning has revolutionized the field of\nmachine learning by dramatically improving the state-of-the-art in various\ndomains. However, as the size of supervised artificial neural networks grows,\ntypically so does the need for larger labeled datasets. Recently, crowdsourcing\nhas established itself as an efficient and cost-effective solution for labeling\nlarge sets of data in a scalable manner, but it often requires aggregating\nlabels from multiple noisy contributors with different levels of expertise. In\nthis paper, we address the problem of learning deep neural networks from\ncrowds. We begin by describing an EM algorithm for jointly learning the\nparameters of the network and the reliabilities of the annotators. Then, a\nnovel general-purpose crowd layer is proposed, which allows us to train deep\nneural networks end-to-end, directly from the noisy labels of multiple\nannotators, using only backpropagation. We empirically show that the proposed\napproach is able to internally capture the reliability and biases of different\nannotators and achieve new state-of-the-art results for various crowdsourced\ndatasets across different settings, namely classification, regression and\nsequence labeling.",
    "published": "2017-09-06T11:41:19Z",
    "pdf_url": "http://arxiv.org/pdf/1709.01779v2",
    "categories": [
      "stat.ML",
      "cs.CV",
      "cs.HC",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2302.11529v2",
    "title": "Modular Deep Learning",
    "authors": [
      "Jonas Pfeiffer",
      "Sebastian Ruder",
      "Ivan Vulić",
      "Edoardo Maria Ponti"
    ],
    "abstract": "Transfer learning has recently become the dominant paradigm of machine\nlearning. Pre-trained models fine-tuned for downstream tasks achieve better\nperformance with fewer labelled examples. Nonetheless, it remains unclear how\nto develop models that specialise towards multiple tasks without incurring\nnegative interference and that generalise systematically to non-identically\ndistributed tasks. Modular deep learning has emerged as a promising solution to\nthese challenges. In this framework, units of computation are often implemented\nas autonomous parameter-efficient modules. Information is conditionally routed\nto a subset of modules and subsequently aggregated. These properties enable\npositive transfer and systematic generalisation by separating computation from\nrouting and updating modules locally. We offer a survey of modular\narchitectures, providing a unified view over several threads of research that\nevolved independently in the scientific literature. Moreover, we explore\nvarious additional purposes of modularity, including scaling language models,\ncausal inference, programme induction, and planning in reinforcement learning.\nFinally, we report various concrete applications where modularity has been\nsuccessfully deployed such as cross-lingual and cross-modal knowledge transfer.\nRelated talks and projects to this survey, are available at\nhttps://www.modulardeeplearning.com/.",
    "published": "2023-02-22T18:11:25Z",
    "pdf_url": "http://arxiv.org/pdf/2302.11529v2",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2307.12187v1",
    "title": "Monadic Deep Learning",
    "authors": [
      "Bo Yang",
      "Zhihao Zhang Kirisame Marisa",
      "Kai Shi"
    ],
    "abstract": "The Java and Scala community has built a very successful big data ecosystem.\nHowever, most of neural networks running on it are modeled in dynamically typed\nprogramming languages. These dynamically typed deep learning frameworks treat\nneural networks as differentiable expressions that contain many trainable\nvariable, and perform automatic differentiation on those expressions when\ntraining them.\n  Until 2019, none of the learning frameworks in statically typed languages\nprovided the expressive power of traditional frameworks. Their users are not\nable to use custom algorithms unless creating plenty of boilerplate code for\nhard-coded back-propagation.\n  We solved this problem in DeepLearning.scala 2. Our contributions are:\n  1. We discovered a novel approach to perform automatic differentiation in\nreverse mode for statically typed functions that contain multiple trainable\nvariable, and can interoperate freely with the metalanguage.\n  2. We designed a set of monads and monad transformers, which allow users to\ncreate monadic expressions that represent dynamic neural networks.\n  3. Along with these monads, we provide some applicative functors, to perform\nmultiple calculations in parallel.\n  With these features, users of DeepLearning.scala were able to create complex\nneural networks in an intuitive and concise way, and still maintain type\nsafety.",
    "published": "2023-07-23T00:17:37Z",
    "pdf_url": "http://arxiv.org/pdf/2307.12187v1",
    "categories": [
      "cs.PL",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2405.08901v2",
    "title": "Preheating with deep learning",
    "authors": [
      "Jong-Hyun Yoon",
      "Simon Cléry",
      "Mathieu Gross",
      "Yann Mambrini"
    ],
    "abstract": "We apply deep learning techniques to the late-time turbulent regime in a\npost-inflationary model where a real scalar inflaton field and the standard\nmodel Higgs doublet interact with renormalizable couplings between them. After\ninflation, the inflaton decays into the Higgs through a trilinear coupling and\nthe Higgs field subsequently thermalizes with gauge bosons via its $SU(2)\\times\nU(1)$ gauge interaction. Depending on the strength of the trilinear interaction\nand the Higgs self-coupling, the effective mass squared of Higgs can become\nnegative, leading to the tachyonic production of Higgs particles. These\nproduced Higgs particles would then share their energy with gauge bosons,\npotentially indicating thermalization. Since the model entails different\nnon-perturbative effects, it is necessary to resort to numerical and\nsemi-classical techniques. However, simulations require significant costs in\nterms of time and computational resources depending on the model used.\nParticularly, when $SU(2)$ gauge interactions are introduced, this becomes\nevident as the gauge field redistributes particle energies through rescattering\nprocesses, leading to an abundance of UV modes that disrupt simulation\nstability. This necessitates very small lattice spacings, resulting in\nexceedingly long simulation runtimes. Furthermore, the late-time behavior of\npreheating dynamics exhibits a universal form by wave kinetic theory.\nTherefore, we analyze patterns in the flow of particle numbers and predict\nfuture behavior using CNN-LSTM (Convolutional Neural Network combined with Long\nShort-Term Memory) time series analysis. In this way, we can reduce our\ndependence on simulations by orders of magnitude in terms of time and\ncomputational resources.",
    "published": "2024-05-14T18:30:02Z",
    "pdf_url": "http://arxiv.org/pdf/2405.08901v2",
    "categories": [
      "hep-ph",
      "astro-ph.CO"
    ]
  },
  {
    "arxiv_id": "2501.14152v1",
    "title": "Multimodal Prescriptive Deep Learning",
    "authors": [
      "Dimitris Bertsimas",
      "Lisa Everest",
      "Vasiliki Stoumpou"
    ],
    "abstract": "We introduce a multimodal deep learning framework, Prescriptive Neural\nNetworks (PNNs), that combines ideas from optimization and machine learning,\nand is, to the best of our knowledge, the first prescriptive method to handle\nmultimodal data. The PNN is a feedforward neural network trained on embeddings\nto output an outcome-optimizing prescription. In two real-world multimodal\ndatasets, we demonstrate that PNNs prescribe treatments that are able to\nsignificantly improve estimated outcomes in transcatheter aortic valve\nreplacement (TAVR) procedures by reducing estimated postoperative complication\nrates by 32% and in liver trauma injuries by reducing estimated mortality rates\nby over 40%. In four real-world, unimodal tabular datasets, we demonstrate that\nPNNs outperform or perform comparably to other well-known, state-of-the-art\nprescriptive models; importantly, on tabular datasets, we also recover\ninterpretability through knowledge distillation, fitting interpretable Optimal\nClassification Tree models onto the PNN prescriptions as classification\ntargets, which is critical for many real-world applications. Finally, we\ndemonstrate that our multimodal PNN models achieve stability across randomized\ndata splits comparable to other prescriptive methods and produce realistic\nprescriptions across the different datasets.",
    "published": "2025-01-24T00:37:28Z",
    "pdf_url": "http://arxiv.org/pdf/2501.14152v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1710.10784v1",
    "title": "How deep learning works --The geometry of deep learning",
    "authors": [
      "Xiao Dong",
      "Jiasong Wu",
      "Ling Zhou"
    ],
    "abstract": "Why and how that deep learning works well on different tasks remains a\nmystery from a theoretical perspective. In this paper we draw a geometric\npicture of the deep learning system by finding its analogies with two existing\ngeometric structures, the geometry of quantum computations and the geometry of\nthe diffeomorphic template matching. In this framework, we give the geometric\nstructures of different deep learning systems including convolutional neural\nnetworks, residual networks, recursive neural networks, recurrent neural\nnetworks and the equilibrium prapagation framework. We can also analysis the\nrelationship between the geometrical structures and their performance of\ndifferent networks in an algorithmic level so that the geometric framework may\nguide the design of the structures and algorithms of deep learning systems.",
    "published": "2017-10-30T06:42:23Z",
    "pdf_url": "http://arxiv.org/pdf/1710.10784v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1709.01953v2",
    "title": "Implicit Regularization in Deep Learning",
    "authors": [
      "Behnam Neyshabur"
    ],
    "abstract": "In an attempt to better understand generalization in deep learning, we study\nseveral possible explanations. We show that implicit regularization induced by\nthe optimization method is playing a key role in generalization and success of\ndeep learning models. Motivated by this view, we study how different complexity\nmeasures can ensure generalization and explain how optimization algorithms can\nimplicitly regularize complexity measures. We empirically investigate the\nability of these measures to explain different observed phenomena in deep\nlearning. We further study the invariances in neural networks, suggest\ncomplexity measures and optimization algorithms that have similar invariances\nto those in neural networks and evaluate them on a number of learning tasks.",
    "published": "2017-09-06T18:12:04Z",
    "pdf_url": "http://arxiv.org/pdf/1709.01953v2",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2107.02584v2",
    "title": "Deep learning for bioimage analysis",
    "authors": [
      "Adrien Hallou",
      "Hannah Yevick",
      "Bianca Dumitrascu",
      "Virginie Uhlmann"
    ],
    "abstract": "Deep learning has transformed the way large and complex image datasets can be\nprocessed, reshaping what is possible in bioimage analysis. As the complexity\nand size of bioimage data continues to grow, this new analysis paradigm is\nbecoming increasingly ubiquitous. In this Review, we begin by introducing the\nconcepts needed for beginners to understand deep learning. We then review how\ndeep learning has impacted bioimage analysis and explore the open-source\nresources available to integrate it into a research project. Finally, we\ndiscuss the future of deep learning applied to cell and developmental biology.\nWe analyse how state-of-the-art methodologies have the potential to transform\nour understanding of biological systems through new image-based analysis and\nmodelling that integrate multimodal inputs in space and time.",
    "published": "2021-07-06T12:53:45Z",
    "pdf_url": "http://arxiv.org/pdf/2107.02584v2",
    "categories": [
      "q-bio.QM",
      "physics.bio-ph",
      "I.2.1; I.4.3; I.4.4; I.4.6; I.4.8"
    ]
  },
  {
    "arxiv_id": "1802.04647v1",
    "title": "Deep Learning with Apache SystemML",
    "authors": [
      "Niketan Pansare",
      "Michael Dusenberry",
      "Nakul Jindal",
      "Matthias Boehm",
      "Berthold Reinwald",
      "Prithviraj Sen"
    ],
    "abstract": "Enterprises operate large data lakes using Hadoop and Spark frameworks that\n(1) run a plethora of tools to automate powerful data\npreparation/transformation pipelines, (2) run on shared, large clusters to (3)\nperform many different analytics tasks ranging from model preparation,\nbuilding, evaluation, and tuning for both machine learning and deep learning.\nDeveloping machine/deep learning models on data in such shared environments is\nchallenging. Apache SystemML provides a unified framework for implementing\nmachine learning and deep learning algorithms in a variety of shared deployment\nscenarios. SystemML's novel compilation approach automatically generates\nruntime execution plans for machine/deep learning algorithms that are composed\nof single-node and distributed runtime operations depending on data and cluster\ncharacteristics such as data size, data sparsity, cluster size, and memory\nconfigurations, while still exploiting the capabilities of the underlying big\ndata frameworks.",
    "published": "2018-02-08T23:54:37Z",
    "pdf_url": "http://arxiv.org/pdf/1802.04647v1",
    "categories": [
      "cs.LG",
      "cs.DC"
    ]
  },
  {
    "arxiv_id": "1807.04950v1",
    "title": "Deep Learning in the Wild",
    "authors": [
      "Thilo Stadelmann",
      "Mohammadreza Amirian",
      "Ismail Arabaci",
      "Marek Arnold",
      "Gilbert François Duivesteijn",
      "Ismail Elezi",
      "Melanie Geiger",
      "Stefan Lörwald",
      "Benjamin Bruno Meier",
      "Katharina Rombach",
      "Lukas Tuggener"
    ],
    "abstract": "Deep learning with neural networks is applied by an increasing number of\npeople outside of classic research environments, due to the vast success of the\nmethodology on a wide range of machine perception tasks. While this interest is\nfueled by beautiful success stories, practical work in deep learning on novel\ntasks without existing baselines remains challenging. This paper explores the\nspecific challenges arising in the realm of real world tasks, based on case\nstudies from research \\& development in conjunction with industry, and extracts\nlessons learned from them. It thus fills a gap between the publication of\nlatest algorithmic and methodical developments, and the usually omitted\nnitty-gritty of how to make them work. Specifically, we give insight into deep\nlearning projects on face matching, print media monitoring, industrial quality\ncontrol, music scanning, strategy game playing, and automated machine learning,\nthereby providing best practices for deep learning in practice.",
    "published": "2018-07-13T07:22:45Z",
    "pdf_url": "http://arxiv.org/pdf/1807.04950v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2205.05764v1",
    "title": "Deep Learning and Synthetic Media",
    "authors": [
      "Raphaël Millière"
    ],
    "abstract": "Deep learning algorithms are rapidly changing the way in which audiovisual\nmedia can be produced. Synthetic audiovisual media generated with deep learning\n- often subsumed colloquially under the label \"deepfakes\" - have a number of\nimpressive characteristics; they are increasingly trivial to produce, and can\nbe indistinguishable from real sounds and images recorded with a sensor. Much\nattention has been dedicated to ethical concerns raised by this technological\ndevelopment. Here, I focus instead on a set of issues related to the notion of\nsynthetic audiovisual media, its place within a broader taxonomy of audiovisual\nmedia, and how deep learning techniques differ from more traditional approaches\nto media synthesis. After reviewing important etiological features of deep\nlearning pipelines for media manipulation and generation, I argue that\n\"deepfakes\" and related synthetic media produced with such pipelines do not\nmerely offer incremental improvements over previous methods, but challenge\ntraditional taxonomical distinctions, and pave the way for genuinely novel\nkinds of audiovisual media.",
    "published": "2022-05-11T20:28:09Z",
    "pdf_url": "http://arxiv.org/pdf/2205.05764v1",
    "categories": [
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2401.02321v1",
    "title": "Deep Learning for Optical Tweezers",
    "authors": [
      "Antonio Ciarlo",
      "David Bronte Ciriza",
      "Martin Selin",
      "Onofrio M. Maragò",
      "Antonio Sasso",
      "Giuseppe Pesce",
      "Giovanni Volpe",
      "Mattias Goksör"
    ],
    "abstract": "Optical tweezers exploit light--matter interactions to trap particles ranging\nfrom single atoms to micrometer-sized eukaryotic cells. For this reason,\noptical tweezers are a ubiquitous tool in physics, biology, and nanotechnology.\nRecently, the use of deep learning has started to enhance optical tweezers by\nimproving their design, calibration, and real-time control as well as the\ntracking and analysis of the trapped objects, often outperforming classical\nmethods thanks to the higher computational speed and versatility of deep\nlearning. Here, we review how deep learning has already remarkably improved\noptical tweezers, while exploring the exciting, new future possibilities\nenabled by this dynamic synergy. Furthermore, we offer guidelines on\nintegrating deep learning with optical trapping and optical manipulation in a\nreliable and trustworthy way.",
    "published": "2024-01-04T15:41:46Z",
    "pdf_url": "http://arxiv.org/pdf/2401.02321v1",
    "categories": [
      "physics.optics",
      "physics.ins-det",
      "78-02"
    ]
  },
  {
    "arxiv_id": "2302.00150v1",
    "title": "Multi-Grade Deep Learning",
    "authors": [
      "Yuesheng Xu"
    ],
    "abstract": "The current deep learning model is of a single-grade, that is, it learns a\ndeep neural network by solving a single nonconvex optimization problem. When\nthe layer number of the neural network is large, it is computationally\nchallenging to carry out such a task efficiently. Inspired by the human\neducation process which arranges learning in grades, we propose a multi-grade\nlearning model: We successively solve a number of optimization problems of\nsmall sizes, which are organized in grades, to learn a shallow neural network\nfor each grade. Specifically, the current grade is to learn the leftover from\nthe previous grade. In each of the grades, we learn a shallow neural network\nstacked on the top of the neural network, learned in the previous grades, which\nremains unchanged in training of the current and future grades. By dividing the\ntask of learning a deep neural network into learning several shallow neural\nnetworks, one can alleviate the severity of the nonconvexity of the original\noptimization problem of a large size. When all grades of the learning are\ncompleted, the final neural network learned is a stair-shape neural network,\nwhich is the superposition of networks learned from all grades. Such a model\nenables us to learn a deep neural network much more effectively and\nefficiently. Moreover, multi-grade learning naturally leads to adaptive\nlearning. We prove that in the context of function approximation if the neural\nnetwork generated by a new grade is nontrivial, the optimal error of the grade\nis strictly reduced from the optimal error of the previous grade. Furthermore,\nwe provide several proof-of-concept numerical examples which demonstrate that\nthe proposed multi-grade model outperforms significantly the traditional\nsingle-grade model and is much more robust than the traditional model.",
    "published": "2023-02-01T00:09:56Z",
    "pdf_url": "http://arxiv.org/pdf/2302.00150v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2302.09656v5",
    "title": "Credal Bayesian Deep Learning",
    "authors": [
      "Michele Caprio",
      "Souradeep Dutta",
      "Kuk Jin Jang",
      "Vivian Lin",
      "Radoslav Ivanov",
      "Oleg Sokolsky",
      "Insup Lee"
    ],
    "abstract": "Uncertainty quantification and robustness to distribution shifts are\nimportant goals in machine learning and artificial intelligence. Although\nBayesian Neural Networks (BNNs) allow for uncertainty in the predictions to be\nassessed, different sources of predictive uncertainty cannot be distinguished\nproperly. We present Credal Bayesian Deep Learning (CBDL). Heuristically, CBDL\nallows to train an (uncountably) infinite ensemble of BNNs, using only finitely\nmany elements. This is possible thanks to prior and likelihood finitely\ngenerated credal sets (FGCSs), a concept from the imprecise probability\nliterature. Intuitively, convex combinations of a finite collection of\nprior-likelihood pairs are able to represent infinitely many such pairs. After\ntraining, CBDL outputs a set of posteriors on the parameters of the neural\nnetwork. At inference time, such posterior set is used to derive a set of\npredictive distributions that is in turn utilized to distinguish between\n(predictive) aleatoric and epistemic uncertainties, and to quantify them. The\npredictive set also produces either (i) a collection of outputs enjoying\ndesirable probabilistic guarantees, or (ii) the single output that is deemed\nthe best, that is, the one having the highest predictive lower probability --\nanother imprecise-probabilistic concept. CBDL is more robust than single BNNs\nto prior and likelihood misspecification, and to distribution shift. We show\nthat CBDL is better at quantifying and disentangling different types of\n(predictive) uncertainties than single BNNs and ensemble of BNNs. In addition,\nwe apply CBDL to two case studies to demonstrate its downstream tasks\ncapabilities: one, for motion prediction in autonomous driving scenarios, and\ntwo, to model blood glucose and insulin dynamics for artificial pancreas\ncontrol. We show that CBDL performs better when compared to an ensemble of BNNs\nbaseline.",
    "published": "2023-02-19T19:03:26Z",
    "pdf_url": "http://arxiv.org/pdf/2302.09656v5",
    "categories": [
      "cs.LG",
      "stat.ML",
      "Primary: 68T37, Secondary: 68T05, 68W25"
    ]
  },
  {
    "arxiv_id": "1807.03523v1",
    "title": "DLOPT: Deep Learning Optimization Library",
    "authors": [
      "Andrés Camero",
      "Jamal Toutouh",
      "Enrique Alba"
    ],
    "abstract": "Deep learning hyper-parameter optimization is a tough task. Finding an\nappropriate network configuration is a key to success, however most of the\ntimes this labor is roughly done. In this work we introduce a novel library to\ntackle this problem, the Deep Learning Optimization Library: DLOPT. We briefly\ndescribe its architecture and present a set of use examples. This is an open\nsource project developed under the GNU GPL v3 license and it is freely\navailable at https://github.com/acamero/dlopt",
    "published": "2018-07-10T08:34:25Z",
    "pdf_url": "http://arxiv.org/pdf/1807.03523v1",
    "categories": [
      "cs.LG",
      "cs.NE",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1809.03559v1",
    "title": "Deep Learning Towards Mobile Applications",
    "authors": [
      "Ji Wang",
      "Bokai Cao",
      "Philip S. Yu",
      "Lichao Sun",
      "Weidong Bao",
      "Xiaomin Zhu"
    ],
    "abstract": "Recent years have witnessed an explosive growth of mobile devices. Mobile\ndevices are permeating every aspect of our daily lives. With the increasing\nusage of mobile devices and intelligent applications, there is a soaring demand\nfor mobile applications with machine learning services. Inspired by the\ntremendous success achieved by deep learning in many machine learning tasks, it\nbecomes a natural trend to push deep learning towards mobile applications.\nHowever, there exist many challenges to realize deep learning in mobile\napplications, including the contradiction between the miniature nature of\nmobile devices and the resource requirement of deep neural networks, the\nprivacy and security concerns about individuals' data, and so on. To resolve\nthese challenges, during the past few years, great leaps have been made in this\narea. In this paper, we provide an overview of the current challenges and\nrepresentative achievements about pushing deep learning on mobile devices from\nthree aspects: training with mobile data, efficient inference on mobile\ndevices, and applications of mobile deep learning. The former two aspects cover\nthe primary tasks of deep learning. Then, we go through our two recent\napplications that apply the data collected by mobile devices to inferring mood\ndisturbance and user identification. Finally, we conclude this paper with the\ndiscussion of the future of this area.",
    "published": "2018-09-10T19:28:57Z",
    "pdf_url": "http://arxiv.org/pdf/1809.03559v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ]
  },
  {
    "arxiv_id": "2005.06068v1",
    "title": "Deep Learning for Wireless Communications",
    "authors": [
      "Tugba Erpek",
      "Timothy J. O'Shea",
      "Yalin E. Sagduyu",
      "Yi Shi",
      "T. Charles Clancy"
    ],
    "abstract": "Existing communication systems exhibit inherent limitations in translating\ntheory to practice when handling the complexity of optimization for emerging\nwireless applications with high degrees of freedom. Deep learning has a strong\npotential to overcome this challenge via data-driven solutions and improve the\nperformance of wireless systems in utilizing limited spectrum resources. In\nthis chapter, we first describe how deep learning is used to design an\nend-to-end communication system using autoencoders. This flexible design\neffectively captures channel impairments and optimizes transmitter and receiver\noperations jointly in single-antenna, multiple-antenna, and multiuser\ncommunications. Next, we present the benefits of deep learning in spectrum\nsituation awareness ranging from channel modeling and estimation to signal\ndetection and classification tasks. Deep learning improves the performance when\nthe model-based methods fail. Finally, we discuss how deep learning applies to\nwireless communication security. In this context, adversarial machine learning\nprovides novel means to launch and defend against wireless attacks. These\napplications demonstrate the power of deep learning in providing novel means to\ndesign, optimize, adapt, and secure wireless communications.",
    "published": "2020-05-12T21:58:44Z",
    "pdf_url": "http://arxiv.org/pdf/2005.06068v1",
    "categories": [
      "cs.NI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2508.02723v1",
    "title": "Mathematical Foundations of Geometric Deep Learning",
    "authors": [
      "Haitz Sáez de Ocáriz Borde",
      "Michael Bronstein"
    ],
    "abstract": "We review the key mathematical concepts necessary for studying Geometric Deep\nLearning.",
    "published": "2025-08-01T06:02:39Z",
    "pdf_url": "http://arxiv.org/pdf/2508.02723v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1904.05391v5",
    "title": "Deep Learning without Weight Transport",
    "authors": [
      "Mohamed Akrout",
      "Collin Wilson",
      "Peter C. Humphreys",
      "Timothy Lillicrap",
      "Douglas Tweed"
    ],
    "abstract": "Current algorithms for deep learning probably cannot run in the brain because\nthey rely on weight transport, where forward-path neurons transmit their\nsynaptic weights to a feedback path, in a way that is likely impossible\nbiologically. An algorithm called feedback alignment achieves deep learning\nwithout weight transport by using random feedback weights, but it performs\npoorly on hard visual-recognition tasks. Here we describe two mechanisms - a\nneural circuit called a weight mirror and a modification of an algorithm\nproposed by Kolen and Pollack in 1994 - both of which let the feedback path\nlearn appropriate synaptic weights quickly and accurately even in large\nnetworks, without weight transport or complex wiring.Tested on the ImageNet\nvisual-recognition task, these mechanisms outperform both feedback alignment\nand the newer sign-symmetry method, and nearly match backprop, the standard\nalgorithm of deep learning, which uses weight transport.",
    "published": "2019-04-10T18:55:59Z",
    "pdf_url": "http://arxiv.org/pdf/1904.05391v5",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1907.02994v2",
    "title": "Deep learning in ultrasound imaging",
    "authors": [
      "Ruud JG van Sloun",
      "Regev Cohen",
      "Yonina C Eldar"
    ],
    "abstract": "We consider deep learning strategies in ultrasound systems, from the\nfront-end to advanced applications. Our goal is to provide the reader with a\nbroad understanding of the possible impact of deep learning methodologies on\nmany aspects of ultrasound imaging. In particular, we discuss methods that lie\nat the interface of signal acquisition and machine learning, exploiting both\ndata structure (e.g. sparsity in some domain) and data dimensionality (big\ndata) already at the raw radio-frequency channel stage. As some examples, we\noutline efficient and effective deep learning solutions for adaptive\nbeamforming and adaptive spectral Doppler through artificial agents, learn\ncompressive encodings for color Doppler, and provide a framework for structured\nsignal recovery by learning fast approximations of iterative minimization\nproblems, with applications to clutter suppression and super-resolution\nultrasound. These emerging technologies may have considerable impact on\nultrasound imaging, showing promise across key components in the receive\nprocessing chain.",
    "published": "2019-07-05T18:39:49Z",
    "pdf_url": "http://arxiv.org/pdf/1907.02994v2",
    "categories": [
      "eess.SP",
      "cs.LG",
      "eess.IV"
    ]
  },
  {
    "arxiv_id": "2102.01194v2",
    "title": "A Statistician Teaches Deep Learning",
    "authors": [
      "G. Jogesh Babu",
      "David Banks",
      "Hyunsoon Cho",
      "David Han",
      "Hailin Sang",
      "Shouyi Wang"
    ],
    "abstract": "Deep learning (DL) has gained much attention and become increasingly popular\nin modern data science. Computer scientists led the way in developing deep\nlearning techniques, so the ideas and perspectives can seem alien to\nstatisticians. Nonetheless, it is important that statisticians become involved\n-- many of our students need this expertise for their careers. In this paper,\ndeveloped as part of a program on DL held at the Statistical and Applied\nMathematical Sciences Institute, we address this culture gap and provide tips\non how to teach deep learning to statistics graduate students. After some\nbackground, we list ways in which DL and statistical perspectives differ,\nprovide a recommended syllabus that evolved from teaching two iterations of a\nDL graduate course, offer examples of suggested homework assignments, give an\nannotated list of teaching resources, and discuss DL in the context of two\nresearch areas.",
    "published": "2021-01-29T04:59:43Z",
    "pdf_url": "http://arxiv.org/pdf/2102.01194v2",
    "categories": [
      "stat.ML",
      "cs.CY",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2405.18281v2",
    "title": "MODL: Multilearner Online Deep Learning",
    "authors": [
      "Antonios Valkanas",
      "Boris N. Oreshkin",
      "Mark Coates"
    ],
    "abstract": "Online deep learning tackles the challenge of learning from data streams by\nbalancing two competing goals: fast learning and deep learning. However,\nexisting research primarily emphasizes deep learning solutions, which are more\nadept at handling the ``deep'' aspect than the ``fast'' aspect of online\nlearning. In this work, we introduce an alternative paradigm through a hybrid\nmultilearner approach. We begin by developing a fast online logistic regression\nlearner, which operates without relying on backpropagation. It leverages\nclosed-form recursive updates of model parameters, efficiently addressing the\nfast learning component of the online learning challenge. This approach is\nfurther integrated with a cascaded multilearner design, where shallow and deep\nlearners are co-trained in a cooperative, synergistic manner to solve the\nonline learning problem. We demonstrate that this approach achieves\nstate-of-the-art performance on standard online learning datasets. We make our\ncode available: https://github.com/AntonValk/MODL",
    "published": "2024-05-28T15:34:33Z",
    "pdf_url": "http://arxiv.org/pdf/2405.18281v2",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1905.13390v1",
    "title": "Vehicle Detection in Deep Learning",
    "authors": [
      "Yao Xiao"
    ],
    "abstract": "Computer vision is developing rapidly with the support of deep learning\ntechniques. This thesis proposes an advanced vehicle-detection model based on\nan improvement to classical convolutional neural networks. The advanced model\nwas applied against a vehicle detection benchmark and was built to detect\non-road objects. First, we propose a high-level architecture for our advanced\nmodel, which utilizes different state-of-the-art deep learning techniques.\nThen, we utilize the residual neural networks and region proposal network to\nachieve competitive performance according to the vehicle detection benchmark.\nLastly, we describe the developing trend of vehicle detection techniques and\nthe future direction of research.",
    "published": "2019-05-29T00:33:28Z",
    "pdf_url": "http://arxiv.org/pdf/1905.13390v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2005.02636v2",
    "title": "Deep Learning and AdS/QCD",
    "authors": [
      "Tetsuya Akutagawa",
      "Koji Hashimoto",
      "Takayuki Sumimoto"
    ],
    "abstract": "We propose a deep learning method to build an AdS/QCD model from the data of\nhadron spectra. A major problem of generic AdS/QCD models is that a large\nambiguity is allowed for the bulk gravity metric with which QCD observables are\nholographically calculated. We adopt the experimentally measured spectra of\n$\\rho$ and $a_2$ mesons as training data, and perform a supervised machine\nlearning which determines concretely a bulk metric and a dilaton profile of an\nAdS/QCD model. Our deep learning (DL) architecture is based on the AdS/DL\ncorrespondence (arXiv:1802.08313) where the deep neural network is identified\nwith the emergent bulk spacetime.",
    "published": "2020-05-06T07:48:00Z",
    "pdf_url": "http://arxiv.org/pdf/2005.02636v2",
    "categories": [
      "hep-th",
      "cond-mat.dis-nn",
      "hep-ph"
    ]
  },
  {
    "arxiv_id": "1904.10345v1",
    "title": "Deep Learning for Survival Outcomes",
    "authors": [
      "Jon Arni Steingrimsson"
    ],
    "abstract": "This manuscripts develops a new class of deep learning algorithms for\noutcomes that are potentially censored. To account for censoring, the\nunobservable loss function used in the absence of censoring is replaced by a\ncensoring unbiased transformation. The resulting class of algorithms can be\nused to estimate both survival probabilities and restricted mean survival. We\nshow how the deep learning algorithms can be implemented using software for\nuncensored data using a form of response transformation. Simulations and\nanalysis of the Netherlands 70 Gene Signature Data show strong performance of\nthe proposed algorithms.",
    "published": "2019-04-23T14:08:38Z",
    "pdf_url": "http://arxiv.org/pdf/1904.10345v1",
    "categories": [
      "stat.ME"
    ]
  },
  {
    "arxiv_id": "2407.18384v3",
    "title": "Mathematical theory of deep learning",
    "authors": [
      "Philipp Petersen",
      "Jakob Zech"
    ],
    "abstract": "This book provides an introduction to the mathematical analysis of deep\nlearning. It covers fundamental results in approximation theory, optimization\ntheory, and statistical learning theory, which are the three main pillars of\ndeep neural network theory. Serving as a guide for students and researchers in\nmathematics and related fields, the book aims to equip readers with\nfoundational knowledge on the topic. It prioritizes simplicity over generality,\nand presents rigorous yet accessible results to help build an understanding of\nthe essential mathematical concepts underpinning deep learning.",
    "published": "2024-07-25T20:37:12Z",
    "pdf_url": "http://arxiv.org/pdf/2407.18384v3",
    "categories": [
      "cs.LG",
      "math.HO"
    ]
  },
  {
    "arxiv_id": "1805.10451v2",
    "title": "Geometric Understanding of Deep Learning",
    "authors": [
      "Na Lei",
      "Zhongxuan Luo",
      "Shing-Tung Yau",
      "David Xianfeng Gu"
    ],
    "abstract": "Deep learning is the mainstream technique for many machine learning tasks,\nincluding image recognition, machine translation, speech recognition, and so\non. It has outperformed conventional methods in various fields and achieved\ngreat successes. Unfortunately, the understanding on how it works remains\nunclear. It has the central importance to lay down the theoretic foundation for\ndeep learning.\n  In this work, we give a geometric view to understand deep learning: we show\nthat the fundamental principle attributing to the success is the manifold\nstructure in data, namely natural high dimensional data concentrates close to a\nlow-dimensional manifold, deep learning learns the manifold and the probability\ndistribution on it.\n  We further introduce the concepts of rectified linear complexity for deep\nneural network measuring its learning capability, rectified linear complexity\nof an embedding manifold describing the difficulty to be learned. Then we show\nfor any deep neural network with fixed architecture, there exists a manifold\nthat cannot be learned by the network. Finally, we propose to apply optimal\nmass transportation theory to control the probability distribution in the\nlatent space.",
    "published": "2018-05-26T09:15:53Z",
    "pdf_url": "http://arxiv.org/pdf/1805.10451v2",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1903.01458v1",
    "title": "Deep Learning for Cognitive Neuroscience",
    "authors": [
      "Katherine R. Storrs",
      "Nikolaus Kriegeskorte"
    ],
    "abstract": "Neural network models can now recognise images, understand text, translate\nlanguages, and play many human games at human or superhuman levels. These\nsystems are highly abstracted, but are inspired by biological brains and use\nonly biologically plausible computations. In the coming years, neural networks\nare likely to become less reliant on learning from massive labelled datasets,\nand more robust and generalisable in their task performance. From their\nsuccesses and failures, we can learn about the computational requirements of\nthe different tasks at which brains excel. Deep learning also provides the\ntools for testing cognitive theories. In order to test a theory, we need to\nrealise the proposed information-processing system at scale, so as to be able\nto assess its feasibility and emergent behaviours. Deep learning allows us to\nscale up from principles and circuit models to end-to-end trainable models\ncapable of performing complex tasks. There are many levels at which cognitive\nneuroscientists can use deep learning in their work, from inspiring theories to\nserving as full computational models. Ongoing advances in deep learning bring\nus closer to understanding how cognition and perception may be implemented in\nthe brain -- the grand challenge at the core of cognitive neuroscience.",
    "published": "2019-03-04T14:34:52Z",
    "pdf_url": "http://arxiv.org/pdf/1903.01458v1",
    "categories": [
      "q-bio.NC",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2001.05266v1",
    "title": "Deep Learning for MIR Tutorial",
    "authors": [
      "Alexander Schindler",
      "Thomas Lidy",
      "Sebastian Böck"
    ],
    "abstract": "Deep Learning has become state of the art in visual computing and\ncontinuously emerges into the Music Information Retrieval (MIR) and audio\nretrieval domain. In order to bring attention to this topic we propose an\nintroductory tutorial on deep learning for MIR. Besides a general introduction\nto neural networks, the proposed tutorial covers a wide range of MIR relevant\ndeep learning approaches. \\textbf{Convolutional Neural Networks} are currently\na de-facto standard for deep learning based audio retrieval. \\textbf{Recurrent\nNeural Networks} have proven to be effective in onset detection tasks such as\nbeat or audio-event detection. \\textbf{Siamese Networks} have been shown\neffective in learning audio representations and distance functions specific for\nmusic similarity retrieval. We will incorporate both academic and industrial\npoints of view into the tutorial. Accompanying the tutorial, we will create a\nGithub repository for the content presented at the tutorial as well as\nreferences to state of the art work and literature for further reading. This\nrepository will remain public after the conference.",
    "published": "2020-01-15T12:23:17Z",
    "pdf_url": "http://arxiv.org/pdf/2001.05266v1",
    "categories": [
      "cs.IR",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "1701.04503v1",
    "title": "Deep Learning for Computational Chemistry",
    "authors": [
      "Garrett B. Goh",
      "Nathan O. Hodas",
      "Abhinav Vishnu"
    ],
    "abstract": "The rise and fall of artificial neural networks is well documented in the\nscientific literature of both computer science and computational chemistry. Yet\nalmost two decades later, we are now seeing a resurgence of interest in deep\nlearning, a machine learning algorithm based on multilayer neural networks.\nWithin the last few years, we have seen the transformative impact of deep\nlearning in many domains, particularly in speech recognition and computer\nvision, to the extent that the majority of expert practitioners in those field\nare now regularly eschewing prior established models in favor of deep learning\nmodels. In this review, we provide an introductory overview into the theory of\ndeep neural networks and their unique properties that distinguish them from\ntraditional machine learning algorithms used in cheminformatics. By providing\nan overview of the variety of emerging applications of deep neural networks, we\nhighlight its ubiquity and broad applicability to a wide range of challenges in\nthe field, including QSAR, virtual screening, protein structure prediction,\nquantum chemistry, materials design and property prediction. In reviewing the\nperformance of deep neural networks, we observed a consistent outperformance\nagainst non-neural networks state-of-the-art models across disparate research\ntopics, and deep neural network based models often exceeded the \"glass ceiling\"\nexpectations of their respective tasks. Coupled with the maturity of\nGPU-accelerated computing for training deep neural networks and the exponential\ngrowth of chemical data on which to train these networks on, we anticipate that\ndeep learning algorithms will be a valuable tool for computational chemistry.",
    "published": "2017-01-17T01:15:14Z",
    "pdf_url": "http://arxiv.org/pdf/1701.04503v1",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.CE",
      "cs.LG",
      "physics.chem-ph"
    ]
  },
  {
    "arxiv_id": "1709.05929v1",
    "title": "Institutionally Distributed Deep Learning Networks",
    "authors": [
      "Ken Chang",
      "Niranjan Balachandar",
      "Carson K Lam",
      "Darvin Yi",
      "James M Brown",
      "Andrew Beers",
      "Bruce R Rosen",
      "Daniel L Rubin",
      "Jayashree Kalpathy-Cramer"
    ],
    "abstract": "Deep learning has become a promising approach for automated medical\ndiagnoses. When medical data samples are limited, collaboration among multiple\ninstitutions is necessary to achieve high algorithm performance. However,\nsharing patient data often has limitations due to technical, legal, or ethical\nconcerns. In such cases, sharing a deep learning model is a more attractive\nalternative. The best method of performing such a task is unclear, however. In\nthis study, we simulate the dissemination of learning deep learning network\nmodels across four institutions using various heuristics and compare the\nresults with a deep learning model trained on centrally hosted patient data.\nThe heuristics investigated include ensembling single institution models,\nsingle weight transfer, and cyclical weight transfer. We evaluated these\napproaches for image classification in three independent image collections\n(retinal fundus photos, mammography, and ImageNet). We find that cyclical\nweight transfer resulted in a performance (testing accuracy = 77.3%) that was\nclosest to that of centrally hosted patient data (testing accuracy = 78.7%). We\nalso found that there is an improvement in the performance of cyclical weight\ntransfer heuristic with high frequency of weight transfer.",
    "published": "2017-09-10T15:36:17Z",
    "pdf_url": "http://arxiv.org/pdf/1709.05929v1",
    "categories": [
      "cs.CV",
      "cs.LG",
      "physics.med-ph"
    ]
  },
  {
    "arxiv_id": "2105.09266v5",
    "title": "Copyright in Generative Deep Learning",
    "authors": [
      "Giorgio Franceschelli",
      "Mirco Musolesi"
    ],
    "abstract": "Machine-generated artworks are now part of the contemporary art scene: they\nare attracting significant investments and they are presented in exhibitions\ntogether with those created by human artists. These artworks are mainly based\non generative deep learning techniques, which have seen a formidable\ndevelopment and remarkable refinement in the very recent years. Given the\ninherent characteristics of these techniques, a series of novel legal problems\narise. In this article, we consider a set of key questions in the area of\ngenerative deep learning for the arts, including the following: is it possible\nto use copyrighted works as training set for generative models? How do we\nlegally store their copies in order to perform the training process? Who (if\nsomeone) will own the copyright on the generated data? We try to answer these\nquestions considering the law in force in both the United States of America and\nthe European Union, and potential future alternatives. We then extend our\nanalysis to code generation, which is an emerging area of generative deep\nlearning. Finally, we also formulate a set of practical guidelines for artists\nand developers working on deep learning generated art, as well as some policy\nsuggestions for policymakers.",
    "published": "2021-05-19T17:22:47Z",
    "pdf_url": "http://arxiv.org/pdf/2105.09266v5",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2106.14085v1",
    "title": "Deep Learning Partial Least Squares",
    "authors": [
      "Nicholas Polson",
      "Vadim Sokolov",
      "Jianeng Xu"
    ],
    "abstract": "High dimensional data reduction techniques are provided by using partial\nleast squares within deep learning. Our framework provides a nonlinear\nextension of PLS together with a disciplined approach to feature selection and\narchitecture design in deep learning. This leads to a statistical\ninterpretation of deep learning that is tailor made for predictive problems. We\ncan use the tools of PLS, such as scree-plot, bi-plot to provide model\ndiagnostics. Posterior predictive uncertainty is available using MCMC methods\nat the last layer. Thus we achieve the best of both worlds: scalability and\nfast predictive rule construction together with uncertainty quantification. Our\nkey construct is to employ deep learning within PLS by predicting the output\nscores as a deep learner of the input scores. As with PLS our X-scores are\nconstructed using SVD and applied to both regression and classification\nproblems and are fast and scalable. Following Frank and Friedman 1993, we\nprovide a Bayesian shrinkage interpretation of our nonlinear predictor. We\nintroduce a variety of new partial least squares models: PLS-ReLU,\nPLS-Autoencoder, PLS-Trees and PLS-GP. To illustrate our methodology, we use\nsimulated examples and the analysis of preferences of orange juice and\npredicting wine quality as a function of input characteristics. We also\nillustrate Brillinger's estimation procedure to provide the feature selection\nand data dimension reduction. Finally, we conclude with directions for future\nresearch.",
    "published": "2021-06-26T20:22:54Z",
    "pdf_url": "http://arxiv.org/pdf/2106.14085v1",
    "categories": [
      "stat.ME"
    ]
  },
  {
    "arxiv_id": "2203.05874v1",
    "title": "Deep Learning for Wireless Dynamics",
    "authors": [
      "Heunchul Lee",
      "Jaeseong Jeong",
      "Zhao Wang"
    ],
    "abstract": "This paper aims to predict radio channel variations over time by deep\nlearning from channel observations without knowledge of the underlying channel\ndynamics. In next-generation wideband cellular systems, multicarrier\ntransmission for higher data rate leads to the high-resolution predicting\nproblem. By leveraging recent advances of deep learning in high-resolution\nimage processing, we propose a purely data-driven deep learning (DL) approach\nto predicting high-resolution temporal evolution of wideband radio channels. In\norder to investigate the effect of architectural design choices, we develop and\nstudy three deep learning prediction models, namely, baseline, image\ncompletion, and next-frame prediction models using UNet. Numerical results show\nthat the proposed DL approach achieves a 52% lower prediction error than the\ntraditional approach based on the Kalman filter (KF) in mean absolute errors.\nTo quantify impact of channel aging and prediction on precoding performance, we\nalso evaluate the performance degradation due to outdated and predicted channel\nstate information (CSI) compared to perfect CSI. Our simulations show that the\nproposed DL approach can reduce the performance loss due to channel aging by\n71% through adapting precoding vector to changes in radio channel while the\ntraditional KF approach only shows a 27% reduction.",
    "published": "2022-03-11T12:21:05Z",
    "pdf_url": "http://arxiv.org/pdf/2203.05874v1",
    "categories": [
      "cs.IT",
      "math.IT"
    ]
  },
  {
    "arxiv_id": "2408.05629v2",
    "title": "Quantum-secure multiparty deep learning",
    "authors": [
      "Kfir Sulimany",
      "Sri Krishna Vadlamani",
      "Ryan Hamerly",
      "Prahlad Iyengar",
      "Dirk Englund"
    ],
    "abstract": "Secure multiparty computation enables the joint evaluation of multivariate\nfunctions across distributed users while ensuring the privacy of their local\ninputs. This field has become increasingly urgent due to the exploding demand\nfor computationally intensive deep learning inference. These computations are\ntypically offloaded to cloud computing servers, leading to vulnerabilities that\ncan compromise the security of the clients' data. To solve this problem, we\nintroduce a linear algebra engine that leverages the quantum nature of light\nfor information-theoretically secure multiparty computation using only\nconventional telecommunication components. We apply this linear algebra engine\nto deep learning and derive rigorous upper bounds on the information leakage of\nboth the deep neural network weights and the client's data via the Holevo and\nthe Cram\\'er-Rao bounds, respectively. Applied to the MNIST classification\ntask, we obtain test accuracies exceeding $96\\%$ while leaking less than $0.1$\nbits per weight symbol and $0.01$ bits per data symbol. This weight leakage is\nan order of magnitude below the minimum bit precision required for accurate\ndeep learning using state-of-the-art quantization techniques. Our work lays the\nfoundation for practical quantum-secure computation and unlocks secure cloud\ndeep learning as a field.",
    "published": "2024-08-10T20:48:40Z",
    "pdf_url": "http://arxiv.org/pdf/2408.05629v2",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "math.IT",
      "physics.optics"
    ]
  },
  {
    "arxiv_id": "2502.18300v3",
    "title": "Bayesian Computation in Deep Learning",
    "authors": [
      "Wenlong Chen",
      "Bolian Li",
      "Ruqi Zhang",
      "Yingzhen Li"
    ],
    "abstract": "This review paper is intended for the 2nd edition of the Handbook of Markov\nchain Monte Carlo. We provide an introduction to approximate inference\ntechniques as Bayesian computation methods applied to deep learning models. We\norganize the chapter by presenting popular computational methods for Bayesian\nneural networks and deep generative models, explaining their unique challenges\nin posterior inference as well as the solutions.",
    "published": "2025-02-25T15:39:33Z",
    "pdf_url": "http://arxiv.org/pdf/2502.18300v3",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1512.06927v4",
    "title": "A C++ library for Multimodal Deep Learning",
    "authors": [
      "Jian Jin"
    ],
    "abstract": "MDL, Multimodal Deep Learning Library, is a deep learning framework that\nsupports multiple models, and this document explains its philosophy and\nfunctionality. MDL runs on Linux, Mac, and Unix platforms. It depends on\nOpenCV.",
    "published": "2015-12-22T01:27:23Z",
    "pdf_url": "http://arxiv.org/pdf/1512.06927v4",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1711.03577v1",
    "title": "What Really is Deep Learning Doing?",
    "authors": [
      "Chuyu Xiong"
    ],
    "abstract": "Deep learning has achieved a great success in many areas, from computer\nvision to natural language processing, to game playing, and much more. Yet,\nwhat deep learning is really doing is still an open question. There are a lot\nof works in this direction. For example, [5] tried to explain deep learning by\ngroup renormalization, and [6] tried to explain deep learning from the view of\nfunctional approximation. In order to address this very crucial question, here\nwe see deep learning from perspective of mechanical learning and learning\nmachine (see [1], [2]). From this particular angle, we can see deep learning\nmuch better and answer with confidence: What deep learning is really doing? why\nit works well, how it works, and how much data is necessary for learning. We\nalso will discuss advantages and disadvantages of deep learning at the end of\nthis work.",
    "published": "2017-11-06T23:00:13Z",
    "pdf_url": "http://arxiv.org/pdf/1711.03577v1",
    "categories": [
      "cs.LG",
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "2009.08328v7",
    "title": "Review: Deep Learning in Electron Microscopy",
    "authors": [
      "Jeffrey M. Ede"
    ],
    "abstract": "Deep learning is transforming most areas of science and technology, including\nelectron microscopy. This review paper offers a practical perspective aimed at\ndevelopers with limited familiarity. For context, we review popular\napplications of deep learning in electron microscopy. Afterwards, we discuss\nhardware and software needed to get started with deep learning and interface\nwith electron microscopes. We then review neural network components, popular\narchitectures, and their optimization. Finally, we discuss future directions of\ndeep learning in electron microscopy.",
    "published": "2020-09-17T14:23:55Z",
    "pdf_url": "http://arxiv.org/pdf/2009.08328v7",
    "categories": [
      "eess.IV",
      "cond-mat.mtrl-sci",
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1801.07883v2",
    "title": "Deep Learning for Sentiment Analysis : A Survey",
    "authors": [
      "Lei Zhang",
      "Shuai Wang",
      "Bing Liu"
    ],
    "abstract": "Deep learning has emerged as a powerful machine learning technique that\nlearns multiple layers of representations or features of the data and produces\nstate-of-the-art prediction results. Along with the success of deep learning in\nmany other application domains, deep learning is also popularly used in\nsentiment analysis in recent years. This paper first gives an overview of deep\nlearning and then provides a comprehensive survey of its current applications\nin sentiment analysis.",
    "published": "2018-01-24T07:32:29Z",
    "pdf_url": "http://arxiv.org/pdf/1801.07883v2",
    "categories": [
      "cs.CL",
      "cs.IR",
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1608.00316v1",
    "title": "Density functionals from deep learning",
    "authors": [
      "Jeffrey M. McMahon"
    ],
    "abstract": "Density-functional theory is a formally exact description of a many-body\nquantum system in terms of its density; in practice, however, approximations to\nthe universal density functional are required. In this work, a model based on\ndeep learning is developed to approximate this functional. Deep learning allows\ncomputational models that are capable of naturally discovering intricate\nstructure in large and/or high-dimensional data sets, with multiple levels of\nabstraction. As no assumptions are made as to the form of this structure, this\napproach is much more powerful and flexible than traditional approaches. As an\nexample application, the model is shown to perform well on approximating the\nkinetic-energy density functional for noninteracting electrons. The model is\nanalyzed in detail, and its advantages over conventional machine learning are\ndiscussed.",
    "published": "2016-08-01T04:28:32Z",
    "pdf_url": "http://arxiv.org/pdf/1608.00316v1",
    "categories": [
      "physics.comp-ph",
      "physics.chem-ph"
    ]
  },
  {
    "arxiv_id": "1706.00473v4",
    "title": "Deep Learning: A Bayesian Perspective",
    "authors": [
      "Nicholas Polson",
      "Vadim Sokolov"
    ],
    "abstract": "Deep learning is a form of machine learning for nonlinear high dimensional\npattern matching and prediction. By taking a Bayesian probabilistic\nperspective, we provide a number of insights into more efficient algorithms for\noptimisation and hyper-parameter tuning. Traditional high-dimensional data\nreduction techniques, such as principal component analysis (PCA), partial least\nsquares (PLS), reduced rank regression (RRR), projection pursuit regression\n(PPR) are all shown to be shallow learners. Their deep learning counterparts\nexploit multiple deep layers of data reduction which provide predictive\nperformance gains. Stochastic gradient descent (SGD) training optimisation and\nDropout (DO) regularization provide estimation and variable selection. Bayesian\nregularization is central to finding weights and connections in networks to\noptimize the predictive bias-variance trade-off. To illustrate our methodology,\nwe provide an analysis of international bookings on Airbnb. Finally, we\nconclude with directions for future research.",
    "published": "2017-06-01T19:50:37Z",
    "pdf_url": "http://arxiv.org/pdf/1706.00473v4",
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ]
  },
  {
    "arxiv_id": "1706.09077v1",
    "title": "Super-Resolution via Deep Learning",
    "authors": [
      "Khizar Hayat"
    ],
    "abstract": "The recent phenomenal interest in convolutional neural networks (CNNs) must\nhave made it inevitable for the super-resolution (SR) community to explore its\npotential. The response has been immense and in the last three years, since the\nadvent of the pioneering work, there appeared too many works not to warrant a\ncomprehensive survey. This paper surveys the SR literature in the context of\ndeep learning. We focus on the three important aspects of multimedia - namely\nimage, video and multi-dimensions, especially depth maps. In each case, first\nrelevant benchmarks are introduced in the form of datasets and state of the art\nSR methods, excluding deep learning. Next is a detailed analysis of the\nindividual works, each including a short description of the method and a\ncritique of the results with special reference to the benchmarking done. This\nis followed by minimum overall benchmarking in the form of comparison on some\ncommon dataset, while relying on the results reported in various works.",
    "published": "2017-06-28T00:02:18Z",
    "pdf_url": "http://arxiv.org/pdf/1706.09077v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1712.00912v2",
    "title": "Deep Learning Diffuse Optical Tomography",
    "authors": [
      "Jaejun Yoo",
      "Sohail Sabir",
      "Duchang Heo",
      "Kee Hyun Kim",
      "Abdul Wahab",
      "Yoonseok Choi",
      "Seul-I Lee",
      "Eun Young Chae",
      "Hak Hee Kim",
      "Young Min Bae",
      "Young-wook Choi",
      "Seungryong Cho",
      "Jong Chul Ye"
    ],
    "abstract": "Diffuse optical tomography (DOT) has been investigated as an alternative\nimaging modality for breast cancer detection thanks to its excellent contrast\nto hemoglobin oxidization level. However, due to the complicated non-linear\nphoton scattering physics and ill-posedness, the conventional reconstruction\nalgorithms are sensitive to imaging parameters such as boundary conditions. To\naddress this, here we propose a novel deep learning approach that learns\nnon-linear photon scattering physics and obtains an accurate three dimensional\n(3D) distribution of optical anomalies. In contrast to the traditional\nblack-box deep learning approaches, our deep network is designed to invert the\nLippman-Schwinger integral equation using the recent mathematical theory of\ndeep convolutional framelets. As an example of clinical relevance, we applied\nthe method to our prototype DOT system. We show that our deep neural network,\ntrained with only simulation data, can accurately recover the location of\nanomalies within biomimetic phantoms and live animals without the use of an\nexogenous contrast agent.",
    "published": "2017-12-04T05:47:10Z",
    "pdf_url": "http://arxiv.org/pdf/1712.00912v2",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1908.09963v2",
    "title": "Deep Learning-Based Average Consensus",
    "authors": [
      "Masako Kishida",
      "Masaki Ogura",
      "Yuichi Yoshida",
      "Tadashi Wadayama"
    ],
    "abstract": "In this study, we analyzed the problem of accelerating the linear average\nconsensus algorithm for complex networks. We propose a data-driven approach to\ntuning the weights of temporal (i.e., time-varying) networks using deep\nlearning techniques. Given a finite-time window, the proposed approach first\nunfolds the linear average consensus protocol to obtain a feedforward\nsignal-flow graph, which is regarded as a neural network. The edge weights of\nthe obtained neural network are then trained using standard deep learning\ntechniques to minimize consensus error over a given finite-time window. Through\nthis training process, we obtain a set of optimized time-varying weights, which\nyield faster consensus for a complex network. We also demonstrate that the\nproposed approach can be extended for infinite-time window problems. Numerical\nexperiments revealed that our approach can achieve a significantly smaller\nconsensus error compared to baseline strategies.",
    "published": "2019-08-27T00:20:48Z",
    "pdf_url": "http://arxiv.org/pdf/1908.09963v2",
    "categories": [
      "math.OC"
    ]
  },
  {
    "arxiv_id": "2104.02395v3",
    "title": "Ensemble deep learning: A review",
    "authors": [
      "M. A. Ganaie",
      "Minghui Hu",
      "A. K. Malik",
      "M. Tanveer",
      "P. N. Suganthan"
    ],
    "abstract": "Ensemble learning combines several individual models to obtain better\ngeneralization performance. Currently, deep learning architectures are showing\nbetter performance compared to the shallow or traditional models. Deep ensemble\nlearning models combine the advantages of both the deep learning models as well\nas the ensemble learning such that the final model has better generalization\nperformance. This paper reviews the state-of-art deep ensemble models and hence\nserves as an extensive summary for the researchers. The ensemble models are\nbroadly categorised into bagging, boosting, stacking, negative correlation\nbased deep ensemble models, explicit/implicit ensembles,\nhomogeneous/heterogeneous ensemble, decision fusion strategies based deep\nensemble models. Applications of deep ensemble models in different domains are\nalso briefly discussed. Finally, we conclude this paper with some potential\nfuture research directions.",
    "published": "2021-04-06T09:56:29Z",
    "pdf_url": "http://arxiv.org/pdf/2104.02395v3",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1802.05383v1",
    "title": "Deep Learning Based Speech Beamforming",
    "authors": [
      "Kaizhi Qian",
      "Yang Zhang",
      "Shiyu Chang",
      "Xuesong Yang",
      "Dinei Florencio",
      "Mark Hasegawa-Johnson"
    ],
    "abstract": "Multi-channel speech enhancement with ad-hoc sensors has been a challenging\ntask. Speech model guided beamforming algorithms are able to recover natural\nsounding speech, but the speech models tend to be oversimplified or the\ninference would otherwise be too complicated. On the other hand, deep learning\nbased enhancement approaches are able to learn complicated speech distributions\nand perform efficient inference, but they are unable to deal with variable\nnumber of input channels. Also, deep learning approaches introduce a lot of\nerrors, particularly in the presence of unseen noise types and settings. We\nhave therefore proposed an enhancement framework called DEEPBEAM, which\ncombines the two complementary classes of algorithms. DEEPBEAM introduces a\nbeamforming filter to produce natural sounding speech, but the filter\ncoefficients are determined with the help of a monaural speech enhancement\nneural network. Experiments on synthetic and real-world data show that DEEPBEAM\nis able to produce clean, dry and natural sounding speech, and is robust\nagainst unseen noise.",
    "published": "2018-02-15T02:00:54Z",
    "pdf_url": "http://arxiv.org/pdf/1802.05383v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS",
      "eess.SP"
    ]
  },
  {
    "arxiv_id": "1909.02730v1",
    "title": "Deep Learning for Spectrum Sensing",
    "authors": [
      "Jiabao Gao",
      "Xuemei Yi",
      "Caijun Zhong",
      "Xiaoming Chen",
      "Zhaoyang Zhang"
    ],
    "abstract": "In cognitive radio systems, the ability to accurately detect primary user's\nsignal is essential to secondary user in order to utilize idle licensed\nspectrum. Conventional energy detector is a good choice for blind signal\ndetection, while it suffers from the well-known SNR-wall due to noise\nuncertainty. In this letter, we firstly propose a deep learning based signal\ndetector which exploits the underlying structural information of the modulated\nsignals, and is shown to achieve the state of the art detection performance,\nrequiring no prior knowledge about channel state information or background\nnoise. In addition, the impacts of modulation scheme and sample length on\nperformance are investigated. Finally, a deep learning based cooperative\ndetection system is proposed, which is shown to provide substantial performance\ngain over conventional cooperative sensing methods.",
    "published": "2019-09-06T06:18:23Z",
    "pdf_url": "http://arxiv.org/pdf/1909.02730v1",
    "categories": [
      "cs.IT",
      "eess.SP",
      "math.IT"
    ]
  },
  {
    "arxiv_id": "2002.12790v1",
    "title": "Entanglement-based quantum deep learning",
    "authors": [
      "Zhenwei Yang",
      "Xiangdong Zhang"
    ],
    "abstract": "Classical deep learning algorithms have aroused great interest in both\nacademia and industry for their utility in image recognition, language\ntranslation, decision-making problems and more. In this work, we have provided\na quantum deep learning scheme based on multi-qubit entanglement states,\nincluding computation and training of neural network in full quantum process.\nIn the course of training, efficient calculation of the distance between\nunknown unit vector and known unit vector has been realized by proper\nmeasurement based on the Greenberger-Horne-Zeilinger entanglement states. An\nexponential speedup over classical algorithms has been demonstrated. In the\nprocess of computation, quantum scheme corresponding to multi-layer feedforward\nneural network has been provided. We have shown the utility of our scheme using\nIris dataset. The extensibility of the present scheme to different types of\nmodel has also been analyzed",
    "published": "2020-02-27T09:14:00Z",
    "pdf_url": "http://arxiv.org/pdf/2002.12790v1",
    "categories": [
      "quant-ph",
      "physics.optics"
    ]
  },
  {
    "arxiv_id": "2302.08002v2",
    "title": "Deep Learning Enhanced Realized GARCH",
    "authors": [
      "Chen Liu",
      "Chao Wang",
      "Minh-Ngoc Tran",
      "Robert Kohn"
    ],
    "abstract": "We propose a new approach to volatility modeling by combining deep learning\n(LSTM) and realized volatility measures. This LSTM-enhanced realized GARCH\nframework incorporates and distills modeling advances from financial\neconometrics, high frequency trading data and deep learning. Bayesian inference\nvia the Sequential Monte Carlo method is employed for statistical inference and\nforecasting. The new framework can jointly model the returns and realized\nvolatility measures, has an excellent in-sample fit and superior predictive\nperformance compared to several benchmark models, while being able to adapt\nwell to the stylized facts in volatility. The performance of the new framework\nis tested using a wide range of metrics, from marginal likelihood, volatility\nforecasting, to tail risk forecasting and option pricing. We report on a\ncomprehensive empirical study using 31 widely traded stock indices over a time\nperiod that includes COVID-19 pandemic.",
    "published": "2023-02-16T00:20:43Z",
    "pdf_url": "http://arxiv.org/pdf/2302.08002v2",
    "categories": [
      "econ.EM",
      "cs.LG",
      "q-fin.CP"
    ]
  },
  {
    "arxiv_id": "2403.11958v1",
    "title": "Language Evolution with Deep Learning",
    "authors": [
      "Mathieu Rita",
      "Paul Michel",
      "Rahma Chaabouni",
      "Olivier Pietquin",
      "Emmanuel Dupoux",
      "Florian Strub"
    ],
    "abstract": "Computational modeling plays an essential role in the study of language\nemergence. It aims to simulate the conditions and learning processes that could\ntrigger the emergence of a structured language within a simulated controlled\nenvironment. Several methods have been used to investigate the origin of our\nlanguage, including agent-based systems, Bayesian agents, genetic algorithms,\nand rule-based systems. This chapter explores another class of computational\nmodels that have recently revolutionized the field of machine learning: deep\nlearning models. The chapter introduces the basic concepts of deep and\nreinforcement learning methods and summarizes their helpfulness for simulating\nlanguage emergence. It also discusses the key findings, limitations, and recent\nattempts to build realistic simulations. This chapter targets linguists and\ncognitive scientists seeking an introduction to deep learning as a tool to\ninvestigate language evolution.",
    "published": "2024-03-18T16:52:54Z",
    "pdf_url": "http://arxiv.org/pdf/2403.11958v1",
    "categories": [
      "cs.CL",
      "cs.MA"
    ]
  },
  {
    "arxiv_id": "2506.02796v1",
    "title": "Deep Learning Enhanced Multivariate GARCH",
    "authors": [
      "Haoyuan Wang",
      "Chen Liu",
      "Minh-Ngoc Tran",
      "Chao Wang"
    ],
    "abstract": "This paper introduces a novel multivariate volatility modeling framework,\nnamed Long Short-Term Memory enhanced BEKK (LSTM-BEKK), that integrates deep\nlearning into multivariate GARCH processes. By combining the flexibility of\nrecurrent neural networks with the econometric structure of BEKK models, our\napproach is designed to better capture nonlinear, dynamic, and high-dimensional\ndependence structures in financial return data. The proposed model addresses\nkey limitations of traditional multivariate GARCH-based methods, particularly\nin capturing persistent volatility clustering and asymmetric co-movement across\nassets. Leveraging the data-driven nature of LSTMs, the framework adapts\neffectively to time-varying market conditions, offering improved robustness and\nforecasting performance. Empirical results across multiple equity markets\nconfirm that the LSTM-BEKK model achieves superior performance in terms of\nout-of-sample portfolio risk forecast, while maintaining the interpretability\nfrom the BEKK models. These findings highlight the potential of hybrid\neconometric-deep learning models in advancing financial risk management and\nmultivariate volatility forecasting.",
    "published": "2025-06-03T12:22:57Z",
    "pdf_url": "http://arxiv.org/pdf/2506.02796v1",
    "categories": [
      "q-fin.CP",
      "cs.AI",
      "econ.EM"
    ]
  },
  {
    "arxiv_id": "1708.07408v1",
    "title": "Quantum fields as deep learning",
    "authors": [
      "Jae-Weon Lee"
    ],
    "abstract": "In this essay we conjecture that quantum fields such as the Higgs field is\nrelated to a restricted Boltzmann machine for deep neural networks. An\naccelerating Rindler observer in a flat spacetime sees the quantum fields\nhaving a thermal distribution from the quantum entanglement, and a\nrenormalization group process for the thermal fields on a lattice is similar to\na deep learning algorithm.\n  This correspondence can be generalized for the KMS states of quantum fields\nin a curved spacetime like a black hole.",
    "published": "2017-08-18T17:43:30Z",
    "pdf_url": "http://arxiv.org/pdf/1708.07408v1",
    "categories": [
      "physics.gen-ph",
      "hep-th"
    ]
  },
  {
    "arxiv_id": "1812.06369v2",
    "title": "Provable limitations of deep learning",
    "authors": [
      "Emmanuel Abbe",
      "Colin Sandon"
    ],
    "abstract": "As the success of deep learning reaches more grounds, one would like to also\nenvision the potential limits of deep learning. This paper gives a first set of\nresults proving that certain deep learning algorithms fail at learning certain\nefficiently learnable functions. The results put forward a notion of\ncross-predictability that characterizes when such failures take place. Parity\nfunctions provide an extreme example with a cross-predictability that decays\nexponentially, while a mere super-polynomial decay of the cross-predictability\nis shown to be sufficient to obtain failures. Examples in community detection\nand arithmetic learning are also discussed.\n  Recall that it is known that the class of neural networks (NNs) with\npolynomial network size can express any function that can be implemented in\npolynomial time, and that their sample complexity scales polynomially with the\nnetwork size. The challenge is with the optimization error (the ERM is\nNP-hard), and the success behind deep learning is to train deep NNs with\ndescent algorithms. The failures shown in this paper apply to training\npoly-size NNs on function distributions of low cross-predictability with a\ndescent algorithm that is either run with limited memory per sample or that is\ninitialized and run with enough randomness. We further claim that such types of\nconstraints are necessary to obtain failures, in that exact SGD with careful\nnon-random initialization can be shown to learn parities. The\ncross-predictability in our results plays a similar role the statistical\ndimension in statistical query (SQ) algorithms, with distinctions explained in\nthe paper. The proof techniques are based on exhibiting algorithmic constraints\nthat imply a statistical indistinguishability between the algorithm's output on\nthe test model v.s.\\ a null model, using information measures to bound the\ntotal variation distance.",
    "published": "2018-12-16T00:10:08Z",
    "pdf_url": "http://arxiv.org/pdf/1812.06369v2",
    "categories": [
      "cs.LG",
      "cs.CC",
      "cs.IT",
      "math.IT",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2009.05426v4",
    "title": "Semantic Relations and Deep Learning",
    "authors": [
      "Vivi Nastase",
      "Stan Szpakowicz"
    ],
    "abstract": "The second edition of \"Semantic Relations Between Nominals\" by Vivi Nastase,\nStan Szpakowicz, Preslav Nakov and Diarmuid \\'O S\\'eaghdha has been published\nin April 2021 by Morgan & Claypool\n(www.morganclaypoolpublishers.com/catalog_Orig/product_info.php?products_id=1627).\nA new Chapter 5 of the book, by Vivi Nastase and Stan Szpakowicz, discusses\nrelation classification/extraction in the deep-learning paradigm which arose\nafter the first edition appeared. This is Chapter 5, made public by the kind\npermission of Morgan & Claypool.",
    "published": "2020-09-11T13:21:28Z",
    "pdf_url": "http://arxiv.org/pdf/2009.05426v4",
    "categories": [
      "cs.CL",
      "I.2.7; H.3.3"
    ]
  },
  {
    "arxiv_id": "2202.12348v1",
    "title": "Bayesian Deep Learning for Graphs",
    "authors": [
      "Federico Errica"
    ],
    "abstract": "The adaptive processing of structured data is a long-standing research topic\nin machine learning that investigates how to automatically learn a mapping from\na structured input to outputs of various nature. Recently, there has been an\nincreasing interest in the adaptive processing of graphs, which led to the\ndevelopment of different neural network-based methodologies. In this thesis, we\ntake a different route and develop a Bayesian Deep Learning framework for graph\nlearning. The dissertation begins with a review of the principles over which\nmost of the methods in the field are built, followed by a study on graph\nclassification reproducibility issues. We then proceed to bridge the basic\nideas of deep learning for graphs with the Bayesian world, by building our deep\narchitectures in an incremental fashion. This framework allows us to consider\ngraphs with discrete and continuous edge features, producing unsupervised\nembeddings rich enough to reach the state of the art on several classification\ntasks. Our approach is also amenable to a Bayesian nonparametric extension that\nautomatizes the choice of almost all model's hyper-parameters. Two real-world\napplications demonstrate the efficacy of deep learning for graphs. The first\nconcerns the prediction of information-theoretic quantities for molecular\nsimulations with supervised neural models. After that, we exploit our Bayesian\nmodels to solve a malware-classification task while being robust to\nintra-procedural code obfuscation techniques. We conclude the dissertation with\nan attempt to blend the best of the neural and Bayesian worlds together. The\nresulting hybrid model is able to predict multimodal distributions conditioned\non input graphs, with the consequent ability to model stochasticity and\nuncertainty better than most works. Overall, we aim to provide a Bayesian\nperspective into the articulated research field of deep learning for graphs.",
    "published": "2022-02-24T20:18:41Z",
    "pdf_url": "http://arxiv.org/pdf/2202.12348v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1501.03084v1",
    "title": "Deep Learning with Nonparametric Clustering",
    "authors": [
      "Gang Chen"
    ],
    "abstract": "Clustering is an essential problem in machine learning and data mining. One\nvital factor that impacts clustering performance is how to learn or design the\ndata representation (or features). Fortunately, recent advances in deep\nlearning can learn unsupervised features effectively, and have yielded state of\nthe art performance in many classification problems, such as character\nrecognition, object recognition and document categorization. However, little\nattention has been paid to the potential of deep learning for unsupervised\nclustering problems. In this paper, we propose a deep belief network with\nnonparametric clustering. As an unsupervised method, our model first leverages\nthe advantages of deep learning for feature representation and dimension\nreduction. Then, it performs nonparametric clustering under a maximum margin\nframework -- a discriminative clustering model and can be trained online\nefficiently in the code space. Lastly model parameters are refined in the deep\nbelief network. Thus, this model can learn features for clustering and infer\nmodel complexity in an unified framework. The experimental results show the\nadvantage of our approach over competitive baselines.",
    "published": "2015-01-13T17:26:26Z",
    "pdf_url": "http://arxiv.org/pdf/1501.03084v1",
    "categories": [
      "cs.LG",
      "68T10",
      "I.2.6"
    ]
  },
  {
    "arxiv_id": "1809.10410v1",
    "title": "Image Reconstruction Using Deep Learning",
    "authors": [
      "Po-Yu Liu",
      "Edmund Y. Lam"
    ],
    "abstract": "This paper proposes a deep learning architecture that attains statistically\nsignificant improvements over traditional algorithms in Poisson image denoising\nespically when the noise is strong. Poisson noise commonly occurs in low-light\nand photon- limited settings, where the noise can be most accurately modeled by\nthe Poission distribution. Poisson noise traditionally prevails only in\nspecific fields such as astronomical imaging. However, with the booming market\nof surveillance cameras, which commonly operate in low-light environments, or\nmobile phones, which produce noisy night scene pictures due to lower-grade\nsensors, the necessity for an advanced Poisson image denoising algorithm has\nincreased. Deep learning has achieved amazing breakthroughs in other imaging\nproblems, such image segmentation and recognition, and this paper proposes a\ndeep learning denoising network that outperforms traditional algorithms in\nPoisson denoising especially when the noise is strong. The architecture\nincorporates a hybrid of convolutional and deconvolutional layers along with\nsymmetric connections. The denoising network achieved statistically significant\n0.38dB, 0.68dB, and 1.04dB average PSNR gains over benchmark traditional\nalgorithms in experiments with image peak values 4, 2, and 1. The denoising\nnetwork can also operate with shorter computational time while still\noutperforming the benchmark algorithm by tuning the reconstruction stride\nsizes.",
    "published": "2018-09-27T08:58:38Z",
    "pdf_url": "http://arxiv.org/pdf/1809.10410v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2005.06540v1",
    "title": "Deep Learning for Political Science",
    "authors": [
      "Kakia Chatsiou",
      "Slava Jankin Mikhaylov"
    ],
    "abstract": "Political science, and social science in general, have traditionally been\nusing computational methods to study areas such as voting behavior, policy\nmaking, international conflict, and international development. More recently,\nincreasingly available quantities of data are being combined with improved\nalgorithms and affordable computational resources to predict, learn, and\ndiscover new insights from data that is large in volume and variety. New\ndevelopments in the areas of machine learning, deep learning, natural language\nprocessing (NLP), and, more generally, artificial intelligence (AI) are opening\nup new opportunities for testing theories and evaluating the impact of\ninterventions and programs in a more dynamic and effective way. Applications\nusing large volumes of structured and unstructured data are becoming common in\ngovernment and industry, and increasingly also in social science research. This\nchapter offers an introduction to such methods drawing examples from political\nscience. Focusing on the areas where the strengths of the methods coincide with\nchallenges in these fields, the chapter first presents an introduction to AI\nand its core technology - machine learning, with its rapidly developing\nsubfield of deep learning. The discussion of deep neural networks is\nillustrated with the NLP tasks that are relevant to political science. The\nlatest advances in deep learning methods for NLP are also reviewed, together\nwith their potential for improving information extraction and pattern\nrecognition from political science texts.",
    "published": "2020-05-13T19:14:37Z",
    "pdf_url": "http://arxiv.org/pdf/2005.06540v1",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2202.14005v2",
    "title": "Deep, Deep Learning with BART",
    "authors": [
      "Moritz Blumenthal",
      "Guanxiong Luo",
      "Martin Schilling",
      "H. Christian M. Holme",
      "Martin Uecker"
    ],
    "abstract": "Purpose: To develop a deep-learning-based image reconstruction framework for\nreproducible research in MRI.\n  Methods: The BART toolbox offers a rich set of implementations of calibration\nand reconstruction algorithms for parallel imaging and compressed sensing. In\nthis work, BART was extended by a non-linear operator framework that provides\nautomatic differentiation to allow computation of gradients. Existing\nMRI-specific operators of BART, such as the non-uniform fast Fourier transform,\nare directly integrated into this framework and are complemented by common\nbuilding blocks used in neural networks. To evaluate the use of the framework\nfor advanced deep-learning-based reconstruction, two state-of-the-art unrolled\nreconstruction networks, namely the Variational Network [1] and MoDL [2], were\nimplemented.\n  Results: State-of-the-art deep image-reconstruction networks can be\nconstructed and trained using BART's gradient based optimization algorithms.\nThe BART implementation achieves a similar performance in terms of training\ntime and reconstruction quality compared to the original implementations based\non TensorFlow.\n  Conclusion: By integrating non-linear operators and neural networks into\nBART, we provide a general framework for deep-learning-based reconstruction in\nMRI.",
    "published": "2022-02-28T18:23:41Z",
    "pdf_url": "http://arxiv.org/pdf/2202.14005v2",
    "categories": [
      "cs.CV",
      "eess.SP"
    ]
  },
  {
    "arxiv_id": "1910.14215v2",
    "title": "Multivariate Uncertainty in Deep Learning",
    "authors": [
      "Rebecca L. Russell",
      "Christopher Reale"
    ],
    "abstract": "Deep learning has the potential to dramatically impact navigation and\ntracking state estimation problems critical to autonomous vehicles and\nrobotics. Measurement uncertainties in state estimation systems based on Kalman\nand other Bayes filters are typically assumed to be a fixed covariance matrix.\nThis assumption is risky, particularly for \"black box\" deep learning models, in\nwhich uncertainty can vary dramatically and unexpectedly. Accurate\nquantification of multivariate uncertainty will allow for the full potential of\ndeep learning to be used more safely and reliably in these applications. We\nshow how to model multivariate uncertainty for regression problems with neural\nnetworks, incorporating both aleatoric and epistemic sources of heteroscedastic\nuncertainty. We train a deep uncertainty covariance matrix model in two ways:\ndirectly using a multivariate Gaussian density loss function, and indirectly\nusing end-to-end training through a Kalman filter. We experimentally show in a\nvisual tracking problem the large impact that accurate multivariate uncertainty\nquantification can have on Kalman filter performance for both in-domain and\nout-of-domain evaluation data. We additionally show in a challenging visual\nodometry problem how end-to-end filter training can allow uncertainty\npredictions to compensate for filter weaknesses.",
    "published": "2019-10-31T02:25:16Z",
    "pdf_url": "http://arxiv.org/pdf/1910.14215v2",
    "categories": [
      "cs.LG",
      "cs.NE",
      "cs.RO",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2012.04115v2",
    "title": "Generalization bounds for deep learning",
    "authors": [
      "Guillermo Valle-Pérez",
      "Ard A. Louis"
    ],
    "abstract": "Generalization in deep learning has been the topic of much recent theoretical\nand empirical research. Here we introduce desiderata for techniques that\npredict generalization errors for deep learning models in supervised learning.\nSuch predictions should 1) scale correctly with data complexity; 2) scale\ncorrectly with training set size; 3) capture differences between architectures;\n4) capture differences between optimization algorithms; 5) be quantitatively\nnot too far from the true error (in particular, be non-vacuous); 6) be\nefficiently computable; and 7) be rigorous. We focus on generalization error\nupper bounds, and introduce a categorisation of bounds depending on assumptions\non the algorithm and data. We review a wide range of existing approaches, from\nclassical VC dimension to recent PAC-Bayesian bounds, commenting on how well\nthey perform against the desiderata.\n  We next use a function-based picture to derive a marginal-likelihood\nPAC-Bayesian bound. This bound is, by one definition, optimal up to a\nmultiplicative constant in the asymptotic limit of large training sets, as long\nas the learning curve follows a power law, which is typically found in practice\nfor deep learning problems. Extensive empirical analysis demonstrates that our\nmarginal-likelihood PAC-Bayes bound fulfills desiderata 1-3 and 5. The results\nfor 6 and 7 are promising, but not yet fully conclusive, while only desideratum\n4 is currently beyond the scope of our bound. Finally, we comment on why this\nfunction-based bound performs significantly better than current parameter-based\nPAC-Bayes bounds.",
    "published": "2020-12-07T23:45:09Z",
    "pdf_url": "http://arxiv.org/pdf/2012.04115v2",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "2211.14395v1",
    "title": "Deep Learning Training Procedure Augmentations",
    "authors": [
      "Cristian Simionescu"
    ],
    "abstract": "Recent advances in Deep Learning have greatly improved performance on various\ntasks such as object detection, image segmentation, sentiment analysis. The\nfocus of most research directions up until very recently has been on beating\nstate-of-the-art results. This has materialized in the utilization of bigger\nand bigger models and techniques which help the training procedure to extract\nmore predictive power out of a given dataset. While this has lead to great\nresults, many of which with real-world applications, other relevant aspects of\ndeep learning have remained neglected and unknown. In this work, we will\npresent several novel deep learning training techniques which, while capable of\noffering significant performance gains they also reveal several interesting\nanalysis results regarding convergence speed, optimization landscape\nsmoothness, and adversarial robustness. The methods presented in this work are\nthe following:\n  $\\bullet$ Perfect Ordering Approximation; a generalized model agnostic\ncurriculum learning approach. The results show the effectiveness of the\ntechnique for improving training time as well as offer some new insight into\nthe training process of deep networks.\n  $\\bullet$ Cascading Sum Augmentation; an extension of mixup capable of\nutilizing more data points for linear interpolation by leveraging a smoother\noptimization landscape. This can be used for computer vision tasks in order to\nimprove both prediction performance as well as improve passive model\nrobustness.",
    "published": "2022-11-25T22:31:11Z",
    "pdf_url": "http://arxiv.org/pdf/2211.14395v1",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2504.05355v2",
    "title": "Deep Learning for Double Auction",
    "authors": [
      "Jiayin Liu",
      "Chenglong Zhang"
    ],
    "abstract": "Auctions are important mechanisms extensively implemented in various markets,\ne.g., search engines' keyword auctions, antique auctions, etc. Finding an\noptimal auction mechanism is extremely difficult due to the constraints of\nimperfect information, incentive compatibility (IC), and individual rationality\n(IR). In addition to the traditional economic methods, some recently attempted\nto find the optimal (single) auction using deep learning methods. Unlike those\nattempts focusing on single auctions, we develop deep learning methods for\ndouble auctions, where imperfect information exists on both the demand and\nsupply sides. The previous attempts on single auction cannot directly apply to\nour contexts and those attempts additionally suffer from limited\ngeneralizability, inefficiency in ensuring the constraints, and learning\nfluctuations. We innovate in designing deep learning models for solving the\nmore complex problem and additionally addressing the previous models' three\nlimitations. Specifically, we achieve generalizability by leveraging a\ntransformer-based architecture to model market participants as sequences for\nvarying market sizes; we utilize the numerical features of the constraints and\npre-treat them for a higher learning efficiency; we develop a\ngradient-conflict-elimination scheme to address the problem of learning\nfluctuation. Extensive experimental evaluations demonstrate the superiority of\nour approach to classical and machine learning baselines.",
    "published": "2025-04-07T08:56:32Z",
    "pdf_url": "http://arxiv.org/pdf/2504.05355v2",
    "categories": [
      "cs.LG",
      "cs.GT",
      "econ.TH"
    ]
  },
  {
    "arxiv_id": "2507.13399v1",
    "title": "Selective Embedding for Deep Learning",
    "authors": [
      "Mert Sehri",
      "Zehui Hua",
      "Francisco de Assis Boldt",
      "Patrick Dumond"
    ],
    "abstract": "Deep learning has revolutionized many industries by enabling models to\nautomatically learn complex patterns from raw data, reducing dependence on\nmanual feature engineering. However, deep learning algorithms are sensitive to\ninput data, and performance often deteriorates under nonstationary conditions\nand across dissimilar domains, especially when using time-domain data.\nConventional single-channel or parallel multi-source data loading strategies\neither limit generalization or increase computational costs. This study\nintroduces selective embedding, a novel data loading strategy, which alternates\nshort segments of data from multiple sources within a single input channel.\nDrawing inspiration from cognitive psychology, selective embedding mimics\nhuman-like information processing to reduce model overfitting, enhance\ngeneralization, and improve computational efficiency. Validation is conducted\nusing six time-domain datasets, demonstrating that the proposed method\nconsistently achieves high classification accuracy across various deep learning\narchitectures while significantly reducing training times. The approach proves\nparticularly effective for complex systems with multiple data sources, offering\na scalable and resource-efficient solution for real-world applications in\nhealthcare, heavy machinery, marine, railway, and agriculture, where robustness\nand adaptability are critical.",
    "published": "2025-07-16T15:45:01Z",
    "pdf_url": "http://arxiv.org/pdf/2507.13399v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1805.08355v1",
    "title": "Opening the black box of deep learning",
    "authors": [
      "Dian Lei",
      "Xiaoxiao Chen",
      "Jianfei Zhao"
    ],
    "abstract": "The great success of deep learning shows that its technology contains\nprofound truth, and understanding its internal mechanism not only has important\nimplications for the development of its technology and effective application in\nvarious fields, but also provides meaningful insights into the understanding of\nhuman brain mechanism. At present, most of the theoretical research on deep\nlearning is based on mathematics. This dissertation proposes that the neural\nnetwork of deep learning is a physical system, examines deep learning from\nthree different perspectives: microscopic, macroscopic, and physical world\nviews, answers multiple theoretical puzzles in deep learning by using physics\nprinciples. For example, from the perspective of quantum mechanics and\nstatistical physics, this dissertation presents the calculation methods for\nconvolution calculation, pooling, normalization, and Restricted Boltzmann\nMachine, as well as the selection of cost functions, explains why deep learning\nmust be deep, what characteristics are learned in deep learning, why\nConvolutional Neural Networks do not have to be trained layer by layer, and the\nlimitations of deep learning, etc., and proposes the theoretical direction and\nbasis for the further development of deep learning now and in the future. The\nbrilliance of physics flashes in deep learning, we try to establish the deep\nlearning technology based on the scientific theory of physics.",
    "published": "2018-05-22T02:12:33Z",
    "pdf_url": "http://arxiv.org/pdf/1805.08355v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1711.11008v1",
    "title": "Security Risks in Deep Learning Implementations",
    "authors": [
      "Qixue Xiao",
      "Kang Li",
      "Deyue Zhang",
      "Weilin Xu"
    ],
    "abstract": "Advance in deep learning algorithms overshadows their security risk in\nsoftware implementations. This paper discloses a set of vulnerabilities in\npopular deep learning frameworks including Caffe, TensorFlow, and Torch.\nContrast to the small code size of deep learning models, these deep learning\nframeworks are complex and contain heavy dependencies on numerous open source\npackages. This paper considers the risks caused by these vulnerabilities by\nstudying their impact on common deep learning applications such as voice\nrecognition and image classifications. By exploiting these framework\nimplementations, attackers can launch denial-of-service attacks that crash or\nhang a deep learning application, or control-flow hijacking attacks that cause\neither system compromise or recognition evasions. The goal of this paper is to\ndraw attention on the software implementations and call for the community\neffort to improve the security of deep learning frameworks.",
    "published": "2017-11-29T18:33:27Z",
    "pdf_url": "http://arxiv.org/pdf/1711.11008v1",
    "categories": [
      "cs.CR"
    ]
  },
  {
    "arxiv_id": "1908.08843v2",
    "title": "Fairness in Deep Learning: A Computational Perspective",
    "authors": [
      "Mengnan Du",
      "Fan Yang",
      "Na Zou",
      "Xia Hu"
    ],
    "abstract": "Deep learning is increasingly being used in high-stake decision making\napplications that affect individual lives. However, deep learning models might\nexhibit algorithmic discrimination behaviors with respect to protected groups,\npotentially posing negative impacts on individuals and society. Therefore,\nfairness in deep learning has attracted tremendous attention recently. We\nprovide a review covering recent progresses to tackle algorithmic fairness\nproblems of deep learning from the computational perspective. Specifically, we\nshow that interpretability can serve as a useful ingredient to diagnose the\nreasons that lead to algorithmic discrimination. We also discuss fairness\nmitigation approaches categorized according to three stages of deep learning\nlife-cycle, aiming to push forward the area of fairness in deep learning and\nbuild genuinely fair and reliable deep learning systems.",
    "published": "2019-08-23T14:38:07Z",
    "pdf_url": "http://arxiv.org/pdf/1908.08843v2",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2103.09177v1",
    "title": "Deep learning: a statistical viewpoint",
    "authors": [
      "Peter L. Bartlett",
      "Andrea Montanari",
      "Alexander Rakhlin"
    ],
    "abstract": "The remarkable practical success of deep learning has revealed some major\nsurprises from a theoretical perspective. In particular, simple gradient\nmethods easily find near-optimal solutions to non-convex optimization problems,\nand despite giving a near-perfect fit to training data without any explicit\neffort to control model complexity, these methods exhibit excellent predictive\naccuracy. We conjecture that specific principles underlie these phenomena: that\noverparametrization allows gradient methods to find interpolating solutions,\nthat these methods implicitly impose regularization, and that\noverparametrization leads to benign overfitting. We survey recent theoretical\nprogress that provides examples illustrating these principles in simpler\nsettings. We first review classical uniform convergence results and why they\nfall short of explaining aspects of the behavior of deep learning methods. We\ngive examples of implicit regularization in simple settings, where gradient\nmethods lead to minimal norm functions that perfectly fit the training data.\nThen we review prediction methods that exhibit benign overfitting, focusing on\nregression problems with quadratic loss. For these methods, we can decompose\nthe prediction rule into a simple component that is useful for prediction and a\nspiky component that is useful for overfitting but, in a favorable setting,\ndoes not harm prediction accuracy. We focus specifically on the linear regime\nfor neural networks, where the network can be approximated by a linear model.\nIn this regime, we demonstrate the success of gradient flow, and we consider\nbenign overfitting with two-layer networks, giving an exact asymptotic analysis\nthat precisely demonstrates the impact of overparametrization. We conclude by\nhighlighting the key challenges that arise in extending these insights to\nrealistic deep learning settings.",
    "published": "2021-03-16T16:26:36Z",
    "pdf_url": "http://arxiv.org/pdf/2103.09177v1",
    "categories": [
      "math.ST",
      "cs.LG",
      "stat.ML",
      "stat.TH"
    ]
  },
  {
    "arxiv_id": "1306.0543v2",
    "title": "Predicting Parameters in Deep Learning",
    "authors": [
      "Misha Denil",
      "Babak Shakibi",
      "Laurent Dinh",
      "Marc'Aurelio Ranzato",
      "Nando de Freitas"
    ],
    "abstract": "We demonstrate that there is significant redundancy in the parameterization\nof several deep learning models. Given only a few weight values for each\nfeature it is possible to accurately predict the remaining values. Moreover, we\nshow that not only can the parameter values be predicted, but many of them need\nnot be learned at all. We train several different architectures by learning\nonly a small number of weights and predicting the rest. In the best case we are\nable to predict more than 95% of the weights of a network without any drop in\naccuracy.",
    "published": "2013-06-03T19:16:26Z",
    "pdf_url": "http://arxiv.org/pdf/1306.0543v2",
    "categories": [
      "cs.LG",
      "cs.NE",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1705.10342v1",
    "title": "Deep Learning for Ontology Reasoning",
    "authors": [
      "Patrick Hohenecker",
      "Thomas Lukasiewicz"
    ],
    "abstract": "In this work, we present a novel approach to ontology reasoning that is based\non deep learning rather than logic-based formal reasoning. To this end, we\nintroduce a new model for statistical relational learning that is built upon\ndeep recursive neural networks, and give experimental evidence that it can\neasily compete with, or even outperform, existing logic-based reasoners on the\ntask of ontology reasoning. More precisely, we compared our implemented system\nwith one of the best logic-based ontology reasoners at present, RDFox, on a\nnumber of large standard benchmark datasets, and found that our system attained\nhigh reasoning quality, while being up to two orders of magnitude faster.",
    "published": "2017-05-29T18:17:52Z",
    "pdf_url": "http://arxiv.org/pdf/1705.10342v1",
    "categories": [
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1808.01174v3",
    "title": "Generalization Error in Deep Learning",
    "authors": [
      "Daniel Jakubovitz",
      "Raja Giryes",
      "Miguel R. D. Rodrigues"
    ],
    "abstract": "Deep learning models have lately shown great performance in various fields\nsuch as computer vision, speech recognition, speech translation, and natural\nlanguage processing. However, alongside their state-of-the-art performance, it\nis still generally unclear what is the source of their generalization ability.\nThus, an important question is what makes deep neural networks able to\ngeneralize well from the training set to new data. In this article, we provide\nan overview of the existing theory and bounds for the characterization of the\ngeneralization error of deep neural networks, combining both classical and more\nrecent theoretical and empirical results.",
    "published": "2018-08-03T12:57:12Z",
    "pdf_url": "http://arxiv.org/pdf/1808.01174v3",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1812.01478v1",
    "title": "Matrix Factorization via Deep Learning",
    "authors": [
      "Duc Minh Nguyen",
      "Evaggelia Tsiligianni",
      "Nikos Deligiannis"
    ],
    "abstract": "Matrix completion is one of the key problems in signal processing and machine\nlearning. In recent years, deep-learning-based models have achieved\nstate-of-the-art results in matrix completion. Nevertheless, they suffer from\ntwo drawbacks: (i) they can not be extended easily to rows or columns unseen\nduring training; and (ii) their results are often degraded in case discrete\npredictions are required. This paper addresses these two drawbacks by\npresenting a deep matrix factorization model and a generic method to allow\njoint training of the factorization model and the discretization operator.\nExperiments on a real movie rating dataset show the efficacy of the proposed\nmodels.",
    "published": "2018-12-04T15:15:23Z",
    "pdf_url": "http://arxiv.org/pdf/1812.01478v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1908.07017v1",
    "title": "Optical deep learning nano-profilometry",
    "authors": [
      "Jinlong Zhu",
      "Yanan Liu",
      "Sanyogita Purandare",
      "Jian-Ming Jin",
      "Shiyuan Liu",
      "Lynford L. Goddard"
    ],
    "abstract": "Determining the dimensions of nanostructures is critical to ensuring the\nmaximum performance of many geometry-sensitive nanoscale functional devices.\nHowever, accurate metrology at the nanoscale is difficult using optics-based\nmethods due to the diffraction limit. In this article, we propose an optical\nnano-profilometry framework with convolutional neural networks, which can\nretrieve deep sub-wavelength geometrical profiles of nanostructures from their\noptical images or scattering spectra. The generality, efficiency, and accuracy\nof the proposed framework are validated by performing two different\nmeasurements on three distinct nanostructures. We believe this work may\ncatalyze more explorations of optics-based nano-metrology with deep learning.",
    "published": "2019-07-24T20:15:08Z",
    "pdf_url": "http://arxiv.org/pdf/1908.07017v1",
    "categories": [
      "physics.app-ph",
      "physics.optics",
      "83C50, 78A45, 78A46"
    ]
  },
  {
    "arxiv_id": "2006.02734v2",
    "title": "Robust Sampling in Deep Learning",
    "authors": [
      "Aurora Cobo Aguilera",
      "Antonio Artés-Rodríguez",
      "Fernando Pérez-Cruz",
      "Pablo Martínez Olmos"
    ],
    "abstract": "Deep learning requires regularization mechanisms to reduce overfitting and\nimprove generalization. We address this problem by a new regularization method\nbased on distributional robust optimization. The key idea is to modify the\ncontribution from each sample for tightening the empirical risk bound. During\nthe stochastic training, the selection of samples is done according to their\naccuracy in such a way that the worst performed samples are the ones that\ncontribute the most in the optimization. We study different scenarios and show\nthe ones where it can make the convergence faster or increase the accuracy.",
    "published": "2020-06-04T09:46:52Z",
    "pdf_url": "http://arxiv.org/pdf/2006.02734v2",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1910.06789v1",
    "title": "Deep learning for Aerosol Forecasting",
    "authors": [
      "Caleb Hoyne",
      "S. Karthik Mukkavilli",
      "David Meger"
    ],
    "abstract": "Reanalysis datasets combining numerical physics models and limited\nobservations to generate a synthesised estimate of variables in an Earth\nsystem, are prone to biases against ground truth. Biases identified with the\nNASA Modern-Era Retrospective Analysis for Research and Applications, Version 2\n(MERRA-2) aerosol optical depth (AOD) dataset, against the Aerosol Robotic\nNetwork (AERONET) ground measurements in previous studies, motivated the\ndevelopment of a deep learning based AOD prediction model globally. This study\ncombines a convolutional neural network (CNN) with MERRA-2, tested against all\nAERONET sites. The new hybrid CNN-based model provides better estimates\nvalidated versus AERONET ground truth, than only using MERRA-2 reanalysis.",
    "published": "2019-10-14T17:35:08Z",
    "pdf_url": "http://arxiv.org/pdf/1910.06789v1",
    "categories": [
      "cs.LG",
      "cs.CV",
      "physics.ao-ph",
      "physics.data-an",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2002.11835v1",
    "title": "Tensor Decompositions in Deep Learning",
    "authors": [
      "Davide Bacciu",
      "Danilo P. Mandic"
    ],
    "abstract": "The paper surveys the topic of tensor decompositions in modern machine\nlearning applications. It focuses on three active research topics of\nsignificant relevance for the community. After a brief review of consolidated\nworks on multi-way data analysis, we consider the use of tensor decompositions\nin compressing the parameter space of deep learning models. Lastly, we discuss\nhow tensor methods can be leveraged to yield richer adaptive representations of\ncomplex data, including structured information. The paper concludes with a\ndiscussion on interesting open research challenges.",
    "published": "2020-02-26T23:07:19Z",
    "pdf_url": "http://arxiv.org/pdf/2002.11835v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1806.07908v1",
    "title": "Como funciona o Deep Learning",
    "authors": [
      "Moacir Antonelli Ponti",
      "Gabriel B. Paranhos da Costa"
    ],
    "abstract": "Deep Learning methods are currently the state-of-the-art in many problems\nwhich can be tackled via machine learning, in particular classification\nproblems. However there is still lack of understanding on how those methods\nwork, why they work and what are the limitations involved in using them. In\nthis chapter we will describe in detail the transition from shallow to deep\nnetworks, include examples of code on how to implement them, as well as the\nmain issues one faces when training a deep network. Afterwards, we introduce\nsome theoretical background behind the use of deep models, and discuss their\nlimitations.",
    "published": "2018-06-20T18:04:09Z",
    "pdf_url": "http://arxiv.org/pdf/1806.07908v1",
    "categories": [
      "cs.LG",
      "cs.CV",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2201.01869v1",
    "title": "Earthquake Nowcasting with Deep Learning",
    "authors": [
      "Geoffrey Fox",
      "John Rundle",
      "Andrea Donnellan",
      "Bo Feng"
    ],
    "abstract": "We review previous approaches to nowcasting earthquakes and introduce new\napproaches based on deep learning using three distinct models based on\nrecurrent neural networks and transformers. We discuss different choices for\nobservables and measures presenting promising initial results for a region of\nSouthern California from 1950-2020. Earthquake activity is predicted as a\nfunction of 0.1-degree spatial bins for time periods varying from two weeks to\nfour years. The overall quality is measured by the Nash Sutcliffe Efficiency\ncomparing the deviation of nowcast and observation with the variance over time\nin each spatial region. The software is available as open-source together with\nthe preprocessed data from the USGS.",
    "published": "2021-12-18T16:55:59Z",
    "pdf_url": "http://arxiv.org/pdf/2201.01869v1",
    "categories": [
      "physics.geo-ph",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2303.15464v1",
    "title": "Mathematical Challenges in Deep Learning",
    "authors": [
      "Vahid Partovi Nia",
      "Guojun Zhang",
      "Ivan Kobyzev",
      "Michael R. Metel",
      "Xinlin Li",
      "Ke Sun",
      "Sobhan Hemati",
      "Masoud Asgharian",
      "Linglong Kong",
      "Wulong Liu",
      "Boxing Chen"
    ],
    "abstract": "Deep models are dominating the artificial intelligence (AI) industry since\nthe ImageNet challenge in 2012. The size of deep models is increasing ever\nsince, which brings new challenges to this field with applications in cell\nphones, personal computers, autonomous cars, and wireless base stations. Here\nwe list a set of problems, ranging from training, inference, generalization\nbound, and optimization with some formalism to communicate these challenges\nwith mathematicians, statisticians, and theoretical computer scientists. This\nis a subjective view of the research questions in deep learning that benefits\nthe tech industry in long run.",
    "published": "2023-03-24T20:12:27Z",
    "pdf_url": "http://arxiv.org/pdf/2303.15464v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ]
  },
  {
    "arxiv_id": "1605.01369v2",
    "title": "Accelerating Deep Learning with Shrinkage and Recall",
    "authors": [
      "Shuai Zheng",
      "Abhinav Vishnu",
      "Chris Ding"
    ],
    "abstract": "Deep Learning is a very powerful machine learning model. Deep Learning trains\na large number of parameters for multiple layers and is very slow when data is\nin large scale and the architecture size is large. Inspired from the shrinking\ntechnique used in accelerating computation of Support Vector Machines (SVM)\nalgorithm and screening technique used in LASSO, we propose a shrinking Deep\nLearning with recall (sDLr) approach to speed up deep learning computation. We\nexperiment shrinking Deep Learning with recall (sDLr) using Deep Neural Network\n(DNN), Deep Belief Network (DBN) and Convolution Neural Network (CNN) on 4 data\nsets. Results show that the speedup using shrinking Deep Learning with recall\n(sDLr) can reach more than 2.0 while still giving competitive classification\nperformance.",
    "published": "2016-05-04T18:17:37Z",
    "pdf_url": "http://arxiv.org/pdf/1605.01369v2",
    "categories": [
      "cs.LG",
      "cs.CV",
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "1908.10206v1",
    "title": "The many faces of deep learning",
    "authors": [
      "Raul Vicente"
    ],
    "abstract": "Deep learning has sparked a network of mutual interactions between different\ndisciplines and AI. Naturally, each discipline focuses and interprets the\nworkings of deep learning in different ways. This diversity of perspectives on\ndeep learning, from neuroscience to statistical physics, is a rich source of\ninspiration that fuels novel developments in the theory and applications of\nmachine learning. In this perspective, we collect and synthesize different\nintuitions scattered across several communities as for how deep learning works.\nIn particular, we will briefly discuss the different perspectives that\ndisciplines across mathematics, physics, computation, and neuroscience take on\nhow deep learning does its tricks. Our discussion on each perspective is\nnecessarily shallow due to the multiple views that had to be covered. The\ndeepness in this case should come from putting all these faces of deep learning\ntogether in the reader's mind, so that one can look at the same problem from\ndifferent angles.",
    "published": "2019-08-25T12:04:49Z",
    "pdf_url": "http://arxiv.org/pdf/1908.10206v1",
    "categories": [
      "cs.LG",
      "physics.data-an",
      "q-bio.NC",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1807.08169v1",
    "title": "Recent Advances in Deep Learning: An Overview",
    "authors": [
      "Matiur Rahman Minar",
      "Jibon Naher"
    ],
    "abstract": "Deep Learning is one of the newest trends in Machine Learning and Artificial\nIntelligence research. It is also one of the most popular scientific research\ntrends now-a-days. Deep learning methods have brought revolutionary advances in\ncomputer vision and machine learning. Every now and then, new and new deep\nlearning techniques are being born, outperforming state-of-the-art machine\nlearning and even existing deep learning techniques. In recent years, the world\nhas seen many major breakthroughs in this field. Since deep learning is\nevolving at a huge speed, its kind of hard to keep track of the regular\nadvances especially for new researchers. In this paper, we are going to briefly\ndiscuss about recent advances in Deep Learning for past few years.",
    "published": "2018-07-21T15:40:10Z",
    "pdf_url": "http://arxiv.org/pdf/1807.08169v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2010.05125v2",
    "title": "Learning Task-aware Robust Deep Learning Systems",
    "authors": [
      "Keji Han",
      "Yun Li",
      "Xianzhong Long",
      "Yao Ge"
    ],
    "abstract": "Many works demonstrate that deep learning system is vulnerable to adversarial\nattack. A deep learning system consists of two parts: the deep learning task\nand the deep model. Nowadays, most existing works investigate the impact of the\ndeep model on robustness of deep learning systems, ignoring the impact of the\nlearning task. In this paper, we adopt the binary and interval label encoding\nstrategy to redefine the classification task and design corresponding loss to\nimprove robustness of the deep learning system. Our method can be viewed as\nimproving the robustness of deep learning systems from both the learning task\nand deep model. Experimental results demonstrate that our learning task-aware\nmethod is much more robust than traditional classification while retaining the\naccuracy.",
    "published": "2020-10-11T01:06:49Z",
    "pdf_url": "http://arxiv.org/pdf/2010.05125v2",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2204.01942v1",
    "title": "Fault-Tolerant Deep Learning: A Hierarchical Perspective",
    "authors": [
      "Cheng Liu",
      "Zhen Gao",
      "Siting Liu",
      "Xuefei Ning",
      "Huawei Li",
      "Xiaowei Li"
    ],
    "abstract": "With the rapid advancements of deep learning in the past decade, it can be\nforeseen that deep learning will be continuously deployed in more and more\nsafety-critical applications such as autonomous driving and robotics. In this\ncontext, reliability turns out to be critical to the deployment of deep\nlearning in these applications and gradually becomes a first-class citizen\namong the major design metrics like performance and energy efficiency.\nNevertheless, the back-box deep learning models combined with the diverse\nunderlying hardware faults make resilient deep learning extremely challenging.\nIn this special session, we conduct a comprehensive survey of fault-tolerant\ndeep learning design approaches with a hierarchical perspective and investigate\nthese approaches from model layer, architecture layer, circuit layer, and cross\nlayer respectively.",
    "published": "2022-04-05T02:31:18Z",
    "pdf_url": "http://arxiv.org/pdf/2204.01942v1",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG",
      "B.2.3; B.8.1"
    ]
  },
  {
    "arxiv_id": "2210.05866v1",
    "title": "Deep Learning for Iris Recognition: A Survey",
    "authors": [
      "Kien Nguyen",
      "Hugo Proença",
      "Fernando Alonso-Fernandez"
    ],
    "abstract": "In this survey, we provide a comprehensive review of more than 200 papers,\ntechnical reports, and GitHub repositories published over the last 10 years on\nthe recent developments of deep learning techniques for iris recognition,\ncovering broad topics on algorithm designs, open-source tools, open challenges,\nand emerging research. First, we conduct a comprehensive analysis of deep\nlearning techniques developed for two main sub-tasks in iris biometrics:\nsegmentation and recognition. Second, we focus on deep learning techniques for\nthe robustness of iris recognition systems against presentation attacks and via\nhuman-machine pairing. Third, we delve deep into deep learning techniques for\nforensic application, especially in post-mortem iris recognition. Fourth, we\nreview open-source resources and tools in deep learning techniques for iris\nrecognition. Finally, we highlight the technical challenges, emerging research\ntrends, and outlook for the future of deep learning in iris recognition.",
    "published": "2022-10-12T01:58:09Z",
    "pdf_url": "http://arxiv.org/pdf/2210.05866v1",
    "categories": [
      "cs.CV",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1312.5355v1",
    "title": "Generative NeuroEvolution for Deep Learning",
    "authors": [
      "Phillip Verbancsics",
      "Josh Harguess"
    ],
    "abstract": "An important goal for the machine learning (ML) community is to create\napproaches that can learn solutions with human-level capability. One domain\nwhere humans have held a significant advantage is visual processing. A\nsignificant approach to addressing this gap has been machine learning\napproaches that are inspired from the natural systems, such as artificial\nneural networks (ANNs), evolutionary computation (EC), and generative and\ndevelopmental systems (GDS). Research into deep learning has demonstrated that\nsuch architectures can achieve performance competitive with humans on some\nvisual tasks; however, these systems have been primarily trained through\nsupervised and unsupervised learning algorithms. Alternatively, research is\nshowing that evolution may have a significant role in the development of visual\nsystems. Thus this paper investigates the role neuro-evolution (NE) can take in\ndeep learning. In particular, the Hypercube-based NeuroEvolution of Augmenting\nTopologies is a NE approach that can effectively learn large neural structures\nby training an indirect encoding that compresses the ANN weight pattern as a\nfunction of geometry. The results show that HyperNEAT struggles with performing\nimage classification by itself, but can be effective in training a feature\nextractor that other ML approaches can learn from. Thus NeuroEvolution combined\nwith other ML methods provides an intriguing area of research that can\nreplicate the processes in nature.",
    "published": "2013-12-18T22:14:31Z",
    "pdf_url": "http://arxiv.org/pdf/1312.5355v1",
    "categories": [
      "cs.NE",
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1507.04761v1",
    "title": "Deep Learning and Music Adversaries",
    "authors": [
      "Corey Kereliuk",
      "Bob L. Sturm",
      "Jan Larsen"
    ],
    "abstract": "An adversary is essentially an algorithm intent on making a classification\nsystem perform in some particular way given an input, e.g., increase the\nprobability of a false negative. Recent work builds adversaries for deep\nlearning systems applied to image object recognition, which exploits the\nparameters of the system to find the minimal perturbation of the input image\nsuch that the network misclassifies it with high confidence. We adapt this\napproach to construct and deploy an adversary of deep learning systems applied\nto music content analysis. In our case, however, the input to the systems is\nmagnitude spectral frames, which requires special care in order to produce\nvalid input audio signals from network-derived perturbations. For two different\ntrain-test partitionings of two benchmark datasets, and two different deep\narchitectures, we find that this adversary is very effective in defeating the\nresulting systems. We find the convolutional networks are more robust, however,\ncompared with systems based on a majority vote over individually classified\naudio frames. Furthermore, we integrate the adversary into the training of new\ndeep systems, but do not find that this improves their resilience against the\nsame adversary.",
    "published": "2015-07-16T20:24:18Z",
    "pdf_url": "http://arxiv.org/pdf/1507.04761v1",
    "categories": [
      "cs.LG",
      "cs.NE",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "1702.00523v1",
    "title": "Deep Learning the Indus Script",
    "authors": [
      "Satish Palaniappan",
      "Ronojoy Adhikari"
    ],
    "abstract": "Standardized corpora of undeciphered scripts, a necessary starting point for\ncomputational epigraphy, requires laborious human effort for their preparation\nfrom raw archaeological records. Automating this process through machine\nlearning algorithms can be of significant aid to epigraphical research. Here,\nwe take the first steps in this direction and present a deep learning pipeline\nthat takes as input images of the undeciphered Indus script, as found in\narchaeological artifacts, and returns as output a string of graphemes, suitable\nfor inclusion in a standard corpus. The image is first decomposed into regions\nusing Selective Search and these regions are classified as containing textual\nand/or graphical information using a convolutional neural network. Regions\nclassified as potentially containing text are hierarchically merged and trimmed\nto remove non-textual information. The remaining textual part of the image is\nsegmented using standard image processing techniques to isolate individual\ngraphemes. This set is finally passed to a second convolutional neural network\nto classify the graphemes, based on a standard corpus. The classifier can\nidentify the presence or absence of the most frequent Indus grapheme, the \"jar\"\nsign, with an accuracy of 92%. Our results demonstrate the great potential of\ndeep learning approaches in computational epigraphy and, more generally, in the\ndigital humanities.",
    "published": "2017-02-02T01:56:22Z",
    "pdf_url": "http://arxiv.org/pdf/1702.00523v1",
    "categories": [
      "cs.CV",
      "cs.CL",
      "cs.LG",
      "I.5.4; I.2.10; I.2.6"
    ]
  },
  {
    "arxiv_id": "1803.00149v1",
    "title": "Deep Learning for Causal Inference",
    "authors": [
      "Vikas Ramachandra"
    ],
    "abstract": "In this paper, we propose deep learning techniques for econometrics,\nspecifically for causal inference and for estimating individual as well as\naverage treatment effects. The contribution of this paper is twofold: 1. For\ngeneralized neighbor matching to estimate individual and average treatment\neffects, we analyze the use of autoencoders for dimensionality reduction while\nmaintaining the local neighborhood structure among the data points in the\nembedding space. This deep learning based technique is shown to perform better\nthan simple k nearest neighbor matching for estimating treatment effects,\nespecially when the data points have several features/covariates but reside in\na low dimensional manifold in high dimensional space. We also observe better\nperformance than manifold learning methods for neighbor matching. 2. Propensity\nscore matching is one specific and popular way to perform matching in order to\nestimate average and individual treatment effects. We propose the use of deep\nneural networks (DNNs) for propensity score matching, and present a network\ncalled PropensityNet for this. This is a generalization of the logistic\nregression technique traditionally used to estimate propensity scores and we\nshow empirically that DNNs perform better than logistic regression at\npropensity score matching. Code for both methods will be made available shortly\non Github at: https://github.com/vikas84bf",
    "published": "2018-03-01T01:01:16Z",
    "pdf_url": "http://arxiv.org/pdf/1803.00149v1",
    "categories": [
      "econ.EM",
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1707.07980v1",
    "title": "Deep Learning Based MIMO Communications",
    "authors": [
      "Timothy J. O'Shea",
      "Tugba Erpek",
      "T. Charles Clancy"
    ],
    "abstract": "We introduce a novel physical layer scheme for single user Multiple-Input\nMultiple-Output (MIMO) communications based on unsupervised deep learning using\nan autoencoder. This method extends prior work on the joint optimization of\nphysical layer representation and encoding and decoding processes as a single\nend-to-end task by expanding transmitter and receivers to the multi-antenna\ncase. We introduce a widely used domain appropriate wireless channel impairment\nmodel (Rayleigh fading channel), into the autoencoder optimization problem in\norder to directly learn a system which optimizes for it. We considered both\nspatial diversity and spatial multiplexing techniques in our implementation.\nOur deep learning-based approach demonstrates significant potential for\nlearning schemes which approach and exceed the performance of the methods which\nare widely used in existing wireless MIMO systems. We discuss how the proposed\nscheme can be easily adapted for open-loop and closed-loop operation in spatial\ndiversity and multiplexing modes and extended use with only compact binary\nchannel state information (CSI) as feedback.",
    "published": "2017-07-25T13:28:27Z",
    "pdf_url": "http://arxiv.org/pdf/1707.07980v1",
    "categories": [
      "cs.IT",
      "math.IT"
    ]
  },
  {
    "arxiv_id": "1809.01604v1",
    "title": "Merging datasets through deep learning",
    "authors": [
      "Kavitha Srinivas",
      "Abraham Gale",
      "Julian Dolby"
    ],
    "abstract": "Merging datasets is a key operation for data analytics. A frequent\nrequirement for merging is joining across columns that have different surface\nforms for the same entity (e.g., the name of a person might be represented as\n\"Douglas Adams\" or \"Adams, Douglas\"). Similarly, ontology alignment can require\nrecognizing distinct surface forms of the same entity, especially when\nontologies are independently developed. However, data management systems are\ncurrently limited to performing merges based on string equality, or at best\nusing string similarity. We propose an approach to performing merges based on\ndeep learning models. Our approach depends on (a) creating a deep learning\nmodel that maps surface forms of an entity into a set of vectors such that\nalternate forms for the same entity are closest in vector space, (b) indexing\nthese vectors using a nearest neighbors algorithm to find the forms that can be\npotentially joined together. To build these models, we had to adapt techniques\nfrom metric learning due to the characteristics of the data; specifically we\ndescribe novel sample selection techniques and loss functions that work for\nthis problem. To evaluate our approach, we used Wikidata as ground truth and\nbuilt models from datasets with approximately 1.1M people's names (200K\nidentities) and 130K company names (70K identities). We developed models that\nallow for joins with precision@1 of .75-.81 and recall of .74-.81. We make the\nmodels available for aligning people or companies across multiple datasets.",
    "published": "2018-09-05T16:19:26Z",
    "pdf_url": "http://arxiv.org/pdf/1809.01604v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1809.10536v1",
    "title": "Deep Learning and Holographic QCD",
    "authors": [
      "Koji Hashimoto",
      "Sotaro Sugishita",
      "Akinori Tanaka",
      "Akio Tomiya"
    ],
    "abstract": "We apply the relation between deep learning (DL) and the AdS/CFT\ncorrespondence to a holographic model of QCD. Using a lattice QCD data of the\nchiral condensate at a finite temperature as our training data, the deep\nlearning procedure holographically determines an emergent bulk metric as neural\nnetwork weights. The emergent bulk metric is found to have both a black hole\nhorizon and a finite-height IR wall, so shares both the confining and\ndeconfining phases, signaling the cross-over thermal phase transition of QCD.\nIn fact, a quark antiquark potential holographically calculated by the emergent\nbulk metric turns out to possess both the linear confining part and the Debye\nscreening part, as is often observed in lattice QCD. From this we argue the\ndiscrepancy between the chiral symmetry breaking and the quark confinement in\nthe holographic QCD. The DL method is shown to provide a novel data-driven\nholographic modeling of QCD, and sheds light on the mechanism of emergence of\nthe bulk geometries in the AdS/CFT correspondence.",
    "published": "2018-09-27T14:19:54Z",
    "pdf_url": "http://arxiv.org/pdf/1809.10536v1",
    "categories": [
      "hep-th",
      "hep-lat",
      "hep-ph"
    ]
  },
  {
    "arxiv_id": "1904.11643v1",
    "title": "Bayesian Generative Active Deep Learning",
    "authors": [
      "Toan Tran",
      "Thanh-Toan Do",
      "Ian Reid",
      "Gustavo Carneiro"
    ],
    "abstract": "Deep learning models have demonstrated outstanding performance in several\nproblems, but their training process tends to require immense amounts of\ncomputational and human resources for training and labeling, constraining the\ntypes of problems that can be tackled. Therefore, the design of effective\ntraining methods that require small labeled training sets is an important\nresearch direction that will allow a more effective use of resources.Among\ncurrent approaches designed to address this issue, two are particularly\ninteresting: data augmentation and active learning. Data augmentation achieves\nthis goal by artificially generating new training points, while active learning\nrelies on the selection of the \"most informative\" subset of unlabeled training\nsamples to be labelled by an oracle. Although successful in practice, data\naugmentation can waste computational resources because it indiscriminately\ngenerates samples that are not guaranteed to be informative, and active\nlearning selects a small subset of informative samples (from a large\nun-annotated set) that may be insufficient for the training process. In this\npaper, we propose a Bayesian generative active deep learning approach that\ncombines active learning with data augmentation -- we provide theoretical and\nempirical evidence (MNIST, CIFAR-$\\{10,100\\}$, and SVHN) that our approach has\nmore efficient training and better classification results than data\naugmentation and active learning.",
    "published": "2019-04-26T01:55:04Z",
    "pdf_url": "http://arxiv.org/pdf/1904.11643v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1503.01445v1",
    "title": "Toxicity Prediction using Deep Learning",
    "authors": [
      "Thomas Unterthiner",
      "Andreas Mayr",
      "Günter Klambauer",
      "Sepp Hochreiter"
    ],
    "abstract": "Everyday we are exposed to various chemicals via food additives, cleaning and\ncosmetic products and medicines -- and some of them might be toxic. However\ntesting the toxicity of all existing compounds by biological experiments is\nneither financially nor logistically feasible. Therefore the government\nagencies NIH, EPA and FDA launched the Tox21 Data Challenge within the\n\"Toxicology in the 21st Century\" (Tox21) initiative. The goal of this challenge\nwas to assess the performance of computational methods in predicting the\ntoxicity of chemical compounds. State of the art toxicity prediction methods\nbuild upon specifically-designed chemical descriptors developed over decades.\nThough Deep Learning is new to the field and was never applied to toxicity\nprediction before, it clearly outperformed all other participating methods. In\nthis application paper we show that deep nets automatically learn features\nresembling well-established toxicophores. In total, our Deep Learning approach\nwon both of the panel-challenges (nuclear receptors and stress response) as\nwell as the overall Grand Challenge, and thereby sets a new standard in tox\nprediction.",
    "published": "2015-03-04T20:18:55Z",
    "pdf_url": "http://arxiv.org/pdf/1503.01445v1",
    "categories": [
      "stat.ML",
      "cs.LG",
      "cs.NE",
      "q-bio.BM"
    ]
  },
  {
    "arxiv_id": "2012.07439v1",
    "title": "Graphs for deep learning representations",
    "authors": [
      "Carlos Lassance"
    ],
    "abstract": "In recent years, Deep Learning methods have achieved state of the art\nperformance in a vast range of machine learning tasks, including image\nclassification and multilingual automatic text translation. These architectures\nare trained to solve machine learning tasks in an end-to-end fashion. In order\nto reach top-tier performance, these architectures often require a very large\nnumber of trainable parameters. There are multiple undesirable consequences,\nand in order to tackle these issues, it is desired to be able to open the black\nboxes of deep learning architectures. Problematically, doing so is difficult\ndue to the high dimensionality of representations and the stochasticity of the\ntraining process. In this thesis, we investigate these architectures by\nintroducing a graph formalism based on the recent advances in Graph Signal\nProcessing (GSP). Namely, we use graphs to represent the latent spaces of deep\nneural networks. We showcase that this graph formalism allows us to answer\nvarious questions including: ensuring generalization abilities, reducing the\namount of arbitrary choices in the design of the learning process, improving\nrobustness to small perturbations added to the inputs, and reducing\ncomputational complexity",
    "published": "2020-12-14T11:51:23Z",
    "pdf_url": "http://arxiv.org/pdf/2012.07439v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2109.11431v1",
    "title": "Deep Learning for Ultrasound Beamforming",
    "authors": [
      "Ruud JG van Sloun",
      "Jong Chul Ye",
      "Yonina C Eldar"
    ],
    "abstract": "Diagnostic imaging plays a critical role in healthcare, serving as a\nfundamental asset for timely diagnosis, disease staging and management as well\nas for treatment choice, planning, guidance, and follow-up. Among the\ndiagnostic imaging options, ultrasound imaging is uniquely positioned, being a\nhighly cost-effective modality that offers the clinician an unmatched and\ninvaluable level of interaction, enabled by its real-time nature. Ultrasound\nprobes are becoming increasingly compact and portable, with the market demand\nfor low-cost pocket-sized and (in-body) miniaturized devices expanding. At the\nsame time, there is a strong trend towards 3D imaging and the use of\nhigh-frame-rate imaging schemes; both accompanied by dramatically increasing\ndata rates that pose a heavy burden on the probe-system communication and\nsubsequent image reconstruction algorithms.\n  With the demand for high-quality image reconstruction and signal extraction\nfrom less (e.g unfocused or parallel) transmissions that facilitate fast\nimaging, and a push towards compact probes, modern ultrasound imaging leans\nheavily on innovations in powerful digital receive channel processing.\nBeamforming, the process of mapping received ultrasound echoes to the spatial\nimage domain, naturally lies at the heart of the ultrasound image formation\nchain. In this chapter on Deep Learning for Ultrasound Beamforming, we discuss\nwhy and when deep learning methods can play a compelling role in the digital\nbeamforming pipeline, and then show how these data-driven systems can be\nleveraged for improved ultrasound image reconstruction.",
    "published": "2021-09-23T15:15:21Z",
    "pdf_url": "http://arxiv.org/pdf/2109.11431v1",
    "categories": [
      "eess.SP",
      "cs.AI",
      "eess.IV"
    ]
  },
  {
    "arxiv_id": "2111.14088v1",
    "title": "Multicriteria interpretability driven Deep Learning",
    "authors": [
      "Marco Repetto"
    ],
    "abstract": "Deep Learning methods are renowned for their performances, yet their lack of\ninterpretability prevents them from high-stakes contexts. Recent model agnostic\nmethods address this problem by providing post-hoc interpretability methods by\nreverse-engineering the model's inner workings. However, in many regulated\nfields, interpretability should be kept in mind from the start, which means\nthat post-hoc methods are valid only as a sanity check after model training.\nInterpretability from the start, in an abstract setting, means posing a set of\nsoft constraints on the model's behavior by injecting knowledge and\nannihilating possible biases. We propose a Multicriteria technique that allows\nto control the feature effects on the model's outcome by injecting knowledge in\nthe objective function. We then extend the technique by including a non-linear\nknowledge function to account for more complex effects and local lack of\nknowledge. The result is a Deep Learning model that embodies interpretability\nfrom the start and aligns with the recent regulations. A practical empirical\nexample based on credit risk, suggests that our approach creates performant yet\nrobust models capable of overcoming biases derived from data scarcity.",
    "published": "2021-11-28T09:41:13Z",
    "pdf_url": "http://arxiv.org/pdf/2111.14088v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2211.04686v3",
    "title": "Directional Privacy for Deep Learning",
    "authors": [
      "Pedro Faustini",
      "Natasha Fernandes",
      "Shakila Tonni",
      "Annabelle McIver",
      "Mark Dras"
    ],
    "abstract": "Differentially Private Stochastic Gradient Descent (DP-SGD) is a key method\nfor applying privacy in the training of deep learning models. It applies\nisotropic Gaussian noise to gradients during training, which can perturb these\ngradients in any direction, damaging utility. Metric DP, however, can provide\nalternative mechanisms based on arbitrary metrics that might be more suitable\nfor preserving utility. In this paper, we apply \\textit{directional privacy},\nvia a mechanism based on the von Mises-Fisher (VMF) distribution, to perturb\ngradients in terms of \\textit{angular distance} so that gradient direction is\nbroadly preserved. We show that this provides both $\\epsilon$-DP and $\\epsilon\nd$-privacy for deep learning training, rather than the $(\\epsilon,\n\\delta)$-privacy of the Gaussian mechanism. Experiments on key datasets then\nindicate that the VMF mechanism can outperform the Gaussian in the\nutility-privacy trade-off. In particular, our experiments provide a direct\nempirical comparison of privacy between the two approaches in terms of their\nability to defend against reconstruction and membership inference.",
    "published": "2022-11-09T05:18:08Z",
    "pdf_url": "http://arxiv.org/pdf/2211.04686v3",
    "categories": [
      "cs.LG",
      "cs.CR"
    ]
  },
  {
    "arxiv_id": "2302.05745v2",
    "title": "Verifying Generalization in Deep Learning",
    "authors": [
      "Guy Amir",
      "Osher Maayan",
      "Tom Zelazny",
      "Guy Katz",
      "Michael Schapira"
    ],
    "abstract": "Deep neural networks (DNNs) are the workhorses of deep learning, which\nconstitutes the state of the art in numerous application domains. However,\nDNN-based decision rules are notoriously prone to poor generalization, i.e.,\nmay prove inadequate on inputs not encountered during training. This limitation\nposes a significant obstacle to employing deep learning for mission-critical\ntasks, and also in real-world environments that exhibit high variability. We\npropose a novel, verification-driven methodology for identifying DNN-based\ndecision rules that generalize well to new input domains. Our approach\nquantifies generalization to an input domain by the extent to which decisions\nreached by independently trained DNNs are in agreement for inputs in this\ndomain. We show how, by harnessing the power of DNN verification, our approach\ncan be efficiently and effectively realized. We evaluate our verification-based\napproach on three deep reinforcement learning (DRL) benchmarks, including a\nsystem for Internet congestion control. Our results establish the usefulness of\nour approach. More broadly, our work puts forth a novel objective for formal\nverification, with the potential for mitigating the risks associated with\ndeploying DNN-based systems in the wild.",
    "published": "2023-02-11T17:08:15Z",
    "pdf_url": "http://arxiv.org/pdf/2302.05745v2",
    "categories": [
      "cs.LG",
      "cs.LO"
    ]
  },
  {
    "arxiv_id": "2103.05127v2",
    "title": "Model Complexity of Deep Learning: A Survey",
    "authors": [
      "Xia Hu",
      "Lingyang Chu",
      "Jian Pei",
      "Weiqing Liu",
      "Jiang Bian"
    ],
    "abstract": "Model complexity is a fundamental problem in deep learning. In this paper we\nconduct a systematic overview of the latest studies on model complexity in deep\nlearning. Model complexity of deep learning can be categorized into expressive\ncapacity and effective model complexity. We review the existing studies on\nthose two categories along four important factors, including model framework,\nmodel size, optimization process and data complexity. We also discuss the\napplications of deep learning model complexity including understanding model\ngeneralization, model optimization, and model selection and design. We conclude\nby proposing several interesting future directions.",
    "published": "2021-03-08T22:39:32Z",
    "pdf_url": "http://arxiv.org/pdf/2103.05127v2",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2011.13726v2",
    "title": "AdS/Deep-Learning made easy: simple examples",
    "authors": [
      "Mugeon Song",
      "Maverick S. H. Oh",
      "Yongjun Ahn",
      "Keun-Young Kim"
    ],
    "abstract": "Deep learning has been widely and actively used in various research areas.\nRecently, in the gauge/gravity duality, a new deep learning technique so-called\nthe AdS/Deep-Learning (DL) has been proposed [1, 2]. The goal of this paper is\nto describe the essence of the AdS/DL in the simplest possible setups, for\nthose who want to apply it to the subject of emergent spacetime as a neural\nnetwork. For prototypical examples, we choose simple classical mechanics\nproblems. This method is a little different from standard deep learning\ntechniques in the sense that not only do we have the right final answers but\nalso obtain a physical understanding of learning parameters.",
    "published": "2020-11-27T13:23:18Z",
    "pdf_url": "http://arxiv.org/pdf/2011.13726v2",
    "categories": [
      "physics.class-ph",
      "cs.LG",
      "hep-th"
    ]
  },
  {
    "arxiv_id": "1906.08986v2",
    "title": "Database Meets Deep Learning: Challenges and Opportunities",
    "authors": [
      "Wei Wang",
      "Meihui Zhang",
      "Gang Chen",
      "H. V. Jagadish",
      "Beng Chin Ooi",
      "Kian-Lee Tan"
    ],
    "abstract": "Deep learning has recently become very popular on account of its incredible\nsuccess in many complex data-driven applications, such as image classification\nand speech recognition. The database community has worked on data-driven\napplications for many years, and therefore should be playing a lead role in\nsupporting this new wave. However, databases and deep learning are different in\nterms of both techniques and applications. In this paper, we discuss research\nproblems at the intersection of the two fields. In particular, we discuss\npossible improvements for deep learning systems from a database perspective,\nand analyze database applications that may benefit from deep learning\ntechniques.",
    "published": "2019-06-21T07:26:31Z",
    "pdf_url": "http://arxiv.org/pdf/1906.08986v2",
    "categories": [
      "cs.DB",
      "cs.DC",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2007.09637v1",
    "title": "Survey on Deep Learning-based Kuzushiji Recognition",
    "authors": [
      "Kazuya Ueki",
      "Tomoka Kojima"
    ],
    "abstract": "Owing to the overwhelming accuracy of the deep learning method demonstrated\nat the 2012 image classification competition, deep learning has been\nsuccessfully applied to a variety of other tasks. The high-precision detection\nand recognition of Kuzushiji, a Japanese cursive script used for transcribing\nhistorical documents, has been made possible through the use of deep learning.\nIn recent years, competitions on Kuzushiji recognition have been held, and many\nresearchers have proposed various recognition methods. This study examines\nrecent research trends, current problems, and future prospects in Kuzushiji\nrecognition using deep learning.",
    "published": "2020-07-19T09:46:46Z",
    "pdf_url": "http://arxiv.org/pdf/2007.09637v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1312.5548v1",
    "title": "My First Deep Learning System of 1991 + Deep Learning Timeline 1962-2013",
    "authors": [
      "Jürgen Schmidhuber"
    ],
    "abstract": "Deep Learning has attracted significant attention in recent years. Here I\npresent a brief overview of my first Deep Learner of 1991, and its historic\ncontext, with a timeline of Deep Learning highlights.",
    "published": "2013-12-19T13:45:45Z",
    "pdf_url": "http://arxiv.org/pdf/1312.5548v1",
    "categories": [
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "1602.00172v2",
    "title": "Deep Learning For Smile Recognition",
    "authors": [
      "Patrick O. Glauner"
    ],
    "abstract": "Inspired by recent successes of deep learning in computer vision, we propose\na novel application of deep convolutional neural networks to facial expression\nrecognition, in particular smile recognition. A smile recognition test accuracy\nof 99.45% is achieved for the Denver Intensity of Spontaneous Facial Action\n(DISFA) database, significantly outperforming existing approaches based on\nhand-crafted features with accuracies ranging from 65.55% to 79.67%. The\nnovelty of this approach includes a comprehensive model selection of the\narchitecture parameters, allowing to find an appropriate architecture for each\nexpression such as smile. This is feasible because all experiments were run on\na Tesla K40c GPU, allowing a speedup of factor 10 over traditional computations\non a CPU.",
    "published": "2016-01-30T23:59:04Z",
    "pdf_url": "http://arxiv.org/pdf/1602.00172v2",
    "categories": [
      "cs.CV",
      "cs.LG",
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "1605.06921v1",
    "title": "Generative Choreography using Deep Learning",
    "authors": [
      "Luka Crnkovic-Friis",
      "Louise Crnkovic-Friis"
    ],
    "abstract": "Recent advances in deep learning have enabled the extraction of high-level\nfeatures from raw sensor data which has opened up new possibilities in many\ndifferent fields, including computer generated choreography. In this paper we\npresent a system chor-rnn for generating novel choreographic material in the\nnuanced choreographic language and style of an individual choreographer. It\nalso shows promising results in producing a higher level compositional\ncohesion, rather than just generating sequences of movement. At the core of\nchor-rnn is a deep recurrent neural network trained on raw motion capture data\nand that can generate new dance sequences for a solo dancer. Chor-rnn can be\nused for collaborative human-machine choreography or as a creative catalyst,\nserving as inspiration for a choreographer.",
    "published": "2016-05-23T07:36:49Z",
    "pdf_url": "http://arxiv.org/pdf/1605.06921v1",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "1705.08665v4",
    "title": "Bayesian Compression for Deep Learning",
    "authors": [
      "Christos Louizos",
      "Karen Ullrich",
      "Max Welling"
    ],
    "abstract": "Compression and computational efficiency in deep learning have become a\nproblem of great significance. In this work, we argue that the most principled\nand effective way to attack this problem is by adopting a Bayesian point of\nview, where through sparsity inducing priors we prune large parts of the\nnetwork. We introduce two novelties in this paper: 1) we use hierarchical\npriors to prune nodes instead of individual weights, and 2) we use the\nposterior uncertainties to determine the optimal fixed point precision to\nencode the weights. Both factors significantly contribute to achieving the\nstate of the art in terms of compression rates, while still staying competitive\nwith methods designed to optimize for speed or energy efficiency.",
    "published": "2017-05-24T09:07:01Z",
    "pdf_url": "http://arxiv.org/pdf/1705.08665v4",
    "categories": [
      "stat.ML",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1708.04439v2",
    "title": "Extractive Summarization using Deep Learning",
    "authors": [
      "Sukriti Verma",
      "Vagisha Nidhi"
    ],
    "abstract": "This paper proposes a text summarization approach for factual reports using a\ndeep learning model. This approach consists of three phases: feature\nextraction, feature enhancement, and summary generation, which work together to\nassimilate core information and generate a coherent, understandable summary. We\nare exploring various features to improve the set of sentences selected for the\nsummary, and are using a Restricted Boltzmann Machine to enhance and abstract\nthose features to improve resultant accuracy without losing any important\ninformation. The sentences are scored based on those enhanced features and an\nextractive summary is constructed. Experimentation carried out on several\narticles demonstrates the effectiveness of the proposed approach. Source code\navailable at: https://github.com/vagisha-nidhi/TextSummarizer",
    "published": "2017-08-15T09:08:50Z",
    "pdf_url": "http://arxiv.org/pdf/1708.04439v2",
    "categories": [
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1803.10768v1",
    "title": "Unreasonable Effectivness of Deep Learning",
    "authors": [
      "Finn Macleod"
    ],
    "abstract": "We show how well known rules of back propagation arise from a weighted\ncombination of finite automata. By redefining a finite automata as a predictor\nwe combine the set of all $k$-state finite automata using a weighted majority\nalgorithm. This aggregated prediction algorithm can be simplified using\nsymmetry, and we prove the equivalence of an algorithm that does this. We\ndemonstrate that this algorithm is equivalent to a form of a back propagation\nacting in a completely connected $k$-node neural network. Thus the use of the\nweighted majority algorithm allows a bound on the general performance of deep\nlearning approaches to prediction via known results from online statistics. The\npresented framework opens more detailed questions about network topology; it is\na bridge to the well studied techniques of semigroup theory and applying these\ntechniques to answer what specific network topologies are capable of\npredicting. This informs both the design of artificial networks and the\nexploration of neuroscience models.",
    "published": "2018-03-28T14:29:30Z",
    "pdf_url": "http://arxiv.org/pdf/1803.10768v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1808.05527v3",
    "title": "Deep Learning for Energy Markets",
    "authors": [
      "Michael Polson",
      "Vadim Sokolov"
    ],
    "abstract": "Deep Learning is applied to energy markets to predict extreme loads observed\nin energy grids. Forecasting energy loads and prices is challenging due to\nsharp peaks and troughs that arise due to supply and demand fluctuations from\nintraday system constraints. We propose deep spatio-temporal models and extreme\nvalue theory (EVT) to capture theses effects and in particular the tail\nbehavior of load spikes. Deep LSTM architectures with ReLU and $\\tanh$\nactivation functions can model trends and temporal dependencies while EVT\ncaptures highly volatile load spikes above a pre-specified threshold. To\nillustrate our methodology, we use hourly price and demand data from 4719 nodes\nof the PJM interconnection, and we construct a deep predictor. We show that\nDL-EVT outperforms traditional Fourier time series methods, both in-and\nout-of-sample, by capturing the observed nonlinearities in prices. Finally, we\nconclude with directions for future research.",
    "published": "2018-08-16T15:01:01Z",
    "pdf_url": "http://arxiv.org/pdf/1808.05527v3",
    "categories": [
      "stat.ML",
      "cs.LG",
      "q-fin.ST"
    ]
  },
  {
    "arxiv_id": "1810.05893v4",
    "title": "Deep Learning-Based Channel Estimation",
    "authors": [
      "Mehran Soltani",
      "Vahid Pourahmadi",
      "Ali Mirzaei",
      "Hamid Sheikhzadeh"
    ],
    "abstract": "In this paper, we present a deep learning (DL) algorithm for channel\nestimation in communication systems. We consider the time-frequency response of\na fast fading communication channel as a two-dimensional image. The aim is to\nfind the unknown values of the channel response using some known values at the\npilot locations. To this end, a general pipeline using deep image processing\ntechniques, image super-resolution (SR) and image restoration (IR) is proposed.\nThis scheme considers the pilot values, altogether, as a low-resolution image\nand uses an SR network cascaded with a denoising IR network to estimate the\nchannel. Moreover, an implementation of the proposed pipeline is presented. The\nestimation error shows that the presented algorithm is comparable to the\nminimum mean square error (MMSE) with full knowledge of the channel statistics\nand it is better than ALMMSE (an approximation to linear MMSE). The results\nconfirm that this pipeline can be used efficiently in channel estimation.",
    "published": "2018-10-13T17:08:52Z",
    "pdf_url": "http://arxiv.org/pdf/1810.05893v4",
    "categories": [
      "cs.IT",
      "cs.LG",
      "eess.SP",
      "math.IT",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2006.09590v2",
    "title": "Deep Learning with Functional Inputs",
    "authors": [
      "Barinder Thind",
      "Kevin Multani",
      "Jiguo Cao"
    ],
    "abstract": "We present a methodology for integrating functional data into deep densely\nconnected feed-forward neural networks. The model is defined for scalar\nresponses with multiple functional and scalar covariates. A by-product of the\nmethod is a set of dynamic functional weights that can be visualized during the\noptimization process. This visualization leads to greater interpretability of\nthe relationship between the covariates and the response relative to\nconventional neural networks. The model is shown to perform well in a number of\ncontexts including prediction of new data and recovery of the true underlying\nfunctional weights; these results were confirmed through real applications and\nsimulation studies. A forthcoming R package is developed on top of a popular\ndeep learning library (Keras) allowing for general use of the approach.",
    "published": "2020-06-17T01:23:00Z",
    "pdf_url": "http://arxiv.org/pdf/2006.09590v2",
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ]
  },
  {
    "arxiv_id": "2005.13665v3",
    "title": "Deep Learning for Portfolio Optimization",
    "authors": [
      "Zihao Zhang",
      "Stefan Zohren",
      "Stephen Roberts"
    ],
    "abstract": "We adopt deep learning models to directly optimise the portfolio Sharpe\nratio. The framework we present circumvents the requirements for forecasting\nexpected returns and allows us to directly optimise portfolio weights by\nupdating model parameters. Instead of selecting individual assets, we trade\nExchange-Traded Funds (ETFs) of market indices to form a portfolio. Indices of\ndifferent asset classes show robust correlations and trading them substantially\nreduces the spectrum of available assets to choose from. We compare our method\nwith a wide range of algorithms with results showing that our model obtains the\nbest performance over the testing period, from 2011 to the end of April 2020,\nincluding the financial instabilities of the first quarter of 2020. A\nsensitivity analysis is included to understand the relevance of input features\nand we further study the performance of our approach under different cost rates\nand different risk levels via volatility scaling.",
    "published": "2020-05-27T21:28:43Z",
    "pdf_url": "http://arxiv.org/pdf/2005.13665v3",
    "categories": [
      "q-fin.PM",
      "cs.LG",
      "q-fin.CP"
    ]
  },
  {
    "arxiv_id": "1701.02620v2",
    "title": "Deep Learning for Logo Recognition",
    "authors": [
      "Simone Bianco",
      "Marco Buzzelli",
      "Davide Mazzini",
      "Raimondo Schettini"
    ],
    "abstract": "In this paper we propose a method for logo recognition using deep learning.\nOur recognition pipeline is composed of a logo region proposal followed by a\nConvolutional Neural Network (CNN) specifically trained for logo\nclassification, even if they are not precisely localized. Experiments are\ncarried out on the FlickrLogos-32 database, and we evaluate the effect on\nrecognition performance of synthetic versus real data augmentation, and image\npre-processing. Moreover, we systematically investigate the benefits of\ndifferent training choices such as class-balancing, sample-weighting and\nexplicit modeling the background class (i.e. no-logo regions). Experimental\nresults confirm the feasibility of the proposed method, that outperforms the\nmethods in the state of the art.",
    "published": "2017-01-10T14:51:39Z",
    "pdf_url": "http://arxiv.org/pdf/1701.02620v2",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1807.03162v2",
    "title": "Deep Learning Based Sphere Decoding",
    "authors": [
      "Mostafa Mohammadkarimi",
      "Mehrtash Mehrabi",
      "Masoud Ardakani",
      "Yindi Jing"
    ],
    "abstract": "In this paper, a deep learning (DL)-based sphere decoding algorithm is\nproposed, where the radius of the decoding hypersphere is learned by a deep\nneural network (DNN). The performance achieved by the proposed algorithm is\nvery close to the optimal maximum likelihood decoding (MLD) over a wide range\nof signal-to-noise ratios (SNRs), while the computational complexity, compared\nto existing sphere decoding variants, is significantly reduced. This\nimprovement is attributed to DNN's ability of intelligently learning the radius\nof the hypersphere used in decoding. The expected complexity of the proposed\nDL-based algorithm is analytically derived and compared with existing ones. It\nis shown that the number of lattice points inside the decoding hypersphere\ndrastically reduces in the DL-based algorithm in both the average and\nworst-case senses. The effectiveness of the proposed algorithm is shown through\nsimulation for high-dimensional multiple-input multiple-output (MIMO) systems,\nusing high-order modulations.",
    "published": "2018-07-06T03:18:35Z",
    "pdf_url": "http://arxiv.org/pdf/1807.03162v2",
    "categories": [
      "eess.SP",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1910.04918v3",
    "title": "Deep Learning for Prostate Pathology",
    "authors": [
      "Okyaz Eminaga",
      "Yuri Tolkach",
      "Christian Kunder",
      "Mahmood Abbas",
      "Ryan Han",
      "Rosalie Nolley",
      "Axel Semjonow",
      "Martin Boegemann",
      "Sebastian Huss",
      "Andreas Loening",
      "Robert West",
      "Geoffrey Sonn",
      "Richard Fan",
      "Olaf Bettendorf",
      "James Brook",
      "Daniel Rubin"
    ],
    "abstract": "The current study detects different morphologies related to prostate\npathology using deep learning models; these models were evaluated on 2,121\nhematoxylin and eosin (H&E) stain histology images captured using bright field\nmicroscopy, which spanned a variety of image qualities, origins (whole slide,\ntissue micro array, whole mount, Internet), scanning machines, timestamps, H&E\nstaining protocols, and institutions. For case usage, these models were applied\nfor the annotation tasks in clinician-oriented pathology reports for\nprostatectomy specimens. The true positive rate (TPR) for slides with prostate\ncancer was 99.7% by a false positive rate of 0.785%. The F1-scores of Gleason\npatterns reported in pathology reports ranged from 0.795 to 1.0 at the case\nlevel. TPR was 93.6% for the cribriform morphology and 72.6% for the ductal\nmorphology. The correlation between the ground truth and the prediction for the\nrelative tumor volume was 0.987 n. Our models cover the major components of\nprostate pathology and successfully accomplish the annotation tasks.",
    "published": "2019-10-11T00:10:59Z",
    "pdf_url": "http://arxiv.org/pdf/1910.04918v3",
    "categories": [
      "q-bio.TO",
      "cs.CV",
      "cs.LG",
      "eess.IV"
    ]
  },
  {
    "arxiv_id": "1910.10231v1",
    "title": "Deep Learning at the Edge",
    "authors": [
      "Sahar Voghoei",
      "Navid Hashemi Tonekaboni",
      "Jason G. Wallace",
      "Hamid R. Arabnia"
    ],
    "abstract": "The ever-increasing number of Internet of Things (IoT) devices has created a\nnew computing paradigm, called edge computing, where most of the computations\nare performed at the edge devices, rather than on centralized servers. An edge\ndevice is an electronic device that provides connections to service providers\nand other edge devices; typically, such devices have limited resources. Since\nedge devices are resource-constrained, the task of launching algorithms,\nmethods, and applications onto edge devices is considered to be a significant\nchallenge. In this paper, we discuss one of the most widely used machine\nlearning methods, namely, Deep Learning (DL) and offer a short survey on the\nrecent approaches used to map DL onto the edge computing paradigm. We also\nprovide relevant discussions about selected applications that would greatly\nbenefit from DL at the edge.",
    "published": "2019-10-22T21:08:09Z",
    "pdf_url": "http://arxiv.org/pdf/1910.10231v1",
    "categories": [
      "cs.LG",
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "1910.12582v1",
    "title": "Engineering Reliable Deep Learning Systems",
    "authors": [
      "P. Santhanam",
      "Eitan Farchi",
      "Victor Pankratius"
    ],
    "abstract": "Recent progress in artificial intelligence (AI) using deep learning\ntechniques has triggered its wide-scale use across a broad range of\napplications. These systems can already perform tasks such as natural language\nprocessing of voice and text, visual recognition, question-answering,\nrecommendations and decision support. However, at the current level of\nmaturity, the use of an AI component in mission-critical or safety-critical\napplications can have unexpected consequences. Consequently, serious concerns\nabout reliability, repeatability, trust, and maintainability of AI applications\nremain. As AI becomes pervasive despite its shortcomings, more systematic ways\nof approaching AI software development and certification are needed. These\nfundamental aspects establish the need for a discipline on \"AI Engineering\".\nThis paper presents the current perspective of relevant AI engineering concepts\nand some key challenges that need to be overcome to make significant progress\nin this important area.",
    "published": "2019-10-14T15:13:45Z",
    "pdf_url": "http://arxiv.org/pdf/1910.12582v1",
    "categories": [
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "1902.03620v2",
    "title": "Deep learning detection of transients",
    "authors": [
      "Iftach Sadeh"
    ],
    "abstract": "The next generation of observatories will facilitate the discovery of new\ntypes of astrophysical transients. The detection of such phenomena, whose\ncharacteristics are presently poorly constrained, will hinge on the ability to\nperform blind searches. We present a new algorithm for this purpose, based on\ndeep learning. We incorporate two approaches, utilising anomaly detection and\nclassification techniques. The first is model-independent, avoiding the use of\nbackground modelling and instrument simulations. The second method enables\ntargeted searches, relying on generic spectral and temporal patterns as input.\nWe compare our methodology with the existing approach to serendipitous\ndetection of gamma-ray transients. The algorithm is shown to be more robust,\nespecially for non-trivial spectral features. We use our framework to derive\nthe detection prospects of low-luminosity gamma-ray bursts with the upcoming\nCherenkov Telescope Array. Our method is an unbiased, completely data-driven\napproach for multiwavelength and multi-messenger transient detection.",
    "published": "2019-02-10T15:22:15Z",
    "pdf_url": "http://arxiv.org/pdf/1902.03620v2",
    "categories": [
      "astro-ph.HE",
      "astro-ph.IM"
    ]
  },
  {
    "arxiv_id": "2008.10293v1",
    "title": "Bosch Deep Learning Hardware Benchmark",
    "authors": [
      "Armin Runge",
      "Thomas Wenzel",
      "Dimitrios Bariamis",
      "Benedikt Sebastian Staffler",
      "Lucas Rego Drumond",
      "Michael Pfeiffer"
    ],
    "abstract": "The widespread use of Deep Learning (DL) applications in science and industry\nhas created a large demand for efficient inference systems. This has resulted\nin a rapid increase of available Hardware Accelerators (HWAs) making comparison\nchallenging and laborious. To address this, several DL hardware benchmarks have\nbeen proposed aiming at a comprehensive comparison for many models, tasks, and\nhardware platforms. Here, we present our DL hardware benchmark which has been\nspecifically developed for inference on embedded HWAs and tasks required for\nautonomous driving. In addition to previous benchmarks, we propose a new\ngranularity level to evaluate common submodules of DL models, a twofold\nbenchmark procedure that accounts for hardware and model optimizations done by\nHWA manufacturers, and an extended set of performance indicators that can help\nto identify a mismatch between a HWA and the DL models used in our benchmark.",
    "published": "2020-08-24T09:50:24Z",
    "pdf_url": "http://arxiv.org/pdf/2008.10293v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2201.09199v1",
    "title": "Deep Learning on Attributed Sequences",
    "authors": [
      "Zhongfang Zhuang"
    ],
    "abstract": "Recent research in feature learning has been extended to sequence data, where\neach instance consists of a sequence of heterogeneous items with a variable\nlength. However, in many real-world applications, the data exists in the form\nof attributed sequences, which is composed of a set of fixed-size attributes\nand variable-length sequences with dependencies between them. In the attributed\nsequence context, feature learning remains challenging due to the dependencies\nbetween sequences and their associated attributes. In this dissertation, we\nfocus on analyzing and building deep learning models for four new problems on\nattributed sequences. Our extensive experiments on real-world datasets\ndemonstrate that the proposed solutions significantly improve the performance\nof each task over the state-of-the-art methods on attributed sequences.",
    "published": "2022-01-23T06:54:31Z",
    "pdf_url": "http://arxiv.org/pdf/2201.09199v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2203.00567v2",
    "title": "Descriptellation: Deep Learned Constellation Descriptors",
    "authors": [
      "Chunwei Xing",
      "Xinyu Sun",
      "Andrei Cramariuc",
      "Samuel Gull",
      "Jen Jen Chung",
      "Cesar Cadena",
      "Roland Siegwart",
      "Florian Tschopp"
    ],
    "abstract": "Current descriptors for global localization often struggle under vast\nviewpoint or appearance changes. One possible improvement is the addition of\ntopological information on semantic objects. However, handcrafted topological\ndescriptors are hard to tune and not robust to environmental noise, drastic\nperspective changes, object occlusion or misdetections. To solve this problem,\nwe formulate a learning-based approach by modelling semantically meaningful\nobject constellations as graphs and using Deep Graph Convolution Networks to\nmap a constellation to a descriptor. We demonstrate the effectiveness of our\nDeep Learned Constellation Descriptor (Descriptellation) on two real-world\ndatasets. Although Descriptellation is trained on randomly generated simulation\ndatasets, it shows good generalization abilities on real-world datasets.\nDescriptellation also outperforms state-of-the-art and handcrafted\nconstellation descriptors for global localization, and is robust to different\ntypes of noise. The code is publicly available at\nhttps://github.com/ethz-asl/Descriptellation.",
    "published": "2022-03-01T15:43:01Z",
    "pdf_url": "http://arxiv.org/pdf/2203.00567v2",
    "categories": [
      "cs.RO",
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2204.08157v1",
    "title": "Deep Learning Coherent Diffractive Imaging",
    "authors": [
      "Dillan J. Chang",
      "Colum M. O'Leary",
      "Cong Su",
      "Salman Kahn",
      "Alex Zettl",
      "Jim Ciston",
      "Peter Ercius",
      "Jianwei Miao"
    ],
    "abstract": "We report the development of deep learning coherent electron diffractive\nimaging at sub-angstrom resolution using convolutional neural networks (CNNs)\ntrained with only simulated data. We experimentally demonstrate this method by\napplying the trained CNNs to directly recover the phase images from electron\ndiffraction patterns of twisted hexagonal boron nitride, monolayer graphene and\na Au nanoparticle with comparable quality to those reconstructed by a\nconventional ptychographic method. Fourier ring correlation between the CNN and\nptychographic images indicates the achievement of a spatial resolution in the\nrange of 0.70 and 0.55 angstrom (depending on different resolution criteria).\nThe ability to replace iterative algorithms with CNNs and perform real-time\nimaging from coherent diffraction patterns is expected to find broad\napplications in the physical and biological sciences.",
    "published": "2022-04-18T04:05:41Z",
    "pdf_url": "http://arxiv.org/pdf/2204.08157v1",
    "categories": [
      "cond-mat.mtrl-sci"
    ]
  },
  {
    "arxiv_id": "2208.09325v1",
    "title": "Deep Learning for Choice Modeling",
    "authors": [
      "Zhongze Cai",
      "Hanzhao Wang",
      "Kalyan Talluri",
      "Xiaocheng Li"
    ],
    "abstract": "Choice modeling has been a central topic in the study of individual\npreference or utility across many fields including economics, marketing,\noperations research, and psychology. While the vast majority of the literature\non choice models has been devoted to the analytical properties that lead to\nmanagerial and policy-making insights, the existing methods to learn a choice\nmodel from empirical data are often either computationally intractable or\nsample inefficient. In this paper, we develop deep learning-based choice models\nunder two settings of choice modeling: (i) feature-free and (ii) feature-based.\nOur model captures both the intrinsic utility for each candidate choice and the\neffect that the assortment has on the choice probability. Synthetic and real\ndata experiments demonstrate the performances of proposed models in terms of\nthe recovery of the existing choice models, sample complexity, assortment\neffect, architecture design, and model interpretation.",
    "published": "2022-08-19T13:10:17Z",
    "pdf_url": "http://arxiv.org/pdf/2208.09325v1",
    "categories": [
      "stat.ML",
      "cs.LG",
      "econ.EM"
    ]
  },
  {
    "arxiv_id": "2210.04323v1",
    "title": "Deep Learning Inference Frameworks Benchmark",
    "authors": [
      "Pierrick Pochelu"
    ],
    "abstract": "Deep learning (DL) has been widely adopted those last years but they are\ncomputing-intensive method. Therefore, scientists proposed diverse optimization\nto accelerate their predictions for end-user applications. However, no single\ninference framework currently dominates in terms of performance. This paper\ntakes a holistic approach to conduct an empirical comparison and analysis of\nfour representative DL inference frameworks. First, given a selection of\nCPU-GPU configurations, we show that for a specific DL framework, different\nconfigurations of its settings may have a significant impact on the prediction\nspeed, memory, and computing power. Second, to the best of our knowledge, this\nstudy is the first to identify the opportunities for accelerating the ensemble\nof co-localized models in the same GPU. This measurement study provides an\nin-depth empirical comparison and analysis of four representative DL frameworks\nand offers practical guidance for service providers to deploy and deliver DL\npredictions.",
    "published": "2022-10-09T19:16:53Z",
    "pdf_url": "http://arxiv.org/pdf/2210.04323v1",
    "categories": [
      "cs.LG",
      "cs.PF"
    ]
  },
  {
    "arxiv_id": "2401.03639v1",
    "title": "Deep Learning for Visual Neuroprosthesis",
    "authors": [
      "Peter Beech",
      "Shanshan Jia",
      "Zhaofei Yu",
      "Jian K. Liu"
    ],
    "abstract": "The visual pathway involves complex networks of cells and regions which\ncontribute to the encoding and processing of visual information. While some\naspects of visual perception are understood, there are still many unanswered\nquestions regarding the exact mechanisms of visual encoding and the\norganization of visual information along the pathway. This chapter discusses\nthe importance of visual perception and the challenges associated with\nunderstanding how visual information is encoded and represented in the brain.\nFurthermore, this chapter introduces the concept of neuroprostheses: devices\ndesigned to enhance or replace bodily functions, and highlights the importance\nof constructing computational models of the visual pathway in the\nimplementation of such devices. A number of such models, employing the use of\ndeep learning models, are outlined, and their value to understanding visual\ncoding and natural vision is discussed.",
    "published": "2024-01-08T02:53:22Z",
    "pdf_url": "http://arxiv.org/pdf/2401.03639v1",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2403.03353v3",
    "title": "Hypothesis Spaces for Deep Learning",
    "authors": [
      "Rui Wang",
      "Yuesheng Xu",
      "Mingsong Yan"
    ],
    "abstract": "This paper introduces a hypothesis space for deep learning based on deep\nneural networks (DNNs). By treating a DNN as a function of two variables - the\ninput variable and the parameter variable - we consider the set of DNNs where\nthe parameter variable belongs to a space of weight matrices and biases\ndetermined by a prescribed depth and layer widths. To construct a Banach space\nof functions of the input variable, we take the weak* closure of the linear\nspan of this DNN set. We prove that the resulting Banach space is a reproducing\nkernel Banach space (RKBS) and explicitly construct its reproducing kernel.\nFurthermore, we investigate two learning models - regularized learning and the\nminimum norm interpolation (MNI) problem - within the RKBS framework by\nestablishing representer theorems. These theorems reveal that the solutions to\nthese learning problems can be expressed as a finite sum of kernel expansions\nbased on training data.",
    "published": "2024-03-05T22:42:29Z",
    "pdf_url": "http://arxiv.org/pdf/2403.03353v3",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.FA"
    ]
  },
  {
    "arxiv_id": "2405.16339v2",
    "title": "BOLD: Boolean Logic Deep Learning",
    "authors": [
      "Van Minh Nguyen",
      "Cristian Ocampo",
      "Aymen Askri",
      "Louis Leconte",
      "Ba-Hien Tran"
    ],
    "abstract": "Deep learning is computationally intensive, with significant efforts focused\non reducing arithmetic complexity, particularly regarding energy consumption\ndominated by data movement. While existing literature emphasizes inference,\ntraining is considerably more resource-intensive. This paper proposes a novel\nmathematical principle by introducing the notion of Boolean variation such that\nneurons made of Boolean weights and inputs can be trained -- for the first time\n-- efficiently in Boolean domain using Boolean logic instead of gradient\ndescent and real arithmetic. We explore its convergence, conduct extensively\nexperimental benchmarking, and provide consistent complexity evaluation by\nconsidering chip architecture, memory hierarchy, dataflow, and arithmetic\nprecision. Our approach achieves baseline full-precision accuracy in ImageNet\nclassification and surpasses state-of-the-art results in semantic segmentation,\nwith notable performance in image super-resolution, and natural language\nunderstanding with transformer-based models. Moreover, it significantly reduces\nenergy consumption during both training and inference.",
    "published": "2024-05-25T19:50:23Z",
    "pdf_url": "http://arxiv.org/pdf/2405.16339v2",
    "categories": [
      "stat.ML",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2405.20594v1",
    "title": "Deep Learning without Weight Symmetry",
    "authors": [
      "Li Ji-An",
      "Marcus K. Benna"
    ],
    "abstract": "Backpropagation (BP), a foundational algorithm for training artificial neural\nnetworks, predominates in contemporary deep learning. Although highly\nsuccessful, it is often considered biologically implausible. A significant\nlimitation arises from the need for precise symmetry between connections in the\nbackward and forward pathways to backpropagate gradient signals accurately,\nwhich is not observed in biological brains. Researchers have proposed several\nalgorithms to alleviate this symmetry constraint, such as feedback alignment\nand direct feedback alignment. However, their divergence from backpropagation\ndynamics presents challenges, particularly in deeper networks and convolutional\nlayers. Here we introduce the Product Feedback Alignment (PFA) algorithm. Our\nfindings demonstrate that PFA closely approximates BP and achieves comparable\nperformance in deep convolutional networks while avoiding explicit weight\nsymmetry. Our results offer a novel solution to the longstanding weight\nsymmetry problem, leading to more biologically plausible learning in deep\nconvolutional networks compared to earlier methods.",
    "published": "2024-05-31T03:11:19Z",
    "pdf_url": "http://arxiv.org/pdf/2405.20594v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.NC"
    ]
  },
  {
    "arxiv_id": "2406.04104v1",
    "title": "Symplectic Methods in Deep Learning",
    "authors": [
      "Sofya Maslovskaya",
      "Sina Ober-Blöbaum"
    ],
    "abstract": "Deep learning is widely used in tasks including image recognition and\ngeneration, in learning dynamical systems from data and many more. It is\nimportant to construct learning architectures with theoretical guarantees to\npermit safety in the applications. There has been considerable progress in this\ndirection lately. In particular, symplectic networks were shown to have the non\nvanishing gradient property, essential for numerical stability. On the other\nhand, architectures based on higher order numerical methods were shown to be\nefficient in many tasks where the learned function has an underlying dynamical\nstructure. In this work we construct symplectic networks based on higher order\nexplicit methods with non vanishing gradient property and test their efficiency\non various examples.",
    "published": "2024-06-06T14:20:55Z",
    "pdf_url": "http://arxiv.org/pdf/2406.04104v1",
    "categories": [
      "math.NA",
      "cs.NA",
      "math.OC"
    ]
  },
  {
    "arxiv_id": "2507.03438v1",
    "title": "Deep Learning and Model Independence",
    "authors": [
      "Martin King"
    ],
    "abstract": "The lack of evidence in favor of any new physics models means that the search\nfor new physics beyond the Standard Model (BSM) is wide open, with no direction\nclearly more promising than any other. This marks a turn towards what can be\ncalled `model-independent' methods-strategies that reduce the influence of\nmodelling assumptions by performing minimally-biased precision measurements,\nusing effective field theories, or using Deep Learning methods (DL). In this\npaper, I present the novel and promising uses of DL as a primary tool in high\nenergy physics research, highlighting the use of autoencoder networks and\nunsupervised learning methods. I advocate for the importance and usefulness of\nthe concept of model independence and propose a definition that recognizes that\nindependence of models is not absolute, but comes in degrees.",
    "published": "2025-07-04T09:53:36Z",
    "pdf_url": "http://arxiv.org/pdf/2507.03438v1",
    "categories": [
      "physics.hist-ph",
      "hep-ph"
    ]
  },
  {
    "arxiv_id": "1409.3358v1",
    "title": "Building Program Vector Representations for Deep Learning",
    "authors": [
      "Lili Mou",
      "Ge Li",
      "Yuxuan Liu",
      "Hao Peng",
      "Zhi Jin",
      "Yan Xu",
      "Lu Zhang"
    ],
    "abstract": "Deep learning has made significant breakthroughs in various fields of\nartificial intelligence. Advantages of deep learning include the ability to\ncapture highly complicated features, weak involvement of human engineering,\netc. However, it is still virtually impossible to use deep learning to analyze\nprograms since deep architectures cannot be trained effectively with pure back\npropagation. In this pioneering paper, we propose the \"coding criterion\" to\nbuild program vector representations, which are the premise of deep learning\nfor program analysis. Our representation learning approach directly makes deep\nlearning a reality in this new field. We evaluate the learned vector\nrepresentations both qualitatively and quantitatively. We conclude, based on\nthe experiments, the coding criterion is successful in building program\nrepresentations. To evaluate whether deep learning is beneficial for program\nanalysis, we feed the representations to deep neural networks, and achieve\nhigher accuracy in the program classification task than \"shallow\" methods, such\nas logistic regression and the support vector machine. This result confirms the\nfeasibility of deep learning to analyze programs. It also gives primary\nevidence of its success in this new field. We believe deep learning will become\nan outstanding technique for program analysis in the near future.",
    "published": "2014-09-11T08:44:28Z",
    "pdf_url": "http://arxiv.org/pdf/1409.3358v1",
    "categories": [
      "cs.SE",
      "cs.LG",
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "1904.05526v2",
    "title": "A Selective Overview of Deep Learning",
    "authors": [
      "Jianqing Fan",
      "Cong Ma",
      "Yiqiao Zhong"
    ],
    "abstract": "Deep learning has arguably achieved tremendous success in recent years. In\nsimple words, deep learning uses the composition of many nonlinear functions to\nmodel the complex dependency between input features and labels. While neural\nnetworks have a long history, recent advances have greatly improved their\nperformance in computer vision, natural language processing, etc. From the\nstatistical and scientific perspective, it is natural to ask: What is deep\nlearning? What are the new characteristics of deep learning, compared with\nclassical methods? What are the theoretical foundations of deep learning? To\nanswer these questions, we introduce common neural network models (e.g.,\nconvolutional neural nets, recurrent neural nets, generative adversarial nets)\nand training techniques (e.g., stochastic gradient descent, dropout, batch\nnormalization) from a statistical point of view. Along the way, we highlight\nnew characteristics of deep learning (including depth and over-parametrization)\nand explain their practical and theoretical benefits. We also sample recent\nresults on theories of deep learning, many of which are only suggestive. While\na complete understanding of deep learning remains elusive, we hope that our\nperspectives and discussions serve as a stimulus for new statistical research.",
    "published": "2019-04-10T17:53:15Z",
    "pdf_url": "http://arxiv.org/pdf/1904.05526v2",
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.ST",
      "stat.ME",
      "stat.TH"
    ]
  },
  {
    "arxiv_id": "1603.07846v1",
    "title": "Deep Learning At Scale and At Ease",
    "authors": [
      "Wei Wang",
      "Gang Chen",
      "Haibo Chen",
      "Tien Tuan Anh Dinh",
      "Jinyang Gao",
      "Beng Chin Ooi",
      "Kian-Lee Tan",
      "Sheng Wang"
    ],
    "abstract": "Recently, deep learning techniques have enjoyed success in various multimedia\napplications, such as image classification and multi-modal data analysis. Large\ndeep learning models are developed for learning rich representations of complex\ndata. There are two challenges to overcome before deep learning can be widely\nadopted in multimedia and other applications. One is usability, namely the\nimplementation of different models and training algorithms must be done by\nnon-experts without much effort especially when the model is large and complex.\nThe other is scalability, that is the deep learning system must be able to\nprovision for a huge demand of computing resources for training large models\nwith massive datasets. To address these two challenges, in this paper, we\ndesign a distributed deep learning platform called SINGA which has an intuitive\nprogramming model based on the common layer abstraction of deep learning\nmodels. Good scalability is achieved through flexible distributed training\narchitecture and specific optimization techniques. SINGA runs on GPUs as well\nas on CPUs, and we show that it outperforms many other state-of-the-art deep\nlearning systems. Our experience with developing and training deep learning\nmodels for real-life multimedia applications in SINGA shows that the platform\nis both usable and scalable.",
    "published": "2016-03-25T08:46:02Z",
    "pdf_url": "http://arxiv.org/pdf/1603.07846v1",
    "categories": [
      "cs.LG",
      "cs.DC"
    ]
  },
  {
    "arxiv_id": "1710.03959v1",
    "title": "Deep learning in remote sensing: a review",
    "authors": [
      "Xiao Xiang Zhu",
      "Devis Tuia",
      "Lichao Mou",
      "Gui-Song Xia",
      "Liangpei Zhang",
      "Feng Xu",
      "Friedrich Fraundorfer"
    ],
    "abstract": "Standing at the paradigm shift towards data-intensive science, machine\nlearning techniques are becoming increasingly important. In particular, as a\nmajor breakthrough in the field, deep learning has proven as an extremely\npowerful tool in many fields. Shall we embrace deep learning as the key to all?\nOr, should we resist a 'black-box' solution? There are controversial opinions\nin the remote sensing community. In this article, we analyze the challenges of\nusing deep learning for remote sensing data analysis, review the recent\nadvances, and provide resources to make deep learning in remote sensing\nridiculously simple to start with. More importantly, we advocate remote sensing\nscientists to bring their expertise into deep learning, and use it as an\nimplicit general model to tackle unprecedented large-scale influential\nchallenges, such as climate change and urbanization.",
    "published": "2017-10-11T08:35:05Z",
    "pdf_url": "http://arxiv.org/pdf/1710.03959v1",
    "categories": [
      "cs.CV",
      "eess.IV"
    ]
  },
  {
    "arxiv_id": "1805.01890v2",
    "title": "RMDL: Random Multimodel Deep Learning for Classification",
    "authors": [
      "Kamran Kowsari",
      "Mojtaba Heidarysafa",
      "Donald E. Brown",
      "Kiana Jafari Meimandi",
      "Laura E. Barnes"
    ],
    "abstract": "The continually increasing number of complex datasets each year necessitates\never improving machine learning methods for robust and accurate categorization\nof these data. This paper introduces Random Multimodel Deep Learning (RMDL): a\nnew ensemble, deep learning approach for classification. Deep learning models\nhave achieved state-of-the-art results across many domains. RMDL solves the\nproblem of finding the best deep learning structure and architecture while\nsimultaneously improving robustness and accuracy through ensembles of deep\nlearning architectures. RDML can accept as input a variety data to include\ntext, video, images, and symbolic. This paper describes RMDL and shows test\nresults for image and text data including MNIST, CIFAR-10, WOS, Reuters, IMDB,\nand 20newsgroup. These test results show that RDML produces consistently better\nperformance than standard methods over a broad range of data types and\nclassification problems.",
    "published": "2018-05-03T19:36:43Z",
    "pdf_url": "http://arxiv.org/pdf/1805.01890v2",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.NE",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1808.05077v1",
    "title": "Exploiting Deep Learning for Persian Sentiment Analysis",
    "authors": [
      "Kia Dashtipour",
      "Mandar Gogate",
      "Ahsan Adeel",
      "Cosimo Ieracitano",
      "Hadi Larijani",
      "Amir Hussain"
    ],
    "abstract": "The rise of social media is enabling people to freely express their opinions\nabout products and services. The aim of sentiment analysis is to automatically\ndetermine subject's sentiment (e.g., positive, negative, or neutral) towards a\nparticular aspect such as topic, product, movie, news etc. Deep learning has\nrecently emerged as a powerful machine learning technique to tackle a growing\ndemand of accurate sentiment analysis. However, limited work has been conducted\nto apply deep learning algorithms to languages other than English, such as\nPersian. In this work, two deep learning models (deep autoencoders and deep\nconvolutional neural networks (CNNs)) are developed and applied to a novel\nPersian movie reviews dataset. The proposed deep learning models are analyzed\nand compared with the state-of-the-art shallow multilayer perceptron (MLP)\nbased machine learning model. Simulation results demonstrate the enhanced\nperformance of deep learning over state-of-the-art MLP.",
    "published": "2018-08-15T13:46:54Z",
    "pdf_url": "http://arxiv.org/pdf/1808.05077v1",
    "categories": [
      "cs.CL",
      "I.2.7; I.5.0"
    ]
  },
  {
    "arxiv_id": "9705270v1",
    "title": "Neural Networks",
    "authors": [
      "Heinz Horner",
      "Reimer Kuehn"
    ],
    "abstract": "We review the theory of neural networks, as it has emerged in the last ten\nyears or so within the physics community, emphasizing questions of biological\nrelevance over those of importance in mathematical statistics and machine\nlearning theory.",
    "published": "1997-05-27T12:16:43Z",
    "pdf_url": "http://arxiv.org/pdf/cond-mat/9705270v1",
    "categories": [
      "cond-mat.dis-nn",
      "q-bio"
    ]
  },
  {
    "arxiv_id": "2106.13594v1",
    "title": "Bayesian Neural Networks: Essentials",
    "authors": [
      "Daniel T. Chang"
    ],
    "abstract": "Bayesian neural networks utilize probabilistic layers that capture\nuncertainty over weights and activations, and are trained using Bayesian\ninference. Since these probabilistic layers are designed to be drop-in\nreplacement of their deterministic counter parts, Bayesian neural networks\nprovide a direct and natural way to extend conventional deep neural networks to\nsupport probabilistic deep learning. However, it is nontrivial to understand,\ndesign and train Bayesian neural networks due to their complexities. We discuss\nthe essentials of Bayesian neural networks including duality (deep neural\nnetworks, probabilistic models), approximate Bayesian inference, Bayesian\npriors, Bayesian posteriors, and deep variational learning. We use TensorFlow\nProbability APIs and code examples for illustration. The main problem with\nBayesian neural networks is that the architecture of deep neural networks makes\nit quite redundant, and costly, to account for uncertainty for a large number\nof successive layers. Hybrid Bayesian neural networks, which use few\nprobabilistic layers judicially positioned in the networks, provide a practical\nsolution.",
    "published": "2021-06-22T13:54:17Z",
    "pdf_url": "http://arxiv.org/pdf/2106.13594v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1907.11569v4",
    "title": "Making Neural Networks FAIR",
    "authors": [
      "Anna Nguyen",
      "Tobias Weller",
      "Michael Färber",
      "York Sure-Vetter"
    ],
    "abstract": "Research on neural networks has gained significant momentum over the past few\nyears. Because training is a resource-intensive process and training data\ncannot always be made available to everyone, there has been a trend to reuse\npre-trained neural networks. As such, neural networks themselves have become\nresearch data. In this paper, we first present the neural network ontology\nFAIRnets Ontology, an ontology to make existing neural network models findable,\naccessible, interoperable, and reusable according to the FAIR principles. Our\nontology allows us to model neural networks on a meta-level in a structured\nway, including the representation of all network layers and their\ncharacteristics. Secondly, we have modeled over 18,400 neural networks from\nGitHub based on this ontology, which we provide to the public as a knowledge\ngraph called FAIRnets, ready to be used for recommending suitable neural\nnetworks to data scientists.",
    "published": "2019-07-26T13:30:02Z",
    "pdf_url": "http://arxiv.org/pdf/1907.11569v4",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2002.10078v3",
    "title": "On Hiding Neural Networks Inside Neural Networks",
    "authors": [
      "Chuan Guo",
      "Ruihan Wu",
      "Kilian Q. Weinberger"
    ],
    "abstract": "Modern neural networks often contain significantly more parameters than the\nsize of their training data. We show that this excess capacity provides an\nopportunity for embedding secret machine learning models within a trained\nneural network. Our novel framework hides the existence of a secret neural\nnetwork with arbitrary desired functionality within a carrier network. We prove\ntheoretically that the secret network's detection is computationally infeasible\nand demonstrate empirically that the carrier network does not compromise the\nsecret network's disguise. Our paper introduces a previously unknown\nsteganographic technique that can be exploited by adversaries if left\nunchecked.",
    "published": "2020-02-24T05:18:29Z",
    "pdf_url": "http://arxiv.org/pdf/2002.10078v3",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2304.05133v2",
    "title": "Lecture Notes: Neural Network Architectures",
    "authors": [
      "Evelyn Herberg"
    ],
    "abstract": "These lecture notes provide an overview of Neural Network architectures from\na mathematical point of view. Especially, Machine Learning with Neural Networks\nis seen as an optimization problem. Covered are an introduction to Neural\nNetworks and the following architectures: Feedforward Neural Network,\nConvolutional Neural Network, ResNet, and Recurrent Neural Network.",
    "published": "2023-04-11T10:54:36Z",
    "pdf_url": "http://arxiv.org/pdf/2304.05133v2",
    "categories": [
      "cs.LG",
      "math.OC",
      "68T07"
    ]
  },
  {
    "arxiv_id": "1908.08926v1",
    "title": "Efficient Deep Neural Networks",
    "authors": [
      "Bichen Wu"
    ],
    "abstract": "The success of deep neural networks (DNNs) is attributable to three factors:\nincreased compute capacity, more complex models, and more data. These factors,\nhowever, are not always present, especially for edge applications such as\nautonomous driving, augmented reality, and internet-of-things. Training DNNs\nrequires a large amount of data, which is difficult to obtain. Edge devices\nsuch as mobile phones have limited compute capacity, and therefore, require\nspecialized and efficient DNNs. However, due to the enormous design space and\nprohibitive training costs, designing efficient DNNs for different target\ndevices is challenging. So the question is, with limited data, compute\ncapacity, and model complexity, can we still successfully apply deep neural\nnetworks?\n  This dissertation focuses on the above problems and improving the efficiency\nof deep neural networks at four levels. Model efficiency: we designed neural\nnetworks for various computer vision tasks and achieved more than 10x faster\nspeed and lower energy. Data efficiency: we developed an advanced tool that\nenables 6.2x faster annotation of a LiDAR point cloud. We also leveraged domain\nadaptation to utilize simulated data, bypassing the need for real data.\nHardware efficiency: we co-designed neural networks and hardware accelerators\nand achieved 11.6x faster inference. Design efficiency: the process of finding\nthe optimal neural networks is time-consuming. Our automated neural\narchitecture search algorithms discovered, using 421x lower computational cost\nthan previous search methods, models with state-of-the-art accuracy and\nefficiency.",
    "published": "2019-08-20T23:26:04Z",
    "pdf_url": "http://arxiv.org/pdf/1908.08926v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2104.07106v1",
    "title": "On quantum neural networks",
    "authors": [
      "Alexandr A. Ezhov"
    ],
    "abstract": "The early definition of a quantum neural network as a new field that combines\nthe classical neurocomputing with quantum computing was rather vague and\nsatisfactory in the 2000s. The widespread in 2020 modern definition of a\nquantum neural network as a model or machine learning algorithm that combines\nthe functions of quantum computing with artificial neural networks deprives\nquantum neural networks of their fundamental importance. We argue that the\nconcept of a quantum neural network should be defined in terms of its most\ngeneral function as a tool for representing the amplitude of an arbitrary\nquantum process. Our reasoning is based on the use of the Feynman path integral\nformulation in quantum mechanics. This approach has been used in many works to\ninvestigate the main problem of quantum cosmology, such as the origin of the\nUniverse. In fact, the question of whether our Universe is a quantum computer\nwas posed by Seth Lloyd, who gave the answer is yes, but we argue that the\nuniverse can be thought of as a quantum neural network.",
    "published": "2021-04-12T18:30:30Z",
    "pdf_url": "http://arxiv.org/pdf/2104.07106v1",
    "categories": [
      "quant-ph"
    ]
  },
  {
    "arxiv_id": "2207.01578v2",
    "title": "Quantum Neural Network Compression",
    "authors": [
      "Zhirui Hu",
      "Peiyan Dong",
      "Zhepeng Wang",
      "Youzuo Lin",
      "Yanzhi Wang",
      "Weiwen Jiang"
    ],
    "abstract": "Model compression, such as pruning and quantization, has been widely applied\nto optimize neural networks on resource-limited classical devices. Recently,\nthere are growing interest in variational quantum circuits (VQC), that is, a\ntype of neural network on quantum computers (a.k.a., quantum neural networks).\nIt is well known that the near-term quantum devices have high noise and limited\nresources (i.e., quantum bits, qubits); yet, how to compress quantum neural\nnetworks has not been thoroughly studied. One might think it is straightforward\nto apply the classical compression techniques to quantum scenarios. However,\nthis paper reveals that there exist differences between the compression of\nquantum and classical neural networks. Based on our observations, we claim that\nthe compilation/traspilation has to be involved in the compression process. On\ntop of this, we propose the very first systematical framework, namely CompVQC,\nto compress quantum neural networks (QNNs).In CompVQC, the key component is a\nnovel compression algorithm, which is based on the alternating direction method\nof multipliers (ADMM) approach. Experiments demonstrate the advantage of the\nCompVQC, reducing the circuit depth (almost over 2.5 %) with a negligible\naccuracy drop (<1%), which outperforms other competitors. Another promising\ntruth is our CompVQC can indeed promote the robustness of the QNN on the\nnear-term noisy quantum devices.",
    "published": "2022-07-04T16:57:46Z",
    "pdf_url": "http://arxiv.org/pdf/2207.01578v2",
    "categories": [
      "quant-ph",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1801.07710v2",
    "title": "Bayesian Neural Networks",
    "authors": [
      "Vikram Mullachery",
      "Aniruddh Khera",
      "Amir Husain"
    ],
    "abstract": "This paper describes and discusses Bayesian Neural Network (BNN). The paper\nshowcases a few different applications of them for classification and\nregression problems. BNNs are comprised of a Probabilistic Model and a Neural\nNetwork. The intent of such a design is to combine the strengths of Neural\nNetworks and Stochastic modeling. Neural Networks exhibit continuous function\napproximator capabilities. Stochastic models allow direct specification of a\nmodel with known interaction between parameters to generate data. During the\nprediction phase, stochastic models generate a complete posterior distribution\nand produce probabilistic guarantees on the predictions. Thus BNNs are a unique\ncombination of neural network and stochastic models with the stochastic model\nforming the core of this integration. BNNs can then produce probabilistic\nguarantees on it's predictions and also generate the distribution of parameters\nthat it has learnt from the observations. That means, in the parameter space,\none can deduce the nature and shape of the neural network's learnt parameters.\nThese two characteristics makes them highly attractive to theoreticians as well\nas practitioners. Recently there has been a lot of activity in this area, with\nthe advent of numerous probabilistic programming libraries such as: PyMC3,\nEdward, Stan etc. Further this area is rapidly gaining ground as a standard\nmachine learning approach for numerous problems",
    "published": "2018-01-23T20:52:44Z",
    "pdf_url": "http://arxiv.org/pdf/1801.07710v2",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2105.03388v2",
    "title": "Hierarchical Graph Neural Networks",
    "authors": [
      "Stanislav Sobolevsky"
    ],
    "abstract": "Over the recent years, Graph Neural Networks have become increasingly popular\nin network analytic and beyond. With that, their architecture noticeable\ndiverges from the classical multi-layered hierarchical organization of the\ntraditional neural networks. At the same time, many conventional approaches in\nnetwork science efficiently utilize the hierarchical approaches to account for\nthe hierarchical organization of the networks, and recent works emphasize their\ncritical importance. This paper aims to connect the dots between the\ntraditional Neural Network and the Graph Neural Network architectures as well\nas the network science approaches, harnessing the power of the hierarchical\nnetwork organization. A Hierarchical Graph Neural Network architecture is\nproposed, supplementing the original input network layer with the hierarchy of\nauxiliary network layers and organizing the computational scheme updating the\nnode features through both - horizontal network connections within each layer\nas well as the vertical connection between the layers. It enables simultaneous\nlearning of the individual node features along with the aggregated network\nfeatures at variable resolution and uses them to improve the convergence and\nstability of the individual node feature learning. The proposed Hierarchical\nGraph Neural network architecture is successfully evaluated on the network\nembedding and modeling as well as network classification, node labeling, and\ncommunity tasks and demonstrates increased efficiency in those.",
    "published": "2021-05-07T16:47:18Z",
    "pdf_url": "http://arxiv.org/pdf/2105.03388v2",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.CO",
      "physics.data-an",
      "68T07, 05C85"
    ]
  },
  {
    "arxiv_id": "2206.05562v1",
    "title": "Parameter Convex Neural Networks",
    "authors": [
      "Jingcheng Zhou",
      "Wei Wei",
      "Xing Li",
      "Bowen Pang",
      "Zhiming Zheng"
    ],
    "abstract": "Deep learning utilizing deep neural networks (DNNs) has achieved a lot of\nsuccess recently in many important areas such as computer vision, natural\nlanguage processing, and recommendation systems. The lack of convexity for DNNs\nhas been seen as a major disadvantage of many optimization methods, such as\nstochastic gradient descent, which greatly reduces the genelization of neural\nnetwork applications. We realize that the convexity make sense in the neural\nnetwork and propose the exponential multilayer neural network (EMLP), a class\nof parameter convex neural network (PCNN) which is convex with regard to the\nparameters of the neural network under some conditions that can be realized.\nBesides, we propose the convexity metric for the two-layer EGCN and test the\naccuracy when the convexity metric changes. For late experiments, we use the\nsame architecture to make the exponential graph convolutional network (EGCN)\nand do the experiment on the graph classificaion dataset in which our model\nEGCN performs better than the graph convolutional network (GCN) and the graph\nattention network (GAT).",
    "published": "2022-06-11T16:44:59Z",
    "pdf_url": "http://arxiv.org/pdf/2206.05562v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1209.4855v1",
    "title": "The Future of Neural Networks",
    "authors": [
      "Sachin Lakra",
      "T. V. Prasad",
      "G. Ramakrishna"
    ],
    "abstract": "The paper describes some recent developments in neural networks and discusses\nthe applicability of neural networks in the development of a machine that\nmimics the human brain. The paper mentions a new architecture, the pulsed\nneural network that is being considered as the next generation of neural\nnetworks. The paper also explores the use of memristors in the development of a\nbrain-like computer called the MoNETA. A new model, multi/infinite dimensional\nneural networks, are a recent development in the area of advanced neural\nnetworks. The paper concludes that the need of neural networks in the\ndevelopment of human-like technology is essential and may be non-expendable for\nit.",
    "published": "2012-09-20T14:14:59Z",
    "pdf_url": "http://arxiv.org/pdf/1209.4855v1",
    "categories": [
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "1810.10627v2",
    "title": "Streaming Graph Neural Networks",
    "authors": [
      "Yao Ma",
      "Ziyi Guo",
      "Zhaochun Ren",
      "Eric Zhao",
      "Jiliang Tang",
      "Dawei Yin"
    ],
    "abstract": "Graphs are essential representations of many real-world data such as social\nnetworks. Recent years have witnessed the increasing efforts made to extend the\nneural network models to graph-structured data. These methods, which are\nusually known as the graph neural networks, have been applied to advance many\ngraphs related tasks such as reasoning dynamics of the physical system, graph\nclassification, and node classification. Most of the existing graph neural\nnetwork models have been designed for static graphs, while many real-world\ngraphs are inherently dynamic. For example, social networks are naturally\nevolving as new users joining and new relations being created. Current graph\nneural network models cannot utilize the dynamic information in dynamic graphs.\nHowever, the dynamic information has been proven to enhance the performance of\nmany graph analytic tasks such as community detection and link prediction.\nHence, it is necessary to design dedicated graph neural networks for dynamic\ngraphs. In this paper, we propose DGNN, a new {\\bf D}ynamic {\\bf G}raph {\\bf\nN}eural {\\bf N}etwork model, which can model the dynamic information as the\ngraph evolving. In particular, the proposed framework can keep updating node\ninformation by capturing the sequential information of edges (interactions),\nthe time intervals between edges and information propagation coherently.\nExperimental results on various dynamic graphs demonstrate the effectiveness of\nthe proposed framework.",
    "published": "2018-10-24T21:20:05Z",
    "pdf_url": "http://arxiv.org/pdf/1810.10627v2",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2310.10013v1",
    "title": "Riemannian Residual Neural Networks",
    "authors": [
      "Isay Katsman",
      "Eric Ming Chen",
      "Sidhanth Holalkere",
      "Anna Asch",
      "Aaron Lou",
      "Ser-Nam Lim",
      "Christopher De Sa"
    ],
    "abstract": "Recent methods in geometric deep learning have introduced various neural\nnetworks to operate over data that lie on Riemannian manifolds. Such networks\nare often necessary to learn well over graphs with a hierarchical structure or\nto learn over manifold-valued data encountered in the natural sciences. These\nnetworks are often inspired by and directly generalize standard Euclidean\nneural networks. However, extending Euclidean networks is difficult and has\nonly been done for a select few manifolds. In this work, we examine the\nresidual neural network (ResNet) and show how to extend this construction to\ngeneral Riemannian manifolds in a geometrically principled manner. Originally\nintroduced to help solve the vanishing gradient problem, ResNets have become\nubiquitous in machine learning due to their beneficial learning properties,\nexcellent empirical results, and easy-to-incorporate nature when building\nvaried neural networks. We find that our Riemannian ResNets mirror these\ndesirable properties: when compared to existing manifold neural networks\ndesigned to learn over hyperbolic space and the manifold of symmetric positive\ndefinite matrices, we outperform both kinds of networks in terms of relevant\ntesting metrics and training dynamics.",
    "published": "2023-10-16T02:12:32Z",
    "pdf_url": "http://arxiv.org/pdf/2310.10013v1",
    "categories": [
      "stat.ML",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2405.03725v2",
    "title": "Deep Oscillatory Neural Network",
    "authors": [
      "Nurani Rajagopal Rohan",
      "Vigneswaran C",
      "Sayan Ghosh",
      "Kishore Rajendran",
      "Gaurav A",
      "V Srinivasa Chakravarthy"
    ],
    "abstract": "We propose a novel, brain-inspired deep neural network model known as the\nDeep Oscillatory Neural Network (DONN). Deep neural networks like the Recurrent\nNeural Networks indeed possess sequence processing capabilities but the\ninternal states of the network are not designed to exhibit brain-like\noscillatory activity. With this motivation, the DONN is designed to have\noscillatory internal dynamics. Neurons of the DONN are either nonlinear neural\noscillators or traditional neurons with sigmoidal or ReLU activation. The\nneural oscillator used in the model is the Hopf oscillator, with the dynamics\ndescribed in the complex domain. Input can be presented to the neural\noscillator in three possible modes. The sigmoid and ReLU neurons also use\ncomplex-valued extensions. All the weight stages are also complex-valued.\nTraining follows the general principle of weight change by minimizing the\noutput error and therefore has an overall resemblance to complex\nbackpropagation. A generalization of DONN to convolutional networks known as\nthe Oscillatory Convolutional Neural Network is also proposed. The two proposed\noscillatory networks are applied to a variety of benchmark problems in signal\nand image/video processing. The performance of the proposed models is either\ncomparable or superior to published results on the same data sets.",
    "published": "2024-05-06T06:17:16Z",
    "pdf_url": "http://arxiv.org/pdf/2405.03725v2",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2412.14695v2",
    "title": "Lorentzian Residual Neural Networks",
    "authors": [
      "Neil He",
      "Menglin Yang",
      "Rex Ying"
    ],
    "abstract": "Hyperbolic neural networks have emerged as a powerful tool for modeling\nhierarchical data structures prevalent in real-world datasets. Notably,\nresidual connections, which facilitate the direct flow of information across\nlayers, have been instrumental in the success of deep neural networks. However,\ncurrent methods for constructing hyperbolic residual networks suffer from\nlimitations such as increased model complexity, numerical instability, and\nerrors due to multiple mappings to and from the tangent space. To address these\nlimitations, we introduce LResNet, a novel Lorentzian residual neural network\nbased on the weighted Lorentzian centroid in the Lorentz model of hyperbolic\ngeometry. Our method enables the efficient integration of residual connections\nin Lorentz hyperbolic neural networks while preserving their hierarchical\nrepresentation capabilities. We demonstrate that our method can theoretically\nderive previous methods while offering improved stability, efficiency, and\neffectiveness. Extensive experiments on both graph and vision tasks showcase\nthe superior performance and robustness of our method compared to\nstate-of-the-art Euclidean and hyperbolic alternatives. Our findings highlight\nthe potential of LResNet for building more expressive neural networks in\nhyperbolic embedding space as a generally applicable method to multiple\narchitectures, including CNNs, GNNs, and graph Transformers.",
    "published": "2024-12-19T09:56:01Z",
    "pdf_url": "http://arxiv.org/pdf/2412.14695v2",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1609.07152v3",
    "title": "Input Convex Neural Networks",
    "authors": [
      "Brandon Amos",
      "Lei Xu",
      "J. Zico Kolter"
    ],
    "abstract": "This paper presents the input convex neural network architecture. These are\nscalar-valued (potentially deep) neural networks with constraints on the\nnetwork parameters such that the output of the network is a convex function of\n(some of) the inputs. The networks allow for efficient inference via\noptimization over some inputs to the network given others, and can be applied\nto settings including structured prediction, data imputation, reinforcement\nlearning, and others. In this paper we lay the basic groundwork for these\nmodels, proposing methods for inference, optimization and learning, and analyze\ntheir representational power. We show that many existing neural network\narchitectures can be made input-convex with a minor modification, and develop\nspecialized optimization algorithms tailored to this setting. Finally, we\nhighlight the performance of the methods on multi-label prediction, image\ncompletion, and reinforcement learning problems, where we show improvement over\nthe existing state of the art in many cases.",
    "published": "2016-09-22T20:10:57Z",
    "pdf_url": "http://arxiv.org/pdf/1609.07152v3",
    "categories": [
      "cs.LG",
      "math.OC"
    ]
  },
  {
    "arxiv_id": "1711.00449v2",
    "title": "Attacking Binarized Neural Networks",
    "authors": [
      "Angus Galloway",
      "Graham W. Taylor",
      "Medhat Moussa"
    ],
    "abstract": "Neural networks with low-precision weights and activations offer compelling\nefficiency advantages over their full-precision equivalents. The two most\nfrequently discussed benefits of quantization are reduced memory consumption,\nand a faster forward pass when implemented with efficient bitwise operations.\nWe propose a third benefit of very low-precision neural networks: improved\nrobustness against some adversarial attacks, and in the worst case, performance\nthat is on par with full-precision models. We focus on the very low-precision\ncase where weights and activations are both quantized to $\\pm$1, and note that\nstochastically quantizing weights in just one layer can sharply reduce the\nimpact of iterative attacks. We observe that non-scaled binary neural networks\nexhibit a similar effect to the original defensive distillation procedure that\nled to gradient masking, and a false notion of security. We address this by\nconducting both black-box and white-box experiments with binary models that do\nnot artificially mask gradients.",
    "published": "2017-11-01T17:28:26Z",
    "pdf_url": "http://arxiv.org/pdf/1711.00449v2",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1908.05164v3",
    "title": "Unconstrained Monotonic Neural Networks",
    "authors": [
      "Antoine Wehenkel",
      "Gilles Louppe"
    ],
    "abstract": "Monotonic neural networks have recently been proposed as a way to define\ninvertible transformations. These transformations can be combined into powerful\nautoregressive flows that have been shown to be universal approximators of\ncontinuous probability distributions. Architectures that ensure monotonicity\ntypically enforce constraints on weights and activation functions, which\nenables invertibility but leads to a cap on the expressiveness of the resulting\ntransformations. In this work, we propose the Unconstrained Monotonic Neural\nNetwork (UMNN) architecture based on the insight that a function is monotonic\nas long as its derivative is strictly positive. In particular, this latter\ncondition can be enforced with a free-form neural network whose only constraint\nis the positiveness of its output. We evaluate our new invertible building\nblock within a new autoregressive flow (UMNN-MAF) and demonstrate its\neffectiveness on density estimation experiments. We also illustrate the ability\nof UMNNs to improve variational inference.",
    "published": "2019-08-14T15:11:31Z",
    "pdf_url": "http://arxiv.org/pdf/1908.05164v3",
    "categories": [
      "cs.LG",
      "cs.NE",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2006.06629v1",
    "title": "Growing Artificial Neural Networks",
    "authors": [
      "John Mixter",
      "Ali Akoglu"
    ],
    "abstract": "Pruning is a legitimate method for reducing the size of a neural network to\nfit in low SWaP hardware, but the networks must be trained and pruned offline.\nWe propose an algorithm, Artificial Neurogenesis (ANG), that grows rather than\nprunes the network and enables neural networks to be trained and executed in\nlow SWaP embedded hardware. ANG accomplishes this by using the training data to\ndetermine critical connections between layers before the actual training takes\nplace. Our experiments use a modified LeNet-5 as a baseline neural network that\nachieves a test accuracy of 98.74% using a total of 61,160 weights. An ANG\ngrown network achieves a test accuracy of 98.80% with only 21,211 weights.",
    "published": "2020-06-11T17:25:51Z",
    "pdf_url": "http://arxiv.org/pdf/2006.06629v1",
    "categories": [
      "cs.NE",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1809.03368v1",
    "title": "Probabilistic Binary Neural Networks",
    "authors": [
      "Jorn W. T. Peters",
      "Max Welling"
    ],
    "abstract": "Low bit-width weights and activations are an effective way of combating the\nincreasing need for both memory and compute power of Deep Neural Networks. In\nthis work, we present a probabilistic training method for Neural Network with\nboth binary weights and activations, called BLRNet. By embracing stochasticity\nduring training, we circumvent the need to approximate the gradient of\nnon-differentiable functions such as sign(), while still obtaining a fully\nBinary Neural Network at test time. Moreover, it allows for anytime ensemble\npredictions for improved performance and uncertainty estimates by sampling from\nthe weight distribution. Since all operations in a layer of the BLRNet operate\non random variables, we introduce stochastic versions of Batch Normalization\nand max pooling, which transfer well to a deterministic network at test time.\nWe evaluate the BLRNet on multiple standardized benchmarks.",
    "published": "2018-09-10T14:51:08Z",
    "pdf_url": "http://arxiv.org/pdf/1809.03368v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1907.00262v1",
    "title": "Dissecting Pruned Neural Networks",
    "authors": [
      "Jonathan Frankle",
      "David Bau"
    ],
    "abstract": "Pruning is a standard technique for removing unnecessary structure from a\nneural network to reduce its storage footprint, computational demands, or\nenergy consumption. Pruning can reduce the parameter-counts of many\nstate-of-the-art neural networks by an order of magnitude without compromising\naccuracy, meaning these networks contain a vast amount of unnecessary\nstructure. In this paper, we study the relationship between pruning and\ninterpretability. Namely, we consider the effect of removing unnecessary\nstructure on the number of hidden units that learn disentangled representations\nof human-recognizable concepts as identified by network dissection. We aim to\nevaluate how the interpretability of pruned neural networks changes as they are\ncompressed. We find that pruning has no detrimental effect on this measure of\ninterpretability until so few parameters remain that accuracy beings to drop.\nResnet-50 models trained on ImageNet maintain the same number of interpretable\nconcepts and units until more than 90% of parameters have been pruned.",
    "published": "2019-06-29T19:27:57Z",
    "pdf_url": "http://arxiv.org/pdf/1907.00262v1",
    "categories": [
      "cs.LG",
      "cs.CV",
      "cs.NE",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1910.03879v2",
    "title": "Dissecting Deep Neural Networks",
    "authors": [
      "Haakon Robinson",
      "Adil Rasheed",
      "Omer San"
    ],
    "abstract": "In exchange for large quantities of data and processing power, deep neural\nnetworks have yielded models that provide state of the art predication\ncapabilities in many fields. However, a lack of strong guarantees on their\nbehaviour have raised concerns over their use in safety-critical applications.\nA first step to understanding these networks is to develop alternate\nrepresentations that allow for further analysis. It has been shown that neural\nnetworks with piecewise affine activation functions are themselves piecewise\naffine, with their domains consisting of a vast number of linear regions. So\nfar, the research on this topic has focused on counting the number of linear\nregions, rather than obtaining explicit piecewise affine representations. This\nwork presents a novel algorithm that can compute the piecewise affine form of\nany fully connected neural network with rectified linear unit activations.",
    "published": "2019-10-09T10:05:23Z",
    "pdf_url": "http://arxiv.org/pdf/1910.03879v2",
    "categories": [
      "cs.LG",
      "cs.NE",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2002.02815v1",
    "title": "Switchable Precision Neural Networks",
    "authors": [
      "Luis Guerra",
      "Bohan Zhuang",
      "Ian Reid",
      "Tom Drummond"
    ],
    "abstract": "Instantaneous and on demand accuracy-efficiency trade-off has been recently\nexplored in the context of neural networks slimming. In this paper, we propose\na flexible quantization strategy, termed Switchable Precision neural Networks\n(SP-Nets), to train a shared network capable of operating at multiple\nquantization levels. At runtime, the network can adjust its precision on the\nfly according to instant memory, latency, power consumption and accuracy\ndemands. For example, by constraining the network weights to 1-bit with\nswitchable precision activations, our shared network spans from BinaryConnect\nto Binarized Neural Network, allowing to perform dot-products using only\nsummations or bit operations. In addition, a self-distillation scheme is\nproposed to increase the performance of the quantized switches. We tested our\napproach with three different quantizers and demonstrate the performance of\nSP-Nets against independently trained quantized models in classification\naccuracy for Tiny ImageNet and ImageNet datasets using ResNet-18 and MobileNet\narchitectures.",
    "published": "2020-02-07T14:43:44Z",
    "pdf_url": "http://arxiv.org/pdf/2002.02815v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2010.11189v2",
    "title": "Quantum Deformed Neural Networks",
    "authors": [
      "Roberto Bondesan",
      "Max Welling"
    ],
    "abstract": "We develop a new quantum neural network layer designed to run efficiently on\na quantum computer but that can be simulated on a classical computer when\nrestricted in the way it entangles input states. We first ask how a classical\nneural network architecture, both fully connected or convolutional, can be\nexecuted on a quantum computer using quantum phase estimation. We then deform\nthe classical layer into a quantum design which entangles activations and\nweights into quantum superpositions. While the full model would need the\nexponential speedups delivered by a quantum computer, a restricted class of\ndesigns represent interesting new classical network layers that still use\nquantum features. We show that these quantum deformed neural networks can be\ntrained and executed on normal data such as images, and even classically\ndeliver modest improvements over standard architectures.",
    "published": "2020-10-21T09:46:12Z",
    "pdf_url": "http://arxiv.org/pdf/2010.11189v2",
    "categories": [
      "quant-ph",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2209.03416v5",
    "title": "Bispectral Neural Networks",
    "authors": [
      "Sophia Sanborn",
      "Christian Shewmake",
      "Bruno Olshausen",
      "Christopher Hillar"
    ],
    "abstract": "We present a neural network architecture, Bispectral Neural Networks (BNNs)\nfor learning representations that are invariant to the actions of compact\ncommutative groups on the space over which a signal is defined. The model\nincorporates the ansatz of the bispectrum, an analytically defined group\ninvariant that is complete -- that is, it preserves all signal structure while\nremoving only the variation due to group actions. Here, we demonstrate that\nBNNs are able to simultaneously learn groups, their irreducible\nrepresentations, and corresponding equivariant and complete-invariant maps\npurely from the symmetries implicit in data. Further, we demonstrate that the\ncompleteness property endows these networks with strong invariance-based\nadversarial robustness. This work establishes Bispectral Neural Networks as a\npowerful computational primitive for robust invariant representation learning",
    "published": "2022-09-07T18:34:48Z",
    "pdf_url": "http://arxiv.org/pdf/2209.03416v5",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2012.06800v1",
    "title": "Delay Differential Neural Networks",
    "authors": [
      "Srinivas Anumasa",
      "P. K. Srijith"
    ],
    "abstract": "Neural ordinary differential equations (NODEs) treat computation of\nintermediate feature vectors as trajectories of ordinary differential equation\nparameterized by a neural network. In this paper, we propose a novel model,\ndelay differential neural networks (DDNN), inspired by delay differential\nequations (DDEs). The proposed model considers the derivative of the hidden\nfeature vector as a function of the current feature vector and past feature\nvectors (history). The function is modelled as a neural network and\nconsequently, it leads to continuous depth alternatives to many recent ResNet\nvariants. We propose two different DDNN architectures, depending on the way\ncurrent and past feature vectors are considered. For training DDNNs, we provide\na memory-efficient adjoint method for computing gradients and back-propagate\nthrough the network. DDNN improves the data efficiency of NODE by further\nreducing the number of parameters without affecting the generalization\nperformance. Experiments conducted on synthetic and real-world image\nclassification datasets such as Cifar10 and Cifar100 show the effectiveness of\nthe proposed models.",
    "published": "2020-12-12T12:20:54Z",
    "pdf_url": "http://arxiv.org/pdf/2012.06800v1",
    "categories": [
      "cs.LG",
      "cs.CV",
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "2102.10472v3",
    "title": "Learning Neural Network Subspaces",
    "authors": [
      "Mitchell Wortsman",
      "Maxwell Horton",
      "Carlos Guestrin",
      "Ali Farhadi",
      "Mohammad Rastegari"
    ],
    "abstract": "Recent observations have advanced our understanding of the neural network\noptimization landscape, revealing the existence of (1) paths of high accuracy\ncontaining diverse solutions and (2) wider minima offering improved\nperformance. Previous methods observing diverse paths require multiple training\nruns. In contrast we aim to leverage both property (1) and (2) with a single\nmethod and in a single training run. With a similar computational cost as\ntraining one model, we learn lines, curves, and simplexes of high-accuracy\nneural networks. These neural network subspaces contain diverse solutions that\ncan be ensembled, approaching the ensemble performance of independently trained\nnetworks without the training cost. Moreover, using the subspace midpoint\nboosts accuracy, calibration, and robustness to label noise, outperforming\nStochastic Weight Averaging.",
    "published": "2021-02-20T23:26:58Z",
    "pdf_url": "http://arxiv.org/pdf/2102.10472v3",
    "categories": [
      "cs.LG",
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2106.13834v2",
    "title": "Ladder Polynomial Neural Networks",
    "authors": [
      "Li-Ping Liu",
      "Ruiyuan Gu",
      "Xiaozhe Hu"
    ],
    "abstract": "Polynomial functions have plenty of useful analytical properties, but they\nare rarely used as learning models because their function class is considered\nto be restricted. This work shows that when trained properly polynomial\nfunctions can be strong learning models. Particularly this work constructs\npolynomial feedforward neural networks using the product activation, a new\nactivation function constructed from multiplications. The new neural network is\na polynomial function and provides accurate control of its polynomial order. It\ncan be trained by standard training techniques such as batch normalization and\ndropout. This new feedforward network covers several previous polynomial models\nas special cases. Compared with common feedforward neural networks, the\npolynomial feedforward network has closed-form calculations of a few\ninteresting quantities, which are very useful in Bayesian learning. In a series\nof regression and classification tasks in the empirical study, the proposed\nmodel outperforms previous polynomial models.",
    "published": "2021-06-25T18:16:48Z",
    "pdf_url": "http://arxiv.org/pdf/2106.13834v2",
    "categories": [
      "cs.LG",
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "2210.02113v3",
    "title": "Optimization-Informed Neural Networks",
    "authors": [
      "Dawen Wu",
      "Abdel Lisser"
    ],
    "abstract": "Solving constrained nonlinear optimization problems (CNLPs) is a longstanding\nproblem that arises in various fields, e.g., economics, computer science, and\nengineering. We propose optimization-informed neural networks (OINN), a deep\nlearning approach to solve CNLPs. By neurodynamic optimization methods, a CNLP\nis first reformulated as an initial value problem (IVP) involving an ordinary\ndifferential equation (ODE) system. A neural network model is then used as an\napproximate solution for this IVP, with the endpoint being the prediction to\nthe CNLP. We propose a novel training algorithm that directs the model to hold\nthe best prediction during training. In a nutshell, OINN transforms a CNLP into\na neural network training problem. By doing so, we can solve CNLPs based on\ndeep learning infrastructure only, without using standard optimization solvers\nor numerical integration solvers. The effectiveness of the proposed approach is\ndemonstrated through a collection of classical problems, e.g., variational\ninequalities, nonlinear complementary problems, and standard CNLPs.",
    "published": "2022-10-05T09:28:55Z",
    "pdf_url": "http://arxiv.org/pdf/2210.02113v3",
    "categories": [
      "math.OC",
      "cs.LG",
      "cs.NA",
      "math.NA"
    ]
  },
  {
    "arxiv_id": "2211.14632v1",
    "title": "Why Neural Networks Work",
    "authors": [
      "Sayandev Mukherjee",
      "Bernardo A. Huberman"
    ],
    "abstract": "We argue that many properties of fully-connected feedforward neural networks\n(FCNNs), also called multi-layer perceptrons (MLPs), are explainable from the\nanalysis of a single pair of operations, namely a random projection into a\nhigher-dimensional space than the input, followed by a sparsification\noperation. For convenience, we call this pair of successive operations\nexpand-and-sparsify following the terminology of Dasgupta. We show how\nexpand-and-sparsify can explain the observed phenomena that have been discussed\nin the literature, such as the so-called Lottery Ticket Hypothesis, the\nsurprisingly good performance of randomly-initialized untrained neural\nnetworks, the efficacy of Dropout in training and most importantly, the\nmysterious generalization ability of overparameterized models, first\nhighlighted by Zhang et al. and subsequently identified even in non-neural\nnetwork models by Belkin et al.",
    "published": "2022-11-26T18:15:17Z",
    "pdf_url": "http://arxiv.org/pdf/2211.14632v1",
    "categories": [
      "cs.LG",
      "cs.CY",
      "cs.NE",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2307.04526v3",
    "title": "Self-Expanding Neural Networks",
    "authors": [
      "Rupert Mitchell",
      "Robin Menzenbach",
      "Kristian Kersting",
      "Martin Mundt"
    ],
    "abstract": "The results of training a neural network are heavily dependent on the\narchitecture chosen; and even a modification of only its size, however small,\ntypically involves restarting the training process. In contrast to this, we\nbegin training with a small architecture, only increase its capacity as\nnecessary for the problem, and avoid interfering with previous optimization\nwhile doing so. We thereby introduce a natural gradient based approach which\nintuitively expands both the width and depth of a neural network when this is\nlikely to substantially reduce the hypothetical converged training loss. We\nprove an upper bound on the ``rate'' at which neurons are added, and a\ncomputationally cheap lower bound on the expansion score. We illustrate the\nbenefits of such Self-Expanding Neural Networks with full connectivity and\nconvolutions in both classification and regression problems, including those\nwhere the appropriate architecture size is substantially uncertain a priori.",
    "published": "2023-07-10T12:49:59Z",
    "pdf_url": "http://arxiv.org/pdf/2307.04526v3",
    "categories": [
      "cs.LG",
      "I.2.6"
    ]
  },
  {
    "arxiv_id": "2402.13144v3",
    "title": "Neural Network Diffusion",
    "authors": [
      "Kai Wang",
      "Dongwen Tang",
      "Boya Zeng",
      "Yida Yin",
      "Zhaopan Xu",
      "Yukun Zhou",
      "Zelin Zang",
      "Trevor Darrell",
      "Zhuang Liu",
      "Yang You"
    ],
    "abstract": "Diffusion models have achieved remarkable success in image and video\ngeneration. In this work, we demonstrate that diffusion models can also\n\\textit{generate high-performing neural network parameters}. Our approach is\nsimple, utilizing an autoencoder and a diffusion model. The autoencoder\nextracts latent representations of a subset of the trained neural network\nparameters. Next, a diffusion model is trained to synthesize these latent\nrepresentations from random noise. This model then generates new\nrepresentations, which are passed through the autoencoder's decoder to produce\nnew subsets of high-performing network parameters. Across various architectures\nand datasets, our approach consistently generates models with comparable or\nimproved performance over trained networks, with minimal additional cost.\nNotably, we empirically find that the generated models are not memorizing the\ntrained ones. Our results encourage more exploration into the versatile use of\ndiffusion models. Our code is available\n\\href{https://github.com/NUS-HPC-AI-Lab/Neural-Network-Diffusion}{here}.",
    "published": "2024-02-20T16:59:03Z",
    "pdf_url": "http://arxiv.org/pdf/2402.13144v3",
    "categories": [
      "cs.LG",
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2508.14101v1",
    "title": "Implicit Hypergraph Neural Network",
    "authors": [
      "Akash Choudhuri",
      "Yongjian Zhong",
      "Bijaya Adhikari"
    ],
    "abstract": "Hypergraphs offer a generalized framework for capturing high-order\nrelationships between entities and have been widely applied in various domains,\nincluding healthcare, social networks, and bioinformatics. Hypergraph neural\nnetworks, which rely on message-passing between nodes over hyperedges to learn\nlatent representations, have emerged as the method of choice for predictive\ntasks in many of these domains. These approaches typically perform only a small\nnumber of message-passing rounds to learn the representations, which they then\nutilize for predictions. The small number of message-passing rounds comes at a\ncost, as the representations only capture local information and forego\nlong-range high-order dependencies. However, as we demonstrate, blindly\nincreasing the message-passing rounds to capture long-range dependency also\ndegrades the performance of hyper-graph neural networks.\n  Recent works have demonstrated that implicit graph neural networks capture\nlong-range dependencies in standard graphs while maintaining performance.\nDespite their popularity, prior work has not studied long-range dependency\nissues on hypergraph neural networks. Here, we first demonstrate that existing\nhypergraph neural networks lose predictive power when aggregating more\ninformation to capture long-range dependency. We then propose Implicit\nHypergraph Neural Network (IHNN), a novel framework that jointly learns\nfixed-point representations for both nodes and hyperedges in an end-to-end\nmanner to alleviate this issue. Leveraging implicit differentiation, we\nintroduce a tractable projected gradient descent approach to train the model\nefficiently. Extensive experiments on real-world hypergraphs for node\nclassification demonstrate that IHNN outperforms the closest prior works in\nmost settings, establishing a new state-of-the-art in hypergraph learning.",
    "published": "2025-08-16T16:58:59Z",
    "pdf_url": "http://arxiv.org/pdf/2508.14101v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1705.08557v1",
    "title": "Grounded Recurrent Neural Networks",
    "authors": [
      "Ankit Vani",
      "Yacine Jernite",
      "David Sontag"
    ],
    "abstract": "In this work, we present the Grounded Recurrent Neural Network (GRNN), a\nrecurrent neural network architecture for multi-label prediction which\nexplicitly ties labels to specific dimensions of the recurrent hidden state (we\ncall this process \"grounding\"). The approach is particularly well-suited for\nextracting large numbers of concepts from text. We apply the new model to\naddress an important problem in healthcare of understanding what medical\nconcepts are discussed in clinical text. Using a publicly available dataset\nderived from Intensive Care Units, we learn to label a patient's diagnoses and\nprocedures from their discharge summary. Our evaluation shows a clear advantage\nto using our proposed architecture over a variety of strong baselines.",
    "published": "2017-05-23T23:17:49Z",
    "pdf_url": "http://arxiv.org/pdf/1705.08557v1",
    "categories": [
      "stat.ML",
      "cs.CL",
      "cs.LG",
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "1706.07966v1",
    "title": "Irregular Convolutional Neural Networks",
    "authors": [
      "Jiabin Ma",
      "Wei Wang",
      "Liang Wang"
    ],
    "abstract": "Convolutional kernels are basic and vital components of deep Convolutional\nNeural Networks (CNN). In this paper, we equip convolutional kernels with shape\nattributes to generate the deep Irregular Convolutional Neural Networks (ICNN).\nCompared to traditional CNN applying regular convolutional kernels like\n${3\\times3}$, our approach trains irregular kernel shapes to better fit the\ngeometric variations of input features. In other words, shapes are learnable\nparameters in addition to weights. The kernel shapes and weights are learned\nsimultaneously during end-to-end training with the standard back-propagation\nalgorithm. Experiments for semantic segmentation are implemented to validate\nthe effectiveness of our proposed ICNN.",
    "published": "2017-06-24T14:19:41Z",
    "pdf_url": "http://arxiv.org/pdf/1706.07966v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1712.05245v2",
    "title": "Pointwise Convolutional Neural Networks",
    "authors": [
      "Binh-Son Hua",
      "Minh-Khoi Tran",
      "Sai-Kit Yeung"
    ],
    "abstract": "Deep learning with 3D data such as reconstructed point clouds and CAD models\nhas received great research interests recently. However, the capability of\nusing point clouds with convolutional neural network has been so far not fully\nexplored. In this paper, we present a convolutional neural network for semantic\nsegmentation and object recognition with 3D point clouds. At the core of our\nnetwork is pointwise convolution, a new convolution operator that can be\napplied at each point of a point cloud. Our fully convolutional network design,\nwhile being surprisingly simple to implement, can yield competitive accuracy in\nboth semantic segmentation and object recognition task.",
    "published": "2017-12-14T14:25:52Z",
    "pdf_url": "http://arxiv.org/pdf/1712.05245v2",
    "categories": [
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1805.06082v2",
    "title": "Optical Neural Networks",
    "authors": [
      "Grant Fennessy",
      "Yevgeniy Vorobeychik"
    ],
    "abstract": "We develop a novel optical neural network (ONN) framework which introduces a\ndegree of scalar invariance to image classification estima- tion. Taking a hint\nfrom the human eye, which has higher resolution near the center of the retina,\nimages are broken out into multiple levels of varying zoom based on a focal\npoint. Each level is passed through an identical convolutional neural network\n(CNN) in a Siamese fashion, and the results are recombined to produce a high\naccuracy estimate of the object class. ONNs act as a wrapper around existing\nCNNs, and can thus be applied to many existing algorithms to produce notable\naccuracy improvements without having to change the underlying architecture.",
    "published": "2018-05-16T01:12:11Z",
    "pdf_url": "http://arxiv.org/pdf/1805.06082v2",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1904.03955v2",
    "title": "Kervolutional Neural Networks",
    "authors": [
      "Chen Wang",
      "Jianfei Yang",
      "Lihua Xie",
      "Junsong Yuan"
    ],
    "abstract": "Convolutional neural networks (CNNs) have enabled the state-of-the-art\nperformance in many computer vision tasks. However, little effort has been\ndevoted to establishing convolution in non-linear space. Existing works mainly\nleverage on the activation layers, which can only provide point-wise\nnon-linearity. To solve this problem, a new operation, kervolution (kernel\nconvolution), is introduced to approximate complex behaviors of human\nperception systems leveraging on the kernel trick. It generalizes convolution,\nenhances the model capacity, and captures higher order interactions of\nfeatures, via patch-wise kernel functions, but without introducing additional\nparameters. Extensive experiments show that kervolutional neural networks (KNN)\nachieve higher accuracy and faster convergence than baseline CNN.",
    "published": "2019-04-08T11:10:51Z",
    "pdf_url": "http://arxiv.org/pdf/1904.03955v2",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1904.07785v1",
    "title": "Graph Wavelet Neural Network",
    "authors": [
      "Bingbing Xu",
      "Huawei Shen",
      "Qi Cao",
      "Yunqi Qiu",
      "Xueqi Cheng"
    ],
    "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional\nneural network (CNN), leveraging graph wavelet transform to address the\nshortcomings of previous spectral graph CNN methods that depend on graph\nFourier transform. Different from graph Fourier transform, graph wavelet\ntransform can be obtained via a fast algorithm without requiring matrix\neigendecomposition with high computational cost. Moreover, graph wavelets are\nsparse and localized in vertex domain, offering high efficiency and good\ninterpretability for graph convolution. The proposed GWNN significantly\noutperforms previous spectral graph CNNs in the task of graph-based\nsemi-supervised classification on three benchmark datasets: Cora, Citeseer and\nPubmed.",
    "published": "2019-04-12T08:20:08Z",
    "pdf_url": "http://arxiv.org/pdf/1904.07785v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1909.13334v2",
    "title": "Symplectic Recurrent Neural Networks",
    "authors": [
      "Zhengdao Chen",
      "Jianyu Zhang",
      "Martin Arjovsky",
      "Léon Bottou"
    ],
    "abstract": "We propose Symplectic Recurrent Neural Networks (SRNNs) as learning\nalgorithms that capture the dynamics of physical systems from observed\ntrajectories. An SRNN models the Hamiltonian function of the system by a neural\nnetwork and furthermore leverages symplectic integration, multiple-step\ntraining and initial state optimization to address the challenging numerical\nissues associated with Hamiltonian systems. We show that SRNNs succeed reliably\non complex and noisy Hamiltonian systems. We also show how to augment the SRNN\nintegration scheme in order to handle stiff dynamical systems such as bouncing\nbilliards.",
    "published": "2019-09-29T18:04:07Z",
    "pdf_url": "http://arxiv.org/pdf/1909.13334v2",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2011.05062v2",
    "title": "Quantum Spike Neural Network",
    "authors": [
      "Yanhu Chen",
      "Hongxiang Guo",
      "Cen Wang",
      "Xiong Gao",
      "Jian Wu"
    ],
    "abstract": "Utilizing quantum computers to deploy artificial neural networks (ANNs) will\nbring the potential of significant advancements in both speed and scale. In\nthis paper, we propose a kind of quantum spike neural networks (SNNs) as well\nas comprehensively evaluate and give a detailed mathematical proof for the\nquantum SNNs, including its successful probability, calculation accuracy, and\nalgorithm complexity. The proof shows the quantum SNNs' computational\ncomplexity that is log-polynomial in the data dimension. Furthermore, we\nprovide a method to improve quantum SNNs' minimum successful probability to\nnearly 100%. Finally, we present the good performance of quantum SNNs for\nsolving pattern recognition from the real-world.",
    "published": "2020-11-10T11:58:05Z",
    "pdf_url": "http://arxiv.org/pdf/2011.05062v2",
    "categories": [
      "quant-ph"
    ]
  },
  {
    "arxiv_id": "1801.05731v1",
    "title": "In-network Neural Networks",
    "authors": [
      "Giuseppe Siracusano",
      "Roberto Bifulco"
    ],
    "abstract": "We present N2Net, a system that implements binary neural networks using\ncommodity switching chips deployed in network switches and routers. Our system\nshows that these devices can run simple neural network models, whose input is\nencoded in the network packets' header, at packet processing speeds (billions\nof packets per second). Furthermore, our experience highlights that switching\nchips could support even more complex models, provided that some minor and\ncheap modifications to the chip's design are applied. We believe N2Net provides\nan interesting building block for future end-to-end networked systems.",
    "published": "2018-01-17T16:17:28Z",
    "pdf_url": "http://arxiv.org/pdf/1801.05731v1",
    "categories": [
      "cs.DC",
      "cs.AR",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1906.01563v3",
    "title": "Hamiltonian Neural Networks",
    "authors": [
      "Sam Greydanus",
      "Misko Dzamba",
      "Jason Yosinski"
    ],
    "abstract": "Even though neural networks enjoy widespread use, they still struggle to\nlearn the basic laws of physics. How might we endow them with better inductive\nbiases? In this paper, we draw inspiration from Hamiltonian mechanics to train\nmodels that learn and respect exact conservation laws in an unsupervised\nmanner. We evaluate our models on problems where conservation of energy is\nimportant, including the two-body problem and pixel observations of a pendulum.\nOur model trains faster and generalizes better than a regular neural network.\nAn interesting side effect is that our model is perfectly reversible in time.",
    "published": "2019-06-04T16:27:55Z",
    "pdf_url": "http://arxiv.org/pdf/1906.01563v3",
    "categories": [
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "2110.02585v1",
    "title": "Simplicial Convolutional Neural Networks",
    "authors": [
      "Maosheng Yang",
      "Elvin Isufi",
      "Geert Leus"
    ],
    "abstract": "Graphs can model networked data by representing them as nodes and their\npairwise relationships as edges. Recently, signal processing and neural\nnetworks have been extended to process and learn from data on graphs, with\nachievements in tasks like graph signal reconstruction, graph or node\nclassifications, and link prediction. However, these methods are only suitable\nfor data defined on the nodes of a graph. In this paper, we propose a\nsimplicial convolutional neural network (SCNN) architecture to learn from data\ndefined on simplices, e.g., nodes, edges, triangles, etc. We study the SCNN\npermutation and orientation equivariance, complexity, and spectral analysis.\nFinally, we test the SCNN performance for imputing citations on a coauthorship\ncomplex.",
    "published": "2021-10-06T08:52:55Z",
    "pdf_url": "http://arxiv.org/pdf/2110.02585v1",
    "categories": [
      "cs.LG",
      "eess.SP"
    ]
  },
  {
    "arxiv_id": "2204.09973v2",
    "title": "Merging of neural networks",
    "authors": [
      "Martin Pašen",
      "Vladimír Boža"
    ],
    "abstract": "We propose a simple scheme for merging two neural networks trained with\ndifferent starting initialization into a single one with the same size as the\noriginal ones. We do this by carefully selecting channels from each input\nnetwork. Our procedure might be used as a finalization step after one tries\nmultiple starting seeds to avoid an unlucky one. We also show that training two\nnetworks and merging them leads to better performance than training a single\nnetwork for an extended period of time.\n  Availability: https://github.com/fmfi-compbio/neural-network-merging",
    "published": "2022-04-21T08:52:54Z",
    "pdf_url": "http://arxiv.org/pdf/2204.09973v2",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2301.02987v1",
    "title": "Neural network models",
    "authors": [
      "Plamen Dimitrov"
    ],
    "abstract": "This work presents the current collection of mathematical models related to\nneural networks and proposes a new family of such with extended structure and\ndynamics in order to attain a selection of cognitive capabilities. It starts by\nproviding a basic background to the morphology and physiology of the biological\nand the foundations and advances of the artificial neural networks. The first\npart then continues with a survey of all current mathematical models and some\nof their derived properties. In the second part, a new family of models is\nformulated, compared with the rest, and developed analytically and numerically.\nFinally, important additional aspects and any limitations to deal with in the\nfuture are discussed.",
    "published": "2023-01-08T05:52:13Z",
    "pdf_url": "http://arxiv.org/pdf/2301.02987v1",
    "categories": [
      "cs.NE",
      "math.DS",
      "37N25 (Primary) 92B20, 68T07 (Secondary)"
    ]
  },
  {
    "arxiv_id": "2405.06409v1",
    "title": "Visualizing Neural Network Imagination",
    "authors": [
      "Nevan Wichers",
      "Victor Tao",
      "Riccardo Volpato",
      "Fazl Barez"
    ],
    "abstract": "In certain situations, neural networks will represent environment states in\ntheir hidden activations. Our goal is to visualize what environment states the\nnetworks are representing. We experiment with a recurrent neural network (RNN)\narchitecture with a decoder network at the end. After training, we apply the\ndecoder to the intermediate representations of the network to visualize what\nthey represent. We define a quantitative interpretability metric and use it to\ndemonstrate that hidden states can be highly interpretable on a simple task. We\nalso develop autoencoder and adversarial techniques and show that benefit\ninterpretability.",
    "published": "2024-05-10T11:43:35Z",
    "pdf_url": "http://arxiv.org/pdf/2405.06409v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2409.02052v1",
    "title": "Robust Fourier Neural Networks",
    "authors": [
      "Halyun Jeong",
      "Jihun Han"
    ],
    "abstract": "Fourier embedding has shown great promise in removing spectral bias during\nneural network training. However, it can still suffer from high generalization\nerrors, especially when the labels or measurements are noisy. We demonstrate\nthat introducing a simple diagonal layer after the Fourier embedding layer\nmakes the network more robust to measurement noise, effectively prompting it to\nlearn sparse Fourier features. We provide theoretical justifications for this\nFourier feature learning, leveraging recent developments in diagonal networks\nand implicit regularization in neural networks. Under certain conditions, our\nproposed approach can also learn functions that are noisy mixtures of nonlinear\nfunctions of Fourier features. Numerical experiments validate the effectiveness\nof our proposed architecture, supporting our theory.",
    "published": "2024-09-03T16:56:41Z",
    "pdf_url": "http://arxiv.org/pdf/2409.02052v1",
    "categories": [
      "cs.LG",
      "65T40, 62J02, 68T07"
    ]
  },
  {
    "arxiv_id": "2504.07923v1",
    "title": "Trading Graph Neural Network",
    "authors": [
      "Xian Wu"
    ],
    "abstract": "This paper proposes a new algorithm -- Trading Graph Neural Network (TGNN)\nthat can structurally estimate the impact of asset features, dealer features\nand relationship features on asset prices in trading networks. It combines the\nstrength of the traditional simulated method of moments (SMM) and recent\nmachine learning techniques -- Graph Neural Network (GNN). It outperforms\nexisting reduced-form methods with network centrality measures in prediction\naccuracy. The method can be used on networks with any structure, allowing for\nheterogeneity among both traders and assets.",
    "published": "2025-04-10T17:40:31Z",
    "pdf_url": "http://arxiv.org/pdf/2504.07923v1",
    "categories": [
      "q-fin.TR",
      "cs.LG",
      "econ.GN",
      "q-fin.EC",
      "q-fin.PR"
    ]
  },
  {
    "arxiv_id": "0005038v1",
    "title": "Quantum Cellular Neural Networks",
    "authors": [
      "Geza Toth",
      "Craig S. Lent",
      "P. Douglas Tougaw",
      "Yuriy Brazhnik",
      "Weiwen Weng",
      "Wolfgang Porod",
      "Ruey-Wen Liu",
      "Yih-Fang Huang"
    ],
    "abstract": "We have previously proposed a way of using coupled quantum dots to construct\ndigital computing elements - quantum-dot cellular automata (QCA). Here we\nconsider a different approach to using coupled quantum-dot cells in an\narchitecture which, rather that reproducing Boolean logic, uses a physical\nnear-neighbor connectivity to construct an analog Cellular Neural Network\n(CNN).",
    "published": "2000-05-02T05:35:35Z",
    "pdf_url": "http://arxiv.org/pdf/cond-mat/0005038v1",
    "categories": [
      "cond-mat.mes-hall",
      "cond-mat.str-el"
    ]
  },
  {
    "arxiv_id": "0601129v1",
    "title": "Instantaneously Trained Neural Networks",
    "authors": [
      "Abhilash Ponnath"
    ],
    "abstract": "This paper presents a review of instantaneously trained neural networks\n(ITNNs). These networks trade learning time for size and, in the basic model, a\nnew hidden node is created for each training sample. Various versions of the\ncorner-classification family of ITNNs, which have found applications in\nartificial intelligence (AI), are described. Implementation issues are also\nconsidered.",
    "published": "2006-01-30T22:02:47Z",
    "pdf_url": "http://arxiv.org/pdf/cs/0601129v1",
    "categories": [
      "cs.NE",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1602.07776v4",
    "title": "Recurrent Neural Network Grammars",
    "authors": [
      "Chris Dyer",
      "Adhiguna Kuncoro",
      "Miguel Ballesteros",
      "Noah A. Smith"
    ],
    "abstract": "We introduce recurrent neural network grammars, probabilistic models of\nsentences with explicit phrase structure. We explain efficient inference\nprocedures that allow application to both parsing and language modeling.\nExperiments show that they provide better parsing in English than any single\npreviously published supervised generative model and better language modeling\nthan state-of-the-art sequential RNNs in English and Chinese.",
    "published": "2016-02-25T02:42:58Z",
    "pdf_url": "http://arxiv.org/pdf/1602.07776v4",
    "categories": [
      "cs.CL",
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "1604.05753v1",
    "title": "Sketching and Neural Networks",
    "authors": [
      "Amit Daniely",
      "Nevena Lazic",
      "Yoram Singer",
      "Kunal Talwar"
    ],
    "abstract": "High-dimensional sparse data present computational and statistical challenges\nfor supervised learning. We propose compact linear sketches for reducing the\ndimensionality of the input, followed by a single layer neural network. We show\nthat any sparse polynomial function can be computed, on nearly all sparse\nbinary vectors, by a single layer neural network that takes a compact sketch of\nthe vector as input. Consequently, when a set of sparse binary vectors is\napproximately separable using a sparse polynomial, there exists a single-layer\nneural network that takes a short sketch as input and correctly classifies\nnearly all the points. Previous work has proposed using sketches to reduce\ndimensionality while preserving the hypothesis class. However, the sketch size\nhas an exponential dependence on the degree in the case of polynomial\nclassifiers. In stark contrast, our approach of using improper learning, using\na larger hypothesis class allows the sketch size to have a logarithmic\ndependence on the degree. Even in the linear case, our approach allows us to\nimprove on the pesky $O({1}/{{\\gamma}^2})$ dependence of random projections, on\nthe margin $\\gamma$. We empirically show that our approach leads to more\ncompact neural networks than related methods such as feature hashing at equal\nor better performance.",
    "published": "2016-04-19T21:22:29Z",
    "pdf_url": "http://arxiv.org/pdf/1604.05753v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1605.09081v1",
    "title": "Understanding Convolutional Neural Networks",
    "authors": [
      "Jayanth Koushik"
    ],
    "abstract": "Convoulutional Neural Networks (CNNs) exhibit extraordinary performance on a\nvariety of machine learning tasks. However, their mathematical properties and\nbehavior are quite poorly understood. There is some work, in the form of a\nframework, for analyzing the operations that they perform. The goal of this\nproject is to present key results from this theory, and provide intuition for\nwhy CNNs work.",
    "published": "2016-05-30T00:50:39Z",
    "pdf_url": "http://arxiv.org/pdf/1605.09081v1",
    "categories": [
      "stat.OT"
    ]
  },
  {
    "arxiv_id": "1611.02145v1",
    "title": "Crowdsourcing in Computer Vision",
    "authors": [
      "Adriana Kovashka",
      "Olga Russakovsky",
      "Li Fei-Fei",
      "Kristen Grauman"
    ],
    "abstract": "Computer vision systems require large amounts of manually annotated data to\nproperly learn challenging visual concepts. Crowdsourcing platforms offer an\ninexpensive method to capture human knowledge and understanding, for a vast\nnumber of visual perception tasks. In this survey, we describe the types of\nannotations computer vision researchers have collected using crowdsourcing, and\nhow they have ensured that this data is of high quality while annotation effort\nis minimized. We begin by discussing data collection on both classic (e.g.,\nobject recognition) and recent (e.g., visual story-telling) vision tasks. We\nthen summarize key design decisions for creating effective data collection\ninterfaces and workflows, and present strategies for intelligently selecting\nthe most important data instances to annotate. Finally, we conclude with some\nthoughts on the future of crowdsourcing in computer vision.",
    "published": "2016-11-07T16:11:19Z",
    "pdf_url": "http://arxiv.org/pdf/1611.02145v1",
    "categories": [
      "cs.CV",
      "cs.HC"
    ]
  },
  {
    "arxiv_id": "2301.02211v1",
    "title": "Teaching Computer Vision for Ecology",
    "authors": [
      "Elijah Cole",
      "Suzanne Stathatos",
      "Björn Lütjens",
      "Tarun Sharma",
      "Justin Kay",
      "Jason Parham",
      "Benjamin Kellenberger",
      "Sara Beery"
    ],
    "abstract": "Computer vision can accelerate ecology research by automating the analysis of\nraw imagery from sensors like camera traps, drones, and satellites. However,\ncomputer vision is an emerging discipline that is rarely taught to ecologists.\nThis work discusses our experience teaching a diverse group of ecologists to\nprototype and evaluate computer vision systems in the context of an intensive\nhands-on summer workshop. We explain the workshop structure, discuss common\nchallenges, and propose best practices. This document is intended for computer\nscientists who teach computer vision across disciplines, but it may also be\nuseful to ecologists or other domain experts who are learning to use computer\nvision themselves.",
    "published": "2023-01-05T18:30:17Z",
    "pdf_url": "http://arxiv.org/pdf/2301.02211v1",
    "categories": [
      "cs.CY",
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1707.07210v1",
    "title": "Inspiring Computer Vision System Solutions",
    "authors": [
      "Julian Zilly",
      "Amit Boyarski",
      "Micael Carvalho",
      "Amir Atapour Abarghouei",
      "Konstantinos Amplianitis",
      "Aleksandr Krasnov",
      "Massimiliano Mancini",
      "Hernán Gonzalez",
      "Riccardo Spezialetti",
      "Carlos Sampedro Pérez",
      "Hao Li"
    ],
    "abstract": "The \"digital Michelangelo project\" was a seminal computer vision project in\nthe early 2000's that pushed the capabilities of acquisition systems and\ninvolved multiple people from diverse fields, many of whom are now leaders in\nindustry and academia. Reviewing this project with modern eyes provides us with\nthe opportunity to reflect on several issues, relevant now as then to the field\nof computer vision and research in general, that go beyond the technical\naspects of the work.\n  This article was written in the context of a reading group competition at the\nweek-long International Computer Vision Summer School 2017 (ICVSS) on Sicily,\nItaly. To deepen the participants understanding of computer vision and to\nfoster a sense of community, various reading groups were tasked to highlight\nimportant lessons which may be learned from provided literature, going beyond\nthe contents of the paper. This report is the winning entry of this guided\ndiscourse (Fig. 1). The authors closely examined the origins, fruits and most\nimportantly lessons about research in general which may be distilled from the\n\"digital Michelangelo project\". Discussions leading to this report were held\nwithin the group as well as with Hao Li, the group mentor.",
    "published": "2017-07-22T20:20:57Z",
    "pdf_url": "http://arxiv.org/pdf/1707.07210v1",
    "categories": [
      "cs.CV",
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "2212.05153v4",
    "title": "Algorithmic progress in computer vision",
    "authors": [
      "Ege Erdil",
      "Tamay Besiroglu"
    ],
    "abstract": "We investigate algorithmic progress in image classification on ImageNet,\nperhaps the most well-known test bed for computer vision. We estimate a model,\ninformed by work on neural scaling laws, and infer a decomposition of progress\ninto the scaling of compute, data, and algorithms. Using Shapley values to\nattribute performance improvements, we find that algorithmic improvements have\nbeen roughly as important as the scaling of compute for progress computer\nvision. Our estimates indicate that algorithmic innovations mostly take the\nform of compute-augmenting algorithmic advances (which enable researchers to\nget better performance from less compute), not data-augmenting algorithmic\nadvances. We find that compute-augmenting algorithmic advances are made at a\npace more than twice as fast as the rate usually associated with Moore's law.\nIn particular, we estimate that compute-augmenting innovations halve compute\nrequirements every nine months (95\\% confidence interval: 4 to 25 months).",
    "published": "2022-12-10T00:18:05Z",
    "pdf_url": "http://arxiv.org/pdf/2212.05153v4",
    "categories": [
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1701.06859v1",
    "title": "Sparse models for Computer Vision",
    "authors": [
      "Laurent Perrinet"
    ],
    "abstract": "The representation of images in the brain is known to be sparse. That is, as\nneural activity is recorded in a visual area ---for instance the primary visual\ncortex of primates--- only a few neurons are active at a given time with\nrespect to the whole population. It is believed that such a property reflects\nthe efficient match of the representation with the statistics of natural\nscenes. Applying such a paradigm to computer vision therefore seems a promising\napproach towards more biomimetic algorithms. Herein, we will describe a\nbiologically-inspired approach to this problem. First, we will describe an\nunsupervised learning paradigm which is particularly adapted to the efficient\ncoding of image patches. Then, we will outline a complete multi-scale framework\n---SparseLets--- implementing a biologically inspired sparse representation of\nnatural images. Finally, we will propose novel methods for integrating prior\ninformation into these algorithms and provide some preliminary experimental\nresults. We will conclude by giving some perspective on applying such\nalgorithms to computer vision. More specifically, we will propose that\nbio-inspired approaches may be applied to computer vision using predictive\ncoding schemes, sparse models being one simple and efficient instance of such\nschemes.",
    "published": "2017-01-24T13:20:11Z",
    "pdf_url": "http://arxiv.org/pdf/1701.06859v1",
    "categories": [
      "cs.CV",
      "q-bio.NC"
    ]
  },
  {
    "arxiv_id": "2301.01161v1",
    "title": "Procedural Humans for Computer Vision",
    "authors": [
      "Charlie Hewitt",
      "Tadas Baltrušaitis",
      "Erroll Wood",
      "Lohit Petikam",
      "Louis Florentin",
      "Hanz Cuevas Velasquez"
    ],
    "abstract": "Recent work has shown the benefits of synthetic data for use in computer\nvision, with applications ranging from autonomous driving to face landmark\ndetection and reconstruction. There are a number of benefits of using synthetic\ndata from privacy preservation and bias elimination to quality and feasibility\nof annotation. Generating human-centered synthetic data is a particular\nchallenge in terms of realism and domain-gap, though recent work has shown that\neffective machine learning models can be trained using synthetic face data\nalone. We show that this can be extended to include the full body by building\non the pipeline of Wood et al. to generate synthetic images of humans in their\nentirety, with ground-truth annotations for computer vision applications.\n  In this report we describe how we construct a parametric model of the face\nand body, including articulated hands; our rendering pipeline to generate\nrealistic images of humans based on this body model; an approach for training\nDNNs to regress a dense set of landmarks covering the entire body; and a method\nfor fitting our body model to dense landmarks predicted from multiple views.",
    "published": "2023-01-03T15:44:48Z",
    "pdf_url": "http://arxiv.org/pdf/2301.01161v1",
    "categories": [
      "cs.CV",
      "cs.GR"
    ]
  },
  {
    "arxiv_id": "1310.0319v3",
    "title": "Second Croatian Computer Vision Workshop (CCVW 2013)",
    "authors": [
      "Sven Lončarić",
      "Siniša Šegvić"
    ],
    "abstract": "Proceedings of the Second Croatian Computer Vision Workshop (CCVW 2013,\nhttp://www.fer.unizg.hr/crv/ccvw2013) held September 19, 2013, in Zagreb,\nCroatia. Workshop was organized by the Center of Excellence for Computer Vision\nof the University of Zagreb.",
    "published": "2013-10-01T14:26:29Z",
    "pdf_url": "http://arxiv.org/pdf/1310.0319v3",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1701.04674v1",
    "title": "Human perception in computer vision",
    "authors": [
      "Ron Dekel"
    ],
    "abstract": "Computer vision has made remarkable progress in recent years. Deep neural\nnetwork (DNN) models optimized to identify objects in images exhibit\nunprecedented task-trained accuracy and, remarkably, some generalization\nability: new visual problems can now be solved more easily based on previous\nlearning. Biological vision (learned in life and through evolution) is also\naccurate and general-purpose. Is it possible that these different learning\nregimes converge to similar problem-dependent optimal computations? We\ntherefore asked whether the human system-level computation of visual perception\nhas DNN correlates and considered several anecdotal test cases. We found that\nperceptual sensitivity to image changes has DNN mid-computation correlates,\nwhile sensitivity to segmentation, crowding and shape has DNN end-computation\ncorrelates. Our results quantify the applicability of using DNN computation to\nestimate perceptual loss, and are consistent with the fascinating theoretical\nview that properties of human perception are a consequence of\narchitecture-independent visual learning.",
    "published": "2017-01-17T14:00:30Z",
    "pdf_url": "http://arxiv.org/pdf/1701.04674v1",
    "categories": [
      "cs.CV",
      "q-bio.NC"
    ]
  },
  {
    "arxiv_id": "1910.12539v1",
    "title": "Virtual Piano using Computer Vision",
    "authors": [
      "Seongjae Kang",
      "Jaeyoon Kim",
      "Sung-eui Yoon"
    ],
    "abstract": "In this research, Piano performances have been analyzed only based on visual\ninformation. Computer vision algorithms, e.g., Hough transform and binary\nthresholding, have been applied to find where the keyboard and specific keys\nare located. At the same time, Convolutional Neural Networks(CNNs) has been\nalso utilized to find whether specific keys are pressed or not, and how much\nintensity the keys are pressed only based on visual information. Especially for\ndetecting intensity, a new method of utilizing spatial, temporal CNNs model is\ndevised. Early fusion technique is especially applied in temporal CNNs\narchitecture to analyze hand movement. We also make a new dataset for training\neach model. Especially when finding an intensity of a pressed key, both of\nvideo frames and their optical flow images are used to train models to find\neffectiveness.",
    "published": "2019-10-28T10:36:30Z",
    "pdf_url": "http://arxiv.org/pdf/1910.12539v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2308.13558v1",
    "title": "Federated Learning for Computer Vision",
    "authors": [
      "Yassine Himeur",
      "Iraklis Varlamis",
      "Hamza Kheddar",
      "Abbes Amira",
      "Shadi Atalla",
      "Yashbir Singh",
      "Faycal Bensaali",
      "Wathiq Mansoor"
    ],
    "abstract": "Computer Vision (CV) is playing a significant role in transforming society by\nutilizing machine learning (ML) tools for a wide range of tasks. However, the\nneed for large-scale datasets to train ML models creates challenges for\ncentralized ML algorithms. The massive computation loads required for\nprocessing and the potential privacy risks associated with storing and\nprocessing data on central cloud servers put these algorithms under severe\nstrain. To address these issues, federated learning (FL) has emerged as a\npromising solution, allowing privacy preservation by training models locally\nand exchanging them to improve overall performance. Additionally, the\ncomputational load is distributed across multiple clients, reducing the burden\non central servers. This paper presents, to the best of the authors' knowledge,\nthe first review discussing recent advancements of FL in CV applications,\ncomparing them to conventional centralized training paradigms. It provides an\noverview of current FL applications in various CV tasks, emphasizing the\nadvantages of FL and the challenges of implementing it in CV. To facilitate\nthis, the paper proposes a taxonomy of FL techniques in CV, outlining their\napplications and security threats. It also discusses privacy concerns related\nto implementing blockchain in FL schemes for CV tasks and summarizes existing\nprivacy preservation methods. Moving on, the paper identifies open research\nchallenges and potential future research directions to further exploit the\npotential of FL and blockchain in CV applications.",
    "published": "2023-08-24T16:05:14Z",
    "pdf_url": "http://arxiv.org/pdf/2308.13558v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2112.03111v1",
    "title": "Ethics and Creativity in Computer Vision",
    "authors": [
      "Negar Rostamzadeh",
      "Emily Denton",
      "Linda Petrini"
    ],
    "abstract": "This paper offers a retrospective of what we learnt from organizing the\nworkshop *Ethical Considerations in Creative applications of Computer Vision*\nat CVPR 2021 conference and, prior to that, a series of workshops on *Computer\nVision for Fashion, Art and Design* at ECCV 2018, ICCV 2019, and CVPR 2020. We\nhope this reflection will bring artists and machine learning researchers into\nconversation around the ethical and social dimensions of creative applications\nof computer vision.",
    "published": "2021-12-06T15:23:08Z",
    "pdf_url": "http://arxiv.org/pdf/2112.03111v1",
    "categories": [
      "cs.CV",
      "cs.CY",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1907.09233v1",
    "title": "Adapting Computer Vision Algorithms for Omnidirectional Video",
    "authors": [
      "Hannes Fassold"
    ],
    "abstract": "Omnidirectional (360{\\deg}) video has got quite popular because it provides a\nhighly immersive viewing experience. For computer vision algorithms, it poses\nseveral challenges, like the special (equirectangular) projection commonly\nemployed and the huge image size. In this work, we give a high-level overview\nof these challenges and outline strategies how to adapt computer vision\nalgorithm for the specifics of omnidirectional video.",
    "published": "2019-07-22T11:12:35Z",
    "pdf_url": "http://arxiv.org/pdf/1907.09233v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1910.13796v1",
    "title": "Deep Learning vs. Traditional Computer Vision",
    "authors": [
      "Niall O' Mahony",
      "Sean Campbell",
      "Anderson Carvalho",
      "Suman Harapanahalli",
      "Gustavo Velasco-Hernandez",
      "Lenka Krpalkova",
      "Daniel Riordan",
      "Joseph Walsh"
    ],
    "abstract": "Deep Learning has pushed the limits of what was possible in the domain of\nDigital Image Processing. However, that is not to say that the traditional\ncomputer vision techniques which had been undergoing progressive development in\nyears prior to the rise of DL have become obsolete. This paper will analyse the\nbenefits and drawbacks of each approach. The aim of this paper is to promote a\ndiscussion on whether knowledge of classical computer vision techniques should\nbe maintained. The paper will also explore how the two sides of computer vision\ncan be combined. Several recent hybrid methodologies are reviewed which have\ndemonstrated the ability to improve computer vision performance and to tackle\nproblems not suited to Deep Learning. For example, combining traditional\ncomputer vision techniques with Deep Learning has been popular in emerging\ndomains such as Panoramic Vision and 3D vision for which Deep Learning models\nhave not yet been fully optimised",
    "published": "2019-10-30T12:25:10Z",
    "pdf_url": "http://arxiv.org/pdf/1910.13796v1",
    "categories": [
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2306.05135v1",
    "title": "Does Image Anonymization Impact Computer Vision Training?",
    "authors": [
      "Håkon Hukkelås",
      "Frank Lindseth"
    ],
    "abstract": "Image anonymization is widely adapted in practice to comply with privacy\nregulations in many regions. However, anonymization often degrades the quality\nof the data, reducing its utility for computer vision development. In this\npaper, we investigate the impact of image anonymization for training computer\nvision models on key computer vision tasks (detection, instance segmentation,\nand pose estimation). Specifically, we benchmark the recognition drop on common\ndetection datasets, where we evaluate both traditional and realistic\nanonymization for faces and full bodies. Our comprehensive experiments reflect\nthat traditional image anonymization substantially impacts final model\nperformance, particularly when anonymizing the full body. Furthermore, we find\nthat realistic anonymization can mitigate this decrease in performance, where\nour experiments reflect a minimal performance drop for face anonymization. Our\nstudy demonstrates that realistic anonymization can enable privacy-preserving\ncomputer vision development with minimal performance degradation across a range\nof important computer vision benchmarks.",
    "published": "2023-06-08T12:02:03Z",
    "pdf_url": "http://arxiv.org/pdf/2306.05135v1",
    "categories": [
      "cs.CV",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2302.08242v1",
    "title": "Tuning computer vision models with task rewards",
    "authors": [
      "André Susano Pinto",
      "Alexander Kolesnikov",
      "Yuge Shi",
      "Lucas Beyer",
      "Xiaohua Zhai"
    ],
    "abstract": "Misalignment between model predictions and intended usage can be detrimental\nfor the deployment of computer vision models. The issue is exacerbated when the\ntask involves complex structured outputs, as it becomes harder to design\nprocedures which address this misalignment. In natural language processing,\nthis is often addressed using reinforcement learning techniques that align\nmodels with a task reward. We adopt this approach and show its surprising\neffectiveness across multiple computer vision tasks, such as object detection,\npanoptic segmentation, colorization and image captioning. We believe this\napproach has the potential to be widely useful for better aligning models with\na diverse range of computer vision tasks.",
    "published": "2023-02-16T11:49:48Z",
    "pdf_url": "http://arxiv.org/pdf/2302.08242v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1705.04402v3",
    "title": "Negative Results in Computer Vision: A Perspective",
    "authors": [
      "Ali Borji"
    ],
    "abstract": "A negative result is when the outcome of an experiment or a model is not what\nis expected or when a hypothesis does not hold. Despite being often overlooked\nin the scientific community, negative results are results and they carry value.\nWhile this topic has been extensively discussed in other fields such as social\nsciences and biosciences, less attention has been paid to it in the computer\nvision community. The unique characteristics of computer vision, particularly\nits experimental aspect, call for a special treatment of this matter. In this\npaper, I will address what makes negative results important, how they should be\ndisseminated and incentivized, and what lessons can be learned from cognitive\nvision research in this regard. Further, I will discuss issues such as computer\nvision and human vision interaction, experimental design and statistical\nhypothesis testing, explanatory versus predictive modeling, performance\nevaluation, model comparison, as well as computer vision research culture.",
    "published": "2017-05-11T23:39:18Z",
    "pdf_url": "http://arxiv.org/pdf/1705.04402v3",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1905.12887v2",
    "title": "Does computer vision matter for action?",
    "authors": [
      "Brady Zhou",
      "Philipp Krähenbühl",
      "Vladlen Koltun"
    ],
    "abstract": "Computer vision produces representations of scene content. Much computer\nvision research is predicated on the assumption that these intermediate\nrepresentations are useful for action. Recent work at the intersection of\nmachine learning and robotics calls this assumption into question by training\nsensorimotor systems directly for the task at hand, from pixels to actions,\nwith no explicit intermediate representations. Thus the central question of our\nwork: Does computer vision matter for action? We probe this question and its\noffshoots via immersive simulation, which allows us to conduct controlled\nreproducible experiments at scale. We instrument immersive three-dimensional\nenvironments to simulate challenges such as urban driving, off-road trail\ntraversal, and battle. Our main finding is that computer vision does matter.\nModels equipped with intermediate representations train faster, achieve higher\ntask performance, and generalize better to previously unseen environments. A\nvideo that summarizes the work and illustrates the results can be found at\nhttps://youtu.be/4MfWa2yZ0Jc",
    "published": "2019-05-30T07:18:33Z",
    "pdf_url": "http://arxiv.org/pdf/1905.12887v2",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ]
  },
  {
    "arxiv_id": "2408.11448v1",
    "title": "Lookism: The overlooked bias in computer vision",
    "authors": [
      "Aditya Gulati",
      "Bruno Lepri",
      "Nuria Oliver"
    ],
    "abstract": "In recent years, there have been significant advancements in computer vision\nwhich have led to the widespread deployment of image recognition and generation\nsystems in socially relevant applications, from hiring to security screening.\nHowever, the prevalence of biases within these systems has raised significant\nethical and social concerns. The most extensively studied biases in this\ncontext are related to gender, race and age. Yet, other biases are equally\npervasive and harmful, such as lookism, i.e., the preferential treatment of\nindividuals based on their physical appearance. Lookism remains under-explored\nin computer vision but can have profound implications not only by perpetuating\nharmful societal stereotypes but also by undermining the fairness and\ninclusivity of AI technologies. Thus, this paper advocates for the systematic\nstudy of lookism as a critical bias in computer vision models. Through a\ncomprehensive review of existing literature, we identify three areas of\nintersection between lookism and computer vision. We illustrate them by means\nof examples and a user study. We call for an interdisciplinary approach to\naddress lookism, urging researchers, developers, and policymakers to prioritize\nthe development of equitable computer vision systems that respect and reflect\nthe diversity of human appearances.",
    "published": "2024-08-21T09:07:20Z",
    "pdf_url": "http://arxiv.org/pdf/2408.11448v1",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CY",
      "I.2.0; I.4.0; K.4.2"
    ]
  },
  {
    "arxiv_id": "2506.11140v3",
    "title": "Autonomous Computer Vision Development with Agentic AI",
    "authors": [
      "Jin Kim",
      "Muhammad Wahi-Anwa",
      "Sangyun Park",
      "Shawn Shin",
      "John M. Hoffman",
      "Matthew S. Brown"
    ],
    "abstract": "Agentic Artificial Intelligence (AI) systems leveraging Large Language Models\n(LLMs) exhibit significant potential for complex reasoning, planning, and tool\nutilization. We demonstrate that a specialized computer vision system can be\nbuilt autonomously from a natural language prompt using Agentic AI methods.\nThis involved extending SimpleMind (SM), an open-source Cognitive AI\nenvironment with configurable tools for medical image analysis, with an\nLLM-based agent, implemented using OpenManus, to automate the planning (tool\nconfiguration) for a particular computer vision task. We provide a\nproof-of-concept demonstration that an agentic system can interpret a computer\nvision task prompt, plan a corresponding SimpleMind workflow by decomposing the\ntask and configuring appropriate tools. From the user input prompt, \"provide sm\n(SimpleMind) config for lungs, heart, and ribs segmentation for cxr (chest\nx-ray)\"), the agent LLM was able to generate the plan (tool configuration file\nin YAML format), and execute SM-Learn (training) and SM-Think (inference)\nscripts autonomously. The computer vision agent automatically configured,\ntrained, and tested itself on 50 chest x-ray images, achieving mean dice scores\nof 0.96, 0.82, 0.83, for lungs, heart, and ribs, respectively. This work shows\nthe potential for autonomous planning and tool configuration that has\ntraditionally been performed by a data scientist in the development of computer\nvision applications.",
    "published": "2025-06-11T02:21:19Z",
    "pdf_url": "http://arxiv.org/pdf/2506.11140v3",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MA"
    ]
  },
  {
    "arxiv_id": "1904.07714v1",
    "title": "Low-Power Computer Vision: Status, Challenges, Opportunities",
    "authors": [
      "Sergei Alyamkin",
      "Matthew Ardi",
      "Alexander C. Berg",
      "Achille Brighton",
      "Bo Chen",
      "Yiran Chen",
      "Hsin-Pai Cheng",
      "Zichen Fan",
      "Chen Feng",
      "Bo Fu",
      "Kent Gauen",
      "Abhinav Goel",
      "Alexander Goncharenko",
      "Xuyang Guo",
      "Soonhoi Ha",
      "Andrew Howard",
      "Xiao Hu",
      "Yuanjun Huang",
      "Donghyun Kang",
      "Jaeyoun Kim",
      "Jong Gook Ko",
      "Alexander Kondratyev",
      "Junhyeok Lee",
      "Seungjae Lee",
      "Suwoong Lee",
      "Zichao Li",
      "Zhiyu Liang",
      "Juzheng Liu",
      "Xin Liu",
      "Yang Lu",
      "Yung-Hsiang Lu",
      "Deeptanshu Malik",
      "Hong Hanh Nguyen",
      "Eunbyung Park",
      "Denis Repin",
      "Liang Shen",
      "Tao Sheng",
      "Fei Sun",
      "David Svitov",
      "George K. Thiruvathukal",
      "Baiwu Zhang",
      "Jingchi Zhang",
      "Xiaopeng Zhang",
      "Shaojie Zhuo"
    ],
    "abstract": "Computer vision has achieved impressive progress in recent years. Meanwhile,\nmobile phones have become the primary computing platforms for millions of\npeople. In addition to mobile phones, many autonomous systems rely on visual\ndata for making decisions and some of these systems have limited energy (such\nas unmanned aerial vehicles also called drones and mobile robots). These\nsystems rely on batteries and energy efficiency is critical. This article\nserves two main purposes: (1) Examine the state-of-the-art for low-power\nsolutions to detect objects in images. Since 2015, the IEEE Annual\nInternational Low-Power Image Recognition Challenge (LPIRC) has been held to\nidentify the most energy-efficient computer vision solutions. This article\nsummarizes 2018 winners' solutions. (2) Suggest directions for research as well\nas opportunities for low-power computer vision.",
    "published": "2019-04-15T17:48:48Z",
    "pdf_url": "http://arxiv.org/pdf/1904.07714v1",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.PF"
    ]
  },
  {
    "arxiv_id": "2204.03643v1",
    "title": "Total Variation Optimization Layers for Computer Vision",
    "authors": [
      "Raymond A. Yeh",
      "Yuan-Ting Hu",
      "Zhongzheng Ren",
      "Alexander G. Schwing"
    ],
    "abstract": "Optimization within a layer of a deep-net has emerged as a new direction for\ndeep-net layer design. However, there are two main challenges when applying\nthese layers to computer vision tasks: (a) which optimization problem within a\nlayer is useful?; (b) how to ensure that computation within a layer remains\nefficient? To study question (a), in this work, we propose total variation (TV)\nminimization as a layer for computer vision. Motivated by the success of total\nvariation in image processing, we hypothesize that TV as a layer provides\nuseful inductive bias for deep-nets too. We study this hypothesis on five\ncomputer vision tasks: image classification, weakly supervised object\nlocalization, edge-preserving smoothing, edge detection, and image denoising,\nimproving over existing baselines. To achieve these results we had to address\nquestion (b): we developed a GPU-based projected-Newton method which is\n$37\\times$ faster than existing solutions.",
    "published": "2022-04-07T17:59:27Z",
    "pdf_url": "http://arxiv.org/pdf/2204.03643v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2302.08054v1",
    "title": "Spectral 3D Computer Vision -- A Review",
    "authors": [
      "Yajie Sun",
      "Ali Zia",
      "Vivien Rolland",
      "Charissa Yu",
      "Jun Zhou"
    ],
    "abstract": "Spectral 3D computer vision examines both the geometric and spectral\nproperties of objects. It provides a deeper understanding of an object's\nphysical properties by providing information from narrow bands in various\nregions of the electromagnetic spectrum. Mapping the spectral information onto\nthe 3D model reveals changes in the spectra-structure space or enhances 3D\nrepresentations with properties such as reflectance, chromatic aberration, and\nvarying defocus blur. This emerging paradigm advances traditional computer\nvision and opens new avenues of research in 3D structure, depth estimation,\nmotion analysis, and more. It has found applications in areas such as smart\nagriculture, environment monitoring, building inspection, geological\nexploration, and digital cultural heritage records. This survey offers a\ncomprehensive overview of spectral 3D computer vision, including a unified\ntaxonomy of methods, key application areas, and future challenges and\nprospects.",
    "published": "2023-02-16T03:29:40Z",
    "pdf_url": "http://arxiv.org/pdf/2302.08054v1",
    "categories": [
      "cs.CV",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2507.18660v1",
    "title": "Fuzzy Theory in Computer Vision: A Review",
    "authors": [
      "Adilet Yerkin",
      "Ayan Igali",
      "Elnara Kadyrgali",
      "Maksat Shagyrov",
      "Malika Ziyada",
      "Muragul Muratbekova",
      "Pakizar Shamoi"
    ],
    "abstract": "Computer vision applications are omnipresent nowadays. The current paper\nexplores the use of fuzzy logic in computer vision, stressing its role in\nhandling uncertainty, noise, and imprecision in image data. Fuzzy logic is able\nto model gradual transitions and human-like reasoning and provides a promising\napproach to computer vision. Fuzzy approaches offer a way to improve object\nrecognition, image segmentation, and feature extraction by providing more\nadaptable and interpretable solutions compared to traditional methods. We\ndiscuss key fuzzy techniques, including fuzzy clustering, fuzzy inference\nsystems, type-2 fuzzy sets, and fuzzy rule-based decision-making. The paper\nalso discusses various applications, including medical imaging, autonomous\nsystems, and industrial inspection. Additionally, we explore the integration of\nfuzzy logic with deep learning models such as convolutional neural networks\n(CNNs) to enhance performance in complex vision tasks. Finally, we examine\nemerging trends such as hybrid fuzzy-deep learning models and explainable AI.",
    "published": "2025-07-23T15:23:09Z",
    "pdf_url": "http://arxiv.org/pdf/2507.18660v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2406.00447v1",
    "title": "DroneVis: Versatile Computer Vision Library for Drones",
    "authors": [
      "Ahmed Heakl",
      "Fatma Youssef",
      "Victor Parque",
      "Walid Gomaa"
    ],
    "abstract": "This paper introduces DroneVis, a novel library designed to automate computer\nvision algorithms on Parrot drones. DroneVis offers a versatile set of features\nand provides a diverse range of computer vision tasks along with a variety of\nmodels to choose from. Implemented in Python, the library adheres to\nhigh-quality code standards, facilitating effortless customization and feature\nexpansion according to user requirements. In addition, comprehensive\ndocumentation is provided, encompassing usage guidelines and illustrative use\ncases. Our documentation, code, and examples are available in\nhttps://github.com/ahmedheakl/drone-vis.",
    "published": "2024-06-01T14:06:46Z",
    "pdf_url": "http://arxiv.org/pdf/2406.00447v1",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "cs.RO"
    ]
  },
  {
    "arxiv_id": "1705.04352v3",
    "title": "Reconfiguring the Imaging Pipeline for Computer Vision",
    "authors": [
      "Mark Buckler",
      "Suren Jayasuriya",
      "Adrian Sampson"
    ],
    "abstract": "Advancements in deep learning have ignited an explosion of research on\nefficient hardware for embedded computer vision. Hardware vision acceleration,\nhowever, does not address the cost of capturing and processing the image data\nthat feeds these algorithms. We examine the role of the image signal processing\n(ISP) pipeline in computer vision to identify opportunities to reduce\ncomputation and save energy. The key insight is that imaging pipelines should\nbe designed to be configurable: to switch between a traditional photography\nmode and a low-power vision mode that produces lower-quality image data\nsuitable only for computer vision. We use eight computer vision algorithms and\na reversible pipeline simulation tool to study the imaging system's impact on\nvision performance. For both CNN-based and classical vision algorithms, we\nobserve that only two ISP stages, demosaicing and gamma compression, are\ncritical for task performance. We propose a new image sensor design that can\ncompensate for skipping these stages. The sensor design features an adjustable\nresolution and tunable analog-to-digital converters (ADCs). Our proposed\nimaging system's vision mode disables the ISP entirely and configures the\nsensor to produce subsampled, lower-precision image data. This vision mode can\nsave ~75% of the average energy of a baseline photography mode while having\nonly a small impact on vision task accuracy.",
    "published": "2017-05-11T18:57:01Z",
    "pdf_url": "http://arxiv.org/pdf/1705.04352v3",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2010.01177v4",
    "title": "Global Adaptive Filtering Layer for Computer Vision",
    "authors": [
      "Viktor Shipitsin",
      "Iaroslav Bespalov",
      "Dmitry V. Dylov"
    ],
    "abstract": "We devise a universal adaptive neural layer to \"learn\" optimal frequency\nfilter for each image together with the weights of the base neural network that\nperforms some computer vision task. The proposed approach takes the source\nimage in the spatial domain, automatically selects the best frequencies from\nthe frequency domain, and transmits the inverse-transform image to the main\nneural network. Remarkably, such a simple add-on layer dramatically improves\nthe performance of the main network regardless of its design. We observe that\nthe light networks gain a noticeable boost in the performance metrics; whereas,\nthe training of the heavy ones converges faster when our adaptive layer is\nallowed to \"learn\" alongside the main architecture. We validate the idea in\nfour classical computer vision tasks: classification, segmentation, denoising,\nand erasing, considering popular natural and medical data benchmarks.",
    "published": "2020-10-02T19:43:49Z",
    "pdf_url": "http://arxiv.org/pdf/2010.01177v4",
    "categories": [
      "eess.IV",
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1906.02337v1",
    "title": "MNIST-C: A Robustness Benchmark for Computer Vision",
    "authors": [
      "Norman Mu",
      "Justin Gilmer"
    ],
    "abstract": "We introduce the MNIST-C dataset, a comprehensive suite of 15 corruptions\napplied to the MNIST test set, for benchmarking out-of-distribution robustness\nin computer vision. Through several experiments and visualizations we\ndemonstrate that our corruptions significantly degrade performance of\nstate-of-the-art computer vision models while preserving the semantic content\nof the test images. In contrast to the popular notion of adversarial\nrobustness, our model-agnostic corruptions do not seek worst-case performance\nbut are instead designed to be broad and diverse, capturing multiple failure\nmodes of modern models. In fact, we find that several previously published\nadversarial defenses significantly degrade robustness as measured by MNIST-C.\nWe hope that our benchmark serves as a useful tool for future work in designing\nsystems that are able to learn robust feature representations that capture the\nunderlying semantics of the input.",
    "published": "2019-06-05T22:23:43Z",
    "pdf_url": "http://arxiv.org/pdf/1906.02337v1",
    "categories": [
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2111.07624v1",
    "title": "Attention Mechanisms in Computer Vision: A Survey",
    "authors": [
      "Meng-Hao Guo",
      "Tian-Xing Xu",
      "Jiang-Jiang Liu",
      "Zheng-Ning Liu",
      "Peng-Tao Jiang",
      "Tai-Jiang Mu",
      "Song-Hai Zhang",
      "Ralph R. Martin",
      "Ming-Ming Cheng",
      "Shi-Min Hu"
    ],
    "abstract": "Humans can naturally and effectively find salient regions in complex scenes.\nMotivated by this observation, attention mechanisms were introduced into\ncomputer vision with the aim of imitating this aspect of the human visual\nsystem. Such an attention mechanism can be regarded as a dynamic weight\nadjustment process based on features of the input image. Attention mechanisms\nhave achieved great success in many visual tasks, including image\nclassification, object detection, semantic segmentation, video understanding,\nimage generation, 3D vision, multi-modal tasks and self-supervised learning. In\nthis survey, we provide a comprehensive review of various attention mechanisms\nin computer vision and categorize them according to approach, such as channel\nattention, spatial attention, temporal attention and branch attention; a\nrelated repository https://github.com/MenghaoGuo/Awesome-Vision-Attentions is\ndedicated to collecting related work. We also suggest future directions for\nattention mechanism research.",
    "published": "2021-11-15T09:18:40Z",
    "pdf_url": "http://arxiv.org/pdf/2111.07624v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1107.2875v1",
    "title": "A Hilbert Scheme in Computer Vision",
    "authors": [
      "Chris Aholt",
      "Bernd Sturmfels",
      "Rekha Thomas"
    ],
    "abstract": "Multiview geometry is the study of two-dimensional images of\nthree-dimensional scenes, a foundational subject in computer vision. We\ndetermine a universal Groebner basis for the multiview ideal of n generic\ncameras. As the cameras move, the multiview varieties vary in a family of\ndimension 11n-15. This family is the distinguished component of a multigraded\nHilbert scheme with a unique Borel-fixed point. We present a combinatorial\nstudy of ideals lying on that Hilbert scheme.",
    "published": "2011-07-14T17:36:59Z",
    "pdf_url": "http://arxiv.org/pdf/1107.2875v1",
    "categories": [
      "math.AG",
      "cs.CV",
      "14N, 14Q, 68"
    ]
  },
  {
    "arxiv_id": "1707.09332v6",
    "title": "Two Hilbert schemes in computer vision",
    "authors": [
      "Max Lieblich",
      "Lucas Van Meter"
    ],
    "abstract": "We study multiview moduli problems that arise in computer vision. We show\nthat these moduli spaces are always smooth and irreducible, in both the\ncalibrated and uncalibrated cases, for any number of views. We also show that\nthese moduli spaces always admit open immersions into Hilbert schemes for more\nthan two views, extending and refining work of Aholt-Sturmfels-Thomas. We use\nthese moduli spaces to study and extend the classical twisted pair covering of\nthe essential variety.",
    "published": "2017-07-28T17:13:22Z",
    "pdf_url": "http://arxiv.org/pdf/1707.09332v6",
    "categories": [
      "math.AG",
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2008.00813v1",
    "title": "Kinematics of motion tracking using computer vision",
    "authors": [
      "José L. Escalona"
    ],
    "abstract": "This paper describes the kinematics of the motion tracking of a rigid body\nusing video recording. The novelty of the paper is on the adaptation of the\nmethods and nomenclature used in Computer Vision to those used in Multibody\nSystem Dynamics. That way, the equations presented here can be used, for\nexample, for inverse-dynamics multibody simulations driven by the motion\ntracking of selected bodies. This paper also adapts the well-known Zhang\ncalibration method to the presented nomenclature.",
    "published": "2020-07-19T18:02:13Z",
    "pdf_url": "http://arxiv.org/pdf/2008.00813v1",
    "categories": [
      "cs.CV",
      "eess.IV"
    ]
  },
  {
    "arxiv_id": "2406.13008v1",
    "title": "ClaudesLens: Uncertainty Quantification in Computer Vision Models",
    "authors": [
      "Mohamad Al Shaar",
      "Nils Ekström",
      "Gustav Gille",
      "Reza Rezvan",
      "Ivan Wely"
    ],
    "abstract": "In a world where more decisions are made using artificial intelligence, it is\nof utmost importance to ensure these decisions are well-grounded. Neural\nnetworks are the modern building blocks for artificial intelligence. Modern\nneural network-based computer vision models are often used for object\nclassification tasks. Correctly classifying objects with \\textit{certainty} has\nbecome of great importance in recent times. However, quantifying the inherent\n\\textit{uncertainty} of the output from neural networks is a challenging task.\nHere we show a possible method to quantify and evaluate the uncertainty of the\noutput of different computer vision models based on Shannon entropy. By adding\nperturbation of different levels, on different parts, ranging from the input to\nthe parameters of the network, one introduces entropy to the system. By\nquantifying and evaluating the perturbed models on the proposed PI and PSI\nmetrics, we can conclude that our theoretical framework can grant insight into\nthe uncertainty of predictions of computer vision models. We believe that this\ntheoretical framework can be applied to different applications for neural\nnetworks. We believe that Shannon entropy may eventually have a bigger role in\nthe SOTA (State-of-the-art) methods to quantify uncertainty in artificial\nintelligence. One day we might be able to apply Shannon entropy to our neural\nsystems.",
    "published": "2024-06-18T18:58:54Z",
    "pdf_url": "http://arxiv.org/pdf/2406.13008v1",
    "categories": [
      "cs.CV",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2411.18224v2",
    "title": "KANs for Computer Vision: An Experimental Study",
    "authors": [
      "Karthik Mohan",
      "Hanxiao Wang",
      "Xiatian Zhu"
    ],
    "abstract": "This paper presents an experimental study of Kolmogorov-Arnold Networks\n(KANs) applied to computer vision tasks, particularly image classification.\nKANs introduce learnable activation functions on edges, offering flexible\nnon-linear transformations compared to traditional pre-fixed activation\nfunctions with specific neural work like Multi-Layer Perceptrons (MLPs) and\nConvolutional Neural Networks (CNNs). While KANs have shown promise mostly in\nsimplified or small-scale datasets, their effectiveness for more complex\nreal-world tasks such as computer vision tasks remains less explored. To fill\nthis gap, this experimental study aims to provide extended observations and\ninsights into the strengths and limitations of KANs. We reveal that although\nKANs can perform well in specific vision tasks, they face significant\nchallenges, including increased hyperparameter sensitivity and higher\ncomputational costs. These limitations suggest that KANs require architectural\nadaptations, such as integration with other architectures, to be practical for\nlarge-scale vision problems. This study focuses on empirical findings rather\nthan proposing new methods, aiming to inform future research on optimizing\nKANs, in particular computer vision applications or alike.",
    "published": "2024-11-27T10:59:28Z",
    "pdf_url": "http://arxiv.org/pdf/2411.18224v2",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1709.00069v1",
    "title": "Learning Inference Models for Computer Vision",
    "authors": [
      "Varun Jampani"
    ],
    "abstract": "Computer vision can be understood as the ability to perform inference on\nimage data. Breakthroughs in computer vision technology are often marked by\nadvances in inference techniques. This thesis proposes novel inference schemes\nand demonstrates applications in computer vision. We propose inference\ntechniques for both generative and discriminative vision models. The use of\ngenerative models in vision is often hampered by the difficulty of posterior\ninference. We propose techniques for improving inference in MCMC sampling and\nmessage-passing inference. Our inference strategy is to learn separate\ndiscriminative models that assist Bayesian inference in a generative model.\nExperiments on a range of generative models show that the proposed techniques\naccelerate the inference process and/or converge to better solutions. A main\ncomplication in the design of discriminative models is the inclusion of prior\nknowledge. We concentrate on CNN models and propose a generalization of\nstandard spatial convolutions to bilateral convolutions. We generalize the\nexisting use of bilateral filters and then propose new neural network\narchitectures with learnable bilateral filters, which we call `Bilateral Neural\nNetworks'. Experiments demonstrate the use of the bilateral networks on a wide\nrange of image and video tasks and datasets. In summary, we propose techniques\nfor better inference in several vision models ranging from inverse graphics to\nfreely parameterized neural networks. In generative models, our inference\ntechniques alleviate some of the crucial hurdles in Bayesian posterior\ninference, paving new ways for the use of model based machine learning in\nvision. In discriminative CNN models, the proposed filter generalizations aid\nin the design of new neural network architectures that can handle sparse\nhigh-dimensional data as well as provide a way to incorporate prior knowledge\ninto CNNs.",
    "published": "2017-08-31T20:33:06Z",
    "pdf_url": "http://arxiv.org/pdf/1709.00069v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2309.00035v1",
    "title": "FACET: Fairness in Computer Vision Evaluation Benchmark",
    "authors": [
      "Laura Gustafson",
      "Chloe Rolland",
      "Nikhila Ravi",
      "Quentin Duval",
      "Aaron Adcock",
      "Cheng-Yang Fu",
      "Melissa Hall",
      "Candace Ross"
    ],
    "abstract": "Computer vision models have known performance disparities across attributes\nsuch as gender and skin tone. This means during tasks such as classification\nand detection, model performance differs for certain classes based on the\ndemographics of the people in the image. These disparities have been shown to\nexist, but until now there has not been a unified approach to measure these\ndifferences for common use-cases of computer vision models. We present a new\nbenchmark named FACET (FAirness in Computer Vision EvaluaTion), a large,\npublicly available evaluation set of 32k images for some of the most common\nvision tasks - image classification, object detection and segmentation. For\nevery image in FACET, we hired expert reviewers to manually annotate\nperson-related attributes such as perceived skin tone and hair type, manually\ndraw bounding boxes and label fine-grained person-related classes such as disk\njockey or guitarist. In addition, we use FACET to benchmark state-of-the-art\nvision models and present a deeper understanding of potential performance\ndisparities and challenges across sensitive demographic attributes. With the\nexhaustive annotations collected, we probe models using single demographics\nattributes as well as multiple attributes using an intersectional approach\n(e.g. hair color and perceived skin tone). Our results show that\nclassification, detection, segmentation, and visual grounding models exhibit\nperformance disparities across demographic attributes and intersections of\nattributes. These harms suggest that not all people represented in datasets\nreceive fair and equitable treatment in these vision tasks. We hope current and\nfuture results using our benchmark will contribute to fairer, more robust\nvision models. FACET is available publicly at https://facet.metademolab.com/",
    "published": "2023-08-31T17:59:48Z",
    "pdf_url": "http://arxiv.org/pdf/2309.00035v1",
    "categories": [
      "cs.CV",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1708.00069v1",
    "title": "Learning Robust Representations for Computer Vision",
    "authors": [
      "Peng Zheng",
      "Aleksandr Y. Aravkin",
      "Karthikeyan Natesan Ramamurthy",
      "Jayaraman Jayaraman Thiagarajan"
    ],
    "abstract": "Unsupervised learning techniques in computer vision often require learning\nlatent representations, such as low-dimensional linear and non-linear\nsubspaces. Noise and outliers in the data can frustrate these approaches by\nobscuring the latent spaces.\n  Our main goal is deeper understanding and new development of robust\napproaches for representation learning. We provide a new interpretation for\nexisting robust approaches and present two specific contributions: a new robust\nPCA approach, which can separate foreground features from dynamic background,\nand a novel robust spectral clustering method, that can cluster facial images\nwith high accuracy. Both contributions show superior performance to standard\nmethods on real-world test sets.",
    "published": "2017-07-31T20:50:01Z",
    "pdf_url": "http://arxiv.org/pdf/1708.00069v1",
    "categories": [
      "stat.ML",
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1811.02234v1",
    "title": "Semantic bottleneck for computer vision tasks",
    "authors": [
      "Maxime Bucher",
      "Stéphane Herbin",
      "Frédéric Jurie"
    ],
    "abstract": "This paper introduces a novel method for the representation of images that is\nsemantic by nature, addressing the question of computation intelligibility in\ncomputer vision tasks. More specifically, our proposition is to introduce what\nwe call a semantic bottleneck in the processing pipeline, which is a crossing\npoint in which the representation of the image is entirely expressed with\nnatural language , while retaining the efficiency of numerical representations.\nWe show that our approach is able to generate semantic representations that\ngive state-of-the-art results on semantic content-based image retrieval and\nalso perform very well on image classification tasks. Intelligibility is\nevaluated through user centered experiments for failure detection.",
    "published": "2018-11-06T09:01:02Z",
    "pdf_url": "http://arxiv.org/pdf/1811.02234v1",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "2004.03120v2",
    "title": "Ranking Computer Vision Service Issues using Emotion",
    "authors": [
      "Maheswaree K Curumsing",
      "Alex Cummaudo",
      "Ulrike Maria Graetsch",
      "Scott Barnett",
      "Rajesh Vasa"
    ],
    "abstract": "Software developers are increasingly using machine learning APIs to implement\n'intelligent' features. Studies show that incorporating machine learning into\nan application increases technical debt, creates data dependencies, and\nintroduces uncertainty due to non-deterministic behaviour. However, we know\nvery little about the emotional state of software developers who deal with such\nissues. In this paper, we do a landscape analysis of emotion found in 1,245\nStack Overflow posts about computer vision APIs. We investigate the application\nof an existing emotion classifier EmoTxt and manually verify our results. We\nfound that the emotion profile varies for different question categories.",
    "published": "2020-04-07T04:27:17Z",
    "pdf_url": "http://arxiv.org/pdf/2004.03120v2",
    "categories": [
      "cs.SE"
    ]
  },
  {
    "arxiv_id": "2004.08708v1",
    "title": "Adaptive Attention Span in Computer Vision",
    "authors": [
      "Jerrod Parker",
      "Shakti Kumar",
      "Joe Roussy"
    ],
    "abstract": "Recent developments in Transformers for language modeling have opened new\nareas of research in computer vision. Results from late 2019 showed vast\nperformance increases in both object detection and recognition when\nconvolutions are replaced by local self-attention kernels. Models using local\nself-attention kernels were also shown to have less parameters and FLOPS\ncompared to equivalent architectures that only use convolutions. In this work\nwe propose a novel method for learning the local self-attention kernel size. We\nthen compare its performance to fixed-size local attention and convolution\nkernels. The code for all our experiments and models is available at\nhttps://github.com/JoeRoussy/adaptive-attention-in-cv",
    "published": "2020-04-18T21:32:47Z",
    "pdf_url": "http://arxiv.org/pdf/2004.08708v1",
    "categories": [
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1211.4860v1",
    "title": "Domain Adaptations for Computer Vision Applications",
    "authors": [
      "Oscar Beijbom"
    ],
    "abstract": "A basic assumption of statistical learning theory is that train and test data\nare drawn from the same underlying distribution. Unfortunately, this assumption\ndoesn't hold in many applications. Instead, ample labeled data might exist in a\nparticular `source' domain while inference is needed in another, `target'\ndomain. Domain adaptation methods leverage labeled data from both domains to\nimprove classification on unseen data in the target domain. In this work we\nsurvey domain transfer learning methods for various application domains with\nfocus on recent work in Computer Vision.",
    "published": "2012-11-20T20:54:30Z",
    "pdf_url": "http://arxiv.org/pdf/1211.4860v1",
    "categories": [
      "cs.CV",
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2305.08075v1",
    "title": "Analyzing Compression Techniques for Computer Vision",
    "authors": [
      "Maniratnam Mandal",
      "Imran Khan"
    ],
    "abstract": "Compressing deep networks is highly desirable for practical use-cases in\ncomputer vision applications. Several techniques have been explored in the\nliterature, and research has been done in finding efficient strategies for\ncombining them. For this project, we aimed to explore three different basic\ncompression techniques - knowledge distillation, pruning, and quantization for\nsmall-scale recognition tasks. Along with the basic methods, we also test the\nefficacy of combining them in a sequential manner. We analyze them using MNIST\nand CIFAR-10 datasets and present the results along with few observations\ninferred from them.",
    "published": "2023-05-14T05:17:32Z",
    "pdf_url": "http://arxiv.org/pdf/2305.08075v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2211.14743v1",
    "title": "Searching for Uncollected Litter with Computer Vision",
    "authors": [
      "Julian Hernandez",
      "Clark Fitzgerald"
    ],
    "abstract": "This study combines photo metadata and computer vision to quantify where\nuncollected litter is present. Images from the Trash Annotations in Context\n(TACO) dataset were used to teach an algorithm to detect 10 categories of\ngarbage. Although it worked well with smartphone photos, it struggled when\ntrying to process images from vehicle mounted cameras. However, increasing the\nvariety of perspectives and backgrounds in the dataset will help it improve in\nunfamiliar situations. These data are plotted onto a map which, as accuracy\nimproves, could be used for measuring waste management strategies and\nquantifying trends.",
    "published": "2022-11-27T06:30:03Z",
    "pdf_url": "http://arxiv.org/pdf/2211.14743v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2412.00076v1",
    "title": "Flaws of ImageNet, Computer Vision's Favourite Dataset",
    "authors": [
      "Nikita Kisel",
      "Illia Volkov",
      "Katerina Hanzelkova",
      "Klara Janouskova",
      "Jiri Matas"
    ],
    "abstract": "Since its release, ImageNet-1k dataset has become a gold standard for\nevaluating model performance. It has served as the foundation for numerous\nother datasets and training tasks in computer vision. As models have improved\nin accuracy, issues related to label correctness have become increasingly\napparent. In this blog post, we analyze the issues in the ImageNet-1k dataset,\nincluding incorrect labels, overlapping or ambiguous class definitions,\ntraining-evaluation domain shifts, and image duplicates. The solutions for some\nproblems are straightforward. For others, we hope to start a broader\nconversation about refining this influential dataset to better serve future\nresearch.",
    "published": "2024-11-26T16:47:59Z",
    "pdf_url": "http://arxiv.org/pdf/2412.00076v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1412.2672v1",
    "title": "When Computer Vision Gazes at Cognition",
    "authors": [
      "Tao Gao",
      "Daniel Harari",
      "Joshua Tenenbaum",
      "Shimon Ullman"
    ],
    "abstract": "Joint attention is a core, early-developing form of social interaction. It is\nbased on our ability to discriminate the third party objects that other people\nare looking at. While it has been shown that people can accurately determine\nwhether another person is looking directly at them versus away, little is known\nabout human ability to discriminate a third person gaze directed towards\nobjects that are further away, especially in unconstraint cases where the\nlooker can move her head and eyes freely. In this paper we address this\nquestion by jointly exploring human psychophysics and a cognitively motivated\ncomputer vision model, which can detect the 3D direction of gaze from 2D face\nimages. The synthesis of behavioral study and computer vision yields several\ninteresting discoveries. (1) Human accuracy of discriminating targets\n8{\\deg}-10{\\deg} of visual angle apart is around 40% in a free looking gaze\ntask; (2) The ability to interpret gaze of different lookers vary dramatically;\n(3) This variance can be captured by the computational model; (4) Human\noutperforms the current model significantly. These results collectively show\nthat the acuity of human joint attention is indeed highly impressive, given the\ncomputational challenge of the natural looking task. Moreover, the gap between\nhuman and model performance, as well as the variability of gaze interpretation\nacross different lookers, require further understanding of the underlying\nmechanisms utilized by humans for this challenging task.",
    "published": "2014-12-08T17:25:57Z",
    "pdf_url": "http://arxiv.org/pdf/1412.2672v1",
    "categories": [
      "cs.AI",
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2111.08772v1",
    "title": "Computer Vision for Supporting Image Search",
    "authors": [
      "Alan F. Smeaton"
    ],
    "abstract": "Computer vision and multimedia information processing have made extreme\nprogress within the last decade and many tasks can be done with a level of\naccuracy as if done by humans, or better. This is because we leverage the\nbenefits of huge amounts of data available for training, we have enormous\ncomputer processing available and we have seen the evolution of machine\nlearning as a suite of techniques to process data and deliver accurate\nvision-based systems. What kind of applications do we use this processing for ?\nWe use this in autonomous vehicle navigation or in security applications,\nsearching CCTV for example, and in medical image analysis for healthcare\ndiagnostics. One application which is not widespread is image or video search\ndirectly by users. In this paper we present the need for such image finding or\nre-finding by examining human memory and when it fails, thus motivating the\nneed for a different approach to image search which is outlined, along with the\nrequirements of computer vision to support it.",
    "published": "2021-11-16T20:50:32Z",
    "pdf_url": "http://arxiv.org/pdf/2111.08772v1",
    "categories": [
      "cs.CV",
      "cs.IR"
    ]
  },
  {
    "arxiv_id": "2302.05011v1",
    "title": "Context Understanding in Computer Vision: A Survey",
    "authors": [
      "Xuan Wang",
      "Zhigang Zhu"
    ],
    "abstract": "Contextual information plays an important role in many computer vision tasks,\nsuch as object detection, video action detection, image classification, etc.\nRecognizing a single object or action out of context could be sometimes very\nchallenging, and context information may help improve the understanding of a\nscene or an event greatly. Appearance context information, e.g., colors or\nshapes of the background of an object can improve the recognition accuracy of\nthe object in the scene. Semantic context (e.g. a keyboard on an empty desk vs.\na keyboard next to a desktop computer ) will improve accuracy and exclude\nunrelated events. Context information that are not in the image itself, such as\nthe time or location of an images captured, can also help to decide whether\ncertain event or action should occur. Other types of context (e.g. 3D structure\nof a building) will also provide additional information to improve the\naccuracy. In this survey, different context information that has been used in\ncomputer vision tasks is reviewed. We categorize context into different types\nand different levels. We also review available machine learning models and\nimage/video datasets that can employ context information. Furthermore, we\ncompare context based integration and context-free integration in mainly two\nclasses of tasks: image-based and video-based. Finally, this survey is\nconcluded by a set of promising future directions in context learning and\nutilization.",
    "published": "2023-02-10T02:01:21Z",
    "pdf_url": "http://arxiv.org/pdf/2302.05011v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2312.12848v1",
    "title": "Quantum Annealing for Computer Vision Minimization Problems",
    "authors": [
      "Shahrokh Heidari",
      "Michael J. Dinneen",
      "Patrice Delmas"
    ],
    "abstract": "Computer Vision (CV) labelling algorithms play a pivotal role in the domain\nof low-level vision. For decades, it has been known that these problems can be\nelegantly formulated as discrete energy minimization problems derived from\nprobabilistic graphical models (such as Markov Random Fields). Despite recent\nadvances in inference algorithms (such as graph-cut and message-passing\nalgorithms), the resulting energy minimization problems are generally viewed as\nintractable. The emergence of quantum computations, which offer the potential\nfor faster solutions to certain problems than classical methods, has led to an\nincreased interest in utilizing quantum properties to overcome intractable\nproblems. Recently, there has also been a growing interest in Quantum Computer\nVision (QCV), with the hope of providing a credible alternative or assistant to\ndeep learning solutions in the field. This study investigates a new Quantum\nAnnealing based inference algorithm for CV discrete energy minimization\nproblems. Our contribution is focused on Stereo Matching as a significant CV\nlabeling problem. As a proof of concept, we also use a hybrid quantum-classical\nsolver provided by D-Wave System to compare our results with the best classical\ninference algorithms in the literature.",
    "published": "2023-12-20T08:56:35Z",
    "pdf_url": "http://arxiv.org/pdf/2312.12848v1",
    "categories": [
      "quant-ph",
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2408.14281v1",
    "title": "Uncertainties of Latent Representations in Computer Vision",
    "authors": [
      "Michael Kirchhof"
    ],
    "abstract": "Uncertainty quantification is a key pillar of trustworthy machine learning.\nIt enables safe reactions under unsafe inputs, like predicting only when the\nmachine learning model detects sufficient evidence, discarding anomalous data,\nor emitting warnings when an error is likely to be inbound. This is\nparticularly crucial in safety-critical areas like medical image classification\nor self-driving cars. Despite the plethora of proposed uncertainty\nquantification methods achieving increasingly higher scores on performance\nbenchmarks, uncertainty estimates are often shied away from in practice. Many\nmachine learning projects start from pretrained latent representations that\ncome without uncertainty estimates. Uncertainties would need to be trained by\npractitioners on their own, which is notoriously difficult and\nresource-intense.\n  This thesis makes uncertainty estimates easily accessible by adding them to\nthe latent representation vectors of pretrained computer vision models. Besides\nproposing approaches rooted in probability and decision theory, such as\nMonte-Carlo InfoNCE (MCInfoNCE) and loss prediction, we delve into both\ntheoretical and empirical questions. We show that these unobservable\nuncertainties about unobservable latent representations are indeed provably\ncorrect. We also provide an uncertainty-aware representation learning (URL)\nbenchmark to compare these unobservables against observable ground-truths.\nFinally, we compile our findings to pretrain lightweight representation\nuncertainties on large-scale computer vision models that transfer to unseen\ndatasets in a zero-shot manner.\n  Our findings do not only advance the current theoretical understanding of\nuncertainties over latent variables, but also facilitate the access to\nuncertainty quantification for future researchers inside and outside the field,\nenabling straightforward but trustworthy machine learning.",
    "published": "2024-08-26T14:02:30Z",
    "pdf_url": "http://arxiv.org/pdf/2408.14281v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1809.04659v2",
    "title": "Are object detection assessment criteria ready for maritime computer\n  vision?",
    "authors": [
      "Dilip K. Prasad",
      "Huixu Dong",
      "Deepu Rajan",
      "Chai Quek"
    ],
    "abstract": "Maritime vessels equipped with visible and infrared cameras can complement\nother conventional sensors for object detection. However, application of\ncomputer vision techniques in maritime domain received attention only recently.\nThe maritime environment offers its own unique requirements and challenges.\nAssessment of the quality of detections is a fundamental need in computer\nvision. However, the conventional assessment metrics suitable for usual object\ndetection are deficient in the maritime setting. Thus, a large body of related\nwork in computer vision appears inapplicable to the maritime setting at the\nfirst sight. We discuss the problem of defining assessment metrics suitable for\nmaritime computer vision. We consider new bottom edge proximity metrics as\nassessment metrics for maritime computer vision. These metrics indicate that\nexisting computer vision approaches are indeed promising for maritime computer\nvision and can play a foundational role in the emerging field of maritime\ncomputer vision.",
    "published": "2018-09-12T20:18:04Z",
    "pdf_url": "http://arxiv.org/pdf/1809.04659v2",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1808.03998v1",
    "title": "Enhancing camera surveillance using computer vision: a research note",
    "authors": [
      "Haroon Idrees",
      "Mubarak Shah",
      "Ray Surette"
    ],
    "abstract": "$\\mathbf{Purpose}$ - The growth of police operated surveillance cameras has\nout-paced the ability of humans to monitor them effectively. Computer vision is\na possible solution. An ongoing research project on the application of computer\nvision within a municipal police department is described. The paper aims to\ndiscuss these issues.\n  $\\mathbf{Design/methodology/approach}$ - Following the demystification of\ncomputer vision technology, its potential for police agencies is developed\nwithin a focus on computer vision as a solution for two common surveillance\ncamera tasks (live monitoring of multiple surveillance cameras and summarizing\narchived video files). Three unaddressed research questions (can specialized\ncomputer vision applications for law enforcement be developed at this time, how\nwill computer vision be utilized within existing public safety camera\nmonitoring rooms, and what are the system-wide impacts of a computer vision\ncapability on local criminal justice systems) are considered.\n  $\\mathbf{Findings}$ - Despite computer vision becoming accessible to law\nenforcement agencies the impact of computer vision has not been discussed or\nadequately researched. There is little knowledge of computer vision or its\npotential in the field.\n  $\\mathbf{Originality/value}$ - This paper introduces and discusses computer\nvision from a law enforcement perspective and will be valuable to police\npersonnel tasked with monitoring large camera networks and considering computer\nvision as a system upgrade.",
    "published": "2018-08-12T20:01:37Z",
    "pdf_url": "http://arxiv.org/pdf/1808.03998v1",
    "categories": [
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "2101.11217v1",
    "title": "Automated Crop Field Surveillance using Computer Vision",
    "authors": [
      "Tejas Atul Khare",
      "Anuradha C. Phadke"
    ],
    "abstract": "Artificial Intelligence is everywhere today. But unfortunately, Agriculture\nhas not been able to get that much attention from Artificial Intelligence (AI).\nA lack of automation persists in the agriculture industry. For over many years,\nfarmers and crop field owners have been facing a problem of trespassing of wild\nanimals for which no feasible solution has been provided. Installing a fence or\nbarrier like structure is neither feasible nor efficient due to the large areas\ncovered by the fields. Also, if the landowner can afford to build a wall or\nbarrier, government policies for building walls are often very irksome. The\npaper intends to give a simple intelligible solution to the problem with\nAutomated Crop Field Surveillance using Computer Vision. The solution will\nsignificantly reduce the cost of crops destroyed annually and completely\nautomate the security of the field.",
    "published": "2021-01-27T05:58:28Z",
    "pdf_url": "http://arxiv.org/pdf/2101.11217v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2107.04902v3",
    "title": "Industry and Academic Research in Computer Vision",
    "authors": [
      "Iuliia Kotseruba",
      "Manos Papagelis",
      "John K. Tsotsos"
    ],
    "abstract": "This work aims to study the dynamic between research in the industry and\nacademia in computer vision. The results are demonstrated on a set of top-5\nvision conferences that are representative of the field. Since data for such\nanalysis was not readily available, significant effort was spent on gathering\nand processing meta-data from the original publications. First, this study\nquantifies the share of industry-sponsored research. Specifically, it shows\nthat the proportion of papers published by industry-affiliated researchers is\nincreasing and that more academics join companies or collaborate with them.\nNext, the possible impact of industry presence is further explored, namely in\nthe distribution of research topics and citation patterns. The results indicate\nthat the distribution of the research topics is similar in industry and\nacademic papers. However, there is a strong preference towards citing industry\npapers. Finally, possible reasons for citation bias, such as code availability\nand influence, are investigated.",
    "published": "2021-07-10T20:09:52Z",
    "pdf_url": "http://arxiv.org/pdf/2107.04902v3",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2104.08702v1",
    "title": "Reconsidering CO2 emissions from Computer Vision",
    "authors": [
      "Andre Fu",
      "Mahdi S. Hosseini",
      "Konstantinos N. Plataniotis"
    ],
    "abstract": "Climate change is a pressing issue that is currently affecting and will\naffect every part of our lives. It's becoming incredibly vital we, as a\nsociety, address the climate crisis as a universal effort, including those in\nthe Computer Vision (CV) community. In this work, we analyze the total cost of\nCO2 emissions by breaking it into (1) the architecture creation cost and (2)\nthe life-time evaluation cost. We show that over time, these costs are\nnon-negligible and are having a direct impact on our future. Importantly, we\nconduct an ethical analysis of how the CV-community is unintentionally\noverlooking its own ethical AI principles by emitting this level of CO2. To\naddress these concerns, we propose adding \"enforcement\" as a pillar of ethical\nAI and provide some recommendations for how architecture designers and broader\nCV community can curb the climate crisis.",
    "published": "2021-04-18T04:01:40Z",
    "pdf_url": "http://arxiv.org/pdf/2104.08702v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1603.09599v1",
    "title": "Total Variation Applications in Computer Vision",
    "authors": [
      "Vania V. Estrela",
      "Hermes Aguiar Magalhaes",
      "Osamu Saotome"
    ],
    "abstract": "The objectives of this chapter are: (i) to introduce a concise overview of\nregularization; (ii) to define and to explain the role of a particular type of\nregularization called total variation norm (TV-norm) in computer vision tasks;\n(iii) to set up a brief discussion on the mathematical background of TV\nmethods; and (iv) to establish a relationship between models and a few existing\nmethods to solve problems cast as TV-norm. For the most part, image-processing\nalgorithms blur the edges of the estimated images, however TV regularization\npreserves the edges with no prior information on the observed and the original\nimages. The regularization scalar parameter {\\lambda} controls the amount of\nregularization allowed and it is an essential to obtain a high-quality\nregularized output. A wide-ranging review of several ways to put into practice\nTV regularization as well as its advantages and limitations are discussed.",
    "published": "2016-03-31T14:08:53Z",
    "pdf_url": "http://arxiv.org/pdf/1603.09599v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2003.08863v3",
    "title": "Towards a Computer Vision Particle Flow",
    "authors": [
      "Francesco Armando Di Bello",
      "Sanmay Ganguly",
      "Eilam Gross",
      "Marumi Kado",
      "Michael Pitt",
      "Lorenzo Santi",
      "Jonathan Shlomi"
    ],
    "abstract": "In High Energy Physics experiments Particle Flow (PFlow) algorithms are\ndesigned to provide an optimal reconstruction of the nature and kinematic\nproperties of the particles produced within the detector acceptance during\ncollisions. At the heart of PFlow algorithms is the ability to distinguish the\ncalorimeter energy deposits of neutral particles from those of charged\nparticles, using the complementary measurements of charged particle tracking\ndevices, to provide a superior measurement of the particle content and\nkinematics. In this paper, a computer vision approach to this fundamental\naspect of PFlow algorithms, based on calorimeter images, is proposed. A\ncomparative study of the state of the art deep learning techniques is\nperformed. A significantly improved reconstruction of the neutral particle\ncalorimeter energy deposits is obtained in a context of large overlaps with the\ndeposits from charged particles. Calorimeter images with augmented finer\ngranularity are also obtained using super-resolution techniques.",
    "published": "2020-03-19T15:26:23Z",
    "pdf_url": "http://arxiv.org/pdf/2003.08863v3",
    "categories": [
      "physics.data-an",
      "hep-ex",
      "hep-ph",
      "physics.ins-det",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2003.13988v2",
    "title": "Fashion Meets Computer Vision: A Survey",
    "authors": [
      "Wen-Huang Cheng",
      "Sijie Song",
      "Chieh-Yun Chen",
      "Shintami Chusnul Hidayati",
      "Jiaying Liu"
    ],
    "abstract": "Fashion is the way we present ourselves to the world and has become one of\nthe world's largest industries. Fashion, mainly conveyed by vision, has thus\nattracted much attention from computer vision researchers in recent years.\nGiven the rapid development, this paper provides a comprehensive survey of more\nthan 200 major fashion-related works covering four main aspects for enabling\nintelligent fashion: (1) Fashion detection includes landmark detection, fashion\nparsing, and item retrieval, (2) Fashion analysis contains attribute\nrecognition, style learning, and popularity prediction, (3) Fashion synthesis\ninvolves style transfer, pose transformation, and physical simulation, and (4)\nFashion recommendation comprises fashion compatibility, outfit matching, and\nhairstyle suggestion. For each task, the benchmark datasets and the evaluation\nprotocols are summarized. Furthermore, we highlight promising directions for\nfuture research.",
    "published": "2020-03-31T07:08:23Z",
    "pdf_url": "http://arxiv.org/pdf/2003.13988v2",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2304.10764v1",
    "title": "Hyperbolic Geometry in Computer Vision: A Survey",
    "authors": [
      "Pengfei Fang",
      "Mehrtash Harandi",
      "Trung Le",
      "Dinh Phung"
    ],
    "abstract": "Hyperbolic geometry, a Riemannian manifold endowed with constant sectional\nnegative curvature, has been considered an alternative embedding space in many\nlearning scenarios, \\eg, natural language processing, graph learning, \\etc, as\na result of its intriguing property of encoding the data's hierarchical\nstructure (like irregular graph or tree-likeness data). Recent studies prove\nthat such data hierarchy also exists in the visual dataset, and investigate the\nsuccessful practice of hyperbolic geometry in the computer vision (CV) regime,\nranging from the classical image classification to advanced model adaptation\nlearning. This paper presents the first and most up-to-date literature review\nof hyperbolic spaces for CV applications. To this end, we first introduce the\nbackground of hyperbolic geometry, followed by a comprehensive investigation of\nalgorithms, with geometric prior of hyperbolic space, in the context of visual\napplications. We also conclude this manuscript and identify possible future\ndirections.",
    "published": "2023-04-21T06:22:16Z",
    "pdf_url": "http://arxiv.org/pdf/2304.10764v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2401.03400v1",
    "title": "Entanglement Structure Detection via Computer Vision",
    "authors": [
      "Rui Li",
      "Junling Du",
      "Zheng Qin",
      "Shikun Zhang",
      "Chunxiao Du",
      "Yang Zhou",
      "Zhisong Xiao"
    ],
    "abstract": "Quantum entanglement plays a pivotal role in various quantum information\nprocessing tasks. However, there still lacks a universal and effective way to\ndetecting entanglement structures, especially for high-dimensional and\nmultipartite quantum systems. Noticing the mathematical similarities between\nthe common representations of many-body quantum states and the data structures\nof images, we are inspired to employ advanced computer vision technologies for\ndata analysis. In this work, we propose a hybrid CNN-Transformer model for both\nthe classification of GHZ and W states and the detection of various\nentanglement structures. By leveraging the feature extraction capabilities of\nCNNs and the powerful modeling abilities of Transformers, we can not only\neffectively reduce the time and computational resources required for the\ntraining process but also obtain high detection accuracies. Through numerical\nsimulation and physical verification, it is confirmed that our hybrid model is\nmore effective than traditional techniques and thus offers a powerful tool for\nindependent detection of multipartite entanglement.",
    "published": "2024-01-07T07:11:22Z",
    "pdf_url": "http://arxiv.org/pdf/2401.03400v1",
    "categories": [
      "quant-ph"
    ]
  },
  {
    "arxiv_id": "2403.00689v1",
    "title": "Hydra: Computer Vision for Data Quality Monitoring",
    "authors": [
      "Thomas Britton",
      "Torri Jeske",
      "David Lawrence",
      "Kishansingh Rajput"
    ],
    "abstract": "Hydra is a system which utilizes computer vision to perform near real time\ndata quality management, initially developed for Hall-D in 2019. Since then, it\nhas been deployed across all experimental halls at Jefferson Lab, with the\nCLAS12 collaboration in Hall-B being the first outside of GlueX to fully\nutilize Hydra. The system comprises back end processes that manage the models,\ntheir inferences, and the data flow. The front-end components, accessible via\nweb pages, allow detector experts and shift crews to view and interact with the\nsystem. This talk will give an overview of the Hydra system as well as\nhighlight significant developments in Hydra's feature set, acute challenges\nwith operating Hydra in all halls, and lessons learned along the way.",
    "published": "2024-03-01T17:20:58Z",
    "pdf_url": "http://arxiv.org/pdf/2403.00689v1",
    "categories": [
      "cs.CV",
      "nucl-ex",
      "physics.ins-det"
    ]
  },
  {
    "arxiv_id": "2509.08712v1",
    "title": "Computational Imaging for Enhanced Computer Vision",
    "authors": [
      "Humera Shaikh",
      "Kaur Jashanpreet"
    ],
    "abstract": "This paper presents a comprehensive survey of computational imaging (CI)\ntechniques and their transformative impact on computer vision (CV)\napplications. Conventional imaging methods often fail to deliver high-fidelity\nvisual data in challenging conditions, such as low light, motion blur, or high\ndynamic range scenes, thereby limiting the performance of state-of-the-art CV\nsystems. Computational imaging techniques, including light field imaging, high\ndynamic range (HDR) imaging, deblurring, high-speed imaging, and glare\nmitigation, address these limitations by enhancing image acquisition and\nreconstruction processes. This survey systematically explores the synergies\nbetween CI techniques and core CV tasks, including object detection, depth\nestimation, optical flow, face recognition, and keypoint detection. By\nanalyzing the relationships between CI methods and their practical\ncontributions to CV applications, this work highlights emerging opportunities,\nchallenges, and future research directions. We emphasize the potential for\ntask-specific, adaptive imaging pipelines that improve robustness, accuracy,\nand efficiency in real-world scenarios, such as autonomous navigation,\nsurveillance, augmented reality, and robotics.",
    "published": "2025-09-10T16:02:42Z",
    "pdf_url": "http://arxiv.org/pdf/2509.08712v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2306.09179v1",
    "title": "Neural World Models for Computer Vision",
    "authors": [
      "Anthony Hu"
    ],
    "abstract": "Humans navigate in their environment by learning a mental model of the world\nthrough passive observation and active interaction. Their world model allows\nthem to anticipate what might happen next and act accordingly with respect to\nan underlying objective. Such world models hold strong promises for planning in\ncomplex environments like in autonomous driving. A human driver, or a\nself-driving system, perceives their surroundings with their eyes or their\ncameras. They infer an internal representation of the world which should: (i)\nhave spatial memory (e.g. occlusions), (ii) fill partially observable or noisy\ninputs (e.g. when blinded by sunlight), and (iii) be able to reason about\nunobservable events probabilistically (e.g. predict different possible\nfutures). They are embodied intelligent agents that can predict, plan, and act\nin the physical world through their world model. In this thesis we present a\ngeneral framework to train a world model and a policy, parameterised by deep\nneural networks, from camera observations and expert demonstrations. We\nleverage important computer vision concepts such as geometry, semantics, and\nmotion to scale world models to complex urban driving scenes.\n  First, we propose a model that predicts important quantities in computer\nvision: depth, semantic segmentation, and optical flow. We then use 3D geometry\nas an inductive bias to operate in the bird's-eye view space. We present for\nthe first time a model that can predict probabilistic future trajectories of\ndynamic agents in bird's-eye view from 360{\\deg} surround monocular cameras\nonly. Finally, we demonstrate the benefits of learning a world model in\nclosed-loop driving. Our model can jointly predict static scene, dynamic scene,\nand ego-behaviour in an urban driving environment.",
    "published": "2023-06-15T14:58:21Z",
    "pdf_url": "http://arxiv.org/pdf/2306.09179v1",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ]
  },
  {
    "arxiv_id": "1506.04130v3",
    "title": "CloudCV: Large Scale Distributed Computer Vision as a Cloud Service",
    "authors": [
      "Harsh Agrawal",
      "Clint Solomon Mathialagan",
      "Yash Goyal",
      "Neelima Chavali",
      "Prakriti Banik",
      "Akrit Mohapatra",
      "Ahmed Osman",
      "Dhruv Batra"
    ],
    "abstract": "We are witnessing a proliferation of massive visual data. Unfortunately\nscaling existing computer vision algorithms to large datasets leaves\nresearchers repeatedly solving the same algorithmic, logistical, and\ninfrastructural problems. Our goal is to democratize computer vision; one\nshould not have to be a computer vision, big data and distributed computing\nexpert to have access to state-of-the-art distributed computer vision\nalgorithms. We present CloudCV, a comprehensive system to provide access to\nstate-of-the-art distributed computer vision algorithms as a cloud service\nthrough a Web Interface and APIs.",
    "published": "2015-06-12T19:50:07Z",
    "pdf_url": "http://arxiv.org/pdf/1506.04130v3",
    "categories": [
      "cs.CV",
      "cs.DC"
    ]
  },
  {
    "arxiv_id": "1512.00567v3",
    "title": "Rethinking the Inception Architecture for Computer Vision",
    "authors": [
      "Christian Szegedy",
      "Vincent Vanhoucke",
      "Sergey Ioffe",
      "Jonathon Shlens",
      "Zbigniew Wojna"
    ],
    "abstract": "Convolutional networks are at the core of most state-of-the-art computer\nvision solutions for a wide variety of tasks. Since 2014 very deep\nconvolutional networks started to become mainstream, yielding substantial gains\nin various benchmarks. Although increased model size and computational cost\ntend to translate to immediate quality gains for most tasks (as long as enough\nlabeled data is provided for training), computational efficiency and low\nparameter count are still enabling factors for various use cases such as mobile\nvision and big-data scenarios. Here we explore ways to scale up networks in\nways that aim at utilizing the added computation as efficiently as possible by\nsuitably factorized convolutions and aggressive regularization. We benchmark\nour methods on the ILSVRC 2012 classification challenge validation set\ndemonstrate substantial gains over the state of the art: 21.2% top-1 and 5.6%\ntop-5 error for single frame evaluation using a network with a computational\ncost of 5 billion multiply-adds per inference and with using less than 25\nmillion parameters. With an ensemble of 4 models and multi-crop evaluation, we\nreport 3.5% top-5 error on the validation set (3.6% error on the test set) and\n17.3% top-1 error on the validation set.",
    "published": "2015-12-02T03:44:38Z",
    "pdf_url": "http://arxiv.org/pdf/1512.00567v3",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1609.09582v1",
    "title": "Digitizing Municipal Street Inspections Using Computer Vision",
    "authors": [
      "Varun Adibhatla",
      "Shi Fan",
      "Krystof Litomisky",
      "Patrick Atwater"
    ],
    "abstract": "\"People want an authority to tell them how to value things. But they chose\nthis authority not based on facts or results. They chose it because it seems\nauthoritative and familiar.\" - The Big Short\n  The pavement condition index is one such a familiar measure used by many US\ncities to measure street quality and justify billions of dollars spent every\nyear on street repair. These billion-dollar decisions are based on evaluation\ncriteria that are subjective and not representative. In this paper, we build\nupon our initial submission to D4GX 2015 that approaches this problem of\ninformation asymmetry in municipal decision-making.\n  We describe a process to identify street-defects using computer vision\ntechniques on data collected using the Street Quality Identification Device\n(SQUID). A User Interface to host a large quantity of image data towards\ndigitizing the street inspection process and enabling actionable intelligence\nfor a core public service is also described. This approach of combining device,\ndata and decision-making around street repair enables cities make targeted\ndecisions about street repair and could lead to an anticipatory response which\ncan result in significant cost savings. Lastly, we share lessons learnt from\nthe deployment of SQUID in the city of Syracuse, NY.",
    "published": "2016-09-30T03:36:03Z",
    "pdf_url": "http://arxiv.org/pdf/1609.09582v1",
    "categories": [
      "cs.CY",
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2003.08485v1",
    "title": "Self-Supervised Contextual Bandits in Computer Vision",
    "authors": [
      "Aniket Anand Deshmukh",
      "Abhimanu Kumar",
      "Levi Boyles",
      "Denis Charles",
      "Eren Manavoglu",
      "Urun Dogan"
    ],
    "abstract": "Contextual bandits are a common problem faced by machine learning\npractitioners in domains as diverse as hypothesis testing to product\nrecommendations. There have been a lot of approaches in exploiting rich data\nrepresentations for contextual bandit problems with varying degree of success.\nSelf-supervised learning is a promising approach to find rich data\nrepresentations without explicit labels. In a typical self-supervised learning\nscheme, the primary task is defined by the problem objective (e.g. clustering,\nclassification, embedding generation etc.) and the secondary task is defined by\nthe self-supervision objective (e.g. rotation prediction, words in\nneighborhood, colorization, etc.). In the usual self-supervision, we learn\nimplicit labels from the training data for a secondary task. However, in the\ncontextual bandit setting, we don't have the advantage of getting implicit\nlabels due to lack of data in the initial phase of learning. We provide a novel\napproach to tackle this issue by combining a contextual bandit objective with a\nself supervision objective. By augmenting contextual bandit learning with\nself-supervision we get a better cumulative reward. Our results on eight\npopular computer vision datasets show substantial gains in cumulative reward.\nWe provide cases where the proposed scheme doesn't perform optimally and give\nalternative methods for better learning in these cases.",
    "published": "2020-03-18T22:06:34Z",
    "pdf_url": "http://arxiv.org/pdf/2003.08485v1",
    "categories": [
      "cs.CV",
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2201.00095v1",
    "title": "Computer Vision Based Parking Optimization System",
    "authors": [
      "Siddharth Chandrasekaran",
      "Jeffrey Matthew Reginald",
      "Wei Wang",
      "Ting Zhu"
    ],
    "abstract": "An improvement in technology is linearly related to time and time-relevant\nproblems. It has been seen that as time progresses, the number of problems\nhumans face also increases. However, technology to resolve these problems tends\nto improve as well. One of the earliest existing problems which started with\nthe invention of vehicles was parking. The ease of resolving this problem using\ntechnology has evolved over the years but the problem of parking still remains\nunsolved. The main reason behind this is that parking does not only involve one\nproblem but it consists of a set of problems within itself. One of these\nproblems is the occupancy detection of the parking slots in a distributed\nparking ecosystem. In a distributed system, users would find preferable parking\nspaces as opposed to random parking spaces. In this paper, we propose a\nweb-based application as a solution for parking space detection in different\nparking spaces. The solution is based on Computer Vision (CV) and is built\nusing the Django framework written in Python 3.0. The solution works to resolve\nthe occupancy detection problem along with providing the user the option to\ndetermine the block based on availability and his preference. The evaluation\nresults for our proposed system are promising and efficient. The proposed\nsystem can also be integrated with different systems and be used for solving\nother relevant parking problems.",
    "published": "2022-01-01T02:35:49Z",
    "pdf_url": "http://arxiv.org/pdf/2201.00095v1",
    "categories": [
      "cs.CV",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2211.13137v1",
    "title": "Pruned Lightweight Encoders for Computer Vision",
    "authors": [
      "Jakub Žádník",
      "Markku Mäkitalo",
      "Pekka Jääskeläinen"
    ],
    "abstract": "Latency-critical computer vision systems, such as autonomous driving or drone\ncontrol, require fast image or video compression when offloading neural network\ninference to a remote computer. To ensure low latency on a near-sensor edge\ndevice, we propose the use of lightweight encoders with constant bitrate and\npruned encoding configurations, namely, ASTC and JPEG XS. Pruning introduces\nsignificant distortion which we show can be recovered by retraining the neural\nnetwork with compressed data after decompression. Such an approach does not\nmodify the network architecture or require coding format modifications. By\nretraining with compressed datasets, we reduced the classification accuracy and\nsegmentation mean intersection over union (mIoU) degradation due to ASTC\ncompression to 4.9-5.0 percentage points (pp) and 4.4-4.0 pp, respectively.\nWith the same method, the mIoU lost due to JPEG XS compression at the main\nprofile was restored to 2.7-2.3 pp. In terms of encoding speed, our ASTC\nencoder implementation is 2.3x faster than JPEG. Even though the JPEG XS\nreference encoder requires optimizations to reach low latency, we showed that\ndisabling significance flag coding saves 22-23% of encoding time at the cost of\n0.4-0.3 mIoU after retraining.",
    "published": "2022-11-23T17:11:48Z",
    "pdf_url": "http://arxiv.org/pdf/2211.13137v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2301.05070v1",
    "title": "Wildfire Smoke Detection with Computer Vision",
    "authors": [
      "Eldan R. Daniel"
    ],
    "abstract": "Wildfires are becoming more frequent and their effects more devastating every\nday. Climate change has directly and indirectly affected the occurrence of\nthese, as well as social phenomena have increased the vulnerability of people.\nConsequently, and given the inevitable occurrence of these, it is important to\nhave early warning systems that allow a timely and effective response.\nArtificial intelligence, machine learning and Computer Vision offer an\neffective and achievable alternative for opportune detection of wildfires and\nthus reduce the risk of disasters. YOLOv7 offers a simple, fast, and efficient\nalgorithm for training object detection models which can be used in early\ndetection of smoke columns in the initial stage wildfires. The developed model\nshowed promising results, achieving a score of 0.74 in the F1 curve when the\nconfidence level is 0.298, that is, a higher score at lower confidence levels\nwas obtained. This means when the conditions are favorable for false positives.\nThe metrics demonstrates the resilience and effectiveness of the model in\ndetecting smoke columns.",
    "published": "2023-01-12T15:12:56Z",
    "pdf_url": "http://arxiv.org/pdf/2301.05070v1",
    "categories": [
      "cs.CV",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2303.11684v2",
    "title": "SpikeCV: Open a Continuous Computer Vision Era",
    "authors": [
      "Yajing Zheng",
      "Jiyuan Zhang",
      "Rui Zhao",
      "Jianhao Ding",
      "Shiyan Chen",
      "Ruiqin Xiong",
      "Zhaofei Yu",
      "Tiejun Huang"
    ],
    "abstract": "SpikeCV is a new open-source computer vision platform for the spike camera,\nwhich is a neuromorphic visual sensor that has developed rapidly in recent\nyears. In the spike camera, each pixel position directly accumulates the light\nintensity and asynchronously fires spikes. The output binary spikes can reach a\nfrequency of 40,000 Hz. As a new type of visual expression, spike sequence has\nhigh spatiotemporal completeness and preserves the continuous visual\ninformation of the external world. Taking advantage of the low latency and high\ndynamic range of the spike camera, many spike-based algorithms have made\nsignificant progress, such as high-quality imaging and ultra-high-speed target\ndetection.\n  To build up a community ecology for the spike vision to facilitate more users\nto take advantage of the spike camera, SpikeCV provides a variety of\nultra-high-speed scene datasets, hardware interfaces, and an easy-to-use\nmodules library. SpikeCV focuses on encapsulation for spike data,\nstandardization for dataset interfaces, modularization for vision tasks, and\nreal-time applications for challenging scenes. With the advent of the\nopen-source Python ecosystem, modules of SpikeCV can be used as a Python\nlibrary to fulfilled most of the numerical analysis needs of researchers. We\ndemonstrate the efficiency of the SpikeCV on offline inference and real-time\napplications. The project repository address are\n\\url{https://openi.pcl.ac.cn/Cordium/SpikeCV} and\n\\url{https://github.com/Zyj061/SpikeCV",
    "published": "2023-03-21T09:00:12Z",
    "pdf_url": "http://arxiv.org/pdf/2303.11684v2",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2307.13992v2",
    "title": "Causal reasoning in typical computer vision tasks",
    "authors": [
      "Kexuan Zhang",
      "Qiyu Sun",
      "Chaoqiang Zhao",
      "Yang Tang"
    ],
    "abstract": "Deep learning has revolutionized the field of artificial intelligence. Based\non the statistical correlations uncovered by deep learning-based methods,\ncomputer vision has contributed to tremendous growth in areas like autonomous\ndriving and robotics. Despite being the basis of deep learning, such\ncorrelation is not stable and is susceptible to uncontrolled factors. In the\nabsence of the guidance of prior knowledge, statistical correlations can easily\nturn into spurious correlations and cause confounders. As a result, researchers\nare now trying to enhance deep learning methods with causal theory. Causal\ntheory models the intrinsic causal structure unaffected by data bias and is\neffective in avoiding spurious correlations. This paper aims to comprehensively\nreview the existing causal methods in typical vision and vision-language tasks\nsuch as semantic segmentation, object detection, and image captioning. The\nadvantages of causality and the approaches for building causal paradigms will\nbe summarized. Future roadmaps are also proposed, including facilitating the\ndevelopment of causal theory and its application in other complex scenes and\nsystems.",
    "published": "2023-07-26T07:01:57Z",
    "pdf_url": "http://arxiv.org/pdf/2307.13992v2",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2309.10878v1",
    "title": "DeepliteRT: Computer Vision at the Edge",
    "authors": [
      "Saad Ashfaq",
      "Alexander Hoffman",
      "Saptarshi Mitra",
      "Sudhakar Sah",
      "MohammadHossein AskariHemmat",
      "Ehsan Saboori"
    ],
    "abstract": "The proliferation of edge devices has unlocked unprecedented opportunities\nfor deep learning model deployment in computer vision applications. However,\nthese complex models require considerable power, memory and compute resources\nthat are typically not available on edge platforms. Ultra low-bit quantization\npresents an attractive solution to this problem by scaling down the model\nweights and activations from 32-bit to less than 8-bit. We implement highly\noptimized ultra low-bit convolution operators for ARM-based targets that\noutperform existing methods by up to 4.34x. Our operator is implemented within\nDeeplite Runtime (DeepliteRT), an end-to-end solution for the compilation,\ntuning, and inference of ultra low-bit models on ARM devices. Compiler passes\nin DeepliteRT automatically convert a fake-quantized model in full precision to\na compact ultra low-bit representation, easing the process of quantized model\ndeployment on commodity hardware. We analyze the performance of DeepliteRT on\nclassification and detection models against optimized 32-bit floating-point,\n8-bit integer, and 2-bit baselines, achieving significant speedups of up to\n2.20x, 2.33x and 2.17x, respectively.",
    "published": "2023-09-19T18:58:38Z",
    "pdf_url": "http://arxiv.org/pdf/2309.10878v1",
    "categories": [
      "cs.LG",
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2404.01116v1",
    "title": "Intelligent Robotic Control System Based on Computer Vision Technology",
    "authors": [
      "Chang Che",
      "Haotian Zheng",
      "Zengyi Huang",
      "Wei Jiang",
      "Bo Liu"
    ],
    "abstract": "The article explores the intersection of computer vision technology and\nrobotic control, highlighting its importance in various fields such as\nindustrial automation, healthcare, and environmental protection. Computer\nvision technology, which simulates human visual observation, plays a crucial\nrole in enabling robots to perceive and understand their surroundings, leading\nto advancements in tasks like autonomous navigation, object recognition, and\nwaste management. By integrating computer vision with robot control, robots\ngain the ability to interact intelligently with their environment, improving\nefficiency.",
    "published": "2024-04-01T13:46:23Z",
    "pdf_url": "http://arxiv.org/pdf/2404.01116v1",
    "categories": [
      "cs.RO"
    ]
  },
  {
    "arxiv_id": "1304.2367v1",
    "title": "Utility-Based Control for Computer Vision",
    "authors": [
      "Tod S. Levitt",
      "Thomas O. Binford",
      "Gil J. Ettinger",
      "Patrice Gelband"
    ],
    "abstract": "Several key issues arise in implementing computer vision recognition of world\nobjects in terms of Bayesian networks. Computational efficiency is a driving\nforce. Perceptual networks are very deep, typically fifteen levels of\nstructure. Images are wide, e.g., an unspecified-number of edges may appear\nanywhere in an image 512 x 512 pixels or larger. For efficiency, we dynamically\ninstantiate hypotheses of observed objects. The network is not fixed, but is\ncreated incrementally at runtime. Generation of hypotheses of world objects and\nindexing of models for recognition are important, but they are not considered\nhere [4,11]. This work is aimed at near-term implementation with parallel\ncomputation in a radar surveillance system, ADRIES [5, 15], and a system for\nindustrial part recognition, SUCCESSOR [2]. For many applications, vision must\nbe faster to be practical and so efficiently controlling the machine vision\nprocess is critical. Perceptual operators may scan megapixels and may require\nminutes of computation time. It is necessary to avoid unnecessary sensor\nactions and computation. Parallel computation is available at several levels of\nprocessor capability. The potential for parallel, distributed computation for\nhigh-level vision means distributing non-homogeneous computations. This paper\naddresses the problem of task control in machine vision systems based on\nBayesian probability models. We separate control and inference to extend the\nprevious work [3] to maximize utility instead of probability. Maximizing\nutility allows adopting perceptual strategies for efficient information\ngathering with sensors and analysis of sensor data. Results of controlling\nmachine vision via utility to recognize military situations are presented in\nthis paper. Future work extends this to industrial part recognition for\nSUCCESSOR.",
    "published": "2013-03-27T19:44:16Z",
    "pdf_url": "http://arxiv.org/pdf/1304.2367v1",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.SY"
    ]
  },
  {
    "arxiv_id": "1704.05072v1",
    "title": "Characterising dark matter haloes with computer vision",
    "authors": [
      "Julian Merten",
      "Quim Llorens",
      "Hans Winther"
    ],
    "abstract": "This work explores the ability of computer vision algorithms to characterise\ndark matter haloes formed in different models of structure formation. We\nproduce surface mass density maps of the most massive haloes in a suite of\neight numerical simulations, all based on the same initial conditions, but\nimplementing different models of gravity. This suite includes a standard\n$\\Lambda$CDM model, two variations of $f(R)$-gravity, two variations of\nSymmetron gravity and three Dvali, Gabadadze and Porrati (DGP) models. We use\nthe publicly available WND-CHARM algorithm to extract 2919 image features from\neither the raw pixel intensities of the maps, or from a variety of image\ntransformations including Fourier, Wavelet, Chebyshev and Edge transformations.\nAfter discarding the most degenerate models, we achieve more than 60%\nsingle-image classification success rate in distinguishing the four different\nmodels of gravity while using a simple weighted neighbour distance (WND) to\ndefine our classification metric. This number can be increased to more than 70%\nif additional information, such as a rough estimate of the halo mass, is\nincluded. We find that the classification success steeply declines when the\nnoise level in the images is increased, but that this trend can be largely\nreduced by smoothing the noisy data. We find Zernike moments of the Fourier\ntransformation of either the raw image or its Wavelet transformation to be the\nmost descriptive feature, followed by the Gini coefficient of several\ntransformations and the Haralick and Tamura textures of the raw pixel data\neventually pre-processed by an Edge transformation. The proposed methodology is\ngeneral and does not only apply to the characterisation of modified gravity\nmodels, but can be used to classify any set of models which show variations in\nthe 2D morphology of their respective structure.",
    "published": "2017-04-17T18:00:07Z",
    "pdf_url": "http://arxiv.org/pdf/1704.05072v1",
    "categories": [
      "astro-ph.CO",
      "gr-qc"
    ]
  },
  {
    "arxiv_id": "2209.05834v1",
    "title": "Computer vision system to count crustacean larvae",
    "authors": [
      "Chen Rothschild"
    ],
    "abstract": "Fish products account for about 16 percent of the human diet worldwide, as of\n2017. The counting action is a significant component in growing and producing\nthese products. Growers must count the fish accurately, to do so technological\nsolutions are needed. Two computer vision systems to automatically count\ncrustacean larvae grown in industrial ponds were developed. The first system\nincluded an iPhone 11 camera with 3024X4032 resolution which acquired images\nfrom an industrial pond in indoor conditions. Two experiments were performed\nwith this system, the first one included 200 images acquired in one day on\ngrowth stages 9,10 with an iPhone 11 camera on specific illumination condition.\nIn the second experiment, a larvae industrial pond was photographed for 11 days\nwith two devices an iPhone 11 and a SONY DSCHX90V cameras. With the first\ndevice (iPhone 11) two illumination conditions were tested. In each condition,\n110 images were acquired. That system resulted in an accuracy of 88.4 percent\nimage detection. The second system included a DSLR Nikon D510 camera with a\n2000X2000 resolution with which seven experiments were performed outside the\nindustrial pond. Images were acquired on day 1 of larvae growing stage\nresulting in the acquisition of a total of 700 images. That system resulted in\nan accuracy of 86 percent for a density of 50. An algorithm that automatically\ncounts the number of larvae was developed for both cases based on the YOLOv5\nCNN model. In addition, in this study, a larvae growth function was developed.\nDaily, several larvae were taken manually from the industrial pond and analyzed\nunder a microscope. Once the growth stage was determined, images of the larva\nwere acquired. Each larva's length was measured manually from the images. The\nmost suitable model was the Gompertz model with a goodness of fit index of R\nsquared of 0.983.",
    "published": "2022-09-13T09:18:13Z",
    "pdf_url": "http://arxiv.org/pdf/2209.05834v1",
    "categories": [
      "cs.CV",
      "eess.IV"
    ]
  },
  {
    "arxiv_id": "2210.05451v1",
    "title": "Enabling ISP-less Low-Power Computer Vision",
    "authors": [
      "Gourav Datta",
      "Zeyu Liu",
      "Zihan Yin",
      "Linyu Sun",
      "Akhilesh R. Jaiswal",
      "Peter A. Beerel"
    ],
    "abstract": "In order to deploy current computer vision (CV) models on\nresource-constrained low-power devices, recent works have proposed in-sensor\nand in-pixel computing approaches that try to partly/fully bypass the image\nsignal processor (ISP) and yield significant bandwidth reduction between the\nimage sensor and the CV processing unit by downsampling the activation maps in\nthe initial convolutional neural network (CNN) layers. However, direct\ninference on the raw images degrades the test accuracy due to the difference in\ncovariance of the raw images captured by the image sensors compared to the\nISP-processed images used for training. Moreover, it is difficult to train deep\nCV models on raw images, because most (if not all) large-scale open-source\ndatasets consist of RGB images. To mitigate this concern, we propose to invert\nthe ISP pipeline, which can convert the RGB images of any dataset to its raw\ncounterparts, and enable model training on raw images. We release the raw\nversion of the COCO dataset, a large-scale benchmark for generic high-level\nvision tasks. For ISP-less CV systems, training on these raw images result in a\n7.1% increase in test accuracy on the visual wake works (VWW) dataset compared\nto relying on training with traditional ISP-processed RGB datasets. To further\nimprove the accuracy of ISP-less CV models and to increase the energy and\nbandwidth benefits obtained by in-sensor/in-pixel computing, we propose an\nenergy-efficient form of analog in-pixel demosaicing that may be coupled with\nin-pixel CNN computations. When evaluated on raw images captured by real\nsensors from the PASCALRAW dataset, our approach results in a 8.1% increase in\nmAP. Lastly, we demonstrate a further 20.5% increase in mAP by using a novel\napplication of few-shot learning with thirty shots each for the novel PASCALRAW\ndataset, constituting 3 classes.",
    "published": "2022-10-11T13:47:30Z",
    "pdf_url": "http://arxiv.org/pdf/2210.05451v1",
    "categories": [
      "cs.CV",
      "eess.IV"
    ]
  },
  {
    "arxiv_id": "1707.03720v1",
    "title": "Multiband NFC for High-Throughput Wireless Computer Vision Sensor\n  Network",
    "authors": [
      "F. Li",
      "J. Du"
    ],
    "abstract": "Vision sensors lie in the heart of computer vision. In many computer vision\napplications, such as AR/VR, non-contacting near-field communication (NFC) with\nhigh throughput is required to transfer information to algorithms. In this\nwork, we proposed a novel NFC system which utilizes multiple frequency bands to\nachieve high throughput.",
    "published": "2017-05-28T06:43:29Z",
    "pdf_url": "http://arxiv.org/pdf/1707.03720v1",
    "categories": [
      "cs.NI",
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2501.10343v1",
    "title": "3rd Workshop on Maritime Computer Vision (MaCVi) 2025: Challenge Results",
    "authors": [
      "Benjamin Kiefer",
      "Lojze Žust",
      "Jon Muhovič",
      "Matej Kristan",
      "Janez Perš",
      "Matija Teršek",
      "Uma Mudenagudi Chaitra Desai",
      "Arnold Wiliem",
      "Marten Kreis",
      "Nikhil Akalwadi",
      "Yitong Quan",
      "Zhiqiang Zhong",
      "Zhe Zhang",
      "Sujie Liu",
      "Xuran Chen",
      "Yang Yang",
      "Matej Fabijanić",
      "Fausto Ferreira",
      "Seongju Lee",
      "Junseok Lee",
      "Kyoobin Lee",
      "Shanliang Yao",
      "Runwei Guan",
      "Xiaoyu Huang",
      "Yi Ni",
      "Himanshu Kumar",
      "Yuan Feng",
      "Yi-Ching Cheng",
      "Tzu-Yu Lin",
      "Chia-Ming Lee",
      "Chih-Chung Hsu",
      "Jannik Sheikh",
      "Andreas Michel",
      "Wolfgang Gross",
      "Martin Weinmann",
      "Josip Šarić",
      "Yipeng Lin",
      "Xiang Yang",
      "Nan Jiang",
      "Yutang Lu",
      "Fei Feng",
      "Ali Awad",
      "Evan Lucas",
      "Ashraf Saleem",
      "Ching-Heng Cheng",
      "Yu-Fan Lin",
      "Tzu-Yu Lin",
      "Chih-Chung Hsu"
    ],
    "abstract": "The 3rd Workshop on Maritime Computer Vision (MaCVi) 2025 addresses maritime\ncomputer vision for Unmanned Surface Vehicles (USV) and underwater. This report\noffers a comprehensive overview of the findings from the challenges. We provide\nboth statistical and qualitative analyses, evaluating trends from over 700\nsubmissions. All datasets, evaluation code, and the leaderboard are available\nto the public at https://macvi.org/workshop/macvi25.",
    "published": "2025-01-17T18:34:47Z",
    "pdf_url": "http://arxiv.org/pdf/2501.10343v1",
    "categories": [
      "cs.CV",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1601.06615v1",
    "title": "A Taxonomy of Deep Convolutional Neural Nets for Computer Vision",
    "authors": [
      "Suraj Srinivas",
      "Ravi Kiran Sarvadevabhatla",
      "Konda Reddy Mopuri",
      "Nikita Prabhu",
      "Srinivas S S Kruthiventi",
      "R. Venkatesh Babu"
    ],
    "abstract": "Traditional architectures for solving computer vision problems and the degree\nof success they enjoyed have been heavily reliant on hand-crafted features.\nHowever, of late, deep learning techniques have offered a compelling\nalternative -- that of automatically learning problem-specific features. With\nthis new paradigm, every problem in computer vision is now being re-examined\nfrom a deep learning perspective. Therefore, it has become important to\nunderstand what kind of deep networks are suitable for a given problem.\nAlthough general surveys of this fast-moving paradigm (i.e. deep-networks)\nexist, a survey specific to computer vision is missing. We specifically\nconsider one form of deep networks widely used in computer vision -\nconvolutional neural networks (CNNs). We start with \"AlexNet\" as our base CNN\nand then examine the broad variations proposed over time to suit different\napplications. We hope that our recipe-style survey will serve as a guide,\nparticularly for novice practitioners intending to use deep-learning techniques\nfor computer vision.",
    "published": "2016-01-25T14:25:07Z",
    "pdf_url": "http://arxiv.org/pdf/1601.06615v1",
    "categories": [
      "cs.CV",
      "cs.LG",
      "cs.MM"
    ]
  },
  {
    "arxiv_id": "2203.15269v1",
    "title": "Vision Transformers in Medical Computer Vision -- A Contemplative\n  Retrospection",
    "authors": [
      "Arshi Parvaiz",
      "Muhammad Anwaar Khalid",
      "Rukhsana Zafar",
      "Huma Ameer",
      "Muhammad Ali",
      "Muhammad Moazam Fraz"
    ],
    "abstract": "Recent escalation in the field of computer vision underpins a huddle of\nalgorithms with the magnificent potential to unravel the information contained\nwithin images. These computer vision algorithms are being practised in medical\nimage analysis and are transfiguring the perception and interpretation of\nImaging data. Among these algorithms, Vision Transformers are evolved as one of\nthe most contemporary and dominant architectures that are being used in the\nfield of computer vision. These are immensely utilized by a plenty of\nresearchers to perform new as well as former experiments. Here, in this article\nwe investigate the intersection of Vision Transformers and Medical images and\nproffered an overview of various ViTs based frameworks that are being used by\ndifferent researchers in order to decipher the obstacles in Medical Computer\nVision. We surveyed the application of Vision transformers in different areas\nof medical computer vision such as image-based disease classification,\nanatomical structure segmentation, registration, region-based lesion Detection,\ncaptioning, report generation, reconstruction using multiple medical imaging\nmodalities that greatly assist in medical diagnosis and hence treatment\nprocess. Along with this, we also demystify several imaging modalities used in\nMedical Computer Vision. Moreover, to get more insight and deeper\nunderstanding, self-attention mechanism of transformers is also explained\nbriefly. Conclusively, we also put some light on available data sets, adopted\nmethodology, their performance measures, challenges and their solutions in form\nof discussion. We hope that this review article will open future directions for\nresearchers in medical computer vision.",
    "published": "2022-03-29T06:32:43Z",
    "pdf_url": "http://arxiv.org/pdf/2203.15269v1",
    "categories": [
      "eess.IV",
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1604.04372v2",
    "title": "The Chow Form of the Essential Variety in Computer Vision",
    "authors": [
      "Gunnar Fløystad",
      "Joe Kileel",
      "Giorgio Ottaviani"
    ],
    "abstract": "The Chow form of the essential variety in computer vision is calculated. Our\nderivation uses secant varieties, Ulrich sheaves and representation theory.\nNumerical experiments show that our formula can detect noisy point\ncorrespondences between two images.",
    "published": "2016-04-15T06:57:09Z",
    "pdf_url": "http://arxiv.org/pdf/1604.04372v2",
    "categories": [
      "math.AG",
      "cs.CV",
      "math.AC",
      "14M12, 14C05, 14Q15, 13D02, 13C14, 68T45"
    ]
  },
  {
    "arxiv_id": "2004.09420v2",
    "title": "Computer Vision For COVID-19 Control: A Survey",
    "authors": [
      "Anwaar Ulhaq",
      "Asim Khan",
      "Douglas Gomes",
      "Manoranjan Paul"
    ],
    "abstract": "The COVID-19 pandemic has triggered an urgent need to contribute to the fight\nagainst an immense threat to the human population. Computer Vision, as a\nsubfield of Artificial Intelligence, has enjoyed recent success in solving\nvarious complex problems in health care and has the potential to contribute to\nthe fight of controlling COVID-19. In response to this call, computer vision\nresearchers are putting their knowledge base at work to devise effective ways\nto counter COVID-19 challenge and serve the global community. New contributions\nare being shared with every passing day. It motivated us to review the recent\nwork, collect information about available research resources and an indication\nof future research directions. We want to make it available to computer vision\nresearchers to save precious time. This survey paper is intended to provide a\npreliminary review of the available literature on the computer vision efforts\nagainst COVID-19 pandemic.",
    "published": "2020-04-15T05:43:52Z",
    "pdf_url": "http://arxiv.org/pdf/2004.09420v2",
    "categories": [
      "eess.IV",
      "cs.CV",
      "I.4.9"
    ]
  },
  {
    "arxiv_id": "2001.02366v2",
    "title": "What can robotics research learn from computer vision research?",
    "authors": [
      "Peter Corke",
      "Feras Dayoub",
      "David Hall",
      "John Skinner",
      "Niko Sünderhauf"
    ],
    "abstract": "The computer vision and robotics research communities are each strong.\nHowever progress in computer vision has become turbo-charged in recent years\ndue to big data, GPU computing, novel learning algorithms and a very effective\nresearch methodology. By comparison, progress in robotics seems slower. It is\ntrue that robotics came later to exploring the potential of learning -- the\nadvantages over the well-established body of knowledge in dynamics, kinematics,\nplanning and control is still being debated, although reinforcement learning\nseems to offer real potential. However, the rapid development of computer\nvision compared to robotics cannot be only attributed to the former's adoption\nof deep learning. In this paper, we argue that the gains in computer vision are\ndue to research methodology -- evaluation under strict constraints versus\nexperiments; bold numbers versus videos.",
    "published": "2020-01-08T04:32:10Z",
    "pdf_url": "http://arxiv.org/pdf/2001.02366v2",
    "categories": [
      "cs.RO",
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2305.06611v1",
    "title": "Hyperbolic Deep Learning in Computer Vision: A Survey",
    "authors": [
      "Pascal Mettes",
      "Mina Ghadimi Atigh",
      "Martin Keller-Ressel",
      "Jeffrey Gu",
      "Serena Yeung"
    ],
    "abstract": "Deep representation learning is a ubiquitous part of modern computer vision.\nWhile Euclidean space has been the de facto standard manifold for learning\nvisual representations, hyperbolic space has recently gained rapid traction for\nlearning in computer vision. Specifically, hyperbolic learning has shown a\nstrong potential to embed hierarchical structures, learn from limited samples,\nquantify uncertainty, add robustness, limit error severity, and more. In this\npaper, we provide a categorization and in-depth overview of current literature\non hyperbolic learning for computer vision. We research both supervised and\nunsupervised literature and identify three main research themes in each\ndirection. We outline how hyperbolic learning is performed in all themes and\ndiscuss the main research problems that benefit from current advances in\nhyperbolic learning for computer vision. Moreover, we provide a high-level\nintuition behind hyperbolic geometry and outline open research questions to\nfurther advance research in this direction.",
    "published": "2023-05-11T07:14:23Z",
    "pdf_url": "http://arxiv.org/pdf/2305.06611v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2109.00783v4",
    "title": "Computer Vision Self-supervised Learning Methods on Time Series",
    "authors": [
      "Daesoo Lee",
      "Erlend Aune"
    ],
    "abstract": "Self-supervised learning (SSL) has had great success in both computer vision.\nMost of the current mainstream computer vision SSL frameworks are based on\nSiamese network architecture. These approaches often rely on cleverly crafted\nloss functions and training setups to avoid feature collapse. In this study, we\nevaluate if those computer-vision SSL frameworks are also effective on a\ndifferent modality (\\textit{i.e.,} time series). The effectiveness is\nexperimented and evaluated on the UCR and UEA archives, and we show that the\ncomputer vision SSL frameworks can be effective even for time series. In\naddition, we propose a new method that improves on the recently proposed VICReg\nmethod. Our method improves on a \\textit{covariance} term proposed in VICReg,\nand in addition we augment the head of the architecture by an iterative\nnormalization layer that accelerates the convergence of the model.",
    "published": "2021-09-02T08:45:53Z",
    "pdf_url": "http://arxiv.org/pdf/2109.00783v4",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2301.07583v1",
    "title": "A Survey of Advanced Computer Vision Techniques for Sports",
    "authors": [
      "Tiago Mendes-Neves",
      "Luís Meireles",
      "João Mendes-Moreira"
    ],
    "abstract": "Computer Vision developments are enabling significant advances in many\nfields, including sports. Many applications built on top of Computer Vision\ntechnologies, such as tracking data, are nowadays essential for every top-level\nanalyst, coach, and even player. In this paper, we survey Computer Vision\ntechniques that can help many sports-related studies gather vast amounts of\ndata, such as Object Detection and Pose Estimation. We provide a use case for\nsuch data: building a model for shot speed estimation with pose data obtained\nusing only Computer Vision models. Our model achieves a correlation of 67%. The\npossibility of estimating shot speeds enables much deeper studies about\nenabling the creation of new metrics and recommendation systems that will help\nathletes improve their performance, in any sport. The proposed methodology is\neasily replicable for many technical movements and is only limited by the\navailability of video data.",
    "published": "2023-01-18T15:01:36Z",
    "pdf_url": "http://arxiv.org/pdf/2301.07583v1",
    "categories": [
      "cs.CV",
      "cs.LG",
      "68T45, 68T01, 92C10"
    ]
  },
  {
    "arxiv_id": "2103.00560v1",
    "title": "Perspectives on individual animal identification from biology and\n  computer vision",
    "authors": [
      "Maxime Vidal",
      "Nathan Wolf",
      "Beth Rosenberg",
      "Bradley P. Harris",
      "Alexander Mathis"
    ],
    "abstract": "Identifying individual animals is crucial for many biological investigations.\nIn response to some of the limitations of current identification methods, new\nautomated computer vision approaches have emerged with strong performance.\nHere, we review current advances of computer vision identification techniques\nto provide both computer scientists and biologists with an overview of the\navailable tools and discuss their applications. We conclude by offering\nrecommendations for starting an animal identification project, illustrate\ncurrent limitations and propose how they might be addressed in the future.",
    "published": "2021-02-28T16:50:09Z",
    "pdf_url": "http://arxiv.org/pdf/2103.00560v1",
    "categories": [
      "cs.CV",
      "q-bio.QM"
    ]
  },
  {
    "arxiv_id": "2305.18035v3",
    "title": "Physics-Informed Computer Vision: A Review and Perspectives",
    "authors": [
      "Chayan Banerjee",
      "Kien Nguyen",
      "Clinton Fookes",
      "George Karniadakis"
    ],
    "abstract": "The incorporation of physical information in machine learning frameworks is\nopening and transforming many application domains. Here the learning process is\naugmented through the induction of fundamental knowledge and governing physical\nlaws. In this work, we explore their utility for computer vision tasks in\ninterpreting and understanding visual data. We present a systematic literature\nreview of more than 250 papers on formulation and approaches to computer vision\ntasks guided by physical laws. We begin by decomposing the popular computer\nvision pipeline into a taxonomy of stages and investigate approaches to\nincorporate governing physical equations in each stage. Existing approaches in\ncomputer vision tasks are analyzed with regard to what governing physical\nprocesses are modeled and formulated, and how they are incorporated, i.e.\nmodification of input data (observation bias), modification of network\narchitectures (inductive bias), and modification of training losses (learning\nbias). The taxonomy offers a unified view of the application of the\nphysics-informed capability, highlighting where physics-informed learning has\nbeen conducted and where the gaps and opportunities are. Finally, we highlight\nopen problems and challenges to inform future research. While still in its\nearly days, the study of physics-informed computer vision has the promise to\ndevelop better computer vision models that can improve physical plausibility,\naccuracy, data efficiency, and generalization in increasingly realistic\napplications.",
    "published": "2023-05-29T11:55:11Z",
    "pdf_url": "http://arxiv.org/pdf/2305.18035v3",
    "categories": [
      "eess.IV",
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2401.11617v3",
    "title": "The State of Computer Vision Research in Africa",
    "authors": [
      "Abdul-Hakeem Omotayo",
      "Ashery Mbilinyi",
      "Lukman Ismaila",
      "Houcemeddine Turki",
      "Mahmoud Abdien",
      "Karim Gamal",
      "Idriss Tondji",
      "Yvan Pimi",
      "Naome A. Etori",
      "Marwa M. Matar",
      "Clifford Broni-Bediako",
      "Abigail Oppong",
      "Mai Gamal",
      "Eman Ehab",
      "Gbetondji Dovonon",
      "Zainab Akinjobi",
      "Daniel Ajisafe",
      "Oluwabukola G. Adegboro",
      "Mennatullah Siam"
    ],
    "abstract": "Despite significant efforts to democratize artificial intelligence (AI),\ncomputer vision which is a sub-field of AI, still lags in Africa. A significant\nfactor to this, is the limited access to computing resources, datasets, and\ncollaborations. As a result, Africa's contribution to top-tier publications in\nthis field has only been 0.06% over the past decade. Towards improving the\ncomputer vision field and making it more accessible and inclusive, this study\nanalyzes 63,000 Scopus-indexed computer vision publications from Africa. We\nutilize large language models to automatically parse their abstracts, to\nidentify and categorize topics and datasets. This resulted in listing more than\n100 African datasets. Our objective is to provide a comprehensive taxonomy of\ndataset categories to facilitate better understanding and utilization of these\nresources. We also analyze collaboration trends of researchers within and\noutside the continent. Additionally, we conduct a large-scale questionnaire\namong African computer vision researchers to identify the structural barriers\nthey believe require urgent attention. In conclusion, our study offers a\ncomprehensive overview of the current state of computer vision research in\nAfrica, to empower marginalized communities to participate in the design and\ndevelopment of computer vision systems.",
    "published": "2024-01-21T22:50:44Z",
    "pdf_url": "http://arxiv.org/pdf/2401.11617v3",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2111.11066v1",
    "title": "FedCV: A Federated Learning Framework for Diverse Computer Vision Tasks",
    "authors": [
      "Chaoyang He",
      "Alay Dilipbhai Shah",
      "Zhenheng Tang",
      "Di Fan1Adarshan Naiynar Sivashunmugam",
      "Keerti Bhogaraju",
      "Mita Shimpi",
      "Li Shen",
      "Xiaowen Chu",
      "Mahdi Soltanolkotabi",
      "Salman Avestimehr"
    ],
    "abstract": "Federated Learning (FL) is a distributed learning paradigm that can learn a\nglobal or personalized model from decentralized datasets on edge devices.\nHowever, in the computer vision domain, model performance in FL is far behind\ncentralized training due to the lack of exploration in diverse tasks with a\nunified FL framework. FL has rarely been demonstrated effectively in advanced\ncomputer vision tasks such as object detection and image segmentation. To\nbridge the gap and facilitate the development of FL for computer vision tasks,\nin this work, we propose a federated learning library and benchmarking\nframework, named FedCV, to evaluate FL on the three most representative\ncomputer vision tasks: image classification, image segmentation, and object\ndetection. We provide non-I.I.D. benchmarking datasets, models, and various\nreference FL algorithms. Our benchmark study suggests that there are multiple\nchallenges that deserve future exploration: centralized training tricks may not\nbe directly applied to FL; the non-I.I.D. dataset actually downgrades the model\naccuracy to some degree in different tasks; improving the system efficiency of\nfederated training is challenging given the huge number of parameters and the\nper-client memory cost. We believe that such a library and benchmark, along\nwith comparable evaluation settings, is necessary to make meaningful progress\nin FL on computer vision tasks. FedCV is publicly available:\nhttps://github.com/FedML-AI/FedCV.",
    "published": "2021-11-22T09:26:08Z",
    "pdf_url": "http://arxiv.org/pdf/2111.11066v1",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2111.11432v1",
    "title": "Florence: A New Foundation Model for Computer Vision",
    "authors": [
      "Lu Yuan",
      "Dongdong Chen",
      "Yi-Ling Chen",
      "Noel Codella",
      "Xiyang Dai",
      "Jianfeng Gao",
      "Houdong Hu",
      "Xuedong Huang",
      "Boxin Li",
      "Chunyuan Li",
      "Ce Liu",
      "Mengchen Liu",
      "Zicheng Liu",
      "Yumao Lu",
      "Yu Shi",
      "Lijuan Wang",
      "Jianfeng Wang",
      "Bin Xiao",
      "Zhen Xiao",
      "Jianwei Yang",
      "Michael Zeng",
      "Luowei Zhou",
      "Pengchuan Zhang"
    ],
    "abstract": "Automated visual understanding of our diverse and open world demands computer\nvision models to generalize well with minimal customization for specific tasks,\nsimilar to human vision. Computer vision foundation models, which are trained\non diverse, large-scale dataset and can be adapted to a wide range of\ndownstream tasks, are critical for this mission to solve real-world computer\nvision applications. While existing vision foundation models such as CLIP,\nALIGN, and Wu Dao 2.0 focus mainly on mapping images and textual\nrepresentations to a cross-modal shared representation, we introduce a new\ncomputer vision foundation model, Florence, to expand the representations from\ncoarse (scene) to fine (object), from static (images) to dynamic (videos), and\nfrom RGB to multiple modalities (caption, depth). By incorporating universal\nvisual-language representations from Web-scale image-text data, our Florence\nmodel can be easily adapted for various computer vision tasks, such as\nclassification, retrieval, object detection, VQA, image caption, video\nretrieval and action recognition. Moreover, Florence demonstrates outstanding\nperformance in many types of transfer learning: fully sampled fine-tuning,\nlinear probing, few-shot transfer and zero-shot transfer for novel images and\nobjects. All of these properties are critical for our vision foundation model\nto serve general purpose vision tasks. Florence achieves new state-of-the-art\nresults in majority of 44 representative benchmarks, e.g., ImageNet-1K\nzero-shot classification with top-1 accuracy of 83.74 and the top-5 accuracy of\n97.18, 62.4 mAP on COCO fine tuning, 80.36 on VQA, and 87.8 on Kinetics-600.",
    "published": "2021-11-22T18:59:55Z",
    "pdf_url": "http://arxiv.org/pdf/2111.11432v1",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2408.02464v1",
    "title": "Fairness and Bias Mitigation in Computer Vision: A Survey",
    "authors": [
      "Sepehr Dehdashtian",
      "Ruozhen He",
      "Yi Li",
      "Guha Balakrishnan",
      "Nuno Vasconcelos",
      "Vicente Ordonez",
      "Vishnu Naresh Boddeti"
    ],
    "abstract": "Computer vision systems have witnessed rapid progress over the past two\ndecades due to multiple advances in the field. As these systems are\nincreasingly being deployed in high-stakes real-world applications, there is a\ndire need to ensure that they do not propagate or amplify any discriminatory\ntendencies in historical or human-curated data or inadvertently learn biases\nfrom spurious correlations. This paper presents a comprehensive survey on\nfairness that summarizes and sheds light on ongoing trends and successes in the\ncontext of computer vision. The topics we discuss include 1) The origin and\ntechnical definitions of fairness drawn from the wider fair machine learning\nliterature and adjacent disciplines. 2) Work that sought to discover and\nanalyze biases in computer vision systems. 3) A summary of methods proposed to\nmitigate bias in computer vision systems in recent years. 4) A comprehensive\nsummary of resources and datasets produced by researchers to measure, analyze,\nand mitigate bias and enhance fairness. 5) Discussion of the field's success,\ncontinuing trends in the context of multimodal foundation and generative\nmodels, and gaps that still need to be addressed. The presented\ncharacterization should help researchers understand the importance of\nidentifying and mitigating bias in computer vision and the state of the field\nand identify potential directions for future research.",
    "published": "2024-08-05T13:44:22Z",
    "pdf_url": "http://arxiv.org/pdf/2408.02464v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1607.07405v3",
    "title": "gvnn: Neural Network Library for Geometric Computer Vision",
    "authors": [
      "Ankur Handa",
      "Michael Bloesch",
      "Viorica Patraucean",
      "Simon Stent",
      "John McCormac",
      "Andrew Davison"
    ],
    "abstract": "We introduce gvnn, a neural network library in Torch aimed towards bridging\nthe gap between classic geometric computer vision and deep learning. Inspired\nby the recent success of Spatial Transformer Networks, we propose several new\nlayers which are often used as parametric transformations on the data in\ngeometric computer vision. These layers can be inserted within a neural network\nmuch in the spirit of the original spatial transformers and allow\nbackpropagation to enable end-to-end learning of a network involving any domain\nknowledge in geometric computer vision. This opens up applications in learning\ninvariance to 3D geometric transformation for place recognition, end-to-end\nvisual odometry, depth estimation and unsupervised learning through warping\nwith a parametric transformation for image reconstruction error.",
    "published": "2016-07-25T18:57:17Z",
    "pdf_url": "http://arxiv.org/pdf/1607.07405v3",
    "categories": [
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1708.08169v1",
    "title": "ChainerCV: a Library for Deep Learning in Computer Vision",
    "authors": [
      "Yusuke Niitani",
      "Toru Ogawa",
      "Shunta Saito",
      "Masaki Saito"
    ],
    "abstract": "Despite significant progress of deep learning in the field of computer\nvision, there has not been a software library that covers these methods in a\nunifying manner. We introduce ChainerCV, a software library that is intended to\nfill this gap. ChainerCV supports numerous neural network models as well as\nsoftware components needed to conduct research in computer vision. These\nimplementations emphasize simplicity, flexibility and good software engineering\npractices. The library is designed to perform on par with the results reported\nin published papers and its tools can be used as a baseline for future research\nin computer vision. Our implementation includes sophisticated models like\nFaster R-CNN and SSD, and covers tasks such as object detection and semantic\nsegmentation.",
    "published": "2017-08-28T02:54:11Z",
    "pdf_url": "http://arxiv.org/pdf/1708.08169v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2104.08188v1",
    "title": "I Find Your Lack of Uncertainty in Computer Vision Disturbing",
    "authors": [
      "Matias Valdenegro-Toro"
    ],
    "abstract": "Neural networks are used for many real world applications, but often they\nhave problems estimating their own confidence. This is particularly problematic\nfor computer vision applications aimed at making high stakes decisions with\nhumans and their lives. In this paper we make a meta-analysis of the\nliterature, showing that most if not all computer vision applications do not\nuse proper epistemic uncertainty quantification, which means that these models\nignore their own limitations. We describe the consequences of using models\nwithout proper uncertainty quantification, and motivate the community to adopt\nversions of the models they use that have proper calibrated epistemic\nuncertainty, in order to enable out of distribution detection. We close the\npaper with a summary of challenges on estimating uncertainty for computer\nvision applications and recommendations.",
    "published": "2021-04-16T15:58:27Z",
    "pdf_url": "http://arxiv.org/pdf/2104.08188v1",
    "categories": [
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1802.06464v3",
    "title": "Robust Fitting in Computer Vision: Easy or Hard?",
    "authors": [
      "Tat-Jun Chin",
      "Zhipeng Cai",
      "Frank Neumann"
    ],
    "abstract": "Robust model fitting plays a vital role in computer vision, and research into\nalgorithms for robust fitting continues to be active. Arguably the most popular\nparadigm for robust fitting in computer vision is consensus maximisation, which\nstrives to find the model parameters that maximise the number of inliers.\nDespite the significant developments in algorithms for consensus maximisation,\nthere has been a lack of fundamental analysis of the problem in the computer\nvision literature. In particular, whether consensus maximisation is \"tractable\"\nremains a question that has not been rigorously dealt with, thus making it\ndifficult to assess and compare the performance of proposed algorithms,\nrelative to what is theoretically achievable. To shed light on these issues, we\npresent several computational hardness results for consensus maximisation. Our\nresults underline the fundamental intractability of the problem, and resolve\nseveral ambiguities existing in the literature.",
    "published": "2018-02-18T22:54:50Z",
    "pdf_url": "http://arxiv.org/pdf/1802.06464v3",
    "categories": [
      "cs.CV",
      "cs.CC"
    ]
  },
  {
    "arxiv_id": "1909.10225v1",
    "title": "WiCV 2019: The Sixth Women In Computer Vision Workshop",
    "authors": [
      "Irene Amerini",
      "Elena Balashova",
      "Sayna Ebrahimi",
      "Kathryn Leonard",
      "Arsha Nagrani",
      "Amaia Salvador"
    ],
    "abstract": "In this paper we present the Women in Computer Vision Workshop - WiCV 2019,\norganized in conjunction with CVPR 2019. This event is meant for increasing the\nvisibility and inclusion of women researchers in the computer vision field.\nComputer vision and machine learning have made incredible progress over the\npast years, but the number of female researchers is still low both in academia\nand in industry. WiCV is organized especially for the following reason: to\nraise visibility of female researchers, to increase collaborations between\nthem, and to provide mentorship to female junior researchers in the field. In\nthis paper, we present a report of trends over the past years, along with a\nsummary of statistics regarding presenters, attendees, and sponsorship for the\ncurrent workshop.",
    "published": "2019-09-23T08:52:33Z",
    "pdf_url": "http://arxiv.org/pdf/1909.10225v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1911.05931v1",
    "title": "VisionISP: Repurposing the Image Signal Processor for Computer Vision\n  Applications",
    "authors": [
      "Chyuan-Tyng Wu",
      "Leo F. Isikdogan",
      "Sushma Rao",
      "Bhavin Nayak",
      "Timo Gerasimow",
      "Aleksandar Sutic",
      "Liron Ain-kedem",
      "Gilad Michael"
    ],
    "abstract": "Traditional image signal processors (ISPs) are primarily designed and\noptimized to improve the image quality perceived by humans. However, optimal\nperceptual image quality does not always translate into optimal performance for\ncomputer vision applications. We propose a set of methods, which we\ncollectively call VisionISP, to repurpose the ISP for machine consumption.\nVisionISP significantly reduces data transmission needs by reducing the\nbit-depth and resolution while preserving the relevant information. The blocks\nin VisionISP are simple, content-aware, and trainable. Experimental results\nshow that VisionISP boosts the performance of a subsequent computer vision\nsystem trained to detect objects in an autonomous driving setting. The results\ndemonstrate the potential and the practicality of VisionISP for computer vision\napplications.",
    "published": "2019-11-14T04:19:28Z",
    "pdf_url": "http://arxiv.org/pdf/1911.05931v1",
    "categories": [
      "eess.IV",
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2203.05825v1",
    "title": "WiCV 2021: The Eighth Women In Computer Vision Workshop",
    "authors": [
      "Arushi Goel",
      "Niveditha Kalavakonda",
      "Nour Karessli",
      "Tejaswi Kasarla",
      "Kathryn Leonard",
      "Boyi Li",
      "Nermin Samet and",
      "Ghada Zamzmi"
    ],
    "abstract": "In this paper, we present the details of Women in Computer Vision Workshop -\nWiCV 2021, organized alongside the virtual CVPR 2021. It provides a voice to a\nminority (female) group in the computer vision community and focuses on\nincreasing the visibility of these researchers, both in academia and industry.\nWiCV believes that such an event can play an important role in lowering the\ngender imbalance in the field of computer vision. WiCV is organized each year\nwhere it provides a)~opportunity for collaboration between researchers from\nminority groups, b)~mentorship to female junior researchers, c)~financial\nsupport to presenters to overcome monetary burden and d)~large and diverse\nchoice of role models, who can serve as examples to younger researchers at the\nbeginning of their careers. In this paper, we present a report on the workshop\nprogram, trends over the past years, a summary of statistics regarding\npresenters, attendees, and sponsorship for the WiCV 2021 workshop.",
    "published": "2022-03-11T10:03:13Z",
    "pdf_url": "http://arxiv.org/pdf/2203.05825v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2208.11388v1",
    "title": "WiCV 2022: The Tenth Women In Computer Vision Workshop",
    "authors": [
      "Doris Antensteiner",
      "Silvia Bucci",
      "Arushi Goel",
      "Marah Halawa",
      "Niveditha Kalavakonda",
      "Tejaswi Kasarla",
      "Miaomiao Liu",
      "Nermin Samet",
      "Ivaxi Sheth"
    ],
    "abstract": "In this paper, we present the details of Women in Computer Vision Workshop -\nWiCV 2022, organized alongside the hybrid CVPR 2022 in New Orleans, Louisiana.\nIt provides a voice to a minority (female) group in the computer vision\ncommunity and focuses on increasing the visibility of these researchers, both\nin academia and industry. WiCV believes that such an event can play an\nimportant role in lowering the gender imbalance in the field of computer\nvision. WiCV is organized each year where it provides a) opportunity for\ncollaboration between researchers from minority groups, b) mentorship to female\njunior researchers, c) financial support to presenters to overcome monetary\nburden and d) large and diverse choice of role models, who can serve as\nexamples to younger researchers at the beginning of their careers. In this\npaper, we present a report on the workshop program, trends over the past years,\na summary of statistics regarding presenters, attendees, and sponsorship for\nthe WiCV 2022 workshop.",
    "published": "2022-08-24T09:12:36Z",
    "pdf_url": "http://arxiv.org/pdf/2208.11388v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2304.06009v2",
    "title": "Literature Review: Computer Vision Applications in Transportation\n  Logistics and Warehousing",
    "authors": [
      "Alexander Naumann",
      "Felix Hertlein",
      "Laura Dörr",
      "Steffen Thoma",
      "Kai Furmans"
    ],
    "abstract": "Computer vision applications in transportation logistics and warehousing have\na huge potential for process automation. We present a structured literature\nreview on research in the field to help leverage this potential. The literature\nis categorized w.r.t. the application, i.e. the task it tackles and w.r.t. the\ncomputer vision techniques that are used. Regarding applications, we subdivide\nthe literature in two areas: Monitoring, i.e. observing and retrieving relevant\ninformation from the environment, and manipulation, where approaches are used\nto analyze and interact with the environment. Additionally, we point out\ndirections for future research and link to recent developments in computer\nvision that are suitable for application in logistics. Finally, we present an\noverview of existing datasets and industrial solutions. The results of our\nanalysis are also available online at https://a-nau.github.io/cv-in-logistics.",
    "published": "2023-04-12T17:33:41Z",
    "pdf_url": "http://arxiv.org/pdf/2304.06009v2",
    "categories": [
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2002.06028v1",
    "title": "Constrained Dominant sets and Its applications in computer vision",
    "authors": [
      "Alemu Leulseged Tesfaye"
    ],
    "abstract": "In this thesis, we present new schemes which leverage a constrained\nclustering method to solve several computer vision tasks ranging from image\nretrieval, image segmentation and co-segmentation, to person re-identification.\nIn the last decades clustering methods have played a vital role in computer\nvision applications; herein, we focus on the extension, reformulation, and\nintegration of a well-known graph and game theoretic clustering method known as\nDominant Sets. Thus, we have demonstrated the validity of the proposed methods\nwith extensive experiments which are conducted on several benchmark datasets.",
    "published": "2020-02-12T20:19:44Z",
    "pdf_url": "http://arxiv.org/pdf/2002.06028v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2507.18650v1",
    "title": "Features extraction for image identification using computer vision",
    "authors": [
      "Venant Niyonkuru",
      "Sylla Sekou",
      "Jimmy Jackson Sinzinkayo"
    ],
    "abstract": "This study examines various feature extraction techniques in computer vision,\nthe primary focus of which is on Vision Transformers (ViTs) and other\napproaches such as Generative Adversarial Networks (GANs), deep feature models,\ntraditional approaches (SIFT, SURF, ORB), and non-contrastive and contrastive\nfeature models. Emphasizing ViTs, the report summarizes their architecture,\nincluding patch embedding, positional encoding, and multi-head self-attention\nmechanisms with which they overperform conventional convolutional neural\nnetworks (CNNs). Experimental results determine the merits and limitations of\nboth methods and their utilitarian applications in advancing computer vision.",
    "published": "2025-07-22T10:43:52Z",
    "pdf_url": "http://arxiv.org/pdf/2507.18650v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1708.07455v2",
    "title": "Review on Computer Vision Techniques in Emergency Situation",
    "authors": [
      "Laura Lopez-Fuentes",
      "Joost van de Weijer",
      "Manuel Gonzalez-Hidalgo",
      "Harald Skinnemoen",
      "Andrew D. Bagdanov"
    ],
    "abstract": "In emergency situations, actions that save lives and limit the impact of\nhazards are crucial. In order to act, situational awareness is needed to decide\nwhat to do. Geolocalized photos and video of the situations as they evolve can\nbe crucial in better understanding them and making decisions faster. Cameras\nare almost everywhere these days, either in terms of smartphones, installed\nCCTV cameras, UAVs or others. However, this poses challenges in big data and\ninformation overflow. Moreover, most of the time there are no disasters at any\ngiven location, so humans aiming to detect sudden situations may not be as\nalert as needed at any point in time. Consequently, computer vision tools can\nbe an excellent decision support. The number of emergencies where computer\nvision tools has been considered or used is very wide, and there is a great\noverlap across related emergency research. Researchers tend to focus on\nstate-of-the-art systems that cover the same emergency as they are studying,\nobviating important research in other fields. In order to unveil this overlap,\nthe survey is divided along four main axes: the types of emergencies that have\nbeen studied in computer vision, the objective that the algorithms can address,\nthe type of hardware needed and the algorithms used. Therefore, this review\nprovides a broad overview of the progress of computer vision covering all sorts\nof emergencies.",
    "published": "2017-08-24T15:24:47Z",
    "pdf_url": "http://arxiv.org/pdf/1708.07455v2",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2101.03787v1",
    "title": "WiCV 2020: The Seventh Women In Computer Vision Workshop",
    "authors": [
      "Hazel Doughty",
      "Nour Karessli",
      "Kathryn Leonard",
      "Boyi Li",
      "Carianne Martinez",
      "Azadeh Mobasher",
      "Arsha Nagrani",
      "Srishti Yadav"
    ],
    "abstract": "In this paper we present the details of Women in Computer Vision Workshop -\nWiCV 2020, organized in alongside virtual CVPR 2020. This event aims at\nencouraging the women researchers in the field of computer vision. It provides\na voice to a minority (female) group in computer vision community and focuses\non increasingly the visibility of these researchers, both in academia and\nindustry. WiCV believes that such an event can play an important role in\nlowering the gender imbalance in the field of computer vision. WiCV is\norganized each year where it provides a.) opportunity for collaboration with\nbetween researchers b.) mentorship to female junior researchers c.) financial\nsupport to presenters to overcome monetary burden and d.) large and diverse\nchoice of role models, who can serve as examples to younger researchers at the\nbeginning of their careers. In this paper, we present a report on the workshop\nprogram, trends over the past years, a summary of statistics regarding\npresenters, attendees, and sponsorship for the current workshop.",
    "published": "2021-01-11T09:48:29Z",
    "pdf_url": "http://arxiv.org/pdf/2101.03787v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2107.03436v1",
    "title": "Tensor Methods in Computer Vision and Deep Learning",
    "authors": [
      "Yannis Panagakis",
      "Jean Kossaifi",
      "Grigorios G. Chrysos",
      "James Oldfield",
      "Mihalis A. Nicolaou",
      "Anima Anandkumar",
      "Stefanos Zafeiriou"
    ],
    "abstract": "Tensors, or multidimensional arrays, are data structures that can naturally\nrepresent visual data of multiple dimensions. Inherently able to efficiently\ncapture structured, latent semantic spaces and high-order interactions, tensors\nhave a long history of applications in a wide span of computer vision problems.\nWith the advent of the deep learning paradigm shift in computer vision, tensors\nhave become even more fundamental. Indeed, essential ingredients in modern deep\nlearning architectures, such as convolutions and attention mechanisms, can\nreadily be considered as tensor mappings. In effect, tensor methods are\nincreasingly finding significant applications in deep learning, including the\ndesign of memory and compute efficient network architectures, improving\nrobustness to random noise and adversarial attacks, and aiding the theoretical\nunderstanding of deep networks.\n  This article provides an in-depth and practical review of tensors and tensor\nmethods in the context of representation learning and deep learning, with a\nparticular focus on visual data analysis and computer vision applications.\nConcretely, besides fundamental work in tensor-based visual data analysis\nmethods, we focus on recent developments that have brought on a gradual\nincrease of tensor methods, especially in deep learning architectures, and\ntheir implications in computer vision applications. To further enable the\nnewcomer to grasp such concepts quickly, we provide companion Python notebooks,\ncovering key aspects of the paper and implementing them, step-by-step with\nTensorLy.",
    "published": "2021-07-07T18:42:45Z",
    "pdf_url": "http://arxiv.org/pdf/2107.03436v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2108.11510v1",
    "title": "Deep Reinforcement Learning in Computer Vision: A Comprehensive Survey",
    "authors": [
      "Ngan Le",
      "Vidhiwar Singh Rathour",
      "Kashu Yamazaki",
      "Khoa Luu",
      "Marios Savvides"
    ],
    "abstract": "Deep reinforcement learning augments the reinforcement learning framework and\nutilizes the powerful representation of deep neural networks. Recent works have\ndemonstrated the remarkable successes of deep reinforcement learning in various\ndomains including finance, medicine, healthcare, video games, robotics, and\ncomputer vision. In this work, we provide a detailed review of recent and\nstate-of-the-art research advances of deep reinforcement learning in computer\nvision. We start with comprehending the theories of deep learning,\nreinforcement learning, and deep reinforcement learning. We then propose a\ncategorization of deep reinforcement learning methodologies and discuss their\nadvantages and limitations. In particular, we divide deep reinforcement\nlearning into seven main categories according to their applications in computer\nvision, i.e. (i)landmark localization (ii) object detection; (iii) object\ntracking; (iv) registration on both 2D image and 3D image volumetric data (v)\nimage segmentation; (vi) videos analysis; and (vii) other applications. Each of\nthese categories is further analyzed with reinforcement learning techniques,\nnetwork design, and performance. Moreover, we provide a comprehensive analysis\nof the existing publicly available datasets and examine source code\navailability. Finally, we present some open issues and discuss future research\ndirections on deep reinforcement learning in computer vision",
    "published": "2021-08-25T23:01:48Z",
    "pdf_url": "http://arxiv.org/pdf/2108.11510v1",
    "categories": [
      "cs.CV",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1904.03321v2",
    "title": "Computer Vision Approach to Study Deformation of Materials",
    "authors": [
      "Chaoyi Zhu",
      "Haoren Wang",
      "Kevin Kaufmann",
      "Kenneth Vecchio"
    ],
    "abstract": "Characterization of the deformation of materials across different length\nscales has continuously attracted enormous attention from the mechanics and\nmaterials communities. In this study, the possibility of utilizing a computer\nvision algorithm to extract deformation information of materials has been\nexplored, which greatly expands the use of computer vision approaches to\nstudying mechanics of materials and potentially opens new dialogues between the\ntwo communities. The computer vision algorithm is first developed and tested on\ncomputationally deformed images, before evaluating experimentally collected\nimages on speckle painted samples before and after deformation. Moreover, a\nvirtual experiment has also shown the feasibility of mapping surface strain of\na sample based on its natural pattern with significantly improved accuracy\ncompared to DIC result, which provides new opportunities in experimentation and\ncomputer algorithms to study deformation mechanics of materials. Validation\nexperiments include evaluating the performance of strain mapping using the\ncomputer vision approach in the uniaxial tensile test and three-point bending\ntest, compared with extensometer reading and digital image correlation\nrespectively.",
    "published": "2019-04-05T23:51:38Z",
    "pdf_url": "http://arxiv.org/pdf/1904.03321v2",
    "categories": [
      "physics.comp-ph",
      "cond-mat.mtrl-sci"
    ]
  },
  {
    "arxiv_id": "1904.13307v1",
    "title": "Survey of Computer Vision and Machine Learning in Gastrointestinal\n  Endoscopy",
    "authors": [
      "Anant S. Vemuri"
    ],
    "abstract": "This paper attempts to provide the reader a place to begin studying the\napplication of computer vision and machine learning to gastrointestinal (GI)\nendoscopy. They have been classified into 18 categories. It should be be noted\nby the reader that this is a review from pre-deep learning era. A lot of deep\nlearning based applications have not been covered in this thesis.",
    "published": "2019-04-26T12:46:03Z",
    "pdf_url": "http://arxiv.org/pdf/1904.13307v1",
    "categories": [
      "physics.med-ph",
      "cs.CV",
      "eess.IV"
    ]
  },
  {
    "arxiv_id": "2010.06188v1",
    "title": "When Wireless Communications Meet Computer Vision in Beyond 5G",
    "authors": [
      "Takayuki Nishio",
      "Yusuke Koda",
      "Jihong Park",
      "Mehdi Bennis",
      "Klaus Doppler"
    ],
    "abstract": "This article articulates the emerging paradigm, sitting at the confluence of\ncomputer vision and wireless communication, to enable beyond-5G/6G\nmission-critical applications (autonomous/remote-controlled vehicles,\nvisuo-haptic VR, and other cyber-physical applications). First, drawing on\nrecent advances in machine learning and the availability of non-RF data,\nvision-aided wireless networks are shown to significantly enhance the\nreliability of wireless communication without sacrificing spectral efficiency.\nIn particular, we demonstrate how computer vision enables {look-ahead}\nprediction in a millimeter-wave channel blockage scenario, before the blockage\nactually happens. From a computer vision perspective, we highlight how radio\nfrequency (RF) based sensing and imaging are instrumental in robustifying\ncomputer vision applications against occlusion and failure. This is\ncorroborated via an RF-based image reconstruction use case, showcasing a\nreceiver-side image failure correction resulting in reduced retransmission and\nlatency. Taken together, this article sheds light on the much-needed\nconvergence of RF and non-RF modalities to enable ultra-reliable communication\nand truly intelligent 6G networks.",
    "published": "2020-10-13T05:25:35Z",
    "pdf_url": "http://arxiv.org/pdf/2010.06188v1",
    "categories": [
      "cs.CV",
      "cs.NI"
    ]
  },
  {
    "arxiv_id": "1902.06804v1",
    "title": "Democratisation of Usable Machine Learning in Computer Vision",
    "authors": [
      "Raymond Bond",
      "Ansgar Koene",
      "Alan Dix",
      "Jennifer Boger",
      "Maurice D. Mulvenna",
      "Mykola Galushka",
      "Bethany Waterhouse Bradley",
      "Fiona Browne",
      "Hui Wang",
      "Alexander Wong"
    ],
    "abstract": "Many industries are now investing heavily in data science and automation to\nreplace manual tasks and/or to help with decision making, especially in the\nrealm of leveraging computer vision to automate many monitoring, inspection,\nand surveillance tasks. This has resulted in the emergence of the 'data\nscientist' who is conversant in statistical thinking, machine learning (ML),\ncomputer vision, and computer programming. However, as ML becomes more\naccessible to the general public and more aspects of ML become automated,\napplications leveraging computer vision are increasingly being created by\nnon-experts with less opportunity for regulatory oversight. This points to the\noverall need for more educated responsibility for these lay-users of usable ML\ntools in order to mitigate potentially unethical ramifications. In this paper,\nwe undertake a SWOT analysis to study the strengths, weaknesses, opportunities,\nand threats of building usable ML tools for mass adoption for important areas\nleveraging ML such as computer vision. The paper proposes a set of data science\nliteracy criteria for educating and supporting lay-users in the responsible\ndevelopment and deployment of ML applications.",
    "published": "2019-02-18T21:22:45Z",
    "pdf_url": "http://arxiv.org/pdf/1902.06804v1",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2003.01994v1",
    "title": "The iCub multisensor datasets for robot and computer vision applications",
    "authors": [
      "Murat Kirtay",
      "Ugo Albanese",
      "Lorenzo Vannucci",
      "Guido Schillaci",
      "Cecilia Laschi",
      "Egidio Falotico"
    ],
    "abstract": "This document presents novel datasets, constructed by employing the iCub\nrobot equipped with an additional depth sensor and color camera. We used the\nrobot to acquire color and depth information for 210 objects in different\nacquisition scenarios. At this end, the results were large scale datasets for\nrobot and computer vision applications: object representation, object\nrecognition and classification, and action recognition.",
    "published": "2020-03-04T10:59:29Z",
    "pdf_url": "http://arxiv.org/pdf/2003.01994v1",
    "categories": [
      "cs.RO",
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2401.16424v2",
    "title": "Computer Vision for Primate Behavior Analysis in the Wild",
    "authors": [
      "Richard Vogg",
      "Timo Lüddecke",
      "Jonathan Henrich",
      "Sharmita Dey",
      "Matthias Nuske",
      "Valentin Hassler",
      "Derek Murphy",
      "Julia Fischer",
      "Julia Ostner",
      "Oliver Schülke",
      "Peter M. Kappeler",
      "Claudia Fichtel",
      "Alexander Gail",
      "Stefan Treue",
      "Hansjörg Scherberger",
      "Florentin Wörgötter",
      "Alexander S. Ecker"
    ],
    "abstract": "Advances in computer vision as well as increasingly widespread video-based\nbehavioral monitoring have great potential for transforming how we study animal\ncognition and behavior. However, there is still a fairly large gap between the\nexciting prospects and what can actually be achieved in practice today,\nespecially in videos from the wild. With this perspective paper, we want to\ncontribute towards closing this gap, by guiding behavioral scientists in what\ncan be expected from current methods and steering computer vision researchers\ntowards problems that are relevant to advance research in animal behavior. We\nstart with a survey of the state-of-the-art methods for computer vision\nproblems that are directly relevant to the video-based study of animal\nbehavior, including object detection, multi-individual tracking, individual\nidentification, and (inter)action recognition. We then review methods for\neffort-efficient learning, which is one of the biggest challenges from a\npractical perspective. Finally, we close with an outlook into the future of the\nemerging field of computer vision for animal behavior, where we argue that the\nfield should develop approaches to unify detection, tracking, identification\nand (inter)action recognition in a single, video-based framework.",
    "published": "2024-01-29T18:59:56Z",
    "pdf_url": "http://arxiv.org/pdf/2401.16424v2",
    "categories": [
      "cs.CV",
      "q-bio.QM"
    ]
  },
  {
    "arxiv_id": "2402.12536v1",
    "title": "Designing High-Performing Networks for Multi-Scale Computer Vision",
    "authors": [
      "Cédric Picron"
    ],
    "abstract": "Since the emergence of deep learning, the computer vision field has\nflourished with models improving at a rapid pace on more and more complex\ntasks. We distinguish three main ways to improve a computer vision model: (1)\nimproving the data aspect by for example training on a large, more diverse\ndataset, (2) improving the training aspect by for example designing a better\noptimizer, and (3) improving the network architecture (or network for short).\nIn this thesis, we chose to improve the latter, i.e. improving the network\ndesigns of computer vision models. More specifically, we investigate new\nnetwork designs for multi-scale computer vision tasks, which are tasks\nrequiring to make predictions about concepts at different scales. The goal of\nthese new network designs is to outperform existing baseline designs from the\nliterature. Specific care is taken to make sure the comparisons are fair, by\nguaranteeing that the different network designs were trained and evaluated with\nthe same settings. Code is publicly available at\nhttps://github.com/CedricPicron/DetSeg.",
    "published": "2024-02-19T20:50:55Z",
    "pdf_url": "http://arxiv.org/pdf/2402.12536v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2005.03318v1",
    "title": "A Review of Computer Vision Methods in Network Security",
    "authors": [
      "Jiawei Zhao",
      "Rahat Masood",
      "Suranga Seneviratne"
    ],
    "abstract": "Network security has become an area of significant importance more than ever\nas highlighted by the eye-opening numbers of data breaches, attacks on critical\ninfrastructure, and malware/ransomware/cryptojacker attacks that are reported\nalmost every day. Increasingly, we are relying on networked infrastructure and\nwith the advent of IoT, billions of devices will be connected to the internet,\nproviding attackers with more opportunities to exploit. Traditional machine\nlearning methods have been frequently used in the context of network security.\nHowever, such methods are more based on statistical features extracted from\nsources such as binaries, emails, and packet flows.\n  On the other hand, recent years witnessed a phenomenal growth in computer\nvision mainly driven by the advances in the area of convolutional neural\nnetworks. At a glance, it is not trivial to see how computer vision methods are\nrelated to network security. Nonetheless, there is a significant amount of work\nthat highlighted how methods from computer vision can be applied in network\nsecurity for detecting attacks or building security solutions. In this paper,\nwe provide a comprehensive survey of such work under three topics; i) phishing\nattempt detection, ii) malware detection, and iii) traffic anomaly detection.\nNext, we review a set of such commercial products for which public information\nis available and explore how computer vision methods are effectively used in\nthose products. Finally, we discuss existing research gaps and future research\ndirections, especially focusing on how network security research community and\nthe industry can leverage the exponential growth of computer vision methods to\nbuild much secure networked systems.",
    "published": "2020-05-07T08:29:11Z",
    "pdf_url": "http://arxiv.org/pdf/2005.03318v1",
    "categories": [
      "cs.NI",
      "cs.CR",
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1909.08148v1",
    "title": "AdaCompress: Adaptive Compression for Online Computer Vision Services",
    "authors": [
      "Hongshan Li",
      "Yu Guo",
      "Zhi Wang",
      "Shutao Xia",
      "Wenwu Zhu"
    ],
    "abstract": "With the growth of computer vision based applications and services, an\nexplosive amount of images have been uploaded to cloud servers which host such\ncomputer vision algorithms, usually in the form of deep learning models. JPEG\nhas been used as the {\\em de facto} compression and encapsulation method before\none uploads the images, due to its wide adaptation. However, standard JPEG\nconfiguration does not always perform well for compressing images that are to\nbe processed by a deep learning model, e.g., the standard quality level of JPEG\nleads to 50\\% of size overhead (compared with the best quality level selection)\non ImageNet under the same inference accuracy in popular computer vision models\nincluding InceptionNet, ResNet, etc. Knowing this, designing a better JPEG\nconfiguration for online computer vision services is still extremely\nchallenging: 1) Cloud-based computer vision models are usually a black box to\nend-users; thus it is difficult to design JPEG configuration without knowing\ntheir model structures. 2) JPEG configuration has to change when different\nusers use it. In this paper, we propose a reinforcement learning based JPEG\nconfiguration framework. In particular, we design an agent that adaptively\nchooses the compression level according to the input image's features and\nbackend deep learning models. Then we train the agent in a reinforcement\nlearning way to adapt it for different deep learning cloud services that act as\nthe {\\em interactive training environment} and feeding a reward with\ncomprehensive consideration of accuracy and data size. In our real-world\nevaluation on Amazon Rekognition, Face++ and Baidu Vision, our approach can\nreduce the size of images by 1/2 -- 1/3 while the overall classification\naccuracy only decreases slightly.",
    "published": "2019-09-17T23:45:28Z",
    "pdf_url": "http://arxiv.org/pdf/1909.08148v1",
    "categories": [
      "cs.MM",
      "eess.IV"
    ]
  },
  {
    "arxiv_id": "2309.13744v3",
    "title": "A Systematic Literature Review of Computer Vision Applications in\n  Robotized Wire Harness Assembly",
    "authors": [
      "Hao Wang",
      "Omkar Salunkhe",
      "Walter Quadrini",
      "Dan Lämkull",
      "Fredrik Ore",
      "Mélanie Despeisse",
      "Luca Fumagalli",
      "Johan Stahre",
      "Björn Johansson"
    ],
    "abstract": "This article provides a systematic literature review of computer vision\napplications in robotized wire harness assembly.",
    "published": "2023-09-24T20:28:01Z",
    "pdf_url": "http://arxiv.org/pdf/2309.13744v3",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ]
  },
  {
    "arxiv_id": "1310.0315v1",
    "title": "Computer Vision Systems in Road Vehicles: A Review",
    "authors": [
      "Kristian Kovačić",
      "Edouard Ivanjko",
      "Hrvoje Gold"
    ],
    "abstract": "The number of road vehicles significantly increased in recent decades. This\ntrend accompanied a build-up of road infrastructure and development of various\ncontrol systems to increase road traffic safety, road capacity and travel\ncomfort. In traffic safety significant development has been made and today's\nsystems more and more include cameras and computer vision methods. Cameras are\nused as part of the road infrastructure or in vehicles. In this paper a review\non computer vision systems in vehicles from the stand point of traffic\nengineering is given. Safety problems of road vehicles are presented, current\nstate of the art in-vehicle vision systems is described and open problems with\nfuture research directions are discussed.",
    "published": "2013-10-01T14:19:11Z",
    "pdf_url": "http://arxiv.org/pdf/1310.0315v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1705.07632v3",
    "title": "Computer vision-based food calorie estimation: dataset, method, and\n  experiment",
    "authors": [
      "Yanchao Liang",
      "Jianhua Li"
    ],
    "abstract": "Computer vision has been introduced to estimate calories from food images.\nBut current food image data sets don't contain volume and mass records of\nfoods, which leads to an incomplete calorie estimation. In this paper, we\npresent a novel food image data set with volume and mass records of foods, and\na deep learning method for food detection, to make a complete calorie\nestimation. Our data set includes 2978 images, and every image contains\ncorresponding each food's annotation, volume and mass records, as well as a\ncertain calibration reference. To estimate calorie of food in the proposed data\nset, a deep learning method using Faster R-CNN first is put forward to detect\nthe food. And the experiment results show our method is effective to estimate\ncalories and our data set contains adequate information for calorie estimation.\nOur data set is the first released food image data set which can be used to\nevaluate computer vision-based calorie estimation methods.",
    "published": "2017-05-22T09:47:29Z",
    "pdf_url": "http://arxiv.org/pdf/1705.07632v3",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1808.08275v1",
    "title": "Binary Image Features Proposed to Empower Computer Vision",
    "authors": [
      "Soumi Ray",
      "Vinod Kumar"
    ],
    "abstract": "This literature has proposed three fast and easy computable image features to\nimprove computer vision by offering more human-like vision power. These\nfeatures are not based on image pixels absolute or relative intensity; neither\nbased on shape or colour. So, no complex pixel by pixel calculation is\nrequired. For human eyes, pixel by pixel calculation is like seeing an image\nwith maximum zoom which is done only when a higher level of details is\nrequired. Normally, first we look at an image to get an overall idea about it\nto know whether it deserves further investigation or not. This capacity of\ngetting an idea at a glance is analysed and three basic features are proposed\nto empower computer vision. Potential of proposed features is tested and\nestablished through different medical dataset. Achieved accuracy in\nclassification demonstrates possibilities and potential of the use of the\nproposed features in image processing.",
    "published": "2018-08-14T06:39:58Z",
    "pdf_url": "http://arxiv.org/pdf/1808.08275v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1905.00310v1",
    "title": "Towards computer vision powered color-nutrient assessment of pureed food",
    "authors": [
      "Kaylen J. Pfisterer",
      "Robert Amelard",
      "Braeden Syrnyk",
      "Alexander Wong"
    ],
    "abstract": "With one in four individuals afflicted with malnutrition, computer vision may\nprovide a way of introducing a new level of automation in the nutrition field\nto reliably monitor food and nutrient intake. In this study, we present a novel\napproach to modeling the link between color and vitamin A content using\ntransmittance imaging of a pureed foods dilution series in a computer vision\npowered nutrient sensing system via a fine-tuned deep autoencoder network,\nwhich in this case was trained to predict the relative concentration of sweet\npotato purees. Experimental results show the deep autoencoder network can\nachieve an accuracy of 80% across beginner (6 month) and intermediate (8 month)\ncommercially prepared pureed sweet potato samples. Prediction errors may be\nexplained by fundamental differences in optical properties which are further\ndiscussed.",
    "published": "2019-05-01T13:42:19Z",
    "pdf_url": "http://arxiv.org/pdf/1905.00310v1",
    "categories": [
      "cs.CV",
      "cs.NE",
      "eess.IV"
    ]
  },
  {
    "arxiv_id": "2107.04259v2",
    "title": "Unity Perception: Generate Synthetic Data for Computer Vision",
    "authors": [
      "Steve Borkman",
      "Adam Crespi",
      "Saurav Dhakad",
      "Sujoy Ganguly",
      "Jonathan Hogins",
      "You-Cyuan Jhang",
      "Mohsen Kamalzadeh",
      "Bowen Li",
      "Steven Leal",
      "Pete Parisi",
      "Cesar Romero",
      "Wesley Smith",
      "Alex Thaman",
      "Samuel Warren",
      "Nupur Yadav"
    ],
    "abstract": "We introduce the Unity Perception package which aims to simplify and\naccelerate the process of generating synthetic datasets for computer vision\ntasks by offering an easy-to-use and highly customizable toolset. This\nopen-source package extends the Unity Editor and engine components to generate\nperfectly annotated examples for several common computer vision tasks.\nAdditionally, it offers an extensible Randomization framework that lets the\nuser quickly construct and configure randomized simulation parameters in order\nto introduce variation into the generated datasets. We provide an overview of\nthe provided tools and how they work, and demonstrate the value of the\ngenerated synthetic datasets by training a 2D object detection model. The model\ntrained with mostly synthetic data outperforms the model trained using only\nreal data.",
    "published": "2021-07-09T07:09:00Z",
    "pdf_url": "http://arxiv.org/pdf/2107.04259v2",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1211.4907v2",
    "title": "Mahotas: Open source software for scriptable computer vision",
    "authors": [
      "Luis Pedro Coelho"
    ],
    "abstract": "Mahotas is a computer vision library for Python. It contains traditional\nimage processing functionality such as filtering and morphological operations\nas well as more modern computer vision functions for feature computation,\nincluding interest point detection and local descriptors.\n  The interface is in Python, a dynamic programming language, which is very\nappropriate for fast development, but the algorithms are implemented in C++ and\nare tuned for speed. The library is designed to fit in with the scientific\nsoftware ecosystem in this language and can leverage the existing\ninfrastructure developed in that language.\n  Mahotas is released under a liberal open source license (MIT License) and is\navailable from (http://github.com/luispedro/mahotas) and from the Python\nPackage Index (http://pypi.python.org/pypi/mahotas).",
    "published": "2012-11-21T00:51:10Z",
    "pdf_url": "http://arxiv.org/pdf/1211.4907v2",
    "categories": [
      "cs.CV",
      "cs.SE"
    ]
  },
  {
    "arxiv_id": "1909.13579v1",
    "title": "Meta-learning algorithms for Few-Shot Computer Vision",
    "authors": [
      "Etienne Bennequin"
    ],
    "abstract": "Few-Shot Learning is the challenge of training a model with only a small\namount of data. Many solutions to this problem use meta-learning algorithms,\ni.e. algorithms that learn to learn. By sampling few-shot tasks from a larger\ndataset, we can teach these algorithms to solve new, unseen tasks. This\ndocument reports my work on meta-learning algorithms for Few-Shot Computer\nVision. This work was done during my internship at Sicara, a French company\nbuilding image recognition solutions for businesses. It contains: 1. an\nextensive review of the state-of-the-art in few-shot computer vision; 2. a\nbenchmark of meta-learning algorithms for few-shot image classification; 3. the\nintroduction to a novel meta-learning algorithm for few-shot object detection,\nwhich is still in development.",
    "published": "2019-09-30T10:51:16Z",
    "pdf_url": "http://arxiv.org/pdf/1909.13579v1",
    "categories": [
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1910.02190v2",
    "title": "Kornia: an Open Source Differentiable Computer Vision Library for\n  PyTorch",
    "authors": [
      "Edgar Riba",
      "Dmytro Mishkin",
      "Daniel Ponsa",
      "Ethan Rublee",
      "Gary Bradski"
    ],
    "abstract": "This work presents Kornia -- an open source computer vision library which\nconsists of a set of differentiable routines and modules to solve generic\ncomputer vision problems. The package uses PyTorch as its main backend both for\nefficiency and to take advantage of the reverse-mode auto-differentiation to\ndefine and compute the gradient of complex functions. Inspired by OpenCV,\nKornia is composed of a set of modules containing operators that can be\ninserted inside neural networks to train models to perform image\ntransformations, camera calibration, epipolar geometry, and low level image\nprocessing techniques, such as filtering and edge detection that operate\ndirectly on high dimensional tensor representations. Examples of classical\nvision problems implemented using our framework are provided including a\nbenchmark comparing to existing vision libraries.",
    "published": "2019-10-05T01:29:54Z",
    "pdf_url": "http://arxiv.org/pdf/1910.02190v2",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2305.14986v1",
    "title": "Non-adversarial Robustness of Deep Learning Methods for Computer Vision",
    "authors": [
      "Gorana Gojić",
      "Vladimir Vincan",
      "Ognjen Kundačina",
      "Dragiša Mišković",
      "Dinu Dragan"
    ],
    "abstract": "Non-adversarial robustness, also known as natural robustness, is a property\nof deep learning models that enables them to maintain performance even when\nfaced with distribution shifts caused by natural variations in data. However,\nachieving this property is challenging because it is difficult to predict in\nadvance the types of distribution shifts that may occur. To address this\nchallenge, researchers have proposed various approaches, some of which\nanticipate potential distribution shifts, while others utilize knowledge about\nthe shifts that have already occurred to enhance model generalizability. In\nthis paper, we present a brief overview of the most recent techniques for\nimproving the robustness of computer vision methods, as well as a summary of\ncommonly used robustness benchmark datasets for evaluating the model's\nperformance under data distribution shifts. Finally, we examine the strengths\nand limitations of the approaches reviewed and identify general trends in deep\nlearning robustness improvement for computer vision.",
    "published": "2023-05-24T10:21:31Z",
    "pdf_url": "http://arxiv.org/pdf/2305.14986v1",
    "categories": [
      "cs.LG",
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1906.07328v2",
    "title": "Losing Confidence in Quality: Unspoken Evolution of Computer Vision\n  Services",
    "authors": [
      "Alex Cummaudo",
      "Rajesh Vasa",
      "John Grundy",
      "Mohamed Abdelrazek",
      "Andrew Cain"
    ],
    "abstract": "Recent advances in artificial intelligence (AI) and machine learning (ML),\nsuch as computer vision, are now available as intelligent services and their\naccessibility and simplicity is compelling. Multiple vendors now offer this\ntechnology as cloud services and developers want to leverage these advances to\nprovide value to end-users. However, there is no firm investigation into the\nmaintenance and evolution risks arising from use of these intelligent services;\nin particular, their behavioural consistency and transparency of their\nfunctionality. We evaluated the responses of three different intelligent\nservices (specifically computer vision) over 11 months using 3 different data\nsets, verifying responses against the respective documentation and assessing\nevolution risk. We found that there are: (1) inconsistencies in how these\nservices behave; (2) evolution risk in the responses; and (3) a lack of clear\ncommunication that documents these risks and inconsistencies. We propose a set\nof recommendations to both developers and intelligent service providers to\ninform risk and assist maintainability.",
    "published": "2019-06-18T01:11:43Z",
    "pdf_url": "http://arxiv.org/pdf/1906.07328v2",
    "categories": [
      "cs.SE",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2109.11369v4",
    "title": "Recent Advances of Continual Learning in Computer Vision: An Overview",
    "authors": [
      "Haoxuan Qu",
      "Hossein Rahmani",
      "Li Xu",
      "Bryan Williams",
      "Jun Liu"
    ],
    "abstract": "In contrast to batch learning where all training data is available at once,\ncontinual learning represents a family of methods that accumulate knowledge and\nlearn continuously with data available in sequential order. Similar to the\nhuman learning process with the ability of learning, fusing, and accumulating\nnew knowledge coming at different time steps, continual learning is considered\nto have high practical significance. Hence, continual learning has been studied\nin various artificial intelligence tasks. In this paper, we present a\ncomprehensive review of the recent progress of continual learning in computer\nvision. In particular, the works are grouped by their representative\ntechniques, including regularization, knowledge distillation, memory,\ngenerative replay, parameter isolation, and a combination of the above\ntechniques. For each category of these techniques, both its characteristics and\napplications in computer vision are presented. At the end of this overview,\nseveral subareas, where continuous knowledge accumulation is potentially\nhelpful while continual learning has not been well studied, are discussed.",
    "published": "2021-09-23T13:30:18Z",
    "pdf_url": "http://arxiv.org/pdf/2109.11369v4",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2211.13508v2",
    "title": "1st Workshop on Maritime Computer Vision (MaCVi) 2023: Challenge Results",
    "authors": [
      "Benjamin Kiefer",
      "Matej Kristan",
      "Janez Perš",
      "Lojze Žust",
      "Fabio Poiesi",
      "Fabio Augusto de Alcantara Andrade",
      "Alexandre Bernardino",
      "Matthew Dawkins",
      "Jenni Raitoharju",
      "Yitong Quan",
      "Adem Atmaca",
      "Timon Höfer",
      "Qiming Zhang",
      "Yufei Xu",
      "Jing Zhang",
      "Dacheng Tao",
      "Lars Sommer",
      "Raphael Spraul",
      "Hangyue Zhao",
      "Hongpu Zhang",
      "Yanyun Zhao",
      "Jan Lukas Augustin",
      "Eui-ik Jeon",
      "Impyeong Lee",
      "Luca Zedda",
      "Andrea Loddo",
      "Cecilia Di Ruberto",
      "Sagar Verma",
      "Siddharth Gupta",
      "Shishir Muralidhara",
      "Niharika Hegde",
      "Daitao Xing",
      "Nikolaos Evangeliou",
      "Anthony Tzes",
      "Vojtěch Bartl",
      "Jakub Špaňhel",
      "Adam Herout",
      "Neelanjan Bhowmik",
      "Toby P. Breckon",
      "Shivanand Kundargi",
      "Tejas Anvekar",
      "Chaitra Desai",
      "Ramesh Ashok Tabib",
      "Uma Mudengudi",
      "Arpita Vats",
      "Yang Song",
      "Delong Liu",
      "Yonglin Li",
      "Shuman Li",
      "Chenhao Tan",
      "Long Lan",
      "Vladimir Somers",
      "Christophe De Vleeschouwer",
      "Alexandre Alahi",
      "Hsiang-Wei Huang",
      "Cheng-Yen Yang",
      "Jenq-Neng Hwang",
      "Pyong-Kun Kim",
      "Kwangju Kim",
      "Kyoungoh Lee",
      "Shuai Jiang",
      "Haiwen Li",
      "Zheng Ziqiang",
      "Tuan-Anh Vu",
      "Hai Nguyen-Truong",
      "Sai-Kit Yeung",
      "Zhuang Jia",
      "Sophia Yang",
      "Chih-Chung Hsu",
      "Xiu-Yu Hou",
      "Yu-An Jhang",
      "Simon Yang",
      "Mau-Tsuen Yang"
    ],
    "abstract": "The 1$^{\\text{st}}$ Workshop on Maritime Computer Vision (MaCVi) 2023 focused\non maritime computer vision for Unmanned Aerial Vehicles (UAV) and Unmanned\nSurface Vehicle (USV), and organized several subchallenges in this domain: (i)\nUAV-based Maritime Object Detection, (ii) UAV-based Maritime Object Tracking,\n(iii) USV-based Maritime Obstacle Segmentation and (iv) USV-based Maritime\nObstacle Detection. The subchallenges were based on the SeaDronesSee and MODS\nbenchmarks. This report summarizes the main findings of the individual\nsubchallenges and introduces a new benchmark, called SeaDronesSee Object\nDetection v2, which extends the previous benchmark by including more classes\nand footage. We provide statistical and qualitative analyses, and assess trends\nin the best-performing methodologies of over 130 submissions. The methods are\nsummarized in the appendix. The datasets, evaluation code and the leaderboard\nare publicly available at https://seadronessee.cs.uni-tuebingen.de/macvi.",
    "published": "2022-11-24T09:59:13Z",
    "pdf_url": "http://arxiv.org/pdf/2211.13508v2",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ]
  },
  {
    "arxiv_id": "2303.15919v3",
    "title": "Fully Hyperbolic Convolutional Neural Networks for Computer Vision",
    "authors": [
      "Ahmad Bdeir",
      "Kristian Schwethelm",
      "Niels Landwehr"
    ],
    "abstract": "Real-world visual data exhibit intrinsic hierarchical structures that can be\nrepresented effectively in hyperbolic spaces. Hyperbolic neural networks (HNNs)\nare a promising approach for learning feature representations in such spaces.\nHowever, current HNNs in computer vision rely on Euclidean backbones and only\nproject features to the hyperbolic space in the task heads, limiting their\nability to fully leverage the benefits of hyperbolic geometry. To address this,\nwe present HCNN, a fully hyperbolic convolutional neural network (CNN) designed\nfor computer vision tasks. Based on the Lorentz model, we generalize\nfundamental components of CNNs and propose novel formulations of the\nconvolutional layer, batch normalization, and multinomial logistic regression.\n{Experiments on standard vision tasks demonstrate the promising performance of\nour HCNN framework in both hybrid and fully hyperbolic settings.} Overall, we\nbelieve our contributions provide a foundation for developing more powerful\nHNNs that can better represent complex structures found in image data. Our code\nis publicly available at https://github.com/kschwethelm/HyperbolicCV.",
    "published": "2023-03-28T12:20:52Z",
    "pdf_url": "http://arxiv.org/pdf/2303.15919v3",
    "categories": [
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2311.14762v1",
    "title": "The 2nd Workshop on Maritime Computer Vision (MaCVi) 2024",
    "authors": [
      "Benjamin Kiefer",
      "Lojze Žust",
      "Matej Kristan",
      "Janez Perš",
      "Matija Teršek",
      "Arnold Wiliem",
      "Martin Messmer",
      "Cheng-Yen Yang",
      "Hsiang-Wei Huang",
      "Zhongyu Jiang",
      "Heng-Cheng Kuo",
      "Jie Mei",
      "Jenq-Neng Hwang",
      "Daniel Stadler",
      "Lars Sommer",
      "Kaer Huang",
      "Aiguo Zheng",
      "Weitu Chong",
      "Kanokphan Lertniphonphan",
      "Jun Xie",
      "Feng Chen",
      "Jian Li",
      "Zhepeng Wang",
      "Luca Zedda",
      "Andrea Loddo",
      "Cecilia Di Ruberto",
      "Tuan-Anh Vu",
      "Hai Nguyen-Truong",
      "Tan-Sang Ha",
      "Quan-Dung Pham",
      "Sai-Kit Yeung",
      "Yuan Feng",
      "Nguyen Thanh Thien",
      "Lixin Tian",
      "Sheng-Yao Kuan",
      "Yuan-Hao Ho",
      "Angel Bueno Rodriguez",
      "Borja Carrillo-Perez",
      "Alexander Klein",
      "Antje Alex",
      "Yannik Steiniger",
      "Felix Sattler",
      "Edgardo Solano-Carrillo",
      "Matej Fabijanić",
      "Magdalena Šumunec",
      "Nadir Kapetanović",
      "Andreas Michel",
      "Wolfgang Gross",
      "Martin Weinmann"
    ],
    "abstract": "The 2nd Workshop on Maritime Computer Vision (MaCVi) 2024 addresses maritime\ncomputer vision for Unmanned Aerial Vehicles (UAV) and Unmanned Surface\nVehicles (USV). Three challenges categories are considered: (i) UAV-based\nMaritime Object Tracking with Re-identification, (ii) USV-based Maritime\nObstacle Segmentation and Detection, (iii) USV-based Maritime Boat Tracking.\nThe USV-based Maritime Obstacle Segmentation and Detection features three\nsub-challenges, including a new embedded challenge addressing efficicent\ninference on real-world embedded devices. This report offers a comprehensive\noverview of the findings from the challenges. We provide both statistical and\nqualitative analyses, evaluating trends from over 195 submissions. All\ndatasets, evaluation code, and the leaderboard are available to the public at\nhttps://macvi.org/workshop/macvi24.",
    "published": "2023-11-23T21:01:14Z",
    "pdf_url": "http://arxiv.org/pdf/2311.14762v1",
    "categories": [
      "cs.CV",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2403.07153v1",
    "title": "2023 Low-Power Computer Vision Challenge (LPCVC) Summary",
    "authors": [
      "Leo Chen",
      "Benjamin Boardley",
      "Ping Hu",
      "Yiru Wang",
      "Yifan Pu",
      "Xin Jin",
      "Yongqiang Yao",
      "Ruihao Gong",
      "Bo Li",
      "Gao Huang",
      "Xianglong Liu",
      "Zifu Wan",
      "Xinwang Chen",
      "Ning Liu",
      "Ziyi Zhang",
      "Dongping Liu",
      "Ruijie Shan",
      "Zhengping Che",
      "Fachao Zhang",
      "Xiaofeng Mou",
      "Jian Tang",
      "Maxim Chuprov",
      "Ivan Malofeev",
      "Alexander Goncharenko",
      "Andrey Shcherbin",
      "Arseny Yanchenko",
      "Sergey Alyamkin",
      "Xiao Hu",
      "George K. Thiruvathukal",
      "Yung Hsiang Lu"
    ],
    "abstract": "This article describes the 2023 IEEE Low-Power Computer Vision Challenge\n(LPCVC). Since 2015, LPCVC has been an international competition devoted to\ntackling the challenge of computer vision (CV) on edge devices. Most CV\nresearchers focus on improving accuracy, at the expense of ever-growing sizes\nof machine models. LPCVC balances accuracy with resource requirements. Winners\nmust achieve high accuracy with short execution time when their CV solutions\nrun on an embedded device, such as Raspberry PI or Nvidia Jetson Nano. The\nvision problem for 2023 LPCVC is segmentation of images acquired by Unmanned\nAerial Vehicles (UAVs, also called drones) after disasters. The 2023 LPCVC\nattracted 60 international teams that submitted 676 solutions during the\nsubmission window of one month. This article explains the setup of the\ncompetition and highlights the winners' methods that improve accuracy and\nshorten execution time.",
    "published": "2024-03-11T20:51:18Z",
    "pdf_url": "http://arxiv.org/pdf/2403.07153v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2404.00936v4",
    "title": "A Comprehensive Review of Knowledge Distillation in Computer Vision",
    "authors": [
      "Gousia Habib",
      "Tausifa jan Saleem",
      "Sheikh Musa Kaleem",
      "Tufail Rouf",
      "Brejesh Lall"
    ],
    "abstract": "Deep learning techniques have been demonstrated to surpass preceding\ncutting-edge machine learning techniques in recent years, with computer vision\nbeing one of the most prominent examples. However, deep learning models suffer\nfrom significant drawbacks when deployed in resource-constrained environments\ndue to their large model size and high complexity. Knowledge Distillation is\none of the prominent solutions to overcome this challenge. This review paper\nexamines the current state of research on knowledge distillation, a technique\nfor compressing complex models into smaller and simpler ones. The paper\nprovides an overview of the major principles and techniques associated with\nknowledge distillation and reviews the applications of knowledge distillation\nin the domain of computer vision. The review focuses on the benefits of\nknowledge distillation, as well as the problems that must be overcome to\nimprove its effectiveness.",
    "published": "2024-04-01T05:46:15Z",
    "pdf_url": "http://arxiv.org/pdf/2404.00936v4",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2412.09612v3",
    "title": "Olympus: A Universal Task Router for Computer Vision Tasks",
    "authors": [
      "Yuanze Lin",
      "Yunsheng Li",
      "Dongdong Chen",
      "Weijian Xu",
      "Ronald Clark",
      "Philip H. S. Torr"
    ],
    "abstract": "We introduce Olympus, a new approach that transforms Multimodal Large\nLanguage Models (MLLMs) into a unified framework capable of handling a wide\narray of computer vision tasks. Utilizing a controller MLLM, Olympus delegates\nover 20 specialized tasks across images, videos, and 3D objects to dedicated\nmodules. This instruction-based routing enables complex workflows through\nchained actions without the need for training heavy generative models. Olympus\neasily integrates with existing MLLMs, expanding their capabilities with\ncomparable performance. Experimental results demonstrate that Olympus achieves\nan average routing accuracy of 94.75% across 20 tasks and precision of 91.82%\nin chained action scenarios, showcasing its effectiveness as a universal task\nrouter that can solve a diverse range of computer vision tasks. Project page:\nhttp://yuanze-lin.me/Olympus_page/",
    "published": "2024-12-12T18:59:40Z",
    "pdf_url": "http://arxiv.org/pdf/2412.09612v3",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2507.22000v1",
    "title": "Staining and locking computer vision models without retraining",
    "authors": [
      "Oliver J. Sutton",
      "Qinghua Zhou",
      "George Leete",
      "Alexander N. Gorban",
      "Ivan Y. Tyukin"
    ],
    "abstract": "We introduce new methods of staining and locking computer vision models, to\nprotect their owners' intellectual property. Staining, also known as\nwatermarking, embeds secret behaviour into a model which can later be used to\nidentify it, while locking aims to make a model unusable unless a secret\ntrigger is inserted into input images. Unlike existing methods, our algorithms\ncan be used to stain and lock pre-trained models without requiring fine-tuning\nor retraining, and come with provable, computable guarantees bounding their\nworst-case false positive rates. The stain and lock are implemented by directly\nmodifying a small number of the model's weights and have minimal impact on the\n(unlocked) model's performance. Locked models are unlocked by inserting a small\n`trigger patch' into the corner of the input image. We present experimental\nresults showing the efficacy of our methods and demonstrating their practical\nperformance on a variety of computer vision models.",
    "published": "2025-07-29T16:47:34Z",
    "pdf_url": "http://arxiv.org/pdf/2507.22000v1",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "68T07, 68T45, 68W40",
      "I.2.10; F.2.0; K.5.1; K.6.5"
    ]
  },
  {
    "arxiv_id": "1809.05076v1",
    "title": "Computer Vision-aided Atom Tracking in STEM Imaging",
    "authors": [
      "Yawei Hui",
      "Yaohua Liu"
    ],
    "abstract": "To address the SMC'17 data challenge -- \"Data mining atomically resolved\nimages for material properties\", we first used the classic \"blob detection\"\nalgorithms developed in computer vision to identify all atom centers in each\nSTEM image frame. With the help of nearest neighbor analysis, we then found and\nlabeled every atom center common to all the STEM frames and tracked their\nmovements through the given time interval for both Molybdenum or Selenium\natoms.",
    "published": "2018-09-13T17:33:18Z",
    "pdf_url": "http://arxiv.org/pdf/1809.05076v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1906.01529v6",
    "title": "Generative Adversarial Networks in Computer Vision: A Survey and\n  Taxonomy",
    "authors": [
      "Zhengwei Wang",
      "Qi She",
      "Tomas E. Ward"
    ],
    "abstract": "Generative adversarial networks (GANs) have been extensively studied in the\npast few years. Arguably their most significant impact has been in the area of\ncomputer vision where great advances have been made in challenges such as\nplausible image generation, image-to-image translation, facial attribute\nmanipulation and similar domains. Despite the significant successes achieved to\ndate, applying GANs to real-world problems still poses significant challenges,\nthree of which we focus on here. These are: (1) the generation of high quality\nimages, (2) diversity of image generation, and (3) stable training. Focusing on\nthe degree to which popular GAN technologies have made progress against these\nchallenges, we provide a detailed review of the state of the art in GAN-related\nresearch in the published scientific literature. We further structure this\nreview through a convenient taxonomy we have adopted based on variations in GAN\narchitectures and loss functions. While several reviews for GANs have been\npresented to date, none have considered the status of this field based on their\nprogress towards addressing practical challenges relevant to computer vision.\nAccordingly, we review and critically discuss the most popular\narchitecture-variant, and loss-variant GANs, for tackling these challenges. Our\nobjective is to provide an overview as well as a critical analysis of the\nstatus of GAN research in terms of relevant progress towards important computer\nvision application requirements. As we do this we also discuss the most\ncompelling applications in computer vision in which GANs have demonstrated\nconsiderable success along with some suggestions for future research\ndirections. Code related to GAN-variants studied in this work is summarized on\nhttps://github.com/sheqi/GAN_Review.",
    "published": "2019-06-04T15:40:53Z",
    "pdf_url": "http://arxiv.org/pdf/1906.01529v6",
    "categories": [
      "cs.LG",
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2105.09137v1",
    "title": "TableZa -- A classical Computer Vision approach to Tabular Extraction",
    "authors": [
      "Saumya Banthia",
      "Anantha Sharma",
      "Ravi Mangipudi"
    ],
    "abstract": "Computer aided Tabular Data Extraction has always been a very challenging and\nerror prone task because it demands both Spectral and Spatial Sanity of data.\nIn this paper we discuss an approach for Tabular Data Extraction in the realm\nof document comprehension. Given the different kinds of the Tabular formats\nthat are often found across various documents, we discuss a novel approach\nusing Computer Vision for extraction of tabular data from images or vector\npdf(s) converted to image(s).",
    "published": "2021-05-19T13:55:33Z",
    "pdf_url": "http://arxiv.org/pdf/2105.09137v1",
    "categories": [
      "cs.CL",
      "cs.CV",
      "cs.IR",
      "I.5.1; I.5.2; I.5.4"
    ]
  },
  {
    "arxiv_id": "2211.02208v1",
    "title": "Automated Logging Drone: A Computer Vision Drone Implementation",
    "authors": [
      "Aaron Yagnik",
      "Adrian S. -W. Tam"
    ],
    "abstract": "In recent years, Artificial Intelligence (AI) and Computer Vision (CV) have\nbecome the pinnacle of technology with new developments seemingly every day.\nThis technology along with more powerful drone technology have made autonomous\nsurveillance more sought after. Here an overview of the Automated Logging Drone\n(ALD) project is presented along with examples of how this project can be used\nwith more refining and added features.",
    "published": "2022-11-04T01:36:32Z",
    "pdf_url": "http://arxiv.org/pdf/2211.02208v1",
    "categories": [
      "cs.HC"
    ]
  },
  {
    "arxiv_id": "2302.12185v1",
    "title": "Scaling Up Computer Vision Neural Networks Using Fast Fourier Transform",
    "authors": [
      "Siddharth Agrawal"
    ],
    "abstract": "Deep Learning-based Computer Vision field has recently been trying to explore\nlarger kernels for convolution to effectively scale up Convolutional Neural\nNetworks. Simultaneously, new paradigm of models such as Vision Transformers\nfind it difficult to scale up to larger higher resolution images due to their\nquadratic complexity in terms of input sequence. In this report, Fast Fourier\nTransform is utilised in various ways to provide some solutions to these\nissues.",
    "published": "2023-02-02T19:19:10Z",
    "pdf_url": "http://arxiv.org/pdf/2302.12185v1",
    "categories": [
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2202.08452v1",
    "title": "PCB Component Detection using Computer Vision for Hardware Assurance",
    "authors": [
      "Wenwei Zhao",
      "Suprith Gurudu",
      "Shayan Taheri",
      "Shajib Ghosh",
      "Mukhil Azhagan Mallaiyan Sathiaseelan",
      "Navid Asadizanjani"
    ],
    "abstract": "Printed Circuit Board (PCB) assurance in the optical domain is a crucial\nfield of study. Though there are many existing PCB assurance methods using\nimage processing, computer vision (CV), and machine learning (ML), the PCB\nfield is complex and increasingly evolving so new techniques are required to\novercome the emerging problems. Existing ML-based methods outperform\ntraditional CV methods, however they often require more data, have low\nexplainability, and can be difficult to adapt when a new technology arises. To\novercome these challenges, CV methods can be used in tandem with ML methods. In\nparticular, human-interpretable CV algorithms such as those that extract color,\nshape, and texture features increase PCB assurance explainability. This allows\nfor incorporation of prior knowledge, which effectively reduce the number of\ntrainable ML parameters and thus, the amount of data needed to achieve high\naccuracy when training or retraining an ML model. Hence, this study explores\nthe benefits and limitations of a variety of common computer vision-based\nfeatures for the task of PCB component detection using semantic data. Results\nof this study indicate that color features demonstrate promising performance\nfor PCB component detection. The purpose of this paper is to facilitate\ncollaboration between the hardware assurance, computer vision, and machine\nlearning communities.",
    "published": "2022-02-17T05:46:53Z",
    "pdf_url": "http://arxiv.org/pdf/2202.08452v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1709.04411v1",
    "title": "Exploiting skeletal structure in computer vision annotation with Benders\n  decomposition",
    "authors": [
      "Shaofei Wang",
      "Konrad Kording",
      "Julian Yarkony"
    ],
    "abstract": "Many annotation problems in computer vision can be phrased as integer linear\nprograms (ILPs). The use of standard industrial solvers does not to exploit the\nunderlying structure of such problems eg, the skeleton in pose estimation. The\nleveraging of the underlying structure in conjunction with industrial solvers\npromises increases in both speed and accuracy. Such structure can be exploited\nusing Bender's decomposition, a technique from operations research, that solves\ncomplex ILPs or mixed integer linear programs by decomposing them into\nsub-problems that communicate via a master problem. The intuition is that\nconditioned on a small subset of the variables the solution to the remaining\nvariables can be computed easily by taking advantage of properties of the ILP\nconstraint matrix such as block structure. In this paper we apply Benders\ndecomposition to a typical problem in computer vision where we have many\nsub-ILPs (eg, partitioning of detections, body-parts) coupled to a master ILP\n(eg, constructing skeletons). Dividing inference problems into a master problem\nand sub-problems motivates the development of a plethora of novel models, and\ninference approaches for the field of computer vision.",
    "published": "2017-09-13T16:43:07Z",
    "pdf_url": "http://arxiv.org/pdf/1709.04411v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2112.03444v2",
    "title": "GPU-Based Homotopy Continuation for Minimal Problems in Computer Vision",
    "authors": [
      "Chiang-Heng Chien",
      "Hongyi Fan",
      "Ahmad Abdelfattah",
      "Elias Tsigaridas",
      "Stanimire Tomov",
      "Benjamin Kimia"
    ],
    "abstract": "Systems of polynomial equations arise frequently in computer vision,\nespecially in multiview geometry problems. Traditional methods for solving\nthese systems typically aim to eliminate variables to reach a univariate\npolynomial, e.g., a tenth-order polynomial for 5-point pose estimation, using\nclever manipulations, or more generally using Grobner basis, resultants, and\nelimination templates, leading to successful algorithms for multiview geometry\nand other problems. However, these methods do not work when the problem is\ncomplex and when they do, they face efficiency and stability issues. Homotopy\nContinuation (HC) can solve more complex problems without the stability issues,\nand with guarantees of a global solution, but they are known to be slow. In\nthis paper we show that HC can be parallelized on a GPU, showing significant\nspeedups up to 26 times on polynomial benchmarks. We also show that GPU-HC can\nbe generically applied to a range of computer vision problems, including 4-view\ntriangulation and trifocal pose estimation with unknown focal length, which\ncannot be solved with elimination template but they can be efficiently solved\nwith HC. GPU-HC opens the door to easy formulation and solution of a range of\ncomputer vision problems.",
    "published": "2021-12-07T01:45:12Z",
    "pdf_url": "http://arxiv.org/pdf/2112.03444v2",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2204.02581v1",
    "title": "Banana Sub-Family Classification and Quality Prediction using Computer\n  Vision",
    "authors": [
      "Narayana Darapaneni",
      "Arjun Tanndalam",
      "Mohit Gupta",
      "Neeta Taneja",
      "Prabu Purushothaman",
      "Swati Eswar",
      "Anwesh Reddy Paduri",
      "Thangaselvi Arichandrapandian"
    ],
    "abstract": "India is the second largest producer of fruits and vegetables in the world,\nand one of the largest consumers of fruits like Banana, Papaya and Mangoes\nthrough retail and ecommerce giants like BigBasket, Grofers and Amazon Fresh.\nHowever, adoption of technology in supply chain and retail stores is still low\nand there is a great potential to adopt computer-vision based technology for\nidentification and classification of fruits. We have chosen banana fruit to\nbuild a computer vision based model to carry out the following three use-cases\n(a) Identify Banana from a given image (b) Determine sub-family or variety of\nBanana (c) Determine the quality of Banana. Successful execution of these\nuse-cases using computer-vision model would greatly help with overall inventory\nmanagement automation, quality control, quick and efficient weighing and\nbilling which all are manual labor intensive currently. In this work, we\nsuggest a machine learning pipeline that combines the ideas of CNNs, transfer\nlearning, and data augmentation towards improving Banana fruit sub family and\nquality image classification. We have built a basic CNN and then went on to\ntune a MobileNet Banana classification model using a combination of\nself-curated and publicly-available dataset of 3064 images. The results show an\noverall 93.4% and 100% accuracy for sub-family/variety and for quality test\nclassifications respectively.",
    "published": "2022-04-06T05:06:51Z",
    "pdf_url": "http://arxiv.org/pdf/2204.02581v1",
    "categories": [
      "cs.CV",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2408.00493v1",
    "title": "Explainable Emotion Decoding for Human and Computer Vision",
    "authors": [
      "Alessio Borriero",
      "Martina Milazzo",
      "Matteo Diano",
      "Davide Orsenigo",
      "Maria Chiara Villa",
      "Chiara Di Fazio",
      "Marco Tamietto",
      "Alan Perotti"
    ],
    "abstract": "Modern Machine Learning (ML) has significantly advanced various research\nfields, but the opaque nature of ML models hinders their adoption in several\ndomains. Explainable AI (XAI) addresses this challenge by providing additional\ninformation to help users understand the internal decision-making process of ML\nmodels. In the field of neuroscience, enriching a ML model for brain decoding\nwith attribution-based XAI techniques means being able to highlight which brain\nareas correlate with the task at hand, thus offering valuable insights to\ndomain experts. In this paper, we analyze human and Computer Vision (CV)\nsystems in parallel, training and explaining two ML models based respectively\non functional Magnetic Resonance Imaging (fMRI) and movie frames. We do so by\nleveraging the \"StudyForrest\" dataset, which includes functional Magnetic\nResonance Imaging (fMRI) scans of subjects watching the \"Forrest Gump\" movie,\nemotion annotations, and eye-tracking data. For human vision the ML task is to\nlink fMRI data with emotional annotations, and the explanations highlight the\nbrain regions strongly correlated with the label. On the other hand, for\ncomputer vision, the input data is movie frames, and the explanations are\npixel-level heatmaps. We cross-analyzed our results, linking human attention\n(obtained through eye-tracking) with XAI saliency on CV models and brain region\nactivations. We show how a parallel analysis of human and computer vision can\nprovide useful information for both the neuroscience community (allocation\ntheory) and the ML community (biological plausibility of convolutional models).",
    "published": "2024-08-01T11:53:44Z",
    "pdf_url": "http://arxiv.org/pdf/2408.00493v1",
    "categories": [
      "cs.CV",
      "eess.IV",
      "q-bio.NC"
    ]
  },
  {
    "arxiv_id": "2505.12425v1",
    "title": "Kornia-rs: A Low-Level 3D Computer Vision Library In Rust",
    "authors": [
      "Edgar Riba",
      "Jian Shi",
      "Aditya Kumar",
      "Andrew Shen",
      "Gary Bradski"
    ],
    "abstract": "We present \\textit{kornia-rs}, a high-performance 3D computer vision library\nwritten entirely in native Rust, designed for safety-critical and real-time\napplications. Unlike C++-based libraries like OpenCV or wrapper-based solutions\nlike OpenCV-Rust, \\textit{kornia-rs} is built from the ground up to leverage\nRust's ownership model and type system for memory and thread safety.\n\\textit{kornia-rs} adopts a statically-typed tensor system and a modular set of\ncrates, providing efficient image I/O, image processing and 3D operations. To\naid cross-platform compatibility, \\textit{kornia-rs} offers Python bindings,\nenabling seamless and efficient integration with Rust code. Empirical results\nshow that \\textit{kornia-rs} achieves a 3~ 5 times speedup in image\ntransformation tasks over native Rust alternatives, while offering comparable\nperformance to C++ wrapper-based libraries. In addition to 2D vision\ncapabilities, \\textit{kornia-rs} addresses a significant gap in the Rust\necosystem by providing a set of 3D computer vision operators. This paper\npresents the architecture and performance characteristics of\n\\textit{kornia-rs}, demonstrating its effectiveness in real-world computer\nvision applications.",
    "published": "2025-05-18T13:50:00Z",
    "pdf_url": "http://arxiv.org/pdf/2505.12425v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "0110157v1",
    "title": "Some Applications of Algebraic Curves to Computational Vision",
    "authors": [
      "Michael Fryers",
      "Jeremy Yirmeyahu Kaminski",
      "Mina Teicher"
    ],
    "abstract": "We introduce a new formalism and a number of new results in the context of\ngeometric computational vision. The classical scope of the research in\ngeometric computer vision is essentially limited to static configurations of\npoints and lines in $P^3$ . By using some well known material from algebraic\ngeometry, we open new branches to computational vision. We introduce algebraic\ncurves embedded in $P^3$ as the building blocks from which the tensor of a\ncouple of cameras (projections) can be computed. In the process we address\ndimensional issues and as a result establish the minimal number of algebraic\ncurves required for the tensor variety to be discrete as a function of their\ndegree and genus. We then establish new results on the reconstruction of an\nalgebraic curves in $P^3$ from multiple projections on projective planes\nembedded in $P^3$ . We address three different presentations of the curve: (i)\ndefinition by a set of equations, for which we show that for a generic\nconfiguration, two projections of a curve of degree d defines a curve in $P^3$\nwith two irreducible components, one of degree d and the other of degree $d(d -\n1)$, (ii) the dual presentation in the dual space $P^{3*}$, for which we derive\na lower bound for the number of projections necessary for linear reconstruction\nas a function of the degree and the genus, and (iii) the presentation as an\nhypersurface of $P^5$, defined by the set of lines in $P^3$ meeting the curve,\nfor which we also derive lower bounds for the number of projections necessary\nfor linear reconstruction as a function of the degree (of the curve). Moreover\nwe show that the latter representation yields a new and efficient algorithm for\ndealing with mixed configurations of static and moving points in $P^3$.",
    "published": "2001-10-15T18:37:04Z",
    "pdf_url": "http://arxiv.org/pdf/math/0110157v1",
    "categories": [
      "math.AG",
      "cs.IT",
      "math.IT"
    ]
  },
  {
    "arxiv_id": "2207.00449v3",
    "title": "Dissecting Self-Supervised Learning Methods for Surgical Computer Vision",
    "authors": [
      "Sanat Ramesh",
      "Vinkle Srivastav",
      "Deepak Alapatt",
      "Tong Yu",
      "Aditya Murali",
      "Luca Sestini",
      "Chinedu Innocent Nwoye",
      "Idris Hamoud",
      "Saurav Sharma",
      "Antoine Fleurentin",
      "Georgios Exarchakis",
      "Alexandros Karargyris",
      "Nicolas Padoy"
    ],
    "abstract": "The field of surgical computer vision has undergone considerable\nbreakthroughs in recent years with the rising popularity of deep neural\nnetwork-based methods. However, standard fully-supervised approaches for\ntraining such models require vast amounts of annotated data, imposing a\nprohibitively high cost; especially in the clinical domain. Self-Supervised\nLearning (SSL) methods, which have begun to gain traction in the general\ncomputer vision community, represent a potential solution to these annotation\ncosts, allowing to learn useful representations from only unlabeled data.\nStill, the effectiveness of SSL methods in more complex and impactful domains,\nsuch as medicine and surgery, remains limited and unexplored. In this work, we\naddress this critical need by investigating four state-of-the-art SSL methods\n(MoCo v2, SimCLR, DINO, SwAV) in the context of surgical computer vision. We\npresent an extensive analysis of the performance of these methods on the\nCholec80 dataset for two fundamental and popular tasks in surgical context\nunderstanding, phase recognition and tool presence detection. We examine their\nparameterization, then their behavior with respect to training data quantities\nin semi-supervised settings. Correct transfer of these methods to surgery, as\ndescribed and conducted in this work, leads to substantial performance gains\nover generic uses of SSL - up to 7.4% on phase recognition and 20% on tool\npresence detection - as well as state-of-the-art semi-supervised phase\nrecognition approaches by up to 14%. Further results obtained on a highly\ndiverse selection of surgical datasets exhibit strong generalization\nproperties. The code is available at\nhttps://github.com/CAMMA-public/SelfSupSurg.",
    "published": "2022-07-01T14:17:11Z",
    "pdf_url": "http://arxiv.org/pdf/2207.00449v3",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2401.17061v1",
    "title": "OmniSCV: An Omnidirectional Synthetic Image Generator for Computer\n  Vision",
    "authors": [
      "Bruno Berenguel-Baeta",
      "Jesus Bermudez-Cameo",
      "Jose J. Guerrero"
    ],
    "abstract": "Omnidirectional and 360{\\deg} images are becoming widespread in industry and\nin consumer society, causing omnidirectional computer vision to gain attention.\nTheir wide field of view allows the gathering of a great amount of information\nabout the environment from only an image. However, the distortion of these\nimages requires the development of specific algorithms for their treatment and\ninterpretation. Moreover, a high number of images is essential for the correct\ntraining of computer vision algorithms based on learning. In this paper, we\npresent a tool for generating datasets of omnidirectional images with semantic\nand depth information. These images are synthesized from a set of captures that\nare acquired in a realistic virtual environment for Unreal Engine 4 through an\ninterface plugin. We gather a variety of well-known projection models such as\nequirectangular and cylindrical panoramas, different fish-eye lenses,\ncatadioptric systems, and empiric models. Furthermore, we include in our tool\nphotorealistic non-central-projection systems as non-central panoramas and\nnon-central catadioptric systems. As far as we know, this is the first reported\ntool for generating photorealistic non-central images in the literature.\nMoreover, since the omnidirectional images are made virtually, we provide\npixel-wise information about semantics and depth as well as perfect knowledge\nof the calibration parameters of the cameras. This allows the creation of\nground-truth information with pixel precision for training learning algorithms\nand testing 3D vision approaches. To validate the proposed tool, different\ncomputer vision algorithms are tested as line extractions from dioptric and\ncatadioptric central images, 3D Layout recovery and SLAM using equirectangular\npanoramas, and 3D reconstruction from non-central panoramas.",
    "published": "2024-01-30T14:40:19Z",
    "pdf_url": "http://arxiv.org/pdf/2401.17061v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1305.1916v1",
    "title": "Computer vision applications for coronagraphic optical alignment and\n  image processing",
    "authors": [
      "Dmitry Savransky",
      "Sandrine J. Thomas",
      "Lisa A. Poyneer",
      "Bruce A. Macintosh"
    ],
    "abstract": "Modern coronagraphic systems require very precise alignment between optical\ncomponents and can benefit greatly from automated image processing. We discuss\nthree techniques commonly employed in the fields of computer vision and image\nanalysis as applied to the Gemini Planet Imager, a new facility instrument for\nthe Gemini South Observatory. We describe how feature extraction and clustering\nmethods can be used to aid in automated system alignment tasks, and also\npresent a search algorithm for finding regular features in science images used\nfor calibration and data processing. Along with discussions of each technique,\nwe present our specific implementation and show results of each one in\noperation.",
    "published": "2013-05-08T19:00:54Z",
    "pdf_url": "http://arxiv.org/pdf/1305.1916v1",
    "categories": [
      "astro-ph.IM"
    ]
  },
  {
    "arxiv_id": "2209.15455v1",
    "title": "Road Network Deterioration Monitoring Using Aerial Images and Computer\n  Vision",
    "authors": [
      "Nicolas Parra-A",
      "Vladimir Vargas-Calderón",
      "Herbert Vinck-Posada",
      "Nicanor Vinck"
    ],
    "abstract": "Road maintenance is an essential process for guaranteeing the quality of\ntransportation in any city. A crucial step towards effective road maintenance\nis the ability to update the inventory of the road network. We present a proof\nof concept of a protocol for maintaining said inventory based on the use of\nunmanned aerial vehicles to quickly collect images which are processed by a\ncomputer vision program that automatically identifies potholes and their\nseverity. Our protocol aims to provide information to local governments to\nprioritise the road network maintenance budget, and to be able to detect early\nstages of road deterioration so as to minimise maintenance expenditure.",
    "published": "2022-09-30T13:05:03Z",
    "pdf_url": "http://arxiv.org/pdf/2209.15455v1",
    "categories": [
      "cs.CV",
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "1610.02431v1",
    "title": "ResearchDoom and CocoDoom: Learning Computer Vision with Games",
    "authors": [
      "A. Mahendran",
      "H. Bilen",
      "J. F. Henriques",
      "A. Vedaldi"
    ],
    "abstract": "In this short note we introduce ResearchDoom, an implementation of the Doom\nfirst-person shooter that can extract detailed metadata from the game. We also\nintroduce the CocoDoom dataset, a collection of pre-recorded data extracted\nfrom Doom gaming sessions along with annotations in the MS Coco format.\nResearchDoom and CocoDoom can be used to train and evaluate a variety of\ncomputer vision methods such as object recognition, detection and segmentation\nat the level of instances and categories, tracking, ego-motion estimation,\nmonocular depth estimation and scene segmentation. The code and data are\navailable at http://www.robots.ox.ac.uk/~vgg/research/researchdoom.",
    "published": "2016-10-07T21:35:02Z",
    "pdf_url": "http://arxiv.org/pdf/1610.02431v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2106.03805v1",
    "title": "3DB: A Framework for Debugging Computer Vision Models",
    "authors": [
      "Guillaume Leclerc",
      "Hadi Salman",
      "Andrew Ilyas",
      "Sai Vemprala",
      "Logan Engstrom",
      "Vibhav Vineet",
      "Kai Xiao",
      "Pengchuan Zhang",
      "Shibani Santurkar",
      "Greg Yang",
      "Ashish Kapoor",
      "Aleksander Madry"
    ],
    "abstract": "We introduce 3DB: an extendable, unified framework for testing and debugging\nvision models using photorealistic simulation. We demonstrate, through a wide\nrange of use cases, that 3DB allows users to discover vulnerabilities in\ncomputer vision systems and gain insights into how models make decisions. 3DB\ncaptures and generalizes many robustness analyses from prior work, and enables\none to study their interplay. Finally, we find that the insights generated by\nthe system transfer to the physical world.\n  We are releasing 3DB as a library (https://github.com/3db/3db) alongside a\nset of example analyses, guides, and documentation: https://3db.github.io/3db/ .",
    "published": "2021-06-07T17:16:12Z",
    "pdf_url": "http://arxiv.org/pdf/2106.03805v1",
    "categories": [
      "cs.CV",
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2204.08601v1",
    "title": "A Tour of Visualization Techniques for Computer Vision Datasets",
    "authors": [
      "Bilal Alsallakh",
      "Pamela Bhattacharya",
      "Vanessa Feng",
      "Narine Kokhlikyan",
      "Orion Reblitz-Richardson",
      "Rahul Rajan",
      "David Yan"
    ],
    "abstract": "We survey a number of data visualization techniques for analyzing Computer\nVision (CV) datasets. These techniques help us understand properties and latent\npatterns in such data, by applying dataset-level analysis. We present various\nexamples of how such analysis helps predict the potential impact of the dataset\nproperties on CV models and informs appropriate mitigation of their\nshortcomings. Finally, we explore avenues for further visualization techniques\nof different modalities of CV datasets as well as ones that are tailored to\nsupport specific CV tasks and analysis needs.",
    "published": "2022-04-19T01:04:28Z",
    "pdf_url": "http://arxiv.org/pdf/2204.08601v1",
    "categories": [
      "cs.CV",
      "cs.GR"
    ]
  },
  {
    "arxiv_id": "2309.11608v1",
    "title": "Dataset Factory: A Toolchain For Generative Computer Vision Datasets",
    "authors": [
      "Daniel Kharitonov",
      "Ryan Turner"
    ],
    "abstract": "Generative AI workflows heavily rely on data-centric tasks - such as\nfiltering samples by annotation fields, vector distances, or scores produced by\ncustom classifiers. At the same time, computer vision datasets are quickly\napproaching petabyte volumes, rendering data wrangling difficult. In addition,\nthe iterative nature of data preparation necessitates robust dataset sharing\nand versioning mechanisms, both of which are hard to implement ad-hoc. To solve\nthese challenges, we propose a \"dataset factory\" approach that separates the\nstorage and processing of samples from metadata and enables data-centric\noperations at scale for machine learning teams and individual researchers.",
    "published": "2023-09-20T19:43:37Z",
    "pdf_url": "http://arxiv.org/pdf/2309.11608v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2406.08898v1",
    "title": "Computer Vision Approaches for Automated Bee Counting Application",
    "authors": [
      "Simon Bilik",
      "Ilona Janakova",
      "Adam Ligocki",
      "Dominik Ficek",
      "Karel Horak"
    ],
    "abstract": "Many application from the bee colony health state monitoring could be\nefficiently solved using a computer vision techniques. One of such challenges\nis an efficient way for counting the number of incoming and outcoming bees,\nwhich could be used to further analyse many trends, such as the bee colony\nhealth state, blooming periods, or for investigating the effects of\nagricultural spraying. In this paper, we compare three methods for the\nautomated bee counting over two own datasets. The best performing method is\nbased on the ResNet-50 convolutional neural network classifier, which achieved\naccuracy of 87% over the BUT1 dataset and the accuracy of 93% over the BUT2\ndataset.",
    "published": "2024-06-13T07:51:08Z",
    "pdf_url": "http://arxiv.org/pdf/2406.08898v1",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1405.4802v2",
    "title": "Use of Computer Vision to Detect Tangles in Tangled Objects",
    "authors": [
      "Paritosh Parmar"
    ],
    "abstract": "Untangling of structures like ropes and wires by autonomous robots can be\nuseful in areas such as personal robotics, industries and electrical wiring &\nrepairing by robots. This problem can be tackled by using computer vision\nsystem in robot. This paper proposes a computer vision based method for\nanalyzing visual data acquired from camera for perceiving the overlap of wires,\nropes, hoses i.e. detecting tangles. Information obtained after processing\nimage according to the proposed method comprises of position of tangles in\ntangled object and which wire passes over which wire. This information can then\nbe used to guide robot to untangle wire/s. Given an image, preprocessing is\ndone to remove noise. Then edges of wire are detected. After that, the image is\ndivided into smaller blocks and each block is checked for wire overlap/s and\nfinding other relevant information. TANGLED-100 dataset was introduced, which\nconsists of images of tangled linear deformable objects. Method discussed in\nhere was tested on the TANGLED-100 dataset. Accuracy achieved during\nexperiments was found to be 74.9%. Robotic simulations were carried out to\ndemonstrate the use of the proposed method in applications of robot. Proposed\nmethod is a general method that can be used by robots working in different\nsituations.",
    "published": "2014-05-19T16:51:11Z",
    "pdf_url": "http://arxiv.org/pdf/1405.4802v2",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1604.04024v3",
    "title": "Towards Automated Melanoma Screening: Proper Computer Vision & Reliable\n  Results",
    "authors": [
      "Michel Fornaciali",
      "Micael Carvalho",
      "Flávia Vasques Bittencourt",
      "Sandra Avila",
      "Eduardo Valle"
    ],
    "abstract": "In this paper we survey, analyze and criticize current art on automated\nmelanoma screening, reimplementing a baseline technique, and proposing two\nnovel ones. Melanoma, although highly curable when detected early, ends as one\nof the most dangerous types of cancer, due to delayed diagnosis and treatment.\nIts incidence is soaring, much faster than the number of trained professionals\nable to diagnose it. Automated screening appears as an alternative to make the\nmost of those professionals, focusing their time on the patients at risk while\nsafely discharging the other patients. However, the potential of automated\nmelanoma diagnosis is currently unfulfilled, due to the emphasis of current\nliterature on outdated computer vision models. Even more problematic is the\nirreproducibility of current art. We show how streamlined pipelines based upon\ncurrent Computer Vision outperform conventional models - a model based on an\nadvanced bags of words reaches an AUC of 84.6%, and a model based on deep\nneural networks reaches 89.3%, while the baseline (a classical bag of words)\nstays at 81.2%. We also initiate a dialog to improve reproducibility in our\ncommunity",
    "published": "2016-04-14T03:26:28Z",
    "pdf_url": "http://arxiv.org/pdf/1604.04024v3",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1605.09527v2",
    "title": "Biconvex Relaxation for Semidefinite Programming in Computer Vision",
    "authors": [
      "Sohil Shah",
      "Abhay Kumar",
      "Carlos Castillo",
      "David Jacobs",
      "Christoph Studer",
      "Tom Goldstein"
    ],
    "abstract": "Semidefinite programming is an indispensable tool in computer vision, but\ngeneral-purpose solvers for semidefinite programs are often too slow and memory\nintensive for large-scale problems. We propose a general framework to\napproximately solve large-scale semidefinite problems (SDPs) at low complexity.\nOur approach, referred to as biconvex relaxation (BCR), transforms a general\nSDP into a specific biconvex optimization problem, which can then be solved in\nthe original, low-dimensional variable space at low complexity. The resulting\nbiconvex problem is solved using an efficient alternating minimization (AM)\nprocedure. Since AM has the potential to get stuck in local minima, we propose\na general initialization scheme that enables BCR to start close to a global\noptimum - this is key for our algorithm to quickly converge to optimal or\nnear-optimal solutions. We showcase the efficacy of our approach on three\napplications in computer vision, namely segmentation, co-segmentation, and\nmanifold metric learning. BCR achieves solution quality comparable to\nstate-of-the-art SDP methods with speedups between 4X and 35X. At the same\ntime, BCR handles a more general set of SDPs than previous approaches, which\nare more specialized.",
    "published": "2016-05-31T08:43:44Z",
    "pdf_url": "http://arxiv.org/pdf/1605.09527v2",
    "categories": [
      "cs.CV",
      "cs.NA",
      "math.NA",
      "math.OC"
    ]
  },
  {
    "arxiv_id": "1811.11316v1",
    "title": "Using Computer Vision Techniques for Moving Poster Design",
    "authors": [
      "Sérgio Rebelo",
      "Pedro Martins",
      "João Bicker",
      "Penousal Machado"
    ],
    "abstract": "Graphic Design encompasses a wide range of activities from the design of\ntraditional print media (e.g., books and posters) to site-specific (e.g.,\nsignage systems) and electronic media (e.g., interfaces). Its practice always\nexplores the new possibilities of information and communication technologies.\nTherefore, interactivity and participation have become key features in the\ndesign process. Even in traditional print media, graphic designers are trying\nto enhance user experience and exploring new interaction models. Moving posters\nare an example of this. This type of posters combine the specific features of\nmotion and print worlds in order to produce attractive forms of communication\nthat explore and exploit the potential of digital screens. In our opinion, the\nnext step towards the integration of moving posters with the surroundings,\nwhere they operate, is incorporating data from the environment, which also\nenables the seamless participation of the audience. As such, the adoption of\ncomputer vision techniques for moving poster design becomes a natural approach.\nFollowing this line of thought, we present a system wherein computer vision\ntechniques are used to shape a moving poster. Although it is still a work in\nprogress, the system is already able to sense the surrounding physical\nenvironment and translate the collected data into graphical information. The\ndata is gathered from the environment in two ways: (1) directly using motion\ntracking; and (2) indirectly via contextual ambient data. In this sense, each\nuser interaction with the system results in a different experience and in a\nunique poster design.",
    "published": "2018-11-27T23:59:46Z",
    "pdf_url": "http://arxiv.org/pdf/1811.11316v1",
    "categories": [
      "cs.HC"
    ]
  },
  {
    "arxiv_id": "2004.13060v3",
    "title": "GIMP-ML: Python Plugins for using Computer Vision Models in GIMP",
    "authors": [
      "Kritik Soman"
    ],
    "abstract": "This paper introduces GIMP-ML v1.1, a set of Python plugins for the widely\npopular GNU Image Manipulation Program (GIMP). It enables the use of recent\nadvances in computer vision to the conventional image editing pipeline.\nApplications from deep learning such as monocular depth estimation, semantic\nsegmentation, mask generative adversarial networks, image super-resolution,\nde-noising, de-hazing, matting, enlightening and coloring have been\nincorporated with GIMP through Python-based plugins. Additionally, operations\non images such as k-means based color clustering have also been added. GIMP-ML\nrelies on standard Python packages such as numpy, pytorch, open-cv, scipy.\nApart from these, several image manipulation techniques using these plugins\nhave been compiled and demonstrated in the YouTube channel\n(https://youtube.com/user/kritiksoman) with the objective of demonstrating the\nuse-cases for machine learning based image modification. In addition, GIMP-ML\nalso aims to bring the benefits of using deep learning networks used for\ncomputer vision tasks to routine image processing workflows. The code and\ninstallation procedure for configuring these plugins is available at\nhttps://github.com/kritiksoman/GIMP-ML.",
    "published": "2020-04-27T18:00:37Z",
    "pdf_url": "http://arxiv.org/pdf/2004.13060v3",
    "categories": [
      "cs.CV",
      "65D19"
    ]
  },
  {
    "arxiv_id": "2009.11931v1",
    "title": "A Computer Vision Approach to Combat Lyme Disease",
    "authors": [
      "Sina Akbarian",
      "Tania Cawston",
      "Laurent Moreno",
      "Samir Patel",
      "Vanessa Allen",
      "Elham Dolatabadi"
    ],
    "abstract": "Lyme disease is an infectious disease transmitted to humans by a bite from an\ninfected Ixodes species (blacklegged ticks). It is one of the fastest growing\nvector-borne illness in North America and is expanding its geographic\nfootprint. Lyme disease treatment is time-sensitive, and can be cured by\nadministering an antibiotic (prophylaxis) to the patient within 72 hours after\na tick bite by the Ixodes species. However, the laboratory-based identification\nof each tick that might carry the bacteria is time-consuming and labour\nintensive and cannot meet the maximum turn-around-time of 72 hours for an\neffective treatment. Early identification of blacklegged ticks using computer\nvision technologies is a potential solution in promptly identifying a tick and\nadministering prophylaxis within a crucial window period. In this work, we\nbuild an automated detection tool that can differentiate blacklegged ticks from\nother ticks species using advanced deep learning and computer vision\napproaches. We demonstrate the classification of tick species using Convolution\nNeural Network (CNN) models, trained end-to-end from tick images directly.\nAdvanced knowledge transfer techniques within teacher-student learning\nframeworks are adopted to improve the performance of classification of tick\nspecies. Our best CNN model achieves 92% accuracy on test set. The tool can be\nintegrated with the geography of exposure to determine the risk of Lyme disease\ninfection and need for prophylaxis treatment.",
    "published": "2020-09-24T20:00:02Z",
    "pdf_url": "http://arxiv.org/pdf/2009.11931v1",
    "categories": [
      "cs.CV",
      "cs.LG",
      "eess.IV"
    ]
  },
  {
    "arxiv_id": "2104.04430v1",
    "title": "Ice Core Science Meets Computer Vision: Challenges and Perspectives",
    "authors": [
      "P. Bohleber",
      "M. Roman",
      "C. Barbante",
      "S. Vascon",
      "K. Siddiqi",
      "M. Pelillo"
    ],
    "abstract": "Polar ice cores play a central role in studies of the earth's climate system\nthrough natural archives. A pressing issue is the analysis of the oldest,\nhighly thinned ice core sections, where the identification of paleoclimate\nsignals is particularly challenging. For this, state-of-the-art imaging by\nlaser-ablation inductively-coupled plasma mass spectrometry (LA-ICP-MS) has the\npotential to be revolutionary due to its combination of micron-scale 2D\nchemical information with visual features. However, the quantitative study of\nrecord preservation in chemical images raises new questions that call for the\nexpertise of the computer vision community. To illustrate this new\ninter-disciplinary frontier, we describe a selected set of key questions. One\ncritical task is to assess the paleoclimate significance of single line\nprofiles along the main core axis, which we show is a scale-dependent problem\nfor which advanced image analysis methods are critical. Another important issue\nis the evaluation of post-depositional layer changes, for which the chemical\nimages provide rich information. Accordingly, the time is ripe to begin an\nintensified exchange among the two scientific communities of computer vision\nand ice core science. The collaborative building of a new framework for\ninvestigating high-resolution chemical images with automated image analysis\ntechniques will also benefit the already wide-spread application of LA-ICP-MS\nchemical imaging in the geosciences.",
    "published": "2021-04-09T15:27:44Z",
    "pdf_url": "http://arxiv.org/pdf/2104.04430v1",
    "categories": [
      "cs.CV",
      "physics.geo-ph"
    ]
  },
  {
    "arxiv_id": "2207.00291v2",
    "title": "A Comparative Study of Graph Matching Algorithms in Computer Vision",
    "authors": [
      "Stefan Haller",
      "Lorenz Feineis",
      "Lisa Hutschenreiter",
      "Florian Bernard",
      "Carsten Rother",
      "Dagmar Kainmüller",
      "Paul Swoboda",
      "Bogdan Savchynskyy"
    ],
    "abstract": "The graph matching optimization problem is an essential component for many\ntasks in computer vision, such as bringing two deformable objects in\ncorrespondence. Naturally, a wide range of applicable algorithms have been\nproposed in the last decades. Since a common standard benchmark has not been\ndeveloped, their performance claims are often hard to verify as evaluation on\ndiffering problem instances and criteria make the results incomparable. To\naddress these shortcomings, we present a comparative study of graph matching\nalgorithms. We create a uniform benchmark where we collect and categorize a\nlarge set of existing and publicly available computer vision graph matching\nproblems in a common format. At the same time we collect and categorize the\nmost popular open-source implementations of graph matching algorithms. Their\nperformance is evaluated in a way that is in line with the best practices for\ncomparing optimization algorithms. The study is designed to be reproducible and\nextensible to serve as a valuable resource in the future.\n  Our study provides three notable insights:\n  1.) popular problem instances are exactly solvable in substantially less than\n1 second and, therefore, are insufficient for future empirical evaluations;\n  2.) the most popular baseline methods are highly inferior to the best\navailable methods;\n  3.) despite the NP-hardness of the problem, instances coming from vision\napplications are often solvable in a few seconds even for graphs with more than\n500 vertices.",
    "published": "2022-07-01T09:37:34Z",
    "pdf_url": "http://arxiv.org/pdf/2207.00291v2",
    "categories": [
      "cs.CV",
      "math.OC"
    ]
  },
  {
    "arxiv_id": "1904.08298v1",
    "title": "Events-to-Video: Bringing Modern Computer Vision to Event Cameras",
    "authors": [
      "Henri Rebecq",
      "René Ranftl",
      "Vladlen Koltun",
      "Davide Scaramuzza"
    ],
    "abstract": "Event cameras are novel sensors that report brightness changes in the form of\nasynchronous \"events\" instead of intensity frames. They have significant\nadvantages over conventional cameras: high temporal resolution, high dynamic\nrange, and no motion blur. Since the output of event cameras is fundamentally\ndifferent from conventional cameras, it is commonly accepted that they require\nthe development of specialized algorithms to accommodate the particular nature\nof events. In this work, we take a different view and propose to apply\nexisting, mature computer vision techniques to videos reconstructed from event\ndata. We propose a novel recurrent network to reconstruct videos from a stream\nof events, and train it on a large amount of simulated event data. Our\nexperiments show that our approach surpasses state-of-the-art reconstruction\nmethods by a large margin (> 20%) in terms of image quality. We further apply\noff-the-shelf computer vision algorithms to videos reconstructed from event\ndata on tasks such as object classification and visual-inertial odometry, and\nshow that this strategy consistently outperforms algorithms that were\nspecifically designed for event data. We believe that our approach opens the\ndoor to bringing the outstanding properties of event cameras to an entirely new\nrange of tasks. A video of the experiments is available at\nhttps://youtu.be/IdYrC4cUO0I",
    "published": "2019-04-17T14:54:49Z",
    "pdf_url": "http://arxiv.org/pdf/1904.08298v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1906.01620v3",
    "title": "Evaluating Scalable Bayesian Deep Learning Methods for Robust Computer\n  Vision",
    "authors": [
      "Fredrik K. Gustafsson",
      "Martin Danelljan",
      "Thomas B. Schön"
    ],
    "abstract": "While deep neural networks have become the go-to approach in computer vision,\nthe vast majority of these models fail to properly capture the uncertainty\ninherent in their predictions. Estimating this predictive uncertainty can be\ncrucial, for example in automotive applications. In Bayesian deep learning,\npredictive uncertainty is commonly decomposed into the distinct types of\naleatoric and epistemic uncertainty. The former can be estimated by letting a\nneural network output the parameters of a certain probability distribution.\nEpistemic uncertainty estimation is a more challenging problem, and while\ndifferent scalable methods recently have emerged, no extensive comparison has\nbeen performed in a real-world setting. We therefore accept this task and\npropose a comprehensive evaluation framework for scalable epistemic uncertainty\nestimation methods in deep learning. Our proposed framework is specifically\ndesigned to test the robustness required in real-world computer vision\napplications. We also apply this framework to provide the first properly\nextensive and conclusive comparison of the two current state-of-the-art\nscalable methods: ensembling and MC-dropout. Our comparison demonstrates that\nensembling consistently provides more reliable and practically useful\nuncertainty estimates. Code is available at\nhttps://github.com/fregu856/evaluating_bdl.",
    "published": "2019-06-04T17:54:20Z",
    "pdf_url": "http://arxiv.org/pdf/1906.01620v3",
    "categories": [
      "cs.LG",
      "cs.CV",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2301.13514v1",
    "title": "Fourier Sensitivity and Regularization of Computer Vision Models",
    "authors": [
      "Kiran Krishnamachari",
      "See-Kiong Ng",
      "Chuan-Sheng Foo"
    ],
    "abstract": "Recent work has empirically shown that deep neural networks latch on to the\nFourier statistics of training data and show increased sensitivity to\nFourier-basis directions in the input. Understanding and modifying this\nFourier-sensitivity of computer vision models may help improve their\nrobustness. Hence, in this paper we study the frequency sensitivity\ncharacteristics of deep neural networks using a principled approach. We first\npropose a basis trick, proving that unitary transformations of the\ninput-gradient of a function can be used to compute its gradient in the basis\ninduced by the transformation. Using this result, we propose a general measure\nof any differentiable model's Fourier-sensitivity using the unitary\nFourier-transform of its input-gradient. When applied to deep neural networks,\nwe find that computer vision models are consistently sensitive to particular\nfrequencies dependent on the dataset, training method and architecture. Based\non this measure, we further propose a Fourier-regularization framework to\nmodify the Fourier-sensitivities and frequency bias of models. Using our\nproposed regularizer-family, we demonstrate that deep neural networks obtain\nimproved classification accuracy on robustness evaluations.",
    "published": "2023-01-31T10:05:35Z",
    "pdf_url": "http://arxiv.org/pdf/2301.13514v1",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2312.01771v1",
    "title": "IMProv: Inpainting-based Multimodal Prompting for Computer Vision Tasks",
    "authors": [
      "Jiarui Xu",
      "Yossi Gandelsman",
      "Amir Bar",
      "Jianwei Yang",
      "Jianfeng Gao",
      "Trevor Darrell",
      "Xiaolong Wang"
    ],
    "abstract": "In-context learning allows adapting a model to new tasks given a task\ndescription at test time. In this paper, we present IMProv - a generative model\nthat is able to in-context learn visual tasks from multimodal prompts. Given a\ntextual description of a visual task (e.g. \"Left: input image, Right:\nforeground segmentation\"), a few input-output visual examples, or both, the\nmodel in-context learns to solve it for a new test input. We train a masked\ngenerative transformer on a new dataset of figures from computer vision papers\nand their associated captions, together with a captioned large-scale image-text\ndataset. During inference time, we prompt the model with text and/or image task\nexample(s) and have the model inpaint the corresponding output. We show that\ntraining our model with text conditioning and scaling the dataset size improves\nin-context learning for computer vision tasks by over +10\\% AP for Foreground\nSegmentation, over +5\\% gains in AP for Single Object Detection, and almost\n20\\% lower LPIPS in Colorization. Our empirical results suggest that vision and\nlanguage prompts are complementary and it is advantageous to use both to\nachieve better in-context learning performance. Project page is available at\nhttps://jerryxu.net/IMProv .",
    "published": "2023-12-04T09:48:29Z",
    "pdf_url": "http://arxiv.org/pdf/2312.01771v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2402.09781v1",
    "title": "A Comprehensive Review on Computer Vision Analysis of Aerial Data",
    "authors": [
      "Vivek Tetarwal",
      "Sandeep Kumar"
    ],
    "abstract": "With the emergence of new technologies in the field of airborne platforms and\nimaging sensors, aerial data analysis is becoming very popular, capitalizing on\nits advantages over land data. This paper presents a comprehensive review of\nthe computer vision tasks within the domain of aerial data analysis. While\naddressing fundamental aspects such as object detection and tracking, the\nprimary focus is on pivotal tasks like change detection, object segmentation,\nand scene-level analysis. The paper provides the comparison of various hyper\nparameters employed across diverse architectures and tasks. A substantial\nsection is dedicated to an in-depth discussion on libraries, their\ncategorization, and their relevance to different domain expertise. The paper\nencompasses aerial datasets, the architectural nuances adopted, and the\nevaluation metrics associated with all the tasks in aerial data analysis.\nApplications of computer vision tasks in aerial data across different domains\nare explored, with case studies providing further insights. The paper\nthoroughly examines the challenges inherent in aerial data analysis, offering\npractical solutions. Additionally, unresolved issues of significance are\nidentified, paving the way for future research directions in the field of\naerial data analysis.",
    "published": "2024-02-15T08:10:09Z",
    "pdf_url": "http://arxiv.org/pdf/2402.09781v1",
    "categories": [
      "cs.CV",
      "cs.IT",
      "math.IT"
    ]
  },
  {
    "arxiv_id": "2407.03755v2",
    "title": "A Computer Vision Approach to Estimate the Localized Sea State",
    "authors": [
      "Aleksandar Vorkapic",
      "Miran Pobar",
      "Marina Ivasic-Kos"
    ],
    "abstract": "This research presents a novel application of computer vision (CV) and deep\nlearning methods for real-time sea state recognition, aiming to contribute to\nimproving the operational safety and energy efficiency of seagoing vessels, key\nfactors in meeting the legislative carbon reduction targets. Our work focuses\non utilizing sea images in operational envelopes captured by a single\nstationary camera mounted on the ship bridge. The collected images are used to\ntrain a deep learning model to automatically recognize the state of the sea\nbased on the Beaufort scale. To recognize the sea state, we used 4\nstate-of-the-art deep neural networks with different characteristics that\nproved useful in various computer vision tasks: Resnet-101, NASNet,\nMobileNet_v2, and Transformer ViT-b32. Furthermore, we have defined a unique\nlarge-scale dataset, collected over a broad range of sea conditions from an\nocean-going vessel prepared for machine learning. We used the transfer learning\napproach to fine-tune the models on our dataset. The obtained results\ndemonstrate the potential for this approach to complement traditional methods,\nparticularly where in-situ measurements are unfeasible or interpolated weather\nbuoy data is insufficiently accurate. This study sets the groundwork for\nfurther development of sea state classification models to address recognized\ngaps in maritime research and enable safer and more efficient maritime\noperations.",
    "published": "2024-07-04T09:07:25Z",
    "pdf_url": "http://arxiv.org/pdf/2407.03755v2",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2408.08250v1",
    "title": "Computer Vision Model Compression Techniques for Embedded Systems: A\n  Survey",
    "authors": [
      "Alexandre Lopes",
      "Fernando Pereira dos Santos",
      "Diulhio de Oliveira",
      "Mauricio Schiezaro",
      "Helio Pedrini"
    ],
    "abstract": "Deep neural networks have consistently represented the state of the art in\nmost computer vision problems. In these scenarios, larger and more complex\nmodels have demonstrated superior performance to smaller architectures,\nespecially when trained with plenty of representative data. With the recent\nadoption of Vision Transformer (ViT) based architectures and advanced\nConvolutional Neural Networks (CNNs), the total number of parameters of leading\nbackbone architectures increased from 62M parameters in 2012 with AlexNet to 7B\nparameters in 2024 with AIM-7B. Consequently, deploying such deep architectures\nfaces challenges in environments with processing and runtime constraints,\nparticularly in embedded systems. This paper covers the main model compression\ntechniques applied for computer vision tasks, enabling modern models to be used\nin embedded systems. We present the characteristics of compression subareas,\ncompare different approaches, and discuss how to choose the best technique and\nexpected variations when analyzing it on various embedded devices. We also\nshare codes to assist researchers and new practitioners in overcoming initial\nimplementation challenges for each subarea and present trends for Model\nCompression. Case studies for compression models are available at\n\\href{https://github.com/venturusbr/cv-model-compression}{https://github.com/venturusbr/cv-model-compression}.",
    "published": "2024-08-15T16:41:55Z",
    "pdf_url": "http://arxiv.org/pdf/2408.08250v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2411.01001v1",
    "title": "Automated Assessment of Residual Plots with Computer Vision Models",
    "authors": [
      "Weihao Li",
      "Dianne Cook",
      "Emi Tanaka",
      "Susan VanderPlas",
      "Klaus Ackermann"
    ],
    "abstract": "Plotting the residuals is a recommended procedure to diagnose deviations from\nlinear model assumptions, such as non-linearity, heteroscedasticity, and\nnon-normality. The presence of structure in residual plots can be tested using\nthe lineup protocol to do visual inference. There are a variety of conventional\nresidual tests, but the lineup protocol, used as a statistical test, performs\nbetter for diagnostic purposes because it is less sensitive and applies more\nbroadly to different types of departures. However, the lineup protocol relies\non human judgment which limits its scalability. This work presents a solution\nby providing a computer vision model to automate the assessment of residual\nplots. It is trained to predict a distance measure that quantifies the\ndisparity between the residual distribution of a fitted classical normal linear\nregression model and the reference distribution, based on Kullback-Leibler\ndivergence. From extensive simulation studies, the computer vision model\nexhibits lower sensitivity than conventional tests but higher sensitivity than\nhuman visual tests. It is slightly less effective on non-linearity patterns.\nSeveral examples from classical papers and contemporary data illustrate the new\nprocedures, highlighting its usefulness in automating the diagnostic process\nand supplementing existing methods.",
    "published": "2024-11-01T19:51:44Z",
    "pdf_url": "http://arxiv.org/pdf/2411.01001v1",
    "categories": [
      "stat.ML",
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2501.15119v2",
    "title": "Leveraging Motion Estimation for Efficient Bayer-Domain Computer Vision",
    "authors": [
      "Haichao Wang",
      "Xinyue Xi",
      "Jiangtao Wen",
      "Yuxing Han"
    ],
    "abstract": "Existing computer vision processing pipeline acquires visual information\nusing an image sensor that captures pixel information in the Bayer pattern. The\nraw sensor data are then processed using an image signal processor (ISP) that\nfirst converts Bayer pixel data to RGB on a pixel by pixel basis, followed by\nvideo convolutional network (VCN) processing on a frame by frame basis. Both\nISP and VCN are computationally expensive with high power consumption and\nlatency. In this paper, we propose a novel framework that eliminates the ISP\nand leverages motion estimation to accelerate video vision tasks directly in\nthe Bayer domain. We introduce Motion Estimation-based Video Convolution\n(MEVC), which integrates sliding-window motion estimation into each\nconvolutional layer, enabling prediction and residual-based refinement that\nreduces redundant computations across frames. This design bridges the\nstructural gap between block-based motion estimation and spatial convolution,\nenabling accurate, low-cost processing. Our end-to-end pipeline supports raw\nBayer input and achieves over 70\\% reduction in FLOPs with minimal accuracy\ndegradation across video semantic segmentation, depth estimation, and object\ndetection benchmarks, using both synthetic Bayer-converted and real Bayer video\ndatasets. This framework generalizes across convolution-based models and marks\nthe first effective reuse of motion estimation for accelerating video computer\nvision directly from raw sensor data.",
    "published": "2025-01-25T08:09:54Z",
    "pdf_url": "http://arxiv.org/pdf/2501.15119v2",
    "categories": [
      "cs.CV",
      "eess.IV"
    ]
  },
  {
    "arxiv_id": "2504.04242v2",
    "title": "Task-based Loss Functions in Computer Vision: A Comprehensive Review",
    "authors": [
      "Omar Elharrouss",
      "Yasir Mahmood",
      "Yassine Bechqito",
      "Mohamed Adel Serhani",
      "Elarbi Badidi",
      "Jamal Riffi",
      "Hamid Tairi"
    ],
    "abstract": "Loss functions are at the heart of deep learning, shaping how models learn\nand perform across diverse tasks. They are used to quantify the difference\nbetween predicted outputs and ground truth labels, guiding the optimization\nprocess to minimize errors. Selecting the right loss function is critical, as\nit directly impacts model convergence, generalization, and overall performance\nacross various applications, from computer vision to time series forecasting.\nThis paper presents a comprehensive review of loss functions, covering\nfundamental metrics like Mean Squared Error and Cross-Entropy to advanced\nfunctions such as Adversarial and Diffusion losses. We explore their\nmathematical foundations, impact on model training, and strategic selection for\nvarious applications, including computer vision (Discriminative and\ngenerative), tabular data prediction, and time series forecasting. For each of\nthese categories, we discuss the most used loss functions in the recent\nadvancements of deep learning techniques. Also, this review explore the\nhistorical evolution, computational efficiency, and ongoing challenges in loss\nfunction design, underlining the need for more adaptive and robust solutions.\nEmphasis is placed on complex scenarios involving multi-modal data, class\nimbalances, and real-world constraints. Finally, we identify key future\ndirections, advocating for loss functions that enhance interpretability,\nscalability, and generalization, leading to more effective and resilient deep\nlearning models.",
    "published": "2025-04-05T18:07:20Z",
    "pdf_url": "http://arxiv.org/pdf/2504.04242v2",
    "categories": [
      "cs.LG",
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2506.19939v1",
    "title": "Computer Vision based Automated Quantification of Agricultural Sprayers\n  Boom Displacement",
    "authors": [
      "Aryan Singh Dalal",
      "Sidharth Rai",
      "Rahul Singh",
      "Treman Singh Kaloya",
      "Rahul Harsha Cheppally",
      "Ajay Sharda"
    ],
    "abstract": "Application rate errors when using self-propelled agricultural sprayers for\nagricultural production remain a concern. Among other factors, spray boom\ninstability is one of the major contributors to application errors. Spray\nbooms' width of 38m, combined with 30 kph driving speeds, varying terrain, and\nmachine dynamics when maneuvering complex field boundaries, make controls of\nthese booms very complex. However, there is no quantitative knowledge on the\nextent of boom movement to systematically develop a solution that might include\nboom designs and responsive boom control systems. Therefore, this study was\nconducted to develop an automated computer vision system to quantify the boom\nmovement of various agricultural sprayers. A computer vision system was\ndeveloped to track a target on the edge of the sprayer boom in real time. YOLO\nV7, V8, and V11 neural network models were trained to track the boom's\nmovements in field operations to quantify effective displacement in the\nvertical and transverse directions. An inclinometer sensor was mounted on the\nboom to capture boom angles and validate the neural network model output. The\nresults showed that the model could detect the target with more than 90 percent\naccuracy, and distance estimates of the target on the boom were within 0.026 m\nof the inclinometer sensor data. This system can quantify the boom movement on\nthe current sprayer and potentially on any other sprayer with minor\nmodifications. The data can be used to make design improvements to make sprayer\nbooms more stable and achieve greater application accuracy.",
    "published": "2025-06-24T18:30:18Z",
    "pdf_url": "http://arxiv.org/pdf/2506.19939v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2508.12802v1",
    "title": "Morphological classification of eclipsing binary stars using computer\n  vision methods",
    "authors": [
      "Štefan Parimucha",
      "Maksim Gabdeev",
      "Yanna Markus",
      "Martin Vaňko",
      "Pavol Gajdoš"
    ],
    "abstract": "We present an application of computer vision methods to classify the light\ncurves of eclipsing binaries (EB). We have used pre-trained models based on\nconvolutional neural networks ($\\textit{ResNet50}$) and vision transformers\n($\\textit{vit\\_base\\_patch16\\_224}$), which were fine-tuned on images created\nfrom synthetic datasets. To improve model generalisation and reduce\noverfitting, we developed a novel image representation by transforming\nphase-folded light curves into polar coordinates combined with hexbin\nvisualisation. Our hierarchical approach in the first stage classifies systems\ninto detached and overcontact types, and in the second stage identifies the\npresence or absence of spots. The binary classification models achieved high\naccuracy ($>96\\%$) on validation data across multiple passbands (Gaia~$G$, $I$,\nand $TESS$) and demonstrated strong performance ($>94\\%$, up to $100\\%$ for\n$TESS$) when tested on extensive observational data from the OGLE, DEBCat, and\nWUMaCat catalogues. While the primary binary classification was highly\nsuccessful, the secondary task of automated spot detection performed poorly,\nrevealing a significant limitation of our models for identifying subtle\nphotometric features. This study highlights the potential of computer vision\nfor EB morphological classification in large-scale surveys, but underscores the\nneed for further research into robust, automated spot detection.",
    "published": "2025-08-18T10:29:19Z",
    "pdf_url": "http://arxiv.org/pdf/2508.12802v1",
    "categories": [
      "cs.CV",
      "astro-ph.IM",
      "astro-ph.SR",
      "I.5.1; J.2"
    ]
  },
  {
    "arxiv_id": "2508.17975v1",
    "title": "Enhanced Drift-Aware Computer Vision Architecture for Autonomous Driving",
    "authors": [
      "Md Shahi Amran Hossain",
      "Abu Shad Ahammed",
      "Sayeri Mukherjee",
      "Roman Obermaisser"
    ],
    "abstract": "The use of computer vision in automotive is a trending research in which\nsafety and security are a primary concern. In particular, for autonomous\ndriving, preventing road accidents requires highly accurate object detection\nunder diverse conditions. To address this issue, recently the International\nOrganization for Standardization (ISO) released the 8800 norm, providing\nstructured frameworks for managing associated AI relevant risks. However,\nchallenging scenarios such as adverse weather or low lighting often introduce\ndata drift, leading to degraded model performance and potential safety\nviolations. In this work, we present a novel hybrid computer vision\narchitecture trained with thousands of synthetic image data from the road\nenvironment to improve robustness in unseen drifted environments. Our dual mode\nframework utilized YOLO version 8 for swift detection and incorporated a\nfive-layer CNN for verification. The system functioned in sequence and improved\nthe detection accuracy by more than 90\\% when tested with drift-augmented road\nimages. The focus was to demonstrate how such a hybrid model can provide better\nroad safety when working together in a hybrid structure.",
    "published": "2025-08-25T12:43:29Z",
    "pdf_url": "http://arxiv.org/pdf/2508.17975v1",
    "categories": [
      "cs.CV",
      "math.LO"
    ]
  },
  {
    "arxiv_id": "2509.07504v1",
    "title": "Backdoor Attacks and Defenses in Computer Vision Domain: A Survey",
    "authors": [
      "Bilal Hussain Abbasi",
      "Yanjun Zhang",
      "Leo Zhang",
      "Shang Gao"
    ],
    "abstract": "Backdoor (trojan) attacks embed hidden, controllable behaviors into\nmachine-learning models so that models behave normally on benign inputs but\nproduce attacker-chosen outputs when a trigger is present. This survey reviews\nthe rapidly growing literature on backdoor attacks and defenses in the\ncomputer-vision domain. We introduce a multi-dimensional taxonomy that\norganizes attacks and defenses by injection stage (dataset poisoning,\nmodel/parameter modification, inference-time injection), trigger type (patch,\nblended/frequency, semantic, transformation), labeling strategy (dirty-label\nvs. clean-label / feature-collision), representation stage (instance-specific,\nmanifold/class-level, neuron/parameter hijacking, distributed encodings), and\ntarget task (classification, detection, segmentation, video, multimodal). For\neach axis we summarize representative methods, highlight evaluation practices,\nand discuss where defenses succeed or fail. For example, many classical\nsanitization and reverse-engineering tools are effective against reusable patch\nattacks but struggle with input-aware, sample-specific, or parameter-space\nbackdoors and with transfer via compromised pre-trained encoders or hardware\nbit-flips. We synthesize trends, identify persistent gaps (supply-chain and\nhardware threats, certifiable defenses, cross-task benchmarks), and propose\npractical guidelines for threat-aware evaluation and layered defenses. This\nsurvey aims to orient researchers and practitioners to the current threat\nlandscape and pressing research directions in secure computer vision.",
    "published": "2025-09-09T08:38:05Z",
    "pdf_url": "http://arxiv.org/pdf/2509.07504v1",
    "categories": [
      "cs.CR"
    ]
  },
  {
    "arxiv_id": "1407.5675v3",
    "title": "Jet-Images: Computer Vision Inspired Techniques for Jet Tagging",
    "authors": [
      "Josh Cogan",
      "Michael Kagan",
      "Emanuel Strauss",
      "Ariel Schwartzman"
    ],
    "abstract": "We introduce a novel approach to jet tagging and classification through the\nuse of techniques inspired by computer vision. Drawing parallels to the problem\nof facial recognition in images, we define a jet-image using calorimeter towers\nas the elements of the image and establish jet-image preprocessing methods. For\nthe jet-image processing step, we develop a discriminant for classifying the\njet-images derived using Fisher discriminant analysis. The effectiveness of the\ntechnique is shown within the context of identifying boosted hadronic W boson\ndecays with respect to a background of quark- and gluon- initiated jets. Using\nMonte Carlo simulation, we demonstrate that the performance of this technique\nintroduces additional discriminating power over other substructure approaches,\nand gives significant insight into the internal structure of jets.",
    "published": "2014-07-21T22:07:37Z",
    "pdf_url": "http://arxiv.org/pdf/1407.5675v3",
    "categories": [
      "hep-ph",
      "hep-ex",
      "physics.data-an"
    ]
  },
  {
    "arxiv_id": "1611.09942v2",
    "title": "Photographic home styles in Congress: a computer vision approach",
    "authors": [
      "L. Jason Anastasopoulos",
      "Dhruvil Badani",
      "Crystal Lee",
      "Shiry Ginosar",
      "Jake Williams"
    ],
    "abstract": "While members of Congress now routinely communicate with constituents using\nimages on a variety of internet platforms, little is known about how images are\nused as a means of strategic political communication. This is due primarily to\ncomputational limitations which have prevented large-scale, systematic analyses\nof image features. New developments in computer vision, however, are bringing\nthe systematic study of images within reach. Here, we develop a framework for\nunderstanding visual political communication by extending Fenno's analysis of\nhome style (Fenno 1978) to images and introduce \"photographic\" home styles.\nUsing approximately 192,000 photographs collected from MCs Facebook profiles,\nwe build machine learning software with convolutional neural networks and\nconduct an image manipulation experiment to explore how the race of people that\nMCs pose with shape photographic home styles. We find evidence that electoral\npressures shape photographic home styles and demonstrate that Democratic and\nRepublican members of Congress use images in very different ways.",
    "published": "2016-11-29T23:41:00Z",
    "pdf_url": "http://arxiv.org/pdf/1611.09942v2",
    "categories": [
      "cs.SI",
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1708.05869v2",
    "title": "Sim4CV: A Photo-Realistic Simulator for Computer Vision Applications",
    "authors": [
      "Matthias Müller",
      "Vincent Casser",
      "Jean Lahoud",
      "Neil Smith",
      "Bernard Ghanem"
    ],
    "abstract": "We present a photo-realistic training and evaluation simulator (Sim4CV) with\nextensive applications across various fields of computer vision. Built on top\nof the Unreal Engine, the simulator integrates full featured physics based\ncars, unmanned aerial vehicles (UAVs), and animated human actors in diverse\nurban and suburban 3D environments. We demonstrate the versatility of the\nsimulator with two case studies: autonomous UAV-based tracking of moving\nobjects and autonomous driving using supervised learning. The simulator fully\nintegrates both several state-of-the-art tracking algorithms with a benchmark\nevaluation tool and a deep neural network (DNN) architecture for training\nvehicles to drive autonomously. It generates synthetic photo-realistic datasets\nwith automatic ground truth annotations to easily extend existing real-world\ndatasets and provides extensive synthetic data variety through its ability to\nreconfigure synthetic worlds on the fly using an automatic world generation\ntool. The supplementary video can be viewed a https://youtu.be/SqAxzsQ7qUU",
    "published": "2017-08-19T16:09:06Z",
    "pdf_url": "http://arxiv.org/pdf/1708.05869v2",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1803.04493v2",
    "title": "Particle Identification In Camera Image Sensors Using Computer Vision",
    "authors": [
      "Miles Winter",
      "James Bourbeau",
      "Silvia Bravo",
      "Felipe Campos",
      "Matthew Meehan",
      "Jeffrey Peacock",
      "Tyler Ruggles",
      "Cassidy Schneider",
      "Ariel Levi Simons",
      "Justin Vandenbroucke"
    ],
    "abstract": "We present a deep learning, computer vision algorithm constructed for the\npurposes of identifying and classifying charged particles in camera image\nsensors. We apply our algorithm to data collected by the Distributed Electronic\nCosmic-ray Observatory (DECO), a global network of smartphones that monitors\ncamera image sensors for the signatures of cosmic rays and other energetic\nparticles, such as those produced by radioactive decays. The algorithm, whose\ncore component is a convolutional neural network, achieves classification\nperformance comparable to human quality across four distinct DECO event\ntopologies. We apply our model to the entire DECO data set and determine a\nselection that achieves $\\ge90\\%$ purity for all event types. In particular, we\nestimate a purity of $95\\%$ when applied to cosmic-ray muons. The automated\nclassification is run on the public DECO data set in real time in order to\nprovide classified particle interaction images to users of the app and other\ninterested members of the public.",
    "published": "2018-03-12T19:49:18Z",
    "pdf_url": "http://arxiv.org/pdf/1803.04493v2",
    "categories": [
      "astro-ph.IM",
      "physics.data-an"
    ]
  },
  {
    "arxiv_id": "1803.06312v2",
    "title": "EVA$^2$: Exploiting Temporal Redundancy in Live Computer Vision",
    "authors": [
      "Mark Buckler",
      "Philip Bedoukian",
      "Suren Jayasuriya",
      "Adrian Sampson"
    ],
    "abstract": "Hardware support for deep convolutional neural networks (CNNs) is critical to\nadvanced computer vision in mobile and embedded devices. Current designs,\nhowever, accelerate generic CNNs; they do not exploit the unique\ncharacteristics of real-time vision. We propose to use the temporal redundancy\nin natural video to avoid unnecessary computation on most frames. A new\nalgorithm, activation motion compensation, detects changes in the visual input\nand incrementally updates a previously-computed output. The technique takes\ninspiration from video compression and applies well-known motion estimation\ntechniques to adapt to visual changes. We use an adaptive key frame rate to\ncontrol the trade-off between efficiency and vision quality as the input\nchanges. We implement the technique in hardware as an extension to existing\nstate-of-the-art CNN accelerator designs. The new unit reduces the average\nenergy per frame by 54.2%, 61.7%, and 87.6% for three CNNs with less than 1%\nloss in vision accuracy.",
    "published": "2018-03-16T16:59:47Z",
    "pdf_url": "http://arxiv.org/pdf/1803.06312v2",
    "categories": [
      "cs.CV",
      "eess.IV"
    ]
  },
  {
    "arxiv_id": "1804.03928v1",
    "title": "Deep Learning For Computer Vision Tasks: A review",
    "authors": [
      "Rajat Kumar Sinha",
      "Ruchi Pandey",
      "Rohan Pattnaik"
    ],
    "abstract": "Deep learning has recently become one of the most popular sub-fields of\nmachine learning owing to its distributed data representation with multiple\nlevels of abstraction. A diverse range of deep learning algorithms are being\nemployed to solve conventional artificial intelligence problems. This paper\ngives an overview of some of the most widely used deep learning algorithms\napplied in the field of computer vision. It first inspects the various\napproaches of deep learning algorithms, followed by a description of their\napplications in image classification, object identification, image extraction\nand semantic segmentation in the presence of noise. The paper concludes with\nthe discussion of the future scope and challenges for construction and training\nof deep neural networks.",
    "published": "2018-04-11T11:13:35Z",
    "pdf_url": "http://arxiv.org/pdf/1804.03928v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1811.10847v1",
    "title": "Algae Detection Using Computer Vision and Deep Learning",
    "authors": [
      "Arabinda Samantaray",
      "Baijian Yang",
      "J. Eric Dietz",
      "Byung-Cheol Min"
    ],
    "abstract": "A disconcerting ramification of water pollution caused by burgeoning\npopulations, rapid industrialization and modernization of agriculture, has been\nthe exponential increase in the incidence of algal growth across the globe.\nHarmful algal blooms (HABs) have devastated fisheries, contaminated drinking\nwater and killed livestock, resulting in economic losses to the tune of\nmillions of dollars. Therefore, it is important to constantly monitor water\nbodies and identify any algae build-up so that prompt action against its\naccumulation can be taken and the harmful consequences can be avoided. In this\npaper, we propose a computer vision system based on deep learning for algae\nmonitoring. The proposed system is fast, accurate and cheap, and it can be\ninstalled on any robotic platforms such as USVs and UAVs for autonomous algae\nmonitoring. The experimental results demonstrate that the proposed system can\ndetect algae in distinct environments regardless of the underlying hardware\nwith high accuracy and in real time.",
    "published": "2018-11-27T07:31:26Z",
    "pdf_url": "http://arxiv.org/pdf/1811.10847v1",
    "categories": [
      "cs.CV",
      "cs.LG",
      "cs.RO"
    ]
  },
  {
    "arxiv_id": "2101.09744v3",
    "title": "Classic versus deep learning approaches to address computer vision\n  challenges",
    "authors": [
      "Nati Ofir",
      "Jean-Christophe Nebel"
    ],
    "abstract": "Computer vision and image processing address many challenging applications.\nWhile the last decade has seen deep neural network architectures\nrevolutionizing those fields, early methods relied on 'classic', i.e.,\nnon-learned approaches. In this study, we explore the differences between\nclassic and deep learning (DL) algorithms to gain new insight regarding which\nis more suitable for a given application. The focus is on two challenging\nill-posed problems, namely faint edge detection and multispectral image\nregistration, studying recent state-of-the-art DL and classic solutions. While\nthose DL algorithms outperform classic methods in terms of accuracy and\ndevelopment time, they tend to have higher resource requirements and are unable\nto perform outside their training space. Moreover, classic algorithms are more\ntransparent, which facilitates their adoption for real-life applications. As\nboth classes of approaches have unique strengths and limitations, the choice of\na solution is clearly application dependent.",
    "published": "2021-01-24T16:27:23Z",
    "pdf_url": "http://arxiv.org/pdf/2101.09744v3",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2108.13465v2",
    "title": "Full-Cycle Energy Consumption Benchmark for Low-Carbon Computer Vision",
    "authors": [
      "Bo Li",
      "Xinyang Jiang",
      "Donglin Bai",
      "Yuge Zhang",
      "Ningxin Zheng",
      "Xuanyi Dong",
      "Lu Liu",
      "Yuqing Yang",
      "Dongsheng Li"
    ],
    "abstract": "The energy consumption of deep learning models is increasing at a\nbreathtaking rate, which raises concerns due to potential negative effects on\ncarbon neutrality in the context of global warming and climate change. With the\nprogress of efficient deep learning techniques, e.g., model compression,\nresearchers can obtain efficient models with fewer parameters and smaller\nlatency. However, most of the existing efficient deep learning methods do not\nexplicitly consider energy consumption as a key performance indicator.\nFurthermore, existing methods mostly focus on the inference costs of the\nresulting efficient models, but neglect the notable energy consumption\nthroughout the entire life cycle of the algorithm. In this paper, we present\nthe first large-scale energy consumption benchmark for efficient computer\nvision models, where a new metric is proposed to explicitly evaluate the\nfull-cycle energy consumption under different model usage intensity. The\nbenchmark can provide insights for low carbon emission when selecting efficient\ndeep learning algorithms in different model usage scenarios.",
    "published": "2021-08-30T18:22:36Z",
    "pdf_url": "http://arxiv.org/pdf/2108.13465v2",
    "categories": [
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2104.08885v1",
    "title": "A survey of image labelling for computer vision applications",
    "authors": [
      "Christoph Sager",
      "Christian Janiesch",
      "Patrick Zschech"
    ],
    "abstract": "Supervised machine learning methods for image analysis require large amounts\nof labelled training data to solve computer vision problems. The recent rise of\ndeep learning algorithms for recognising image content has led to the emergence\nof many ad-hoc labelling tools. With this survey, we capture and systematise\nthe commonalities as well as the distinctions between existing image labelling\nsoftware. We perform a structured literature review to compile the underlying\nconcepts and features of image labelling software such as annotation\nexpressiveness and degree of automation. We structure the manual labelling task\nby its organisation of work, user interface design options, and user support\ntechniques to derive a systematisation schema for this survey. Applying it to\navailable software and the body of literature, enabled us to uncover several\napplication archetypes and key domains such as image retrieval or instance\nidentification in healthcare or television.",
    "published": "2021-04-18T16:01:55Z",
    "pdf_url": "http://arxiv.org/pdf/2104.08885v1",
    "categories": [
      "cs.CV",
      "cs.HC",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2202.07242v1",
    "title": "Neural Architecture Search for Dense Prediction Tasks in Computer Vision",
    "authors": [
      "Thomas Elsken",
      "Arber Zela",
      "Jan Hendrik Metzen",
      "Benedikt Staffler",
      "Thomas Brox",
      "Abhinav Valada",
      "Frank Hutter"
    ],
    "abstract": "The success of deep learning in recent years has lead to a rising demand for\nneural network architecture engineering. As a consequence, neural architecture\nsearch (NAS), which aims at automatically designing neural network\narchitectures in a data-driven manner rather than manually, has evolved as a\npopular field of research. With the advent of weight sharing strategies across\narchitectures, NAS has become applicable to a much wider range of problems. In\nparticular, there are now many publications for dense prediction tasks in\ncomputer vision that require pixel-level predictions, such as semantic\nsegmentation or object detection. These tasks come with novel challenges, such\nas higher memory footprints due to high-resolution data, learning multi-scale\nrepresentations, longer training times, and more complex and larger neural\narchitectures. In this manuscript, we provide an overview of NAS for dense\nprediction tasks by elaborating on these novel challenges and surveying ways to\naddress them to ease future research and application of existing methods to\nnovel problems.",
    "published": "2022-02-15T08:06:50Z",
    "pdf_url": "http://arxiv.org/pdf/2202.07242v1",
    "categories": [
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2207.07428v1",
    "title": "Automatic detection of equiaxed dendrites using computer vision neural\n  networks",
    "authors": [
      "A. Viardin",
      "K. Noth",
      "M. Torabi Rad",
      "L. Sturz"
    ],
    "abstract": "Equaixed dendrites are frequently encountered in solidification. They\ntypically form in large numbers, which makes their detection, localization, and\ntracking practically impossible for a human eye. In this paper, we show how\nrecent progress in the field of machine learning can be leveraged to tackle\nthis problem and we present computer vision neural network to automatically\ndetect equiaxed dendrites. Our network is trained using phase-field simulation\nresults, and proper data augmentation allows to perform the detection task in\nsolidification conditions entirely different from those simulated for training.\nFor example, here we show how they can successfully detect dendrites of various\nsizes in a microgravity solidification experiment. We discuss challenges in\ntraining such a network along with our solutions for them, and compare the\nperformance of neural network with traditional methods of shapes detection.",
    "published": "2022-07-15T12:12:47Z",
    "pdf_url": "http://arxiv.org/pdf/2207.07428v1",
    "categories": [
      "cond-mat.mtrl-sci"
    ]
  },
  {
    "arxiv_id": "1907.10915v3",
    "title": "Self-supervised Domain Adaptation for Computer Vision Tasks",
    "authors": [
      "Jiaolong Xu",
      "Liang Xiao",
      "Antonio M. Lopez"
    ],
    "abstract": "Recent progress of self-supervised visual representation learning has\nachieved remarkable success on many challenging computer vision benchmarks.\nHowever, whether these techniques can be used for domain adaptation has not\nbeen explored. In this work, we propose a generic method for self-supervised\ndomain adaptation, using object recognition and semantic segmentation of urban\nscenes as use cases. Focusing on simple pretext/auxiliary tasks (e.g. image\nrotation prediction), we assess different learning strategies to improve domain\nadaptation effectiveness by self-supervision. Additionally, we propose two\ncomplementary strategies to further boost the domain adaptation accuracy on\nsemantic segmentation within our method, consisting of prediction layer\nalignment and batch normalization calibration. The experimental results show\nadaptation levels comparable to most studied domain adaptation methods, thus,\nbringing self-supervision as a new alternative for reaching domain adaptation.\nThe code is available at https://github.com/Jiaolong/self-supervised-da.",
    "published": "2019-07-25T09:20:29Z",
    "pdf_url": "http://arxiv.org/pdf/1907.10915v3",
    "categories": [
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1911.10037v1",
    "title": "Computer Vision-based Accident Detection in Traffic Surveillance",
    "authors": [
      "Earnest Paul Ijjina",
      "Dhananjai Chand",
      "Savyasachi Gupta",
      "Goutham K"
    ],
    "abstract": "Computer vision-based accident detection through video surveillance has\nbecome a beneficial but daunting task. In this paper, a neoteric framework for\ndetection of road accidents is proposed. The proposed framework capitalizes on\nMask R-CNN for accurate object detection followed by an efficient centroid\nbased object tracking algorithm for surveillance footage. The probability of an\naccident is determined based on speed and trajectory anomalies in a vehicle\nafter an overlap with other vehicles. The proposed framework provides a robust\nmethod to achieve a high Detection Rate and a low False Alarm Rate on general\nroad-traffic CCTV surveillance footage. This framework was evaluated on diverse\nconditions such as broad daylight, low visibility, rain, hail, and snow using\nthe proposed dataset. This framework was found effective and paves the way to\nthe development of general-purpose vehicular accident detection algorithms in\nreal-time.",
    "published": "2019-11-22T13:38:06Z",
    "pdf_url": "http://arxiv.org/pdf/1911.10037v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2010.13714v1",
    "title": "ActiveNet: A computer-vision based approach to determine lethargy",
    "authors": [
      "Aitik Gupta",
      "Aadit Agarwal"
    ],
    "abstract": "The outbreak of COVID-19 has forced everyone to stay indoors, fabricating a\nsignificant drop in physical activeness. Our work is constructed upon the idea\nto formulate a backbone mechanism, to detect levels of activeness in real-time,\nusing a single monocular image of a target person. The scope can be generalized\nunder many applications, be it in an interview, online classes, security\nsurveillance, et cetera. We propose a Computer Vision based multi-stage\napproach, wherein the pose of a person is first detected, encoded with a novel\napproach, and then assessed by a classical machine learning algorithm to\ndetermine the level of activeness. An alerting system is wrapped around the\napproach to provide a solution to inhibit lethargy by sending notification\nalerts to individuals involved.",
    "published": "2020-10-26T16:54:03Z",
    "pdf_url": "http://arxiv.org/pdf/2010.13714v1",
    "categories": [
      "cs.CV",
      "cs.HC",
      "I.2.10; I.4.7; I.4.8; I.4.9; I.5.4"
    ]
  },
  {
    "arxiv_id": "2305.09293v1",
    "title": "Out-of-Distribution Detection for Adaptive Computer Vision",
    "authors": [
      "Simon Kristoffersson Lind",
      "Rudolph Triebel",
      "Luigi Nardi",
      "Volker Krueger"
    ],
    "abstract": "It is well known that computer vision can be unreliable when faced with\npreviously unseen imaging conditions. This paper proposes a method to adapt\ncamera parameters according to a normalizing flow-based out-of-distibution\ndetector. A small-scale study is conducted which shows that adapting camera\nparameters according to this out-of-distibution detector leads to an average\nincrease of 3 to 4 percentage points in mAP, mAR and F1 performance metrics of\na YOLOv4 object detector. As a secondary result, this paper also shows that it\nis possible to train a normalizing flow model for out-of-distribution detection\non the COCO dataset, which is larger and more diverse than most benchmarks for\nout-of-distibution detectors.",
    "published": "2023-05-16T09:01:42Z",
    "pdf_url": "http://arxiv.org/pdf/2305.09293v1",
    "categories": [
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1901.00211v1",
    "title": "Mapping Areas using Computer Vision Algorithms and Drones",
    "authors": [
      "Bashar Alhafni",
      "Saulo Fernando Guedes",
      "Lays Cavalcante Ribeiro",
      "Juhyun Park",
      "Jeongkyu Lee"
    ],
    "abstract": "The goal of this paper is to implement a system, titled as Drone Map Creator\n(DMC) using Computer Vision techniques. DMC can process visual information from\nan HD camera in a drone and automatically create a map by stitching together\nvisual information captured by a drone. The proposed approach employs the\nSpeeded up robust features (SURF) method to detect the key points for each\nimage frame; then the corresponding points between the frames are identified by\nmaximizing the determinant of a Hessian matrix. Finally, two images are\nstitched together by using the identified points. Our results show that despite\nsome limitations from the external environment, we could have successfully\nstitched images together along video sequences.",
    "published": "2019-01-01T21:24:07Z",
    "pdf_url": "http://arxiv.org/pdf/1901.00211v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1902.11128v1",
    "title": "FixyNN: Efficient Hardware for Mobile Computer Vision via Transfer\n  Learning",
    "authors": [
      "Paul N. Whatmough",
      "Chuteng Zhou",
      "Patrick Hansen",
      "Shreyas Kolala Venkataramanaiah",
      "Jae-sun Seo",
      "Matthew Mattina"
    ],
    "abstract": "The computational demands of computer vision tasks based on state-of-the-art\nConvolutional Neural Network (CNN) image classification far exceed the energy\nbudgets of mobile devices. This paper proposes FixyNN, which consists of a\nfixed-weight feature extractor that generates ubiquitous CNN features, and a\nconventional programmable CNN accelerator which processes a dataset-specific\nCNN. Image classification models for FixyNN are trained end-to-end via transfer\nlearning, with the common feature extractor representing the transfered part,\nand the programmable part being learnt on the target dataset. Experimental\nresults demonstrate FixyNN hardware can achieve very high energy efficiencies\nup to 26.6 TOPS/W ($4.81 \\times$ better than iso-area programmable\naccelerator). Over a suite of six datasets we trained models via transfer\nlearning with an accuracy loss of $<1\\%$ resulting in up to 11.2 TOPS/W -\nnearly $2 \\times$ more efficient than a conventional programmable CNN\naccelerator of the same area.",
    "published": "2019-02-27T02:42:33Z",
    "pdf_url": "http://arxiv.org/pdf/1902.11128v1",
    "categories": [
      "cs.CV",
      "cs.AR",
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2003.03396v1",
    "title": "Scalable Uncertainty for Computer Vision with Functional Variational\n  Inference",
    "authors": [
      "Eduardo D C Carvalho",
      "Ronald Clark",
      "Andrea Nicastro",
      "Paul H J Kelly"
    ],
    "abstract": "As Deep Learning continues to yield successful applications in Computer\nVision, the ability to quantify all forms of uncertainty is a paramount\nrequirement for its safe and reliable deployment in the real-world. In this\nwork, we leverage the formulation of variational inference in function space,\nwhere we associate Gaussian Processes (GPs) to both Bayesian CNN priors and\nvariational family. Since GPs are fully determined by their mean and covariance\nfunctions, we are able to obtain predictive uncertainty estimates at the cost\nof a single forward pass through any chosen CNN architecture and for any\nsupervised learning task. By leveraging the structure of the induced covariance\nmatrices, we propose numerically efficient algorithms which enable fast\ntraining in the context of high-dimensional tasks such as depth estimation and\nsemantic segmentation. Additionally, we provide sufficient conditions for\nconstructing regression loss functions whose probabilistic counterparts are\ncompatible with aleatoric uncertainty quantification.",
    "published": "2020-03-06T19:09:42Z",
    "pdf_url": "http://arxiv.org/pdf/2003.03396v1",
    "categories": [
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2007.08364v1",
    "title": "A high fidelity synthetic face framework for computer vision",
    "authors": [
      "Tadas Baltrusaitis",
      "Erroll Wood",
      "Virginia Estellers",
      "Charlie Hewitt",
      "Sebastian Dziadzio",
      "Marek Kowalski",
      "Matthew Johnson",
      "Thomas J. Cashman",
      "Jamie Shotton"
    ],
    "abstract": "Analysis of faces is one of the core applications of computer vision, with\ntasks ranging from landmark alignment, head pose estimation, expression\nrecognition, and face recognition among others. However, building reliable\nmethods requires time-consuming data collection and often even more\ntime-consuming manual annotation, which can be unreliable. In our work we\npropose synthesizing such facial data, including ground truth annotations that\nwould be almost impossible to acquire through manual annotation at the\nconsistency and scale possible through use of synthetic data. We use a\nparametric face model together with hand crafted assets which enable us to\ngenerate training data with unprecedented quality and diversity (varying shape,\ntexture, expression, pose, lighting, and hair).",
    "published": "2020-07-16T14:40:28Z",
    "pdf_url": "http://arxiv.org/pdf/2007.08364v1",
    "categories": [
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2110.00791v1",
    "title": "Optimizing Neural Network for Computer Vision task in Edge Device",
    "authors": [
      "Ranjith M S",
      "S Parameshwara",
      "Pavan Yadav A",
      "Shriganesh Hegde"
    ],
    "abstract": "The field of computer vision has grown very rapidly in the past few years due\nto networks like convolution neural networks and their variants. The memory\nrequired to store the model and computational expense are very high for such a\nnetwork limiting it to deploy on the edge device. Many times, applications rely\non the cloud but that makes it hard for working in real-time due to round-trip\ndelays. We overcome these problems by deploying the neural network on the edge\ndevice itself. The computational expense for edge devices is reduced by\nreducing the floating-point precision of the parameters in the model. After\nthis the memory required for the model decreases and the speed of the\ncomputation increases where the performance of the model is least affected.\nThis makes an edge device to predict from the neural network all by itself.",
    "published": "2021-10-02T12:25:18Z",
    "pdf_url": "http://arxiv.org/pdf/2110.00791v1",
    "categories": [
      "cs.CV",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2110.02551v4",
    "title": "A Survey of Fish Tracking Techniques Based on Computer Vision",
    "authors": [
      "Weiran Li",
      "Zhenbo Li",
      "Fei Li",
      "Meng Yuan",
      "Chaojun Cen",
      "Yanyu Qi",
      "Qiannan Guo",
      "You Li"
    ],
    "abstract": "Fish tracking is a key technology for obtaining movement trajectories and\nidentifying abnormal behavior. However, it faces considerable challenges,\nincluding occlusion, multi-scale tracking, and fish deformation. Notably,\nextant reviews have focused more on behavioral analysis rather than providing a\ncomprehensive overview of computer vision-based fish tracking approaches. This\npaper presents a comprehensive review of the advancements of fish tracking\ntechnologies over the past seven years (2017-2023). It explores diverse fish\ntracking techniques with an emphasis on fundamental localization and tracking\nmethods. Auxiliary plugins commonly integrated into fish tracking systems, such\nas underwater image enhancement and re-identification, are also examined.\nAdditionally, this paper summarizes open-source datasets, evaluation metrics,\nchallenges, and applications in fish tracking research. Finally, a\ncomprehensive discussion offers insights and future directions for vision-based\nfish tracking techniques. We hope that our work could provide a partial\nreference in the development of fish tracking algorithms.",
    "published": "2021-10-06T07:46:35Z",
    "pdf_url": "http://arxiv.org/pdf/2110.02551v4",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2403.19758v2",
    "title": "Quantum Natural Language Processing",
    "authors": [
      "Dominic Widdows",
      "Willie Aboumrad",
      "Dohun Kim",
      "Sayonee Ray",
      "Jonathan Mei"
    ],
    "abstract": "Language processing is at the heart of current developments in artificial\nintelligence, and quantum computers are becoming available at the same time.\nThis has led to great interest in quantum natural language processing, and\nseveral early proposals and experiments.\n  This paper surveys the state of this area, showing how NLP-related techniques\nhave been used in quantum language processing. We examine the art of word\nembeddings and sequential models, proposing some avenues for future\ninvestigation and discussing the tradeoffs present in these directions. We also\nhighlight some recent methods to compute attention in transformer models, and\nperform grammatical parsing. We also introduce a new quantum design for the\nbasic task of text encoding (representing a string of characters in memory),\nwhich has not been addressed in detail before.\n  Quantum theory has contributed toward quantifying uncertainty and explaining\n\"What is intelligence?\" In this context, we argue that \"hallucinations\" in\nmodern artificial intelligence systems are a misunderstanding of the way facts\nare conceptualized: language can express many plausible hypotheses, of which\nonly a few become actual.",
    "published": "2024-03-28T18:15:07Z",
    "pdf_url": "http://arxiv.org/pdf/2403.19758v2",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2305.13246v1",
    "title": "Interactive Natural Language Processing",
    "authors": [
      "Zekun Wang",
      "Ge Zhang",
      "Kexin Yang",
      "Ning Shi",
      "Wangchunshu Zhou",
      "Shaochun Hao",
      "Guangzheng Xiong",
      "Yizhi Li",
      "Mong Yuan Sim",
      "Xiuying Chen",
      "Qingqing Zhu",
      "Zhenzhu Yang",
      "Adam Nik",
      "Qi Liu",
      "Chenghua Lin",
      "Shi Wang",
      "Ruibo Liu",
      "Wenhu Chen",
      "Ke Xu",
      "Dayiheng Liu",
      "Yike Guo",
      "Jie Fu"
    ],
    "abstract": "Interactive Natural Language Processing (iNLP) has emerged as a novel\nparadigm within the field of NLP, aimed at addressing limitations in existing\nframeworks while aligning with the ultimate goals of artificial intelligence.\nThis paradigm considers language models as agents capable of observing, acting,\nand receiving feedback iteratively from external entities. Specifically,\nlanguage models in this context can: (1) interact with humans for better\nunderstanding and addressing user needs, personalizing responses, aligning with\nhuman values, and improving the overall user experience; (2) interact with\nknowledge bases for enriching language representations with factual knowledge,\nenhancing the contextual relevance of responses, and dynamically leveraging\nexternal information to generate more accurate and informed responses; (3)\ninteract with models and tools for effectively decomposing and addressing\ncomplex tasks, leveraging specialized expertise for specific subtasks, and\nfostering the simulation of social behaviors; and (4) interact with\nenvironments for learning grounded representations of language, and effectively\ntackling embodied tasks such as reasoning, planning, and decision-making in\nresponse to environmental observations. This paper offers a comprehensive\nsurvey of iNLP, starting by proposing a unified definition and framework of the\nconcept. We then provide a systematic classification of iNLP, dissecting its\nvarious components, including interactive objects, interaction interfaces, and\ninteraction methods. We proceed to delve into the evaluation methodologies used\nin the field, explore its diverse applications, scrutinize its ethical and\nsafety issues, and discuss prospective research directions. This survey serves\nas an entry point for researchers who are interested in this rapidly evolving\narea and offers a broad view of the current landscape and future trajectory of\niNLP.",
    "published": "2023-05-22T17:18:29Z",
    "pdf_url": "http://arxiv.org/pdf/2305.13246v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2302.03490v1",
    "title": "Natural Language Processing for Policymaking",
    "authors": [
      "Zhijing Jin",
      "Rada Mihalcea"
    ],
    "abstract": "Language is the medium for many political activities, from campaigns to news\nreports. Natural language processing (NLP) uses computational tools to parse\ntext into key information that is needed for policymaking. In this chapter, we\nintroduce common methods of NLP, including text classification, topic modeling,\nevent extraction, and text scaling. We then overview how these methods can be\nused for policymaking through four major applications including data collection\nfor evidence-based policymaking, interpretation of political decisions, policy\ncommunication, and investigation of policy effects. Finally, we highlight some\npotential limitations and ethical concerns when using NLP for policymaking.\n  This text is from Chapter 7 (pages 141-162) of the Handbook of Computational\nSocial Science for Policy (2023). Open Access on Springer:\nhttps://doi.org/10.1007/978-3-031-16624-2",
    "published": "2023-02-07T14:34:39Z",
    "pdf_url": "http://arxiv.org/pdf/2302.03490v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2504.14530v1",
    "title": "Causality for Natural Language Processing",
    "authors": [
      "Zhijing Jin"
    ],
    "abstract": "Causal reasoning is a cornerstone of human intelligence and a critical\ncapability for artificial systems aiming to achieve advanced understanding and\ndecision-making. This thesis delves into various dimensions of causal reasoning\nand understanding in large language models (LLMs). It encompasses a series of\nstudies that explore the causal inference skills of LLMs, the mechanisms behind\ntheir performance, and the implications of causal and anticausal learning for\nnatural language processing (NLP) tasks. Additionally, it investigates the\napplication of causal reasoning in text-based computational social science,\nspecifically focusing on political decision-making and the evaluation of\nscientific impact through citations. Through novel datasets, benchmark tasks,\nand methodological frameworks, this work identifies key challenges and\nopportunities to improve the causal capabilities of LLMs, providing a\ncomprehensive foundation for future research in this evolving field.",
    "published": "2025-04-20T08:11:11Z",
    "pdf_url": "http://arxiv.org/pdf/2504.14530v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2102.03732v1",
    "title": "Representation Learning for Natural Language Processing",
    "authors": [
      "Zhiyuan Liu",
      "Yankai Lin",
      "Maosong Sun"
    ],
    "abstract": "This book aims to review and present the recent advances of distributed\nrepresentation learning for NLP, including why representation learning can\nimprove NLP, how representation learning takes part in various important topics\nof NLP, and what challenges are still not well addressed by distributed\nrepresentation.",
    "published": "2021-02-07T07:37:07Z",
    "pdf_url": "http://arxiv.org/pdf/2102.03732v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2110.15803v3",
    "title": "Natural Language Processing for Smart Healthcare",
    "authors": [
      "Binggui Zhou",
      "Guanghua Yang",
      "Zheng Shi",
      "Shaodan Ma"
    ],
    "abstract": "Smart healthcare has achieved significant progress in recent years. Emerging\nartificial intelligence (AI) technologies enable various smart applications\nacross various healthcare scenarios. As an essential technology powered by AI,\nnatural language processing (NLP) plays a key role in smart healthcare due to\nits capability of analysing and understanding human language. In this work, we\nreview existing studies that concern NLP for smart healthcare from the\nperspectives of technique and application. We first elaborate on different NLP\napproaches and the NLP pipeline for smart healthcare from the technical point\nof view. Then, in the context of smart healthcare applications employing NLP\ntechniques, we introduce representative smart healthcare scenarios, including\nclinical practice, hospital management, personal care, public health, and drug\ndevelopment. We further discuss two specific medical issues, i.e., the\ncoronavirus disease 2019 (COVID-19) pandemic and mental health, in which\nNLP-driven smart healthcare plays an important role. Finally, we discuss the\nlimitations of current works and identify the directions for future works.",
    "published": "2021-10-19T02:48:44Z",
    "pdf_url": "http://arxiv.org/pdf/2110.15803v3",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1801.01331v2",
    "title": "VnCoreNLP: A Vietnamese Natural Language Processing Toolkit",
    "authors": [
      "Thanh Vu",
      "Dat Quoc Nguyen",
      "Dai Quoc Nguyen",
      "Mark Dras",
      "Mark Johnson"
    ],
    "abstract": "We present an easy-to-use and fast toolkit, namely VnCoreNLP---a Java NLP\nannotation pipeline for Vietnamese. Our VnCoreNLP supports key natural language\nprocessing (NLP) tasks including word segmentation, part-of-speech (POS)\ntagging, named entity recognition (NER) and dependency parsing, and obtains\nstate-of-the-art (SOTA) results for these tasks. We release VnCoreNLP to\nprovide rich linguistic annotations to facilitate research work on Vietnamese\nNLP. Our VnCoreNLP is open-source and available at:\nhttps://github.com/vncorenlp/VnCoreNLP",
    "published": "2018-01-04T12:52:43Z",
    "pdf_url": "http://arxiv.org/pdf/1801.01331v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2410.14194v1",
    "title": "Speciesism in Natural Language Processing Research",
    "authors": [
      "Masashi Takeshita",
      "Rafal Rzepka"
    ],
    "abstract": "Natural Language Processing (NLP) research on AI Safety and social bias in AI\nhas focused on safety for humans and social bias against human minorities.\nHowever, some AI ethicists have argued that the moral significance of nonhuman\nanimals has been ignored in AI research. Therefore, the purpose of this study\nis to investigate whether there is speciesism, i.e., discrimination against\nnonhuman animals, in NLP research. First, we explain why nonhuman animals are\nrelevant in NLP research. Next, we survey the findings of existing research on\nspeciesism in NLP researchers, data, and models and further investigate this\nproblem in this study. The findings of this study suggest that speciesism\nexists within researchers, data, and models, respectively. Specifically, our\nsurvey and experiments show that (a) among NLP researchers, even those who\nstudy social bias in AI, do not recognize speciesism or speciesist bias; (b)\namong NLP data, speciesist bias is inherent in the data annotated in the\ndatasets used to evaluate NLP models; (c) OpenAI GPTs, recent NLP models,\nexhibit speciesist bias by default. Finally, we discuss how we can reduce\nspeciesism in NLP research.",
    "published": "2024-10-18T06:09:41Z",
    "pdf_url": "http://arxiv.org/pdf/2410.14194v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2311.02579v1",
    "title": "mahaNLP: A Marathi Natural Language Processing Library",
    "authors": [
      "Vidula Magdum",
      "Omkar Dhekane",
      "Sharayu Hiwarkhedkar",
      "Saloni Mittal",
      "Raviraj Joshi"
    ],
    "abstract": "We present mahaNLP, an open-source natural language processing (NLP) library\nspecifically built for the Marathi language. It aims to enhance the support for\nthe low-resource Indian language Marathi in the field of NLP. It is an\neasy-to-use, extensible, and modular toolkit for Marathi text analysis built on\nstate-of-the-art MahaBERT-based transformer models. Our work holds significant\nimportance as other existing Indic NLP libraries provide basic Marathi\nprocessing support and rely on older models with restricted performance. Our\ntoolkit stands out by offering a comprehensive array of NLP tasks, encompassing\nboth fundamental preprocessing tasks and advanced NLP tasks like sentiment\nanalysis, NER, hate speech detection, and sentence completion. This paper\nfocuses on an overview of the mahaNLP framework, its features, and its usage.\nThis work is a part of the L3Cube MahaNLP initiative, more information about it\ncan be found at https://github.com/l3cube-pune/MarathiNLP .",
    "published": "2023-11-05T06:59:59Z",
    "pdf_url": "http://arxiv.org/pdf/2311.02579v1",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2311.07171v1",
    "title": "calamanCy: A Tagalog Natural Language Processing Toolkit",
    "authors": [
      "Lester James V. Miranda"
    ],
    "abstract": "We introduce calamanCy, an open-source toolkit for constructing natural\nlanguage processing (NLP) pipelines for Tagalog. It is built on top of spaCy,\nenabling easy experimentation and integration with other frameworks. calamanCy\naddresses the development gap by providing a consistent API for building NLP\napplications and offering general-purpose multitask models with out-of-the-box\nsupport for dependency parsing, parts-of-speech (POS) tagging, and named entity\nrecognition (NER). calamanCy aims to accelerate the progress of Tagalog NLP by\nconsolidating disjointed resources in a unified framework. The calamanCy\ntoolkit is available on GitHub: https://github.com/ljvmiranda921/calamanCy.",
    "published": "2023-11-13T09:06:43Z",
    "pdf_url": "http://arxiv.org/pdf/2311.07171v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "9702005v1",
    "title": "Software Infrastructure for Natural Language Processing",
    "authors": [
      "Hamish Cunningham",
      "Kevin Humphreys",
      "Robert Gaizauskas",
      "Yorick Wilks"
    ],
    "abstract": "We classify and review current approaches to software infrastructure for\nresearch, development and delivery of NLP systems. The task is motivated by a\ndiscussion of current trends in the field of NLP and Language Engineering. We\ndescribe a system called GATE (a General Architecture for Text Engineering)\nthat provides a software infrastructure on top of which heterogeneous NLP\nprocessing modules may be evaluated and refined individually, or may be\ncombined into larger application systems. GATE aims to support both researchers\nand developers working on component technologies (e.g. parsing, tagging,\nmorphological analysis) and those working on developing end-user applications\n(e.g. information extraction, text summarisation, document generation, machine\ntranslation, and second language learning). GATE promotes reuse of component\ntechnology, permits specialisation and collaboration in large-scale projects,\nand allows for the comparison and evaluation of alternative technologies. The\nfirst release of GATE is now available - see\nhttp://www.dcs.shef.ac.uk/research/groups/nlp/gate/",
    "published": "1997-02-10T21:07:20Z",
    "pdf_url": "http://arxiv.org/pdf/cmp-lg/9702005v1",
    "categories": [
      "cmp-lg",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "1209.6238v1",
    "title": "Natural Language Processing - A Survey",
    "authors": [
      "Kevin Mote"
    ],
    "abstract": "The utility and power of Natural Language Processing (NLP) seems destined to\nchange our technological society in profound and fundamental ways. However\nthere are, to date, few accessible descriptions of the science of NLP that have\nbeen written for a popular audience, or even for an audience of intelligent,\nbut uninitiated scientists. This paper aims to provide just such an overview.\nIn short, the objective of this article is to describe the purpose, procedures\nand practical applications of NLP in a clear, balanced, and readable way. We\nwill examine the most recent literature describing the methods and processes of\nNLP, analyze some of the challenges that researchers are faced with, and\nbriefly survey some of the current and future applications of this science to\nIT research in general.",
    "published": "2012-09-25T21:05:08Z",
    "pdf_url": "http://arxiv.org/pdf/1209.6238v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2005.00870v1",
    "title": "Predicting Performance for Natural Language Processing Tasks",
    "authors": [
      "Mengzhou Xia",
      "Antonios Anastasopoulos",
      "Ruochen Xu",
      "Yiming Yang",
      "Graham Neubig"
    ],
    "abstract": "Given the complexity of combinations of tasks, languages, and domains in\nnatural language processing (NLP) research, it is computationally prohibitive\nto exhaustively test newly proposed models on each possible experimental\nsetting. In this work, we attempt to explore the possibility of gaining\nplausible judgments of how well an NLP model can perform under an experimental\nsetting, without actually training or testing the model. To do so, we build\nregression models to predict the evaluation score of an NLP experiment given\nthe experimental settings as input. Experimenting on 9 different NLP tasks, we\nfind that our predictors can produce meaningful predictions over unseen\nlanguages and different modeling architectures, outperforming reasonable\nbaselines as well as human experts. Going further, we outline how our predictor\ncan be used to find a small subset of representative experiments that should be\nrun in order to obtain plausible predictions for all other experimental\nsettings.",
    "published": "2020-05-02T16:02:18Z",
    "pdf_url": "http://arxiv.org/pdf/2005.00870v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2109.12575v2",
    "title": "Paradigm Shift in Natural Language Processing",
    "authors": [
      "Tianxiang Sun",
      "Xiangyang Liu",
      "Xipeng Qiu",
      "Xuanjing Huang"
    ],
    "abstract": "In the era of deep learning, modeling for most NLP tasks has converged to\nseveral mainstream paradigms. For example, we usually adopt the sequence\nlabeling paradigm to solve a bundle of tasks such as POS-tagging, NER,\nChunking, and adopt the classification paradigm to solve tasks like sentiment\nanalysis. With the rapid progress of pre-trained language models, recent years\nhave observed a rising trend of Paradigm Shift, which is solving one NLP task\nby reformulating it as another one. Paradigm shift has achieved great success\non many tasks, becoming a promising way to improve model performance. Moreover,\nsome of these paradigms have shown great potential to unify a large number of\nNLP tasks, making it possible to build a single model to handle diverse tasks.\nIn this paper, we review such phenomenon of paradigm shifts in recent years,\nhighlighting several paradigms that have the potential to solve different NLP\ntasks.",
    "published": "2021-09-26T11:55:23Z",
    "pdf_url": "http://arxiv.org/pdf/2109.12575v2",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2302.12039v1",
    "title": "Natural Language Processing in the Legal Domain",
    "authors": [
      "Daniel Martin Katz",
      "Dirk Hartung",
      "Lauritz Gerlach",
      "Abhik Jana",
      "Michael J. Bommarito II"
    ],
    "abstract": "In this paper, we summarize the current state of the field of NLP & Law with\na specific focus on recent technical and substantive developments. To support\nour analysis, we construct and analyze a nearly complete corpus of more than\nsix hundred NLP & Law related papers published over the past decade. Our\nanalysis highlights several major trends. Namely, we document an increasing\nnumber of papers written, tasks undertaken, and languages covered over the\ncourse of the past decade. We observe an increase in the sophistication of the\nmethods which researchers deployed in this applied context. Slowly but surely,\nLegal NLP is beginning to match not only the methodological sophistication of\ngeneral NLP but also the professional standards of data availability and code\nreproducibility observed within the broader scientific community. We believe\nall of these trends bode well for the future of the field, but many questions\nin both the academic and commercial sphere still remain open.",
    "published": "2023-02-23T14:02:47Z",
    "pdf_url": "http://arxiv.org/pdf/2302.12039v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2306.08193v2",
    "title": "Operationalising Representation in Natural Language Processing",
    "authors": [
      "Jacqueline Harding"
    ],
    "abstract": "Despite its centrality in the philosophy of cognitive science, there has been\nlittle prior philosophical work engaging with the notion of representation in\ncontemporary NLP practice. This paper attempts to fill that lacuna: drawing on\nideas from cognitive science, I introduce a framework for evaluating the\nrepresentational claims made about components of neural NLP models, proposing\nthree criteria with which to evaluate whether a component of a model represents\na property and operationalising these criteria using probing classifiers, a\npopular analysis technique in NLP (and deep learning more broadly).\n  The project of operationalising a philosophically-informed notion of\nrepresentation should be of interest to both philosophers of science and NLP\npractitioners. It affords philosophers a novel testing-ground for claims about\nthe nature of representation, and helps NLPers organise the large literature on\nprobing experiments, suggesting novel avenues for empirical research.",
    "published": "2023-06-14T01:34:16Z",
    "pdf_url": "http://arxiv.org/pdf/2306.08193v2",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2405.10845v1",
    "title": "Natural Language Processing for Requirements Traceability",
    "authors": [
      "Jin L. C. Guo",
      "Jan-Philipp Steghöfer",
      "Andreas Vogelsang",
      "Jane Cleland-Huang"
    ],
    "abstract": "Traceability, the ability to trace relevant software artifacts to support\nreasoning about the quality of the software and its development process, plays\na crucial role in requirements and software engineering, particularly for\nsafety-critical systems. In this chapter, we provide a comprehensive overview\nof the representative tasks in requirement traceability for which natural\nlanguage processing (NLP) and related techniques have made considerable\nprogress in the past decade. We first present the definition of traceability in\nthe context of requirements and the overall engineering process, as well as\nother important concepts related to traceability tasks. Then, we discuss two\ntasks in detail, including trace link recovery and trace link maintenance. We\nalso introduce two other related tasks concerning when trace links are used in\npractical contexts. For each task, we explain the characteristics of the task,\nhow it can be approached through NLP techniques, and how to design and conduct\nthe experiment to demonstrate the performance of the NLP techniques. We further\ndiscuss practical considerations on how to effectively apply NLP techniques and\nassess their effectiveness regarding the data set collection, the metrics\nselection, and the role of humans when evaluating the NLP approaches. Overall,\nthis chapter prepares the readers with the fundamental knowledge of designing\nautomated traceability solutions enabled by NLP in practice.",
    "published": "2024-05-17T15:17:00Z",
    "pdf_url": "http://arxiv.org/pdf/2405.10845v1",
    "categories": [
      "cs.SE"
    ]
  },
  {
    "arxiv_id": "2005.00912v1",
    "title": "Examining Citations of Natural Language Processing Literature",
    "authors": [
      "Saif M. Mohammad"
    ],
    "abstract": "We extracted information from the ACL Anthology (AA) and Google Scholar (GS)\nto examine trends in citations of NLP papers. We explore questions such as: how\nwell cited are papers of different types (journal articles, conference papers,\ndemo papers, etc.)? how well cited are papers from different areas of within\nNLP? etc. Notably, we show that only about 56\\% of the papers in AA are cited\nten or more times. CL Journal has the most cited papers, but its citation\ndominance has lessened in recent years. On average, long papers get almost\nthree times as many citations as short papers; and papers on sentiment\nclassification, anaphora resolution, and entity recognition have the highest\nmedian citations. The analyses presented here, and the associated dataset of\nNLP papers mapped to citations, have a number of uses including: understanding\nhow the field is growing and quantifying the impact of different types of\npapers.",
    "published": "2020-05-02T20:01:59Z",
    "pdf_url": "http://arxiv.org/pdf/2005.00912v1",
    "categories": [
      "cs.DL",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2304.12404v1",
    "title": "Semantic Tokenizer for Enhanced Natural Language Processing",
    "authors": [
      "Sandeep Mehta",
      "Darpan Shah",
      "Ravindra Kulkarni",
      "Cornelia Caragea"
    ],
    "abstract": "Traditionally, NLP performance improvement has been focused on improving\nmodels and increasing the number of model parameters. NLP vocabulary\nconstruction has remained focused on maximizing the number of words represented\nthrough subword regularization. We present a novel tokenizer that uses\nsemantics to drive vocabulary construction. The tokenizer includes a trainer\nthat uses stemming to enhance subword formation. Further optimizations and\nadaptations are implemented to minimize the number of words that cannot be\nencoded. The encoder is updated to integrate with the trainer. The tokenizer is\nimplemented as a drop-in replacement for the SentencePiece tokenizer. The new\ntokenizer more than doubles the number of wordforms represented in the\nvocabulary. The enhanced vocabulary significantly improves NLP model\nconvergence, and improves quality of word and sentence embeddings. Our\nexperimental results show top performance on two Glue tasks using BERT-base,\nimproving on models more than 50X in size.",
    "published": "2023-04-24T19:33:41Z",
    "pdf_url": "http://arxiv.org/pdf/2304.12404v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2405.05966v4",
    "title": "Natural Language Processing RELIES on Linguistics",
    "authors": [
      "Juri Opitz",
      "Shira Wein",
      "Nathan Schneider"
    ],
    "abstract": "Large Language Models (LLMs) have become capable of generating highly fluent\ntext in certain languages, without modules specially designed to capture\ngrammar or semantic coherence. What does this mean for the future of linguistic\nexpertise in NLP? We highlight several aspects in which NLP (still) relies on\nlinguistics, or where linguistic thinking can illuminate new directions. We\nargue our case around the acronym RELIES that encapsulates six major facets\nwhere linguistics contributes to NLP: Resources, Evaluation, Low-resource\nsettings, Interpretability, Explanation, and the Study of language. This list\nis not exhaustive, nor is linguistics the main point of reference for every\neffort under these themes; but at a macro level, these facets highlight the\nenduring importance of studying machine systems vis-\\`a-vis systems of human\nlanguage.",
    "published": "2024-05-09T17:59:32Z",
    "pdf_url": "http://arxiv.org/pdf/2405.05966v4",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2507.21112v1",
    "title": "InsurTech innovation using natural language processing",
    "authors": [
      "Panyi Dong",
      "Zhiyu Quan"
    ],
    "abstract": "With the rapid rise of InsurTech, traditional insurance companies are\nincreasingly exploring alternative data sources and advanced technologies to\nsustain their competitive edge. This paper provides both a conceptual overview\nand practical case studies of natural language processing (NLP) and its\nemerging applications within insurance operations with a focus on transforming\nraw, unstructured text into structured data suitable for actuarial analysis and\ndecision-making. Leveraging real-world alternative data provided by an\nInsurTech industry partner that enriches traditional insurance data sources, we\napply various NLP techniques to demonstrate practical use cases in the\ncommercial insurance context. These enriched, text-derived insights not only\nadd to and refine traditional rating factors for commercial insurance pricing\nbut also offer novel perspectives for assessing underlying risk by introducing\nnovel industry classifications. Through these demonstrations, we show that NLP\nis not merely a supplementary tool but a foundational element for modern,\ndata-driven insurance analytics.",
    "published": "2025-07-12T23:10:59Z",
    "pdf_url": "http://arxiv.org/pdf/2507.21112v1",
    "categories": [
      "cs.CL",
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "9607017v1",
    "title": "Natural Language Processing: Structure and Complexity",
    "authors": [
      "Wlodek Zadrozny"
    ],
    "abstract": "We introduce a method for analyzing the complexity of natural language\nprocessing tasks, and for predicting the difficulty new NLP tasks.\n  Our complexity measures are derived from the Kolmogorov complexity of a class\nof automata --- {\\it meaning automata}, whose purpose is to extract relevant\npieces of information from sentences. Natural language semantics is defined\nonly relative to the set of questions an automaton can answer.\n  The paper shows examples of complexity estimates for various NLP programs and\ntasks, and some recipes for complexity management. It positions natural\nlanguage processing as a subdomain of software engineering, and lays down its\nformal foundation.",
    "published": "1996-07-13T21:31:43Z",
    "pdf_url": "http://arxiv.org/pdf/cmp-lg/9607017v1",
    "categories": [
      "cmp-lg",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "1811.07253v1",
    "title": "Quantifying Uncertainties in Natural Language Processing Tasks",
    "authors": [
      "Yijun Xiao",
      "William Yang Wang"
    ],
    "abstract": "Reliable uncertainty quantification is a first step towards building\nexplainable, transparent, and accountable artificial intelligent systems.\nRecent progress in Bayesian deep learning has made such quantification\nrealizable. In this paper, we propose novel methods to study the benefits of\ncharacterizing model and data uncertainties for natural language processing\n(NLP) tasks. With empirical experiments on sentiment analysis, named entity\nrecognition, and language modeling using convolutional and recurrent neural\nnetwork models, we show that explicitly modeling uncertainties is not only\nnecessary to measure output confidence levels, but also useful at enhancing\nmodel performances in various NLP tasks.",
    "published": "2018-11-18T01:36:05Z",
    "pdf_url": "http://arxiv.org/pdf/1811.07253v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "1807.02200v1",
    "title": "Natural Language Processing for Music Knowledge Discovery",
    "authors": [
      "Sergio Oramas",
      "Luis Espinosa-Anke",
      "Francisco Gómez",
      "Xavier Serra"
    ],
    "abstract": "Today, a massive amount of musical knowledge is stored in written form, with\ntestimonies dated as far back as several centuries ago. In this work, we\npresent different Natural Language Processing (NLP) approaches to harness the\npotential of these text collections for automatic music knowledge discovery,\ncovering different phases in a prototypical NLP pipeline, namely corpus\ncompilation, text-mining, information extraction, knowledge graph generation\nand sentiment analysis. Each of these approaches is presented alongside\ndifferent use cases (i.e., flamenco, Renaissance and popular music) where large\ncollections of documents are processed, and conclusions stemming from\ndata-driven analyses are presented and discussed.",
    "published": "2018-07-06T00:07:27Z",
    "pdf_url": "http://arxiv.org/pdf/1807.02200v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2105.02590v3",
    "title": "Reliability Testing for Natural Language Processing Systems",
    "authors": [
      "Samson Tan",
      "Shafiq Joty",
      "Kathy Baxter",
      "Araz Taeihagh",
      "Gregory A. Bennett",
      "Min-Yen Kan"
    ],
    "abstract": "Questions of fairness, robustness, and transparency are paramount to address\nbefore deploying NLP systems. Central to these concerns is the question of\nreliability: Can NLP systems reliably treat different demographics fairly and\nfunction correctly in diverse and noisy environments? To address this, we argue\nfor the need for reliability testing and contextualize it among existing work\non improving accountability. We show how adversarial attacks can be reframed\nfor this goal, via a framework for developing reliability tests. We argue that\nreliability testing -- with an emphasis on interdisciplinary collaboration --\nwill enable rigorous and targeted testing, and aid in the enactment and\nenforcement of industry standards.",
    "published": "2021-05-06T11:24:58Z",
    "pdf_url": "http://arxiv.org/pdf/2105.02590v3",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "2208.10228v2",
    "title": "Review of Natural Language Processing in Pharmacology",
    "authors": [
      "Dimitar Trajanov",
      "Vangel Trajkovski",
      "Makedonka Dimitrieva",
      "Jovana Dobreva",
      "Milos Jovanovik",
      "Matej Klemen",
      "Aleš Žagar",
      "Marko Robnik-Šikonja"
    ],
    "abstract": "Natural language processing (NLP) is an area of artificial intelligence that\napplies information technologies to process the human language, understand it\nto a certain degree, and use it in various applications. This area has rapidly\ndeveloped in the last few years and now employs modern variants of deep neural\nnetworks to extract relevant patterns from large text corpora. The main\nobjective of this work is to survey the recent use of NLP in the field of\npharmacology. As our work shows, NLP is a highly relevant information\nextraction and processing approach for pharmacology. It has been used\nextensively, from intelligent searches through thousands of medical documents\nto finding traces of adversarial drug interactions in social media. We split\nour coverage into five categories to survey modern NLP methodology, commonly\naddressed tasks, relevant textual data, knowledge bases, and useful programming\nlibraries. We split each of the five categories into appropriate subcategories,\ndescribe their main properties and ideas, and summarize them in a tabular form.\nThe resulting survey presents a comprehensive overview of the area, useful to\npractitioners and interested observers.",
    "published": "2022-08-22T12:10:27Z",
    "pdf_url": "http://arxiv.org/pdf/2208.10228v2",
    "categories": [
      "cs.CL",
      "cs.LG",
      "q-bio.BM",
      "J.3; A.1"
    ]
  },
  {
    "arxiv_id": "2501.16836v1",
    "title": "Misspellings in Natural Language Processing: A survey",
    "authors": [
      "Gianluca Sperduti",
      "Alejandro Moreo"
    ],
    "abstract": "This survey provides an overview of the challenges of misspellings in natural\nlanguage processing (NLP). While often unintentional, misspellings have become\nubiquitous in digital communication, especially with the proliferation of Web\n2.0, user-generated content, and informal text mediums such as social media,\nblogs, and forums. Even if humans can generally interpret misspelled text, NLP\nmodels frequently struggle to handle it: this causes a decline in performance\nin common tasks like text classification and machine translation. In this\npaper, we reconstruct a history of misspellings as a scientific problem. We\nthen discuss the latest advancements to address the challenge of misspellings\nin NLP. Main strategies to mitigate the effect of misspellings include data\naugmentation, double step, character-order agnostic, and tuple-based methods,\namong others. This survey also examines dedicated data challenges and\ncompetitions to spur progress in the field. Critical safety and ethical\nconcerns are also examined, for example, the voluntary use of misspellings to\ninject malicious messages and hate speech on social networks. Furthermore, the\nsurvey explores psycholinguistic perspectives on how humans process\nmisspellings, potentially informing innovative computational techniques for\ntext normalization and representation. Finally, the misspelling-related\nchallenges and opportunities associated with modern large language models are\nalso analyzed, including benchmarks, datasets, and performances of the most\nprominent language models against misspellings. This survey aims to be an\nexhaustive resource for researchers seeking to mitigate the impact of\nmisspellings in the rapidly evolving landscape of NLP.",
    "published": "2025-01-28T10:26:04Z",
    "pdf_url": "http://arxiv.org/pdf/2501.16836v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2507.00297v1",
    "title": "Natural language processing for African languages",
    "authors": [
      "David Ifeoluwa Adelani"
    ],
    "abstract": "Recent advances in word embeddings and language models use large-scale,\nunlabelled data and self-supervised learning to boost NLP performance.\nMultilingual models, often trained on web-sourced data like Wikipedia, face\nchallenges: few low-resource languages are included, their data is often noisy,\nand lack of labeled datasets makes it hard to evaluate performance outside\nhigh-resource languages like English. In this dissertation, we focus on\nlanguages spoken in Sub-Saharan Africa where all the indigenous languages in\nthis region can be regarded as low-resourced in terms of the availability of\nlabelled data for NLP tasks and unlabelled data found on the web. We analyse\nthe noise in the publicly available corpora, and curate a high-quality corpus,\ndemonstrating that the quality of semantic representations learned in word\nembeddings does not only depend on the amount of data but on the quality of\npre-training data. We demonstrate empirically the limitations of word\nembeddings, and the opportunities the multilingual pre-trained language model\n(PLM) offers especially for languages unseen during pre-training and\nlow-resource scenarios. We further study how to adapt and specialize\nmultilingual PLMs to unseen African languages using a small amount of\nmonolingual texts. To address the under-representation of the African languages\nin NLP research, we developed large scale human-annotated labelled datasets for\n21 African languages in two impactful NLP tasks: named entity recognition and\nmachine translation. We conduct an extensive empirical evaluation using\nstate-of-the-art methods across supervised, weakly-supervised, and transfer\nlearning settings.",
    "published": "2025-06-30T22:26:36Z",
    "pdf_url": "http://arxiv.org/pdf/2507.00297v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2305.04572v2",
    "title": "Putting Natural in Natural Language Processing",
    "authors": [
      "Grzegorz Chrupała"
    ],
    "abstract": "Human language is firstly spoken and only secondarily written. Text, however,\nis a very convenient and efficient representation of language, and modern\ncivilization has made it ubiquitous. Thus the field of NLP has overwhelmingly\nfocused on processing written rather than spoken language. Work on spoken\nlanguage, on the other hand, has been siloed off within the largely separate\nspeech processing community which has been inordinately preoccupied with\ntranscribing speech into text. Recent advances in deep learning have led to a\nfortuitous convergence in methods between speech processing and mainstream NLP.\nArguably, the time is ripe for a unification of these two fields, and for\nstarting to take spoken language seriously as the primary mode of human\ncommunication. Truly natural language processing could lead to better\nintegration with the rest of language science and could lead to systems which\nare more data-efficient and more human-like, and which can communicate beyond\nthe textual modality.",
    "published": "2023-05-08T09:29:31Z",
    "pdf_url": "http://arxiv.org/pdf/2305.04572v2",
    "categories": [
      "cs.CL",
      "cs.AI",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2109.13037v2",
    "title": "Language Invariant Properties in Natural Language Processing",
    "authors": [
      "Federico Bianchi",
      "Debora Nozza",
      "Dirk Hovy"
    ],
    "abstract": "Meaning is context-dependent, but many properties of language (should) remain\nthe same even if we transform the context. For example, sentiment, entailment,\nor speaker properties should be the same in a translation and original of a\ntext. We introduce language invariant properties: i.e., properties that should\nnot change when we transform text, and how they can be used to quantitatively\nevaluate the robustness of transformation algorithms. We use translation and\nparaphrasing as transformation examples, but our findings apply more broadly to\nany transformation. Our results indicate that many NLP transformations change\nproperties like author characteristics, i.e., make them sound more male. We\nbelieve that studying these properties will allow NLP to address both social\nfactors and pragmatic aspects of language. We also release an application suite\nthat can be used to evaluate the invariance of transformation applications.",
    "published": "2021-09-27T13:23:05Z",
    "pdf_url": "http://arxiv.org/pdf/2109.13037v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2310.10930v1",
    "title": "Enhanced Transformer Architecture for Natural Language Processing",
    "authors": [
      "Woohyeon Moon",
      "Taeyoung Kim",
      "Bumgeun Park",
      "Dongsoo Har"
    ],
    "abstract": "Transformer is a state-of-the-art model in the field of natural language\nprocessing (NLP). Current NLP models primarily increase the number of\ntransformers to improve processing performance. However, this technique\nrequires a lot of training resources such as computing capacity. In this paper,\na novel structure of Transformer is proposed. It is featured by full layer\nnormalization, weighted residual connection, positional encoding exploiting\nreinforcement learning, and zero masked self-attention. The proposed\nTransformer model, which is called Enhanced Transformer, is validated by the\nbilingual evaluation understudy (BLEU) score obtained with the Multi30k\ntranslation dataset. As a result, the Enhanced Transformer achieves 202.96%\nhigher BLEU score as compared to the original transformer with the translation\ndataset.",
    "published": "2023-10-17T01:59:07Z",
    "pdf_url": "http://arxiv.org/pdf/2310.10930v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1807.05519v1",
    "title": "Concept-Based Embeddings for Natural Language Processing",
    "authors": [
      "Yukun Ma",
      "Erik Cambria"
    ],
    "abstract": "In this work, we focus on effectively leveraging and integrating information\nfrom concept-level as well as word-level via projecting concepts and words into\na lower dimensional space while retaining most critical semantics. In a broad\ncontext of opinion understanding system, we investigate the use of the fused\nembedding for several core NLP tasks: named entity detection and\nclassification, automatic speech recognition reranking, and targeted sentiment\nanalysis.",
    "published": "2018-07-15T09:36:39Z",
    "pdf_url": "http://arxiv.org/pdf/1807.05519v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2303.12804v1",
    "title": "Features matching using natural language processing",
    "authors": [
      "Muhammad Danial Khilji"
    ],
    "abstract": "The feature matching is a basic step in matching different datasets. This\narticle proposes shows a new hybrid model of a pretrained Natural Language\nProcessing (NLP) based model called BERT used in parallel with a statistical\nmodel based on Jaccard similarity to measure the similarity between list of\nfeatures from two different datasets. This reduces the time required to search\nfor correlations or manually match each feature from one dataset to another.",
    "published": "2023-03-14T13:31:19Z",
    "pdf_url": "http://arxiv.org/pdf/2303.12804v1",
    "categories": [
      "cs.DB",
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1908.01851v1",
    "title": "Self-Knowledge Distillation in Natural Language Processing",
    "authors": [
      "Sangchul Hahn",
      "Heeyoul Choi"
    ],
    "abstract": "Since deep learning became a key player in natural language processing (NLP),\nmany deep learning models have been showing remarkable performances in a\nvariety of NLP tasks, and in some cases, they are even outperforming humans.\nSuch high performance can be explained by efficient knowledge representation of\ndeep learning models. While many methods have been proposed to learn more\nefficient representation, knowledge distillation from pretrained deep networks\nsuggest that we can use more information from the soft target probability to\ntrain other neural networks. In this paper, we propose a new knowledge\ndistillation method self-knowledge distillation, based on the soft target\nprobabilities of the training model itself, where multimode information is\ndistilled from the word embedding space right below the softmax layer. Due to\nthe time complexity, our method approximates the soft target probabilities. In\nexperiments, we applied the proposed method to two different and fundamental\nNLP tasks: language model and neural machine translation. The experiment\nresults show that our proposed method improves performance on the tasks.",
    "published": "2019-08-02T15:17:27Z",
    "pdf_url": "http://arxiv.org/pdf/1908.01851v1",
    "categories": [
      "cs.CL",
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2108.13300v1",
    "title": "Deep Natural Language Processing for LinkedIn Search",
    "authors": [
      "Weiwei Guo",
      "Xiaowei Liu",
      "Sida Wang",
      "Michaeel Kazi",
      "Zhiwei Wang",
      "Zhoutong Fu",
      "Jun Jia",
      "Liang Zhang",
      "Huiji Gao",
      "Bo Long"
    ],
    "abstract": "Many search systems work with large amounts of natural language data, e.g.,\nsearch queries, user profiles, and documents. Building a successful search\nsystem requires a thorough understanding of textual data semantics, where deep\nlearning based natural language processing techniques (deep NLP) can be of\ngreat help. In this paper, we introduce a comprehensive study for applying deep\nNLP techniques to five representative tasks in search systems: query intent\nprediction (classification), query tagging (sequential tagging), document\nranking (ranking), query auto completion (language modeling), and query\nsuggestion (sequence to sequence). We also introduce BERT pre-training as a\nsixth task that can be applied to many of the other tasks. Through the model\ndesign and experiments of the six tasks, readers can find answers to four\nimportant questions: (1). When is deep NLP helpful/not helpful in search\nsystems? (2). How to address latency challenges? (3). How to ensure model\nrobustness? This work builds on existing efforts of LinkedIn search, and is\ntested at scale on LinkedIn's commercial search engines. We believe our\nexperiences can provide useful insights for the industry and research\ncommunities.",
    "published": "2021-08-16T23:37:33Z",
    "pdf_url": "http://arxiv.org/pdf/2108.13300v1",
    "categories": [
      "cs.IR",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2105.05222v2",
    "title": "Including Signed Languages in Natural Language Processing",
    "authors": [
      "Kayo Yin",
      "Amit Moryossef",
      "Julie Hochgesang",
      "Yoav Goldberg",
      "Malihe Alikhani"
    ],
    "abstract": "Signed languages are the primary means of communication for many deaf and\nhard of hearing individuals. Since signed languages exhibit all the fundamental\nlinguistic properties of natural language, we believe that tools and theories\nof Natural Language Processing (NLP) are crucial towards its modeling. However,\nexisting research in Sign Language Processing (SLP) seldom attempt to explore\nand leverage the linguistic organization of signed languages. This position\npaper calls on the NLP community to include signed languages as a research area\nwith high social and scientific impact. We first discuss the linguistic\nproperties of signed languages to consider during their modeling. Then, we\nreview the limitations of current SLP models and identify the open challenges\nto extend NLP to signed languages. Finally, we urge (1) the adoption of an\nefficient tokenization method; (2) the development of linguistically-informed\nmodels; (3) the collection of real-world signed language data; (4) the\ninclusion of local signed language communities as an active and leading voice\nin the direction of research.",
    "published": "2021-05-11T17:37:55Z",
    "pdf_url": "http://arxiv.org/pdf/2105.05222v2",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2109.03009v1",
    "title": "Sequential Attention Module for Natural Language Processing",
    "authors": [
      "Mengyuan Zhou",
      "Jian Ma",
      "Haiqin Yang",
      "Lianxin Jiang",
      "Yang Mo"
    ],
    "abstract": "Recently, large pre-trained neural language models have attained remarkable\nperformance on many downstream natural language processing (NLP) applications\nvia fine-tuning. In this paper, we target at how to further improve the token\nrepresentations on the language models. We, therefore, propose a simple yet\neffective plug-and-play module, Sequential Attention Module (SAM), on the token\nembeddings learned from a pre-trained language model. Our proposed SAM consists\nof two main attention modules deployed sequentially: Feature-wise Attention\nModule (FAM) and Token-wise Attention Module (TAM). More specifically, FAM can\neffectively identify the importance of features at each dimension and promote\nthe effect via dot-product on the original token embeddings for downstream NLP\napplications. Meanwhile, TAM can further re-weight the features at the\ntoken-wise level. Moreover, we propose an adaptive filter on FAM to prevent\nnoise impact and increase information absorption. Finally, we conduct extensive\nexperiments to demonstrate the advantages and properties of our proposed SAM.\nWe first show how SAM plays a primary role in the champion solution of two\nsubtasks of SemEval'21 Task 7. After that, we apply SAM on sentiment analysis\nand three popular NLP tasks and demonstrate that SAM consistently outperforms\nthe state-of-the-art baselines.",
    "published": "2021-09-07T11:48:23Z",
    "pdf_url": "http://arxiv.org/pdf/2109.03009v1",
    "categories": [
      "cs.AI",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2302.04725v1",
    "title": "Lightweight Transformers for Clinical Natural Language Processing",
    "authors": [
      "Omid Rohanian",
      "Mohammadmahdi Nouriborji",
      "Hannah Jauncey",
      "Samaneh Kouchaki",
      "ISARIC Clinical Characterisation Group",
      "Lei Clifton",
      "Laura Merson",
      "David A. Clifton"
    ],
    "abstract": "Specialised pre-trained language models are becoming more frequent in NLP\nsince they can potentially outperform models trained on generic texts. BioBERT\nand BioClinicalBERT are two examples of such models that have shown promise in\nmedical NLP tasks. Many of these models are overparametrised and\nresource-intensive, but thanks to techniques like Knowledge Distillation (KD),\nit is possible to create smaller versions that perform almost as well as their\nlarger counterparts. In this work, we specifically focus on development of\ncompact language models for processing clinical texts (i.e. progress notes,\ndischarge summaries etc). We developed a number of efficient lightweight\nclinical transformers using knowledge distillation and continual learning, with\nthe number of parameters ranging from 15 million to 65 million. These models\nperformed comparably to larger models such as BioBERT and ClinicalBioBERT and\nsignificantly outperformed other compact models trained on general or\nbiomedical data. Our extensive evaluation was done across several standard\ndatasets and covered a wide range of clinical text-mining tasks, including\nNatural Language Inference, Relation Extraction, Named Entity Recognition, and\nSequence Classification. To our knowledge, this is the first comprehensive\nstudy specifically focused on creating efficient and compact transformers for\nclinical NLP tasks. The models and code used in this study can be found on our\nHuggingface profile at https://huggingface.co/nlpie and Github page at\nhttps://github.com/nlpie-research/Lightweight-Clinical-Transformers,\nrespectively, promoting reproducibility of our results.",
    "published": "2023-02-09T16:07:31Z",
    "pdf_url": "http://arxiv.org/pdf/2302.04725v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "68T50",
      "I.2.7"
    ]
  },
  {
    "arxiv_id": "2109.03383v1",
    "title": "DeepZensols: Deep Natural Language Processing Framework",
    "authors": [
      "Paul Landes",
      "Barbara Di Eugenio",
      "Cornelia Caragea"
    ],
    "abstract": "Reproducing results in publications by distributing publicly available source\ncode is becoming ever more popular. Given the difficulty of reproducing machine\nlearning (ML) experiments, there have been significant efforts in reducing the\nvariance of these results. As in any science, the ability to consistently\nreproduce results effectively strengthens the underlying hypothesis of the\nwork, and thus, should be regarded as important as the novel aspect of the\nresearch itself. The contribution of this work is a framework that is able to\nreproduce consistent results and provides a means of easily creating, training,\nand evaluating natural language processing (NLP) deep learning (DL) models.",
    "published": "2021-09-08T01:16:05Z",
    "pdf_url": "http://arxiv.org/pdf/2109.03383v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2310.20077v1",
    "title": "Partial Tensorized Transformers for Natural Language Processing",
    "authors": [
      "Subhadra Vadlamannati",
      "Ryan Solgi"
    ],
    "abstract": "The transformer architecture has revolutionized Natural Language Processing\n(NLP) and other machine-learning tasks, due to its unprecedented accuracy.\nHowever, their extensive memory and parameter requirements often hinder their\npractical applications. In this work, we study the effect of tensor-train\ndecomposition to improve the accuracy and compress transformer vision-language\nneural networks, namely BERT and ViT. We focus both on embedding-layer\ncompression and partial tensorization of neural networks (PTNN) through an\nalgorithmic approach. Our novel PTNN approach significantly improves the\naccuracy of existing models by up to 5%, all without the need for post-training\nadjustments, breaking new ground in the field of tensor decomposition.",
    "published": "2023-10-30T23:19:06Z",
    "pdf_url": "http://arxiv.org/pdf/2310.20077v1",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2312.04649v1",
    "title": "PyThaiNLP: Thai Natural Language Processing in Python",
    "authors": [
      "Wannaphong Phatthiyaphaibun",
      "Korakot Chaovavanich",
      "Charin Polpanumas",
      "Arthit Suriyawongkul",
      "Lalita Lowphansirikul",
      "Pattarawat Chormai",
      "Peerat Limkonchotiwat",
      "Thanathip Suntorntip",
      "Can Udomcharoenchaikit"
    ],
    "abstract": "We present PyThaiNLP, a free and open-source natural language processing\n(NLP) library for Thai language implemented in Python. It provides a wide range\nof software, models, and datasets for Thai language. We first provide a brief\nhistorical context of tools for Thai language prior to the development of\nPyThaiNLP. We then outline the functionalities it provided as well as datasets\nand pre-trained language models. We later summarize its development milestones\nand discuss our experience during its development. We conclude by demonstrating\nhow industrial and research communities utilize PyThaiNLP in their work. The\nlibrary is freely available at https://github.com/pythainlp/pythainlp.",
    "published": "2023-12-07T19:19:43Z",
    "pdf_url": "http://arxiv.org/pdf/2312.04649v1",
    "categories": [
      "cs.CL",
      "I.2.7"
    ]
  },
  {
    "arxiv_id": "1807.11714v2",
    "title": "Gender Bias in Neural Natural Language Processing",
    "authors": [
      "Kaiji Lu",
      "Piotr Mardziel",
      "Fangjing Wu",
      "Preetam Amancharla",
      "Anupam Datta"
    ],
    "abstract": "We examine whether neural natural language processing (NLP) systems reflect\nhistorical biases in training data. We define a general benchmark to quantify\ngender bias in a variety of neural NLP tasks. Our empirical evaluation with\nstate-of-the-art neural coreference resolution and textbook RNN-based language\nmodels trained on benchmark datasets finds significant gender bias in how\nmodels view occupations. We then mitigate bias with CDA: a generic methodology\nfor corpus augmentation via causal interventions that breaks associations\nbetween gendered and gender-neutral words. We empirically show that CDA\neffectively decreases gender bias while preserving accuracy. We also explore\nthe space of mitigation strategies with CDA, a prior approach to word embedding\ndebiasing (WED), and their compositions. We show that CDA outperforms WED,\ndrastically so when word embeddings are trained. For pre-trained embeddings,\nthe two methods can be effectively composed. We also find that as training\nproceeds on the original data set with gradient descent the gender bias grows\nas the loss reduces, indicating that the optimization encourages bias; CDA\nmitigates this behavior.",
    "published": "2018-07-31T09:27:27Z",
    "pdf_url": "http://arxiv.org/pdf/1807.11714v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2301.04230v1",
    "title": "User-Centered Security in Natural Language Processing",
    "authors": [
      "Chris Emmery"
    ],
    "abstract": "This dissertation proposes a framework of user-centered security in Natural\nLanguage Processing (NLP), and demonstrates how it can improve the\naccessibility of related research. Accordingly, it focuses on two security\ndomains within NLP with great public interest. First, that of author profiling,\nwhich can be employed to compromise online privacy through invasive inferences.\nWithout access and detailed insight into these models' predictions, there is no\nreasonable heuristic by which Internet users might defend themselves from such\ninferences. Secondly, that of cyberbullying detection, which by default\npresupposes a centralized implementation; i.e., content moderation across\nsocial platforms. As access to appropriate data is restricted, and the nature\nof the task rapidly evolves (both through lexical variation, and cultural\nshifts), the effectiveness of its classifiers is greatly diminished and thereby\noften misrepresented.\n  Under the proposed framework, we predominantly investigate the use of\nadversarial attacks on language; i.e., changing a given input (generating\nadversarial samples) such that a given model does not function as intended.\nThese attacks form a common thread between our user-centered security problems;\nthey are highly relevant for privacy-preserving obfuscation methods against\nauthor profiling, and adversarial samples might also prove useful to assess the\ninfluence of lexical variation and augmentation on cyberbullying detection.",
    "published": "2023-01-10T22:34:19Z",
    "pdf_url": "http://arxiv.org/pdf/2301.04230v1",
    "categories": [
      "cs.CL",
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "2011.08073v2",
    "title": "Analyzing Sustainability Reports Using Natural Language Processing",
    "authors": [
      "Alexandra Luccioni",
      "Emily Baylor",
      "Nicolas Duchene"
    ],
    "abstract": "Climate change is a far-reaching, global phenomenon that will impact many\naspects of our society, including the global stock market\n\\cite{dietz2016climate}. In recent years, companies have increasingly been\naiming to both mitigate their environmental impact and adapt to the changing\nclimate context. This is reported via increasingly exhaustive reports, which\ncover many types of climate risks and exposures under the umbrella of\nEnvironmental, Social, and Governance (ESG). However, given this abundance of\ndata, sustainability analysts are obliged to comb through hundreds of pages of\nreports in order to find relevant information. We leveraged recent progress in\nNatural Language Processing (NLP) to create a custom model, ClimateQA, which\nallows the analysis of financial reports in order to identify climate-relevant\nsections based on a question answering approach. We present this tool and the\nmethodology that we used to develop it in the present article.",
    "published": "2020-11-03T21:22:42Z",
    "pdf_url": "http://arxiv.org/pdf/2011.08073v2",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1903.02784v1",
    "title": "Arabic natural language processing: An overview",
    "authors": [
      "Imane Guellil",
      "Houda Saâdane",
      "Faical Azouaou",
      "Billel Gueni",
      "Damien Nouvel"
    ],
    "abstract": "Arabic is recognised as the 4th most used language of the Internet. Arabic\nhas three main varieties: (1) classical Arabic (CA), (2) Modern Standard Arabic\n(MSA), (3) Arabic Dialect (AD). MSA and AD could be written either in Arabic or\nin Roman script (Arabizi), which corresponds to Arabic written with Latin\nletters, numerals and punctuation. Due to the complexity of this language and\nthe number of corresponding challenges for NLP, many surveys have been\nconducted, in order to synthesise the work done on Arabic. However these\nsurveys principally focus on two varieties of Arabic (MSA and AD, written in\nArabic letters only), they are slightly old (no such survey since 2015) and\ntherefore do not cover recent resources and tools. To bridge the gap, we\npropose a survey focusing on 90 recent research papers (74% of which were\npublished after 2015). Our study presents and classifies the work done on the\nthree varieties of Arabic, by concentrating on both Arabic and Arabizi, and\nassociates each work to its publicly available resources whenever available.",
    "published": "2019-03-07T09:22:35Z",
    "pdf_url": "http://arxiv.org/pdf/1903.02784v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "1807.02383v1",
    "title": "Natural Language Processing for Information Extraction",
    "authors": [
      "Sonit Singh"
    ],
    "abstract": "With rise of digital age, there is an explosion of information in the form of\nnews, articles, social media, and so on. Much of this data lies in unstructured\nform and manually managing and effectively making use of it is tedious, boring\nand labor intensive. This explosion of information and need for more\nsophisticated and efficient information handling tools gives rise to\nInformation Extraction(IE) and Information Retrieval(IR) technology.\nInformation Extraction systems takes natural language text as input and\nproduces structured information specified by certain criteria, that is relevant\nto a particular application. Various sub-tasks of IE such as Named Entity\nRecognition, Coreference Resolution, Named Entity Linking, Relation Extraction,\nKnowledge Base reasoning forms the building blocks of various high end Natural\nLanguage Processing (NLP) tasks such as Machine Translation, Question-Answering\nSystem, Natural Language Understanding, Text Summarization and Digital\nAssistants like Siri, Cortana and Google Now. This paper introduces Information\nExtraction technology, its various sub-tasks, highlights state-of-the-art\nresearch in various IE subtasks, current challenges and future research\ndirections.",
    "published": "2018-07-06T12:44:31Z",
    "pdf_url": "http://arxiv.org/pdf/1807.02383v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2509.04462v1",
    "title": "Benchmarking GPT-5 for biomedical natural language processing",
    "authors": [
      "Yu Hou",
      "Zaifu Zhan",
      "Rui Zhang"
    ],
    "abstract": "The rapid expansion of biomedical literature has heightened the need for\nscalable natural language processing (NLP) solutions. While GPT-4 substantially\nnarrowed the gap with task-specific systems, especially in question answering,\nits performance across other domains remained uneven. We updated a standardized\nBioNLP benchmark to evaluate GPT-5 and GPT-4o under zero-, one-, and five-shot\nprompting across 12 datasets spanning six task families: named entity\nrecognition, relation extraction, multi-label document classification, question\nanswering, text summarization, and text simplification. Using fixed prompt\ntemplates, identical decoding parameters, and batch inference, we report\nprimary metrics per dataset and include prior results for GPT-4, GPT-3.5, and\nLLaMA-2-13B for comparison. GPT-5 achieved the strongest overall benchmark\nperformance, with macro-average scores rising to 0.557 under five-shot\nprompting versus 0.506 for GPT-4 and 0.508 for GPT-4o. On MedQA, GPT-5 reached\n94.1% accuracy, exceeding the previous supervised state of the art by over\nfifty points, and attained parity with supervised systems on PubMedQA (0.734).\nIn extraction tasks, GPT-5 delivered major gains in chemical NER (0.886 F1) and\nChemProt relation extraction (0.616 F1), outperforming GPT-4 and GPT-4o, though\nsummarization and disease NER still lagged behind domain-specific baselines.\nThese results establish GPT-5 as a general-purpose model now offering\ndeployment-ready performance for reasoning-oriented biomedical QA, while\nprecision-critical extraction and evidence-dense summarization continue to\nfavor fine-tuned or hybrid approaches. The benchmark delineates where simple\nprompting suffices and where retrieval-augmented or planning-based scaffolds\nare likely required, providing actionable guidance for BioNLP system design as\nfrontier models advance.",
    "published": "2025-08-28T13:06:53Z",
    "pdf_url": "http://arxiv.org/pdf/2509.04462v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1905.11833v4",
    "title": "Interpreting and improving natural-language processing (in machines)\n  with natural language-processing (in the brain)",
    "authors": [
      "Mariya Toneva",
      "Leila Wehbe"
    ],
    "abstract": "Neural networks models for NLP are typically implemented without the explicit\nencoding of language rules and yet they are able to break one performance\nrecord after another. This has generated a lot of research interest in\ninterpreting the representations learned by these networks. We propose here a\nnovel interpretation approach that relies on the only processing system we have\nthat does understand language: the human brain. We use brain imaging recordings\nof subjects reading complex natural text to interpret word and sequence\nembeddings from 4 recent NLP models - ELMo, USE, BERT and Transformer-XL. We\nstudy how their representations differ across layer depth, context length, and\nattention type. Our results reveal differences in the context-related\nrepresentations across these models. Further, in the transformer models, we\nfind an interaction between layer depth and context length, and between layer\ndepth and attention type. We finally hypothesize that altering BERT to better\nalign with brain recordings would enable it to also better understand language.\nProbing the altered BERT using syntactic NLP tasks reveals that the model with\nincreased brain-alignment outperforms the original model. Cognitive\nneuroscientists have already begun using NLP networks to study the brain, and\nthis work closes the loop to allow the interaction between NLP and cognitive\nneuroscience to be a true cross-pollination.",
    "published": "2019-05-28T14:13:09Z",
    "pdf_url": "http://arxiv.org/pdf/1905.11833v4",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ]
  },
  {
    "arxiv_id": "2205.01500v2",
    "title": "Meta Learning for Natural Language Processing: A Survey",
    "authors": [
      "Hung-yi Lee",
      "Shang-Wen Li",
      "Ngoc Thang Vu"
    ],
    "abstract": "Deep learning has been the mainstream technique in natural language\nprocessing (NLP) area. However, the techniques require many labeled data and\nare less generalizable across domains. Meta-learning is an arising field in\nmachine learning studying approaches to learn better learning algorithms.\nApproaches aim at improving algorithms in various aspects, including data\nefficiency and generalizability. Efficacy of approaches has been shown in many\nNLP tasks, but there is no systematic survey of these approaches in NLP, which\nhinders more researchers from joining the field. Our goal with this survey\npaper is to offer researchers pointers to relevant meta-learning works in NLP\nand attract more attention from the NLP community to drive future innovation.\nThis paper first introduces the general concepts of meta-learning and the\ncommon approaches. Then we summarize task construction settings and application\nof meta-learning for various NLP problems and review the development of\nmeta-learning in NLP community.",
    "published": "2022-05-03T13:58:38Z",
    "pdf_url": "http://arxiv.org/pdf/2205.01500v2",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2103.04044v1",
    "title": "Putting Humans in the Natural Language Processing Loop: A Survey",
    "authors": [
      "Zijie J. Wang",
      "Dongjin Choi",
      "Shenyu Xu",
      "Diyi Yang"
    ],
    "abstract": "How can we design Natural Language Processing (NLP) systems that learn from\nhuman feedback? There is a growing research body of Human-in-the-loop (HITL)\nNLP frameworks that continuously integrate human feedback to improve the model\nitself. HITL NLP research is nascent but multifarious -- solving various NLP\nproblems, collecting diverse feedback from different people, and applying\ndifferent methods to learn from collected feedback. We present a survey of HITL\nNLP work from both Machine Learning (ML) and Human-Computer Interaction (HCI)\ncommunities that highlights its short yet inspiring history, and thoroughly\nsummarize recent frameworks focusing on their tasks, goals, human interactions,\nand feedback learning methods. Finally, we discuss future directions for\nintegrating human feedback in the NLP development loop.",
    "published": "2021-03-06T06:26:00Z",
    "pdf_url": "http://arxiv.org/pdf/2103.04044v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1807.00571v1",
    "title": "The Interplay between Lexical Resources and Natural Language Processing",
    "authors": [
      "Jose Camacho-Collados",
      "Luis Espinosa-Anke",
      "Mohammad Taher Pilehvar"
    ],
    "abstract": "Incorporating linguistic, world and common sense knowledge into AI/NLP\nsystems is currently an important research area, with several open problems and\nchallenges. At the same time, processing and storing this knowledge in lexical\nresources is not a straightforward task. This tutorial proposes to address\nthese complementary goals from two methodological perspectives: the use of NLP\nmethods to help the process of constructing and enriching lexical resources and\nthe use of lexical resources for improving NLP applications. Two main types of\naudience can benefit from this tutorial: those working on language resources\nwho are interested in becoming acquainted with automatic NLP techniques, with\nthe end goal of speeding and/or easing up the process of resource curation; and\non the other hand, researchers in NLP who would like to benefit from the\nknowledge of lexical resources to improve their systems and models. The slides\nof the tutorial are available at https://bitbucket.org/luisespinosa/lr-nlp/",
    "published": "2018-07-02T09:53:50Z",
    "pdf_url": "http://arxiv.org/pdf/1807.00571v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "1401.0569v2",
    "title": "Natural Language Processing in Biomedicine: A Unified System\n  Architecture Overview",
    "authors": [
      "Son Doan",
      "Mike Conway",
      "Tu Minh Phuong",
      "Lucila Ohno-Machado"
    ],
    "abstract": "In modern electronic medical records (EMR) much of the clinically important\ndata - signs and symptoms, symptom severity, disease status, etc. - are not\nprovided in structured data fields, but rather are encoded in clinician\ngenerated narrative text. Natural language processing (NLP) provides a means of\n\"unlocking\" this important data source for applications in clinical decision\nsupport, quality assurance, and public health. This chapter provides an\noverview of representative NLP systems in biomedicine based on a unified\narchitectural view. A general architecture in an NLP system consists of two\nmain components: background knowledge that includes biomedical knowledge\nresources and a framework that integrates NLP tools to process text. Systems\ndiffer in both components, which we will review briefly. Additionally,\nchallenges facing current research efforts in biomedical NLP include the\npaucity of large, publicly available annotated corpora, although initiatives\nthat facilitate data sharing, system evaluation, and collaborative work between\nresearchers in clinical NLP are starting to emerge.",
    "published": "2014-01-03T00:57:13Z",
    "pdf_url": "http://arxiv.org/pdf/1401.0569v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2406.09765v2",
    "title": "Application of Natural Language Processing in Financial Risk Detection",
    "authors": [
      "Liyang Wang",
      "Yu Cheng",
      "Ao Xiang",
      "Jingyu Zhang",
      "Haowei Yang"
    ],
    "abstract": "This paper explores the application of Natural Language Processing (NLP) in\nfinancial risk detection. By constructing an NLP-based financial risk detection\nmodel, this study aims to identify and predict potential risks in financial\ndocuments and communications. First, the fundamental concepts of NLP and its\ntheoretical foundation, including text mining methods, NLP model design\nprinciples, and machine learning algorithms, are introduced. Second, the\nprocess of text data preprocessing and feature extraction is described.\nFinally, the effectiveness and predictive performance of the model are\nvalidated through empirical research. The results show that the NLP-based\nfinancial risk detection model performs excellently in risk identification and\nprediction, providing effective risk management tools for financial\ninstitutions. This study offers valuable references for the field of financial\nrisk management, utilizing advanced NLP techniques to improve the accuracy and\nefficiency of financial risk detection.",
    "published": "2024-06-14T07:06:24Z",
    "pdf_url": "http://arxiv.org/pdf/2406.09765v2",
    "categories": [
      "q-fin.RM",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "1702.01923v1",
    "title": "Comparative Study of CNN and RNN for Natural Language Processing",
    "authors": [
      "Wenpeng Yin",
      "Katharina Kann",
      "Mo Yu",
      "Hinrich Schütze"
    ],
    "abstract": "Deep neural networks (DNN) have revolutionized the field of natural language\nprocessing (NLP). Convolutional neural network (CNN) and recurrent neural\nnetwork (RNN), the two main types of DNN architectures, are widely explored to\nhandle various NLP tasks. CNN is supposed to be good at extracting\nposition-invariant features and RNN at modeling units in sequence. The state of\nthe art on many NLP tasks often switches due to the battle between CNNs and\nRNNs. This work is the first systematic comparison of CNN and RNN on a wide\nrange of representative NLP tasks, aiming to give basic guidance for DNN\nselection.",
    "published": "2017-02-07T08:33:35Z",
    "pdf_url": "http://arxiv.org/pdf/1702.01923v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2209.06169v1",
    "title": "The Role of Explanatory Value in Natural Language Processing",
    "authors": [
      "Kees van Deemter"
    ],
    "abstract": "A key aim of science is explanation, yet the idea of explaining language\nphenomena has taken a backseat in mainstream Natural Language Processing (NLP)\nand many other areas of Artificial Intelligence. I argue that explanation of\nlinguistic behaviour should be a main goal of NLP, and that this is not the\nsame as making NLP models explainable. To illustrate these ideas, some recent\nmodels of human language production are compared with each other. I conclude by\nasking what it would mean for NLP research and institutional policies if our\ncommunity took explanatory value seriously, while heeding some possible\npitfalls.",
    "published": "2022-09-13T17:19:04Z",
    "pdf_url": "http://arxiv.org/pdf/2209.06169v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2410.16498v2",
    "title": "Natural Language Processing for Human Resources: A Survey",
    "authors": [
      "Naoki Otani",
      "Nikita Bhutani",
      "Estevam Hruschka"
    ],
    "abstract": "Advances in Natural Language Processing (NLP) have the potential to transform\nHR processes, from recruitment to employee management. While recent\nbreakthroughs in NLP have generated significant interest in its industrial\napplications, a comprehensive overview of how NLP can be applied across HR\nactivities is still lacking. This paper discovers opportunities for researchers\nand practitioners to harness NLP's transformative potential in this domain. We\nanalyze key fundamental tasks such as information extraction and text\nclassification, and their roles in downstream applications like recommendation\nand language generation, while also discussing ethical concerns. Additionally,\nwe identify gaps in current research and encourage future work to explore\nholistic approaches for achieving broader objectives in this field.",
    "published": "2024-10-21T20:41:00Z",
    "pdf_url": "http://arxiv.org/pdf/2410.16498v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2204.04282v1",
    "title": "Classification of Natural Language Processing Techniques for\n  Requirements Engineering",
    "authors": [
      "Liping Zhao",
      "Waad Alhoshan",
      "Alessio Ferrari",
      "Keletso J. Letsholo"
    ],
    "abstract": "Research in applying natural language processing (NLP) techniques to\nrequirements engineering (RE) tasks spans more than 40 years, from initial\nefforts carried out in the 1980s to more recent attempts with machine learning\n(ML) and deep learning (DL) techniques. However, in spite of the progress, our\nrecent survey shows that there is still a lack of systematic understanding and\norganization of commonly used NLP techniques in RE. We believe one hurdle\nfacing the industry is lack of shared knowledge of NLP techniques and their\nusage in RE tasks. In this paper, we present our effort to synthesize and\norganize 57 most frequently used NLP techniques in RE. We classify these NLP\ntechniques in two ways: first, by their NLP tasks in typical pipelines and\nsecond, by their linguist analysis levels. We believe these two ways of\nclassification are complementary, contributing to a better understanding of the\nNLP techniques in RE and such understanding is crucial to the development of\nbetter NLP tools for RE.",
    "published": "2022-04-08T20:28:00Z",
    "pdf_url": "http://arxiv.org/pdf/2204.04282v1",
    "categories": [
      "cs.CL",
      "cs.SE",
      "68-02",
      "A.1; D.m; I.7.m"
    ]
  },
  {
    "arxiv_id": "2108.04674v2",
    "title": "Natural Language Processing with Commonsense Knowledge: A Survey",
    "authors": [
      "Yubo Xie",
      "Zonghui Liu",
      "Zongyang Ma",
      "Fanyuan Meng",
      "Yan Xiao",
      "Fahui Miao",
      "Pearl Pu"
    ],
    "abstract": "Commonsense knowledge is essential for advancing natural language processing\n(NLP) by enabling models to engage in human-like reasoning, which requires a\ndeeper understanding of context and often involves making inferences based on\nimplicit external knowledge. This paper explores the integration of commonsense\nknowledge into various NLP tasks. We begin by reviewing prominent commonsense\nknowledge bases and then discuss the benchmarks used to evaluate the\ncommonsense reasoning capabilities of NLP models, particularly language models.\nFurthermore, we highlight key methodologies for incorporating commonsense\nknowledge and their applications across different NLP tasks. The paper also\nexamines the challenges and emerging trends in enhancing NLP systems with\ncommonsense reasoning. All literature referenced in this survey can be accessed\nvia our GitHub repository: https://github.com/yuboxie/awesome-commonsense.",
    "published": "2021-08-10T13:25:29Z",
    "pdf_url": "http://arxiv.org/pdf/2108.04674v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "1906.08976v1",
    "title": "Mitigating Gender Bias in Natural Language Processing: Literature Review",
    "authors": [
      "Tony Sun",
      "Andrew Gaut",
      "Shirlyn Tang",
      "Yuxin Huang",
      "Mai ElSherief",
      "Jieyu Zhao",
      "Diba Mirza",
      "Elizabeth Belding",
      "Kai-Wei Chang",
      "William Yang Wang"
    ],
    "abstract": "As Natural Language Processing (NLP) and Machine Learning (ML) tools rise in\npopularity, it becomes increasingly vital to recognize the role they play in\nshaping societal biases and stereotypes. Although NLP models have shown success\nin modeling various applications, they propagate and may even amplify gender\nbias found in text corpora. While the study of bias in artificial intelligence\nis not new, methods to mitigate gender bias in NLP are relatively nascent. In\nthis paper, we review contemporary studies on recognizing and mitigating gender\nbias in NLP. We discuss gender bias based on four forms of representation bias\nand analyze methods recognizing gender bias. Furthermore, we discuss the\nadvantages and drawbacks of existing gender debiasing methods. Finally, we\ndiscuss future studies for recognizing and mitigating gender bias in NLP.",
    "published": "2019-06-21T06:39:11Z",
    "pdf_url": "http://arxiv.org/pdf/1906.08976v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2109.09138v2",
    "title": "Multi-Task Learning in Natural Language Processing: An Overview",
    "authors": [
      "Shijie Chen",
      "Yu Zhang",
      "Qiang Yang"
    ],
    "abstract": "Deep learning approaches have achieved great success in the field of Natural\nLanguage Processing (NLP). However, directly training deep neural models often\nsuffer from overfitting and data scarcity problems that are pervasive in NLP\ntasks. In recent years, Multi-Task Learning (MTL), which can leverage useful\ninformation of related tasks to achieve simultaneous performance improvement on\nthese tasks, has been used to handle these problems. In this paper, we give an\noverview of the use of MTL in NLP tasks. We first review MTL architectures used\nin NLP tasks and categorize them into four classes, including parallel\narchitecture, hierarchical architecture, modular architecture, and generative\nadversarial architecture. Then we present optimization techniques on loss\nconstruction, gradient regularization, data sampling, and task scheduling to\nproperly train a multi-task model. After presenting applications of MTL in a\nvariety of NLP tasks, we introduce some benchmark datasets. Finally, we make a\nconclusion and discuss several possible research directions in this field.",
    "published": "2021-09-19T14:51:51Z",
    "pdf_url": "http://arxiv.org/pdf/2109.09138v2",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2201.00768v1",
    "title": "Robust Natural Language Processing: Recent Advances, Challenges, and\n  Future Directions",
    "authors": [
      "Marwan Omar",
      "Soohyeon Choi",
      "DaeHun Nyang",
      "David Mohaisen"
    ],
    "abstract": "Recent natural language processing (NLP) techniques have accomplished high\nperformance on benchmark datasets, primarily due to the significant improvement\nin the performance of deep learning. The advances in the research community\nhave led to great enhancements in state-of-the-art production systems for NLP\ntasks, such as virtual assistants, speech recognition, and sentiment analysis.\nHowever, such NLP systems still often fail when tested with adversarial\nattacks. The initial lack of robustness exposed troubling gaps in current\nmodels' language understanding capabilities, creating problems when NLP systems\nare deployed in real life. In this paper, we present a structured overview of\nNLP robustness research by summarizing the literature in a systemic way across\nvarious dimensions. We then take a deep-dive into the various dimensions of\nrobustness, across techniques, metrics, embeddings, and benchmarks. Finally, we\nargue that robustness should be multi-dimensional, provide insights into\ncurrent research, identify gaps in the literature to suggest directions worth\npursuing to address these gaps.",
    "published": "2022-01-03T17:17:11Z",
    "pdf_url": "http://arxiv.org/pdf/2201.00768v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.HC",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2208.08140v1",
    "title": "Differential Privacy in Natural Language Processing: The Story So Far",
    "authors": [
      "Oleksandra Klymenko",
      "Stephen Meisenbacher",
      "Florian Matthes"
    ],
    "abstract": "As the tide of Big Data continues to influence the landscape of Natural\nLanguage Processing (NLP), the utilization of modern NLP methods has grounded\nitself in this data, in order to tackle a variety of text-based tasks. These\nmethods without a doubt can include private or otherwise personally\nidentifiable information. As such, the question of privacy in NLP has gained\nfervor in recent years, coinciding with the development of new\nPrivacy-Enhancing Technologies (PETs). Among these PETs, Differential Privacy\nboasts several desirable qualities in the conversation surrounding data\nprivacy. Naturally, the question becomes whether Differential Privacy is\napplicable in the largely unstructured realm of NLP. This topic has sparked\nnovel research, which is unified in one basic goal: how can one adapt\nDifferential Privacy to NLP methods? This paper aims to summarize the\nvulnerabilities addressed by Differential Privacy, the current thinking, and\nabove all, the crucial next steps that must be considered.",
    "published": "2022-08-17T08:15:44Z",
    "pdf_url": "http://arxiv.org/pdf/2208.08140v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2309.10880v1",
    "title": "Classifying Organizations for Food System Ontologies using Natural\n  Language Processing",
    "authors": [
      "Tianyu Jiang",
      "Sonia Vinogradova",
      "Nathan Stringham",
      "E. Louise Earl",
      "Allan D. Hollander",
      "Patrick R. Huber",
      "Ellen Riloff",
      "R. Sandra Schillo",
      "Giorgio A. Ubbiali",
      "Matthew Lange"
    ],
    "abstract": "Our research explores the use of natural language processing (NLP) methods to\nautomatically classify entities for the purpose of knowledge graph population\nand integration with food system ontologies. We have created NLP models that\ncan automatically classify organizations with respect to categories associated\nwith environmental issues as well as Standard Industrial Classification (SIC)\ncodes, which are used by the U.S. government to characterize business\nactivities. As input, the NLP models are provided with text snippets retrieved\nby the Google search engine for each organization, which serves as a textual\ndescription of the organization that is used for learning. Our experimental\nresults show that NLP models can achieve reasonably good performance for these\ntwo classification tasks, and they rely on a general framework that could be\napplied to many other classification problems as well. We believe that NLP\nmodels represent a promising approach for automatically harvesting information\nto populate knowledge graphs and aligning the information with existing\nontologies through shared categories and concepts.",
    "published": "2023-09-19T19:07:48Z",
    "pdf_url": "http://arxiv.org/pdf/2309.10880v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.IR",
      "H.3.1; I.2.7; J.3; J.4; K.4.3"
    ]
  },
  {
    "arxiv_id": "2106.06090v2",
    "title": "Graph Neural Networks for Natural Language Processing: A Survey",
    "authors": [
      "Lingfei Wu",
      "Yu Chen",
      "Kai Shen",
      "Xiaojie Guo",
      "Hanning Gao",
      "Shucheng Li",
      "Jian Pei",
      "Bo Long"
    ],
    "abstract": "Deep learning has become the dominant approach in coping with various tasks\nin Natural LanguageProcessing (NLP). Although text inputs are typically\nrepresented as a sequence of tokens, there isa rich variety of NLP problems\nthat can be best expressed with a graph structure. As a result, thereis a surge\nof interests in developing new deep learning techniques on graphs for a large\nnumberof NLP tasks. In this survey, we present a comprehensive overview onGraph\nNeural Networks(GNNs) for Natural Language Processing. We propose a new\ntaxonomy of GNNs for NLP, whichsystematically organizes existing research of\nGNNs for NLP along three axes: graph construction,graph representation\nlearning, and graph based encoder-decoder models. We further introducea large\nnumber of NLP applications that are exploiting the power of GNNs and summarize\nthecorresponding benchmark datasets, evaluation metrics, and open-source codes.\nFinally, we discussvarious outstanding challenges for making the full use of\nGNNs for NLP as well as future researchdirections. To the best of our\nknowledge, this is the first comprehensive overview of Graph NeuralNetworks for\nNatural Language Processing.",
    "published": "2021-06-10T23:59:26Z",
    "pdf_url": "http://arxiv.org/pdf/2106.06090v2",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2106.07410v1",
    "title": "Model Explainability in Deep Learning Based Natural Language Processing",
    "authors": [
      "Shafie Gholizadeh",
      "Nengfeng Zhou"
    ],
    "abstract": "Machine learning (ML) model explainability has received growing attention,\nespecially in the area related to model risk and regulations. In this paper, we\nreviewed and compared some popular ML model explainability methodologies,\nespecially those related to Natural Language Processing (NLP) models. We then\napplied one of the NLP explainability methods Layer-wise Relevance Propagation\n(LRP) to a NLP classification model. We used the LRP method to derive a\nrelevance score for each word in an instance, which is a local explainability.\nThe relevance scores are then aggregated together to achieve global variable\nimportance of the model. Through the case study, we also demonstrated how to\napply the local explainability method to false positive and false negative\ninstances to discover the weakness of a NLP model. These analysis can help us\nto understand NLP models better and reduce the risk due to the black-box nature\nof NLP models. We also identified some common issues due to the special natures\nof NLP models and discussed how explainability analysis can act as a control to\ndetect these issues after the model has been trained.",
    "published": "2021-06-14T13:23:20Z",
    "pdf_url": "http://arxiv.org/pdf/2106.07410v1",
    "categories": [
      "cs.AI",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2210.06929v1",
    "title": "On the Explainability of Natural Language Processing Deep Models",
    "authors": [
      "Julia El Zini",
      "Mariette Awad"
    ],
    "abstract": "While there has been a recent explosion of work on ExplainableAI ExAI on deep\nmodels that operate on imagery and tabular data, textual datasets present new\nchallenges to the ExAI community. Such challenges can be attributed to the lack\nof input structure in textual data, the use of word embeddings that add to the\nopacity of the models and the difficulty of the visualization of the inner\nworkings of deep models when they are trained on textual data.\n  Lately, methods have been developed to address the aforementioned challenges\nand present satisfactory explanations on Natural Language Processing (NLP)\nmodels. However, such methods are yet to be studied in a comprehensive\nframework where common challenges are properly stated and rigorous evaluation\npractices and metrics are proposed. Motivated to democratize ExAI methods in\nthe NLP field, we present in this work a survey that studies model-agnostic as\nwell as model-specific explainability methods on NLP models. Such methods can\neither develop inherently interpretable NLP models or operate on pre-trained\nmodels in a post-hoc manner. We make this distinction and we further decompose\nthe methods into three categories according to what they explain: (1) word\nembeddings (input-level), (2) inner workings of NLP models (processing-level)\nand (3) models' decisions (output-level). We also detail the different\nevaluation approaches interpretability methods in the NLP field. Finally, we\npresent a case-study on the well-known neural machine translation in an\nappendix and we propose promising future research directions for ExAI in the\nNLP field.",
    "published": "2022-10-13T11:59:39Z",
    "pdf_url": "http://arxiv.org/pdf/2210.06929v1",
    "categories": [
      "cs.CL",
      "cs.HC"
    ]
  },
  {
    "arxiv_id": "2401.01262v2",
    "title": "Fairness Certification for Natural Language Processing and Large\n  Language Models",
    "authors": [
      "Vincent Freiberger",
      "Erik Buchmann"
    ],
    "abstract": "Natural Language Processing (NLP) plays an important role in our daily lives,\nparticularly due to the enormous progress of Large Language Models (LLM).\nHowever, NLP has many fairness-critical use cases, e.g., as an expert system in\nrecruitment or as an LLM-based tutor in education. Since NLP is based on human\nlanguage, potentially harmful biases can diffuse into NLP systems and produce\nunfair results, discriminate against minorities or generate legal issues.\nHence, it is important to develop a fairness certification for NLP approaches.\nWe follow a qualitative research approach towards a fairness certification for\nNLP. In particular, we have reviewed a large body of literature on algorithmic\nfairness, and we have conducted semi-structured expert interviews with a wide\nrange of experts from that area. We have systematically devised six fairness\ncriteria for NLP, which can be further refined into 18 sub-categories. Our\ncriteria offer a foundation for operationalizing and testing processes to\ncertify fairness, both from the perspective of the auditor and the audited\norganization.",
    "published": "2024-01-02T16:09:36Z",
    "pdf_url": "http://arxiv.org/pdf/2401.01262v2",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "68T50",
      "I.2.7"
    ]
  },
  {
    "arxiv_id": "1708.02709v8",
    "title": "Recent Trends in Deep Learning Based Natural Language Processing",
    "authors": [
      "Tom Young",
      "Devamanyu Hazarika",
      "Soujanya Poria",
      "Erik Cambria"
    ],
    "abstract": "Deep learning methods employ multiple processing layers to learn hierarchical\nrepresentations of data and have produced state-of-the-art results in many\ndomains. Recently, a variety of model designs and methods have blossomed in the\ncontext of natural language processing (NLP). In this paper, we review\nsignificant deep learning related models and methods that have been employed\nfor numerous NLP tasks and provide a walk-through of their evolution. We also\nsummarize, compare and contrast the various models and put forward a detailed\nunderstanding of the past, present and future of deep learning in NLP.",
    "published": "2017-08-09T04:02:17Z",
    "pdf_url": "http://arxiv.org/pdf/1708.02709v8",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2209.00099v2",
    "title": "Efficient Methods for Natural Language Processing: A Survey",
    "authors": [
      "Marcos Treviso",
      "Ji-Ung Lee",
      "Tianchu Ji",
      "Betty van Aken",
      "Qingqing Cao",
      "Manuel R. Ciosici",
      "Michael Hassid",
      "Kenneth Heafield",
      "Sara Hooker",
      "Colin Raffel",
      "Pedro H. Martins",
      "André F. T. Martins",
      "Jessica Zosa Forde",
      "Peter Milder",
      "Edwin Simpson",
      "Noam Slonim",
      "Jesse Dodge",
      "Emma Strubell",
      "Niranjan Balasubramanian",
      "Leon Derczynski",
      "Iryna Gurevych",
      "Roy Schwartz"
    ],
    "abstract": "Recent work in natural language processing (NLP) has yielded appealing\nresults from scaling model parameters and training data; however, using only\nscale to improve performance means that resource consumption also grows. Such\nresources include data, time, storage, or energy, all of which are naturally\nlimited and unevenly distributed. This motivates research into efficient\nmethods that require fewer resources to achieve similar results. This survey\nsynthesizes and relates current methods and findings in efficient NLP. We aim\nto provide both guidance for conducting NLP under limited resources, and point\ntowards promising research directions for developing more efficient methods.",
    "published": "2022-08-31T20:32:35Z",
    "pdf_url": "http://arxiv.org/pdf/2209.00099v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2003.08271v4",
    "title": "Pre-trained Models for Natural Language Processing: A Survey",
    "authors": [
      "Xipeng Qiu",
      "Tianxiang Sun",
      "Yige Xu",
      "Yunfan Shao",
      "Ning Dai",
      "Xuanjing Huang"
    ],
    "abstract": "Recently, the emergence of pre-trained models (PTMs) has brought natural\nlanguage processing (NLP) to a new era. In this survey, we provide a\ncomprehensive review of PTMs for NLP. We first briefly introduce language\nrepresentation learning and its research progress. Then we systematically\ncategorize existing PTMs based on a taxonomy with four perspectives. Next, we\ndescribe how to adapt the knowledge of PTMs to the downstream tasks. Finally,\nwe outline some potential directions of PTMs for future research. This survey\nis purposed to be a hands-on guide for understanding, using, and developing\nPTMs for various NLP tasks.",
    "published": "2020-03-18T15:22:51Z",
    "pdf_url": "http://arxiv.org/pdf/2003.08271v4",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2204.09591v1",
    "title": "A Survey on Bias and Fairness in Natural Language Processing",
    "authors": [
      "Rajas Bansal"
    ],
    "abstract": "As NLP models become more integrated with the everyday lives of people, it\nbecomes important to examine the social effect that the usage of these systems\nhas. While these models understand language and have increased accuracy on\ndifficult downstream tasks, there is evidence that these models amplify gender,\nracial and cultural stereotypes and lead to a vicious cycle in many settings.\nIn this survey, we analyze the origins of biases, the definitions of fairness,\nand how different subfields of NLP mitigate bias. We finally discuss how future\nstudies can work towards eradicating pernicious biases from NLP algorithms.",
    "published": "2022-03-06T18:12:30Z",
    "pdf_url": "http://arxiv.org/pdf/2204.09591v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2405.01976v1",
    "title": "Conformal Prediction for Natural Language Processing: A Survey",
    "authors": [
      "Margarida M. Campos",
      "António Farinhas",
      "Chrysoula Zerva",
      "Mário A. T. Figueiredo",
      "André F. T. Martins"
    ],
    "abstract": "The rapid proliferation of large language models and natural language\nprocessing (NLP) applications creates a crucial need for uncertainty\nquantification to mitigate risks such as hallucinations and to enhance\ndecision-making reliability in critical applications. Conformal prediction is\nemerging as a theoretically sound and practically useful framework, combining\nflexibility with strong statistical guarantees. Its model-agnostic and\ndistribution-free nature makes it particularly promising to address the current\nshortcomings of NLP systems that stem from the absence of uncertainty\nquantification. This paper provides a comprehensive survey of conformal\nprediction techniques, their guarantees, and existing applications in NLP,\npointing to directions for future research and open challenges.",
    "published": "2024-05-03T10:00:45Z",
    "pdf_url": "http://arxiv.org/pdf/2405.01976v1",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1311.6063v5",
    "title": "NILE: Fast Natural Language Processing for Electronic Health Records",
    "authors": [
      "Sheng Yu",
      "Tianrun Cai",
      "Tianxi Cai"
    ],
    "abstract": "Objective: Narrative text in Electronic health records (EHR) contain rich\ninformation for medical and data science studies. This paper introduces the\ndesign and performance of Narrative Information Linear Extraction (NILE), a\nnatural language processing (NLP) package for EHR analysis that we share with\nthe medical informatics community. Methods: NILE uses a modified prefix-tree\nsearch algorithm for named entity recognition, which can detect prefix and\nsuffix sharing. The semantic analyses are implemented as rule-based finite\nstate machines. Analyses include negation, location, modification, family\nhistory, and ignoring. Result: The processing speed of NILE is hundreds to\nthousands times faster than existing NLP software for medical text. The\naccuracy of presence analysis of NILE is on par with the best performing models\non the 2010 i2b2/VA NLP challenge data. Conclusion: The speed, accuracy, and\nbeing able to operate via API make NILE a valuable addition to the NLP software\nfor medical informatics and data science.",
    "published": "2013-11-23T22:39:52Z",
    "pdf_url": "http://arxiv.org/pdf/1311.6063v5",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2004.13832v1",
    "title": "Towards an evolutionary-based approach for natural language processing",
    "authors": [
      "Luca Manzoni",
      "Domagoj Jakobovic",
      "Luca Mariot",
      "Stjepan Picek",
      "Mauro Castelli"
    ],
    "abstract": "Tasks related to Natural Language Processing (NLP) have recently been the\nfocus of a large research endeavor by the machine learning community. The\nincreased interest in this area is mainly due to the success of deep learning\nmethods. Genetic Programming (GP), however, was not under the spotlight with\nrespect to NLP tasks. Here, we propose a first proof-of-concept that combines\nGP with the well established NLP tool word2vec for the next word prediction\ntask. The main idea is that, once words have been moved into a vector space,\ntraditional GP operators can successfully work on vectors, thus producing\nmeaningful words as the output. To assess the suitability of this approach, we\nperform an experimental evaluation on a set of existing newspaper headlines.\nIndividuals resulting from this (pre-)training phase can be employed as the\ninitial population in other NLP tasks, like sentence generation, which will be\nthe focus of future investigations, possibly employing adversarial\nco-evolutionary approaches.",
    "published": "2020-04-23T18:44:12Z",
    "pdf_url": "http://arxiv.org/pdf/2004.13832v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "2003.01200v4",
    "title": "Natural Language Processing Advancements By Deep Learning: A Survey",
    "authors": [
      "Amirsina Torfi",
      "Rouzbeh A. Shirvani",
      "Yaser Keneshloo",
      "Nader Tavaf",
      "Edward A. Fox"
    ],
    "abstract": "Natural Language Processing (NLP) helps empower intelligent machines by\nenhancing a better understanding of the human language for linguistic-based\nhuman-computer communication. Recent developments in computational power and\nthe advent of large amounts of linguistic data have heightened the need and\ndemand for automating semantic analysis using data-driven approaches. The\nutilization of data-driven strategies is pervasive now due to the significant\nimprovements demonstrated through the usage of deep learning methods in areas\nsuch as Computer Vision, Automatic Speech Recognition, and in particular, NLP.\nThis survey categorizes and addresses the different aspects and applications of\nNLP that have benefited from deep learning. It covers core NLP tasks and\napplications and describes how deep learning methods and models advance these\nareas. We further analyze and compare different approaches and state-of-the-art\nmodels.",
    "published": "2020-03-02T21:32:05Z",
    "pdf_url": "http://arxiv.org/pdf/2003.01200v4",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2106.10512v1",
    "title": "TweeNLP: A Twitter Exploration Portal for Natural Language Processing",
    "authors": [
      "Viraj Shah",
      "Shruti Singh",
      "Mayank Singh"
    ],
    "abstract": "We present TweeNLP, a one-stop portal that organizes Twitter's natural\nlanguage processing (NLP) data and builds a visualization and exploration\nplatform. It curates 19,395 tweets (as of April 2021) from various NLP\nconferences and general NLP discussions. It supports multiple features such as\nTweetExplorer to explore tweets by topics, visualize insights from Twitter\nactivity throughout the organization cycle of conferences, discover popular\nresearch papers and researchers. It also builds a timeline of conference and\nworkshop submission deadlines. We envision TweeNLP to function as a collective\nmemory unit for the NLP community by integrating the tweets pertaining to\nresearch papers with the NLPExplorer scientific literature search engine. The\ncurrent system is hosted at http://nlpexplorer.org/twitter/CFP .",
    "published": "2021-06-19T15:11:22Z",
    "pdf_url": "http://arxiv.org/pdf/2106.10512v1",
    "categories": [
      "cs.CL",
      "cs.SI"
    ]
  },
  {
    "arxiv_id": "2111.13827v3",
    "title": "Natural Language Processing in-and-for Design Research",
    "authors": [
      "L Siddharth",
      "Lucienne T. M. Blessing",
      "Jianxi Luo"
    ],
    "abstract": "We review the scholarly contributions that utilise Natural Language\nProcessing (NLP) techniques to support the design process. Using a heuristic\napproach, we gathered 223 articles that are published in 32 journals within the\nperiod 1991-present. We present state-of-the-art NLP in-and-for design research\nby reviewing these articles according to the type of natural language text\nsources: internal reports, design concepts, discourse transcripts, technical\npublications, consumer opinions, and others. Upon summarizing and identifying\nthe gaps in these contributions, we utilise an existing design innovation\nframework to identify the applications that are currently being supported by\nNLP. We then propose a few methodological and theoretical directions for future\nNLP in-and-for design research.",
    "published": "2021-11-27T06:32:54Z",
    "pdf_url": "http://arxiv.org/pdf/2111.13827v3",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DL",
      "cs.IR"
    ]
  },
  {
    "arxiv_id": "2208.06525v1",
    "title": "Automated Utterance Labeling of Conversations Using Natural Language\n  Processing",
    "authors": [
      "Maria Laricheva",
      "Chiyu Zhang",
      "Yan Liu",
      "Guanyu Chen",
      "Terence Tracey",
      "Richard Young",
      "Giuseppe Carenini"
    ],
    "abstract": "Conversational data is essential in psychology because it can help\nresearchers understand individuals cognitive processes, emotions, and\nbehaviors. Utterance labelling is a common strategy for analyzing this type of\ndata. The development of NLP algorithms allows researchers to automate this\ntask. However, psychological conversational data present some challenges to NLP\nresearchers, including multilabel classification, a large number of classes,\nand limited available data. This study explored how automated labels generated\nby NLP methods are comparable to human labels in the context of conversations\non adulthood transition. We proposed strategies to handle three common\nchallenges raised in psychological studies. Our findings showed that the deep\nlearning method with domain adaptation (RoBERTa-CON) outperformed all other\nmachine learning methods; and the hierarchical labelling system that we\nproposed was shown to help researchers strategically analyze conversational\ndata. Our Python code and NLP model are available at\nhttps://github.com/mlaricheva/automated_labeling.",
    "published": "2022-08-12T23:03:45Z",
    "pdf_url": "http://arxiv.org/pdf/2208.06525v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2302.14286v1",
    "title": "HugNLP: A Unified and Comprehensive Library for Natural Language\n  Processing",
    "authors": [
      "Jianing Wang",
      "Nuo Chen",
      "Qiushi Sun",
      "Wenkang Huang",
      "Chengyu Wang",
      "Ming Gao"
    ],
    "abstract": "In this paper, we introduce HugNLP, a unified and comprehensive library for\nnatural language processing (NLP) with the prevalent backend of HuggingFace\nTransformers, which is designed for NLP researchers to easily utilize\noff-the-shelf algorithms and develop novel methods with user-defined models and\ntasks in real-world scenarios. HugNLP consists of a hierarchical structure\nincluding models, processors and applications that unifies the learning process\nof pre-trained language models (PLMs) on different NLP tasks. Additionally, we\npresent some featured NLP applications to show the effectiveness of HugNLP,\nsuch as knowledge-enhanced PLMs, universal information extraction, low-resource\nmining, and code understanding and generation, etc. The source code will be\nreleased on GitHub (https://github.com/wjn1996/HugNLP).",
    "published": "2023-02-28T03:38:26Z",
    "pdf_url": "http://arxiv.org/pdf/2302.14286v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2307.10652v5",
    "title": "Exploring the Landscape of Natural Language Processing Research",
    "authors": [
      "Tim Schopf",
      "Karim Arabi",
      "Florian Matthes"
    ],
    "abstract": "As an efficient approach to understand, generate, and process natural\nlanguage texts, research in natural language processing (NLP) has exhibited a\nrapid spread and wide adoption in recent years. Given the increasing research\nwork in this area, several NLP-related approaches have been surveyed in the\nresearch community. However, a comprehensive study that categorizes established\ntopics, identifies trends, and outlines areas for future research remains\nabsent. Contributing to closing this gap, we have systematically classified and\nanalyzed research papers in the ACL Anthology. As a result, we present a\nstructured overview of the research landscape, provide a taxonomy of fields of\nstudy in NLP, analyze recent developments in NLP, summarize our findings, and\nhighlight directions for future work.",
    "published": "2023-07-20T07:33:30Z",
    "pdf_url": "http://arxiv.org/pdf/2307.10652v5",
    "categories": [
      "cs.CL",
      "I.2.7"
    ]
  },
  {
    "arxiv_id": "2503.00624v1",
    "title": "An evaluation of DeepSeek Models in Biomedical Natural Language\n  Processing",
    "authors": [
      "Zaifu Zhan",
      "Shuang Zhou",
      "Huixue Zhou",
      "Jiawen Deng",
      "Yu Hou",
      "Jeremy Yeung",
      "Rui Zhang"
    ],
    "abstract": "The advancement of Large Language Models (LLMs) has significantly impacted\nbiomedical Natural Language Processing (NLP), enhancing tasks such as named\nentity recognition, relation extraction, event extraction, and text\nclassification. In this context, the DeepSeek series of models have shown\npromising potential in general NLP tasks, yet their capabilities in the\nbiomedical domain remain underexplored. This study evaluates multiple DeepSeek\nmodels (Distilled-DeepSeek-R1 series and Deepseek-LLMs) across four key\nbiomedical NLP tasks using 12 datasets, benchmarking them against\nstate-of-the-art alternatives (Llama3-8B, Qwen2.5-7B, Mistral-7B, Phi-4-14B,\nGemma-2-9B). Our results reveal that while DeepSeek models perform\ncompetitively in named entity recognition and text classification, challenges\npersist in event and relation extraction due to precision-recall trade-offs. We\nprovide task-specific model recommendations and highlight future research\ndirections. This evaluation underscores the strengths and limitations of\nDeepSeek models in biomedical NLP, guiding their future deployment and\noptimization.",
    "published": "2025-03-01T21:26:29Z",
    "pdf_url": "http://arxiv.org/pdf/2503.00624v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2505.16061v1",
    "title": "Internal and External Impacts of Natural Language Processing Papers",
    "authors": [
      "Yu Zhang"
    ],
    "abstract": "We investigate the impacts of NLP research published in top-tier conferences\n(i.e., ACL, EMNLP, and NAACL) from 1979 to 2024. By analyzing citations from\nresearch articles and external sources such as patents, media, and policy\ndocuments, we examine how different NLP topics are consumed both within the\nacademic community and by the broader public. Our findings reveal that language\nmodeling has the widest internal and external influence, while linguistic\nfoundations have lower impacts. We also observe that internal and external\nimpacts generally align, but topics like ethics, bias, and fairness show\nsignificant attention in policy documents with much fewer academic citations.\nAdditionally, external domains exhibit distinct preferences, with patents\nfocusing on practical NLP applications and media and policy documents engaging\nmore with the societal implications of NLP models.",
    "published": "2025-05-21T22:25:58Z",
    "pdf_url": "http://arxiv.org/pdf/2505.16061v1",
    "categories": [
      "cs.CL",
      "cs.DL"
    ]
  },
  {
    "arxiv_id": "9704010v1",
    "title": "The Theoretical Status of Ontologies in Natural Language Processing",
    "authors": [
      "John A. Bateman"
    ],
    "abstract": "This paper discusses the use of `ontologies' in Natural Language Processing.\nIt classifies various kinds of ontologies that have been employed in NLP and\ndiscusses various benefits and problems with those designs. Particular focus is\nthen placed on experiences gained in the use of the Upper Model, a\nlinguistically-motivated `ontology' originally designed for use with the Penman\ntext generation system. Some proposals for further NLP ontology design criteria\nare then made.",
    "published": "1997-04-25T13:00:14Z",
    "pdf_url": "http://arxiv.org/pdf/cmp-lg/9704010v1",
    "categories": [
      "cmp-lg",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2210.10109v2",
    "title": "A Survey of Active Learning for Natural Language Processing",
    "authors": [
      "Zhisong Zhang",
      "Emma Strubell",
      "Eduard Hovy"
    ],
    "abstract": "In this work, we provide a survey of active learning (AL) for its\napplications in natural language processing (NLP). In addition to a\nfine-grained categorization of query strategies, we also investigate several\nother important aspects of applying AL to NLP problems. These include AL for\nstructured prediction tasks, annotation cost, model learning (especially with\ndeep neural models), and starting and stopping AL. Finally, we conclude with a\ndiscussion of related topics and future directions.",
    "published": "2022-10-18T19:14:42Z",
    "pdf_url": "http://arxiv.org/pdf/2210.10109v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2405.06563v1",
    "title": "What Can Natural Language Processing Do for Peer Review?",
    "authors": [
      "Ilia Kuznetsov",
      "Osama Mohammed Afzal",
      "Koen Dercksen",
      "Nils Dycke",
      "Alexander Goldberg",
      "Tom Hope",
      "Dirk Hovy",
      "Jonathan K. Kummerfeld",
      "Anne Lauscher",
      "Kevin Leyton-Brown",
      "Sheng Lu",
      "Mausam",
      "Margot Mieskes",
      "Aurélie Névéol",
      "Danish Pruthi",
      "Lizhen Qu",
      "Roy Schwartz",
      "Noah A. Smith",
      "Thamar Solorio",
      "Jingyan Wang",
      "Xiaodan Zhu",
      "Anna Rogers",
      "Nihar B. Shah",
      "Iryna Gurevych"
    ],
    "abstract": "The number of scientific articles produced every year is growing rapidly.\nProviding quality control over them is crucial for scientists and, ultimately,\nfor the public good. In modern science, this process is largely delegated to\npeer review -- a distributed procedure in which each submission is evaluated by\nseveral independent experts in the field. Peer review is widely used, yet it is\nhard, time-consuming, and prone to error. Since the artifacts involved in peer\nreview -- manuscripts, reviews, discussions -- are largely text-based, Natural\nLanguage Processing has great potential to improve reviewing. As the emergence\nof large language models (LLMs) has enabled NLP assistance for many new tasks,\nthe discussion on machine-assisted peer review is picking up the pace. Yet,\nwhere exactly is help needed, where can NLP help, and where should it stand\naside? The goal of our paper is to provide a foundation for the future efforts\nin NLP for peer-reviewing assistance. We discuss peer review as a general\nprocess, exemplified by reviewing at AI conferences. We detail each step of the\nprocess from manuscript submission to camera-ready revision, and discuss the\nassociated challenges and opportunities for NLP assistance, illustrated by\nexisting work. We then turn to the big challenges in NLP for peer review as a\nwhole, including data acquisition and licensing, operationalization and\nexperimentation, and ethical issues. To help consolidate community efforts, we\ncreate a companion repository that aggregates key datasets pertaining to peer\nreview. Finally, we issue a detailed call for action for the scientific\ncommunity, NLP and AI researchers, policymakers, and funding bodies to help\nbring the research in NLP for peer review forward. We hope that our work will\nhelp set the agenda for research in machine-assisted scientific quality control\nin the age of AI, within the NLP community and beyond.",
    "published": "2024-05-10T16:06:43Z",
    "pdf_url": "http://arxiv.org/pdf/2405.06563v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2401.05632v4",
    "title": "Natural Language Processing for Dialects of a Language: A Survey",
    "authors": [
      "Aditya Joshi",
      "Raj Dabre",
      "Diptesh Kanojia",
      "Zhuang Li",
      "Haolan Zhan",
      "Gholamreza Haffari",
      "Doris Dippold"
    ],
    "abstract": "State-of-the-art natural language processing (NLP) models are trained on\nmassive training corpora, and report a superlative performance on evaluation\ndatasets. This survey delves into an important attribute of these datasets: the\ndialect of a language. Motivated by the performance degradation of NLP models\nfor dialectal datasets and its implications for the equity of language\ntechnologies, we survey past research in NLP for dialects in terms of datasets,\nand approaches. We describe a wide range of NLP tasks in terms of two\ncategories: natural language understanding (NLU) (for tasks such as dialect\nclassification, sentiment analysis, parsing, and NLU benchmarks) and natural\nlanguage generation (NLG) (for summarisation, machine translation, and dialogue\nsystems). The survey is also broad in its coverage of languages which include\nEnglish, Arabic, German, among others. We observe that past work in NLP\nconcerning dialects goes deeper than mere dialect classification, and extends\nto several NLU and NLG tasks. For these tasks, we describe classical machine\nlearning using statistical models, along with the recent deep learning-based\napproaches based on pre-trained language models. We expect that this survey\nwill be useful to NLP researchers interested in building equitable language\ntechnologies by rethinking LLM benchmarks and model architectures.",
    "published": "2024-01-11T03:04:38Z",
    "pdf_url": "http://arxiv.org/pdf/2401.05632v4",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2412.15471v2",
    "title": "A Review of the Marathi Natural Language Processing",
    "authors": [
      "Asang Dani",
      "Shailesh R Sathe"
    ],
    "abstract": "Marathi is one of the most widely used languages in the world. One might\nexpect that the latest advances in NLP research in languages like English reach\nsuch a large community. However, NLP advancements in English didn't immediately\nreach Indian languages like Marathi. There were several reasons for this. They\nincluded diversity of scripts used, lack of (publicly available) resources like\ntokenization strategies, high quality datasets \\& benchmarks, and evaluation\nmetrics. In addition to this, the morphologically rich nature of Marathi, made\nNLP tasks challenging. Advances in Neural Network (NN) based models and tools\nsince the early 2000s helped improve this situation and make NLP research more\naccessible. In the past 10 years, significant efforts were made to improve\nlanguage resources for all 22 scheduled languages of India. This paper presents\na broad overview of evolution of NLP research in Indic languages with a focus\non Marathi and state-of-the-art resources and tools available to the research\ncommunity. It also provides an overview of tools \\& techniques associated with\nMarathi NLP tasks.",
    "published": "2024-12-20T00:56:13Z",
    "pdf_url": "http://arxiv.org/pdf/2412.15471v2",
    "categories": [
      "cs.CL",
      "I.2.7"
    ]
  },
  {
    "arxiv_id": "2501.10319v1",
    "title": "Natural Language Processing of Privacy Policies: A Survey",
    "authors": [
      "Andrick Adhikari",
      "Sanchari Das",
      "Rinku Dewri"
    ],
    "abstract": "Natural Language Processing (NLP) is an essential subset of artificial\nintelligence. It has become effective in several domains, such as healthcare,\nfinance, and media, to identify perceptions, opinions, and misuse, among\nothers. Privacy is no exception, and initiatives have been taken to address the\nchallenges of usable privacy notifications to users with the help of NLP. To\nthis aid, we conduct a literature review by analyzing 109 papers at the\nintersection of NLP and privacy policies. First, we provide a brief\nintroduction to privacy policies and discuss various facets of associated\nproblems, which necessitate the application of NLP to elevate the current state\nof privacy notices and disclosures to users. Subsequently, we a) provide an\noverview of the implementation and effectiveness of NLP approaches for better\nprivacy policy communication; b) identify the methodologies that can be further\nenhanced to provide robust privacy policies; and c) identify the gaps in the\ncurrent state-of-the-art research. Our systematic analysis reveals that several\nresearch papers focus on annotating and classifying privacy texts for analysis\nbut need to adequately dwell on other aspects of NLP applications, such as\nsummarization. More specifically, ample research opportunities exist in this\ndomain, covering aspects such as corpus generation, summarization vectors,\ncontextualized word embedding, identification of privacy-relevant statement\ncategories, fine-grained classification, and domain-specific model tuning.",
    "published": "2025-01-17T17:47:15Z",
    "pdf_url": "http://arxiv.org/pdf/2501.10319v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2506.22481v1",
    "title": "Theories of \"Sexuality\" in Natural Language Processing Bias Research",
    "authors": [
      "Jacob Hobbs"
    ],
    "abstract": "In recent years, significant advancements in the field of Natural Language\nProcessing (NLP) have positioned commercialized language models as\nwide-reaching, highly useful tools. In tandem, there has been an explosion of\nmultidisciplinary research examining how NLP tasks reflect, perpetuate, and\namplify social biases such as gender and racial bias. A significant gap in this\nscholarship is a detailed analysis of how queer sexualities are encoded and\n(mis)represented by both NLP systems and practitioners. Following previous work\nin the field of AI fairness, we document how sexuality is defined and\noperationalized via a survey and analysis of 55 articles that quantify\nsexuality-based NLP bias. We find that sexuality is not clearly defined in a\nmajority of the literature surveyed, indicating a reliance on assumed or\nnormative conceptions of sexual/romantic practices and identities. Further, we\nfind that methods for extracting biased outputs from NLP technologies often\nconflate gender and sexual identities, leading to monolithic conceptions of\nqueerness and thus improper quantifications of bias. With the goal of improving\nsexuality-based NLP bias analyses, we conclude with recommendations that\nencourage more thorough engagement with both queer communities and\ninterdisciplinary literature.",
    "published": "2025-06-22T18:16:53Z",
    "pdf_url": "http://arxiv.org/pdf/2506.22481v1",
    "categories": [
      "cs.CY",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "1707.01890v2",
    "title": "An Interactive Tool for Natural Language Processing on Clinical Text",
    "authors": [
      "Gaurav Trivedi",
      "Phuong Pham",
      "Wendy Chapman",
      "Rebecca Hwa",
      "Janyce Wiebe",
      "Harry Hochheiser"
    ],
    "abstract": "Natural Language Processing (NLP) systems often make use of machine learning\ntechniques that are unfamiliar to end-users who are interested in analyzing\nclinical records. Although NLP has been widely used in extracting information\nfrom clinical text, current systems generally do not support model revision\nbased on feedback from domain experts.\n  We present a prototype tool that allows end users to visualize and review the\noutputs of an NLP system that extracts binary variables from clinical text. Our\ntool combines multiple visualizations to help the users understand these\nresults and make any necessary corrections, thus forming a feedback loop and\nhelping improve the accuracy of the NLP models. We have tested our prototype in\na formative think-aloud user study with clinicians and researchers involved in\ncolonoscopy research. Results from semi-structured interviews and a System\nUsability Scale (SUS) analysis show that the users are able to quickly start\nrefining NLP models, despite having very little or no experience with machine\nlearning. Observations from these sessions suggest revisions to the interface\nto better support review workflow and interpretation of results.",
    "published": "2017-07-06T17:44:15Z",
    "pdf_url": "http://arxiv.org/pdf/1707.01890v2",
    "categories": [
      "cs.HC",
      "cs.CL",
      "cs.IR"
    ]
  },
  {
    "arxiv_id": "1902.00679v1",
    "title": "Natural Language Processing, Sentiment Analysis and Clinical Analytics",
    "authors": [
      "Adil Rajput"
    ],
    "abstract": "Recent advances in Big Data has prompted health care practitioners to utilize\nthe data available on social media to discern sentiment and emotions\nexpression. Health Informatics and Clinical Analytics depend heavily on\ninformation gathered from diverse sources. Traditionally, a healthcare\npractitioner will ask a patient to fill out a questionnaire that will form the\nbasis of diagnosing the medical condition. However, medical practitioners have\naccess to many sources of data including the patients writings on various\nmedia. Natural Language Processing (NLP) allows researchers to gather such data\nand analyze it to glean the underlying meaning of such writings. The field of\nsentiment analysis (applied to many other domains) depend heavily on techniques\nutilized by NLP. This work will look into various prevalent theories underlying\nthe NLP field and how they can be leveraged to gather users sentiments on\nsocial media. Such sentiments can be culled over a period of time thus\nminimizing the errors introduced by data input and other stressors.\nFurthermore, we look at some applications of sentiment analysis and application\nof NLP to mental health. The reader will also learn about the NLTK toolkit that\nimplements various NLP theories and how they can make the data scavenging\nprocess a lot easier.",
    "published": "2019-02-02T09:30:26Z",
    "pdf_url": "http://arxiv.org/pdf/1902.00679v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2110.10470v2",
    "title": "Interpreting Deep Learning Models in Natural Language Processing: A\n  Review",
    "authors": [
      "Xiaofei Sun",
      "Diyi Yang",
      "Xiaoya Li",
      "Tianwei Zhang",
      "Yuxian Meng",
      "Han Qiu",
      "Guoyin Wang",
      "Eduard Hovy",
      "Jiwei Li"
    ],
    "abstract": "Neural network models have achieved state-of-the-art performances in a wide\nrange of natural language processing (NLP) tasks. However, a long-standing\ncriticism against neural network models is the lack of interpretability, which\nnot only reduces the reliability of neural NLP systems but also limits the\nscope of their applications in areas where interpretability is essential (e.g.,\nhealth care applications). In response, the increasing interest in interpreting\nneural NLP models has spurred a diverse array of interpretation methods over\nrecent years. In this survey, we provide a comprehensive review of various\ninterpretation methods for neural models in NLP. We first stretch out a\nhigh-level taxonomy for interpretation methods in NLP, i.e., training-based\napproaches, test-based approaches, and hybrid approaches. Next, we describe\nsub-categories in each category in detail, e.g., influence-function based\nmethods, KNN-based methods, attention-based models, saliency-based methods,\nperturbation-based methods, etc. We point out deficiencies of current methods\nand suggest some avenues for future research.",
    "published": "2021-10-20T10:17:04Z",
    "pdf_url": "http://arxiv.org/pdf/2110.10470v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2306.04459v1",
    "title": "Uncertainty in Natural Language Processing: Sources, Quantification, and\n  Applications",
    "authors": [
      "Mengting Hu",
      "Zhen Zhang",
      "Shiwan Zhao",
      "Minlie Huang",
      "Bingzhe Wu"
    ],
    "abstract": "As a main field of artificial intelligence, natural language processing (NLP)\nhas achieved remarkable success via deep neural networks. Plenty of NLP tasks\nhave been addressed in a unified manner, with various tasks being associated\nwith each other through sharing the same paradigm. However, neural networks are\nblack boxes and rely on probability computation. Making mistakes is inevitable.\nTherefore, estimating the reliability and trustworthiness (in other words,\nuncertainty) of neural networks becomes a key research direction, which plays a\ncrucial role in reducing models' risks and making better decisions. Therefore,\nin this survey, we provide a comprehensive review of uncertainty-relevant works\nin the NLP field. Considering the data and paradigms characteristics, we first\ncategorize the sources of uncertainty in natural language into three types,\nincluding input, system, and output. Then, we systemically review uncertainty\nquantification approaches and the main applications. Finally, we discuss the\nchallenges of uncertainty estimation in NLP and discuss potential future\ndirections, taking into account recent trends in the field. Though there have\nbeen a few surveys about uncertainty estimation, our work is the first to\nreview uncertainty from the NLP perspective.",
    "published": "2023-06-05T06:46:53Z",
    "pdf_url": "http://arxiv.org/pdf/2306.04459v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2401.17911v1",
    "title": "SNNLP: Energy-Efficient Natural Language Processing Using Spiking Neural\n  Networks",
    "authors": [
      "R. Alexander Knipper",
      "Kaniz Mishty",
      "Mehdi Sadi",
      "Shubhra Kanti Karmaker Santu"
    ],
    "abstract": "As spiking neural networks receive more attention, we look toward\napplications of this computing paradigm in fields other than computer vision\nand signal processing. One major field, underexplored in the neuromorphic\nsetting, is Natural Language Processing (NLP), where most state-of-the-art\nsolutions still heavily rely on resource-consuming and power-hungry traditional\ndeep learning architectures. Therefore, it is compelling to design NLP models\nfor neuromorphic architectures due to their low energy requirements, with the\nadditional benefit of a more human-brain-like operating model for processing\ninformation. However, one of the biggest issues with bringing NLP to the\nneuromorphic setting is in properly encoding text into a spike train so that it\ncan be seamlessly handled by both current and future SNN architectures. In this\npaper, we compare various methods of encoding text as spikes and assess each\nmethod's performance in an associated SNN on a downstream NLP task, namely,\nsentiment analysis. Furthermore, we go on to propose a new method of encoding\ntext as spikes that outperforms a widely-used rate-coding technique, Poisson\nrate-coding, by around 13\\% on our benchmark NLP tasks. Subsequently, we\ndemonstrate the energy efficiency of SNNs implemented in hardware for the\nsentiment analysis task compared to traditional deep neural networks, observing\nan energy efficiency increase of more than 32x during inference and 60x during\ntraining while incurring the expected energy-performance tradeoff.",
    "published": "2024-01-31T15:16:25Z",
    "pdf_url": "http://arxiv.org/pdf/2401.17911v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2004.13922v2",
    "title": "Revisiting Pre-Trained Models for Chinese Natural Language Processing",
    "authors": [
      "Yiming Cui",
      "Wanxiang Che",
      "Ting Liu",
      "Bing Qin",
      "Shijin Wang",
      "Guoping Hu"
    ],
    "abstract": "Bidirectional Encoder Representations from Transformers (BERT) has shown\nmarvelous improvements across various NLP tasks, and consecutive variants have\nbeen proposed to further improve the performance of the pre-trained language\nmodels. In this paper, we target on revisiting Chinese pre-trained language\nmodels to examine their effectiveness in a non-English language and release the\nChinese pre-trained language model series to the community. We also propose a\nsimple but effective model called MacBERT, which improves upon RoBERTa in\nseveral ways, especially the masking strategy that adopts MLM as correction\n(Mac). We carried out extensive experiments on eight Chinese NLP tasks to\nrevisit the existing pre-trained language models as well as the proposed\nMacBERT. Experimental results show that MacBERT could achieve state-of-the-art\nperformances on many NLP tasks, and we also ablate details with several\nfindings that may help future research. Resources available:\nhttps://github.com/ymcui/MacBERT",
    "published": "2020-04-29T02:08:30Z",
    "pdf_url": "http://arxiv.org/pdf/2004.13922v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2108.08252v1",
    "title": "Deep Natural Language Processing for LinkedIn Search Systems",
    "authors": [
      "Weiwei Guo",
      "Xiaowei Liu",
      "Sida Wang",
      "Michaeel Kazi",
      "Zhoutong Fu",
      "Huiji Gao",
      "Jun Jia",
      "Liang Zhang",
      "Bo Long"
    ],
    "abstract": "Many search systems work with large amounts of natural language data, e.g.,\nsearch queries, user profiles and documents, where deep learning based natural\nlanguage processing techniques (deep NLP) can be of great help. In this paper,\nwe introduce a comprehensive study of applying deep NLP techniques to five\nrepresentative tasks in search engines. Through the model design and\nexperiments of the five tasks, readers can find answers to three important\nquestions: (1) When is deep NLP helpful/not helpful in search systems? (2) How\nto address latency challenges? (3) How to ensure model robustness? This work\nbuilds on existing efforts of LinkedIn search, and is tested at scale on a\ncommercial search engine. We believe our experiences can provide useful\ninsights for the industry and research communities.",
    "published": "2021-07-30T17:40:36Z",
    "pdf_url": "http://arxiv.org/pdf/2108.08252v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1907.01055v2",
    "title": "Is artificial data useful for biomedical Natural Language Processing\n  algorithms?",
    "authors": [
      "Zixu Wang",
      "Julia Ive",
      "Sumithra Velupillai",
      "Lucia Specia"
    ],
    "abstract": "A major obstacle to the development of Natural Language Processing (NLP)\nmethods in the biomedical domain is data accessibility. This problem can be\naddressed by generating medical data artificially. Most previous studies have\nfocused on the generation of short clinical text, and evaluation of the data\nutility has been limited. We propose a generic methodology to guide the\ngeneration of clinical text with key phrases. We use the artificial data as\nadditional training data in two key biomedical NLP tasks: text classification\nand temporal relation extraction. We show that artificially generated training\ndata used in conjunction with real training data can lead to performance boosts\nfor data-greedy neural network algorithms. We also demonstrate the usefulness\nof the generated data for NLP setups where it fully replaces real training\ndata.",
    "published": "2019-07-01T20:17:59Z",
    "pdf_url": "http://arxiv.org/pdf/1907.01055v2",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1906.04393v1",
    "title": "Lightweight and Efficient Neural Natural Language Processing with\n  Quaternion Networks",
    "authors": [
      "Yi Tay",
      "Aston Zhang",
      "Luu Anh Tuan",
      "Jinfeng Rao",
      "Shuai Zhang",
      "Shuohang Wang",
      "Jie Fu",
      "Siu Cheung Hui"
    ],
    "abstract": "Many state-of-the-art neural models for NLP are heavily parameterized and\nthus memory inefficient. This paper proposes a series of lightweight and memory\nefficient neural architectures for a potpourri of natural language processing\n(NLP) tasks. To this end, our models exploit computation using Quaternion\nalgebra and hypercomplex spaces, enabling not only expressive inter-component\ninteractions but also significantly ($75\\%$) reduced parameter size due to\nlesser degrees of freedom in the Hamilton product. We propose Quaternion\nvariants of models, giving rise to new architectures such as the Quaternion\nattention Model and Quaternion Transformer. Extensive experiments on a battery\nof NLP tasks demonstrates the utility of proposed Quaternion-inspired models,\nenabling up to $75\\%$ reduction in parameter size without significant loss in\nperformance.",
    "published": "2019-06-11T04:56:17Z",
    "pdf_url": "http://arxiv.org/pdf/1906.04393v1",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2112.13969v1",
    "title": "LINDA: Unsupervised Learning to Interpolate in Natural Language\n  Processing",
    "authors": [
      "Yekyung Kim",
      "Seohyeong Jeong",
      "Kyunghyun Cho"
    ],
    "abstract": "Despite the success of mixup in data augmentation, its applicability to\nnatural language processing (NLP) tasks has been limited due to the discrete\nand variable-length nature of natural languages. Recent studies have thus\nrelied on domain-specific heuristics and manually crafted resources, such as\ndictionaries, in order to apply mixup in NLP. In this paper, we instead propose\nan unsupervised learning approach to text interpolation for the purpose of data\naugmentation, to which we refer as \"Learning to INterpolate for Data\nAugmentation\" (LINDA), that does not require any heuristics nor manually\ncrafted resources but learns to interpolate between any pair of natural\nlanguage sentences over a natural language manifold. After empirically\ndemonstrating the LINDA's interpolation capability, we show that LINDA indeed\nallows us to seamlessly apply mixup in NLP and leads to better generalization\nin text classification both in-domain and out-of-domain.",
    "published": "2021-12-28T02:56:41Z",
    "pdf_url": "http://arxiv.org/pdf/2112.13969v1",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2307.13693v2",
    "title": "Evaluating Large Language Models for Radiology Natural Language\n  Processing",
    "authors": [
      "Zhengliang Liu",
      "Tianyang Zhong",
      "Yiwei Li",
      "Yutong Zhang",
      "Yi Pan",
      "Zihao Zhao",
      "Peixin Dong",
      "Chao Cao",
      "Yuxiao Liu",
      "Peng Shu",
      "Yaonai Wei",
      "Zihao Wu",
      "Chong Ma",
      "Jiaqi Wang",
      "Sheng Wang",
      "Mengyue Zhou",
      "Zuowei Jiang",
      "Chunlin Li",
      "Jason Holmes",
      "Shaochen Xu",
      "Lu Zhang",
      "Haixing Dai",
      "Kai Zhang",
      "Lin Zhao",
      "Yuanhao Chen",
      "Xu Liu",
      "Peilong Wang",
      "Pingkun Yan",
      "Jun Liu",
      "Bao Ge",
      "Lichao Sun",
      "Dajiang Zhu",
      "Xiang Li",
      "Wei Liu",
      "Xiaoyan Cai",
      "Xintao Hu",
      "Xi Jiang",
      "Shu Zhang",
      "Xin Zhang",
      "Tuo Zhang",
      "Shijie Zhao",
      "Quanzheng Li",
      "Hongtu Zhu",
      "Dinggang Shen",
      "Tianming Liu"
    ],
    "abstract": "The rise of large language models (LLMs) has marked a pivotal shift in the\nfield of natural language processing (NLP). LLMs have revolutionized a\nmultitude of domains, and they have made a significant impact in the medical\nfield. Large language models are now more abundant than ever, and many of these\nmodels exhibit bilingual capabilities, proficient in both English and Chinese.\nHowever, a comprehensive evaluation of these models remains to be conducted.\nThis lack of assessment is especially apparent within the context of radiology\nNLP. This study seeks to bridge this gap by critically evaluating thirty two\nLLMs in interpreting radiology reports, a crucial component of radiology NLP.\nSpecifically, the ability to derive impressions from radiologic findings is\nassessed. The outcomes of this evaluation provide key insights into the\nperformance, strengths, and weaknesses of these LLMs, informing their practical\napplications within the medical domain.",
    "published": "2023-07-25T17:57:18Z",
    "pdf_url": "http://arxiv.org/pdf/2307.13693v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2507.17974v2",
    "title": "Natural Language Processing for Tigrinya: Current State and Future\n  Directions",
    "authors": [
      "Fitsum Gaim",
      "Jong C. Park"
    ],
    "abstract": "Despite being spoken by millions of people, Tigrinya remains severely\nunderrepresented in Natural Language Processing (NLP) research. This work\npresents a comprehensive survey of NLP research for Tigrinya, analyzing over 40\nstudies spanning more than a decade of work from 2011 to 2025. We\nsystematically review the current state of computational resources, models, and\napplications across ten distinct downstream tasks, including morphological\nprocessing, machine translation, speech recognition, and question-answering.\nOur analysis reveals a clear trajectory from foundational, rule-based systems\nto modern neural architectures, with progress consistently unlocked by resource\ncreation milestones. We identify key challenges rooted in Tigrinya's\nmorphological complexity and resource scarcity, while highlighting promising\nresearch directions, including morphology-aware modeling, cross-lingual\ntransfer, and community-centered resource development. This work serves as both\na comprehensive reference for researchers and a roadmap for advancing Tigrinya\nNLP. A curated metadata of the surveyed studies and resources is made publicly\navailable.",
    "published": "2025-07-23T22:45:30Z",
    "pdf_url": "http://arxiv.org/pdf/2507.17974v2",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ]
  },
  {
    "arxiv_id": "1407.6099v1",
    "title": "Autonomous requirements specification processing using natural language\n  processing",
    "authors": [
      "S. G. Macdonell",
      "K. Min",
      "A. M. Connor"
    ],
    "abstract": "We describe our ongoing research that centres on the application of natural\nlanguage processing (NLP) to software engineering and systems development\nactivities. In particular, this paper addresses the use of NLP in the\nrequirements analysis and systems design processes. We have developed a\nprototype toolset that can assist the systems analyst or software engineer to\nselect and verify terms relevant to a project. In this paper we describe the\nprocesses employed by the system to extract and classify objects of interest\nfrom requirements documents. These processes are illustrated using a small\nexample.",
    "published": "2014-07-23T03:29:44Z",
    "pdf_url": "http://arxiv.org/pdf/1407.6099v1",
    "categories": [
      "cs.CL",
      "cs.SE"
    ]
  },
  {
    "arxiv_id": "1508.05154v2",
    "title": "Posterior calibration and exploratory analysis for natural language\n  processing models",
    "authors": [
      "Khanh Nguyen",
      "Brendan O'Connor"
    ],
    "abstract": "Many models in natural language processing define probabilistic distributions\nover linguistic structures. We argue that (1) the quality of a model' s\nposterior distribution can and should be directly evaluated, as to whether\nprobabilities correspond to empirical frequencies, and (2) NLP uncertainty can\nbe projected not only to pipeline components, but also to exploratory data\nanalysis, telling a user when to trust and not trust the NLP analysis. We\npresent a method to analyze calibration, and apply it to compare the\nmiscalibration of several commonly used models. We also contribute a\ncoreference sampling algorithm that can create confidence intervals for a\npolitical event extraction task.",
    "published": "2015-08-21T00:25:51Z",
    "pdf_url": "http://arxiv.org/pdf/1508.05154v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2103.07929v2",
    "title": "A Systematic Review of Reproducibility Research in Natural Language\n  Processing",
    "authors": [
      "Anya Belz",
      "Shubham Agarwal",
      "Anastasia Shimorina",
      "Ehud Reiter"
    ],
    "abstract": "Against the background of what has been termed a reproducibility crisis in\nscience, the NLP field is becoming increasingly interested in, and\nconscientious about, the reproducibility of its results. The past few years\nhave seen an impressive range of new initiatives, events and active research in\nthe area. However, the field is far from reaching a consensus about how\nreproducibility should be defined, measured and addressed, with diversity of\nviews currently increasing rather than converging. With this focused\ncontribution, we aim to provide a wide-angle, and as near as possible complete,\nsnapshot of current work on reproducibility in NLP, delineating differences and\nsimilarities, and providing pointers to common denominators.",
    "published": "2021-03-14T13:53:05Z",
    "pdf_url": "http://arxiv.org/pdf/2103.07929v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2204.06251v2",
    "title": "Experimental Standards for Deep Learning in Natural Language Processing\n  Research",
    "authors": [
      "Dennis Ulmer",
      "Elisa Bassignana",
      "Max Müller-Eberstein",
      "Daniel Varab",
      "Mike Zhang",
      "Rob van der Goot",
      "Christian Hardmeier",
      "Barbara Plank"
    ],
    "abstract": "The field of Deep Learning (DL) has undergone explosive growth during the\nlast decade, with a substantial impact on Natural Language Processing (NLP) as\nwell. Yet, compared to more established disciplines, a lack of common\nexperimental standards remains an open challenge to the field at large.\nStarting from fundamental scientific principles, we distill ongoing discussions\non experimental standards in NLP into a single, widely-applicable methodology.\nFollowing these best practices is crucial to strengthen experimental evidence,\nimprove reproducibility and support scientific progress. These standards are\nfurther collected in a public repository to help them transparently adapt to\nfuture needs.",
    "published": "2022-04-13T08:42:52Z",
    "pdf_url": "http://arxiv.org/pdf/2204.06251v2",
    "categories": [
      "cs.LG",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2504.08910v1",
    "title": "Assessing Physics Students' Scientific Argumentation using Natural\n  Language Processing",
    "authors": [
      "Winter Allen",
      "Carina M. Rebello",
      "N. Sanjay Rebello"
    ],
    "abstract": "Scientific argumentation is an important science and engineering practice and\na necessary 21st Century workforce skill. Due to the nature of large enrollment\nclasses, it is difficult to individually assess students and provide feedback\non their argumentation. The recent developments in Natural Language Processing\n(NLP) and Machine Learning (ML) may provide a solution. In this study we\ninvestigate methods using NLP and ML to assess and understand students'\nargumentation. Specifically, we investigate the use of topic modeling to\nanalyze student essays of argumentation after solving a problem in the\nrecitation section of an introductory calculus-based physics course four\nsemesters. We report on the emergent themes present in each semester.",
    "published": "2025-04-11T18:25:10Z",
    "pdf_url": "http://arxiv.org/pdf/2504.08910v1",
    "categories": [
      "physics.ed-ph"
    ]
  },
  {
    "arxiv_id": "1301.3547v1",
    "title": "A Rhetorical Analysis Approach to Natural Language Processing",
    "authors": [
      "Benjamin Englard"
    ],
    "abstract": "The goal of this research was to find a way to extend the capabilities of\ncomputers through the processing of language in a more human way, and present\napplications which demonstrate the power of this method. This research presents\na novel approach, Rhetorical Analysis, to solving problems in Natural Language\nProcessing (NLP). The main benefit of Rhetorical Analysis, as opposed to\nprevious approaches, is that it does not require the accumulation of large sets\nof training data, but can be used to solve a multitude of problems within the\nfield of NLP. The NLP problems investigated with Rhetorical Analysis were the\nAuthor Identification problem - predicting the author of a piece of text based\non its rhetorical strategies, Election Prediction - predicting the winner of a\npresidential candidate's re-election campaign based on rhetorical strategies\nwithin that president's inaugural address, Natural Language Generation - having\na computer produce text containing rhetorical strategies, and Document\nSummarization. The results of this research indicate that an Author\nIdentification system based on Rhetorical Analysis could predict the correct\nauthor 100% of the time, that a re-election predictor based on Rhetorical\nAnalysis could predict the correct winner of a re-election campaign 55% of the\ntime, that a Natural Language Generation system based on Rhetorical Analysis\ncould output text with up to 87.3% similarity to Shakespeare in style, and that\na Document Summarization system based on Rhetorical Analysis could extract\nhighly relevant sentences. Overall, this study demonstrated that Rhetorical\nAnalysis could be a useful approach to solving problems in NLP.",
    "published": "2013-01-16T01:42:53Z",
    "pdf_url": "http://arxiv.org/pdf/1301.3547v1",
    "categories": [
      "cs.CL",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1811.00770v2",
    "title": "A Survey on Natural Language Processing for Fake News Detection",
    "authors": [
      "Ray Oshikawa",
      "Jing Qian",
      "William Yang Wang"
    ],
    "abstract": "Fake news detection is a critical yet challenging problem in Natural Language\nProcessing (NLP). The rapid rise of social networking platforms has not only\nyielded a vast increase in information accessibility but has also accelerated\nthe spread of fake news. Thus, the effect of fake news has been growing,\nsometimes extending to the offline world and threatening public safety. Given\nthe massive amount of Web content, automatic fake news detection is a practical\nNLP problem useful to all online content providers, in order to reduce the\nhuman time and effort to detect and prevent the spread of fake news. In this\npaper, we describe the challenges involved in fake news detection and also\ndescribe related tasks. We systematically review and compare the task\nformulations, datasets and NLP solutions that have been developed for this\ntask, and also discuss the potentials and limitations of them. Based on our\ninsights, we outline promising research directions, including more\nfine-grained, detailed, fair, and practical detection models. We also highlight\nthe difference between fake news detection and other related tasks, and the\nimportance of NLP solutions for fake news detection.",
    "published": "2018-11-02T08:10:21Z",
    "pdf_url": "http://arxiv.org/pdf/1811.00770v2",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2104.04069v2",
    "title": "A survey on extremism analysis using Natural Language Processing",
    "authors": [
      "Javier Torregrosa",
      "Gema Bello-Orgaz",
      "Eugenio Martinez-Camara",
      "Javier Del Ser",
      "David Camacho"
    ],
    "abstract": "Extremism research has grown as an open problem for several countries during\nrecent years, especially due to the apparition of movements such as jihadism.\nThis and other extremist groups have taken advantage of different approaches,\nsuch as the use of Social Media, to spread their ideology, promote their acts\nand recruit followers. Natural Language Processing (NLP) represents a way of\ndetecting this type of content, and several authors make use of it to describe\nand discriminate the discourse held by this groups, with the final objective of\ndetecting and preventing its spread. This survey aims to review the\ncontributions of NLP to the field of extremism research, providing the reader\nwith a comprehensive picture of the state of the art of this research area. The\ncontent includes a description and comparison of the frequently used NLP\ntechniques, how they were applied, the insights they provided, the most\nfrequently used NLP software tools and the availability of datasets and data\nsources for research. Finally, research questions are approached and answered\nwith highlights from the review, while future trends, challenges and directions\nderived from these highlights are suggested.",
    "published": "2021-03-28T11:05:43Z",
    "pdf_url": "http://arxiv.org/pdf/2104.04069v2",
    "categories": [
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "2104.06535v1",
    "title": "NPE: An FPGA-based Overlay Processor for Natural Language Processing",
    "authors": [
      "Hamza Khan",
      "Asma Khan",
      "Zainab Khan",
      "Lun Bin Huang",
      "Kun Wang",
      "Lei He"
    ],
    "abstract": "In recent years, transformer-based models have shown state-of-the-art results\nfor Natural Language Processing (NLP). In particular, the introduction of the\nBERT language model brought with it breakthroughs in tasks such as question\nanswering and natural language inference, advancing applications that allow\nhumans to interact naturally with embedded devices. FPGA-based overlay\nprocessors have been shown as effective solutions for edge image and video\nprocessing applications, which mostly rely on low precision linear matrix\noperations. In contrast, transformer-based NLP techniques employ a variety of\nhigher precision nonlinear operations with significantly higher frequency. We\npresent NPE, an FPGA-based overlay processor that can efficiently execute a\nvariety of NLP models. NPE offers software-like programmability to the end user\nand, unlike FPGA designs that implement specialized accelerators for each\nnonlinear function, can be upgraded for future NLP models without requiring\nreconfiguration. We demonstrate that NPE can meet real-time conversational AI\nlatency targets for the BERT language model with $4\\times$ lower power than\nCPUs and $6\\times$ lower power than GPUs. We also show NPE uses $3\\times$ fewer\nFPGA resources relative to comparable BERT network-specific accelerators in the\nliterature. NPE provides a cost-effective and power-efficient FPGA-based\nsolution for Natural Language Processing at the edge.",
    "published": "2021-04-13T22:34:33Z",
    "pdf_url": "http://arxiv.org/pdf/2104.06535v1",
    "categories": [
      "cs.AR"
    ]
  },
  {
    "arxiv_id": "2305.14671v2",
    "title": "A Survey of Diffusion Models in Natural Language Processing",
    "authors": [
      "Hao Zou",
      "Zae Myung Kim",
      "Dongyeop Kang"
    ],
    "abstract": "This survey paper provides a comprehensive review of the use of diffusion\nmodels in natural language processing (NLP). Diffusion models are a class of\nmathematical models that aim to capture the diffusion of information or signals\nacross a network or manifold. In NLP, diffusion models have been used in a\nvariety of applications, such as natural language generation, sentiment\nanalysis, topic modeling, and machine translation. This paper discusses the\ndifferent formulations of diffusion models used in NLP, their strengths and\nlimitations, and their applications. We also perform a thorough comparison\nbetween diffusion models and alternative generative models, specifically\nhighlighting the autoregressive (AR) models, while also examining how diverse\narchitectures incorporate the Transformer in conjunction with diffusion models.\nCompared to AR models, diffusion models have significant advantages for\nparallel generation, text interpolation, token-level controls such as syntactic\nstructures and semantic contents, and robustness. Exploring further\npermutations of integrating Transformers into diffusion models would be a\nvaluable pursuit. Also, the development of multimodal diffusion models and\nlarge-scale diffusion language models with notable capabilities for few-shot\nlearning would be important directions for the future advance of diffusion\nmodels in NLP.",
    "published": "2023-05-24T03:25:32Z",
    "pdf_url": "http://arxiv.org/pdf/2305.14671v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2007.09604v1",
    "title": "Meta-learning for Few-shot Natural Language Processing: A Survey",
    "authors": [
      "Wenpeng Yin"
    ],
    "abstract": "Few-shot natural language processing (NLP) refers to NLP tasks that are\naccompanied with merely a handful of labeled examples. This is a real-world\nchallenge that an AI system must learn to handle. Usually we rely on collecting\nmore auxiliary information or developing a more efficient learning algorithm.\nHowever, the general gradient-based optimization in high capacity models, if\ntraining from scratch, requires many parameter-updating steps over a large\nnumber of labeled examples to perform well (Snell et al., 2017). If the target\ntask itself cannot provide more information, how about collecting more tasks\nequipped with rich annotations to help the model learning? The goal of\nmeta-learning is to train a model on a variety of tasks with rich annotations,\nsuch that it can solve a new task using only a few labeled samples. The key\nidea is to train the model's initial parameters such that the model has maximal\nperformance on a new task after the parameters have been updated through zero\nor a couple of gradient steps. There are already some surveys for\nmeta-learning, such as (Vilalta and Drissi, 2002; Vanschoren, 2018; Hospedales\net al., 2020). Nevertheless, this paper focuses on NLP domain, especially\nfew-shot applications. We try to provide clearer definitions, progress summary\nand some common datasets of applying meta-learning to few-shot NLP.",
    "published": "2020-07-19T06:36:41Z",
    "pdf_url": "http://arxiv.org/pdf/2007.09604v1",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2007.15779v6",
    "title": "Domain-Specific Language Model Pretraining for Biomedical Natural\n  Language Processing",
    "authors": [
      "Yu Gu",
      "Robert Tinn",
      "Hao Cheng",
      "Michael Lucas",
      "Naoto Usuyama",
      "Xiaodong Liu",
      "Tristan Naumann",
      "Jianfeng Gao",
      "Hoifung Poon"
    ],
    "abstract": "Pretraining large neural language models, such as BERT, has led to impressive\ngains on many natural language processing (NLP) tasks. However, most\npretraining efforts focus on general domain corpora, such as newswire and Web.\nA prevailing assumption is that even domain-specific pretraining can benefit by\nstarting from general-domain language models. In this paper, we challenge this\nassumption by showing that for domains with abundant unlabeled text, such as\nbiomedicine, pretraining language models from scratch results in substantial\ngains over continual pretraining of general-domain language models. To\nfacilitate this investigation, we compile a comprehensive biomedical NLP\nbenchmark from publicly-available datasets. Our experiments show that\ndomain-specific pretraining serves as a solid foundation for a wide range of\nbiomedical NLP tasks, leading to new state-of-the-art results across the board.\nFurther, in conducting a thorough evaluation of modeling choices, both for\npretraining and task-specific fine-tuning, we discover that some common\npractices are unnecessary with BERT models, such as using complex tagging\nschemes in named entity recognition (NER). To help accelerate research in\nbiomedical NLP, we have released our state-of-the-art pretrained and\ntask-specific models for the community, and created a leaderboard featuring our\nBLURB benchmark (short for Biomedical Language Understanding & Reasoning\nBenchmark) at https://aka.ms/BLURB.",
    "published": "2020-07-31T00:04:15Z",
    "pdf_url": "http://arxiv.org/pdf/2007.15779v6",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2112.08628v2",
    "title": "Explainable Natural Language Processing with Matrix Product States",
    "authors": [
      "Jirawat Tangpanitanon",
      "Chanatip Mangkang",
      "Pradeep Bhadola",
      "Yuichiro Minato",
      "Dimitris G. Angelakis",
      "Thiparat Chotibut"
    ],
    "abstract": "Despite empirical successes of recurrent neural networks (RNNs) in natural\nlanguage processing (NLP), theoretical understanding of RNNs is still limited\ndue to intrinsically complex non-linear computations. We systematically analyze\nRNNs' behaviors in a ubiquitous NLP task, the sentiment analysis of movie\nreviews, via the mapping between a class of RNNs called recurrent arithmetic\ncircuits (RACs) and a matrix product state (MPS). Using the von-Neumann\nentanglement entropy (EE) as a proxy for information propagation, we show that\nsingle-layer RACs possess a maximum information propagation capacity, reflected\nby the saturation of the EE. Enlarging the bond dimension beyond the EE\nsaturation threshold does not increase model prediction accuracies, so a\nminimal model that best estimates the data statistics can be inferred. Although\nthe saturated EE is smaller than the maximum EE allowed by the area law, our\nminimal model still achieves ~99% training accuracies in realistic sentiment\nanalysis data sets. Thus, low EE is not a warrant against the adoption of\nsingle-layer RACs for NLP. Contrary to a common belief that long-range\ninformation propagation is the main source of RNNs' successes, we show that\nsingle-layer RACs harness high expressiveness from the subtle interplay between\nthe information propagation and the word vector embeddings. Our work sheds\nlight on the phenomenology of learning in RACs, and more generally on the\nexplainability of RNNs for NLP, using tools from many-body quantum physics.",
    "published": "2021-12-16T05:10:32Z",
    "pdf_url": "http://arxiv.org/pdf/2112.08628v2",
    "categories": [
      "cond-mat.dis-nn",
      "cond-mat.stat-mech",
      "cs.CL",
      "cs.LG",
      "quant-ph",
      "15A69",
      "I.2.7"
    ]
  },
  {
    "arxiv_id": "2212.05789v1",
    "title": "Collaborating Heterogeneous Natural Language Processing Tasks via\n  Federated Learning",
    "authors": [
      "Chenhe Dong",
      "Yuexiang Xie",
      "Bolin Ding",
      "Ying Shen",
      "Yaliang Li"
    ],
    "abstract": "The increasing privacy concerns on personal private text data promote the\ndevelopment of federated learning (FL) in recent years. However, the existing\nstudies on applying FL in NLP are not suitable to coordinate participants with\nheterogeneous or private learning objectives. In this study, we further broaden\nthe application scope of FL in NLP by proposing an Assign-Then-Contrast\n(denoted as ATC) framework, which enables clients with heterogeneous NLP tasks\nto construct an FL course and learn useful knowledge from each other.\nSpecifically, the clients are suggested to first perform local training with\nthe unified tasks assigned by the server rather than using their own learning\nobjectives, which is called the Assign training stage. After that, in the\nContrast training stage, clients train with different local learning objectives\nand exchange knowledge with other clients who contribute consistent and useful\nmodel updates. We conduct extensive experiments on six widely-used datasets\ncovering both Natural Language Understanding (NLU) and Natural Language\nGeneration (NLG) tasks, and the proposed ATC framework achieves significant\nimprovements compared with various baseline methods. The source code is\navailable at\n\\url{https://github.com/alibaba/FederatedScope/tree/master/federatedscope/nlp/hetero_tasks}.",
    "published": "2022-12-12T09:27:50Z",
    "pdf_url": "http://arxiv.org/pdf/2212.05789v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2302.06476v3",
    "title": "Is ChatGPT a General-Purpose Natural Language Processing Task Solver?",
    "authors": [
      "Chengwei Qin",
      "Aston Zhang",
      "Zhuosheng Zhang",
      "Jiaao Chen",
      "Michihiro Yasunaga",
      "Diyi Yang"
    ],
    "abstract": "Spurred by advancements in scale, large language models (LLMs) have\ndemonstrated the ability to perform a variety of natural language processing\n(NLP) tasks zero-shot -- i.e., without adaptation on downstream data. Recently,\nthe debut of ChatGPT has drawn a great deal of attention from the natural\nlanguage processing (NLP) community due to the fact that it can generate\nhigh-quality responses to human input and self-correct previous mistakes based\non subsequent conversations. However, it is not yet known whether ChatGPT can\nserve as a generalist model that can perform many NLP tasks zero-shot. In this\nwork, we empirically analyze the zero-shot learning ability of ChatGPT by\nevaluating it on 20 popular NLP datasets covering 7 representative task\ncategories. With extensive empirical studies, we demonstrate both the\neffectiveness and limitations of the current version of ChatGPT. We find that\nChatGPT performs well on many tasks favoring reasoning capabilities (e.g.,\narithmetic reasoning) while it still faces challenges when solving specific\ntasks such as sequence tagging. We additionally provide in-depth analysis\nthrough qualitative case studies.",
    "published": "2023-02-08T09:44:51Z",
    "pdf_url": "http://arxiv.org/pdf/2302.06476v3",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2302.10499v2",
    "title": "Intergenerational Test Generation for Natural Language Processing\n  Applications",
    "authors": [
      "Pin Ji",
      "Yang Feng",
      "Weitao Huang",
      "Jia Liu",
      "Zhihong Zhao"
    ],
    "abstract": "The development of modern NLP applications often relies on various benchmark\ndatasets containing plenty of manually labeled tests to evaluate performance.\nWhile constructing datasets often costs many resources, the performance on the\nheld-out data may not properly reflect their capability in real-world\napplication scenarios and thus cause tremendous misunderstanding and monetary\nloss. To alleviate this problem, in this paper, we propose an automated test\ngeneration method for detecting erroneous behaviors of various NLP\napplications. Our method is designed based on the sentence parsing process of\nclassic linguistics, and thus it is capable of assembling basic grammatical\nelements and adjuncts into a grammatically correct test with proper oracle\ninformation. We implement this method into NLPLego, which is designed to fully\nexploit the potential of seed sentences to automate the test generation.\nNLPLego disassembles the seed sentence into the template and adjuncts and then\ngenerates new sentences by assembling context-appropriate adjuncts with the\ntemplate in a specific order. Unlike the taskspecific methods, the tests\ngenerated by NLPLego have derivation relations and different degrees of\nvariation, which makes constructing appropriate metamorphic relations easier.\nThus, NLPLego is general, meaning it can meet the testing requirements of\nvarious NLP applications. To validate NLPLego, we experiment with three common\nNLP tasks, identifying failures in four state-of-art models. Given seed tests\nfrom SQuAD 2.0, SST, and QQP, NLPLego successfully detects 1,732, 5301, and\n261,879 incorrect behaviors with around 95.7% precision in three tasks,\nrespectively.",
    "published": "2023-02-21T07:57:59Z",
    "pdf_url": "http://arxiv.org/pdf/2302.10499v2",
    "categories": [
      "cs.SE"
    ]
  },
  {
    "arxiv_id": "2403.04105v3",
    "title": "Natural Language Processing in the Patent Domain: A Survey",
    "authors": [
      "Lekang Jiang",
      "Stephan Goetz"
    ],
    "abstract": "Patents, which encapsulate crucial technical and legal information in text\nform and referenced drawings, present a rich domain for natural language\nprocessing (NLP) applications. As NLP technologies evolve, large language\nmodels (LLMs) have demonstrated outstanding capabilities in general text\nprocessing and generation tasks. However, the application of LLMs in the patent\ndomain remains under-explored and under-developed due to the complexity of\npatents, particularly their language and legal framework. Understanding the\nunique characteristics of patent documents and related research in the patent\ndomain becomes essential for researchers to apply these tools effectively.\nTherefore, this paper aims to equip NLP researchers with the essential\nknowledge to navigate this complex domain efficiently. We introduce the\nrelevant fundamental aspects of patents to provide solid background\ninformation. In addition, we systematically break down the structural and\nlinguistic characteristics unique to patents and map out how NLP can be\nleveraged for patent analysis and generation. Moreover, we demonstrate the\nspectrum of text-based and multimodal patent-related tasks, including nine\npatent analysis and four patent generation tasks.",
    "published": "2024-03-06T23:17:16Z",
    "pdf_url": "http://arxiv.org/pdf/2403.04105v3",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "9607018v1",
    "title": "TSNLP - Test Suites for Natural Language Processing",
    "authors": [
      "Sabine Lehmann",
      "Stephan Oepen",
      "Sylvie Regnier-Prost",
      "Klaus Netter",
      "Veronika Lux",
      "Judith Klein",
      "Kirsten Falkedal",
      "Frederik Fouvry",
      "Dominique Estival",
      "Eva Dauphin",
      "Herve Compagnion",
      "Judith Baur",
      "Judith Baur",
      "Lorna Balkan",
      "Doug Arnold"
    ],
    "abstract": "The TSNLP project has investigated various aspects of the construction,\nmaintenance and application of systematic test suites as diagnostic and\nevaluation tools for NLP applications. The paper summarizes the motivation and\nmain results of the project: besides the solid methodological foundation, TSNLP\nhas produced substantial multi-purpose and multi-user test suites for three\nEuropean languages together with a set of specialized tools that facilitate the\nconstruction, extension, maintenance, retrieval, and customization of the test\ndata. As TSNLP results, including the data and technology, are made publicly\navailable, the project presents a valuable linguistic resourc e that has the\npotential of providing a wide-spread pre-standard diagnostic and evaluation\ntool for both developers and users of NLP applications.",
    "published": "1996-07-15T10:28:12Z",
    "pdf_url": "http://arxiv.org/pdf/cmp-lg/9607018v1",
    "categories": [
      "cmp-lg",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2004.06800v1",
    "title": "A hybrid classical-quantum workflow for natural language processing",
    "authors": [
      "Lee J. O'Riordan",
      "Myles Doyle",
      "Fabio Baruffa",
      "Venkatesh Kannan"
    ],
    "abstract": "Natural language processing (NLP) problems are ubiquitous in classical\ncomputing, where they often require significant computational resources to\ninfer sentence meanings. With the appearance of quantum computing hardware and\nsimulators, it is worth developing methods to examine such problems on these\nplatforms. In this manuscript we demonstrate the use of quantum computing\nmodels to perform NLP tasks, where we represent corpus meanings, and perform\ncomparisons between sentences of a given structure. We develop a hybrid\nworkflow for representing small and large scale corpus data sets to be encoded,\nprocessed, and decoded using a quantum circuit model. In addition, we provide\nour results showing the efficacy of the method, and release our developed\ntoolkit as an open software suite.",
    "published": "2020-04-12T12:19:17Z",
    "pdf_url": "http://arxiv.org/pdf/2004.06800v1",
    "categories": [
      "quant-ph",
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2107.12603v1",
    "title": "Federated Learning Meets Natural Language Processing: A Survey",
    "authors": [
      "Ming Liu",
      "Stella Ho",
      "Mengqi Wang",
      "Longxiang Gao",
      "Yuan Jin",
      "He Zhang"
    ],
    "abstract": "Federated Learning aims to learn machine learning models from multiple\ndecentralized edge devices (e.g. mobiles) or servers without sacrificing local\ndata privacy. Recent Natural Language Processing techniques rely on deep\nlearning and large pre-trained language models. However, both big deep neural\nand language models are trained with huge amounts of data which often lies on\nthe server side. Since text data is widely originated from end users, in this\nwork, we look into recent NLP models and techniques which use federated\nlearning as the learning framework. Our survey discusses major challenges in\nfederated natural language processing, including the algorithm challenges,\nsystem challenges as well as the privacy issues. We also provide a critical\nreview of the existing Federated NLP evaluation methods and tools. Finally, we\nhighlight the current research gaps and future directions.",
    "published": "2021-07-27T05:07:48Z",
    "pdf_url": "http://arxiv.org/pdf/2107.12603v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DC"
    ]
  },
  {
    "arxiv_id": "2207.04959v1",
    "title": "Learning Mutual Fund Categorization using Natural Language Processing",
    "authors": [
      "Dimitrios Vamvourellis",
      "Mate Attila Toth",
      "Dhruv Desai",
      "Dhagash Mehta",
      "Stefano Pasquali"
    ],
    "abstract": "Categorization of mutual funds or Exchange-Traded-funds (ETFs) have long\nserved the financial analysts to perform peer analysis for various purposes\nstarting from competitor analysis, to quantifying portfolio diversification.\nThe categorization methodology usually relies on fund composition data in the\nstructured format extracted from the Form N-1A. Here, we initiate a study to\nlearn the categorization system directly from the unstructured data as depicted\nin the forms using natural language processing (NLP). Positing as a multi-class\nclassification problem with the input data being only the investment strategy\ndescription as reported in the form and the target variable being the Lipper\nGlobal categories, and using various NLP models, we show that the\ncategorization system can indeed be learned with high accuracy. We discuss\nimplications and applications of our findings as well as limitations of\nexisting pre-trained architectures in applying them to learn fund\ncategorization.",
    "published": "2022-07-11T15:40:18Z",
    "pdf_url": "http://arxiv.org/pdf/2207.04959v1",
    "categories": [
      "q-fin.CP",
      "q-fin.ST",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1911.10708v1",
    "title": "hauWE: Hausa Words Embedding for Natural Language Processing",
    "authors": [
      "Idris Abdulmumin",
      "Bashir Shehu Galadanci"
    ],
    "abstract": "Words embedding (distributed word vector representations) have become an\nessential component of many natural language processing (NLP) tasks such as\nmachine translation, sentiment analysis, word analogy, named entity recognition\nand word similarity. Despite this, the only work that provides word vectors for\nHausa language is that of Bojanowski et al. [1] trained using fastText,\nconsisting of only a few words vectors. This work presents words embedding\nmodels using Word2Vec's Continuous Bag of Words (CBoW) and Skip Gram (SG)\nmodels. The models, hauWE (Hausa Words Embedding), are bigger and better than\nthe only previous model, making them more useful in NLP tasks. To compare the\nmodels, they were used to predict the 10 most similar words to 30 randomly\nselected Hausa words. hauWE CBoW's 88.7% and hauWE SG's 79.3% prediction\naccuracy greatly outperformed Bojanowski et al. [1]'s 22.3%.",
    "published": "2019-11-25T05:46:56Z",
    "pdf_url": "http://arxiv.org/pdf/1911.10708v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2305.19383v1",
    "title": "Quantum Natural Language Processing based Sentiment Analysis using\n  lambeq Toolkit",
    "authors": [
      "Srinjoy Ganguly",
      "Sai Nandan Morapakula",
      "Luis Miguel Pozo Coronado"
    ],
    "abstract": "Sentiment classification is one the best use case of classical natural\nlanguage processing (NLP) where we can witness its power in various daily life\ndomains such as banking, business and marketing industry. We already know how\nclassical AI and machine learning can change and improve technology. Quantum\nnatural language processing (QNLP) is a young and gradually emerging technology\nwhich has the potential to provide quantum advantage for NLP tasks. In this\npaper we show the first application of QNLP for sentiment analysis and achieve\nperfect test set accuracy for three different kinds of simulations and a decent\naccuracy for experiments ran on a noisy quantum device. We utilize the lambeq\nQNLP toolkit and $t|ket>$ by Cambridge Quantum (Quantinuum) to bring out the\nresults.",
    "published": "2023-05-30T19:54:02Z",
    "pdf_url": "http://arxiv.org/pdf/2305.19383v1",
    "categories": [
      "quant-ph",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2007.04239v1",
    "title": "A Survey on Transfer Learning in Natural Language Processing",
    "authors": [
      "Zaid Alyafeai",
      "Maged Saeed AlShaibani",
      "Irfan Ahmad"
    ],
    "abstract": "Deep learning models usually require a huge amount of data. However, these\nlarge datasets are not always attainable. This is common in many challenging\nNLP tasks. Consider Neural Machine Translation, for instance, where curating\nsuch large datasets may not be possible specially for low resource languages.\nAnother limitation of deep learning models is the demand for huge computing\nresources. These obstacles motivate research to question the possibility of\nknowledge transfer using large trained models. The demand for transfer learning\nis increasing as many large models are emerging. In this survey, we feature the\nrecent transfer learning advances in the field of NLP. We also provide a\ntaxonomy for categorizing different transfer learning approaches from the\nliterature.",
    "published": "2020-05-31T21:52:31Z",
    "pdf_url": "http://arxiv.org/pdf/2007.04239v1",
    "categories": [
      "cs.CL",
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2007.12969v1",
    "title": "Constructing a Testbed for Psychometric Natural Language Processing",
    "authors": [
      "Ahmed Abbasi",
      "David G. Dobolyi",
      "Richard G. Netemeyer"
    ],
    "abstract": "Psychometric measures of ability, attitudes, perceptions, and beliefs are\ncrucial for understanding user behaviors in various contexts including health,\nsecurity, e-commerce, and finance. Traditionally, psychometric dimensions have\nbeen measured and collected using survey-based methods. Inferring such\nconstructs from user-generated text could afford opportunities for timely,\nunobtrusive, collection and analysis. In this paper, we describe our efforts to\nconstruct a corpus for psychometric natural language processing (NLP). We\ndiscuss our multi-step process to align user text with their survey-based\nresponse items and provide an overview of the resulting testbed which\nencompasses survey-based psychometric measures and accompanying user-generated\ntext from over 8,500 respondents. We report preliminary results on the use of\nthe text to categorize/predict users' survey response labels. We also discuss\nthe important implications of our work and resulting testbed for future\npsychometric NLP research.",
    "published": "2020-07-25T16:29:24Z",
    "pdf_url": "http://arxiv.org/pdf/2007.12969v1",
    "categories": [
      "cs.CL",
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "2012.09823v1",
    "title": "Continual Lifelong Learning in Natural Language Processing: A Survey",
    "authors": [
      "Magdalena Biesialska",
      "Katarzyna Biesialska",
      "Marta R. Costa-jussà"
    ],
    "abstract": "Continual learning (CL) aims to enable information systems to learn from a\ncontinuous data stream across time. However, it is difficult for existing deep\nlearning architectures to learn a new task without largely forgetting\npreviously acquired knowledge. Furthermore, CL is particularly challenging for\nlanguage learning, as natural language is ambiguous: it is discrete,\ncompositional, and its meaning is context-dependent. In this work, we look at\nthe problem of CL through the lens of various NLP tasks. Our survey discusses\nmajor challenges in CL and current methods applied in neural network models. We\nalso provide a critical review of the existing CL evaluation methods and\ndatasets in NLP. Finally, we present our outlook on future research directions.",
    "published": "2020-12-17T18:44:36Z",
    "pdf_url": "http://arxiv.org/pdf/2012.09823v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "2012.15495v1",
    "title": "Towards Zero-Shot Knowledge Distillation for Natural Language Processing",
    "authors": [
      "Ahmad Rashid",
      "Vasileios Lioutas",
      "Abbas Ghaddar",
      "Mehdi Rezagholizadeh"
    ],
    "abstract": "Knowledge Distillation (KD) is a common knowledge transfer algorithm used for\nmodel compression across a variety of deep learning based natural language\nprocessing (NLP) solutions. In its regular manifestations, KD requires access\nto the teacher's training data for knowledge transfer to the student network.\nHowever, privacy concerns, data regulations and proprietary reasons may prevent\naccess to such data. We present, to the best of our knowledge, the first work\non Zero-Shot Knowledge Distillation for NLP, where the student learns from the\nmuch larger teacher without any task specific data. Our solution combines out\nof domain data and adversarial training to learn the teacher's output\ndistribution. We investigate six tasks from the GLUE benchmark and demonstrate\nthat we can achieve between 75% and 92% of the teacher's classification score\n(accuracy or F1) while compressing the model 30 times.",
    "published": "2020-12-31T08:16:29Z",
    "pdf_url": "http://arxiv.org/pdf/2012.15495v1",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2105.02388v1",
    "title": "Security Vulnerability Detection Using Deep Learning Natural Language\n  Processing",
    "authors": [
      "Noah Ziems",
      "Shaoen Wu"
    ],
    "abstract": "Detecting security vulnerabilities in software before they are exploited has\nbeen a challenging problem for decades. Traditional code analysis methods have\nbeen proposed, but are often ineffective and inefficient. In this work, we\nmodel software vulnerability detection as a natural language processing (NLP)\nproblem with source code treated as texts, and address the automated software\nvenerability detection with recent advanced deep learning NLP models assisted\nby transfer learning on written English. For training and testing, we have\npreprocessed the NIST NVD/SARD databases and built a dataset of over 100,000\nfiles in $C$ programming language with 123 types of vulnerabilities. The\nextensive experiments generate the best performance of over 93\\% accuracy in\ndetecting security vulnerabilities.",
    "published": "2021-05-06T01:28:21Z",
    "pdf_url": "http://arxiv.org/pdf/2105.02388v1",
    "categories": [
      "cs.CR",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2109.02846v1",
    "title": "Datasets: A Community Library for Natural Language Processing",
    "authors": [
      "Quentin Lhoest",
      "Albert Villanova del Moral",
      "Yacine Jernite",
      "Abhishek Thakur",
      "Patrick von Platen",
      "Suraj Patil",
      "Julien Chaumond",
      "Mariama Drame",
      "Julien Plu",
      "Lewis Tunstall",
      "Joe Davison",
      "Mario Šaško",
      "Gunjan Chhablani",
      "Bhavitvya Malik",
      "Simon Brandeis",
      "Teven Le Scao",
      "Victor Sanh",
      "Canwen Xu",
      "Nicolas Patry",
      "Angelina McMillan-Major",
      "Philipp Schmid",
      "Sylvain Gugger",
      "Clément Delangue",
      "Théo Matussière",
      "Lysandre Debut",
      "Stas Bekman",
      "Pierric Cistac",
      "Thibault Goehringer",
      "Victor Mustar",
      "François Lagunas",
      "Alexander M. Rush",
      "Thomas Wolf"
    ],
    "abstract": "The scale, variety, and quantity of publicly-available NLP datasets has grown\nrapidly as researchers propose new tasks, larger models, and novel benchmarks.\nDatasets is a community library for contemporary NLP designed to support this\necosystem. Datasets aims to standardize end-user interfaces, versioning, and\ndocumentation, while providing a lightweight front-end that behaves similarly\nfor small datasets as for internet-scale corpora. The design of the library\nincorporates a distributed, community-driven approach to adding datasets and\ndocumenting usage. After a year of development, the library now includes more\nthan 650 unique datasets, has more than 250 contributors, and has helped\nsupport a variety of novel cross-dataset research projects and shared tasks.\nThe library is available at https://github.com/huggingface/datasets.",
    "published": "2021-09-07T03:59:22Z",
    "pdf_url": "http://arxiv.org/pdf/2109.02846v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2201.01956v2",
    "title": "HuSpaCy: an industrial-strength Hungarian natural language processing\n  toolkit",
    "authors": [
      "György Orosz",
      "Zsolt Szántó",
      "Péter Berkecz",
      "Gergő Szabó",
      "Richárd Farkas"
    ],
    "abstract": "Although there are a couple of open-source language processing pipelines\navailable for Hungarian, none of them satisfies the requirements of today's NLP\napplications. A language processing pipeline should consist of close to\nstate-of-the-art lemmatization, morphosyntactic analysis, entity recognition\nand word embeddings. Industrial text processing applications have to satisfy\nnon-functional software quality requirements, what is more, frameworks\nsupporting multiple languages are more and more favored. This paper introduces\nHuSpaCy, an industry-ready Hungarian language processing toolkit. The presented\ntool provides components for the most important basic linguistic analysis\ntasks. It is open-source and is available under a permissive license. Our\nsystem is built upon spaCy's NLP components resulting in an easily usable, fast\nyet accurate application. Experiments confirm that HuSpaCy has high accuracy\nwhile maintaining resource-efficient prediction capabilities.",
    "published": "2022-01-06T07:49:45Z",
    "pdf_url": "http://arxiv.org/pdf/2201.01956v2",
    "categories": [
      "cs.CL",
      "stat.ML",
      "68T50",
      "I.2.7"
    ]
  },
  {
    "arxiv_id": "2203.07580v1",
    "title": "TSM: Measuring the Enticement of Honeyfiles with Natural Language\n  Processing",
    "authors": [
      "Roelien C. Timmer",
      "David Liebowitz",
      "Surya Nepal",
      "Salil Kanhere"
    ],
    "abstract": "Honeyfile deployment is a useful breach detection method in cyber deception\nthat can also inform defenders about the intent and interests of intruders and\nmalicious insiders. A key property of a honeyfile, enticement, is the extent to\nwhich the file can attract an intruder to interact with it. We introduce a\nnovel metric, Topic Semantic Matching (TSM), which uses topic modelling to\nrepresent files in the repository and semantic matching in an embedding vector\nspace to compare honeyfile text and topic words robustly. We also present a\nhoneyfile corpus created with different Natural Language Processing (NLP)\nmethods. Experiments show that TSM is effective in inter-corpus comparisons and\nis a promising tool to measure the enticement of honeyfiles. TSM is the first\nmeasure to use NLP techniques to quantify the enticement of honeyfile content\nthat compares the essential topical content of local contexts to honeyfiles and\nis robust to paraphrasing.",
    "published": "2022-03-15T01:07:51Z",
    "pdf_url": "http://arxiv.org/pdf/2203.07580v1",
    "categories": [
      "cs.CL",
      "cs.CR",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2205.14728v2",
    "title": "L3Cube-MahaNLP: Marathi Natural Language Processing Datasets, Models,\n  and Library",
    "authors": [
      "Raviraj Joshi"
    ],
    "abstract": "Despite being the third most popular language in India, the Marathi language\nlacks useful NLP resources. Moreover, popular NLP libraries do not have support\nfor the Marathi language. With L3Cube-MahaNLP, we aim to build resources and a\nlibrary for Marathi natural language processing. We present datasets and\ntransformer models for supervised tasks like sentiment analysis, named entity\nrecognition, and hate speech detection. We have also published a monolingual\nMarathi corpus for unsupervised language modeling tasks. Overall we present\nMahaCorpus, MahaSent, MahaNER, and MahaHate datasets and their corresponding\nMahaBERT models fine-tuned on these datasets. We aim to move ahead of benchmark\ndatasets and prepare useful resources for Marathi. The resources are available\nat https://github.com/l3cube-pune/MarathiNLP.",
    "published": "2022-05-29T17:51:00Z",
    "pdf_url": "http://arxiv.org/pdf/2205.14728v2",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2206.14774v3",
    "title": "TweetNLP: Cutting-Edge Natural Language Processing for Social Media",
    "authors": [
      "Jose Camacho-Collados",
      "Kiamehr Rezaee",
      "Talayeh Riahi",
      "Asahi Ushio",
      "Daniel Loureiro",
      "Dimosthenis Antypas",
      "Joanne Boisson",
      "Luis Espinosa-Anke",
      "Fangyu Liu",
      "Eugenio Martínez-Cámara",
      "Gonzalo Medina",
      "Thomas Buhrmann",
      "Leonardo Neves",
      "Francesco Barbieri"
    ],
    "abstract": "In this paper we present TweetNLP, an integrated platform for Natural\nLanguage Processing (NLP) in social media. TweetNLP supports a diverse set of\nNLP tasks, including generic focus areas such as sentiment analysis and named\nentity recognition, as well as social media-specific tasks such as emoji\nprediction and offensive language identification. Task-specific systems are\npowered by reasonably-sized Transformer-based language models specialized on\nsocial media text (in particular, Twitter) which can be run without the need\nfor dedicated hardware or cloud services. The main contributions of TweetNLP\nare: (1) an integrated Python library for a modern toolkit supporting social\nmedia analysis using our various task-specific models adapted to the social\ndomain; (2) an interactive online demo for codeless experimentation using our\nmodels; and (3) a tutorial covering a wide variety of typical social media\napplications.",
    "published": "2022-06-29T17:16:58Z",
    "pdf_url": "http://arxiv.org/pdf/2206.14774v3",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2211.12701v2",
    "title": "Continual Learning of Natural Language Processing Tasks: A Survey",
    "authors": [
      "Zixuan Ke",
      "Bing Liu"
    ],
    "abstract": "Continual learning (CL) is a learning paradigm that emulates the human\ncapability of learning and accumulating knowledge continually without\nforgetting the previously learned knowledge and also transferring the learned\nknowledge to help learn new tasks better. This survey presents a comprehensive\nreview and analysis of the recent progress of CL in NLP, which has significant\ndifferences from CL in computer vision and machine learning. It covers (1) all\nCL settings with a taxonomy of existing techniques; (2) catastrophic forgetting\n(CF) prevention, (3) knowledge transfer (KT), which is particularly important\nfor NLP tasks; and (4) some theory and the hidden challenge of inter-task class\nseparation (ICS). (1), (3) and (4) have not been included in the existing\nsurvey. Finally, a list of future directions is discussed.",
    "published": "2022-11-23T04:46:28Z",
    "pdf_url": "http://arxiv.org/pdf/2211.12701v2",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "2302.13812v1",
    "title": "Adapting Pre-trained Language Models for Quantum Natural Language\n  Processing",
    "authors": [
      "Qiuchi Li",
      "Benyou Wang",
      "Yudong Zhu",
      "Christina Lioma",
      "Qun Liu"
    ],
    "abstract": "The emerging classical-quantum transfer learning paradigm has brought a\ndecent performance to quantum computational models in many tasks, such as\ncomputer vision, by enabling a combination of quantum models and classical\npre-trained neural networks. However, using quantum computing with pre-trained\nmodels has yet to be explored in natural language processing (NLP). Due to the\nhigh linearity constraints of the underlying quantum computing infrastructures,\nexisting Quantum NLP models are limited in performance on real tasks. We fill\nthis gap by pre-training a sentence state with complex-valued BERT-like\narchitecture, and adapting it to the classical-quantum transfer learning scheme\nfor sentence classification. On quantum simulation experiments, the pre-trained\nrepresentation can bring 50\\% to 60\\% increases to the capacity of end-to-end\nquantum models.",
    "published": "2023-02-24T14:59:02Z",
    "pdf_url": "http://arxiv.org/pdf/2302.13812v1",
    "categories": [
      "quant-ph",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2306.14918v1",
    "title": "Utilizing Natural Language Processing for Automated Assessment of\n  Classroom Discussion",
    "authors": [
      "Nhat Tran",
      "Benjamin Pierce",
      "Diane Litman",
      "Richard Correnti",
      "Lindsay Clare Matsumura"
    ],
    "abstract": "Rigorous and interactive class discussions that support students to engage in\nhigh-level thinking and reasoning are essential to learning and are a central\ncomponent of most teaching interventions. However, formally assessing\ndiscussion quality 'at scale' is expensive and infeasible for most researchers.\nIn this work, we experimented with various modern natural language processing\n(NLP) techniques to automatically generate rubric scores for individual\ndimensions of classroom text discussion quality. Specifically, we worked on a\ndataset of 90 classroom discussion transcripts consisting of over 18000 turns\nannotated with fine-grained Analyzing Teaching Moves (ATM) codes and focused on\nfour Instructional Quality Assessment (IQA) rubrics. Despite the limited amount\nof data, our work shows encouraging results in some of the rubrics while\nsuggesting that there is room for improvement in the others. We also found that\ncertain NLP approaches work better for certain rubrics.",
    "published": "2023-06-21T16:45:24Z",
    "pdf_url": "http://arxiv.org/pdf/2306.14918v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2307.11032v1",
    "title": "A Natural Language Processing Approach to Malware Classification",
    "authors": [
      "Ritik Mehta",
      "Olha Jurečková",
      "Mark Stamp"
    ],
    "abstract": "Many different machine learning and deep learning techniques have been\nsuccessfully employed for malware detection and classification. Examples of\npopular learning techniques in the malware domain include Hidden Markov Models\n(HMM), Random Forests (RF), Convolutional Neural Networks (CNN), Support Vector\nMachines (SVM), and Recurrent Neural Networks (RNN) such as Long Short-Term\nMemory (LSTM) networks. In this research, we consider a hybrid architecture,\nwhere HMMs are trained on opcode sequences, and the resulting hidden states of\nthese trained HMMs are used as feature vectors in various classifiers. In this\ncontext, extracting the HMM hidden state sequences can be viewed as a form of\nfeature engineering that is somewhat analogous to techniques that are commonly\nemployed in Natural Language Processing (NLP). We find that this NLP-based\napproach outperforms other popular techniques on a challenging malware dataset,\nwith an HMM-Random Forrest model yielding the best results.",
    "published": "2023-07-07T23:16:23Z",
    "pdf_url": "http://arxiv.org/pdf/2307.11032v1",
    "categories": [
      "cs.CR",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2312.01221v1",
    "title": "Enabling Quantum Natural Language Processing for Hindi Language",
    "authors": [
      "Naman Srivastava",
      "Gaurang Belekar",
      "Sunil Saumya",
      "Aswath Babu H"
    ],
    "abstract": "Quantum Natural Language Processing (QNLP) is taking huge leaps in solving\nthe shortcomings of classical Natural Language Processing (NLP) techniques and\nmoving towards a more \"Explainable\" NLP system. The current literature around\nQNLP focuses primarily on implementing QNLP techniques in sentences in the\nEnglish language. In this paper, we propose to enable the QNLP approach to\nHINDI, which is the third most spoken language in South Asia. We present the\nprocess of building the parameterized quantum circuits required to undertake\nQNLP on Hindi sentences. We use the pregroup representation of Hindi and the\nDisCoCat framework to draw sentence diagrams. Later, we translate these\ndiagrams to Parameterised Quantum Circuits based on Instantaneous Quantum\nPolynomial (IQP) style ansatz. Using these parameterized quantum circuits\nallows one to train grammar and topic-aware sentence classifiers for the Hindi\nLanguage.",
    "published": "2023-12-02T20:19:11Z",
    "pdf_url": "http://arxiv.org/pdf/2312.01221v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2404.01443v1",
    "title": "Enterprise Use Cases Combining Knowledge Graphs and Natural Language\n  Processing",
    "authors": [
      "Phillip Schneider",
      "Tim Schopf",
      "Juraj Vladika",
      "Florian Matthes"
    ],
    "abstract": "Knowledge management is a critical challenge for enterprises in today's\ndigital world, as the volume and complexity of data being generated and\ncollected continue to grow incessantly. Knowledge graphs (KG) emerged as a\npromising solution to this problem by providing a flexible, scalable, and\nsemantically rich way to organize and make sense of data. This paper builds\nupon a recent survey of the research literature on combining KGs and Natural\nLanguage Processing (NLP). Based on selected application scenarios from\nenterprise context, we discuss synergies that result from such a combination.\nWe cover various approaches from the three core areas of KG construction,\nreasoning as well as KG-based NLP tasks. In addition to explaining innovative\nenterprise use cases, we assess their maturity in terms of practical\napplicability and conclude with an outlook on emergent application areas for\nthe future.",
    "published": "2024-04-01T19:28:52Z",
    "pdf_url": "http://arxiv.org/pdf/2404.01443v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2412.18036v2",
    "title": "Explainability in Neural Networks for Natural Language Processing Tasks",
    "authors": [
      "Melkamu Mersha",
      "Mingiziem Bitewa",
      "Tsion Abay",
      "Jugal Kalita"
    ],
    "abstract": "Neural networks are widely regarded as black-box models, creating significant\nchallenges in understanding their inner workings, especially in natural\nlanguage processing (NLP) applications. To address this opacity, model\nexplanation techniques like Local Interpretable Model-Agnostic Explanations\n(LIME) have emerged as essential tools for providing insights into the behavior\nof these complex systems. This study leverages LIME to interpret a multi-layer\nperceptron (MLP) neural network trained on a text classification task. By\nanalyzing the contribution of individual features to model predictions, the\nLIME approach enhances interpretability and supports informed decision-making.\nDespite its effectiveness in offering localized explanations, LIME has\nlimitations in capturing global patterns and feature interactions. This\nresearch highlights the strengths and shortcomings of LIME and proposes\ndirections for future work to achieve more comprehensive interpretability in\nneural NLP models.",
    "published": "2024-12-23T23:09:56Z",
    "pdf_url": "http://arxiv.org/pdf/2412.18036v2",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2505.17642v2",
    "title": "A Survey on Stereotype Detection in Natural Language Processing",
    "authors": [
      "Alessandra Teresa Cignarella",
      "Anastasia Giachanou",
      "Els Lefever"
    ],
    "abstract": "Stereotypes influence social perceptions and can escalate into discrimination\nand violence. While NLP research has extensively addressed gender bias and hate\nspeech, stereotype detection remains an emerging field with significant\nsocietal implications. In this work is presented a survey of existing research,\nanalyzing definitions from psychology, sociology, and philosophy. A\nsemi-automatic literature review was performed by using Semantic Scholar. We\nretrieved and filtered over 6,000 papers (in the year range 2000-2025),\nidentifying key trends, methodologies, challenges and future directions. The\nfindings emphasize stereotype detection as a potential early-monitoring tool to\nprevent bias escalation and the rise of hate speech. Conclusions highlight the\nneed for a broader, multilingual, and intersectional approach in NLP studies.",
    "published": "2025-05-23T09:03:56Z",
    "pdf_url": "http://arxiv.org/pdf/2505.17642v2",
    "categories": [
      "cs.CL",
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "2103.11441v3",
    "title": "TextFlint: Unified Multilingual Robustness Evaluation Toolkit for\n  Natural Language Processing",
    "authors": [
      "Tao Gui",
      "Xiao Wang",
      "Qi Zhang",
      "Qin Liu",
      "Yicheng Zou",
      "Xin Zhou",
      "Rui Zheng",
      "Chong Zhang",
      "Qinzhuo Wu",
      "Jiacheng Ye",
      "Zexiong Pang",
      "Yongxin Zhang",
      "Zhengyan Li",
      "Ruotian Ma",
      "Zichu Fei",
      "Ruijian Cai",
      "Jun Zhao",
      "Xingwu Hu",
      "Zhiheng Yan",
      "Yiding Tan",
      "Yuan Hu",
      "Qiyuan Bian",
      "Zhihua Liu",
      "Bolin Zhu",
      "Shan Qin",
      "Xiaoyu Xing",
      "Jinlan Fu",
      "Yue Zhang",
      "Minlong Peng",
      "Xiaoqing Zheng",
      "Yaqian Zhou",
      "Zhongyu Wei",
      "Xipeng Qiu",
      "Xuanjing Huang"
    ],
    "abstract": "Various robustness evaluation methodologies from different perspectives have\nbeen proposed for different natural language processing (NLP) tasks. These\nmethods have often focused on either universal or task-specific generalization\ncapabilities. In this work, we propose a multilingual robustness evaluation\nplatform for NLP tasks (TextFlint) that incorporates universal text\ntransformation, task-specific transformation, adversarial attack,\nsubpopulation, and their combinations to provide comprehensive robustness\nanalysis. TextFlint enables practitioners to automatically evaluate their\nmodels from all aspects or to customize their evaluations as desired with just\na few lines of code. To guarantee user acceptability, all the text\ntransformations are linguistically based, and we provide a human evaluation for\neach one. TextFlint generates complete analytical reports as well as targeted\naugmented data to address the shortcomings of the model's robustness. To\nvalidate TextFlint's utility, we performed large-scale empirical evaluations\n(over 67,000 evaluations) on state-of-the-art deep learning models, classic\nsupervised methods, and real-world systems. Almost all models showed\nsignificant performance degradation, including a decline of more than 50% of\nBERT's prediction accuracy on tasks such as aspect-level sentiment\nclassification, named entity recognition, and natural language inference.\nTherefore, we call for the robustness to be included in the model evaluation,\nso as to promote the healthy development of NLP technology.",
    "published": "2021-03-21T17:20:38Z",
    "pdf_url": "http://arxiv.org/pdf/2103.11441v3",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2104.08815v3",
    "title": "FedNLP: Benchmarking Federated Learning Methods for Natural Language\n  Processing Tasks",
    "authors": [
      "Bill Yuchen Lin",
      "Chaoyang He",
      "Zihang Zeng",
      "Hulin Wang",
      "Yufen Huang",
      "Christophe Dupuy",
      "Rahul Gupta",
      "Mahdi Soltanolkotabi",
      "Xiang Ren",
      "Salman Avestimehr"
    ],
    "abstract": "Increasing concerns and regulations about data privacy and sparsity\nnecessitate the study of privacy-preserving, decentralized learning methods for\nnatural language processing (NLP) tasks. Federated learning (FL) provides\npromising approaches for a large number of clients (e.g., personal devices or\norganizations) to collaboratively learn a shared global model to benefit all\nclients while allowing users to keep their data locally. Despite interest in\nstudying FL methods for NLP tasks, a systematic comparison and analysis is\nlacking in the literature. Herein, we present the FedNLP, a benchmarking\nframework for evaluating federated learning methods on four different task\nformulations: text classification, sequence tagging, question answering, and\nseq2seq. We propose a universal interface between Transformer-based language\nmodels (e.g., BERT, BART) and FL methods (e.g., FedAvg, FedOPT, etc.) under\nvarious non-IID partitioning strategies. Our extensive experiments with FedNLP\nprovide empirical comparisons between FL methods and helps us better understand\nthe inherent challenges of this direction. The comprehensive analysis points to\nintriguing and exciting future research aimed at developing FL methods for NLP\ntasks.",
    "published": "2021-04-18T11:04:49Z",
    "pdf_url": "http://arxiv.org/pdf/2104.08815v3",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2305.14716v1",
    "title": "GlobalBench: A Benchmark for Global Progress in Natural Language\n  Processing",
    "authors": [
      "Yueqi Song",
      "Catherine Cui",
      "Simran Khanuja",
      "Pengfei Liu",
      "Fahim Faisal",
      "Alissa Ostapenko",
      "Genta Indra Winata",
      "Alham Fikri Aji",
      "Samuel Cahyawijaya",
      "Yulia Tsvetkov",
      "Antonios Anastasopoulos",
      "Graham Neubig"
    ],
    "abstract": "Despite the major advances in NLP, significant disparities in NLP system\nperformance across languages still exist. Arguably, these are due to uneven\nresource allocation and sub-optimal incentives to work on less resourced\nlanguages. To track and further incentivize the global development of equitable\nlanguage technology, we introduce GlobalBench. Prior multilingual benchmarks\nare static and have focused on a limited number of tasks and languages. In\ncontrast, GlobalBench is an ever-expanding collection that aims to dynamically\ntrack progress on all NLP datasets in all languages. Rather than solely\nmeasuring accuracy, GlobalBench also tracks the estimated per-speaker utility\nand equity of technology across all languages, providing a multi-faceted view\nof how language technology is serving people of the world. Furthermore,\nGlobalBench is designed to identify the most under-served languages, and\nrewards research efforts directed towards those languages. At present, the most\nunder-served languages are the ones with a relatively high population, but\nnonetheless overlooked by composite multilingual benchmarks (like Punjabi,\nPortuguese, and Wu Chinese). Currently, GlobalBench covers 966 datasets in 190\nlanguages, and has 1,128 system submissions spanning 62 languages.",
    "published": "2023-05-24T04:36:32Z",
    "pdf_url": "http://arxiv.org/pdf/2305.14716v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "1806.04820v2",
    "title": "Natural Language Processing for EHR-Based Computational Phenotyping",
    "authors": [
      "Zexian Zeng",
      "Yu Deng",
      "Xiaoyu Li",
      "Tristan Naumann",
      "Yuan Luo"
    ],
    "abstract": "This article reviews recent advances in applying natural language processing\n(NLP) to Electronic Health Records (EHRs) for computational phenotyping.\nNLP-based computational phenotyping has numerous applications including\ndiagnosis categorization, novel phenotype discovery, clinical trial screening,\npharmacogenomics, drug-drug interaction (DDI) and adverse drug event (ADE)\ndetection, as well as genome-wide and phenome-wide association studies.\nSignificant progress has been made in algorithm development and resource\nconstruction for computational phenotyping. Among the surveyed methods,\nwell-designed keyword search and rule-based systems often achieve good\nperformance. However, the construction of keyword and rule lists requires\nsignificant manual effort, which is difficult to scale. Supervised machine\nlearning models have been favored because they are capable of acquiring both\nclassification patterns and structures from data. Recently, deep learning and\nunsupervised learning have received growing attention, with the former favored\nfor its performance and the latter for its ability to find novel phenotypes.\nIntegrating heterogeneous data sources have become increasingly important and\nhave shown promise in improving model performance. Often better performance is\nachieved by combining multiple modalities of information. Despite these many\nadvances, challenges and opportunities remain for NLP-based computational\nphenotyping, including better model interpretability and generalizability, and\nproper characterization of feature relations in clinical narratives",
    "published": "2018-06-13T02:14:19Z",
    "pdf_url": "http://arxiv.org/pdf/1806.04820v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2105.12202v1",
    "title": "Context-Sensitive Visualization of Deep Learning Natural Language\n  Processing Models",
    "authors": [
      "Andrew Dunn",
      "Diana Inkpen",
      "Răzvan Andonie"
    ],
    "abstract": "The introduction of Transformer neural networks has changed the landscape of\nNatural Language Processing (NLP) during the last years. So far, none of the\nvisualization systems has yet managed to examine all the facets of the\nTransformers. This gave us the motivation of the current work. We propose a new\nNLP Transformer context-sensitive visualization method that leverages existing\nNLP tools to find the most significant groups of tokens (words) that have the\ngreatest effect on the output, thus preserving some context from the original\ntext. First, we use a sentence-level dependency parser to highlight promising\nword groups. The dependency parser creates a tree of relationships between the\nwords in the sentence. Next, we systematically remove adjacent and non-adjacent\ntuples of \\emph{n} tokens from the input text, producing several new texts with\nthose tokens missing. The resulting texts are then passed to a pre-trained BERT\nmodel. The classification output is compared with that of the full text, and\nthe difference in the activation strength is recorded. The modified texts that\nproduce the largest difference in the target classification output neuron are\nselected, and the combination of removed words are then considered to be the\nmost influential on the model's output. Finally, the most influential word\ncombinations are visualized in a heatmap.",
    "published": "2021-05-25T20:26:38Z",
    "pdf_url": "http://arxiv.org/pdf/2105.12202v1",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2211.04256v1",
    "title": "Bridging Fairness and Environmental Sustainability in Natural Language\n  Processing",
    "authors": [
      "Marius Hessenthaler",
      "Emma Strubell",
      "Dirk Hovy",
      "Anne Lauscher"
    ],
    "abstract": "Fairness and environmental impact are important research directions for the\nsustainable development of artificial intelligence. However, while each topic\nis an active research area in natural language processing (NLP), there is a\nsurprising lack of research on the interplay between the two fields. This\nlacuna is highly problematic, since there is increasing evidence that an\nexclusive focus on fairness can actually hinder environmental sustainability,\nand vice versa. In this work, we shed light on this crucial intersection in NLP\nby (1) investigating the efficiency of current fairness approaches through\nsurveying example methods for reducing unfair stereotypical bias from the\nliterature, and (2) evaluating a common technique to reduce energy consumption\n(and thus environmental impact) of English NLP models, knowledge distillation\n(KD), for its impact on fairness. In this case study, we evaluate the effect of\nimportant KD factors, including layer and dimensionality reduction, with\nrespect to: (a) performance on the distillation task (natural language\ninference and semantic similarity prediction), and (b) multiple measures and\ndimensions of stereotypical bias (e.g., gender bias measured via the Word\nEmbedding Association Test). Our results lead us to clarify current assumptions\nregarding the effect of KD on unfair bias: contrary to other findings, we show\nthat KD can actually decrease model fairness.",
    "published": "2022-11-08T14:05:07Z",
    "pdf_url": "http://arxiv.org/pdf/2211.04256v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2303.16039v2",
    "title": "Exploring Natural Language Processing Methods for Interactive Behaviour\n  Modelling",
    "authors": [
      "Guanhua Zhang",
      "Matteo Bortoletto",
      "Zhiming Hu",
      "Lei Shi",
      "Mihai Bâce",
      "Andreas Bulling"
    ],
    "abstract": "Analysing and modelling interactive behaviour is an important topic in\nhuman-computer interaction (HCI) and a key requirement for the development of\nintelligent interactive systems. Interactive behaviour has a sequential\n(actions happen one after another) and hierarchical (a sequence of actions\nforms an activity driven by interaction goals) structure, which may be similar\nto the structure of natural language. Designed based on such a structure,\nnatural language processing (NLP) methods have achieved groundbreaking success\nin various downstream tasks. However, few works linked interactive behaviour\nwith natural language. In this paper, we explore the similarity between\ninteractive behaviour and natural language by applying an NLP method, byte pair\nencoding (BPE), to encode mouse and keyboard behaviour. We then analyse the\nvocabulary, i.e., the set of action sequences, learnt by BPE, as well as use\nthe vocabulary to encode the input behaviour for interactive task recognition.\nAn existing dataset collected in constrained lab settings and our novel\nout-of-the-lab dataset were used for evaluation. Results show that this natural\nlanguage-inspired approach not only learns action sequences that reflect\nspecific interaction goals, but also achieves higher F1 scores on task\nrecognition than other methods. Our work reveals the similarity between\ninteractive behaviour and natural language, and presents the potential of\napplying the new pack of methods that leverage insights from NLP to model\ninteractive behaviour in HCI.",
    "published": "2023-03-28T15:15:03Z",
    "pdf_url": "http://arxiv.org/pdf/2303.16039v2",
    "categories": [
      "cs.HC"
    ]
  },
  {
    "arxiv_id": "2307.04648v1",
    "title": "Can ChatGPT's Responses Boost Traditional Natural Language Processing?",
    "authors": [
      "Mostafa M. Amin",
      "Erik Cambria",
      "Björn W. Schuller"
    ],
    "abstract": "The employment of foundation models is steadily expanding, especially with\nthe launch of ChatGPT and the release of other foundation models. These models\nhave shown the potential of emerging capabilities to solve problems, without\nbeing particularly trained to solve. A previous work demonstrated these\nemerging capabilities in affective computing tasks; the performance quality was\nsimilar to traditional Natural Language Processing (NLP) techniques, but\nfalling short of specialised trained models, like fine-tuning of the RoBERTa\nlanguage model. In this work, we extend this by exploring if ChatGPT has novel\nknowledge that would enhance existing specialised models when they are fused\ntogether. We achieve this by investigating the utility of verbose responses\nfrom ChatGPT about solving a downstream task, in addition to studying the\nutility of fusing that with existing NLP methods. The study is conducted on\nthree affective computing problems, namely sentiment analysis, suicide tendency\ndetection, and big-five personality assessment. The results conclude that\nChatGPT has indeed novel knowledge that can improve existing NLP techniques by\nway of fusion, be it early or late fusion.",
    "published": "2023-07-06T15:42:05Z",
    "pdf_url": "http://arxiv.org/pdf/2307.04648v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2206.02171v3",
    "title": "Near-Term Advances in Quantum Natural Language Processing",
    "authors": [
      "Dominic Widdows",
      "Aaranya Alexander",
      "Daiwei Zhu",
      "Chase Zimmerman",
      "Arunava Majumder"
    ],
    "abstract": "This paper describes experiments showing that some tasks in natural language\nprocessing (NLP) can already be performed using quantum computers, though so\nfar only with small datasets.\n  We demonstrate various approaches to topic classification. The first uses an\nexplicit word-based approach, in which word-topic scoring weights are\nimplemented as fractional rotations of individual qubit, and a new phrase is\nclassified based on the accumulation of these weights in a scoring qubit using\nentangling controlled-NOT gates. This is compared with more scalable quantum\nencodings of word embedding vectors, which are used in the computation of\nkernel values in a quantum support vector machine: this approach achieved an\naverage of 62% accuracy on classification tasks involving over 10000 words,\nwhich is the largest such quantum computing experiment to date.\n  We describe a quantum probability approach to bigram modeling that can be\napplied to sequences of words and formal concepts, investigating a generative\napproximation to these distributions using a quantum circuit Born machine, and\nan approach to ambiguity resolution in verb-noun composition using single-qubit\nrotations for simple nouns and 2-qubit controlled-NOT gates for simple verbs.\n  The smaller systems described have been run successfully on physical quantum\ncomputers, and the larger ones have been simulated. We show that statistically\nmeaningful results can be obtained using real datasets, but this is much more\ndifficult to predict than with easier artificial language examples used\npreviously in developing quantum NLP systems.\n  Other approaches to quantum NLP are compared, partly with respect to\ncontemporary issues including informal language, fluency, and truthfulness.",
    "published": "2022-06-05T13:10:46Z",
    "pdf_url": "http://arxiv.org/pdf/2206.02171v3",
    "categories": [
      "cs.CL",
      "quant-ph"
    ]
  },
  {
    "arxiv_id": "2502.02722v1",
    "title": "Cross-Lingual Transfer for Low-Resource Natural Language Processing",
    "authors": [
      "Iker García-Ferrero"
    ],
    "abstract": "Natural Language Processing (NLP) has seen remarkable advances in recent\nyears, particularly with the emergence of Large Language Models that have\nachieved unprecedented performance across many tasks. However, these\ndevelopments have mainly benefited a small number of high-resource languages\nsuch as English. The majority of languages still face significant challenges\ndue to the scarcity of training data and computational resources. To address\nthis issue, this thesis focuses on cross-lingual transfer learning, a research\narea aimed at leveraging data and models from high-resource languages to\nimprove NLP performance for low-resource languages. Specifically, we focus on\nSequence Labeling tasks such as Named Entity Recognition, Opinion Target\nExtraction, and Argument Mining.\n  The research is structured around three main objectives: (1) advancing\ndata-based cross-lingual transfer learning methods through improved translation\nand annotation projection techniques, (2) developing enhanced model-based\ntransfer learning approaches utilizing state-of-the-art multilingual models,\nand (3) applying these methods to real-world problems while creating\nopen-source resources that facilitate future research in low-resource NLP.\n  More specifically, this thesis presents a new method to improve data-based\ntransfer with T-Projection, a state-of-the-art annotation projection method\nthat leverages text-to-text multilingual models and machine translation\nsystems. T-Projection significantly outperforms previous annotation projection\nmethods by a wide margin. For model-based transfer, we introduce a constrained\ndecoding algorithm that enhances cross-lingual Sequence Labeling in zero-shot\nsettings using text-to-text models. Finally, we develop Medical mT5, the first\nmultilingual text-to-text medical model, demonstrating the practical impact of\nour research on real-world applications.",
    "published": "2025-02-04T21:17:46Z",
    "pdf_url": "http://arxiv.org/pdf/2502.02722v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "1805.12518v2",
    "title": "Incremental Natural Language Processing: Challenges, Strategies, and\n  Evaluation",
    "authors": [
      "Arne Köhn"
    ],
    "abstract": "Incrementality is ubiquitous in human-human interaction and beneficial for\nhuman-computer interaction. It has been a topic of research in different parts\nof the NLP community, mostly with focus on the specific topic at hand even\nthough incremental systems have to deal with similar challenges regardless of\ndomain. In this survey, I consolidate and categorize the approaches,\nidentifying similarities and differences in the computation and data, and show\ntrade-offs that have to be considered. A focus lies on evaluating incremental\nsystems because the standard metrics often fail to capture the incremental\nproperties of a system and coming up with a suitable evaluation scheme is\nnon-trivial.",
    "published": "2018-05-31T15:29:32Z",
    "pdf_url": "http://arxiv.org/pdf/1805.12518v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2106.10899v2",
    "title": "Ad Text Classification with Transformer-Based Natural Language\n  Processing Methods",
    "authors": [
      "Umut Özdil",
      "Büşra Arslan",
      "D. Emre Taşar",
      "Gökçe Polat",
      "Şükrü Ozan"
    ],
    "abstract": "In this study, a natural language processing-based (NLP-based) method is\nproposed for the sector-wise automatic classification of ad texts created on\nonline advertising platforms. Our data set consists of approximately 21,000\nlabeled advertising texts from 12 different sectors. In the study, the\nBidirectional Encoder Representations from Transformers (BERT) model, which is\na transformer-based language model that is recently used in fields such as text\nclassification in the natural language processing literature, was used. The\nclassification efficiencies obtained using a pre-trained BERT model for the\nTurkish language are shown in detail.",
    "published": "2021-06-21T07:38:31Z",
    "pdf_url": "http://arxiv.org/pdf/2106.10899v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2201.00490v2",
    "title": "Learning with Latent Structures in Natural Language Processing: A Survey",
    "authors": [
      "Zhaofeng Wu"
    ],
    "abstract": "While end-to-end learning with fully differentiable models has enabled\ntremendous success in natural language process (NLP) and machine learning,\nthere have been significant recent interests in learning with latent discrete\nstructures to incorporate better inductive biases for improved end-task\nperformance and better interpretability. This paradigm, however, is not\nstraightforwardly amenable to the mainstream gradient-based optimization\nmethods. This work surveys three main families of methods to learn such models:\nsurrogate gradients, continuous relaxation, and marginal likelihood\nmaximization via sampling. We conclude with a review of applications of these\nmethods and an inspection of the learned latent structure that they induce.",
    "published": "2022-01-03T06:16:17Z",
    "pdf_url": "http://arxiv.org/pdf/2201.00490v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2205.11509v1",
    "title": "Information Propagation by Composited Labels in Natural Language\n  Processing",
    "authors": [
      "Takeshi Inagaki"
    ],
    "abstract": "In natural language processing (NLP), labeling on regions of text, such as\nwords, sentences and paragraphs, is a basic task. In this paper, label is\ndefined as map between mention of entity in a region on text and context of\nentity in a broader region on text containing the mention. This definition\nnaturally introduces linkage of entities induced from inclusion relation of\nregions, and connected entities form a graph representing information flow\ndefined by map. It also enables calculation of information loss through map\nusing entropy, and entropy lost is regarded as distance between two entities\nover a path on graph.",
    "published": "2022-05-23T23:19:14Z",
    "pdf_url": "http://arxiv.org/pdf/2205.11509v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2212.05773v2",
    "title": "A Survey on Natural Language Processing for Programming",
    "authors": [
      "Qingfu Zhu",
      "Xianzhen Luo",
      "Fang Liu",
      "Cuiyun Gao",
      "Wanxiang Che"
    ],
    "abstract": "Natural language processing for programming aims to use NLP techniques to\nassist programming. It is increasingly prevalent for its effectiveness in\nimproving productivity. Distinct from natural language, a programming language\nis highly structured and functional. Constructing a structure-based\nrepresentation and a functionality-oriented algorithm is at the heart of\nprogram understanding and generation. In this paper, we conduct a systematic\nreview covering tasks, datasets, evaluation methods, techniques, and models\nfrom the perspective of the structure-based and functionality-oriented\nproperty, aiming to understand the role of the two properties in each\ncomponent. Based on the analysis, we illustrate unexplored areas and suggest\npotential directions for future work.",
    "published": "2022-12-12T08:51:30Z",
    "pdf_url": "http://arxiv.org/pdf/2212.05773v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2402.02864v1",
    "title": "EEVEE: An Easy Annotation Tool for Natural Language Processing",
    "authors": [
      "Axel Sorensen",
      "Siyao Peng",
      "Barbara Plank",
      "Rob van der Goot"
    ],
    "abstract": "Annotation tools are the starting point for creating Natural Language\nProcessing (NLP) datasets. There is a wide variety of tools available; setting\nup these tools is however a hindrance. We propose EEVEE, an annotation tool\nfocused on simplicity, efficiency, and ease of use. It can run directly in the\nbrowser (no setup required) and uses tab-separated files (as opposed to\ncharacter offsets or task-specific formats) for annotation. It allows for\nannotation of multiple tasks on a single dataset and supports four task-types:\nsequence labeling, span labeling, text classification and seq2seq.",
    "published": "2024-02-05T10:24:40Z",
    "pdf_url": "http://arxiv.org/pdf/2402.02864v1",
    "categories": [
      "cs.CL",
      "cs.HC"
    ]
  },
  {
    "arxiv_id": "1710.01025v3",
    "title": "MMCR4NLP: Multilingual Multiway Corpora Repository for Natural Language\n  Processing",
    "authors": [
      "Raj Dabre",
      "Sadao Kurohashi"
    ],
    "abstract": "Multilinguality is gradually becoming ubiquitous in the sense that more and\nmore researchers have successfully shown that using additional languages help\nimprove the results in many Natural Language Processing tasks. Multilingual\nMultiway Corpora (MMC) contain the same sentence in multiple languages. Such\ncorpora have been primarily used for Multi-Source and Pivot Language Machine\nTranslation but are also useful for developing multilingual sequence taggers by\ntransfer learning. While these corpora are available, they are not organized\nfor multilingual experiments and researchers need to write boilerplate code\nevery time they want to use said corpora. Moreover, because there is no\nofficial MMC collection it becomes difficult to compare against existing\napproaches. As such we present our work on creating a unified and\nsystematically organized repository of MMC spanning a large number of\nlanguages. We also provide training, development and test splits for corpora\nwhere official splits are unavailable. We hope that this will help speed up the\npace of multilingual NLP research and ensure that NLP researchers obtain\nresults that are more trustable since they can be compared easily. We indicate\ncorpora sources, extraction procedures if any and relevant statistics. We also\nmake our collection public for research purposes.",
    "published": "2017-10-03T08:19:24Z",
    "pdf_url": "http://arxiv.org/pdf/1710.01025v3",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "1803.07136v1",
    "title": "Dynamic Natural Language Processing with Recurrence Quantification\n  Analysis",
    "authors": [
      "Rick Dale",
      "Nicholas D. Duran",
      "Moreno Coco"
    ],
    "abstract": "Writing and reading are dynamic processes. As an author composes a text, a\nsequence of words is produced. This sequence is one that, the author hopes,\ncauses a revisitation of certain thoughts and ideas in others. These processes\nof composition and revisitation by readers are ordered in time. This means that\ntext itself can be investigated under the lens of dynamical systems. A common\ntechnique for analyzing the behavior of dynamical systems, known as recurrence\nquantification analysis (RQA), can be used as a method for analyzing sequential\nstructure of text. RQA treats text as a sequential measurement, much like a\ntime series, and can thus be seen as a kind of dynamic natural language\nprocessing (NLP). The extension has several benefits. Because it is part of a\nsuite of time series analysis tools, many measures can be extracted in one\ncommon framework. Secondly, the measures have a close relationship with some\ncommonly used measures from natural language processing. Finally, using\nrecurrence analysis offers an opportunity expand analysis of text by developing\ntheoretical descriptions derived from complex dynamic systems. We showcase an\nexample analysis on 8,000 texts from the Gutenberg Project, compare it to\nwell-known NLP approaches, and describe an R package (crqanlp) that can be used\nin conjunction with R library crqa.",
    "published": "2018-03-19T19:45:38Z",
    "pdf_url": "http://arxiv.org/pdf/1803.07136v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2004.04361v2",
    "title": "Calibrating Structured Output Predictors for Natural Language Processing",
    "authors": [
      "Abhyuday Jagannatha",
      "Hong Yu"
    ],
    "abstract": "We address the problem of calibrating prediction confidence for output\nentities of interest in natural language processing (NLP) applications. It is\nimportant that NLP applications such as named entity recognition and question\nanswering produce calibrated confidence scores for their predictions,\nespecially if the system is to be deployed in a safety-critical domain such as\nhealthcare. However, the output space of such structured prediction models is\noften too large to adapt binary or multi-class calibration methods directly. In\nthis study, we propose a general calibration scheme for output entities of\ninterest in neural-network based structured prediction models. Our proposed\nmethod can be used with any binary class calibration scheme and a neural\nnetwork model. Additionally, we show that our calibration method can also be\nused as an uncertainty-aware, entity-specific decoding step to improve the\nperformance of the underlying model at no additional training cost or data\nrequirements. We show that our method outperforms current calibration\ntechniques for named-entity-recognition, part-of-speech and question answering.\nWe also improve our model's performance from our decoding step across several\ntasks and benchmark datasets. Our method improves the calibration and model\nperformance on out-of-domain test scenarios as well.",
    "published": "2020-04-09T04:14:46Z",
    "pdf_url": "http://arxiv.org/pdf/2004.04361v2",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2006.07116v1",
    "title": "NAS-Bench-NLP: Neural Architecture Search Benchmark for Natural Language\n  Processing",
    "authors": [
      "Nikita Klyuchnikov",
      "Ilya Trofimov",
      "Ekaterina Artemova",
      "Mikhail Salnikov",
      "Maxim Fedorov",
      "Evgeny Burnaev"
    ],
    "abstract": "Neural Architecture Search (NAS) is a promising and rapidly evolving research\narea. Training a large number of neural networks requires an exceptional amount\nof computational power, which makes NAS unreachable for those researchers who\nhave limited or no access to high-performance clusters and supercomputers. A\nfew benchmarks with precomputed neural architectures performances have been\nrecently introduced to overcome this problem and ensure more reproducible\nexperiments. However, these benchmarks are only for the computer vision domain\nand, thus, are built from the image datasets and convolution-derived\narchitectures. In this work, we step outside the computer vision domain by\nleveraging the language modeling task, which is the core of natural language\nprocessing (NLP). Our main contribution is as follows: we have provided search\nspace of recurrent neural networks on the text datasets and trained 14k\narchitectures within it; we have conducted both intrinsic and extrinsic\nevaluation of the trained models using datasets for semantic relatedness and\nlanguage understanding evaluation; finally, we have tested several NAS\nalgorithms to demonstrate how the precomputed results can be utilized. We\nbelieve that our results have high potential of usage for both NAS and NLP\ncommunities.",
    "published": "2020-06-12T12:19:06Z",
    "pdf_url": "http://arxiv.org/pdf/2006.07116v1",
    "categories": [
      "cs.LG",
      "cs.CL",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2108.04990v2",
    "title": "Perturbing Inputs for Fragile Interpretations in Deep Natural Language\n  Processing",
    "authors": [
      "Sanchit Sinha",
      "Hanjie Chen",
      "Arshdeep Sekhon",
      "Yangfeng Ji",
      "Yanjun Qi"
    ],
    "abstract": "Interpretability methods like Integrated Gradient and LIME are popular\nchoices for explaining natural language model predictions with relative word\nimportance scores. These interpretations need to be robust for trustworthy NLP\napplications in high-stake areas like medicine or finance. Our paper\ndemonstrates how interpretations can be manipulated by making simple word\nperturbations on an input text. Via a small portion of word-level swaps, these\nadversarial perturbations aim to make the resulting text semantically and\nspatially similar to its seed input (therefore sharing similar\ninterpretations). Simultaneously, the generated examples achieve the same\nprediction label as the seed yet are given a substantially different\nexplanation by the interpretation methods. Our experiments generate fragile\ninterpretations to attack two SOTA interpretation methods, across three popular\nTransformer models and on two different NLP datasets. We observe that the rank\norder correlation drops by over 20% when less than 10% of words are perturbed\non average. Further, rank-order correlation keeps decreasing as more words get\nperturbed. Furthermore, we demonstrate that candidates generated from our\nmethod have good quality metrics.",
    "published": "2021-08-11T02:07:21Z",
    "pdf_url": "http://arxiv.org/pdf/2108.04990v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2202.13871v2",
    "title": "Wastewater Pipe Rating Model Using Natural Language Processing",
    "authors": [
      "Sai Nethra Betgeri",
      "Shashank Reddy Vadyala",
      "John C. Mattews",
      "Hongfang Lu"
    ],
    "abstract": "Closed-circuit video (CCTV) inspection has been the most popular technique\nfor visually evaluating the interior status of pipelines in recent decades.\nCertified inspectors prepare the pipe repair document based on the CCTV\ninspection. The traditional manual method of assessing sewage structural\nconditions from pipe repair documents takes a long time and is prone to human\nmistakes. The automatic identification of necessary texts has received little\nattention. By building an automated framework employing Natural Language\nProcessing (NLP), this study presents an effective technique to automate the\nidentification of the pipe defect rating of the pipe repair documents. NLP\ntechnologies are employed to break down textual material into grammatical units\nin this research. Further analysis entails using words to discover pipe defect\nsymptoms and their frequency and then combining that information into a single\nscore. Our model achieves 95.0% accuracy,94.9% sensitivity, 94.4% specificity,\n95.9% precision score, and 95.7% F1 score, showing the potential of the\nproposed model to be used in large-scale pipe repair documents for accurate and\nefficient pipeline failure detection to improve the quality of the pipeline.\nKeywords: Sewer pipe inspection, Defect detection, Natural language processing,\nText recognition",
    "published": "2022-02-22T18:03:24Z",
    "pdf_url": "http://arxiv.org/pdf/2202.13871v2",
    "categories": [
      "cs.IR",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1910.07370v1",
    "title": "Evolution of transfer learning in natural language processing",
    "authors": [
      "Aditya Malte",
      "Pratik Ratadiya"
    ],
    "abstract": "In this paper, we present a study of the recent advancements which have\nhelped bring Transfer Learning to NLP through the use of semi-supervised\ntraining. We discuss cutting-edge methods and architectures such as BERT, GPT,\nELMo, ULMFit among others. Classically, tasks in natural language processing\nhave been performed through rule-based and statistical methodologies. However,\nowing to the vast nature of natural languages these methods do not generalise\nwell and failed to learn the nuances of language. Thus machine learning\nalgorithms such as Naive Bayes and decision trees coupled with traditional\nmodels such as Bag-of-Words and N-grams were used to usurp this problem.\nEventually, with the advent of advanced recurrent neural network architectures\nsuch as the LSTM, we were able to achieve state-of-the-art performance in\nseveral natural language processing tasks such as text classification and\nmachine translation. We talk about how Transfer Learning has brought about the\nwell-known ImageNet moment for NLP. Several advanced architectures such as the\nTransformer and its variants have allowed practitioners to leverage knowledge\ngained from unrelated task to drastically fasten convergence and provide better\nperformance on the target task. This survey represents an effort at providing a\nsuccinct yet complete understanding of the recent advances in natural language\nprocessing using deep learning in with a special focus on detailing transfer\nlearning and its potential advantages.",
    "published": "2019-10-16T14:24:37Z",
    "pdf_url": "http://arxiv.org/pdf/1910.07370v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "1911.03268v1",
    "title": "Inducing brain-relevant bias in natural language processing models",
    "authors": [
      "Dan Schwartz",
      "Mariya Toneva",
      "Leila Wehbe"
    ],
    "abstract": "Progress in natural language processing (NLP) models that estimate\nrepresentations of word sequences has recently been leveraged to improve the\nunderstanding of language processing in the brain. However, these models have\nnot been specifically designed to capture the way the brain represents language\nmeaning. We hypothesize that fine-tuning these models to predict recordings of\nbrain activity of people reading text will lead to representations that encode\nmore brain-activity-relevant language information. We demonstrate that a\nversion of BERT, a recently introduced and powerful language model, can improve\nthe prediction of brain activity after fine-tuning. We show that the\nrelationship between language and brain activity learned by BERT during this\nfine-tuning transfers across multiple participants. We also show that, for some\nparticipants, the fine-tuned representations learned from both\nmagnetoencephalography (MEG) and functional magnetic resonance imaging (fMRI)\nare better for predicting fMRI than the representations learned from fMRI\nalone, indicating that the learned representations capture\nbrain-activity-relevant information that is not simply an artifact of the\nmodality. While changes to language representations help the model predict\nbrain activity, they also do not harm the model's ability to perform downstream\nNLP tasks. Our findings are notable for research on language understanding in\nthe brain.",
    "published": "2019-10-29T23:28:16Z",
    "pdf_url": "http://arxiv.org/pdf/1911.03268v1",
    "categories": [
      "q-bio.NC",
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2112.14168v1",
    "title": "A Survey on Gender Bias in Natural Language Processing",
    "authors": [
      "Karolina Stanczak",
      "Isabelle Augenstein"
    ],
    "abstract": "Language can be used as a means of reproducing and enforcing harmful\nstereotypes and biases and has been analysed as such in numerous research. In\nthis paper, we present a survey of 304 papers on gender bias in natural\nlanguage processing. We analyse definitions of gender and its categories within\nsocial sciences and connect them to formal definitions of gender bias in NLP\nresearch. We survey lexica and datasets applied in research on gender bias and\nthen compare and contrast approaches to detecting and mitigating gender bias.\nWe find that research on gender bias suffers from four core limitations. 1)\nMost research treats gender as a binary variable neglecting its fluidity and\ncontinuity. 2) Most of the work has been conducted in monolingual setups for\nEnglish or other high-resource languages. 3) Despite a myriad of papers on\ngender bias in NLP methods, we find that most of the newly developed algorithms\ndo not test their models for bias and disregard possible ethical considerations\nof their work. 4) Finally, methodologies developed in this line of research are\nfundamentally flawed covering very limited definitions of gender bias and\nlacking evaluation baselines and pipelines. We suggest recommendations towards\novercoming these limitations as a guide for future research.",
    "published": "2021-12-28T14:54:18Z",
    "pdf_url": "http://arxiv.org/pdf/2112.14168v1",
    "categories": [
      "cs.CL",
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "2208.08887v1",
    "title": "Brand Celebrity Matching Model Based on Natural Language Processing",
    "authors": [
      "Heming Yang",
      "Ke Yang",
      "Erhan Zhang"
    ],
    "abstract": "Celebrity Endorsement is one of the most significant strategies in brand\ncommunication. Nowadays, more and more companies try to build a vivid\ncharacteristic for themselves. Therefore, their brand identity communications\nshould accord with some characteristics as humans and regulations. However, the\nprevious works mostly stop by assumptions, instead of proposing a specific way\nto perform matching between brands and celebrities. In this paper, we propose a\nbrand celebrity matching model (BCM) based on Natural Language Processing (NLP)\ntechniques. Given a brand and a celebrity, we firstly obtain some descriptive\ndocuments of them from the Internet, then summarize these documents, and\nfinally calculate a matching degree between the brand and the celebrity to\ndetermine whether they are matched. According to the experimental result, our\nproposed model outperforms the best baselines with a 0.362 F1 score and 6.3% of\naccuracy, which indicates the effectiveness and application value of our model\nin the real-world scene. What's more, to our best knowledge, the proposed BCM\nmodel is the first work on using NLP to solve endorsement issues, so it can\nprovide some novel research ideas and methodologies for the following works.",
    "published": "2022-08-18T15:07:14Z",
    "pdf_url": "http://arxiv.org/pdf/2208.08887v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2211.02899v1",
    "title": "Tri-Attention: Explicit Context-Aware Attention Mechanism for Natural\n  Language Processing",
    "authors": [
      "Rui Yu",
      "Yifeng Li",
      "Wenpeng Lu",
      "Longbing Cao"
    ],
    "abstract": "In natural language processing (NLP), the context of a word or sentence plays\nan essential role. Contextual information such as the semantic representation\nof a passage or historical dialogue forms an essential part of a conversation\nand a precise understanding of the present phrase or sentence. However, the\nstandard attention mechanisms typically generate weights using query and key\nbut ignore context, forming a Bi-Attention framework, despite their great\nsuccess in modeling sequence alignment. This Bi-Attention mechanism does not\nexplicitly model the interactions between the contexts, queries and keys of\ntarget sequences, missing important contextual information and resulting in\npoor attention performance. Accordingly, a novel and general triple-attention\n(Tri-Attention) framework expands the standard Bi-Attention mechanism and\nexplicitly interacts query, key, and context by incorporating context as the\nthird dimension in calculating relevance scores. Four variants of Tri-Attention\nare generated by expanding the two-dimensional vector-based additive,\ndot-product, scaled dot-product, and bilinear operations in Bi-Attention to the\ntensor operations for Tri-Attention. Extensive experiments on three NLP tasks\ndemonstrate that Tri-Attention outperforms about 30 state-of-the-art\nnon-attention, standard Bi-Attention, contextual Bi-Attention approaches and\npretrained neural language models1.",
    "published": "2022-11-05T13:07:40Z",
    "pdf_url": "http://arxiv.org/pdf/2211.02899v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2212.09523v1",
    "title": "Natural Language Processing in Customer Service: A Systematic Review",
    "authors": [
      "Malak Mashaabi",
      "Areej Alotaibi",
      "Hala Qudaih",
      "Raghad Alnashwan",
      "Hend Al-Khalifa"
    ],
    "abstract": "Artificial intelligence and natural language processing (NLP) are\nincreasingly being used in customer service to interact with users and answer\ntheir questions. The goal of this systematic review is to examine existing\nresearch on the use of NLP technology in customer service, including the\nresearch domain, applications, datasets used, and evaluation methods. The\nreview also looks at the future direction of the field and any significant\nlimitations. The review covers the time period from 2015 to 2022 and includes\npapers from five major scientific databases. Chatbots and question-answering\nsystems were found to be used in 10 main fields, with the most common use in\ngeneral, social networking, and e-commerce areas. Twitter was the second most\ncommonly used dataset, with most research also using their own original\ndatasets. Accuracy, precision, recall, and F1 were the most common evaluation\nmethods. Future work aims to improve the performance and understanding of user\nbehavior and emotions, and address limitations such as the volume, diversity,\nand quality of datasets. This review includes research on different spoken\nlanguages and models and techniques.",
    "published": "2022-12-16T18:17:07Z",
    "pdf_url": "http://arxiv.org/pdf/2212.09523v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2409.04491v2",
    "title": "Protein sequence classification using natural language processing\n  techniques",
    "authors": [
      "Huma Perveen",
      "Julie Weeds"
    ],
    "abstract": "Purpose: This study aimed to enhance protein sequence classification using\nnatural language processing (NLP) techniques while addressing the impact of\nsequence similarity on model performance. We compared various machine learning\nand deep learning models under two different data-splitting strategies: random\nsplitting and ECOD family-based splitting, which ensures evolutionary-related\nsequences are grouped together. Methods: The study evaluated models such as\nK-Nearest Neighbors (KNN), Multinomial Na\\\"ive Bayes, Logistic Regression,\nMulti-Layer Perceptron (MLP), Decision Tree, Random Forest, XGBoost, Voting and\nStacking classifiers, Convolutional Neural Network (CNN), Long Short-Term\nMemory (LSTM), and transformer models (BertForSequenceClassification,\nDistilBERT, and ProtBert). Performance was tested using different amino acid\nranges and sequence lengths with a focus on generalization across unseen\nevolutionary families. Results: The Voting classifier achieved the highest\nperformance with 74% accuracy, 74% weighted F1 score, and 65% macro F1 score\nunder random splitting, while ProtBERT obtained 77% accuracy, 76% weighted F1\nscore, and 61% macro F1 score among transformer models. However, performance\ndeclined across all models when tested using ECOD-based splitting, revealing\nthe impact of sequence similarity on classification performance. Conclusion:\nAdvanced NLP techniques, particularly ensemble methods like Voting classifiers,\nand transformer models show significant potential in protein classification,\nwith sufficient training data and sequence similarity management being crucial\nfor optimal performance. However, the use of biologically meaningful splitting\nmethods, such as ECOD family-based splitting, is crucial for realistic\nperformance evaluation and generalization to unseen evolutionary families.",
    "published": "2024-09-06T13:16:16Z",
    "pdf_url": "http://arxiv.org/pdf/2409.04491v2",
    "categories": [
      "q-bio.QM",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2509.12782v1",
    "title": "Designing Shadow Tomography Protocols by Natural Language Processing",
    "authors": [
      "Yadong Wu",
      "Pengfei Zhang",
      "Ce Wang",
      "Juan Yao",
      "Yi-Zhuang You"
    ],
    "abstract": "Quantum circuits form a foundational framework in quantum science, enabling\nthe description, analysis, and implementation of quantum computations. However,\ndesigning efficient circuits, typically constructed from single- and two-qubit\ngates, remains a major challenge for specific computational tasks. In this\nwork, we introduce a novel artificial intelligence-driven protocol for quantum\ncircuit design, benchmarked using shadow tomography for efficient quantum state\nreadout. Inspired by techniques from natural language processing (NLP), our\napproach first selects a compact gate dictionary by optimizing the entangling\npower of two-qubit gates. We identify the iSWAP gate as a key element that\nsignificantly enhances sample efficiency, resulting in a minimal gate set of\n{I, SWAP, iSWAP}. Building on this, we implement a recurrent neural network\ntrained via reinforcement learning to generate high-performing quantum\ncircuits. The trained model demonstrates strong generalization ability,\ndiscovering efficient circuit architectures with low sample complexity beyond\nthe training set. Our NLP-inspired framework offers broad potential for quantum\ncomputation, including extracting properties of logical qubits in quantum error\ncorrection.",
    "published": "2025-09-16T07:58:43Z",
    "pdf_url": "http://arxiv.org/pdf/2509.12782v1",
    "categories": [
      "quant-ph"
    ]
  },
  {
    "arxiv_id": "1510.07439v1",
    "title": "Object Oriented Analysis using Natural Language Processing concepts: A\n  Review",
    "authors": [
      "Abinash Tripathy",
      "Santanu Kumar Rath"
    ],
    "abstract": "The Software Development Life Cycle (SDLC) starts with eliciting requirements\nof the customers in the form of Software Requirement Specification (SRS). SRS\ndocument needed for software development is mostly written in Natural\nLanguage(NL) convenient for the client. From the SRS document only, the class\nname, its attributes and the functions incorporated in the body of the class\nare traced based on pre-knowledge of analyst. The paper intends to present a\nreview on Object Oriented (OO) analysis using Natural Language Processing (NLP)\ntechniques. This analysis can be manual where domain expert helps to generate\nthe required diagram or automated system, where the system generates the\nrequired diagram, from the input in the form of SRS.",
    "published": "2015-10-26T11:12:59Z",
    "pdf_url": "http://arxiv.org/pdf/1510.07439v1",
    "categories": [
      "cs.SE",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "1903.01039v4",
    "title": "SECNLP: A Survey of Embeddings in Clinical Natural Language Processing",
    "authors": [
      "Kalyan KS",
      "S Sangeetha"
    ],
    "abstract": "Traditional representations like Bag of words are high dimensional, sparse\nand ignore the order as well as syntactic and semantic information. Distributed\nvector representations or embeddings map variable length text to dense fixed\nlength vectors as well as capture the prior knowledge which can transferred to\ndownstream tasks. Even though embedding has become de facto standard for\nrepresentations in deep learning based NLP tasks in both general and clinical\ndomains, there is no survey paper which presents a detailed review of\nembeddings in Clinical Natural Language Processing. In this survey paper, we\ndiscuss various medical corpora and their characteristics, medical codes and\npresent a brief overview as well as comparison of popular embeddings models. We\nclassify clinical embeddings into nine types and discuss each embedding type in\ndetail. We discuss various evaluation methods followed by possible solutions to\nvarious challenges in clinical embeddings. Finally, we conclude with some of\nthe future directions which will advance the research in clinical embeddings.",
    "published": "2019-03-04T01:37:52Z",
    "pdf_url": "http://arxiv.org/pdf/1903.01039v4",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2103.11072v3",
    "title": "Local Interpretations for Explainable Natural Language Processing: A\n  Survey",
    "authors": [
      "Siwen Luo",
      "Hamish Ivison",
      "Caren Han",
      "Josiah Poon"
    ],
    "abstract": "As the use of deep learning techniques has grown across various fields over\nthe past decade, complaints about the opaqueness of the black-box models have\nincreased, resulting in an increased focus on transparency in deep learning\nmodels. This work investigates various methods to improve the interpretability\nof deep neural networks for Natural Language Processing (NLP) tasks, including\nmachine translation and sentiment analysis. We provide a comprehensive\ndiscussion on the definition of the term interpretability and its various\naspects at the beginning of this work. The methods collected and summarised in\nthis survey are only associated with local interpretation and are specifically\ndivided into three categories: 1) interpreting the model's predictions through\nrelated input features; 2) interpreting through natural language explanation;\n3) probing the hidden states of models and word representations.",
    "published": "2021-03-20T02:28:33Z",
    "pdf_url": "http://arxiv.org/pdf/2103.11072v3",
    "categories": [
      "cs.CL",
      "cs.AI",
      "A.1; I.2.7"
    ]
  },
  {
    "arxiv_id": "2104.12846v2",
    "title": "Teaching a Massive Open Online Course on Natural Language Processing",
    "authors": [
      "Ekaterina Artemova",
      "Murat Apishev",
      "Veronika Sarkisyan",
      "Sergey Aksenov",
      "Denis Kirjanov",
      "Oleg Serikov"
    ],
    "abstract": "This paper presents a new Massive Open Online Course on Natural Language\nProcessing, targeted at non-English speaking students. The course lasts 12\nweeks; every week consists of lectures, practical sessions, and quiz\nassignments. Three weeks out of 12 are followed by Kaggle-style coding\nassignments.\n  Our course intends to serve multiple purposes: (i) familiarize students with\nthe core concepts and methods in NLP, such as language modeling or word or\nsentence representations, (ii) show that recent advances, including pre-trained\nTransformer-based models, are built upon these concepts; (iii) introduce\narchitectures for most demanded real-life applications, (iv) develop practical\nskills to process texts in multiple languages. The course was prepared and\nrecorded during 2020, launched by the end of the year, and in early 2021 has\nreceived positive feedback.",
    "published": "2021-04-26T19:52:00Z",
    "pdf_url": "http://arxiv.org/pdf/2104.12846v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2202.07101v2",
    "title": "A Survey on Dynamic Neural Networks for Natural Language Processing",
    "authors": [
      "Canwen Xu",
      "Julian McAuley"
    ],
    "abstract": "Effectively scaling large Transformer models is a main driver of recent\nadvances in natural language processing. Dynamic neural networks, as an\nemerging research direction, are capable of scaling up neural networks with\nsub-linear increases in computation and time by dynamically adjusting their\ncomputational path based on the input. Dynamic neural networks could be a\npromising solution to the growing parameter numbers of pretrained language\nmodels, allowing both model pretraining with trillions of parameters and faster\ninference on mobile devices. In this survey, we summarize progress of three\ntypes of dynamic neural networks in NLP: skimming, mixture of experts, and\nearly exit. We also highlight current challenges in dynamic neural networks and\ndirections for future research.",
    "published": "2022-02-15T00:13:05Z",
    "pdf_url": "http://arxiv.org/pdf/2202.07101v2",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2202.11766v1",
    "title": "A gentle introduction to Quantum Natural Language Processing",
    "authors": [
      "Shervin Le Du",
      "Senaida Hernández Santana",
      "Giannicola Scarpa"
    ],
    "abstract": "The main goal of this master's thesis is to introduce Quantum Natural\nLanguage Processing (QNLP) in a way understandable by both the NLP engineer and\nthe quantum computing practitioner. QNLP is a recent application of quantum\ncomputing that aims at representing sentences' meaning as vectors encoded into\nquantum computers. To achieve this, the distributional meaning of words is\nextended by the compositional meaning of sentences (DisCoCat model) : the\nvectors representing words' meanings are composed through the syntactic\nstructure of the sentence. This is done using an algorithm based on tensor\nproducts. We see that this algorithm is inefficient on classical computers but\nscales well using quantum circuits. After exposing the practical details of its\nimplementation, we go through three use-cases.",
    "published": "2022-02-23T20:17:00Z",
    "pdf_url": "http://arxiv.org/pdf/2202.11766v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "1807.06638v1",
    "title": "Developing a Portable Natural Language Processing Based Phenotyping\n  System",
    "authors": [
      "Himanshu Sharma",
      "Chengsheng Mao",
      "Yizhen Zhang",
      "Haleh Vatani",
      "Liang Yao",
      "Yizhen Zhong",
      "Luke Rasmussen",
      "Guoqian Jiang",
      "Jyotishman Pathak",
      "Yuan Luo"
    ],
    "abstract": "This paper presents a portable phenotyping system that is capable of\nintegrating both rule-based and statistical machine learning based approaches.\nOur system utilizes UMLS to extract clinically relevant features from the\nunstructured text and then facilitates portability across different\ninstitutions and data systems by incorporating OHDSI's OMOP Common Data Model\n(CDM) to standardize necessary data elements. Our system can also store the key\ncomponents of rule-based systems (e.g., regular expression matches) in the\nformat of OMOP CDM, thus enabling the reuse, adaptation and extension of many\nexisting rule-based clinical NLP systems. We experimented with our system on\nthe corpus from i2b2's Obesity Challenge as a pilot study. Our system\nfacilitates portable phenotyping of obesity and its 15 comorbidities based on\nthe unstructured patient discharge summaries, while achieving a performance\nthat often ranked among the top 10 of the challenge participants. This\nstandardization enables a consistent application of numerous rule-based and\nmachine learning based classification techniques downstream.",
    "published": "2018-07-17T19:40:28Z",
    "pdf_url": "http://arxiv.org/pdf/1807.06638v1",
    "categories": [
      "cs.CL",
      "cs.IR"
    ]
  },
  {
    "arxiv_id": "2110.01852v3",
    "title": "Data Augmentation Approaches in Natural Language Processing: A Survey",
    "authors": [
      "Bohan Li",
      "Yutai Hou",
      "Wanxiang Che"
    ],
    "abstract": "As an effective strategy, data augmentation (DA) alleviates data scarcity\nscenarios where deep learning techniques may fail. It is widely applied in\ncomputer vision then introduced to natural language processing and achieves\nimprovements in many tasks. One of the main focuses of the DA methods is to\nimprove the diversity of training data, thereby helping the model to better\ngeneralize to unseen testing data. In this survey, we frame DA methods into\nthree categories based on the diversity of augmented data, including\nparaphrasing, noising, and sampling. Our paper sets out to analyze DA methods\nin detail according to the above categories. Further, we also introduce their\napplications in NLP tasks as well as the challenges. Some helpful resources are\nprovided in the appendix.",
    "published": "2021-10-05T07:35:32Z",
    "pdf_url": "http://arxiv.org/pdf/2110.01852v3",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2112.15471v2",
    "title": "A Survey on Using Gaze Behaviour for Natural Language Processing",
    "authors": [
      "Sandeep Mathias",
      "Diptesh Kanojia",
      "Abhijit Mishra",
      "Pushpak Bhattacharyya"
    ],
    "abstract": "Gaze behaviour has been used as a way to gather cognitive information for a\nnumber of years. In this paper, we discuss the use of gaze behaviour in solving\ndifferent tasks in natural language processing (NLP) without having to record\nit at test time. This is because the collection of gaze behaviour is a costly\ntask, both in terms of time and money. Hence, in this paper, we focus on\nresearch done to alleviate the need for recording gaze behaviour at run time.\nWe also mention different eye tracking corpora in multiple languages, which are\ncurrently available and can be used in natural language processing. We conclude\nour paper by discussing applications in a domain - education - and how learning\ngaze behaviour can help in solving the tasks of complex word identification and\nautomatic essay grading.",
    "published": "2021-12-21T15:52:56Z",
    "pdf_url": "http://arxiv.org/pdf/2112.15471v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2206.11862v1",
    "title": "Urdu News Article Recommendation Model using Natural Language Processing\n  Techniques",
    "authors": [
      "Syed Zain Abbas",
      "Arif ur Rahman",
      "Abdul Basit Mughal",
      "Syed Mujtaba Haider"
    ],
    "abstract": "There are several online newspapers in urdu but for the users it is difficult\nto find the content they are looking for because these most of them contain\nirrelevant data and most users did not get what they want to retrieve. Our\nproposed framework will help to predict Urdu news in the interests of users and\nreduce the users searching time for news. For this purpose, NLP techniques are\nused for pre-processing, and then TF-IDF with cosine similarity is used for\ngaining the highest similarity and recommended news on user preferences.\nMoreover, the BERT language model is also used for similarity, and by using the\nBERT model similarity increases as compared to TF-IDF so the approach works\nbetter with the BERT language model and recommends news to the user on their\ninterest. The news is recommended when the similarity of the articles is above\n60 percent.",
    "published": "2022-05-29T12:43:32Z",
    "pdf_url": "http://arxiv.org/pdf/2206.11862v1",
    "categories": [
      "cs.IR",
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2211.02956v1",
    "title": "Privacy-Preserving Models for Legal Natural Language Processing",
    "authors": [
      "Ying Yin",
      "Ivan Habernal"
    ],
    "abstract": "Pre-training large transformer models with in-domain data improves domain\nadaptation and helps gain performance on the domain-specific downstream tasks.\nHowever, sharing models pre-trained on potentially sensitive data is prone to\nadversarial privacy attacks. In this paper, we asked to which extent we can\nguarantee privacy of pre-training data and, at the same time, achieve better\ndownstream performance on legal tasks without the need of additional labeled\ndata. We extensively experiment with scalable self-supervised learning of\ntransformer models under the formal paradigm of differential privacy and show\nthat under specific training configurations we can improve downstream\nperformance without sacrifying privacy protection for the in-domain data. Our\nmain contribution is utilizing differential privacy for large-scale\npre-training of transformer language models in the legal NLP domain, which, to\nthe best of our knowledge, has not been addressed before.",
    "published": "2022-11-05T18:10:50Z",
    "pdf_url": "http://arxiv.org/pdf/2211.02956v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2211.09680v1",
    "title": "Analyse der Entwicklungstreiber militärischer Schwarmdrohnen durch\n  Natural Language Processing",
    "authors": [
      "Manuel Mundt"
    ],
    "abstract": "Military drones are taking an increasingly prominent role in armed conflict,\nand the use of multiple drones in a swarm can be useful. Who the drivers of the\nresearch are and what sub-domains exist is analyzed and visually presented in\nthis research using NLP techniques based on 946 studies. Most research is\nconducted in the Western world, led by the United States, the United Kingdom,\nand Germany. Through Tf-idf scoring, it is shown that countries have\nsignificant differences in the subdomains studied. Overall, 2019 and 2020 saw\nthe most works published, with significant interest in military swarm drones as\nearly as 2008. This study provides a first glimpse into research in this area\nand prompts further investigation.",
    "published": "2022-11-15T20:22:33Z",
    "pdf_url": "http://arxiv.org/pdf/2211.09680v1",
    "categories": [
      "cs.CL",
      "cs.LG",
      "cs.RO",
      "68U15",
      "I.2.7"
    ]
  },
  {
    "arxiv_id": "2303.05666v1",
    "title": "Research on CPI Prediction Based on Natural Language Processing",
    "authors": [
      "Xiaobin Tang",
      "Nuo Lei"
    ],
    "abstract": "In the past, the seed keywords for CPI prediction were often selected based\non empirical summaries of research and literature studies, which were prone to\nselect omitted and invalid variables. In this paper, we design a keyword\nexpansion technique for CPI prediction based on the cutting-edge NLP model,\nPANGU. We improve the CPI prediction ability using the corresponding web search\nindex. Compared with the unsupervised pre-training and supervised downstream\nfine-tuning natural language processing models such as BERT and NEZHA, the\nPANGU model can be expanded to obtain more reliable CPI-generated keywords by\nits excellent zero-sample learning capability without the limitation of the\ndownstream fine-tuning data set. Finally, this paper empirically tests the\nkeyword prediction ability obtained by this keyword expansion method with\nhistorical CPI data.",
    "published": "2023-03-10T02:41:47Z",
    "pdf_url": "http://arxiv.org/pdf/2303.05666v1",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ]
  },
  {
    "arxiv_id": "2401.01487v1",
    "title": "Natural Language Processing and Multimodal Stock Price Prediction",
    "authors": [
      "Kevin Taylor",
      "Jerry Ng"
    ],
    "abstract": "In the realm of financial decision-making, predicting stock prices is\npivotal. Artificial intelligence techniques such as long short-term memory\nnetworks (LSTMs), support-vector machines (SVMs), and natural language\nprocessing (NLP) models are commonly employed to predict said prices. This\npaper utilizes stock percentage change as training data, in contrast to the\ntraditional use of raw currency values, with a focus on analyzing publicly\nreleased news articles. The choice of percentage change aims to provide models\nwith context regarding the significance of price fluctuations and overall price\nchange impact on a given stock. The study employs specialized BERT natural\nlanguage processing models to predict stock price trends, with a particular\nemphasis on various data modalities. The results showcase the capabilities of\nsuch strategies with a small natural language processing model to accurately\npredict overall stock trends, and highlight the effectiveness of certain data\nfeatures and sector-specific data.",
    "published": "2024-01-03T01:21:30Z",
    "pdf_url": "http://arxiv.org/pdf/2401.01487v1",
    "categories": [
      "cs.LG",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2407.13193v3",
    "title": "Retrieval-Augmented Generation for Natural Language Processing: A Survey",
    "authors": [
      "Shangyu Wu",
      "Ying Xiong",
      "Yufei Cui",
      "Haolun Wu",
      "Can Chen",
      "Ye Yuan",
      "Lianming Huang",
      "Xue Liu",
      "Tei-Wei Kuo",
      "Nan Guan",
      "Chun Jason Xue"
    ],
    "abstract": "Large language models (LLMs) have demonstrated great success in various\nfields, benefiting from their huge amount of parameters that store knowledge.\nHowever, LLMs still suffer from several key issues, such as hallucination\nproblems, knowledge update issues, and lacking domain-specific expertise. The\nappearance of retrieval-augmented generation (RAG), which leverages an external\nknowledge database to augment LLMs, makes up those drawbacks of LLMs. This\npaper reviews all significant techniques of RAG, especially in the retriever\nand the retrieval fusions. Besides, tutorial codes are provided for\nimplementing the representative techniques in RAG. This paper further discusses\nthe RAG update, including RAG with/without knowledge update. Then, we introduce\nRAG evaluation and benchmarking, as well as the application of RAG in\nrepresentative NLP tasks and industrial scenarios. Finally, this paper\ndiscusses RAG's future directions and challenges for promoting this field's\ndevelopment.",
    "published": "2024-07-18T06:06:53Z",
    "pdf_url": "http://arxiv.org/pdf/2407.13193v3",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2410.12759v1",
    "title": "Unitary Multi-Margin BERT for Robust Natural Language Processing",
    "authors": [
      "Hao-Yuan Chang",
      "Kang L. Wang"
    ],
    "abstract": "Recent developments in adversarial attacks on deep learning leave many\nmission-critical natural language processing (NLP) systems at risk of\nexploitation. To address the lack of computationally efficient adversarial\ndefense methods, this paper reports a novel, universal technique that\ndrastically improves the robustness of Bidirectional Encoder Representations\nfrom Transformers (BERT) by combining the unitary weights with the multi-margin\nloss. We discover that the marriage of these two simple ideas amplifies the\nprotection against malicious interference. Our model, the unitary multi-margin\nBERT (UniBERT), boosts post-attack classification accuracies significantly by\n5.3% to 73.8% while maintaining competitive pre-attack accuracies. Furthermore,\nthe pre-attack and post-attack accuracy tradeoff can be adjusted via a single\nscalar parameter to best fit the design requirements for the target\napplications.",
    "published": "2024-10-16T17:30:58Z",
    "pdf_url": "http://arxiv.org/pdf/2410.12759v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2505.02199v1",
    "title": "Exploring new Approaches for Information Retrieval through Natural\n  Language Processing",
    "authors": [
      "Manak Raj",
      "Nidhi Mishra"
    ],
    "abstract": "This review paper explores recent advancements and emerging approaches in\nInformation Retrieval (IR) applied to Natural Language Processing (NLP). We\nexamine traditional IR models such as Boolean, vector space, probabilistic, and\ninference network models, and highlight modern techniques including deep\nlearning, reinforcement learning, and pretrained transformer models like BERT.\nWe discuss key tools and libraries - Lucene, Anserini, and Pyserini - for\nefficient text indexing and search. A comparative analysis of sparse, dense,\nand hybrid retrieval methods is presented, along with applications in web\nsearch engines, cross-language IR, argument mining, private information\nretrieval, and hate speech detection. Finally, we identify open challenges and\nfuture research directions to enhance retrieval accuracy, scalability, and\nethical considerations.",
    "published": "2025-05-04T17:37:26Z",
    "pdf_url": "http://arxiv.org/pdf/2505.02199v1",
    "categories": [
      "cs.IR",
      "cs.CL",
      "68T50",
      "H.3.3; I.2.7"
    ]
  },
  {
    "arxiv_id": "2501.14701v2",
    "title": "An Unsupervised Natural Language Processing Pipeline for Assessing\n  Referral Appropriateness",
    "authors": [
      "Vittorio Torri",
      "Annamaria Bottelli",
      "Michele Ercolanoni",
      "Olivia Leoni",
      "Francesca Ieva"
    ],
    "abstract": "Objective: Assessing the appropriateness of diagnostic referrals is critical\nfor improving healthcare efficiency and reducing unnecessary procedures.\nHowever, this task becomes challenging when referral reasons are recorded only\nas free text rather than structured codes, like in the Italian NHS. To address\nthis gap, we propose a fully unsupervised Natural Language Processing (NLP)\npipeline capable of extracting and evaluating referral reasons without relying\non labelled datasets.\n  Methods: Our pipeline leverages Transformer-based embeddings pre-trained on\nItalian medical texts to cluster referral reasons and assess their alignment\nwith appropriateness guidelines. It operates in an unsupervised setting and is\ndesigned to generalize across different examination types. We analyzed two\ncomplete regional datasets from the Lombardy Region (Italy), covering all\nreferrals between 2019 and 2021 for venous echocolordoppler of the lower limbs\n(ECD;n=496,971; development) and flexible endoscope colonoscopy (FEC;\nn=407,949; testing only). For both, a random sample of 1,000 referrals was\nmanually annotated to measure performance.\n  Results: The pipeline achieved high performance in identifying referral\nreasons (Prec=92.43% (ECD), 93.59% (FEC); Rec=83.28% (ECD), 92.70% (FEC)) and\nappropriateness (Prec=93.58% (ECD), 94.66% (FEC); Rec=91.52% (ECD), 93.96%\n(FEC)). At the regional level, the analysis identified relevant inappropriate\nreferral groups and variation across contexts, findings that informed a new\nLombardy Region resolution to reinforce guideline adherence.\n  Conclusions: This study presents a robust, scalable, unsupervised NLP\npipeline for assessing referral appropriateness in large, real-world datasets.\nIt demonstrates how such data can be effectively leveraged, providing public\nhealth authorities with a deployable AI tool to monitor practices and support\nevidence-based policy.",
    "published": "2025-01-24T18:24:16Z",
    "pdf_url": "http://arxiv.org/pdf/2501.14701v2",
    "categories": [
      "cs.CL",
      "cs.LG",
      "68T50",
      "I.2.7; J.1; J.3"
    ]
  },
  {
    "arxiv_id": "1301.7738v2",
    "title": "PyPLN: a Distributed Platform for Natural Language Processing",
    "authors": [
      "Flávio Codeço Coelho",
      "Renato Rocha Souza",
      "Álvaro Justen",
      "Flávio Amieiro",
      "Heliana Mello"
    ],
    "abstract": "This paper presents a distributed platform for Natural Language Processing\ncalled PyPLN. PyPLN leverages a vast array of NLP and text processing open\nsource tools, managing the distribution of the workload on a variety of\nconfigurations: from a single server to a cluster of linux servers. PyPLN is\ndeveloped using Python 2.7.3 but makes it very easy to incorporate other\nsoftwares for specific tasks as long as a linux version is available. PyPLN\nfacilitates analyses both at document and corpus level, simplifying management\nand publication of corpora and analytical results through an easy to use web\ninterface. In the current (beta) release, it supports English and Portuguese\nlanguages with support to other languages planned for future releases. To\nsupport the Portuguese language PyPLN uses the PALAVRAS parser\\citep{Bick2000}.\nCurrently PyPLN offers the following features: Text extraction with encoding\nnormalization (to UTF-8), part-of-speech tagging, token frequency, semantic\nannotation, n-gram extraction, word and sentence repertoire, and full-text\nsearch across corpora. The platform is licensed as GPL-v3.",
    "published": "2013-01-31T20:21:52Z",
    "pdf_url": "http://arxiv.org/pdf/1301.7738v2",
    "categories": [
      "cs.CL",
      "cs.IR"
    ]
  },
  {
    "arxiv_id": "2101.11889v1",
    "title": "Explaining Natural Language Processing Classifiers with Occlusion and\n  Language Modeling",
    "authors": [
      "David Harbecke"
    ],
    "abstract": "Deep neural networks are powerful statistical learners. However, their\npredictions do not come with an explanation of their process. To analyze these\nmodels, explanation methods are being developed. We present a novel explanation\nmethod, called OLM, for natural language processing classifiers. This method\ncombines occlusion and language modeling, which are techniques central to\nexplainability and NLP, respectively. OLM gives explanations that are\ntheoretically sound and easy to understand.\n  We make several contributions to the theory of explanation methods. Axioms\nfor explanation methods are an interesting theoretical concept to explore their\nbasics and deduce methods. We introduce a new axiom, give its intuition and\nshow it contradicts another existing axiom. Additionally, we point out\ntheoretical difficulties of existing gradient-based and some occlusion-based\nexplanation methods in natural language processing. We provide an extensive\nargument why evaluation of explanation methods is difficult. We compare OLM to\nother explanation methods and underline its uniqueness experimentally. Finally,\nwe investigate corner cases of OLM and discuss its validity and possible\nimprovements.",
    "published": "2021-01-28T09:44:04Z",
    "pdf_url": "http://arxiv.org/pdf/2101.11889v1",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2103.13942v1",
    "title": "Visual Grounding Strategies for Text-Only Natural Language Processing",
    "authors": [
      "Damien Sileo"
    ],
    "abstract": "Visual grounding is a promising path toward more robust and accurate Natural\nLanguage Processing (NLP) models. Many multimodal extensions of BERT (e.g.,\nVideoBERT, LXMERT, VL-BERT) allow a joint modeling of texts and images that\nlead to state-of-the-art results on multimodal tasks such as Visual Question\nAnswering. Here, we leverage multimodal modeling for purely textual tasks\n(language modeling and classification) with the expectation that the multimodal\npretraining provides a grounding that can improve text processing accuracy. We\npropose possible strategies in this respect. A first type of strategy, referred\nto as {\\it transferred grounding} consists in applying multimodal models to\ntext-only tasks using a placeholder to replace image input. The second one,\nwhich we call {\\it associative grounding}, harnesses image retrieval to match\ntexts with related images during both pretraining and text-only downstream\ntasks. We draw further distinctions into both strategies and then compare them\naccording to their impact on language modeling and commonsense-related\ndownstream tasks, showing improvement over text-only baselines.",
    "published": "2021-03-25T16:03:00Z",
    "pdf_url": "http://arxiv.org/pdf/2103.13942v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2005.14187v1",
    "title": "HAT: Hardware-Aware Transformers for Efficient Natural Language\n  Processing",
    "authors": [
      "Hanrui Wang",
      "Zhanghao Wu",
      "Zhijian Liu",
      "Han Cai",
      "Ligeng Zhu",
      "Chuang Gan",
      "Song Han"
    ],
    "abstract": "Transformers are ubiquitous in Natural Language Processing (NLP) tasks, but\nthey are difficult to be deployed on hardware due to the intensive computation.\nTo enable low-latency inference on resource-constrained hardware platforms, we\npropose to design Hardware-Aware Transformers (HAT) with neural architecture\nsearch. We first construct a large design space with $\\textit{arbitrary\nencoder-decoder attention}$ and $\\textit{heterogeneous layers}$. Then we train\na $\\textit{SuperTransformer}$ that covers all candidates in the design space,\nand efficiently produces many $\\textit{SubTransformers}$ with weight sharing.\nFinally, we perform an evolutionary search with a hardware latency constraint\nto find a specialized $\\textit{SubTransformer}$ dedicated to run fast on the\ntarget hardware. Extensive experiments on four machine translation tasks\ndemonstrate that HAT can discover efficient models for different hardware (CPU,\nGPU, IoT device). When running WMT'14 translation task on Raspberry Pi-4, HAT\ncan achieve $\\textbf{3}\\times$ speedup, $\\textbf{3.7}\\times$ smaller size over\nbaseline Transformer; $\\textbf{2.7}\\times$ speedup, $\\textbf{3.6}\\times$\nsmaller size over Evolved Transformer with $\\textbf{12,041}\\times$ less search\ncost and no performance loss. HAT code is\nhttps://github.com/mit-han-lab/hardware-aware-transformers.git",
    "published": "2020-05-28T17:58:56Z",
    "pdf_url": "http://arxiv.org/pdf/2005.14187v1",
    "categories": [
      "cs.CL",
      "cs.LG",
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "2002.09812v1",
    "title": "Sketching Transformed Matrices with Applications to Natural Language\n  Processing",
    "authors": [
      "Yingyu Liang",
      "Zhao Song",
      "Mengdi Wang",
      "Lin F. Yang",
      "Xin Yang"
    ],
    "abstract": "Suppose we are given a large matrix $A=(a_{i,j})$ that cannot be stored in\nmemory but is in a disk or is presented in a data stream. However, we need to\ncompute a matrix decomposition of the entry-wisely transformed matrix,\n$f(A):=(f(a_{i,j}))$ for some function $f$. Is it possible to do it in a space\nefficient way? Many machine learning applications indeed need to deal with such\nlarge transformed matrices, for example word embedding method in NLP needs to\nwork with the pointwise mutual information (PMI) matrix, while the entrywise\ntransformation makes it difficult to apply known linear algebraic tools.\nExisting approaches for this problem either need to store the whole matrix and\nperform the entry-wise transformation afterwards, which is space consuming or\ninfeasible, or need to redesign the learning method, which is application\nspecific and requires substantial remodeling.\n  In this paper, we first propose a space-efficient sketching algorithm for\ncomputing the product of a given small matrix with the transformed matrix. It\nworks for a general family of transformations with provable small error bounds\nand thus can be used as a primitive in downstream learning tasks. We then apply\nthis primitive to a concrete application: low-rank approximation. We show that\nour approach obtains small error and is efficient in both space and time. We\ncomplement our theoretical results with experiments on synthetic and real data.",
    "published": "2020-02-23T03:07:31Z",
    "pdf_url": "http://arxiv.org/pdf/2002.09812v1",
    "categories": [
      "cs.DS",
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2010.16357v1",
    "title": "A Cross-lingual Natural Language Processing Framework for Infodemic\n  Management",
    "authors": [
      "Ridam Pal",
      "Rohan Pandey",
      "Vaibhav Gautam",
      "Kanav Bhagat",
      "Tavpritesh Sethi"
    ],
    "abstract": "The COVID-19 pandemic has put immense pressure on health systems which are\nfurther strained due to the misinformation surrounding it. Under such a\nsituation, providing the right information at the right time is crucial. There\nis a growing demand for the management of information spread using Artificial\nIntelligence. Hence, we have exploited the potential of Natural Language\nProcessing for identifying relevant information that needs to be disseminated\namongst the masses. In this work, we present a novel Cross-lingual Natural\nLanguage Processing framework to provide relevant information by matching daily\nnews with trusted guidelines from the World Health Organization. The proposed\npipeline deploys various techniques of NLP such as summarizers, word\nembeddings, and similarity metrics to provide users with news articles along\nwith a corresponding healthcare guideline. A total of 36 models were evaluated\nand a combination of LexRank based summarizer on Word2Vec embedding with Word\nMover distance metric outperformed all other models. This novel open-source\napproach can be used as a template for proactive dissemination of relevant\nhealthcare information in the midst of misinformation spread associated with\nepidemics.",
    "published": "2020-10-30T16:26:35Z",
    "pdf_url": "http://arxiv.org/pdf/2010.16357v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2111.06741v2",
    "title": "A Quantum Natural Language Processing Approach to Musical Intelligence",
    "authors": [
      "Eduardo Reck Miranda",
      "Richie Yeung",
      "Anna Pearson",
      "Konstantinos Meichanetzidis",
      "Bob Coecke"
    ],
    "abstract": "There has been tremendous progress in Artificial Intelligence (AI) for music,\nin particular for musical composition and access to large databases for\ncommercialisation through the Internet. We are interested in further advancing\nthis field, focusing on composition. In contrast to current black-box AI\nmethods, we are championing an interpretable compositional outlook on\ngenerative music systems. In particular, we are importing methods from the\nDistributional Compositional Categorical (DisCoCat) modelling framework for\nNatural Language Processing (NLP), motivated by musical grammars. Quantum\ncomputing is a nascent technology, which is very likely to impact the music\nindustry in time to come. Thus, we are pioneering a Quantum Natural Language\nProcessing (QNLP) approach to develop a new generation of intelligent musical\nsystems. This work follows from previous experimental implementations of\nDisCoCat linguistic models on quantum hardware. In this chapter, we present\nQuanthoven, the first proof-of-concept ever built, which (a) demonstrates that\nit is possible to program a quantum computer to learn to classify music that\nconveys different meanings and (b) illustrates how such a capability might be\nleveraged to develop a system to compose meaningful pieces of music. After a\ndiscussion about our current understanding of music as a communication medium\nand its relationship to natural language, the chapter focuses on the techniques\ndeveloped to (a) encode musical compositions as quantum circuits, and (b)\ndesign a quantum classifier. The chapter ends with demonstrations of\ncompositions created with the system.",
    "published": "2021-11-10T12:35:07Z",
    "pdf_url": "http://arxiv.org/pdf/2111.06741v2",
    "categories": [
      "quant-ph",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2206.11867v1",
    "title": "Lifelong Learning Natural Language Processing Approach for Multilingual\n  Data Classification",
    "authors": [
      "Jędrzej Kozal",
      "Michał Leś",
      "Paweł Zyblewski",
      "Paweł Ksieniewicz",
      "Michał Woźniak"
    ],
    "abstract": "The abundance of information in digital media, which in today's world is the\nmain source of knowledge about current events for the masses, makes it possible\nto spread disinformation on a larger scale than ever before. Consequently,\nthere is a need to develop novel fake news detection approaches capable of\nadapting to changing factual contexts and generalizing previously or\nconcurrently acquired knowledge. To deal with this problem, we propose a\nlifelong learning-inspired approach, which allows for fake news detection in\nmultiple languages and the mutual transfer of knowledge acquired in each of\nthem. Both classical feature extractors, such as Term frequency-inverse\ndocument frequency or Latent Dirichlet Allocation, and integrated deep NLP\n(Natural Language Processing) BERT (Bidirectional Encoder Representations from\nTransformers) models paired with MLP (Multilayer Perceptron) classifier, were\nemployed. The results of experiments conducted on two datasets dedicated to the\nfake news classification task (in English and Spanish, respectively), supported\nby statistical analysis, confirmed that utilization of additional languages\ncould improve performance for traditional methods. Also, in some cases\nsupplementing the deep learning method with classical ones can positively\nimpact obtained results. The ability of models to generalize the knowledge\nacquired between the analyzed languages was also observed.",
    "published": "2022-05-25T10:34:04Z",
    "pdf_url": "http://arxiv.org/pdf/2206.11867v1",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2206.15076v1",
    "title": "BigBIO: A Framework for Data-Centric Biomedical Natural Language\n  Processing",
    "authors": [
      "Jason Alan Fries",
      "Leon Weber",
      "Natasha Seelam",
      "Gabriel Altay",
      "Debajyoti Datta",
      "Samuele Garda",
      "Myungsun Kang",
      "Ruisi Su",
      "Wojciech Kusa",
      "Samuel Cahyawijaya",
      "Fabio Barth",
      "Simon Ott",
      "Matthias Samwald",
      "Stephen Bach",
      "Stella Biderman",
      "Mario Sänger",
      "Bo Wang",
      "Alison Callahan",
      "Daniel León Periñán",
      "Théo Gigant",
      "Patrick Haller",
      "Jenny Chim",
      "Jose David Posada",
      "John Michael Giorgi",
      "Karthik Rangasai Sivaraman",
      "Marc Pàmies",
      "Marianna Nezhurina",
      "Robert Martin",
      "Michael Cullan",
      "Moritz Freidank",
      "Nathan Dahlberg",
      "Shubhanshu Mishra",
      "Shamik Bose",
      "Nicholas Michio Broad",
      "Yanis Labrak",
      "Shlok S Deshmukh",
      "Sid Kiblawi",
      "Ayush Singh",
      "Minh Chien Vu",
      "Trishala Neeraj",
      "Jonas Golde",
      "Albert Villanova del Moral",
      "Benjamin Beilharz"
    ],
    "abstract": "Training and evaluating language models increasingly requires the\nconstruction of meta-datasets --diverse collections of curated data with clear\nprovenance. Natural language prompting has recently lead to improved zero-shot\ngeneralization by transforming existing, supervised datasets into a diversity\nof novel pretraining tasks, highlighting the benefits of meta-dataset curation.\nWhile successful in general-domain text, translating these data-centric\napproaches to biomedical language modeling remains challenging, as labeled\nbiomedical datasets are significantly underrepresented in popular data hubs. To\naddress this challenge, we introduce BigBIO a community library of 126+\nbiomedical NLP datasets, currently covering 12 task categories and 10+\nlanguages. BigBIO facilitates reproducible meta-dataset curation via\nprogrammatic access to datasets and their metadata, and is compatible with\ncurrent platforms for prompt engineering and end-to-end few/zero shot language\nmodel evaluation. We discuss our process for task schema harmonization, data\nauditing, contribution guidelines, and outline two illustrative use cases:\nzero-shot evaluation of biomedical prompts and large-scale, multi-task\nlearning. BigBIO is an ongoing community effort and is available at\nhttps://github.com/bigscience-workshop/biomedical",
    "published": "2022-06-30T07:15:45Z",
    "pdf_url": "http://arxiv.org/pdf/2206.15076v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2212.06334v1",
    "title": "Auto-labelling of Bug Report using Natural Language Processing",
    "authors": [
      "Avinash Patil",
      "Aryan Jadon"
    ],
    "abstract": "The exercise of detecting similar bug reports in bug tracking systems is\nknown as duplicate bug report detection. Having prior knowledge of a bug\nreport's existence reduces efforts put into debugging problems and identifying\nthe root cause. Rule and Query-based solutions recommend a long list of\npotential similar bug reports with no clear ranking. In addition, triage\nengineers are less motivated to spend time going through an extensive list.\nConsequently, this deters the use of duplicate bug report retrieval solutions.\nIn this paper, we have proposed a solution using a combination of NLP\ntechniques. Our approach considers unstructured and structured attributes of a\nbug report like summary, description and severity, impacted products,\nplatforms, categories, etc. It uses a custom data transformer, a deep neural\nnetwork, and a non-generalizing machine learning method to retrieve existing\nidentical bug reports. We have performed numerous experiments with significant\ndata sources containing thousands of bug reports and showcased that the\nproposed solution achieves a high retrieval accuracy of 70% for recall@5.",
    "published": "2022-12-13T02:32:42Z",
    "pdf_url": "http://arxiv.org/pdf/2212.06334v1",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2103.00112v3",
    "title": "Transformer in Transformer",
    "authors": [
      "Kai Han",
      "An Xiao",
      "Enhua Wu",
      "Jianyuan Guo",
      "Chunjing Xu",
      "Yunhe Wang"
    ],
    "abstract": "Transformer is a new kind of neural architecture which encodes the input data\nas powerful features via the attention mechanism. Basically, the visual\ntransformers first divide the input images into several local patches and then\ncalculate both representations and their relationship. Since natural images are\nof high complexity with abundant detail and color information, the granularity\nof the patch dividing is not fine enough for excavating features of objects in\ndifferent scales and locations. In this paper, we point out that the attention\ninside these local patches are also essential for building visual transformers\nwith high performance and we explore a new architecture, namely, Transformer iN\nTransformer (TNT). Specifically, we regard the local patches (e.g.,\n16$\\times$16) as \"visual sentences\" and present to further divide them into\nsmaller patches (e.g., 4$\\times$4) as \"visual words\". The attention of each\nword will be calculated with other words in the given visual sentence with\nnegligible computational costs. Features of both words and sentences will be\naggregated to enhance the representation ability. Experiments on several\nbenchmarks demonstrate the effectiveness of the proposed TNT architecture,\ne.g., we achieve an 81.5% top-1 accuracy on the ImageNet, which is about 1.7%\nhigher than that of the state-of-the-art visual transformer with similar\ncomputational cost. The PyTorch code is available at\nhttps://github.com/huawei-noah/CV-Backbones, and the MindSpore code is\navailable at https://gitee.com/mindspore/models/tree/master/research/cv/TNT.",
    "published": "2021-02-27T03:12:16Z",
    "pdf_url": "http://arxiv.org/pdf/2103.00112v3",
    "categories": [
      "cs.CV",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2307.01189v2",
    "title": "Trainable Transformer in Transformer",
    "authors": [
      "Abhishek Panigrahi",
      "Sadhika Malladi",
      "Mengzhou Xia",
      "Sanjeev Arora"
    ],
    "abstract": "Recent works attribute the capability of in-context learning (ICL) in large\npre-trained language models to implicitly simulating and fine-tuning an\ninternal model (e.g., linear or 2-layer MLP) during inference. However, such\nconstructions require large memory overhead, which makes simulation of more\nsophisticated internal models intractable. In this work, we propose an\nefficient construction, Transformer in Transformer (in short, TinT), that\nallows a transformer to simulate and fine-tune complex models internally during\ninference (e.g., pre-trained language models). In particular, we introduce\ninnovative approximation techniques that allow a TinT model with less than 2\nbillion parameters to simulate and fine-tune a 125 million parameter\ntransformer model within a single forward pass. TinT accommodates many common\ntransformer variants and its design ideas also improve the efficiency of past\ninstantiations of simple models inside transformers. We conduct end-to-end\nexperiments to validate the internal fine-tuning procedure of TinT on various\nlanguage modeling and downstream tasks. For example, even with a limited\none-step budget, we observe TinT for a OPT-125M model improves performance by\n4-16% absolute on average compared to OPT-125M. These findings suggest that\nlarge pre-trained language models are capable of performing intricate\nsubroutines. To facilitate further work, a modular and extensible codebase for\nTinT is included.",
    "published": "2023-07-03T17:53:39Z",
    "pdf_url": "http://arxiv.org/pdf/2307.01189v2",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "0409265v1",
    "title": "Transformation Digroups",
    "authors": [
      "Keqin Liu"
    ],
    "abstract": "We introduce the notion of a transformation digroup and prove that every\ndigroup is isomorphic to a transformation digroup.",
    "published": "2004-09-16T16:32:13Z",
    "pdf_url": "http://arxiv.org/pdf/math/0409265v1",
    "categories": [
      "math.GR",
      "math.RA",
      "20N05, 20N99"
    ]
  },
  {
    "arxiv_id": "1105.1427v2",
    "title": "Riesz transforms for Dunkl transform",
    "authors": [
      "Béchir Amri",
      "Mohamed Sifi"
    ],
    "abstract": "In this paper we obtain the $L^p$-boundedness of Riesz transforms for Dunkl\ntransform for all $1<p<\\infty$.",
    "published": "2011-05-07T09:00:11Z",
    "pdf_url": "http://arxiv.org/pdf/1105.1427v2",
    "categories": [
      "math.CA",
      "17B22, 32A55, 43A32, 42A45"
    ]
  },
  {
    "arxiv_id": "1107.3625v1",
    "title": "Appell Transformation and Canonical Transforms",
    "authors": [
      "Amalia Torre"
    ],
    "abstract": "The interpretation of the optical Appell transformation, as previously\nelaborated in relation to the free-space paraxial propagation under both a\nrectangular and a circular cylindrical symmetry, is reviewed. Then, the caloric\nAppell transformation, well known in the theory of heat equation, is shown to\nbe amenable for a similar interpretation involving the Laplace transform rather\nthan the Fourier transform, when dealing with the 1D heat equation.\nAccordingly, when considering the radial heat equation, suitably defined\nHankel-type transforms come to be involved in the inherent Appell\ntransformation. The analysis is aimed at outlining the link between the Appell\ntransformation and the canonical transforms.",
    "published": "2011-07-19T05:25:36Z",
    "pdf_url": "http://arxiv.org/pdf/1107.3625v1",
    "categories": [
      "math-ph",
      "math.MP",
      "physics.optics"
    ]
  },
  {
    "arxiv_id": "0604173v1",
    "title": "Comment on \"Gauge transformations are Canonical transformations\"",
    "authors": [
      "Pathikrit Bhattacharya",
      "Bhabani Prasad Mandal"
    ],
    "abstract": "We comment on the work of Tai L Chow, Eur. J. Phys. 18, 467 (1997). By\nconsidering the Lagrangians which are uniquely defined only to within an\nadditive total time derivative of a function of co-ordinates and time the\nauthor has tried to show that the gauge transformations which relate these\nLagrangians are canonical transformations. He has obtained the right conclusion\nonly by using wrong canonical equations and the entire exercise has hence\nbecome erroneous and inconclusive. By using the definition of canonical\ntransformation through Poisson brackets we prove that the above gauge\ntransformations are canonical transformations.",
    "published": "2006-04-21T04:06:28Z",
    "pdf_url": "http://arxiv.org/pdf/physics/0604173v1",
    "categories": [
      "physics.class-ph",
      "hep-th",
      "physics.gen-ph",
      "quant-ph"
    ]
  },
  {
    "arxiv_id": "1706.07699v1",
    "title": "Bicomplex Mobius Transformation",
    "authors": [
      "Chinmay Ghosh"
    ],
    "abstract": "In this article the bicomplex version of Mobius transformation is defined and\nspecial attention is paid to find the fixed points of a bicomplex Mobius\ntransformation.",
    "published": "2017-06-22T06:03:53Z",
    "pdf_url": "http://arxiv.org/pdf/1706.07699v1",
    "categories": [
      "math.CV",
      "30G35"
    ]
  },
  {
    "arxiv_id": "1711.05359v1",
    "title": "On Finite Gauss Transform",
    "authors": [
      "Maxim Arnold",
      "Anatoly Eydelzon"
    ],
    "abstract": "We present an invariant density for the finite Gauss transformation of the\nunit interval and discuss some properties of this transformation.",
    "published": "2017-11-15T00:03:24Z",
    "pdf_url": "http://arxiv.org/pdf/1711.05359v1",
    "categories": [
      "math.DS"
    ]
  },
  {
    "arxiv_id": "9409051v1",
    "title": "On Hurwitz Transformations",
    "authors": [
      "M. Hage Hassan",
      "M. Kibler"
    ],
    "abstract": "A bibliography on the Hurwitz transformations is given. We deal here, with\nsome details, with two particular Hurwitz transformations, viz, the $\\grq \\to\n\\grt$ Kustaanheimo-Stiefel transformation and its $\\grh \\to \\grc$ compact\nextension. These transformations are derived in the context of\nFock-Bargmann-Schwinger calculus with special emphasis on angular momentum\ntheory.",
    "published": "1994-09-10T13:59:28Z",
    "pdf_url": "http://arxiv.org/pdf/hep-th/9409051v1",
    "categories": [
      "hep-th"
    ]
  },
  {
    "arxiv_id": "9706228v1",
    "title": "Topological transformation groups",
    "authors": [
      "Alejandro Adem",
      "James F. Davis"
    ],
    "abstract": "This paper surveys some results and methods in topological transformation\ngroups.",
    "published": "1997-06-03T00:00:00Z",
    "pdf_url": "http://arxiv.org/pdf/math/9706228v1",
    "categories": [
      "math.AT"
    ]
  },
  {
    "arxiv_id": "1201.6584v1",
    "title": "Polyhedron under Linear Transformations",
    "authors": [
      "Zaikun Zhang"
    ],
    "abstract": "The image and the inverse image of a polyhedron under a linear transformation\nare polyhedrons.",
    "published": "2012-01-31T15:56:10Z",
    "pdf_url": "http://arxiv.org/pdf/1201.6584v1",
    "categories": [
      "math.FA"
    ]
  },
  {
    "arxiv_id": "1712.06453v2",
    "title": "Radon Transform for Sheaves",
    "authors": [
      "Honghao Gao"
    ],
    "abstract": "We define the Radon transform functor for sheaves and prove that it is an\nequivalence after suitable microlocal localizations. As a result, the sheaf\ncategory associated to a Legendrian is invariant under the Radon transform. We\nalso manage to place the Radon transform and other transforms in microlocal\nsheaf theory altogether in a diagram.",
    "published": "2017-12-18T15:06:15Z",
    "pdf_url": "http://arxiv.org/pdf/1712.06453v2",
    "categories": [
      "math.SG"
    ]
  },
  {
    "arxiv_id": "1807.07109v1",
    "title": "The trinomial transform triangle",
    "authors": [
      "László Németh"
    ],
    "abstract": "The trinomial transform of a sequence is a generalization of the well-known\nbinomial transform, replacing binomial coefficients with trinomial\ncoefficients. We examine Pascal-like triangles under trinomial transform,\nfocusing on the ternary linear recurrent sequences. We determine the sums and\nalternating sums of the elements in columns, and we give some examples of the\ntrinomial transform triangle.",
    "published": "2018-07-18T19:13:57Z",
    "pdf_url": "http://arxiv.org/pdf/1807.07109v1",
    "categories": [
      "math.NT",
      "math.CO",
      "11B37, 11B65, 11B75, 11B39"
    ]
  },
  {
    "arxiv_id": "0306424v1",
    "title": "The Wilson function transform",
    "authors": [
      "Wolter Groenevelt"
    ],
    "abstract": "Two unitary integral transforms with a very-well poised $_7F_6$-function as a\nkernel are given. For both integral transforms the inverse is the same as the\noriginal transform after an involution on the parameters. The $_7F_6$-function\ninvolved can be considered as a non-polynomial extension of the Wilson\npolynomial, and is therefore called a Wilson function. The two integral\ntransforms are called a Wilson function transform of type I and type II.\nFurthermore, a few explicit transformations of hypergeometric functions are\ncalculated, and it is shown that the Wilson function transform of type I maps a\nbasis of orthogonal polynomials onto a similar basis of polynomials.",
    "published": "2003-06-30T12:32:40Z",
    "pdf_url": "http://arxiv.org/pdf/math/0306424v1",
    "categories": [
      "math.CA"
    ]
  },
  {
    "arxiv_id": "1208.3342v1",
    "title": "Index hypergeometric integral transform",
    "authors": [
      "Yury A. Neretin"
    ],
    "abstract": "This is a brief overview of the index hypergeometric transform (other terms\nfor this integral operator are: Olevskii transform, Jacobi transform,\ngeneralized Mehler--Fock transform). We discuss applications of this transform\nto special functions and harmonic analysis. The text is an addendum to the\nRussian edition of the book by G.E.Andrews, R.Askey, and R.Roy, Special\nFunctions, Encycl. of Math. Appl. 71, Cambridge Univ. Press, 1999.",
    "published": "2012-08-16T11:23:28Z",
    "pdf_url": "http://arxiv.org/pdf/1208.3342v1",
    "categories": [
      "math.CA",
      "65R10, 33C05, 33C60, 53C35, 33C45"
    ]
  },
  {
    "arxiv_id": "1309.1855v1",
    "title": "Bounded rank-one transformations",
    "authors": [
      "Su Gao",
      "Aaron Hill"
    ],
    "abstract": "We define the notion of canonical boundedness among rank-one transformations\nand use it to characterize the class of all bounded rank-one transformations\nwith trivial centralizer. We also explicitly characterize totally ergodic\nrank-one transformations with bounded cutting parameter. Together with a recent\nresult of Ryzhikov our results provide a simple procedure for determining\nwhether a bounded rank-one transformation has minimal self-joinings of all\norders purely in terms of the cutting and spacer parameters for the\ntransformation.",
    "published": "2013-09-07T11:51:42Z",
    "pdf_url": "http://arxiv.org/pdf/1309.1855v1",
    "categories": [
      "math.DS"
    ]
  },
  {
    "arxiv_id": "1403.6568v4",
    "title": "Whirly 3-Interval Exchange Transformations",
    "authors": [
      "Yue Wu"
    ],
    "abstract": "Irreducible interval exchange transformations are studied with regard to\nwhirly property, a condition for non-trivial spatial factor. Uniformly whirly\ntransformation is defined and to be further studied. An equivalent condition is\nintroduced for whirly transformation. We will prove that almost all 3-interval\nexchange transformations are whirly, using a combinatorics approach with\napplication of the Rauzy-Veech Induction. It is still an open question whether\nwhirly property is a generic property for m-interval exchange transformations\n(m>=4).",
    "published": "2014-03-26T03:36:13Z",
    "pdf_url": "http://arxiv.org/pdf/1403.6568v4",
    "categories": [
      "math.DS",
      "28D15, 22F10"
    ]
  },
  {
    "arxiv_id": "1703.05022v1",
    "title": "Steerable Discrete Fourier Transform",
    "authors": [
      "Giulia Fracastoro",
      "Enrico Magli"
    ],
    "abstract": "Directional transforms have recently raised a lot of interest thanks to their\nnumerous applications in signal compression and analysis. In this letter, we\nintroduce a generalization of the discrete Fourier transform, called steerable\nDFT (SDFT). Since the DFT is used in numerous fields, it may be of interest in\na wide range of applications. Moreover, we also show that the SDFT is highly\nrelated to other well-known transforms, such as the Fourier sine and cosine\ntransforms and the Hilbert transforms.",
    "published": "2017-03-15T09:05:13Z",
    "pdf_url": "http://arxiv.org/pdf/1703.05022v1",
    "categories": [
      "cs.IT",
      "math.IT"
    ]
  },
  {
    "arxiv_id": "1409.0692v1",
    "title": "Gauge transformations are canonical transformations, redux",
    "authors": [
      "Z. K. Silagadze"
    ],
    "abstract": "In this short note we return to the old paper by Tai L. Chow (Eur. J. Phys.\n18 (1997), 467-468) and correct its erroneous final part. We also note that the\nmain result of that paper, that gauge transformations of mechanics are\ncanonical transformations, was known much earlier.",
    "published": "2014-09-02T13:07:22Z",
    "pdf_url": "http://arxiv.org/pdf/1409.0692v1",
    "categories": [
      "physics.class-ph",
      "math-ph",
      "math.MP"
    ]
  },
  {
    "arxiv_id": "1701.01326v1",
    "title": "Higher Order Context Transformations",
    "authors": [
      "Michal Vašinek",
      "Jan Platoš"
    ],
    "abstract": "The context transformation and generalized context transformation methods, we\nintroduced recently, were able to reduce zero order entropy by exchanging\ndigrams, and as a consequence, they were removing mutual information between\nconsecutive symbols of the input message. These transformations were intended\nto be used as a preprocessor for zero-order entropy coding algorithms like\nArithmetic or Huffman coding, since we know, that especially Arithmetic coding\ncan achieve a compression rate almost of the size of Shannon's entropy.\n  This paper introduces a novel algorithm based on the concept of generalized\ncontext transformation, that allows transformation of words longer than simple\ndigrams. The higher order contexts are exploited using recursive form of a\ngeneralized context transformation. It is shown that the zero order entropy of\ntransformed data drops significantly, but on the other hand, the overhead given\nby a description of individual transformations increases and it has become a\nlimiting factor in a successful transformation of smaller files.",
    "published": "2017-01-05T14:26:48Z",
    "pdf_url": "http://arxiv.org/pdf/1701.01326v1",
    "categories": [
      "cs.IT",
      "math.IT"
    ]
  },
  {
    "arxiv_id": "2105.14424v1",
    "title": "Gaze Estimation using Transformer",
    "authors": [
      "Yihua Cheng",
      "Feng Lu"
    ],
    "abstract": "Recent work has proven the effectiveness of transformers in many computer\nvision tasks. However, the performance of transformers in gaze estimation is\nstill unexplored. In this paper, we employ transformers and assess their\neffectiveness for gaze estimation. We consider two forms of vision transformer\nwhich are pure transformers and hybrid transformers. We first follow the\npopular ViT and employ a pure transformer to estimate gaze from images. On the\nother hand, we preserve the convolutional layers and integrate CNNs as well as\ntransformers. The transformer serves as a component to complement CNNs. We\ncompare the performance of the two transformers in gaze estimation. The Hybrid\ntransformer significantly outperforms the pure transformer in all evaluation\ndatasets with less parameters. We further conduct experiments to assess the\neffectiveness of the hybrid transformer and explore the advantage of\nself-attention mechanism. Experiments show the hybrid transformer can achieve\nstate-of-the-art performance in all benchmarks with pre-training.To facilitate\nfurther research, we release codes and models in\nhttps://github.com/yihuacheng/GazeTR.",
    "published": "2021-05-30T04:06:29Z",
    "pdf_url": "http://arxiv.org/pdf/2105.14424v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1109.0337v1",
    "title": "On discrete cosine transform",
    "authors": [
      "Jianqin Zhou"
    ],
    "abstract": "The discrete cosine transform (DCT), introduced by Ahmed, Natarajan and Rao,\nhas been used in many applications of digital signal processing, data\ncompression and information hiding. There are four types of the discrete cosine\ntransform. In simulating the discrete cosine transform, we propose a\ngeneralized discrete cosine transform with three parameters, and prove its\northogonality for some new cases. A new type of discrete cosine transform is\nproposed and its orthogonality is proved. Finally, we propose a generalized\ndiscrete W transform with three parameters, and prove its orthogonality for\nsome new cases.",
    "published": "2011-09-02T01:10:34Z",
    "pdf_url": "http://arxiv.org/pdf/1109.0337v1",
    "categories": [
      "cs.IT",
      "math.IT"
    ]
  },
  {
    "arxiv_id": "2210.08288v1",
    "title": "Transformer-based dimensionality reduction",
    "authors": [
      "Ruisheng Ran",
      "Tianyu Gao",
      "Bin Fang"
    ],
    "abstract": "Recently, Transformer is much popular and plays an important role in the\nfields of Machine Learning (ML), Natural Language Processing (NLP), and\nComputer Vision (CV), etc. In this paper, based on the Vision Transformer (ViT)\nmodel, a new dimensionality reduction (DR) model is proposed, named\nTransformer-DR. From data visualization, image reconstruction and face\nrecognition, the representation ability of Transformer-DR after dimensionality\nreduction is studied, and it is compared with some representative DR methods to\nunderstand the difference between Transformer-DR and existing DR methods. The\nexperimental results show that Transformer-DR is an effective dimensionality\nreduction method.",
    "published": "2022-10-15T13:24:43Z",
    "pdf_url": "http://arxiv.org/pdf/2210.08288v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2309.05224v1",
    "title": "SparseSwin: Swin Transformer with Sparse Transformer Block",
    "authors": [
      "Krisna Pinasthika",
      "Blessius Sheldo Putra Laksono",
      "Riyandi Banovbi Putera Irsal",
      "Syifa Hukma Shabiyya",
      "Novanto Yudistira"
    ],
    "abstract": "Advancements in computer vision research have put transformer architecture as\nthe state of the art in computer vision tasks. One of the known drawbacks of\nthe transformer architecture is the high number of parameters, this can lead to\na more complex and inefficient algorithm. This paper aims to reduce the number\nof parameters and in turn, made the transformer more efficient. We present\nSparse Transformer (SparTa) Block, a modified transformer block with an\naddition of a sparse token converter that reduces the number of tokens used. We\nuse the SparTa Block inside the Swin T architecture (SparseSwin) to leverage\nSwin capability to downsample its input and reduce the number of initial tokens\nto be calculated. The proposed SparseSwin model outperforms other state of the\nart models in image classification with an accuracy of 86.96%, 97.43%, and\n85.35% on the ImageNet100, CIFAR10, and CIFAR100 datasets respectively. Despite\nits fewer parameters, the result highlights the potential of a transformer\narchitecture using a sparse token converter with a limited number of tokens to\noptimize the use of the transformer and improve its performance.",
    "published": "2023-09-11T04:03:43Z",
    "pdf_url": "http://arxiv.org/pdf/2309.05224v1",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "0704.2744v2",
    "title": "Nahm transform and parabolic minimal Laplace transform",
    "authors": [
      "Szilard Szabo"
    ],
    "abstract": "We prove that Nahm transform for integrable connections with a finite number\nof regular singularities and an irregular singularity of rank 1 on the Riemann\nsphere is equivalent -- up to considering integrable connections as holonomic\n$\\D$-modules -- to minimal Laplace transform. We assume semi-simplicity and\nresonance-freeness conditions, and we work in the framework of objects with a\nparabolic structure. In particular, we describe the definition of the parabolic\nversion of Laplace transform due to C. Sabbah. The proof of the main result\nrelies on the study of a twisted de Rham complex.",
    "published": "2007-04-20T15:00:53Z",
    "pdf_url": "http://arxiv.org/pdf/0704.2744v2",
    "categories": [
      "math.AG",
      "14H60, 14F40, 13N10"
    ]
  },
  {
    "arxiv_id": "2004.06462v2",
    "title": "On dual transform of fractional Hankel transform",
    "authors": [
      "Allal Ghanmi"
    ],
    "abstract": "We deal with a class of one-parameter family of integral transforms of\nBargmann type arising as dual transforms of fractional Hankel transform. Their\nranges are identified to be special subspaces of the weighted hyperholomorphic\nleft Hilbert spaces, generalizing the slice Bergman space of the second kind.\nTheir reproducing kernel is given by closed expression involving the\n$\\star$-regularization of Gauss hypergeometric function. We also discuss their\nbasic properties such as their boundedness and we determinate their singular\nvalues. Moreover, we describe their compactness and membership in $p$-Schatten\nclasses.",
    "published": "2020-04-14T13:05:23Z",
    "pdf_url": "http://arxiv.org/pdf/2004.06462v2",
    "categories": [
      "math.CV",
      "math.FA",
      "math.SP",
      "44A20, 30G35, 30H20, 47B38, 30D55"
    ]
  },
  {
    "arxiv_id": "9210212v1",
    "title": "Radon transform and curvature",
    "authors": [
      "Peter W. Michor"
    ],
    "abstract": "We interpret the setting for a Radon transform as a submanifold of the space\nof generalized functions, and compute its extrinsic curvature: it is the\nHessian composed with the Radon transform.",
    "published": "1992-10-01T00:00:00Z",
    "pdf_url": "http://arxiv.org/pdf/math/9210212v1",
    "categories": [
      "math.DG",
      "math.FA",
      "44A12 58D15"
    ]
  },
  {
    "arxiv_id": "1302.2527v2",
    "title": "The Tsallis-Laplace Transform",
    "authors": [
      "A. Plastino",
      "M. C. Rocca"
    ],
    "abstract": "We introduce here the q-Laplace transform as a new weapon in Tsallis'\narsenal, discussing its main properties and analyzing some examples. The\nq-Gaussian instance receives special consideration. Also, we derive the\nq-partition function from the q-Laplace transform.",
    "published": "2013-02-11T16:40:55Z",
    "pdf_url": "http://arxiv.org/pdf/1302.2527v2",
    "categories": [
      "math-ph",
      "cond-mat.stat-mech",
      "math.MP"
    ]
  },
  {
    "arxiv_id": "1802.07563v1",
    "title": "Laplace transforms and valuations",
    "authors": [
      "Jin Li",
      "Dan Ma"
    ],
    "abstract": "It is proved that the classical Laplace transform is a continuous valuation\nwhich is positively GL$(n)$ covariant and logarithmic translation covariant.\nConversely, these properties turn out to be sufficient to characterize this\ntransform.",
    "published": "2018-02-21T13:33:04Z",
    "pdf_url": "http://arxiv.org/pdf/1802.07563v1",
    "categories": [
      "math.MG",
      "math.FA",
      "52A20, 52B45, 44A10"
    ]
  },
  {
    "arxiv_id": "2505.07505v1",
    "title": "On discrete X-ray transform",
    "authors": [
      "Roman Novikov",
      "Basant Lal Sharma"
    ],
    "abstract": "We consider a discrete version of X-ray transform going back, in particular,\nto Strichartz (1982). We suggest non-overdetermined reconstruction for this\ndiscrete transform. Extensions to weighted (attenuated) analogues are given.\nConnections to the continuous case are presented.",
    "published": "2025-05-12T12:41:05Z",
    "pdf_url": "http://arxiv.org/pdf/2505.07505v1",
    "categories": [
      "math.FA",
      "44A12, 46F12, 65R10, 65N21, 65N22"
    ]
  },
  {
    "arxiv_id": "9411199v1",
    "title": "Quantum Canonical Transformations revisited",
    "authors": [
      "A. Y. Shiekh"
    ],
    "abstract": "A preferred form for the path integral discretization is suggested that\nallows the implementation of canonical transformations in quantum theory.",
    "published": "1994-11-28T10:42:08Z",
    "pdf_url": "http://arxiv.org/pdf/hep-th/9411199v1",
    "categories": [
      "hep-th",
      "funct-an",
      "hep-lat",
      "math.FA"
    ]
  },
  {
    "arxiv_id": "0207129v1",
    "title": "Transformation de Fourier homogene",
    "authors": [
      "Gerard Laumon"
    ],
    "abstract": "In their proof of the Drinfeld-Langlands correspondence, Frenkel, Gaitsgory\nand Vilonen make use of a geometric Fourier transformation. Therefore, they\nwork either with l-adic sheaves in characteristic p>0, or with D-modules in\ncharacteristic 0. Actually, they only need to consider the Fourier transforms\nof homogeneous sheaves for which one expects a uniform geometric construction\nin any characteristic.\n  In this note, we propose such a homogeneous geometric Fourier transformation.\nIt extends the geometric Radon transformation which has been studied by\nBrylinski.",
    "published": "2002-07-16T12:19:28Z",
    "pdf_url": "http://arxiv.org/pdf/math/0207129v1",
    "categories": [
      "math.AG"
    ]
  },
  {
    "arxiv_id": "0312045v1",
    "title": "Hyperkähler Nahm transform",
    "authors": [
      "Claudio Bartocci",
      "Marcos Jardim"
    ],
    "abstract": "Given two hyperk\\\"ahler manifolds $M$ and $N$ and a quaternionic instanton on\ntheir product, a hyperk\\\"ahler Nahm transform can be defined, which maps\nquaternionic instantons on $M$ to quaternionic instantons on $N$. This\nconstruction includes the case of Nahm transform for periodic instantons on\n$\\bR^4$, the Fourier-Mukai transform for instantons on K3 surfaces, as well as\nthe Nahm transform for ALE instantons.",
    "published": "2003-12-02T03:02:01Z",
    "pdf_url": "http://arxiv.org/pdf/math/0312045v1",
    "categories": [
      "math.DG"
    ]
  },
  {
    "arxiv_id": "0202020v2",
    "title": "Fractional Darboux Transformations",
    "authors": [
      "Mayer Humi"
    ],
    "abstract": "In this paper we utilize the covariance of Ricatti equation with respect to\nlinear fractional transformations to define classes of conformally equivalent\nsecond order differential equations. This motivates then the introduction of\nfractional Darboux transformations which can be recognized also as generalized\nCole-Hopf transformations. We apply these transformations to find Schrodinger\nequations with isospectral potentials and to the linearization of some new\nclasses of nonlinear partial differential equations.",
    "published": "2002-02-13T19:39:19Z",
    "pdf_url": "http://arxiv.org/pdf/math-ph/0202020v2",
    "categories": [
      "math-ph",
      "math.DS",
      "math.MP"
    ]
  },
  {
    "arxiv_id": "0806.0489v1",
    "title": "Generalized field-transforming metamaterials",
    "authors": [
      "Sergei Tretyakov",
      "Igor Nefedov",
      "Pekka Alitalo"
    ],
    "abstract": "In this paper we introduce a generalized concept of field-transforming\nmetamaterials, which perform field transformations defined as linear relations\nbetween the original and transformed fields. These artificial media change the\nfields in a prescribed fashion in the volume occupied by the medium. We show\nwhat electromagnetic properties of transforming medium are required. The\ncoefficients of these linear functions can be arbitrary scalar functions of\nposition and frequency, which makes the approach quite general and opens a\npossibility to realize various unusual devices.",
    "published": "2008-06-03T10:28:47Z",
    "pdf_url": "http://arxiv.org/pdf/0806.0489v1",
    "categories": [
      "physics.optics",
      "physics.class-ph"
    ]
  },
  {
    "arxiv_id": "1308.2233v2",
    "title": "Frame Transformations for Fermions",
    "authors": [
      "Chris W Patterson",
      "William G Harter"
    ],
    "abstract": "The analog to the Legendre addition theorem is found for half-integral\nangular momentum using frame transformations for rotor states.",
    "published": "2013-08-09T20:08:57Z",
    "pdf_url": "http://arxiv.org/pdf/1308.2233v2",
    "categories": [
      "quant-ph",
      "math-ph",
      "math.MP"
    ]
  },
  {
    "arxiv_id": "2502.10647v1",
    "title": "A Power Transform",
    "authors": [
      "Jonathan T. Barron"
    ],
    "abstract": "Power transforms, such as the Box-Cox transform and Tukey's ladder of powers,\nare a fundamental tool in mathematics and statistics. These transforms are\nprimarily used for normalizing and standardizing datasets, effectively by\nraising values to a power. In this work I present a novel power transform, and\nI show that it serves as a unifying framework for wide family of loss\nfunctions, kernel functions, probability distributions, bump functions, and\nneural network activation functions.",
    "published": "2025-02-15T02:47:55Z",
    "pdf_url": "http://arxiv.org/pdf/2502.10647v1",
    "categories": [
      "cs.LG",
      "stat.ML",
      "stat.TH"
    ]
  },
  {
    "arxiv_id": "2505.23581v2",
    "title": "Quantum Hilbert Transform",
    "authors": [
      "Nitin Jha",
      "Abhishek Parakh"
    ],
    "abstract": "The Hilbert transform has been one of the foundational transforms in signal\nprocessing, finding it's way into multiple disciplines from cryptography to\nbiomedical sciences. However, there does not exist any quantum analogue for the\nHilbert transform. In this work, we introduce a formulation for the quantum\nHilbert transform (QHT)and apply it to a quantum steganography protocol. By\nbridging classical phase-shift techniques with quantum operations, QHT opens\nnew pathways in quantum signal processing, communications, sensing, and secure\ninformation hiding.",
    "published": "2025-05-29T15:53:26Z",
    "pdf_url": "http://arxiv.org/pdf/2505.23581v2",
    "categories": [
      "quant-ph",
      "cs.CR",
      "cs.DM",
      "cs.NI"
    ]
  },
  {
    "arxiv_id": "0808.1551v2",
    "title": "On SYZ mirror transformations",
    "authors": [
      "Kwokwai Chan",
      "Naichung Conan Leung"
    ],
    "abstract": "In this expository paper, we discuss how Fourier-Mukai-type transformations,\nwhich we call SYZ mirror transformations, can be applied to provide a geometric\nunderstanding of the mirror symmetry phenomena for semi-flat Calabi-Yau\nmanifolds and toric Fano manifolds. We also speculate the possible applications\nof these transformations to other more general settings.",
    "published": "2008-08-11T18:10:02Z",
    "pdf_url": "http://arxiv.org/pdf/0808.1551v2",
    "categories": [
      "math.SG",
      "math.AG",
      "14J32, 53D45, 53D12, 14J45"
    ]
  },
  {
    "arxiv_id": "1306.4899v2",
    "title": "Spacetime transformation acoustics",
    "authors": [
      "C. García-Meca",
      "S. Carloni",
      "C. Barceló",
      "G. Jannes",
      "J. Sánchez-Dehesa",
      "A. Martínez"
    ],
    "abstract": "A recently proposed analogue transformation method has allowed the extension\nof transformation acoustics to general spacetime transformations. We analyze\nhere in detail the differences between this new analogue transformation\nacoustics (ATA) method and the standard one (STA). We show explicitly that STA\nis not suitable for transformations that mix space and time. ATA takes as\nstarting point the acoustic equation for the velocity potential, instead of\nthat for the pressure as in STA. This velocity-potential equation by itself\nalready allows for some transformations mixing space and time, but not all of\nthem. We explicitly obtain the entire set of transformations that do not leave\nits form invariant. It is in these cases that ATA shows its true potential,\nallowing for building a transformation acoustics method that enables the full\nrange of spacetime transformations. We provide an example of an important\ntransformation which cannot be achieved with STA. Using this transformation, we\ndesign and simulate an acoustic frequency converter via the ATA approach.\nFurthermore, in those cases in which one can apply both the STA and ATA\napproaches, we study the different transformational properties of the\ncorresponding physical quantities.",
    "published": "2013-06-20T14:55:47Z",
    "pdf_url": "http://arxiv.org/pdf/1306.4899v2",
    "categories": [
      "gr-qc",
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci"
    ]
  },
  {
    "arxiv_id": "1403.8088v3",
    "title": "Multiple Geronimus transformations",
    "authors": [
      "Maxim Derevyagin",
      "Juan Carlos García-Ardila",
      "Francisco Marcellán"
    ],
    "abstract": "We consider multiple Geronimus transformations and show that they lead to\ndiscrete (non-diagonal) Sobolev type inner products. Moreover, it is shown that\nevery discrete Sobolev inner product can be obtained as a multiple Geronimus\ntransformation. A connection with Geronimus spectral transformations for matrix\northogonal polynomials is also considered.",
    "published": "2014-03-31T17:02:10Z",
    "pdf_url": "http://arxiv.org/pdf/1403.8088v3",
    "categories": [
      "math.CA",
      "math.NA",
      "Primary 42C05, Secondary 15A23"
    ]
  },
  {
    "arxiv_id": "1803.04248v1",
    "title": "On Quaternion Shearlet Transforms",
    "authors": [
      "Firdous A. Shah",
      "Azhar Y. Tantary"
    ],
    "abstract": "In this paper, we introduce the notion of quaternion shearlet transform-\nwhich is an extension of the ordinary shearlet transform. Firstly, we study the\nfundamental properties of quaternion shearlet transforms and then establish\nsome basic results including Moyal's and inversion formulae. Finally, we derive\nthe associated Heisenberg's uncertainty inequality and the corresponding\nlogarithmic version for quaternion shearlet transforms.",
    "published": "2018-03-01T11:01:28Z",
    "pdf_url": "http://arxiv.org/pdf/1803.04248v1",
    "categories": [
      "math.FA",
      "42C40. 42C15. 81R30. 42A38"
    ]
  },
  {
    "arxiv_id": "1804.00877v2",
    "title": "Mind Duggal Transforms",
    "authors": [
      "C. Benhida"
    ],
    "abstract": "It is known that if an operator $T$ is complex symmetric then its Aluthge\ntransform is also complex symmetric. This Note is devoted to showing that the\nDuggal transform doesn't inherit this property. For instance, we'll show that\nthe Duggal transform isn't always complex symmetric when $T$ is, as it was\nclaimed in \\cite{Ga}.",
    "published": "2018-04-03T09:14:55Z",
    "pdf_url": "http://arxiv.org/pdf/1804.00877v2",
    "categories": [
      "math.FA"
    ]
  },
  {
    "arxiv_id": "2006.01459v2",
    "title": "Infinite-Parameter ADHM Transform",
    "authors": [
      "R. S. Ward"
    ],
    "abstract": "The Atiyah-Drinfeld-Hitchin-Manin (ADHM) transform and its various\ngeneralizations are examples of non-linear integral transforms between\nfinite-dimensional moduli spaces. This note describes a natural\ninfinite-dimansional generalization, where the transform becomes a map from\nboundary data to a family of solutions of the self-duality equations in a\ndomain.",
    "published": "2020-06-02T08:59:55Z",
    "pdf_url": "http://arxiv.org/pdf/2006.01459v2",
    "categories": [
      "math-ph",
      "hep-th",
      "math.MP"
    ]
  },
  {
    "arxiv_id": "1901.01322v1",
    "title": "Transformed Snapshot Interpolation with High Resolution Transforms",
    "authors": [
      "G. Welper"
    ],
    "abstract": "In the last few years, several methods have been developed to deal with jump\nsingularities in parametric or stochastic hyperbolic PDEs. They typically use\nsome alignment of the jump-sets in physical space before performing well\nestablished reduced order modelling techniques such as reduced basis methods,\nPOD or simply interpolation. In the current literature, the transforms are\ntypically of low resolution in space, mostly low order polynomials, Fourier\nmodes or constant shifts. In this paper, we discuss higher resolution\ntransforms in one of the recent methods, the transformed snapshot interpolation\n(TSI). We introduce a new discretization of the transforms with an appropriate\nbehaviour near singularities and consider their numerical computation via an\noptimization procedure.",
    "published": "2019-01-04T21:48:27Z",
    "pdf_url": "http://arxiv.org/pdf/1901.01322v1",
    "categories": [
      "math.NA",
      "cs.NA",
      "41A46, 41A25, 35L67, 65M12"
    ]
  },
  {
    "arxiv_id": "1110.1589v2",
    "title": "Type-II Bäcklund Transformations via Gauge Transformations",
    "authors": [
      "A. R. Aguirre",
      "T. R. Araujo",
      "J. F. Gomes",
      "A. H. Zimerman"
    ],
    "abstract": "The construction of type II Backlund transformation for the sine-Gordon and\nthe Tzitzeica-Bullough-Dodd models are obtained from gauge transformation. An\ninfinite number of conserved quantities are constructed from the defect\nmatrices. This guarantees that the introduction of type II defects for these\nmodels does not spoil their integrability. In particular, modified energy and\nmomentum are derived and compared with those presented in recent literature.",
    "published": "2011-10-07T17:19:27Z",
    "pdf_url": "http://arxiv.org/pdf/1110.1589v2",
    "categories": [
      "nlin.SI",
      "hep-th",
      "math-ph",
      "math.MP"
    ]
  },
  {
    "arxiv_id": "2211.14655v1",
    "title": "How Crucial is Transformer in Decision Transformer?",
    "authors": [
      "Max Siebenborn",
      "Boris Belousov",
      "Junning Huang",
      "Jan Peters"
    ],
    "abstract": "Decision Transformer (DT) is a recently proposed architecture for\nReinforcement Learning that frames the decision-making process as an\nauto-regressive sequence modeling problem and uses a Transformer model to\npredict the next action in a sequence of states, actions, and rewards. In this\npaper, we analyze how crucial the Transformer model is in the complete DT\narchitecture on continuous control tasks. Namely, we replace the Transformer by\nan LSTM model while keeping the other parts unchanged to obtain what we call a\nDecision LSTM model. We compare it to DT on continuous control tasks, including\npendulum swing-up and stabilization, in simulation and on physical hardware.\nOur experiments show that DT struggles with continuous control problems, such\nas inverted pendulum and Furuta pendulum stabilization. On the other hand, the\nproposed Decision LSTM is able to achieve expert-level performance on these\ntasks, in addition to learning a swing-up controller on the real system. These\nresults suggest that the strength of the Decision Transformer for continuous\ncontrol tasks may lie in the overall sequential modeling architecture and not\nin the Transformer per se.",
    "published": "2022-11-26T20:13:22Z",
    "pdf_url": "http://arxiv.org/pdf/2211.14655v1",
    "categories": [
      "cs.LG",
      "cs.RO"
    ]
  },
  {
    "arxiv_id": "9601105v1",
    "title": "The inverse loop transform",
    "authors": [
      "Thomas Thiemann"
    ],
    "abstract": "The loop transform in quantum gauge field theory can be recognized as the\nFourier transform (or characteristic functional) of a measure on the space of\ngeneralized connections modulo gauge transformations. Since this space is a\ncompact Hausdorff space, conversely, we know from the Riesz-Markov theorem that\nevery positive linear functional on the space of continuous functions thereon\nqualifies as the loop transform of a regular Borel measure on the moduli space.\nIn the present article we show how one can compute the finite joint\ndistributions of a given characteristic functional, that is, we derive the\ninverse loop transform.",
    "published": "1996-01-19T23:20:52Z",
    "pdf_url": "http://arxiv.org/pdf/hep-th/9601105v1",
    "categories": [
      "hep-th",
      "gr-qc"
    ]
  },
  {
    "arxiv_id": "1210.0803v2",
    "title": "Invertible Darboux Transformations",
    "authors": [
      "Ekaterina Shemyakova"
    ],
    "abstract": "For operators of many different kinds it has been proved that (generalized)\nDarboux transformations can be built using so called Wronskian formulae. Such\nDarboux transformations are not invertible in the sense that the corresponding\nmappings of the operator kernels are not invertible. The only known invertible\nones were Laplace transformations (and their compositions), which are special\ncases of Darboux transformations for hyperbolic bivariate operators of order 2.\nIn the present paper we find a criteria for a bivariate linear partial\ndifferential operator of an arbitrary order d to have an invertible Darboux\ntransformation. We show that Wronkian formulae may fail in some cases, and find\nsufficient conditions for such formulae to work.",
    "published": "2012-10-02T15:21:56Z",
    "pdf_url": "http://arxiv.org/pdf/1210.0803v2",
    "categories": [
      "math-ph",
      "math.DG",
      "math.MP"
    ]
  },
  {
    "arxiv_id": "1407.0456v1",
    "title": "Transformed Auto-correlation",
    "authors": [
      "Jianfeng Zhou",
      "Yang Gao"
    ],
    "abstract": "A transformed auto-correlation method is presented here, where a received\nsignal is transformed based on a priori reflecting model, and then the\ntransformed signal is cross-correlated to its original one. If the model is\ncorrect, after transformation, the reflected signal will be coherent to the\ntransmitted signal, with zero delay. A map of transformed auto-correlation\nfunction with zero delay can be generated in a given parametric space. The\nsignificant peaks in the map may indicate the possible reflectors nearby the\ncentral transmitter. The true values of the parameters of reflectors can be\nestimated at the same time.",
    "published": "2014-07-02T05:47:16Z",
    "pdf_url": "http://arxiv.org/pdf/1407.0456v1",
    "categories": [
      "astro-ph.IM"
    ]
  },
  {
    "arxiv_id": "2004.03761v1",
    "title": "Adaptive Transformers in RL",
    "authors": [
      "Shakti Kumar",
      "Jerrod Parker",
      "Panteha Naderian"
    ],
    "abstract": "Recent developments in Transformers have opened new interesting areas of\nresearch in partially observable reinforcement learning tasks. Results from\nlate 2019 showed that Transformers are able to outperform LSTMs on both memory\nintense and reactive tasks. In this work we first partially replicate the\nresults shown in Stabilizing Transformers in RL on both reactive and memory\nbased environments. We then show performance improvement coupled with reduced\ncomputation when adding adaptive attention span to this Stable Transformer on a\nchallenging DMLab30 environment. The code for all our experiments and models is\navailable at https://github.com/jerrodparker20/adaptive-transformers-in-rl.",
    "published": "2020-04-08T01:03:10Z",
    "pdf_url": "http://arxiv.org/pdf/2004.03761v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "2002.06170v1",
    "title": "Transformer on a Diet",
    "authors": [
      "Chenguang Wang",
      "Zihao Ye",
      "Aston Zhang",
      "Zheng Zhang",
      "Alexander J. Smola"
    ],
    "abstract": "Transformer has been widely used thanks to its ability to capture sequence\ninformation in an efficient way. However, recent developments, such as BERT and\nGPT-2, deliver only heavy architectures with a focus on effectiveness. In this\npaper, we explore three carefully-designed light Transformer architectures to\nfigure out whether the Transformer with less computations could produce\ncompetitive results. Experimental results on language model benchmark datasets\nhint that such trade-off is promising, and the light Transformer reduces 70%\nparameters at best, while obtains competitive perplexity compared to standard\nTransformer. The source code is publicly available.",
    "published": "2020-02-14T18:41:58Z",
    "pdf_url": "http://arxiv.org/pdf/2002.06170v1",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1806.00208v1",
    "title": "Degenerate Miller-Paris transformations",
    "authors": [
      "Dmitrii B. Karp",
      "Elena G. Prilepkina"
    ],
    "abstract": "Important new transformations for the generalized hypergeometric functions\nwith integral parameter differences have been discovered some years ago by\nMiller and Paris and studied in detail in a series of papers by a number of\nauthors. These transformations fail if the free bottom parameter is greater\nthan a free top parameter by a small positive integer. In this paper we fill\nthis gap in the theory of Miller-Paris transformations by computing the limit\ncases of these transformations in such previously prohibited situations. This\nleads to a number of new transformation and summation formulas including\nextensions of Karlsson-Minton theorem.",
    "published": "2018-06-01T06:20:48Z",
    "pdf_url": "http://arxiv.org/pdf/1806.00208v1",
    "categories": [
      "math.CA",
      "33C20"
    ]
  },
  {
    "arxiv_id": "1901.09458v2",
    "title": "Learning Transformation Synchronization",
    "authors": [
      "Xiangru Huang",
      "Zhenxiao Liang",
      "Xiaowei Zhou",
      "Yao Xie",
      "Leonidas Guibas",
      "Qixing Huang"
    ],
    "abstract": "Reconstructing the 3D model of a physical object typically requires us to\nalign the depth scans obtained from different camera poses into the same\ncoordinate system. Solutions to this global alignment problem usually proceed\nin two steps. The first step estimates relative transformations between pairs\nof scans using an off-the-shelf technique. Due to limited information presented\nbetween pairs of scans, the resulting relative transformations are generally\nnoisy. The second step then jointly optimizes the relative transformations\namong all input depth scans. A natural constraint used in this step is the\ncycle-consistency constraint, which allows us to prune incorrect relative\ntransformations by detecting inconsistent cycles. The performance of such\napproaches, however, heavily relies on the quality of the input relative\ntransformations. Instead of merely using the relative transformations as the\ninput to perform transformation synchronization, we propose to use a neural\nnetwork to learn the weights associated with each relative transformation. Our\napproach alternates between transformation synchronization using weighted\nrelative transformations and predicting new weights of the input relative\ntransformations using a neural network. We demonstrate the usefulness of this\napproach across a wide range of datasets.",
    "published": "2019-01-27T23:09:21Z",
    "pdf_url": "http://arxiv.org/pdf/1901.09458v2",
    "categories": [
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2306.01128v2",
    "title": "Learning Transformer Programs",
    "authors": [
      "Dan Friedman",
      "Alexander Wettig",
      "Danqi Chen"
    ],
    "abstract": "Recent research in mechanistic interpretability has attempted to\nreverse-engineer Transformer models by carefully inspecting network weights and\nactivations. However, these approaches require considerable manual effort and\nstill fall short of providing complete, faithful descriptions of the underlying\nalgorithms. In this work, we introduce a procedure for training Transformers\nthat are mechanistically interpretable by design. We build on RASP [Weiss et\nal., 2021], a programming language that can be compiled into Transformer\nweights. Instead of compiling human-written programs into Transformers, we\ndesign a modified Transformer that can be trained using gradient-based\noptimization and then automatically converted into a discrete, human-readable\nprogram. We refer to these models as Transformer Programs. To validate our\napproach, we learn Transformer Programs for a variety of problems, including an\nin-context learning task, a suite of algorithmic problems (e.g. sorting,\nrecognizing Dyck languages), and NLP tasks including named entity recognition\nand text classification. The Transformer Programs can automatically find\nreasonable solutions, performing on par with standard Transformers of\ncomparable size; and, more importantly, they are easy to interpret. To\ndemonstrate these advantages, we convert Transformers into Python programs and\nuse off-the-shelf code analysis tools to debug model errors and identify the\n\"circuits\" used to solve different sub-problems. We hope that Transformer\nPrograms open a new path toward the goal of intrinsically interpretable machine\nlearning.",
    "published": "2023-06-01T20:27:01Z",
    "pdf_url": "http://arxiv.org/pdf/2306.01128v2",
    "categories": [
      "cs.LG",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2404.19350v1",
    "title": "Transform Dialect Tutorial",
    "authors": [
      "Oleksandr Zinenko"
    ],
    "abstract": "Transform Dialect in MLIR provides operations that can be used to control\ntransformation of the Intermediate Representation (IR) using a different\nportion of the IR. It refers to the IR being transformed as payload IR, and to\nthe IR guiding the transformation as transform IR.\n  The main use case for this dialect is orchestrating fine-grain\ntransformations on individual IR objects (operations or values) or sets\nthereof. For example, it may involve finding loop-like operations with specific\nproperties (e.g., large size) in the payload IR, applying loop tiling to those\nand only those operations, and then applying loop unrolling to the inner loops\nproduced by the previous transformations. As such, it is not intended as a\nreplacement for the pass infrastructure, nor for the pattern rewriting\ninfrastructure. In the most common case, the transform IR will be processed and\napplied to the payload IR by a pass. Transformations expressed by the Transform\ndialect may be implemented using the pattern infrastructure or any other\nrelevant MLIR component.\n  The rest of this document explains the main concepts and usage scenario of\nthe MLIR Transform Dialect combined with structured operations.",
    "published": "2024-04-30T08:25:36Z",
    "pdf_url": "http://arxiv.org/pdf/2404.19350v1",
    "categories": [
      "cs.PL"
    ]
  },
  {
    "arxiv_id": "9702028v1",
    "title": "Efficient Quantum Transforms",
    "authors": [
      "Peter Hoyer"
    ],
    "abstract": "Quantum mechanics requires the operation of quantum computers to be unitary,\nand thus makes it important to have general techniques for developing fast\nquantum algorithms for computing unitary transforms. A quantum routine for\ncomputing a generalized Kronecker product is given. Applications include\nre-development of the networks for computing the Walsh-Hadamard and the quantum\nFourier transform. New networks for two wavelet transforms are given. Quantum\ncomputation of Fourier transforms for non-Abelian groups is defined. A slightly\nrelaxed definition is shown to simplify the analysis and the networks that\ncomputes the transforms. Efficient networks for computing such transforms for a\nclass of metacyclic groups are introduced. A novel network for computing a\nFourier transform for a group used in quantum error-correction is also given.",
    "published": "1997-02-12T00:52:17Z",
    "pdf_url": "http://arxiv.org/pdf/quant-ph/9702028v1",
    "categories": [
      "quant-ph"
    ]
  },
  {
    "arxiv_id": "1306.1669v1",
    "title": "Quaternionic Fourier-Mellin Transform",
    "authors": [
      "Eckhard Hitzer"
    ],
    "abstract": "In this contribution we generalize the classical Fourier Mellin transform [S.\nDorrode and F. Ghorbel, Robust and efficient Fourier-Mellin transform\napproximations for gray-level image reconstruction and complete invariant\ndescription, Computer Vision and Image Understanding, 83(1) (2001), 57-78, DOI\n10.1006/cviu.2001.0922.], which transforms functions $f$ representing, e.g., a\ngray level image defined over a compact set of $\\mathbb{R}^2$. The quaternionic\nFourier Mellin transform (QFMT) applies to functions $f: \\mathbb{R}^2\n\\rightarrow \\mathbb{H}$, for which $|f|$ is summable over $\\mathbb{R}_+^*\n\\times \\mathbb{S}^1$ under the measure $d\\theta \\frac{dr}{r}$. $\\mathbb{R}_+^*$\nis the multiplicative group of positive and non-zero real numbers. We\ninvestigate the properties of the QFMT similar to the investigation of the\nquaternionic Fourier Transform (QFT) in [E. Hitzer, Quaternion Fourier\nTransform on Quaternion Fields and Generalizations, Advances in Applied\nClifford Algebras, 17(3) (2007), 497-517.; E. Hitzer, Directional Uncertainty\nPrinciple for Quaternion Fourier Transforms, Advances in Applied Clifford\nAlgebras, 20(2) (2010), 271-284, online since 08 July 2009.].",
    "published": "2013-06-07T09:32:25Z",
    "pdf_url": "http://arxiv.org/pdf/1306.1669v1",
    "categories": [
      "math.RA",
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2004.12760v5",
    "title": "Unitary pseudonatural transformations",
    "authors": [
      "Dominic Verdon"
    ],
    "abstract": "We suggest two approaches to a definition of unitarity for pseudonatural\ntransformations between unitary pseudofunctors on pivotal dagger 2-categories.\nThe first is to require that the 2-morphism components of the transformation be\nunitary. The second is to require that the dagger of the transformation be\nequal to its inverse. We show that the `inverse' making these definitions\nequivalent is the right dual of the transformation in the 2-category Fun(C,D)\nof pseudofunctors C -> D, pseudonatural transformations, and modifications. We\nshow that the subcategory Fun_u(C,D) $\\subset$ Fun(C,D) whose objects are\nunitary pseudofunctors and whose 1-morphisms are unitary pseudonatural\ntransformations is a pivotal dagger 2-category. We apply these results to\nobtain a Morita-theoretical classification of unitary pseudonatural\ntransformations between fibre functors on the category of representations of a\ncompact quantum group.",
    "published": "2020-04-27T13:03:58Z",
    "pdf_url": "http://arxiv.org/pdf/2004.12760v5",
    "categories": [
      "math.CT",
      "math.QA"
    ]
  },
  {
    "arxiv_id": "2103.14803v2",
    "title": "Face Transformer for Recognition",
    "authors": [
      "Yaoyao Zhong",
      "Weihong Deng"
    ],
    "abstract": "Recently there has been a growing interest in Transformer not only in NLP but\nalso in computer vision. We wonder if transformer can be used in face\nrecognition and whether it is better than CNNs. Therefore, we investigate the\nperformance of Transformer models in face recognition. Considering the original\nTransformer may neglect the inter-patch information, we modify the patch\ngeneration process and make the tokens with sliding patches which overlaps with\neach others. The models are trained on CASIA-WebFace and MS-Celeb-1M databases,\nand evaluated on several mainstream benchmarks, including LFW, SLLFW, CALFW,\nCPLFW, TALFW, CFP-FP, AGEDB and IJB-C databases. We demonstrate that Face\nTransformer models trained on a large-scale database, MS-Celeb-1M, achieve\ncomparable performance as CNN with similar number of parameters and MACs. To\nfacilitate further researches, Face Transformer models and codes are available\nat https://github.com/zhongyy/Face-Transformer.",
    "published": "2021-03-27T03:53:29Z",
    "pdf_url": "http://arxiv.org/pdf/2103.14803v2",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2411.07218v1",
    "title": "TreeCoders: Trees of Transformers",
    "authors": [
      "Pierre Colonna D'Istria",
      "Abdulrahman Altahhan"
    ],
    "abstract": "In this paper, we introduce TreeCoders, a novel family of transformer trees.\nWe moved away from traditional linear transformers to complete k-ary trees.\nTransformer blocks serve as nodes, and generic classifiers learn to select the\nbest child and route the sequence of tokens to a specific leaf. The selectors,\nmoved outside the transformer blocks, allow for the use of a variety of\narchitecture without further modifications. Furthermore, our proposed\narchitecture supports sparse node activation due to the logarithmic complexity\nof a tree search. We validate our idea by testing a series of decoder-only tree\ntransformers, achieving competitive results across a diverse range of language\ndatasets. Our study demonstrates that the proposed tree transformer model\noutperforms a size-equivalent linear transformer model 76\\% of the time over a\nwide range of tree architectures. Furthermore, our proposed model naturally\nlends itself to distributed implementation.",
    "published": "2024-11-11T18:40:04Z",
    "pdf_url": "http://arxiv.org/pdf/2411.07218v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "0604220v1",
    "title": "Combined Reduced-Rank Transform",
    "authors": [
      "Anatoli Torokhti",
      "Phil Howlett"
    ],
    "abstract": "We propose and justify a new approach to constructing optimal nonlinear\ntransforms of random vectors. We show that the proposed transform improves such\ncharacteristics of rank-reduced transforms as compression ratio, accuracy of\ndecompression and reduces required computational work. The proposed transform\n${\\mathcal T}_p$ is presented in the form of a sum with $p$ terms where each\nterm is interpreted as a particular rank-reduced transform. Moreover, terms in\n${\\mathcal T}_p$ are represented as a combination of three operations\n${\\mathcal F}_k$, ${\\mathcal Q}_k$ and ${\\boldsymbol{\\phi}}_k$ with\n$k=1,...,p$. The prime idea is to determine ${\\mathcal F}_k$ separately, for\neach $k=1,...,p$, from an associated rank-constrained minimization problem\nsimilar to that used in the Karhunen--Lo\\`{e}ve transform. The operations\n${\\mathcal Q}_k$ and ${\\boldsymbol{\\phi}}_k$ are auxiliary for finding\n${\\mathcal F}_k$. The contribution of each term in ${\\mathcal T}_p$ improves\nthe entire transform performance. A corresponding unconstrained nonlinear\noptimal transform is also considered. Such a transform is important in its own\nright because it is treated as an optimal filter without signal compression. A\nrigorous analysis of errors associated with the proposed transforms is given.",
    "published": "2006-04-10T10:43:51Z",
    "pdf_url": "http://arxiv.org/pdf/math/0604220v1",
    "categories": [
      "math.OC",
      "math.CA",
      "math.NA"
    ]
  },
  {
    "arxiv_id": "2209.08167v2",
    "title": "Quantum Vision Transformers",
    "authors": [
      "El Amine Cherrat",
      "Iordanis Kerenidis",
      "Natansh Mathur",
      "Jonas Landman",
      "Martin Strahm",
      "Yun Yvonna Li"
    ],
    "abstract": "In this work, quantum transformers are designed and analysed in detail by\nextending the state-of-the-art classical transformer neural network\narchitectures known to be very performant in natural language processing and\nimage analysis. Building upon the previous work, which uses parametrised\nquantum circuits for data loading and orthogonal neural layers, we introduce\nthree types of quantum transformers for training and inference, including a\nquantum transformer based on compound matrices, which guarantees a theoretical\nadvantage of the quantum attention mechanism compared to their classical\ncounterpart both in terms of asymptotic run time and the number of model\nparameters. These quantum architectures can be built using shallow quantum\ncircuits and produce qualitatively different classification models. The three\nproposed quantum attention layers vary on the spectrum between closely\nfollowing the classical transformers and exhibiting more quantum\ncharacteristics. As building blocks of the quantum transformer, we propose a\nnovel method for loading a matrix as quantum states as well as two new\ntrainable quantum orthogonal layers adaptable to different levels of\nconnectivity and quality of quantum computers. We performed extensive\nsimulations of the quantum transformers on standard medical image datasets that\nshowed competitively, and at times better performance compared to the classical\nbenchmarks, including the best-in-class classical vision transformers. The\nquantum transformers we trained on these small-scale datasets require fewer\nparameters compared to standard classical benchmarks. Finally, we implemented\nour quantum transformers on superconducting quantum computers and obtained\nencouraging results for up to six qubit experiments.",
    "published": "2022-09-16T20:51:23Z",
    "pdf_url": "http://arxiv.org/pdf/2209.08167v2",
    "categories": [
      "quant-ph",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2407.09777v1",
    "title": "Graph Transformers: A Survey",
    "authors": [
      "Ahsan Shehzad",
      "Feng Xia",
      "Shagufta Abid",
      "Ciyuan Peng",
      "Shuo Yu",
      "Dongyu Zhang",
      "Karin Verspoor"
    ],
    "abstract": "Graph transformers are a recent advancement in machine learning, offering a\nnew class of neural network models for graph-structured data. The synergy\nbetween transformers and graph learning demonstrates strong performance and\nversatility across various graph-related tasks. This survey provides an\nin-depth review of recent progress and challenges in graph transformer\nresearch. We begin with foundational concepts of graphs and transformers. We\nthen explore design perspectives of graph transformers, focusing on how they\nintegrate graph inductive biases and graph attention mechanisms into the\ntransformer architecture. Furthermore, we propose a taxonomy classifying graph\ntransformers based on depth, scalability, and pre-training strategies,\nsummarizing key principles for effective development of graph transformer\nmodels. Beyond technical analysis, we discuss the applications of graph\ntransformer models for node-level, edge-level, and graph-level tasks, exploring\ntheir potential in other application scenarios as well. Finally, we identify\nremaining challenges in the field, such as scalability and efficiency,\ngeneralization and robustness, interpretability and explainability, dynamic and\ncomplex graphs, as well as data quality and diversity, charting future\ndirections for graph transformer research.",
    "published": "2024-07-13T05:15:24Z",
    "pdf_url": "http://arxiv.org/pdf/2407.09777v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T07, 68T05, 68U01",
      "I.2.6"
    ]
  },
  {
    "arxiv_id": "0511211v1",
    "title": "Gauge transformations are not canonical transformations",
    "authors": [
      "A. T. Suzuki",
      "J. H. O. Sales"
    ],
    "abstract": "In classical mechanics, we can describe the dynamics of a given system using\neither the Lagrangian formalism or the Hamiltonian formalism, the choice of\neither one being determined by whether one wants to deal with a second degree\ndifferential equation or a pair of first degree ones. For the former approach,\nwe know that the Euler-Lagrange equation of motion remains invariant under\nadditive total derivative with respect to time of any function of coordinates\nand time in the Lagrangian function, whereas the latter one is invariant under\ncanonical transformations. In this short paper we address the question whether\nthe transformation that leaves the Euler-Lagrange equation of motion invariant\nis also a canonical transformation and show that it is not.",
    "published": "2005-11-21T18:20:51Z",
    "pdf_url": "http://arxiv.org/pdf/hep-th/0511211v1",
    "categories": [
      "hep-th"
    ]
  },
  {
    "arxiv_id": "2305.16982v1",
    "title": "TranSFormer: Slow-Fast Transformer for Machine Translation",
    "authors": [
      "Bei Li",
      "Yi Jing",
      "Xu Tan",
      "Zhen Xing",
      "Tong Xiao",
      "Jingbo Zhu"
    ],
    "abstract": "Learning multiscale Transformer models has been evidenced as a viable\napproach to augmenting machine translation systems. Prior research has\nprimarily focused on treating subwords as basic units in developing such\nsystems. However, the incorporation of fine-grained character-level features\ninto multiscale Transformer has not yet been explored. In this work, we present\na \\textbf{S}low-\\textbf{F}ast two-stream learning model, referred to as\nTran\\textbf{SF}ormer, which utilizes a ``slow'' branch to deal with subword\nsequences and a ``fast'' branch to deal with longer character sequences. This\nmodel is efficient since the fast branch is very lightweight by reducing the\nmodel width, and yet provides useful fine-grained features for the slow branch.\nOur TranSFormer shows consistent BLEU improvements (larger than 1 BLEU point)\non several machine translation benchmarks.",
    "published": "2023-05-26T14:37:38Z",
    "pdf_url": "http://arxiv.org/pdf/2305.16982v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2404.12362v1",
    "title": "Transformer tricks: Removing weights for skipless transformers",
    "authors": [
      "Nils Graef"
    ],
    "abstract": "He and Hofmann (arXiv:2311.01906) detailed a skipless transformer without the\nV and P (post-attention projection) linear layers, which reduces the total\nnumber of weights. However, this scheme is only applicable to MHA (multi-head\nattention), but not for MQA (multi-query attention) and GQA (grouped-query\nattention). The latter schemes are used by many popular LLMs such as Llama 2,\nMistral, Mixtral, PaLM, and Gemma. Therefore, this micro-paper proposes\nmathematically equivalent versions that are suitable for MQA and GQA. For\nexample, removing Q and P from a skipless version of Mistral-7B would remove\n15% of its weights (and thus reduce its compute and memory complexity). See\narXiv:2402.13388 and https://github.com/OpenMachine-ai/transformer-tricks for\ncode and more transformer tricks.",
    "published": "2024-04-18T17:45:19Z",
    "pdf_url": "http://arxiv.org/pdf/2404.12362v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "0503668v1",
    "title": "The Hough transform estimator",
    "authors": [
      "Alexander Goldenshluger",
      "Assaf Zeevi"
    ],
    "abstract": "This article pursues a statistical study of the Hough transform, the\ncelebrated computer vision algorithm used to detect the presence of lines in a\nnoisy image. We first study asymptotic properties of the Hough transform\nestimator, whose objective is to find the line that ``best'' fits a set of\nplanar points. In particular, we establish strong consistency and rates of\nconvergence, and characterize the limiting distribution of the Hough transform\nestimator. While the convergence rates are seen to be slower than those found\nin some standard regression methods, the Hough transform estimator is shown to\nbe more robust as measured by its breakdown point. We next study the Hough\ntransform in the context of the problem of detecting multiple lines. This is\naddressed via the framework of excess mass functionals and modality testing.\nThroughout, several numerical examples help illustrate various properties of\nthe estimator. Relations between the Hough transform and more mainstream\nstatistical paradigms and methods are discussed as well.",
    "published": "2005-03-29T10:12:30Z",
    "pdf_url": "http://arxiv.org/pdf/math/0503668v1",
    "categories": [
      "math.ST",
      "stat.TH",
      "62F12, 62F35, 68T45 (Primary)"
    ]
  },
  {
    "arxiv_id": "0607224v1",
    "title": "Composite Cosine Transforms",
    "authors": [
      "E. Ournycheva",
      "B. Rubin"
    ],
    "abstract": "The cosine transforms of functions on the unit sphere play an important role\nin convex geometry, the Banach space theory, stochastic geometry and other\nareas. Their higher-rank generalization to Grassmann manifolds represents an\ninteresting mathematical object useful for applications. We introduce more\ngeneral integral transforms that reveal distinctive features of higher-rank\nobjects in full generality. We call these new transforms the composite cosine\ntransforms, by taking into account that their kernels agree with the composite\npower function of the cone of positive definite symmetric matrices. We show\nthat injectivity of the composite cosine transforms can be studied using\nstandard tools of the Fourier analysis on matrix spaces. In the framework of\nthis approach, we introduce associated generalized zeta integrals and give new\nsimple proofs to the relevant functional relations. Our technique is based on\napplication of the higher-rank Radon transform on matrix spaces.",
    "published": "2006-07-09T00:05:13Z",
    "pdf_url": "http://arxiv.org/pdf/math/0607224v1",
    "categories": [
      "math.FA",
      "Primary 42B10; Secondary 52A22"
    ]
  },
  {
    "arxiv_id": "0208153v1",
    "title": "Comparison of unitary transforms",
    "authors": [
      "Erika Andersson",
      "Igor Jex",
      "Stephen M. Barnett"
    ],
    "abstract": "We analyze the problem of comparing unitary transformations. The task is to\ndecide, with minimal resources and maximal reliability, whether two given\nunitary transformations are identical or different. It is possible to make such\ncomparisons without obtaining any information about the individual\ntransformations. Different comparison strategies are presented and compared\nwith respect to their efficiency. With an interferometric setup, it is possible\nto compare two unitary transforms using only one test particle. Another\nstrategy makes use of a two-particle singlet state. This strategy is more\nefficient than using a non-entangled two-particle test state, thus\ndemonstrating the benefit of entanglement. Generalisations to higher\ndimensional transforms and to more than two transformations are made.",
    "published": "2002-08-26T17:18:42Z",
    "pdf_url": "http://arxiv.org/pdf/quant-ph/0208153v1",
    "categories": [
      "quant-ph"
    ]
  },
  {
    "arxiv_id": "0711.3577v1",
    "title": "Transform martingale estimating functions",
    "authors": [
      "T. Merkouris"
    ],
    "abstract": "An estimation method is proposed for a wide variety of discrete time\nstochastic processes that have an intractable likelihood function but are\notherwise conveniently specified by an integral transform such as the\ncharacteristic function, the Laplace transform or the probability generating\nfunction. This method involves the construction of classes of transform-based\nmartingale estimating functions that fit into the general framework of\nquasi-likelihood. In the parametric setting of a discrete time stochastic\nprocess, we obtain transform quasi-score functions by projecting the\nunavailable score function onto the special linear spaces formed by these\nclasses. The specification of the process by any of the main integral\ntransforms makes possible an arbitrarily close approximation of the score\nfunction in an infinite-dimensional Hilbert space by optimally combining\ntransform martingale quasi-score functions. It also allows an extension of the\ndomain of application of quasi-likelihood methodology to processes with\ninfinite conditional second moment.",
    "published": "2007-11-22T14:03:14Z",
    "pdf_url": "http://arxiv.org/pdf/0711.3577v1",
    "categories": [
      "math.ST",
      "stat.TH",
      "62M99, 60G42, 60E10 (Primary) 62M05, 62M09 (Secondary)"
    ]
  },
  {
    "arxiv_id": "1611.02564v1",
    "title": "Generalizing the Lorentz transformations",
    "authors": [
      "James M. Chappell",
      "David L. Berkahn",
      "Nicolangelo Iannella",
      "John G. Hartnett",
      "Azhar Iqbal",
      "Derek Abbott"
    ],
    "abstract": "In this paper we develop a framework allowing a natural extension of the\nLorentz transformations. To begin, we show that by expanding conventional\nfour-dimensional spacetime to eight-dimensions that a natural generalization is\nindeed obtained. We then find with these generalized coordinate transformations\nacting on Maxwell's equations that the electromagnetic field transformations\nare nevertheless unchanged. We find further, that if we assume the absence of\nmagnetic monopoles, in accordance with Maxwell's theory, our generalized\ntransformations are then restricted to be the conventional ones. While the\nconventional Lorentz transformations are indeed recovered from our framework,\nwe nevertheless provide a new perspective into why the Lorentz transformations\nare constrained to be the conventional ones. Also, this generalized framework\nmay assist in explaining several unresolved questions in electromagnetism as\nwell as to be able to describe quasi magnetic monopoles found in spin-ice\nsystems.",
    "published": "2016-11-01T01:46:43Z",
    "pdf_url": "http://arxiv.org/pdf/1611.02564v1",
    "categories": [
      "physics.gen-ph",
      "J.2"
    ]
  },
  {
    "arxiv_id": "1905.04116v1",
    "title": "Holomorphic fractional Fourier transforms",
    "authors": [
      "William D. Kirwin",
      "José Mourão",
      "João P. Nunes",
      "Thomas Thiemann"
    ],
    "abstract": "The Fractional Fourier Transform (FrFT) has widespread applications in areas\nlike signal analysis, Fourier optics, diffraction theory, etc. The Holomorphic\nFractional Fourier Transform (HFrFT) proposed in the present paper may be used\nin the same wide range of applications with improved properties. The HFrFT of\nsignals spans a one-parameter family of (essentially) holomorphic functions,\nwhere the parameter takes values in the bounded interval $t\\in (0,\\pi/2)$. At\nthe boundary values of the parameter, one obtains the original signal at $t=0$\nand its Fourier transform at the other end of the interval $t=\\pi/2$. If the\ninitial signal is $L^2 $, then, for an appropriate choice of inner product that\nwill be detailed below, the transform is unitary for all values of the\nparameter in the interval. This transform provides a heat kernel smoothening of\nthe signals while preserving unitarity for $L^2$-signals and continuously\ninterpolating between the original signal and its Fourier transform.",
    "published": "2019-05-10T12:35:12Z",
    "pdf_url": "http://arxiv.org/pdf/1905.04116v1",
    "categories": [
      "math-ph",
      "eess.SP",
      "math.MP"
    ]
  },
  {
    "arxiv_id": "1905.08494v2",
    "title": "Deep Signature Transforms",
    "authors": [
      "Patric Bonnier",
      "Patrick Kidger",
      "Imanol Perez Arribas",
      "Cristopher Salvi",
      "Terry Lyons"
    ],
    "abstract": "The signature is an infinite graded sequence of statistics known to\ncharacterise a stream of data up to a negligible equivalence class. It is a\ntransform which has previously been treated as a fixed feature transformation,\non top of which a model may be built. We propose a novel approach which\ncombines the advantages of the signature transform with modern deep learning\nframeworks. By learning an augmentation of the stream prior to the signature\ntransform, the terms of the signature may be selected in a data-dependent way.\nMore generally, we describe how the signature transform may be used as a layer\nanywhere within a neural network. In this context it may be interpreted as a\npooling operation. We present the results of empirical experiments to back up\nthe theoretical justification. Code available at\nhttps://github.com/patrick-kidger/Deep-Signature-Transforms.",
    "published": "2019-05-21T08:39:55Z",
    "pdf_url": "http://arxiv.org/pdf/1905.08494v2",
    "categories": [
      "cs.LG",
      "stat.ML",
      "68T01"
    ]
  },
  {
    "arxiv_id": "2004.03637v2",
    "title": "Probabilistic Spatial Transformer Networks",
    "authors": [
      "Pola Schwöbel",
      "Frederik Warburg",
      "Martin Jørgensen",
      "Kristoffer H. Madsen",
      "Søren Hauberg"
    ],
    "abstract": "Spatial Transformer Networks (STNs) estimate image transformations that can\nimprove downstream tasks by `zooming in' on relevant regions in an image.\nHowever, STNs are hard to train and sensitive to mis-predictions of\ntransformations. To circumvent these limitations, we propose a probabilistic\nextension that estimates a stochastic transformation rather than a\ndeterministic one. Marginalizing transformations allows us to consider each\nimage at multiple poses, which makes the localization task easier and the\ntraining more robust. As an additional benefit, the stochastic transformations\nact as a localized, learned data augmentation that improves the downstream\ntasks. We show across standard imaging benchmarks and on a challenging\nreal-world dataset that these two properties lead to improved classification\nperformance, robustness and model calibration. We further demonstrate that the\napproach generalizes to non-visual domains by improving model performance on\ntime-series data.",
    "published": "2020-04-07T18:22:02Z",
    "pdf_url": "http://arxiv.org/pdf/2004.03637v2",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1802.05834v2",
    "title": "On discrete Wigner transforms",
    "authors": [
      "Zhenning Cai",
      "Jianfeng Lu",
      "Kevin Stubbs"
    ],
    "abstract": "In this work, we derive a discrete analog of the Wigner transform over the\nspace $(\\mathbb{C}^p)^{\\otimes N}$ for any prime $p$ and any positive integer\n$N$. We show that the Wigner transform over this space can be constructed as\nthe inverse Fourier transform of the standard Pauli matrices for $p=2$ or more\ngenerally of the Heisenberg-Weyl group elements for $p > 2$. We connect our\nwork to a previous construction by Wootters of a discrete Wigner transform by\nshowing that for all $p$, Wootters' construction corresponds to taking the\ninverse symplectic Fourier transform instead of the inverse Fourier transform.\nFinally, we discuss some implications of these results for the numerical\nsimulation of many-body quantum spin systems.",
    "published": "2018-02-16T04:38:02Z",
    "pdf_url": "http://arxiv.org/pdf/1802.05834v2",
    "categories": [
      "math-ph",
      "math.MP"
    ]
  },
  {
    "arxiv_id": "1610.09152v2",
    "title": "Steerable Discrete Cosine Transform",
    "authors": [
      "Giulia Fracastoro",
      "Sophie Marie Fosson",
      "Enrico Magli"
    ],
    "abstract": "In image compression, classical block-based separable transforms tend to be\ninefficient when image blocks contain arbitrarily shaped discontinuities. For\nthis reason, transforms incorporating directional information are an appealing\nalternative. In this paper, we propose a new approach to this problem, namely a\ndiscrete cosine transform (DCT) that can be steered in any chosen direction.\nSuch transform, called steerable DCT (SDCT), allows to rotate in a flexible way\npairs of basis vectors, and enables precise matching of directionality in each\nimage block, achieving improved coding efficiency. The optimal rotation angles\nfor SDCT can be represented as solution of a suitable rate-distortion (RD)\nproblem. We propose iterative methods to search such solution, and we develop a\nfully fledged image encoder to practically compare our techniques with other\ncompeting transforms. Analytical and numerical results prove that SDCT\noutperforms both DCT and state-of-the-art directional transforms.",
    "published": "2016-10-28T10:09:12Z",
    "pdf_url": "http://arxiv.org/pdf/1610.09152v2",
    "categories": [
      "cs.IT",
      "cs.MM",
      "math.IT",
      "math.OC"
    ]
  },
  {
    "arxiv_id": "2008.02934v1",
    "title": "Transformational Verification of Quicksort",
    "authors": [
      "Emanuele De Angelis",
      "Fabio Fioravanti",
      "Maurizio Proietti"
    ],
    "abstract": "Many transformation techniques developed for constraint logic programs, also\nknown as constrained Horn clauses (CHCs), have found new useful applications in\nthe field of program verification. In this paper, we work out a nontrivial case\nstudy through the transformation-based verification approach. We consider the\nfamiliar Quicksort program for sorting lists, written in a functional\nprogramming language, and we verify the pre/-postconditions that specify the\nintended correctness properties of the functions defined in the program. We\nverify these properties by: (1) translating them into CHCs, (2) transforming\nthe CHCs by removing all list occurrences, and (3) checking the satisfiability\nof the transformed CHCs by using the Eldarica solver over booleans and\nintegers. The transformation mentioned at Point (2) requires an extension of\nthe algorithms for the elimination of inductively defined data structures\npresented in previous work, because during one stage of the transformation we\nuse as lemmas some properties that have been proved at previous stages.",
    "published": "2020-08-07T01:23:40Z",
    "pdf_url": "http://arxiv.org/pdf/2008.02934v1",
    "categories": [
      "cs.LO",
      "cs.PL"
    ]
  },
  {
    "arxiv_id": "2111.11067v2",
    "title": "Semi-Supervised Vision Transformers",
    "authors": [
      "Zejia Weng",
      "Xitong Yang",
      "Ang Li",
      "Zuxuan Wu",
      "Yu-Gang Jiang"
    ],
    "abstract": "We study the training of Vision Transformers for semi-supervised image\nclassification. Transformers have recently demonstrated impressive performance\non a multitude of supervised learning tasks. Surprisingly, we show Vision\nTransformers perform significantly worse than Convolutional Neural Networks\nwhen only a small set of labeled data is available. Inspired by this\nobservation, we introduce a joint semi-supervised learning framework,\nSemiformer, which contains a transformer stream, a convolutional stream and a\ncarefully designed fusion module for knowledge sharing between these streams.\nThe convolutional stream is trained on limited labeled data and further used to\ngenerate pseudo labels to supervise the training of the transformer stream on\nunlabeled data. Extensive experiments on ImageNet demonstrate that Semiformer\nachieves 75.5% top-1 accuracy, outperforming the state-of-the-art by a clear\nmargin. In addition, we show, among other things, Semiformer is a general\nframework that is compatible with most modern transformer and convolutional\nneural architectures. Code is available at\nhttps://github.com/wengzejia1/Semiformer.",
    "published": "2021-11-22T09:28:13Z",
    "pdf_url": "http://arxiv.org/pdf/2111.11067v2",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2201.05706v2",
    "title": "Perspective Transformation Layer",
    "authors": [
      "Nishan Khatri",
      "Agnibh Dasgupta",
      "Yucong Shen",
      "Xin Zhong",
      "Frank Y. Shih"
    ],
    "abstract": "Incorporating geometric transformations that reflect the relative position\nchanges between an observer and an object into computer vision and deep\nlearning models has attracted much attention in recent years. However, the\nexisting proposals mainly focus on the affine transformation that is\ninsufficient to reflect such geometric position changes. Furthermore, current\nsolutions often apply a neural network module to learn a single transformation\nmatrix, which not only ignores the importance of multi-view analysis but also\nincludes extra training parameters from the module apart from the\ntransformation matrix parameters that increase the model complexity. In this\npaper, a perspective transformation layer is proposed in the context of deep\nlearning. The proposed layer can learn homography, therefore reflecting the\ngeometric positions between observers and objects. In addition, by directly\ntraining its transformation matrices, a single proposed layer can learn an\nadjustable number of multiple viewpoints without considering module parameters.\nThe experiments and evaluations confirm the superiority of the proposed layer.",
    "published": "2022-01-14T23:09:26Z",
    "pdf_url": "http://arxiv.org/pdf/2201.05706v2",
    "categories": [
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2302.04869v1",
    "title": "Reversible Vision Transformers",
    "authors": [
      "Karttikeya Mangalam",
      "Haoqi Fan",
      "Yanghao Li",
      "Chao-Yuan Wu",
      "Bo Xiong",
      "Christoph Feichtenhofer",
      "Jitendra Malik"
    ],
    "abstract": "We present Reversible Vision Transformers, a memory efficient architecture\ndesign for visual recognition. By decoupling the GPU memory requirement from\nthe depth of the model, Reversible Vision Transformers enable scaling up\narchitectures with efficient memory usage. We adapt two popular models, namely\nVision Transformer and Multiscale Vision Transformers, to reversible variants\nand benchmark extensively across both model sizes and tasks of image\nclassification, object detection and video classification. Reversible Vision\nTransformers achieve a reduced memory footprint of up to 15.5x at roughly\nidentical model complexity, parameters and accuracy, demonstrating the promise\nof reversible vision transformers as an efficient backbone for hardware\nresource limited training regimes. Finally, we find that the additional\ncomputational burden of recomputing activations is more than overcome for\ndeeper models, where throughput can increase up to 2.3x over their\nnon-reversible counterparts. Full code and trained models are available at\nhttps://github.com/facebookresearch/slowfast. A simpler, easy to understand and\nmodify version is also available at https://github.com/karttikeya/minREV",
    "published": "2023-02-09T18:59:54Z",
    "pdf_url": "http://arxiv.org/pdf/2302.04869v1",
    "categories": [
      "cs.CV",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2304.10557v5",
    "title": "An Introduction to Transformers",
    "authors": [
      "Richard E. Turner"
    ],
    "abstract": "The transformer is a neural network component that can be used to learn\nuseful representations of sequences or sets of data-points. The transformer has\ndriven recent advances in natural language processing, computer vision, and\nspatio-temporal modelling. There are many introductions to transformers, but\nmost do not contain precise mathematical descriptions of the architecture and\nthe intuitions behind the design choices are often also missing. Moreover, as\nresearch takes a winding path, the explanations for the components of the\ntransformer can be idiosyncratic. In this note we aim for a mathematically\nprecise, intuitive, and clean description of the transformer architecture. We\nwill not discuss training as this is rather standard. We assume that the reader\nis familiar with fundamental topics in machine learning including multi-layer\nperceptrons, linear transformations, softmax functions and basic probability.",
    "published": "2023-04-20T14:54:19Z",
    "pdf_url": "http://arxiv.org/pdf/2304.10557v5",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2306.09539v4",
    "title": "Block-State Transformers",
    "authors": [
      "Mahan Fathi",
      "Jonathan Pilault",
      "Orhan Firat",
      "Christopher Pal",
      "Pierre-Luc Bacon",
      "Ross Goroshin"
    ],
    "abstract": "State space models (SSMs) have shown impressive results on tasks that require\nmodeling long-range dependencies and efficiently scale to long sequences owing\nto their subquadratic runtime complexity. Originally designed for continuous\nsignals, SSMs have shown superior performance on a plethora of tasks, in vision\nand audio; however, SSMs still lag Transformer performance in Language Modeling\ntasks. In this work, we propose a hybrid layer named Block-State Transformer\n(BST), that internally combines an SSM sublayer for long-range\ncontextualization, and a Block Transformer sublayer for short-term\nrepresentation of sequences. We study three different, and completely\nparallelizable, variants that integrate SSMs and block-wise attention. We show\nthat our model outperforms similar Transformer-based architectures on language\nmodeling perplexity and generalizes to longer sequences. In addition, the\nBlock-State Transformer demonstrates more than tenfold increase in speed at the\nlayer level compared to the Block-Recurrent Transformer when model\nparallelization is employed.",
    "published": "2023-06-15T22:48:08Z",
    "pdf_url": "http://arxiv.org/pdf/2306.09539v4",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1605.08683v1",
    "title": "The Fourier and Hilbert transforms under the Bargmann transform",
    "authors": [
      "Xing-Tang Dong",
      "Kehe Zhu"
    ],
    "abstract": "There is a canonical unitary transformation from $L^2(\\R)$ onto the Fock\nspace $F^2$, called the Bargmann transform. We study the action of the Bargmann\ntransform on several classical integral operators on $L^2(\\R)$, including the\nfractional Fourier transform, the fractional Hilbert transform, and the wavelet\ntransform.",
    "published": "2016-05-27T15:23:27Z",
    "pdf_url": "http://arxiv.org/pdf/1605.08683v1",
    "categories": [
      "math.CV",
      "math.FA"
    ]
  },
  {
    "arxiv_id": "9503416v1",
    "title": "The Foldy-Wouthuysen transformation",
    "authors": [
      "John P. Costella",
      "Bruce H. J. McKellar"
    ],
    "abstract": "The Foldy-Wouthuysen transformation of the Dirac Hamiltonian is generally\ntaught as simply a mathematical trick that allows one to obtain a two-component\ntheory in the low-energy limit. It is not often emphasized that the transformed\nrepresentation is the only one in which one can take a meaningful *classical\nlimit*, in terms of particles and antiparticles. We briefly review the history\nand physics of this transformation.",
    "published": "1995-03-23T00:03:04Z",
    "pdf_url": "http://arxiv.org/pdf/hep-ph/9503416v1",
    "categories": [
      "hep-ph"
    ]
  },
  {
    "arxiv_id": "0002133v2",
    "title": "Ramond-Ramond Field Transformation",
    "authors": [
      "Yungui Gong"
    ],
    "abstract": "We find that the mixture of Ramond-Ramond fields and Neveu-Schwarz two form\nare transformed as Majorana spinors under the T-duality group $O(d,d)$. The\nRamond-Ramond field transformation under the group $O(d,d)$ is realized in a\nsimple form by using the spinor representation. The Ramond-Ramond field\ntransformation rule obtained by Bergshoeff et al. is shown as a specific simple\nexample. We also give some explicit examples of the spinor representation.",
    "published": "2000-02-16T20:48:30Z",
    "pdf_url": "http://arxiv.org/pdf/hep-th/0002133v2",
    "categories": [
      "hep-th"
    ]
  },
  {
    "arxiv_id": "0212105v1",
    "title": "Henstock--Kurzweil Fourier transforms",
    "authors": [
      "Erik Talvila"
    ],
    "abstract": "The Fourier transform is considered as a Henstock--Kurzweil integral.\nSufficient conditions are given for the existence of the Fourier transform and\nnecessary and sufficient conditions are given for it to be continuous. The\nRiemann--Lebesgue lemma fails: Henstock--Kurzweil Fourier transforms can have\narbitrarily large point-wise growth. Convolution and inversion theorems are\nestablished. An appendix gives sufficient conditions for interchanging repeated\nHenstock--Kurzweil integrals and gives an estimate on the integral of a\nproduct.",
    "published": "2002-12-07T00:53:27Z",
    "pdf_url": "http://arxiv.org/pdf/math/0212105v1",
    "categories": [
      "math.CA",
      "42A38, 26A39"
    ]
  },
  {
    "arxiv_id": "0507099v1",
    "title": "Relativistic force transformation",
    "authors": [
      "Valery P. Dmitriyev"
    ],
    "abstract": "Formulae relating one and the same force in two inertial frames of reference\nare derived directly from the Lorentz transformation of space and time\ncoordinates and relativistic equation for the dynamic law of motion in three\ndimensions. We obtain firstly relativistic transformation for the velocity and\nacceleration of a particle. Then we substitute them in the relativistic dynamic\nequation and perform tedious algebraic manipulations. No recourse were made to\n\"general rules for the transformation of 4-tensors\". Formulae obtained were\nverified in electrodynamics.",
    "published": "2005-07-13T04:37:18Z",
    "pdf_url": "http://arxiv.org/pdf/physics/0507099v1",
    "categories": [
      "physics.ed-ph"
    ]
  },
  {
    "arxiv_id": "1112.3639v1",
    "title": "The Run Transform",
    "authors": [
      "David Callan",
      "Emeric Deutsch"
    ],
    "abstract": "We consider the transform from sequences to triangular arrays defined in\nterms of generating functions by f(x) -> (1-x)/(1-xy) f(x(1-x)/(1-xy)). We\nestablish a criterion for the transform of a nonnegative sequence to be\nnonnegative, and we show that the transform counts certain classes of lattice\npaths by number of \"pyramid ascents\", as well as certain classes of ordered\npartitions by number of blocks that consist of increasing consecutive integers.",
    "published": "2011-12-15T20:29:01Z",
    "pdf_url": "http://arxiv.org/pdf/1112.3639v1",
    "categories": [
      "math.CO",
      "05A15"
    ]
  },
  {
    "arxiv_id": "1212.0957v1",
    "title": "Generalized Stirling transform",
    "authors": [
      "Mourad Rahmani"
    ],
    "abstract": "In this paper, algorithms are developed for computing the Stirling transform\nand the inverse Stirling transform; specifically, we investigate a class of\nsequences satisfying a two-term recurrence. We derive a general identity which\ngeneralizes the usual Stirling transform and investigate the corresponding\ngenerating functions also. In addition, some interesting consequences of these\nresults related to classical sequences like Fibonacci, Bernoulli and the\nnumbers of derangements have been derived.",
    "published": "2012-12-05T08:06:28Z",
    "pdf_url": "http://arxiv.org/pdf/1212.0957v1",
    "categories": [
      "math.CO",
      "math.NT",
      "05A19, 11B68"
    ]
  },
  {
    "arxiv_id": "1705.07401v2",
    "title": "Transformations of partial matchings",
    "authors": [
      "Inasa Nakamura"
    ],
    "abstract": "We consider partial matchings, which are finite graphs consisting of edges\nand vertices of degree zero or one. We consider transformations between two\nstates of partial matchings. We introduce a method of presenting a\ntransformation between partial matchings. We introduce the notion of the\nlattice presentation of a partial matching, and the lattice polytope associated\nwith a pair of lattice presentations, and we investigate transformations with\nminimal area.",
    "published": "2017-05-21T06:08:39Z",
    "pdf_url": "http://arxiv.org/pdf/1705.07401v2",
    "categories": [
      "math.GT"
    ]
  },
  {
    "arxiv_id": "2305.01857v1",
    "title": "Toward Textual Transform Coding",
    "authors": [
      "Tsachy Weissman"
    ],
    "abstract": "Inspired by recent work on compression with and for young humans, the success\nof transform-based approaches to information processing, and the rise of\npowerful language-based AI, we propose \\emph{textual transform coding}. It\nshares some of its key properties with traditional transform-based coding\nunderlying much of our current multimedia compression technologies. It can form\nthe basis for compression at bit rates until recently considered uselessly low,\nand for boosting human satisfaction from reconstructions at more traditional\nbit rates.",
    "published": "2023-05-03T01:59:49Z",
    "pdf_url": "http://arxiv.org/pdf/2305.01857v1",
    "categories": [
      "cs.IT",
      "math.IT"
    ]
  },
  {
    "arxiv_id": "1401.0821v1",
    "title": "Intuitionistic Fuzzy Linear Transformations",
    "authors": [
      "Rajkumar Pradhan",
      "Madhumangal Pal"
    ],
    "abstract": "In this paper, we discussed about the intuitionistic fuzzy linear\ntransformations (IFLT) and shown that the set of all linear transformations\nL(V) defined over an intuitionistic fuzzy vector space V does not form an\nvector space. Here we determine the unique intuitionistic fuzzy matrix\nassociated with an intuitionistic fuzzy linear transformation with respect to\nan ordered standard basis for an intuitionistic fuzzy vector space. We\nintroduced the concept of the inverse of an IFLT.",
    "published": "2014-01-04T15:41:27Z",
    "pdf_url": "http://arxiv.org/pdf/1401.0821v1",
    "categories": [
      "cs.DM",
      "08A72, 15B15"
    ]
  },
  {
    "arxiv_id": "2111.13921v1",
    "title": "Transformed K-means Clustering",
    "authors": [
      "Anurag Goel",
      "Angshul Majumdar"
    ],
    "abstract": "In this work we propose a clustering framework based on the paradigm of\ntransform learning. In simple terms the representation from transform learning\nis used for K-means clustering; however, the problem is not solved in such a\nna\\\"ive piecemeal fashion. The K-means clustering loss is embedded into the\ntransform learning framework and the joint problem is solved using the\nalternating direction method of multipliers. Results on document clustering\nshow that our proposed approach improves over the state-of-the-art.",
    "published": "2021-11-27T15:28:37Z",
    "pdf_url": "http://arxiv.org/pdf/2111.13921v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2307.02649v1",
    "title": "Periodic discrete Darboux transforms",
    "authors": [
      "Joseph Cho",
      "Katrin Leschke",
      "Yuta Ogata"
    ],
    "abstract": "We express Darboux transformations of discrete polarised curves as parallel\nsections of discrete connections in the quaternionic formalism. This\nimmediately leads to the linearisation of the monodromy of the transformation.\nWe also consider the integrable reduction to the case of discrete bicycle\ncorrespondence. Applying our method to the case of discrete circles, we obtain\nclosed-form discrete parametrisations of all (closed) Darboux transforms and\n(closed) bicycle correspondences.",
    "published": "2023-07-05T20:47:23Z",
    "pdf_url": "http://arxiv.org/pdf/2307.02649v1",
    "categories": [
      "math.DG",
      "(2020): 53A70 (Primary) 58J72 (Secondary)"
    ]
  },
  {
    "arxiv_id": "2503.10462v1",
    "title": "Convolutional transformer wave functions",
    "authors": [
      "Ao Chen",
      "Vighnesh Dattatraya Naik",
      "Markus Heyl"
    ],
    "abstract": "Deep neural quantum states have recently achieved remarkable performance in\nsolving challenging quantum many-body problems. While transformer networks\nappear particularly promising due to their success in computer science, we show\nthat previously reported transformer wave functions haven't so far been capable\nto utilize their full power. Here, we introduce the convolutional transformer\nwave function (CTWF). We show that our CTWFs exhibit superior performance in\nground-state search and non-equilibrium dynamics compared to previous results,\ndemonstrating promising capacity in complex quantum problems.",
    "published": "2025-03-13T15:32:21Z",
    "pdf_url": "http://arxiv.org/pdf/2503.10462v1",
    "categories": [
      "cond-mat.dis-nn",
      "quant-ph"
    ]
  },
  {
    "arxiv_id": "0907.1975v2",
    "title": "On semifast Fourier transform algorithms",
    "authors": [
      "Sergei V. Fedorenko"
    ],
    "abstract": "We consider the relations between well-known Fourier transform algorithms.",
    "published": "2009-07-11T17:13:50Z",
    "pdf_url": "http://arxiv.org/pdf/0907.1975v2",
    "categories": [
      "cs.IT",
      "math.IT"
    ]
  },
  {
    "arxiv_id": "9603004v1",
    "title": "Transformation de Fourier generalisee",
    "authors": [
      "Gerard Laumon"
    ],
    "abstract": "In this paper I construct a geometric transformation for generalized\n1-motives which extends the Fourier-Mukai transformation for O-Modules on\nabelian varieties, the geometric Fourier transformation for D-Modules on vector\nspaces and the geometric Mellin transformation for D-Modules on tori. In\nparticular, I construct an equivalence of triangulated categories between the\nderived category of quasi-coherent D-Modules on an abelian variety and the\nderived category of quasi-coherent O-Modules on the universal extension of the\ndual abelian variety. This equivalence has also been obtained by Mitchell\nRothstein.",
    "published": "1996-03-05T12:45:12Z",
    "pdf_url": "http://arxiv.org/pdf/alg-geom/9603004v1",
    "categories": [
      "alg-geom",
      "math.AG",
      "14F05 (Primary) 14K05 (Secondary)"
    ]
  },
  {
    "arxiv_id": "9705001v1",
    "title": "Generalized Fourier-Mukai Transforms",
    "authors": [
      "Antony Maciocia"
    ],
    "abstract": "The paper sets out a generalized framework for Fourier-Mukai transforms and\nillustrates their use via vector bundle transforms. A Fourier-Mukai transform\nis, roughly, an isomorphism of derived categories of (sheaves) on smooth\nvarieties X and Y. We show that these can only exist if the first Chern class\nof the varieties vanishes and, in the case of vector bundle transforms, will\nexist if and only if there is a bi-universal bundle on XxY which is \"strongly\nsimple\" in a suitable sense. Some applications are given to abelian varieties\nextending the work of Mukai.",
    "published": "1997-05-01T15:31:54Z",
    "pdf_url": "http://arxiv.org/pdf/alg-geom/9705001v1",
    "categories": [
      "alg-geom",
      "math.AG"
    ]
  },
  {
    "arxiv_id": "9612007v1",
    "title": "Twisted Legendre transformation",
    "authors": [
      "S. Zakrzewski"
    ],
    "abstract": "The general framework of Legendre transformation is extended to the case of\nsymplectic groupoids, using an appropriate generalization of the notion of\ngenerating function (of a Lagrangian submanifold).",
    "published": "1996-12-04T12:38:07Z",
    "pdf_url": "http://arxiv.org/pdf/dg-ga/9612007v1",
    "categories": [
      "dg-ga",
      "math.DG",
      "58F05 (Primary) 22A22, 58H05, 53Z05 (Secondary)"
    ]
  },
  {
    "arxiv_id": "0412087v1",
    "title": "A New Integral Transform",
    "authors": [
      "B. G. Sidharth"
    ],
    "abstract": "Using Bauer's expansion and properties of spherical Bessel and Legender\nfunctions, we deduce a new transform and briefly indicate its use.",
    "published": "2004-12-04T16:20:22Z",
    "pdf_url": "http://arxiv.org/pdf/math/0412087v1",
    "categories": [
      "math.GM"
    ]
  },
  {
    "arxiv_id": "0505248v1",
    "title": "An elliptic determinant transformation",
    "authors": [
      "Hjalmar Rosengren"
    ],
    "abstract": "We prove a transformation formula relating two determinants involving\nelliptic shifted factorials. Similar determinants have been applied to multiple\nelliptic hypergeometric series.",
    "published": "2005-05-12T10:01:07Z",
    "pdf_url": "http://arxiv.org/pdf/math/0505248v1",
    "categories": [
      "math.CA",
      "15A15; 33D67; 33E05"
    ]
  },
  {
    "arxiv_id": "0702107v1",
    "title": "The Quantum Mellin transform",
    "authors": [
      "J. Twamley",
      "G. J. Milburn"
    ],
    "abstract": "We uncover a new type of unitary operation for quantum mechanics on the\nhalf-line which yields a transformation to ``Hyperbolic phase space''. We show\nthat this new unitary change of basis from the position x on the half line to\nthe Hyperbolic momentum $p_\\eta$, transforms the wavefunction via a Mellin\ntransform on to the critial line $s=1/2-ip_\\eta$. We utilise this new transform\nto find quantum wavefunctions whose Hyperbolic momentum representation\napproximate a class of higher transcendental functions, and in particular,\napproximate the Riemann Zeta function. We finally give possible physical\nrealisations to perform an indirect measurement of the Hyperbolic momentum of a\nquantum system on the half-line.",
    "published": "2007-02-12T11:42:37Z",
    "pdf_url": "http://arxiv.org/pdf/quant-ph/0702107v1",
    "categories": [
      "quant-ph"
    ]
  },
  {
    "arxiv_id": "0708.1328v1",
    "title": "Limited scope adic transformations",
    "authors": [
      "Sarah Bailey Frick"
    ],
    "abstract": "We introduce a family of adic transformations on diagrams that are\nnonstationary and nonsimple. This family includes some previously studied adic\ntransformations. We relate the dimension group of each these diagrams to the\ndynamical system determined by the adic transformation on the infinite edge\npaths, and we explicitly compute the dimension group for a subfamily. We also\ndetermine the ergodic adic invariant probability measures for this subfamily,\nand show that each system of the subfamily is loosely Bernoulli. We also give\nexamples of particular adic transformations with roots of unity as well as one\nwhich is totally ergodic called the Euler adic. We also show that the Euler\nadic is loosely Bernoulli.",
    "published": "2007-08-09T20:16:00Z",
    "pdf_url": "http://arxiv.org/pdf/0708.1328v1",
    "categories": [
      "math.DS",
      "37A05, 37A25"
    ]
  },
  {
    "arxiv_id": "1107.1695v1",
    "title": "On Krawtchouk Transforms",
    "authors": [
      "Philip Feinsilver",
      "René Schott"
    ],
    "abstract": "Krawtchouk polynomials appear in a variety of contexts, most notably as\northogonal polynomials and in coding theory via the Krawtchouk transform. We\npresent an operator calculus formulation of the Krawtchouk transform that is\nsuitable for computer implementation. A positivity result for the Krawtchouk\ntransform is shown. Then our approach is compared with the use of the\nKrawtchouk transform in coding theory where it appears in MacWilliams' and\nDelsarte's theorems on weight enumerators. We conclude with a construction of\nKrawtchouk polynomials in an arbitrary finite number of variables, orthogonal\nwith respect to the multinomial distribution.",
    "published": "2011-06-24T02:34:47Z",
    "pdf_url": "http://arxiv.org/pdf/1107.1695v1",
    "categories": [
      "cs.IT",
      "math.CA",
      "math.IT",
      "Primary: 15.0, 15A69 Secondary: 05E35, 42C05"
    ]
  },
  {
    "arxiv_id": "1303.7298v1",
    "title": "Generalized ideal transforms",
    "authors": [
      "Tran Tuan Nam",
      "Nguyen minh Tri"
    ],
    "abstract": "We study basic properties of the generalized ideal transforms $D_I(M, N)$ and\nthe set of associated primes of the modules $R^iD_I(M,N).$",
    "published": "2013-03-29T05:50:34Z",
    "pdf_url": "http://arxiv.org/pdf/1303.7298v1",
    "categories": [
      "math.AC",
      "13D45"
    ]
  },
  {
    "arxiv_id": "1508.07879v3",
    "title": "Noncommutative bispectral Darboux transformations",
    "authors": [
      "Joel Geiger",
      "Emil Horozov",
      "Milen Yakimov"
    ],
    "abstract": "We prove a general theorem establishing the bispectrality of noncommutative\nDarboux transformations. It has a wide range of applications that establish\nbispectrality of such transformations for differential, difference and\nq-difference operators with values in all noncommutative algebras. All known\nbispectral Darboux transformations are special cases of the theorem. Using the\nmethods of quasideterminants and the spectral theory of matrix polynomials, we\nexplicitly classify the set of bispectral Darboux transformations from rank one\ndifferential operators and Airy operators with values in matrix algebras. These\nsets generalize the classical Calogero-Moser spaces and Wilson's adelic\nGrassmannian.",
    "published": "2015-08-31T15:47:00Z",
    "pdf_url": "http://arxiv.org/pdf/1508.07879v3",
    "categories": [
      "math.CA",
      "math.RA",
      "Primary 37K35, Secondary 16S32, 39A70"
    ]
  },
  {
    "arxiv_id": "1611.08230v2",
    "title": "Learning Fast Sparsifying Transforms",
    "authors": [
      "Cristian Rusu",
      "John Thompson"
    ],
    "abstract": "Given a dataset, the task of learning a transform that allows sparse\nrepresentations of the data bears the name of dictionary learning. In many\napplications, these learned dictionaries represent the data much better than\nthe static well-known transforms (Fourier, Hadamard etc.). The main downside of\nlearned transforms is that they lack structure and therefore they are not\ncomputationally efficient, unlike their classical counterparts. These posse\nseveral difficulties especially when using power limited hardware such as\nmobile devices, therefore discouraging the application of sparsity techniques\nin such scenarios. In this paper we construct orthogonal and non-orthogonal\ndictionaries that are factorized as a product of a few basic transformations.\nIn the orthogonal case, we solve exactly the dictionary update problem for one\nbasic transformation, which can be viewed as a generalized Givens rotation, and\nthen propose to construct orthogonal dictionaries that are a product of these\ntransformations, guaranteeing their fast manipulation. We also propose a method\nto construct fast square but non-orthogonal dictionaries that are factorized as\na product of few transforms that can be viewed as a further generalization of\nGivens rotations to the non-orthogonal setting. We show how the proposed\ntransforms can balance very well data representation performance and\ncomputational complexity. We also compare with classical fast and learned\ngeneral and orthogonal transforms.",
    "published": "2016-11-24T15:57:09Z",
    "pdf_url": "http://arxiv.org/pdf/1611.08230v2",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1905.13475v1",
    "title": "Tetrahedron trinomial coefficient transform",
    "authors": [
      "László Németh"
    ],
    "abstract": "We introduce the tetrahedron trinomial coefficient transform which takes a\nPascal-like arithmetical triangle to a sequence. We define a Pascal-like\ninfinite tetrahedron H, and prove that the application of the tetrahedron\ntrinomial transform to one face T of H provides the opposite edge E to T in H.\nIt follows from the construction that the other directions in H parallel to E\ncan be obtained similarly. In case of Pascal's triangle the sequence generated\nby the trinomial transform coincides the binomial transform of the central\nbinomial coefficients.",
    "published": "2019-05-31T09:14:41Z",
    "pdf_url": "http://arxiv.org/pdf/1905.13475v1",
    "categories": [
      "math.CO",
      "math.NT",
      "11B65, 11B75, 05A10"
    ]
  },
  {
    "arxiv_id": "2108.02975v1",
    "title": "Biquaternion Z Transform",
    "authors": [
      "Wenshan Bi",
      "Zhen-Feng Cai",
      "Kit Ian Kou"
    ],
    "abstract": "In this work, the biquaternion Z transformation method is proposed to solve a\nclass of biquaternion recurrence relations. Biqueternion Z transform is an\nnatural extension of the complex Z transform. In the design process, special\nnorm presentation is employed to analyze the region of convergence of the\nbiquaternion geometry sequence. In addition, some useful properties have been\ngiven. It is shown that the proposed properties is helpful to understand the\nbiquaternion Z transform. Finally, several examples have been given to\nillustrate the effectiveness of the proposed design method.",
    "published": "2021-08-06T07:00:34Z",
    "pdf_url": "http://arxiv.org/pdf/2108.02975v1",
    "categories": [
      "math.CA",
      "math.CV"
    ]
  },
  {
    "arxiv_id": "1511.08071v2",
    "title": "Catalytic coherence transformations",
    "authors": [
      "Kaifeng Bu",
      "Uttam Singh",
      "Junde Wu"
    ],
    "abstract": "Catalytic coherence transformations allow the otherwise impossible state\ntransformations using only incoherent operations with the aid of an auxiliary\nsystem with finite coherence which is not being consumed in anyway. Here we\nfind the necessary and sufficient conditions for the deterministic and\nstochastic catalytic coherence transformations between pair of pure quantum\nstates. In particular, we show that the simultaneous decrease of a family of\nR\\'enyi entropies of the diagonal parts of the states under consideration are\nnecessary and sufficient conditions for the deterministic catalytic coherence\ntransformations. Similarly, for stochastic catalytic coherence transformations\nwe find the necessary and sufficient conditions for achieving higher optimal\nprobability of conversion. We, thus, completely characterize the coherence\ntransformations amongst pure quantum states under incoherent operations. We\ngive numerous examples to elaborate our results. We also explore the\npossibility of the same system acting as a catalyst for itself and find that\nindeed {\\it self catalysis} is possible. Further, for the cases where no\ncatalytic coherence transformation is possible we provide entanglement assisted\ncoherence transformations and find the necessary and sufficient conditions for\nsuch transformations.",
    "published": "2015-11-25T14:20:52Z",
    "pdf_url": "http://arxiv.org/pdf/1511.08071v2",
    "categories": [
      "quant-ph"
    ]
  },
  {
    "arxiv_id": "2002.02337v1",
    "title": "The Generalized Crofoot Transform",
    "authors": [
      "Rewayat Khan"
    ],
    "abstract": "We introduce a generalized Crofoot transform between the model spaces\ncorresponding to matrix-valued inner functions. As an application, we obtain\nresults about matrix-valued truncated Toeplitz operators.",
    "published": "2020-01-23T17:50:19Z",
    "pdf_url": "http://arxiv.org/pdf/2002.02337v1",
    "categories": [
      "math.FA",
      "math.OA",
      "47B35, 47A45, 47B32, 30J05"
    ]
  },
  {
    "arxiv_id": "2305.18487v1",
    "title": "Solar Irradiance Anticipative Transformer",
    "authors": [
      "Thomas M. Mercier",
      "Tasmiat Rahman",
      "Amin Sabet"
    ],
    "abstract": "This paper proposes an anticipative transformer-based model for short-term\nsolar irradiance forecasting. Given a sequence of sky images, our proposed\nvision transformer encodes features of consecutive images, feeding into a\ntransformer decoder to predict irradiance values associated with future unseen\nsky images. We show that our model effectively learns to attend only to\nrelevant features in images in order to forecast irradiance. Moreover, the\nproposed anticipative transformer captures long-range dependencies between sky\nimages to achieve a forecasting skill of 21.45 % on a 15 minute ahead\nprediction for a newly introduced dataset of all-sky images when compared to a\nsmart persistence model.",
    "published": "2023-05-29T12:38:12Z",
    "pdf_url": "http://arxiv.org/pdf/2305.18487v1",
    "categories": [
      "cs.CV",
      "cs.LG",
      "physics.ao-ph"
    ]
  },
  {
    "arxiv_id": "1806.08887v2",
    "title": "The Sparse Manifold Transform",
    "authors": [
      "Yubei Chen",
      "Dylan M. Paiton",
      "Bruno A. Olshausen"
    ],
    "abstract": "We present a signal representation framework called the sparse manifold\ntransform that combines key ideas from sparse coding, manifold learning, and\nslow feature analysis. It turns non-linear transformations in the primary\nsensory signal space into linear interpolations in a representational embedding\nspace while maintaining approximate invertibility. The sparse manifold\ntransform is an unsupervised and generative framework that explicitly and\nsimultaneously models the sparse discreteness and low-dimensional manifold\nstructure found in natural scenes. When stacked, it also models hierarchical\ncomposition. We provide a theoretical description of the transform and\ndemonstrate properties of the learned representation on both synthetic data and\nnatural videos.",
    "published": "2018-06-23T01:44:50Z",
    "pdf_url": "http://arxiv.org/pdf/1806.08887v2",
    "categories": [
      "stat.ML",
      "cs.LG",
      "eess.IV"
    ]
  },
  {
    "arxiv_id": "2105.00493v2",
    "title": "Synthesizing Abstract Transformers",
    "authors": [
      "Pankaj Kumar Kalita",
      "Sujit Kumar Muduli",
      "Loris D'Antoni",
      "Thomas Reps",
      "Subhajit Roy"
    ],
    "abstract": "This paper addresses the problem of creating abstract transformers\nautomatically. The method we present automates the construction of static\nanalyzers in a fashion similar to the way $\\textit{yacc}$ automates the\nconstruction of parsers. Our method treats the problem as a program-synthesis\nproblem. The user provides specifications of (i) the concrete semantics of a\ngiven operation $\\textit{op}$, (ii) the abstract domain A to be used by the\nanalyzer, and (iii) the semantics of a domain-specific language $L$ in which\nthe abstract transformer is to be expressed. As output, our method creates an\nabstract transformer for $\\textit{op}$ in abstract domain A, expressed in $L$\n(an \"$L$-transformer for $\\textit{op}$ over A\"). Moreover, the abstract\ntransformer obtained is a most-precise $L$-transformer for $\\textit{op}$ over\nA; that is, there is no other $L$-transformer for $\\textit{op}$ over A that is\nstrictly more precise.\n  We implemented our method in a tool called AMURTH. We used AMURTH to create\nsets of replacement abstract transformers for those used in two existing\nanalyzers, and obtained essentially identical performance. However, when we\ncompared the existing transformers with the transformers obtained using AMURTH,\nwe discovered that four of the existing transformers were unsound, which\ndemonstrates the risk of using manually created transformers.",
    "published": "2021-05-02T15:09:41Z",
    "pdf_url": "http://arxiv.org/pdf/2105.00493v2",
    "categories": [
      "cs.PL"
    ]
  },
  {
    "arxiv_id": "2106.04554v2",
    "title": "A Survey of Transformers",
    "authors": [
      "Tianyang Lin",
      "Yuxin Wang",
      "Xiangyang Liu",
      "Xipeng Qiu"
    ],
    "abstract": "Transformers have achieved great success in many artificial intelligence\nfields, such as natural language processing, computer vision, and audio\nprocessing. Therefore, it is natural to attract lots of interest from academic\nand industry researchers. Up to the present, a great variety of Transformer\nvariants (a.k.a. X-formers) have been proposed, however, a systematic and\ncomprehensive literature review on these Transformer variants is still missing.\nIn this survey, we provide a comprehensive review of various X-formers. We\nfirst briefly introduce the vanilla Transformer and then propose a new taxonomy\nof X-formers. Next, we introduce the various X-formers from three perspectives:\narchitectural modification, pre-training, and applications. Finally, we outline\nsome potential directions for future research.",
    "published": "2021-06-08T17:43:08Z",
    "pdf_url": "http://arxiv.org/pdf/2106.04554v2",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2112.04981v1",
    "title": "PE-former: Pose Estimation Transformer",
    "authors": [
      "Paschalis Panteleris",
      "Antonis Argyros"
    ],
    "abstract": "Vision transformer architectures have been demonstrated to work very\neffectively for image classification tasks. Efforts to solve more challenging\nvision tasks with transformers rely on convolutional backbones for feature\nextraction. In this paper we investigate the use of a pure transformer\narchitecture (i.e., one with no CNN backbone) for the problem of 2D body pose\nestimation. We evaluate two ViT architectures on the COCO dataset. We\ndemonstrate that using an encoder-decoder transformer architecture yields state\nof the art results on this estimation problem.",
    "published": "2021-12-09T15:20:23Z",
    "pdf_url": "http://arxiv.org/pdf/2112.04981v1",
    "categories": [
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2211.13184v1",
    "title": "TorchScale: Transformers at Scale",
    "authors": [
      "Shuming Ma",
      "Hongyu Wang",
      "Shaohan Huang",
      "Wenhui Wang",
      "Zewen Chi",
      "Li Dong",
      "Alon Benhaim",
      "Barun Patra",
      "Vishrav Chaudhary",
      "Xia Song",
      "Furu Wei"
    ],
    "abstract": "Large Transformers have achieved state-of-the-art performance across many\ntasks. Most open-source libraries on scaling Transformers focus on improving\ntraining or inference with better parallelization. In this work, we present\nTorchScale, an open-source toolkit that allows researchers and developers to\nscale up Transformers efficiently and effectively. TorchScale has the\nimplementation of several modeling techniques, which can improve modeling\ngenerality and capability, as well as training stability and efficiency.\nExperimental results on language modeling and neural machine translation\ndemonstrate that TorchScale can successfully scale Transformers to different\nsizes without tears. The library is available at https://aka.ms/torchscale.",
    "published": "2022-11-23T17:58:51Z",
    "pdf_url": "http://arxiv.org/pdf/2211.13184v1",
    "categories": [
      "cs.LG",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2212.10554v1",
    "title": "A Length-Extrapolatable Transformer",
    "authors": [
      "Yutao Sun",
      "Li Dong",
      "Barun Patra",
      "Shuming Ma",
      "Shaohan Huang",
      "Alon Benhaim",
      "Vishrav Chaudhary",
      "Xia Song",
      "Furu Wei"
    ],
    "abstract": "Position modeling plays a critical role in Transformers. In this paper, we\nfocus on length extrapolation, i.e., training on short texts while evaluating\nlonger sequences. We define attention resolution as an indicator of\nextrapolation. Then we propose two designs to improve the above metric of\nTransformers. Specifically, we introduce a relative position embedding to\nexplicitly maximize attention resolution. Moreover, we use blockwise causal\nattention during inference for better resolution. We evaluate different\nTransformer variants with language modeling. Experimental results show that our\nmodel achieves strong performance in both interpolation and extrapolation\nsettings. The code will be available at https://aka.ms/LeX-Transformer.",
    "published": "2022-12-20T18:56:20Z",
    "pdf_url": "http://arxiv.org/pdf/2212.10554v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2311.07373v2",
    "title": "Optical Darboux Transformer",
    "authors": [
      "Auro M. Perego"
    ],
    "abstract": "The Optical Darboux Transformer is introduced as a photonic device which\nperforms the Darboux transformation directly in the optical domain. This\nenables two major advances for signal processing based on the nonlinear Fourier\ntransform: (i) the multiplexing of different solitonic waveforms corresponding\nto arbitrary number of discrete eigenvalues of the Zakharov-Shabat system in\nthe optical domain, and (ii) the selective filtering of an arbitrary number of\nindividual solitons too. The Optical Darboux Transformer can be built using\nexisting commercially available photonic technology components and constitutes\na universal tool for signal processing, optical communications, optical rogue\nwaves generation, and waveform shaping and control in the nonlinear Fourier\ndomain.",
    "published": "2023-11-13T14:42:27Z",
    "pdf_url": "http://arxiv.org/pdf/2311.07373v2",
    "categories": [
      "nlin.PS",
      "physics.optics"
    ]
  },
  {
    "arxiv_id": "2311.16925v1",
    "title": "Multiallelic Walsh transforms",
    "authors": [
      "Devin Greene"
    ],
    "abstract": "A closed formula multiallelic Walsh (or Hadamard) transform is introduced.\nBasic results are derived, and a statistical interpretation of some of the\nresulting linear forms is discussed.",
    "published": "2023-11-28T16:30:58Z",
    "pdf_url": "http://arxiv.org/pdf/2311.16925v1",
    "categories": [
      "q-bio.QM",
      "q-bio.PE"
    ]
  },
  {
    "arxiv_id": "2405.06188v2",
    "title": "Multidimensional empirical wavelet transform",
    "authors": [
      "Charles-Gérard Lucas",
      "Jérôme Gilles"
    ],
    "abstract": "The empirical wavelet transform is a data-driven time-scale representation\nconsisting of an adaptive filter bank. Its robustness to data has made it the\nsubject of intense developments and an increasing number of applications in the\nlast decade. However, it has been mostly studied theoretically for signals and\nits extension to images is limited to a particular generating function. This\nwork presents a general framework for multidimensional empirical wavelet\ntransform based on any wavelet kernel. It also provides conditions to build\nwavelet frames for both continuous and discrete transforms. Moreover, numerical\nsimulations of transforms are given.",
    "published": "2024-05-10T02:06:34Z",
    "pdf_url": "http://arxiv.org/pdf/2405.06188v2",
    "categories": [
      "eess.IV",
      "42C15, 42C40, 68U10"
    ]
  },
  {
    "arxiv_id": "2406.08443v2",
    "title": "Transform-Dependent Adversarial Attacks",
    "authors": [
      "Yaoteng Tan",
      "Zikui Cai",
      "M. Salman Asif"
    ],
    "abstract": "Deep networks are highly vulnerable to adversarial attacks, yet conventional\nattack methods utilize static adversarial perturbations that induce fixed\nmispredictions. In this work, we exploit an overlooked property of adversarial\nperturbations--their dependence on image transforms--and introduce\ntransform-dependent adversarial attacks. Unlike traditional attacks, our\nperturbations exhibit metamorphic properties, enabling diverse adversarial\neffects as a function of transformation parameters. We demonstrate that this\ntransform-dependent vulnerability exists across different architectures (e.g.,\nCNN and transformer), vision tasks (e.g., image classification and object\ndetection), and a wide range of image transforms. Additionally, we show that\ntransform-dependent perturbations can serve as a defense mechanism, preventing\nsensitive information disclosure when image enhancement transforms pose a risk\nof revealing private content. Through analysis in blackbox and defended model\nsettings, we show that transform-dependent perturbations achieve high targeted\nattack success rates, outperforming state-of-the-art transfer attacks by 17-31%\nin blackbox scenarios. Our work introduces novel, controllable paradigm for\nadversarial attack deployment, revealing a previously overlooked vulnerability\nin deep networks.",
    "published": "2024-06-12T17:31:36Z",
    "pdf_url": "http://arxiv.org/pdf/2406.08443v2",
    "categories": [
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2507.10739v1",
    "title": "Quantum Wave Atom Transforms",
    "authors": [
      "Marianna Podzorova",
      "Yi-Kai Liu"
    ],
    "abstract": "This paper constructs the first quantum algorithm for wavelet packet\ntransforms with a tree structure, sometimes called wave atom transforms.\nClassically, wave atoms are used to construct sparse representations of\ndifferential operators, which enable fast numerical algorithms for partial\ndifferential equations. Compared to previous work, our quantum algorithm can\nimplement a larger class of wavelet and wave atom transforms, by using an\nefficient representation for a larger class of possible tree structures. Our\nquantum implementation has $O(\\mathrm{poly}(n))$ gate complexity for the\ntransform of dimension $2^n$, while classical implementations have $O(n 2^n)$\nfloating point operations. The result can be used to improve existing quantum\nalgorithms for solving hyperbolic partial differential equations.",
    "published": "2025-07-14T19:03:22Z",
    "pdf_url": "http://arxiv.org/pdf/2507.10739v1",
    "categories": [
      "quant-ph",
      "cs.NA",
      "math.NA"
    ]
  },
  {
    "arxiv_id": "1306.2024v2",
    "title": "The ridgelet transform of distributions",
    "authors": [
      "Sanja Kostadinova",
      "Stevan Pilipovic",
      "Katerina Saneva",
      "Jasson Vindas"
    ],
    "abstract": "We define and study the ridgelet transform of (Lizorkin) distributions. We\nestablish connections with the Radon and wavelet transforms.",
    "published": "2013-06-09T14:45:15Z",
    "pdf_url": "http://arxiv.org/pdf/1306.2024v2",
    "categories": [
      "math.FA",
      "math.CA",
      "Primary 44A15, 46F12. Secondary 42C20, 44A12, 44A35"
    ]
  },
  {
    "arxiv_id": "1705.07298v1",
    "title": "The Integral Transform of N.I.Akhiezer",
    "authors": [
      "Victor Katsnelson"
    ],
    "abstract": "We study the integral transform which appeared in a different form in\nAkhiezer's textbook \"Lectures on Integral Transforms\".",
    "published": "2017-05-20T12:53:12Z",
    "pdf_url": "http://arxiv.org/pdf/1705.07298v1",
    "categories": [
      "math.CA",
      "44A15, 44A35"
    ]
  },
  {
    "arxiv_id": "2302.01128v3",
    "title": "Mnemosyne: Learning to Train Transformers with Transformers",
    "authors": [
      "Deepali Jain",
      "Krzysztof Marcin Choromanski",
      "Avinava Dubey",
      "Sumeet Singh",
      "Vikas Sindhwani",
      "Tingnan Zhang",
      "Jie Tan"
    ],
    "abstract": "In this work, we propose a new class of learnable optimizers, called\n\\textit{Mnemosyne}. It is based on the novel spatio-temporal low-rank implicit\nattention Transformers that can learn to train entire neural network\narchitectures, including other Transformers, without any task-specific\noptimizer tuning. We show that Mnemosyne: (a) outperforms popular LSTM\noptimizers (also with new feature engineering to mitigate catastrophic\nforgetting of LSTMs), (b) can successfully train Transformers while using\nsimple meta-training strategies that require minimal computational resources,\n(c) matches accuracy-wise SOTA hand-designed optimizers with carefully tuned\nhyper-parameters (often producing top performing models). Furthermore,\nMnemosyne provides space complexity comparable to that of its hand-designed\nfirst-order counterparts, which allows it to scale to training larger sets of\nparameters. We conduct an extensive empirical evaluation of Mnemosyne on: (a)\nfine-tuning a wide range of Vision Transformers (ViTs) from medium-size\narchitectures to massive ViT-Hs (36 layers, 16 heads), (b) pre-training BERT\nmodels and (c) soft prompt-tuning large 11B+ T5XXL models. We complement our\nresults with a comprehensive theoretical analysis of the compact associative\nmemory used by Mnemosyne which we believe was never done before.",
    "published": "2023-02-02T14:40:28Z",
    "pdf_url": "http://arxiv.org/pdf/2302.01128v3",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2506.17671v2",
    "title": "TPTT: Transforming Pretrained Transformers into Titans",
    "authors": [
      "Fabien Furfaro"
    ],
    "abstract": "Transformer-based large language models (LLMs) have achieved strong\nperformance across many natural language processing tasks. Nonetheless, their\nquadratic computational and memory requirements, particularly in self-attention\nlayers, pose challenges for efficient inference on long contexts and for\ndeployment in resource-limited environments. We present TPTT (Transforming\nPretrained Transformers into Titans), a framework designed to augment\npretrained Transformers with linearized attention (LiZA) and internal memory\ngating via Memory as Gate (MaG), applied without full retraining. TPTT supports\nparameter-efficient fine-tuning (LoRA) and integrates with standard toolkits\nsuch as Hugging Face Transformers. We evaluated TPTT on several pretrained\nmodels, including Llama-1B, OlMoE-1B-7B, Qwen2.5-1.5B, Gemma3-270m,\nOpenELM-1.3B, and Mistral-7B, in order to assess applicability across\narchitectures of different scales. Experiments on models with approximately 1\nbillion parameters, evaluated primarily on the MMLU benchmark, suggest\npotential improvements in both efficiency and accuracy compared to baseline\nmodels. For example, Titans-Llama-1B exhibited up to a 20\\% relative increase\nin Exact Match scores in one-shot evaluation. An additional finding is that it\nis possible to convert a quadratic-attention model into a purely\nlinear-attention model using the DeltaProduct mechanism. All training runs were\ncarried out with modest computational resources. These preliminary findings\nindicate that TPTT may help adapt pretrained LLMs for long-context tasks with\nlimited overhead. Further studies on larger models and a broader set of\nbenchmarks will be necessary to evaluate the generality and robustness of the\nframework. Code is available at https://github.com/fabienfrfr/tptt . Python\npackage at https://pypi.org/project/tptt/ .",
    "published": "2025-06-21T10:06:07Z",
    "pdf_url": "http://arxiv.org/pdf/2506.17671v2",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "0603578v1",
    "title": "Fast complexified quaternion Fourier transform",
    "authors": [
      "Salem Said",
      "Nicolas Le Bihan",
      "Stephen J. Sangwine"
    ],
    "abstract": "A discrete complexified quaternion Fourier transform is introduced. This is a\ngeneralization of the discrete quaternion Fourier transform to the case where\neither or both of the signal/image and the transform kernel are complex\nquaternion-valued. It is shown how to compute the transform using four standard\ncomplex Fourier transforms and the properties of the transform are briefly\ndiscussed.",
    "published": "2006-03-24T15:30:14Z",
    "pdf_url": "http://arxiv.org/pdf/math/0603578v1",
    "categories": [
      "math.NA",
      "math.FA",
      "65T50"
    ]
  },
  {
    "arxiv_id": "0508104v1",
    "title": "A Generalised Hadamard Transform",
    "authors": [
      "K. J. Horadam"
    ],
    "abstract": "A Generalised Hadamard Transform for multi-phase or multilevel signals is\nintroduced, which includes the Fourier, Generalised, Discrete Fourier,\nWalsh-Hadamard and Reverse Jacket Transforms. The jacket construction is\nformalised and shown to admit a tensor product decomposition. Primary matrices\nunder this decomposition are identified. New examples of primary jacket\nmatrices of orders 8 and 12 are presented.",
    "published": "2005-08-24T01:03:34Z",
    "pdf_url": "http://arxiv.org/pdf/cs/0508104v1",
    "categories": [
      "cs.IT",
      "cs.DM",
      "math.IT"
    ]
  },
  {
    "arxiv_id": "9602019v1",
    "title": "Two Different Squeeze Transformations",
    "authors": [
      "D. Han",
      "Y. S. Kim"
    ],
    "abstract": "Lorentz boosts are squeeze transformations. While these transformations are\nsimilar to those in squeezed states of light, they are fundamentally different\nfrom both physical and mathematical points of view. The difference is\nillustrated in terms of two coupled harmonic oscillators, and in terms of the\ncovariant harmonic oscillator formalism.",
    "published": "1996-02-05T15:28:54Z",
    "pdf_url": "http://arxiv.org/pdf/hep-th/9602019v1",
    "categories": [
      "hep-th"
    ]
  },
  {
    "arxiv_id": "9901009v1",
    "title": "Fourier transform for D-algebras",
    "authors": [
      "Alexander Polishchuk",
      "Mitchell Rothstein"
    ],
    "abstract": "We construct a version of Fourier transform for a class of non-commutative\nalgebras over abelian varieties which include algebras of twisted differential\noperators generalizing the previous construction of Laumon (alg-geom/9603004)\nand of the second author (alg-geom/9602023). We also construct the microlocal\nversion of this transform and its etale localization in the framework of\nKapranov's theory of NC-schemes (see math.AG/9802041).",
    "published": "1999-01-04T21:45:13Z",
    "pdf_url": "http://arxiv.org/pdf/math/9901009v1",
    "categories": [
      "math.AG"
    ]
  },
  {
    "arxiv_id": "0212199v1",
    "title": "The amplitude modulation transform",
    "authors": [
      "Igor Rivin"
    ],
    "abstract": "Motivated by the study of the local extrema of sin(x)/x we define the\n\\emph{Amplitude Modulation} transform of functions defined on (subsets of) the\nreal line. We discuss certain properties of this transform and invert it in\nsome easy cases.",
    "published": "2002-12-15T23:56:50Z",
    "pdf_url": "http://arxiv.org/pdf/math/0212199v1",
    "categories": [
      "math.CA",
      "26A09; 14Q99"
    ]
  },
  {
    "arxiv_id": "0404082v2",
    "title": "Transformations of Grassman Spaces",
    "authors": [
      "Mark Pankov"
    ],
    "abstract": "This is a version of a part of the book ``Transformations of Grassman\nSpaces'' (in progress). We study transformations of Grassman spaces preserving\ncertain geometrical constructions related to buildings. The next part will be\ndevoted to Grassman spaces associated with polar spaces.",
    "published": "2004-04-05T13:44:28Z",
    "pdf_url": "http://arxiv.org/pdf/math/0404082v2",
    "categories": [
      "math.GM",
      "math.MG",
      "20B99"
    ]
  },
  {
    "arxiv_id": "0507132v3",
    "title": "Laplace transformation updated",
    "authors": [
      "Ernst Terhardt"
    ],
    "abstract": "The traditional theory of Laplace transformation in its currently prevalent\nform is unsatisfactory. Its deficiencies can be traced back to a mismatch of\nthe definition intervals of the original function and of the inverse\nL-transform. A new approach is outlined by which Laplace transformation becomes\nliberated from its inconsistencies.",
    "published": "2005-07-07T05:40:06Z",
    "pdf_url": "http://arxiv.org/pdf/math/0507132v3",
    "categories": [
      "math.HO",
      "44A10"
    ]
  },
  {
    "arxiv_id": "9905024v1",
    "title": "Octonionic Mobius Transformations",
    "authors": [
      "Corinne A. Manogue",
      "Tevian Dray"
    ],
    "abstract": "A vexing problem involving nonassociativity is resolved, allowing a\ngeneralization of the usual complex Mobius transformations to the octonions.\nThis is accomplished by relating the octonionic Mobius transformations to the\nLorentz group in 10 spacetime dimensions. The result will be of particular\ninterest to physicists working with lightlike objects in 10 dimensions.",
    "published": "1999-05-27T16:51:12Z",
    "pdf_url": "http://arxiv.org/pdf/math-ph/9905024v1",
    "categories": [
      "math-ph",
      "hep-th",
      "math.MP",
      "math.RA",
      "17A35"
    ]
  },
  {
    "arxiv_id": "9607029v1",
    "title": "Gauge transformations and quasitriangularity",
    "authors": [
      "S. Zakrzewski"
    ],
    "abstract": "Natural conditions on a Poisson/quantum group G to implement Poisson/quantum\ngauge transformations on the lattice are investigated. In addition to our\nprevious result that transformations on one lattice link require G to be\ncoboundary, it is shown that for a sequence of links one needs a\nquasitriangular G.",
    "published": "1996-07-29T12:09:06Z",
    "pdf_url": "http://arxiv.org/pdf/q-alg/9607029v1",
    "categories": [
      "q-alg",
      "math.QA"
    ]
  },
  {
    "arxiv_id": "1305.5224v3",
    "title": "Generalized Lorentz Transformations",
    "authors": [
      "Virendra Gupta"
    ],
    "abstract": "Generalized Lorentz transformations with modified velocity parameter are\nconsidered. Lorentz transformations depending on the mass of the observer are\nsuggested.The modified formula for the addition of velocities remarkably\npreserves the constancy of the velocity of light for all observers. The Doppler\nred shift is affected and can provide a test of such generalisations.",
    "published": "2013-05-22T18:36:40Z",
    "pdf_url": "http://arxiv.org/pdf/1305.5224v3",
    "categories": [
      "physics.gen-ph"
    ]
  },
  {
    "arxiv_id": "1403.0274v4",
    "title": "Enumerating Transformation Semigroups",
    "authors": [
      "James East",
      "Attila Egri-Nagy",
      "James D. Mitchell"
    ],
    "abstract": "We describe general methods for enumerating subsemigroups of finite\nsemigroups and techniques to improve the algorithmic efficiency of the\ncalculations. As a particular application we use our algorithms to enumerate\nall transformation semigroups up to degree 4. Classification of these\nsemigroups up to conjugacy, isomorphism and anti-isomorphism, by size and rank,\nprovides a solid base for further investigations of transformation semigroups.",
    "published": "2014-03-02T22:40:31Z",
    "pdf_url": "http://arxiv.org/pdf/1403.0274v4",
    "categories": [
      "math.GR",
      "20M20"
    ]
  },
  {
    "arxiv_id": "2207.09238v1",
    "title": "Formal Algorithms for Transformers",
    "authors": [
      "Mary Phuong",
      "Marcus Hutter"
    ],
    "abstract": "This document aims to be a self-contained, mathematically precise overview of\ntransformer architectures and algorithms (*not* results). It covers what\ntransformers are, how they are trained, what they are used for, their key\narchitectural components, and a preview of the most prominent models. The\nreader is assumed to be familiar with basic ML terminology and simpler neural\nnetwork architectures such as MLPs.",
    "published": "2022-07-19T12:49:02Z",
    "pdf_url": "http://arxiv.org/pdf/2207.09238v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "1211.3285v2",
    "title": "Cramér transform and t-entropy",
    "authors": [
      "Urszula Ostaszewska",
      "Krzysztof Zajkowski"
    ],
    "abstract": "t-entropy is the convex conjugate of the logarithm of the spectral radius of\na weighted composition operator (WCO). Let $X$ be a nonnegative random\nvariable. We show how the Cram\\'er transform with respect to the spectral\nradius of WCO is expressed by the t-entropy and the Cram\\'er transform of the\ngiven random variable X.",
    "published": "2012-11-14T12:06:25Z",
    "pdf_url": "http://arxiv.org/pdf/1211.3285v2",
    "categories": [
      "math.PR",
      "math.FA",
      "44A15, 47A10, 47B37, 60F99"
    ]
  },
  {
    "arxiv_id": "1701.00544v1",
    "title": "Binomial transform of products",
    "authors": [
      "Khristo N. Boyadzhiev"
    ],
    "abstract": "Given two infinite sequences with known binomial transforms, we compute the\nbinomial transform of the product sequence. Various identities are obtained and\nnumerous examples are given involving sequences of special numbers: Harmonic\nnumbers, Bernoulli numbers, Fibonacci numbers, and also Laguerre polynomials.",
    "published": "2017-01-02T22:15:49Z",
    "pdf_url": "http://arxiv.org/pdf/1701.00544v1",
    "categories": [
      "math.NT",
      "11B65, 05A10, 33C45, 40A99"
    ]
  },
  {
    "arxiv_id": "2305.03232v2",
    "title": "Neuromodulation Gated Transformer",
    "authors": [
      "Kobe Knowles",
      "Joshua Bensemann",
      "Diana Benavides-Prado",
      "Vithya Yogarajan",
      "Michael Witbrock",
      "Gillian Dobbie",
      "Yang Chen"
    ],
    "abstract": "We introduce a novel architecture, the Neuromodulation Gated Transformer\n(NGT), which is a simple implementation of neuromodulation in transformers via\na multiplicative effect. We compare it to baselines and show that it results in\nthe best average performance on the SuperGLUE benchmark validation sets.",
    "published": "2023-05-05T01:23:22Z",
    "pdf_url": "http://arxiv.org/pdf/2305.03232v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "1901.11117v4",
    "title": "The Evolved Transformer",
    "authors": [
      "David R. So",
      "Chen Liang",
      "Quoc V. Le"
    ],
    "abstract": "Recent works have highlighted the strength of the Transformer architecture on\nsequence tasks while, at the same time, neural architecture search (NAS) has\nbegun to outperform human-designed models. Our goal is to apply NAS to search\nfor a better alternative to the Transformer. We first construct a large search\nspace inspired by the recent advances in feed-forward sequence models and then\nrun evolutionary architecture search with warm starting by seeding our initial\npopulation with the Transformer. To directly search on the computationally\nexpensive WMT 2014 English-German translation task, we develop the Progressive\nDynamic Hurdles method, which allows us to dynamically allocate more resources\nto more promising candidate models. The architecture found in our experiments\n-- the Evolved Transformer -- demonstrates consistent improvement over the\nTransformer on four well-established language tasks: WMT 2014 English-German,\nWMT 2014 English-French, WMT 2014 English-Czech and LM1B. At a big model size,\nthe Evolved Transformer establishes a new state-of-the-art BLEU score of 29.8\non WMT'14 English-German; at smaller sizes, it achieves the same quality as the\noriginal \"big\" Transformer with 37.6% less parameters and outperforms the\nTransformer by 0.7 BLEU at a mobile-friendly model size of 7M parameters.",
    "published": "2019-01-30T22:03:01Z",
    "pdf_url": "http://arxiv.org/pdf/1901.11117v4",
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.NE",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2003.05031v3",
    "title": "Transformations of Hypergeometric Motives",
    "authors": [
      "J. William Hoffman",
      "Fang-Ting Tu"
    ],
    "abstract": "We consider algebraic transformations of hypergeometric functions from a\ngeometric point of view. Hypergeometric functions are shown to arise from the\ndeRham realization of a hypergeometric motive. The $\\ell$-adic realization of\nthe motive gives rise to hypergeometric characters sums over finite fields.\nThis helps to unify and explain some recent results about transformations of\nhypergeometric character sums.",
    "published": "2020-03-10T23:16:58Z",
    "pdf_url": "http://arxiv.org/pdf/2003.05031v3",
    "categories": [
      "math.NT"
    ]
  },
  {
    "arxiv_id": "2012.06963v1",
    "title": "The Arithmetic Fourier Transform",
    "authors": [
      "Joel L. Schiff"
    ],
    "abstract": "The Arithmetic Fourier Transform is a numerical formulation for computing\nFourier series and Taylor series coefficients. It competes with the Fast\nFourier Transform in terms of speed and efficiency, requiring only addition\noperations and can be performed by parallel processing. The AFT has some deep\nconnections with the Prime Number Theorem and its rich history is discussed in\nthis expository article.",
    "published": "2020-12-13T05:20:12Z",
    "pdf_url": "http://arxiv.org/pdf/2012.06963v1",
    "categories": [
      "math.CV",
      "math.NT",
      "42A16, 11A25, 30J99"
    ]
  },
  {
    "arxiv_id": "2307.01694v1",
    "title": "Spike-driven Transformer",
    "authors": [
      "Man Yao",
      "Jiakui Hu",
      "Zhaokun Zhou",
      "Li Yuan",
      "Yonghong Tian",
      "Bo Xu",
      "Guoqi Li"
    ],
    "abstract": "Spiking Neural Networks (SNNs) provide an energy-efficient deep learning\noption due to their unique spike-based event-driven (i.e., spike-driven)\nparadigm. In this paper, we incorporate the spike-driven paradigm into\nTransformer by the proposed Spike-driven Transformer with four unique\nproperties: 1) Event-driven, no calculation is triggered when the input of\nTransformer is zero; 2) Binary spike communication, all matrix multiplications\nassociated with the spike matrix can be transformed into sparse additions; 3)\nSelf-attention with linear complexity at both token and channel dimensions; 4)\nThe operations between spike-form Query, Key, and Value are mask and addition.\nTogether, there are only sparse addition operations in the Spike-driven\nTransformer. To this end, we design a novel Spike-Driven Self-Attention (SDSA),\nwhich exploits only mask and addition operations without any multiplication,\nand thus having up to $87.2\\times$ lower computation energy than vanilla\nself-attention. Especially in SDSA, the matrix multiplication between Query,\nKey, and Value is designed as the mask operation. In addition, we rearrange all\nresidual connections in the vanilla Transformer before the activation functions\nto ensure that all neurons transmit binary spike signals. It is shown that the\nSpike-driven Transformer can achieve 77.1\\% top-1 accuracy on ImageNet-1K,\nwhich is the state-of-the-art result in the SNN field. The source code is\navailable at https://github.com/BICLab/Spike-Driven-Transformer.",
    "published": "2023-07-04T13:00:18Z",
    "pdf_url": "http://arxiv.org/pdf/2307.01694v1",
    "categories": [
      "cs.NE",
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2307.07843v1",
    "title": "Transformers are Universal Predictors",
    "authors": [
      "Sourya Basu",
      "Moulik Choraria",
      "Lav R. Varshney"
    ],
    "abstract": "We find limits to the Transformer architecture for language modeling and show\nit has a universal prediction property in an information-theoretic sense. We\nfurther analyze performance in non-asymptotic data regimes to understand the\nrole of various components of the Transformer architecture, especially in the\ncontext of data-efficient training. We validate our theoretical analysis with\nexperiments on both synthetic and real datasets.",
    "published": "2023-07-15T16:19:37Z",
    "pdf_url": "http://arxiv.org/pdf/2307.07843v1",
    "categories": [
      "cs.LG",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2411.19659v2",
    "title": "Ruijsenaars spectral transform",
    "authors": [
      "N. Belousov",
      "S. Khoroshkin"
    ],
    "abstract": "Spectral decomposition with respect to the wave functions of Ruijsenaars\nhyperbolic system defines an integral transform, which generalizes classical\nFourier integral. For a certain class of analytical symmetric functions we\nprove inversion formula and orthogonality relations, valid for complex valued\nparameters of the system. Besides, we study four regimes of unitarity, when\nthis transform defines isomorphisms of the corresponding $L_2$ spaces.",
    "published": "2024-11-29T12:32:48Z",
    "pdf_url": "http://arxiv.org/pdf/2411.19659v2",
    "categories": [
      "math-ph",
      "hep-th",
      "math.CA",
      "math.MP",
      "nlin.SI"
    ]
  },
  {
    "arxiv_id": "9712017v2",
    "title": "Transformations of Quadrilateral Lattices",
    "authors": [
      "A. Doliwa",
      "P. M. Santini",
      "M. Manas"
    ],
    "abstract": "Motivated by the classical studies on transformations of conjugate nets, we\ndevelop the general geometric theory of transformations of their discrete\nanalogues: the multidimensional quadrilateral lattices, i.e. lattices x: Z^N ->\nR^M, whose elementary quadrilaterals are planar. Our investigation is based on\nthe discrete analogue of the theory of the rectilinear congruences, which we\nalso present in detail. We study, in particular, the discrete analogues of the\nLaplace, Combescure, Levy, radial and fundamental transformations and their\ninterrelations. The composition of these transformations and their\npermutability is also investigated from a geometric point of view. The deep\nconnections between \"transformations\" and \"discretizations\" is also\ninvestigated for quadrilateral lattices. We finally interpret these results\nwithin the D-bar formalism.",
    "published": "1997-12-20T11:02:51Z",
    "pdf_url": "http://arxiv.org/pdf/solv-int/9712017v2",
    "categories": [
      "solv-int",
      "nlin.SI"
    ]
  },
  {
    "arxiv_id": "1202.1773v2",
    "title": "Fast Finite Shearlet Transform",
    "authors": [
      "S. Häuser",
      "G. Steidl"
    ],
    "abstract": "In recent years it has turned out that shearlets have the potential to\nretrieve directional information so that they became interesting for many\napplications. Moreover the continuous shearlet transform has the outstanding\nproperty to stem from a square integrable group representation. However, to use\nshearlets and the shearlet transform for reasonable applications one needs fast\nalgorithms to compute a discrete shearlet transform. In this tutorial we\npresent the steps towards an implementation of a fast and finite shearlet\ntransform that is only based on the FFT. Using band-limited shearlets we\nconstruct a Parseval frame that provides a simple and straightforward inverse\nshearlet transform. We provide all proofs and discuss several aspects of our\nimplementation.",
    "published": "2012-02-08T17:24:00Z",
    "pdf_url": "http://arxiv.org/pdf/1202.1773v2",
    "categories": [
      "math.NA"
    ]
  },
  {
    "arxiv_id": "1406.0190v1",
    "title": "Amplified Quantum Transforms",
    "authors": [
      "David Cornwell"
    ],
    "abstract": "In this thesis we investigate two new Amplified Quantum Transforms. In\nparticular we create and analyze the Amplified Quantum Fourier Transform\n(Amplified-QFT) and the Amplified-Haar Wavelet Transform. First, we provide a\nbrief history of quantum mechanics and quantum computing. Second, we examine\nthe Amplified-QFT in detail and compare it against the Quantum Fourier\nTransform (QFT) and Quantum Hidden Subgroup (QHS) algorithms for solving the\nLocal Period Problem. We calculate the probabilities of success of each\nalgorithm and show the Amplified-QFT is quadratically faster than the QFT and\nQHS algorithms. Third, we examine the Amplified-QFT algorithm for solving The\nLocal Period Problem with an Error Stream. Fourth, we produce an uncertainty\nrelation for the Amplified-QFT algorithm. Fifth, we show how the Amplified-Haar\nWavelet Transform can solve the Local Constant or Balanced Signal Decision\nProblem which is a generalization of the Deutsch-Jozsa algorithm.",
    "published": "2014-06-01T18:13:25Z",
    "pdf_url": "http://arxiv.org/pdf/1406.0190v1",
    "categories": [
      "quant-ph"
    ]
  },
  {
    "arxiv_id": "1508.06749v4",
    "title": "Most Likely Transformations",
    "authors": [
      "Torsten Hothorn",
      "Lisa Möst",
      "Peter Bühlmann"
    ],
    "abstract": "We propose and study properties of maximum likelihood estimators in the class\nof conditional transformation models. Based on a suitable explicit\nparameterisation of the unconditional or conditional transformation function,\nwe establish a cascade of increasingly complex transformation models that can\nbe estimated, compared and analysed in the maximum likelihood framework. Models\nfor the unconditional or conditional distribution function of any univariate\nresponse variable can be set-up and estimated in the same theoretical and\ncomputational framework simply by choosing an appropriate transformation\nfunction and parameterisation thereof. The ability to evaluate the distribution\nfunction directly allows us to estimate models based on the exact likelihood,\nespecially in the presence of random censoring or truncation. For discrete and\ncontinuous responses, we establish the asymptotic normality of the proposed\nestimators. A reference software implementation of maximum likelihood-based\nestimation for conditional transformation models allowing the same flexibility\nas the theory developed here was employed to illustrate the wide range of\npossible applications.",
    "published": "2015-08-27T08:26:51Z",
    "pdf_url": "http://arxiv.org/pdf/1508.06749v4",
    "categories": [
      "stat.ME"
    ]
  },
  {
    "arxiv_id": "2104.08500v4",
    "title": "Vision Transformer Pruning",
    "authors": [
      "Mingjian Zhu",
      "Yehui Tang",
      "Kai Han"
    ],
    "abstract": "Vision transformer has achieved competitive performance on a variety of\ncomputer vision applications. However, their storage, run-time memory, and\ncomputational demands are hindering the deployment to mobile devices. Here we\npresent a vision transformer pruning approach, which identifies the impacts of\ndimensions in each layer of transformer and then executes pruning accordingly.\nBy encouraging dimension-wise sparsity in the transformer, important dimensions\nautomatically emerge. A great number of dimensions with small importance scores\ncan be discarded to achieve a high pruning ratio without significantly\ncompromising accuracy. The pipeline for vision transformer pruning is as\nfollows: 1) training with sparsity regularization; 2) pruning dimensions of\nlinear projections; 3) fine-tuning. The reduced parameters and FLOPs ratios of\nthe proposed algorithm are well evaluated and analyzed on ImageNet dataset to\ndemonstrate the effectiveness of our proposed method.",
    "published": "2021-04-17T09:49:24Z",
    "pdf_url": "http://arxiv.org/pdf/2104.08500v4",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2104.11227v1",
    "title": "Multiscale Vision Transformers",
    "authors": [
      "Haoqi Fan",
      "Bo Xiong",
      "Karttikeya Mangalam",
      "Yanghao Li",
      "Zhicheng Yan",
      "Jitendra Malik",
      "Christoph Feichtenhofer"
    ],
    "abstract": "We present Multiscale Vision Transformers (MViT) for video and image\nrecognition, by connecting the seminal idea of multiscale feature hierarchies\nwith transformer models. Multiscale Transformers have several\nchannel-resolution scale stages. Starting from the input resolution and a small\nchannel dimension, the stages hierarchically expand the channel capacity while\nreducing the spatial resolution. This creates a multiscale pyramid of features\nwith early layers operating at high spatial resolution to model simple\nlow-level visual information, and deeper layers at spatially coarse, but\ncomplex, high-dimensional features. We evaluate this fundamental architectural\nprior for modeling the dense nature of visual signals for a variety of video\nrecognition tasks where it outperforms concurrent vision transformers that rely\non large scale external pre-training and are 5-10x more costly in computation\nand parameters. We further remove the temporal dimension and apply our model\nfor image classification where it outperforms prior work on vision\ntransformers. Code is available at:\nhttps://github.com/facebookresearch/SlowFast",
    "published": "2021-04-22T17:59:45Z",
    "pdf_url": "http://arxiv.org/pdf/2104.11227v1",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2402.09269v2",
    "title": "Personalized Large Language Models",
    "authors": [
      "Stanisław Woźniak",
      "Bartłomiej Koptyra",
      "Arkadiusz Janz",
      "Przemysław Kazienko",
      "Jan Kocoń"
    ],
    "abstract": "Large language models (LLMs) have significantly advanced Natural Language\nProcessing (NLP) tasks in recent years. However, their universal nature poses\nlimitations in scenarios requiring personalized responses, such as\nrecommendation systems and chatbots. This paper investigates methods to\npersonalize LLMs, comparing fine-tuning and zero-shot reasoning approaches on\nsubjective tasks. Results demonstrate that personalized fine-tuning improves\nmodel reasoning compared to non-personalized models. Experiments on datasets\nfor emotion recognition and hate speech detection show consistent performance\ngains with personalized methods across different LLM architectures. These\nfindings underscore the importance of personalization for enhancing LLM\ncapabilities in subjective text perception tasks.",
    "published": "2024-02-14T15:55:30Z",
    "pdf_url": "http://arxiv.org/pdf/2402.09269v2",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2509.05757v1",
    "title": "Hyperbolic Large Language Models",
    "authors": [
      "Sarang Patil",
      "Zeyong Zhang",
      "Yiran Huang",
      "Tengfei Ma",
      "Mengjia Xu"
    ],
    "abstract": "Large language models (LLMs) have achieved remarkable success and\ndemonstrated superior performance across various tasks, including natural\nlanguage processing (NLP), weather forecasting, biological protein folding,\ntext generation, and solving mathematical problems. However, many real-world\ndata exhibit highly non-Euclidean latent hierarchical anatomy, such as protein\nnetworks, transportation networks, financial networks, brain networks, and\nlinguistic structures or syntactic trees in natural languages. Effectively\nlearning intrinsic semantic entailment and hierarchical relationships from\nthese raw, unstructured input data using LLMs remains an underexplored area.\nDue to its effectiveness in modeling tree-like hierarchical structures,\nhyperbolic geometry -- a non-Euclidean space -- has rapidly gained popularity\nas an expressive latent representation space for complex data modeling across\ndomains such as graphs, images, languages, and multi-modal data. Here, we\nprovide a comprehensive and contextual exposition of recent advancements in\nLLMs that leverage hyperbolic geometry as a representation space to enhance\nsemantic representation learning and multi-scale reasoning. Specifically, the\npaper presents a taxonomy of the principal techniques of Hyperbolic LLMs\n(HypLLMs) in terms of four main categories: (1) hyperbolic LLMs through exp/log\nmaps; (2) hyperbolic fine-tuned models; (3) fully hyperbolic LLMs, and (4)\nhyperbolic state-space models. We also explore crucial potential applications\nand outline future research directions. A repository of key papers, models,\ndatasets, and code implementations is available at\nhttps://github.com/sarangp2402/Hyperbolic-LLM-Models/tree/main.",
    "published": "2025-09-06T15:56:46Z",
    "pdf_url": "http://arxiv.org/pdf/2509.05757v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2305.05364v1",
    "title": "Large Language Model Programs",
    "authors": [
      "Imanol Schlag",
      "Sainbayar Sukhbaatar",
      "Asli Celikyilmaz",
      "Wen-tau Yih",
      "Jason Weston",
      "Jürgen Schmidhuber",
      "Xian Li"
    ],
    "abstract": "In recent years, large pre-trained language models (LLMs) have demonstrated\nthe ability to follow instructions and perform novel tasks from a few examples.\nThe possibility to parameterise an LLM through such in-context examples widens\ntheir capability at a much lower cost than finetuning. We extend this line of\nreasoning and present a method which further expands the capabilities of an LLM\nby embedding it within an algorithm or program. To demonstrate the benefits of\nthis approach, we present an illustrative example of evidence-supported\nquestion-answering. We obtain a 6.4\\% improvement over the chain of thought\nbaseline through a more algorithmic approach without any finetuning.\nFurthermore, we highlight recent work from this perspective and discuss the\nadvantages and disadvantages in comparison to the standard approaches.",
    "published": "2023-05-09T11:55:36Z",
    "pdf_url": "http://arxiv.org/pdf/2305.05364v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2307.05782v2",
    "title": "Large Language Models",
    "authors": [
      "Michael R. Douglas"
    ],
    "abstract": "Artificial intelligence is making spectacular progress, and one of the best\nexamples is the development of large language models (LLMs) such as OpenAI's\nGPT series. In these lectures, written for readers with a background in\nmathematics or physics, we give a brief history and survey of the state of the\nart, and describe the underlying transformer architecture in detail. We then\nexplore some current ideas on how LLMs work and how models trained to predict\nthe next word in a text are able to perform other tasks displaying\nintelligence.",
    "published": "2023-07-11T20:21:02Z",
    "pdf_url": "http://arxiv.org/pdf/2307.05782v2",
    "categories": [
      "cs.CL",
      "hep-th",
      "math.HO",
      "physics.comp-ph",
      "68T01",
      "I.2.7"
    ]
  },
  {
    "arxiv_id": "2310.10683v2",
    "title": "Large Language Model Unlearning",
    "authors": [
      "Yuanshun Yao",
      "Xiaojun Xu",
      "Yang Liu"
    ],
    "abstract": "We study how to perform unlearning, i.e. forgetting undesirable misbehaviors,\non large language models (LLMs). We show at least three scenarios of aligning\nLLMs with human preferences can benefit from unlearning: (1) removing harmful\nresponses, (2) erasing copyright-protected content as requested, and (3)\nreducing hallucinations. Unlearning, as an alignment technique, has three\nadvantages. (1) It only requires negative (e.g. harmful) examples, which are\nmuch easier and cheaper to collect (e.g. via red teaming or user reporting)\nthan positive (e.g. helpful and often human-written) examples required in RLHF\n(RL from human feedback). (2) It is computationally efficient. (3) It is\nespecially effective when we know which training samples cause the misbehavior.\nTo the best of our knowledge, our work is among the first to explore LLM\nunlearning. We are also among the first to formulate the settings, goals, and\nevaluations in LLM unlearning. We show that if practitioners only have limited\nresources, and therefore the priority is to stop generating undesirable outputs\nrather than to try to generate desirable outputs, unlearning is particularly\nappealing. Despite only having negative samples, our ablation study shows that\nunlearning can still achieve better alignment performance than RLHF with just\n2% of its computational time.",
    "published": "2023-10-14T00:32:55Z",
    "pdf_url": "http://arxiv.org/pdf/2310.10683v2",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2406.00030v1",
    "title": "Large Language Model Pruning",
    "authors": [
      "Hanjuan Huang",
      "Hao-Jia Song",
      "Hsing-Kuo Pao"
    ],
    "abstract": "We surely enjoy the larger the better models for their superior performance\nin the last couple of years when both the hardware and software support the\nbirth of such extremely huge models. The applied fields include text mining and\nothers. In particular, the success of LLMs on text understanding and text\ngeneration draws attention from researchers who have worked on NLP and related\nareas for years or even decades. On the side, LLMs may suffer from problems\nlike model overfitting, hallucination, and device limitation to name a few. In\nthis work, we suggest a model pruning technique specifically focused on LLMs.\nThe proposed methodology emphasizes the explainability of deep learning models.\nBy having the theoretical foundation, we obtain a trustworthy deep model so\nthat huge models with a massive number of model parameters become not quite\nnecessary. A mutual information-based estimation is adopted to find neurons\nwith redundancy to eliminate. Moreover, an estimator with well-tuned parameters\nhelps to find precise estimation to guide the pruning procedure. At the same\ntime, we also explore the difference between pruning on large-scale models vs.\npruning on small-scale models. The choice of pruning criteria is sensitive in\nsmall models but not for large-scale models. It is a novel finding through this\nwork. Overall, we demonstrate the superiority of the proposed model to the\nstate-of-the-art models.",
    "published": "2024-05-24T18:22:15Z",
    "pdf_url": "http://arxiv.org/pdf/2406.00030v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2405.06640v1",
    "title": "Linearizing Large Language Models",
    "authors": [
      "Jean Mercat",
      "Igor Vasiljevic",
      "Sedrick Keh",
      "Kushal Arora",
      "Achal Dave",
      "Adrien Gaidon",
      "Thomas Kollar"
    ],
    "abstract": "Linear transformers have emerged as a subquadratic-time alternative to\nsoftmax attention and have garnered significant interest due to their\nfixed-size recurrent state that lowers inference cost. However, their original\nformulation suffers from poor scaling and underperforms compute-matched\ntransformers. Recent linear models such as RWKV and Mamba have attempted to\naddress these shortcomings by proposing novel time-mixing and gating\narchitectures, but pre-training large language models requires significant data\nand compute investments. Thus, the search for subquadratic architectures is\nlimited by the availability of compute and quality pre-training datasets. As a\ncost-effective alternative to pre-training linear transformers, we propose\nScalable UPtraining for Recurrent Attention (SUPRA). We present a method to\nuptrain existing large pre-trained transformers into Recurrent Neural Networks\n(RNNs) with a modest compute budget. This allows us to leverage the strong\npre-training data and performance of existing transformer LLMs, while requiring\n5% of the training cost. We find that our linearization technique leads to\ncompetitive performance on standard benchmarks, but we identify persistent\nin-context learning and long-context modeling shortfalls for even the largest\nlinear models. Our code and models can be found at\nhttps://github.com/TRI-ML/linear_open_lm.",
    "published": "2024-05-10T17:59:08Z",
    "pdf_url": "http://arxiv.org/pdf/2405.06640v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2412.07992v4",
    "title": "Concept Bottleneck Large Language Models",
    "authors": [
      "Chung-En Sun",
      "Tuomas Oikarinen",
      "Berk Ustun",
      "Tsui-Wei Weng"
    ],
    "abstract": "We introduce Concept Bottleneck Large Language Models (CB-LLMs), a novel\nframework for building inherently interpretable Large Language Models (LLMs).\nIn contrast to traditional black-box LLMs that rely on limited post-hoc\ninterpretations, CB-LLMs integrate intrinsic interpretability directly into the\nLLMs -- allowing accurate explanations with scalability and transparency. We\nbuild CB-LLMs for two essential NLP tasks: text classification and text\ngeneration. In text classification, CB-LLMs is competitive with, and at times\noutperforms, traditional black-box models while providing explicit and\ninterpretable reasoning. For the more challenging task of text generation,\ninterpretable neurons in CB-LLMs enable precise concept detection, controlled\ngeneration, and safer outputs. The embedded interpretability empowers users to\ntransparently identify harmful content, steer model behavior, and unlearn\nundesired concepts -- significantly enhancing the safety, reliability, and\ntrustworthiness of LLMs, which are critical capabilities notably absent in\nexisting models. Our code is available at\nhttps://github.com/Trustworthy-ML-Lab/CB-LLMs.",
    "published": "2024-12-11T00:04:10Z",
    "pdf_url": "http://arxiv.org/pdf/2412.07992v4",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2402.06196v3",
    "title": "Large Language Models: A Survey",
    "authors": [
      "Shervin Minaee",
      "Tomas Mikolov",
      "Narjes Nikzad",
      "Meysam Chenaghlu",
      "Richard Socher",
      "Xavier Amatriain",
      "Jianfeng Gao"
    ],
    "abstract": "Large Language Models (LLMs) have drawn a lot of attention due to their\nstrong performance on a wide range of natural language tasks, since the release\nof ChatGPT in November 2022. LLMs' ability of general-purpose language\nunderstanding and generation is acquired by training billions of model's\nparameters on massive amounts of text data, as predicted by scaling laws\n\\cite{kaplan2020scaling,hoffmann2022training}. The research area of LLMs, while\nvery recent, is evolving rapidly in many different ways. In this paper, we\nreview some of the most prominent LLMs, including three popular LLM families\n(GPT, LLaMA, PaLM), and discuss their characteristics, contributions and\nlimitations. We also give an overview of techniques developed to build, and\naugment LLMs. We then survey popular datasets prepared for LLM training,\nfine-tuning, and evaluation, review widely used LLM evaluation metrics, and\ncompare the performance of several popular LLMs on a set of representative\nbenchmarks. Finally, we conclude the paper by discussing open challenges and\nfuture research directions.",
    "published": "2024-02-09T05:37:09Z",
    "pdf_url": "http://arxiv.org/pdf/2402.06196v3",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2409.10482v3",
    "title": "Schrodinger's Memory: Large Language Models",
    "authors": [
      "Wei Wang",
      "Qing Li"
    ],
    "abstract": "Memory is the foundation of all human activities; without memory, it would be\nnearly impossible for people to perform any task in daily life. With the\ndevelopment of Large Language Models (LLMs), their language capabilities are\nbecoming increasingly comparable to those of humans. But do LLMs have memory?\nBased on current performance, LLMs do appear to exhibit memory. So, what is the\nunderlying mechanism of this memory? Previous research has lacked a deep\nexploration of LLMs' memory capabilities and the underlying theory. In this\npaper, we use Universal Approximation Theorem (UAT) to explain the memory\nmechanism in LLMs. We also conduct experiments to verify the memory\ncapabilities of various LLMs, proposing a new method to assess their abilities\nbased on these memory ability. We argue that LLM memory operates like\nSchr\\\"odinger's memory, meaning that it only becomes observable when a specific\nmemory is queried. We can only determine if the model retains a memory based on\nits output in response to the query; otherwise, it remains indeterminate.\nFinally, we expand on this concept by comparing the memory capabilities of the\nhuman brain and LLMs, highlighting the similarities and differences in their\noperational mechanisms.",
    "published": "2024-09-16T17:18:11Z",
    "pdf_url": "http://arxiv.org/pdf/2409.10482v3",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2502.12150v2",
    "title": "Idiosyncrasies in Large Language Models",
    "authors": [
      "Mingjie Sun",
      "Yida Yin",
      "Zhiqiu Xu",
      "J. Zico Kolter",
      "Zhuang Liu"
    ],
    "abstract": "In this work, we unveil and study idiosyncrasies in Large Language Models\n(LLMs) -- unique patterns in their outputs that can be used to distinguish the\nmodels. To do so, we consider a simple classification task: given a particular\ntext output, the objective is to predict the source LLM that generates the\ntext. We evaluate this synthetic task across various groups of LLMs and find\nthat simply fine-tuning text embedding models on LLM-generated texts yields\nexcellent classification accuracy. Notably, we achieve 97.1% accuracy on\nheld-out validation data in the five-way classification problem involving\nChatGPT, Claude, Grok, Gemini, and DeepSeek. Our further investigation reveals\nthat these idiosyncrasies are rooted in word-level distributions. These\npatterns persist even when the texts are rewritten, translated, or summarized\nby an external LLM, suggesting that they are also encoded in the semantic\ncontent. Additionally, we leverage LLM as judges to generate detailed,\nopen-ended descriptions of each model's idiosyncrasies. Finally, we discuss the\nbroader implications of our findings, including training on synthetic data,\ninferring model similarity, and robust evaluation of LLMs. Code is available at\nhttps://github.com/locuslab/llm-idiosyncrasies.",
    "published": "2025-02-17T18:59:02Z",
    "pdf_url": "http://arxiv.org/pdf/2502.12150v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2503.04748v2",
    "title": "Large Language Models in Healthcare",
    "authors": [
      "Mohammed Al-Garadi",
      "Tushar Mungle",
      "Abdulaziz Ahmed",
      "Abeed Sarker",
      "Zhuqi Miao",
      "Michael E. Matheny"
    ],
    "abstract": "Large language models (LLMs) hold promise for transforming healthcare, from\nstreamlining administrative and clinical workflows to enriching patient\nengagement and advancing clinical decision-making. However, their successful\nintegration requires rigorous development, adaptation, and evaluation\nstrategies tailored to clinical needs. In this Review, we highlight recent\nadvancements, explore emerging opportunities for LLM-driven innovation, and\npropose a framework for their responsible implementation in healthcare\nsettings. We examine strategies for adapting LLMs to domain-specific healthcare\ntasks, such as fine-tuning, prompt engineering, and multimodal integration with\nelectronic health records. We also summarize various evaluation metrics\ntailored to healthcare, addressing clinical accuracy, fairness, robustness, and\npatient outcomes. Furthermore, we discuss the challenges associated with\ndeploying LLMs in healthcare--including data privacy, bias mitigation,\nregulatory compliance, and computational sustainability--and underscore the\nneed for interdisciplinary collaboration. Finally, these challenges present\npromising future research directions for advancing LLM implementation in\nclinical settings and healthcare.",
    "published": "2025-02-06T20:53:33Z",
    "pdf_url": "http://arxiv.org/pdf/2503.04748v2",
    "categories": [
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "2410.15319v1",
    "title": "Causality for Large Language Models",
    "authors": [
      "Anpeng Wu",
      "Kun Kuang",
      "Minqin Zhu",
      "Yingrong Wang",
      "Yujia Zheng",
      "Kairong Han",
      "Baohong Li",
      "Guangyi Chen",
      "Fei Wu",
      "Kun Zhang"
    ],
    "abstract": "Recent breakthroughs in artificial intelligence have driven a paradigm shift,\nwhere large language models (LLMs) with billions or trillions of parameters are\ntrained on vast datasets, achieving unprecedented success across a series of\nlanguage tasks. However, despite these successes, LLMs still rely on\nprobabilistic modeling, which often captures spurious correlations rooted in\nlinguistic patterns and social stereotypes, rather than the true causal\nrelationships between entities and events. This limitation renders LLMs\nvulnerable to issues such as demographic biases, social stereotypes, and LLM\nhallucinations. These challenges highlight the urgent need to integrate\ncausality into LLMs, moving beyond correlation-driven paradigms to build more\nreliable and ethically aligned AI systems.\n  While many existing surveys and studies focus on utilizing prompt engineering\nto activate LLMs for causal knowledge or developing benchmarks to assess their\ncausal reasoning abilities, most of these efforts rely on human intervention to\nactivate pre-trained models. How to embed causality into the training process\nof LLMs and build more general and intelligent models remains unexplored.\nRecent research highlights that LLMs function as causal parrots, capable of\nreciting causal knowledge without truly understanding or applying it. These\nprompt-based methods are still limited to human interventional improvements.\nThis survey aims to address this gap by exploring how causality can enhance\nLLMs at every stage of their lifecycle-from token embedding learning and\nfoundation model training to fine-tuning, alignment, inference, and\nevaluation-paving the way for more interpretable, reliable, and\ncausally-informed models. Additionally, we further outline six promising future\ndirections to advance LLM development, enhance their causal reasoning\ncapabilities, and address the current limitations these models face.",
    "published": "2024-10-20T07:22:23Z",
    "pdf_url": "http://arxiv.org/pdf/2410.15319v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2407.00365v1",
    "title": "Financial Knowledge Large Language Model",
    "authors": [
      "Cehao Yang",
      "Chengjin Xu",
      "Yiyan Qi"
    ],
    "abstract": "Artificial intelligence is making significant strides in the finance\nindustry, revolutionizing how data is processed and interpreted. Among these\ntechnologies, large language models (LLMs) have demonstrated substantial\npotential to transform financial services by automating complex tasks,\nenhancing customer service, and providing detailed financial analysis. Firstly,\nwe introduce IDEA-FinBench, an evaluation benchmark specifically tailored for\nassessing financial knowledge in large language models (LLMs). This benchmark\nutilizes questions from two globally respected and authoritative financial\nprofessional exams, aimimg to comprehensively evaluate the capability of LLMs\nto directly address exam questions pertinent to the finance sector. Secondly,\nwe propose IDEA-FinKER, a Financial Knowledge Enhancement framework designed to\nfacilitate the rapid adaptation of general LLMs to the financial domain,\nintroducing a retrieval-based few-shot learning method for real-time\ncontext-level knowledge injection, and a set of high-quality financial\nknowledge instructions for fine-tuning any general LLM. Finally, we present\nIDEA-FinQA, a financial question-answering system powered by LLMs. This system\nis structured around a scheme of real-time knowledge injection and factual\nenhancement using external knowledge. IDEA-FinQA is comprised of three main\nmodules: the data collector, the data querying module, and LLM-based agents\ntasked with specific functions.",
    "published": "2024-06-29T08:26:49Z",
    "pdf_url": "http://arxiv.org/pdf/2407.00365v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2312.04556v2",
    "title": "Large Language Models for Mathematicians",
    "authors": [
      "Simon Frieder",
      "Julius Berner",
      "Philipp Petersen",
      "Thomas Lukasiewicz"
    ],
    "abstract": "Large language models (LLMs) such as ChatGPT have received immense interest\nfor their general-purpose language understanding and, in particular, their\nability to generate high-quality text or computer code. For many professions,\nLLMs represent an invaluable tool that can speed up and improve the quality of\nwork. In this note, we discuss to what extent they can aid professional\nmathematicians. We first provide a mathematical description of the transformer\nmodel used in all modern language models. Based on recent studies, we then\noutline best practices and potential issues and report on the mathematical\nabilities of language models. Finally, we shed light on the potential of LLMs\nto change how mathematicians work.",
    "published": "2023-12-07T18:59:29Z",
    "pdf_url": "http://arxiv.org/pdf/2312.04556v2",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "math.HO"
    ]
  },
  {
    "arxiv_id": "2305.05576v1",
    "title": "Large Language Models Humanize Technology",
    "authors": [
      "Pratyush Kumar"
    ],
    "abstract": "Large Language Models (LLMs) have made rapid progress in recent months and\nweeks, garnering significant public attention. This has sparked concerns about\naligning these models with human values, their impact on labor markets, and the\npotential need for regulation in further research and development. However, the\ndiscourse often lacks a focus on the imperative to widely diffuse the societal\nbenefits of LLMs. To qualify this societal benefit, we assert that LLMs exhibit\nemergent abilities to humanize technology more effectively than previous\ntechnologies, and for people across language, occupation, and accessibility\ndivides. We argue that they do so by addressing three mechanizing bottlenecks\nin today's computing technologies: creating diverse and accessible content,\nlearning complex digital tools, and personalizing machine learning algorithms.\nWe adopt a case-based approach and illustrate each bottleneck with two examples\nwhere current technology imposes bottlenecks that LLMs demonstrate the ability\nto address. Given this opportunity to humanize technology widely, we advocate\nfor more widespread understanding of LLMs, tools and methods to simplify use of\nLLMs, and cross-cutting institutional capacity.",
    "published": "2023-05-09T16:05:36Z",
    "pdf_url": "http://arxiv.org/pdf/2305.05576v1",
    "categories": [
      "cs.CY",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2408.10946v2",
    "title": "Large Language Model Driven Recommendation",
    "authors": [
      "Anton Korikov",
      "Scott Sanner",
      "Yashar Deldjoo",
      "Zhankui He",
      "Julian McAuley",
      "Arnau Ramisa",
      "Rene Vidal",
      "Mahesh Sathiamoorthy",
      "Atoosa Kasrizadeh",
      "Silvia Milano",
      "Francesco Ricci"
    ],
    "abstract": "While previous chapters focused on recommendation systems (RSs) based on\nstandardized, non-verbal user feedback such as purchases, views, and clicks --\nthe advent of LLMs has unlocked the use of natural language (NL) interactions\nfor recommendation. This chapter discusses how LLMs' abilities for general NL\nreasoning present novel opportunities to build highly personalized RSs -- which\ncan effectively connect nuanced and diverse user preferences to items,\npotentially via interactive dialogues. To begin this discussion, we first\npresent a taxonomy of the key data sources for language-driven recommendation,\ncovering item descriptions, user-system interactions, and user profiles. We\nthen proceed to fundamental techniques for LLM recommendation, reviewing the\nuse of encoder-only and autoregressive LLM recommendation in both tuned and\nuntuned settings. Afterwards, we move to multi-module recommendation\narchitectures in which LLMs interact with components such as retrievers and RSs\nin multi-stage pipelines. This brings us to architectures for conversational\nrecommender systems (CRSs), in which LLMs facilitate multi-turn dialogues where\neach turn presents an opportunity not only to make recommendations, but also to\nengage with the user in interactive preference elicitation, critiquing, and\nquestion-answering.",
    "published": "2024-08-20T15:36:24Z",
    "pdf_url": "http://arxiv.org/pdf/2408.10946v2",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2402.07616v3",
    "title": "Anchor-based Large Language Models",
    "authors": [
      "Jianhui Pang",
      "Fanghua Ye",
      "Derek Fai Wong",
      "Xin He",
      "Wanshun Chen",
      "Longyue Wang"
    ],
    "abstract": "Large language models (LLMs) predominantly employ decoder-only transformer\narchitectures, necessitating the retention of keys/values information for\nhistorical tokens to provide contextual information and avoid redundant\ncomputation. However, the substantial size and parameter volume of these LLMs\nrequire massive GPU memory. This memory demand increases with the length of the\ninput text, leading to an urgent need for more efficient methods of information\nstorage and processing. This study introduces Anchor-based LLMs (AnLLMs), which\nutilize an innovative anchor-based self-attention network (AnSAN) and also an\nanchor-based inference strategy. This approach enables LLMs to compress\nsequence information into an anchor token, reducing the keys/values cache and\nenhancing inference efficiency. Experiments on question-answering benchmarks\nreveal that AnLLMs maintain similar accuracy levels while achieving up to 99%\nkeys/values cache reduction and up to 3.5 times faster inference. Despite a\nminor compromise in accuracy, the substantial enhancements of AnLLMs employing\nthe AnSAN technique in resource utilization and computational efficiency\nunderscore their potential for practical LLM applications.",
    "published": "2024-02-12T12:48:02Z",
    "pdf_url": "http://arxiv.org/pdf/2402.07616v3",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2410.21418v1",
    "title": "Large Language Models for Manufacturing",
    "authors": [
      "Yiwei Li",
      "Huaqin Zhao",
      "Hanqi Jiang",
      "Yi Pan",
      "Zhengliang Liu",
      "Zihao Wu",
      "Peng Shu",
      "Jie Tian",
      "Tianze Yang",
      "Shaochen Xu",
      "Yanjun Lyu",
      "Parker Blenk",
      "Jacob Pence",
      "Jason Rupram",
      "Eliza Banu",
      "Ninghao Liu",
      "Linbing Wang",
      "Wenzhan Song",
      "Xiaoming Zhai",
      "Kenan Song",
      "Dajiang Zhu",
      "Beiwen Li",
      "Xianqiao Wang",
      "Tianming Liu"
    ],
    "abstract": "The rapid advances in Large Language Models (LLMs) have the potential to\ntransform manufacturing industry, offering new opportunities to optimize\nprocesses, improve efficiency, and drive innovation. This paper provides a\ncomprehensive exploration of the integration of LLMs into the manufacturing\ndomain, focusing on their potential to automate and enhance various aspects of\nmanufacturing, from product design and development to quality control, supply\nchain optimization, and talent management. Through extensive evaluations across\nmultiple manufacturing tasks, we demonstrate the remarkable capabilities of\nstate-of-the-art LLMs, such as GPT-4V, in understanding and executing complex\ninstructions, extracting valuable insights from vast amounts of data, and\nfacilitating knowledge sharing. We also delve into the transformative potential\nof LLMs in reshaping manufacturing education, automating coding processes,\nenhancing robot control systems, and enabling the creation of immersive,\ndata-rich virtual environments through the industrial metaverse. By\nhighlighting the practical applications and emerging use cases of LLMs in\nmanufacturing, this paper aims to provide a valuable resource for\nprofessionals, researchers, and decision-makers seeking to harness the power of\nthese technologies to address real-world challenges, drive operational\nexcellence, and unlock sustainable growth in an increasingly competitive\nlandscape.",
    "published": "2024-10-28T18:13:47Z",
    "pdf_url": "http://arxiv.org/pdf/2410.21418v1",
    "categories": [
      "cs.AI",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2501.00885v1",
    "title": "Representation in large language models",
    "authors": [
      "Cameron C. Yetman"
    ],
    "abstract": "The extraordinary success of recent Large Language Models (LLMs) on a diverse\narray of tasks has led to an explosion of scientific and philosophical\ntheorizing aimed at explaining how they do what they do. Unfortunately,\ndisagreement over fundamental theoretical issues has led to stalemate, with\nentrenched camps of LLM optimists and pessimists often committed to very\ndifferent views of how these systems work. Overcoming stalemate requires\nagreement on fundamental questions, and the goal of this paper is to address\none such question, namely: is LLM behavior driven partly by\nrepresentation-based information processing of the sort implicated in\nbiological cognition, or is it driven entirely by processes of memorization and\nstochastic table look-up? This is a question about what kind of algorithm LLMs\nimplement, and the answer carries serious implications for higher level\nquestions about whether these systems have beliefs, intentions, concepts,\nknowledge, and understanding. I argue that LLM behavior is partially driven by\nrepresentation-based information processing, and then I describe and defend a\nseries of practical techniques for investigating these representations and\ndeveloping explanations on their basis. The resulting account provides a\ngroundwork for future theorizing about language models and their successors.",
    "published": "2025-01-01T16:19:48Z",
    "pdf_url": "http://arxiv.org/pdf/2501.00885v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2501.05643v1",
    "title": "Iconicity in Large Language Models",
    "authors": [
      "Anna Marklová",
      "Jiří Milička",
      "Leonid Ryvkin",
      "Ľudmila Lacková Bennet",
      "Libuše Kormaníková"
    ],
    "abstract": "Lexical iconicity, a direct relation between a word's meaning and its form,\nis an important aspect of every natural language, most commonly manifesting\nthrough sound-meaning associations. Since Large language models' (LLMs') access\nto both meaning and sound of text is only mediated (meaning through textual\ncontext, sound through written representation, further complicated by\ntokenization), we might expect that the encoding of iconicity in LLMs would be\neither insufficient or significantly different from human processing. This\nstudy addresses this hypothesis by having GPT-4 generate highly iconic\npseudowords in artificial languages. To verify that these words actually carry\niconicity, we had their meanings guessed by Czech and German participants\n(n=672) and subsequently by LLM-based participants (generated by GPT-4 and\nClaude 3.5 Sonnet). The results revealed that humans can guess the meanings of\npseudowords in the generated iconic language more accurately than words in\ndistant natural languages and that LLM-based participants are even more\nsuccessful than humans in this task. This core finding is accompanied by\nseveral additional analyses concerning the universality of the generated\nlanguage and the cues that both human and LLM-based participants utilize.",
    "published": "2025-01-10T01:00:05Z",
    "pdf_url": "http://arxiv.org/pdf/2501.05643v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2212.03551v5",
    "title": "Talking About Large Language Models",
    "authors": [
      "Murray Shanahan"
    ],
    "abstract": "Thanks to rapid progress in artificial intelligence, we have entered an era\nwhen technology and philosophy intersect in interesting ways. Sitting squarely\nat the centre of this intersection are large language models (LLMs). The more\nadept LLMs become at mimicking human language, the more vulnerable we become to\nanthropomorphism, to seeing the systems in which they are embedded as more\nhuman-like than they really are. This trend is amplified by the natural\ntendency to use philosophically loaded terms, such as \"knows\", \"believes\", and\n\"thinks\", when describing these systems. To mitigate this trend, this paper\nadvocates the practice of repeatedly stepping back to remind ourselves of how\nLLMs, and the systems of which they form a part, actually work. The hope is\nthat increased scientific precision will encourage more philosophical nuance in\nthe discourse around artificial intelligence, both within the field and in the\npublic sphere.",
    "published": "2022-12-07T10:01:44Z",
    "pdf_url": "http://arxiv.org/pdf/2212.03551v5",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2311.15180v1",
    "title": "Benchmarking Large Language Model Volatility",
    "authors": [
      "Boyang Yu"
    ],
    "abstract": "The impact of non-deterministic outputs from Large Language Models (LLMs) is\nnot well examined for financial text understanding tasks. Through a compelling\ncase study on investing in the US equity market via news sentiment analysis, we\nuncover substantial variability in sentence-level sentiment classification\nresults, underscoring the innate volatility of LLM outputs. These uncertainties\ncascade downstream, leading to more significant variations in portfolio\nconstruction and return. While tweaking the temperature parameter in the\nlanguage model decoder presents a potential remedy, it comes at the expense of\nstifled creativity. Similarly, while ensembling multiple outputs mitigates the\neffect of volatile outputs, it demands a notable computational investment. This\nwork furnishes practitioners with invaluable insights for adeptly navigating\nuncertainty in the integration of LLMs into financial decision-making,\nparticularly in scenarios dictated by non-deterministic information.",
    "published": "2023-11-26T03:54:03Z",
    "pdf_url": "http://arxiv.org/pdf/2311.15180v1",
    "categories": [
      "q-fin.TR",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2403.00835v4",
    "title": "CLLMs: Consistency Large Language Models",
    "authors": [
      "Siqi Kou",
      "Lanxiang Hu",
      "Zhezhi He",
      "Zhijie Deng",
      "Hao Zhang"
    ],
    "abstract": "Parallel decoding methods such as Jacobi decoding show promise for more\nefficient LLM inference as it breaks the sequential nature of the LLM decoding\nprocess and transforms it into parallelizable computation. However, in\npractice, it achieves little speedup compared to traditional autoregressive\n(AR) decoding, primarily because Jacobi decoding seldom accurately predicts\nmore than one token in a single fixed-point iteration step. To address this, we\ndevelop a new approach aimed at realizing fast convergence from any state to\nthe fixed point on a Jacobi trajectory. This is accomplished by refining the\ntarget LLM to consistently predict the fixed point given any state as input.\nExtensive experiments demonstrate the effectiveness of our method, showing\n2.4$\\times$ to 3.4$\\times$ improvements in generation speed while preserving\ngeneration quality across both domain-specific and open-domain benchmarks.",
    "published": "2024-02-28T20:17:04Z",
    "pdf_url": "http://arxiv.org/pdf/2403.00835v4",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2407.05750v3",
    "title": "Large Language Models Understand Layout",
    "authors": [
      "Weiming Li",
      "Manni Duan",
      "Dong An",
      "Yan Shao"
    ],
    "abstract": "Large language models (LLMs) demonstrate extraordinary abilities in a wide\nrange of natural language processing (NLP) tasks. In this paper, we show that,\nbeyond text understanding capability, LLMs are capable of processing text\nlayouts that are denoted by spatial markers. They are able to answer questions\nthat require explicit spatial perceiving and reasoning, while a drastic\nperformance drop is observed when the spatial markers from the original data\nare excluded. We perform a series of experiments with the GPT-3.5, Baichuan2,\nLlama2 and ChatGLM3 models on various types of layout-sensitive datasets for\nfurther analysis. The experimental results reveal that the layout understanding\nability of LLMs is mainly introduced by the coding data for pretraining, which\nis further enhanced at the instruction-tuning stage. In addition, layout\nunderstanding can be enhanced by integrating low-cost, auto-generated data\napproached by a novel text game. Finally, we show that layout understanding\nability is beneficial for building efficient visual question-answering (VQA)\nsystems.",
    "published": "2024-07-08T09:03:12Z",
    "pdf_url": "http://arxiv.org/pdf/2407.05750v3",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2503.06709v1",
    "title": "Delusions of Large Language Models",
    "authors": [
      "Hongshen Xu",
      "Zixv yang",
      "Zichen Zhu",
      "Kunyao Lan",
      "Zihan Wang",
      "Mengyue Wu",
      "Ziwei Ji",
      "Lu Chen",
      "Pascale Fung",
      "Kai Yu"
    ],
    "abstract": "Large Language Models often generate factually incorrect but plausible\noutputs, known as hallucinations. We identify a more insidious phenomenon, LLM\ndelusion, defined as high belief hallucinations, incorrect outputs with\nabnormally high confidence, making them harder to detect and mitigate. Unlike\nordinary hallucinations, delusions persist with low uncertainty, posing\nsignificant challenges to model reliability. Through empirical analysis across\ndifferent model families and sizes on several Question Answering tasks, we show\nthat delusions are prevalent and distinct from hallucinations. LLMs exhibit\nlower honesty with delusions, which are harder to override via finetuning or\nself reflection. We link delusion formation with training dynamics and dataset\nnoise and explore mitigation strategies such as retrieval augmented generation\nand multi agent debating to mitigate delusions. By systematically investigating\nthe nature, prevalence, and mitigation of LLM delusions, our study provides\ninsights into the underlying causes of this phenomenon and outlines future\ndirections for improving model reliability.",
    "published": "2025-03-09T17:59:16Z",
    "pdf_url": "http://arxiv.org/pdf/2503.06709v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2410.12428v2",
    "title": "Conformity in Large Language Models",
    "authors": [
      "Xiaochen Zhu",
      "Caiqi Zhang",
      "Tom Stafford",
      "Nigel Collier",
      "Andreas Vlachos"
    ],
    "abstract": "The conformity effect describes the tendency of individuals to align their\nresponses with the majority. Studying this bias in large language models (LLMs)\nis crucial, as LLMs are increasingly used in various information-seeking and\ndecision-making tasks as conversation partners to improve productivity. Thus,\nconformity to incorrect responses can compromise their effectiveness. In this\npaper, we adapt psychological experiments to examine the extent of conformity\nin popular LLMs. Our findings reveal that all tested models exhibit varying\nlevels of conformity toward the majority, regardless of their initial choice or\ncorrectness, across different knowledge domains. Notably, we are the first to\nshow that LLMs are more likely to conform when they are more uncertain in their\nown prediction. We further explore factors that influence conformity, such as\ntraining paradigms and input characteristics, finding that instruction-tuned\nmodels are less susceptible to conformity, while increasing the naturalness of\nmajority tones amplifies conformity. Finally, we propose two interventions,\nDevil's Advocate and Question Distillation, to mitigate conformity, providing\ninsights into building more robust language models.",
    "published": "2024-10-16T10:16:34Z",
    "pdf_url": "http://arxiv.org/pdf/2410.12428v2",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2504.18085v1",
    "title": "Random-Set Large Language Models",
    "authors": [
      "Muhammad Mubashar",
      "Shireen Kudukkil Manchingal",
      "Fabio Cuzzolin"
    ],
    "abstract": "Large Language Models (LLMs) are known to produce very high-quality tests and\nresponses to our queries. But how much can we trust this generated text? In\nthis paper, we study the problem of uncertainty quantification in LLMs. We\npropose a novel Random-Set Large Language Model (RSLLM) approach which predicts\nfinite random sets (belief functions) over the token space, rather than\nprobability vectors as in classical LLMs. In order to allow so efficiently, we\nalso present a methodology based on hierarchical clustering to extract and use\na budget of \"focal\" subsets of tokens upon which the belief prediction is\ndefined, rather than using all possible collections of tokens, making the\nmethod scalable yet effective. RS-LLMs encode the epistemic uncertainty induced\nin their generation process by the size and diversity of its training set via\nthe size of the credal sets associated with the predicted belief functions. The\nproposed approach is evaluated on CoQA and OBQA datasets using Llama2-7b,\nMistral-7b and Phi-2 models and is shown to outperform the standard model in\nboth datasets in terms of correctness of answer while also showing potential in\nestimating the second level uncertainty in its predictions and providing the\ncapability to detect when its hallucinating.",
    "published": "2025-04-25T05:25:27Z",
    "pdf_url": "http://arxiv.org/pdf/2504.18085v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.7"
    ]
  },
  {
    "arxiv_id": "2306.08161v2",
    "title": "h2oGPT: Democratizing Large Language Models",
    "authors": [
      "Arno Candel",
      "Jon McKinney",
      "Philipp Singer",
      "Pascal Pfeiffer",
      "Maximilian Jeblick",
      "Prithvi Prabhu",
      "Jeff Gambera",
      "Mark Landry",
      "Shivam Bansal",
      "Ryan Chesler",
      "Chun Ming Lee",
      "Marcos V. Conde",
      "Pasha Stetsenko",
      "Olivier Grellier",
      "SriSatish Ambati"
    ],
    "abstract": "Applications built on top of Large Language Models (LLMs) such as GPT-4\nrepresent a revolution in AI due to their human-level capabilities in natural\nlanguage processing. However, they also pose many significant risks such as the\npresence of biased, private, or harmful text, and the unauthorized inclusion of\ncopyrighted material.\n  We introduce h2oGPT, a suite of open-source code repositories for the\ncreation and use of LLMs based on Generative Pretrained Transformers (GPTs).\nThe goal of this project is to create the world's best truly open-source\nalternative to closed-source approaches. In collaboration with and as part of\nthe incredible and unstoppable open-source community, we open-source several\nfine-tuned h2oGPT models from 7 to 40 Billion parameters, ready for commercial\nuse under fully permissive Apache 2.0 licenses. Included in our release is\n100\\% private document search using natural language.\n  Open-source language models help boost AI development and make it more\naccessible and trustworthy. They lower entry hurdles, allowing people and\ngroups to tailor these models to their needs. This openness increases\ninnovation, transparency, and fairness. An open-source strategy is needed to\nshare AI benefits fairly, and H2O.ai will continue to democratize AI and LLMs.",
    "published": "2023-06-13T22:19:53Z",
    "pdf_url": "http://arxiv.org/pdf/2306.08161v2",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.IR",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2309.03409v3",
    "title": "Large Language Models as Optimizers",
    "authors": [
      "Chengrun Yang",
      "Xuezhi Wang",
      "Yifeng Lu",
      "Hanxiao Liu",
      "Quoc V. Le",
      "Denny Zhou",
      "Xinyun Chen"
    ],
    "abstract": "Optimization is ubiquitous. While derivative-based algorithms have been\npowerful tools for various problems, the absence of gradient imposes challenges\non many real-world applications. In this work, we propose Optimization by\nPROmpting (OPRO), a simple and effective approach to leverage large language\nmodels (LLMs) as optimizers, where the optimization task is described in\nnatural language. In each optimization step, the LLM generates new solutions\nfrom the prompt that contains previously generated solutions with their values,\nthen the new solutions are evaluated and added to the prompt for the next\noptimization step. We first showcase OPRO on linear regression and traveling\nsalesman problems, then move on to our main application in prompt optimization,\nwhere the goal is to find instructions that maximize the task accuracy. With a\nvariety of LLMs, we demonstrate that the best prompts optimized by OPRO\noutperform human-designed prompts by up to 8% on GSM8K, and by up to 50% on\nBig-Bench Hard tasks. Code at https://github.com/google-deepmind/opro.",
    "published": "2023-09-07T00:07:15Z",
    "pdf_url": "http://arxiv.org/pdf/2309.03409v3",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2312.13951v1",
    "title": "Typhoon: Thai Large Language Models",
    "authors": [
      "Kunat Pipatanakul",
      "Phatrasek Jirabovonvisut",
      "Potsawee Manakul",
      "Sittipong Sripaisarnmongkol",
      "Ruangsak Patomwong",
      "Pathomporn Chokchainant",
      "Kasima Tharnpipitchai"
    ],
    "abstract": "Typhoon is a series of Thai large language models (LLMs) developed\nspecifically for the Thai language. This technical report presents challenges\nand insights in developing Thai LLMs, including data preparation, pretraining,\ninstruction-tuning, and evaluation. As one of the challenges of low-resource\nlanguages is the amount of pretraining data, we apply continual training to\ntransfer existing world knowledge from a strong LLM. To evaluate the Thai\nknowledge encapsulated in each model from the pretraining stage, we develop\nThaiExam, a benchmark based on examinations for high-school students and\ninvestment professionals in Thailand. In addition, we fine-tune Typhoon to\nfollow Thai instructions, and we evaluate instruction-tuned models on Thai\ninstruction datasets as well as translation, summarization, and\nquestion-answering tasks. Experimental results on a suite of Thai benchmarks\nshow that Typhoon outperforms all open-source Thai language models, and its\nperformance is on par with GPT-3.5 in Thai while having only 7 billion\nparameters and being 2.62 times more efficient in tokenizing Thai text.",
    "published": "2023-12-21T15:38:41Z",
    "pdf_url": "http://arxiv.org/pdf/2312.13951v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2402.18158v2",
    "title": "Evaluating Quantized Large Language Models",
    "authors": [
      "Shiyao Li",
      "Xuefei Ning",
      "Luning Wang",
      "Tengxuan Liu",
      "Xiangsheng Shi",
      "Shengen Yan",
      "Guohao Dai",
      "Huazhong Yang",
      "Yu Wang"
    ],
    "abstract": "Post-training quantization (PTQ) has emerged as a promising technique to\nreduce the cost of large language models (LLMs). Specifically, PTQ can\neffectively mitigate memory consumption and reduce computational overhead in\nLLMs. To meet the requirements of both high efficiency and performance across\ndiverse scenarios, a comprehensive evaluation of quantized LLMs is essential to\nguide the selection of quantization methods. This paper presents a thorough\nevaluation of these factors by evaluating the effect of PTQ on Weight,\nActivation, and KV Cache on 11 model families, including OPT, LLaMA2, Falcon,\nBloomz, Mistral, ChatGLM, Vicuna, LongChat, StableLM, Gemma, and Mamba, with\nparameters ranging from 125M to 180B. The evaluation encompasses five types of\ntasks: basic NLP, emergent ability, trustworthiness, dialogue, and long-context\ntasks. Moreover, we also evaluate the state-of-the-art (SOTA) quantization\nmethods to demonstrate their applicability. Based on the extensive experiments,\nwe systematically summarize the effect of quantization, provide recommendations\nto apply quantization techniques, and point out future directions. The code can\nbe found in https://github.com/thu-nics/qllm-eval.",
    "published": "2024-02-28T08:43:05Z",
    "pdf_url": "http://arxiv.org/pdf/2402.18158v2",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2406.07177v1",
    "title": "TernaryLLM: Ternarized Large Language Model",
    "authors": [
      "Tianqi Chen",
      "Zhe Li",
      "Weixiang Xu",
      "Zeyu Zhu",
      "Dong Li",
      "Lu Tian",
      "Emad Barsoum",
      "Peisong Wang",
      "Jian Cheng"
    ],
    "abstract": "Large language models (LLMs) have achieved remarkable performance on Natural\nLanguage Processing (NLP) tasks, but they are hindered by high computational\ncosts and memory requirements. Ternarization, an extreme form of quantization,\noffers a solution by reducing memory usage and enabling energy-efficient\nfloating-point additions. However, applying ternarization to LLMs faces\nchallenges stemming from outliers in both weights and activations. In this\nwork, observing asymmetric outliers and non-zero means in weights, we introduce\nDual Learnable Ternarization (DLT), which enables both scales and shifts to be\nlearnable. We also propose Outlier-Friendly Feature Knowledge Distillation\n(OFF) to recover the information lost in extremely low-bit quantization. The\nproposed OFF can incorporate semantic information and is insensitive to\noutliers. At the core of OFF is maximizing the mutual information between\nfeatures in ternarized and floating-point models using cosine similarity.\nExtensive experiments demonstrate that our TernaryLLM surpasses previous\nlow-bit quantization methods on the standard text generation and zero-shot\nbenchmarks for different LLM families. Specifically, for one of the most\npowerful open-source models, LLaMA-3, our approach (W1.58A16) outperforms the\nprevious state-of-the-art method (W2A16) by 5.8 in terms of perplexity on C4\nand by 8.2% in terms of average accuracy on zero-shot tasks.",
    "published": "2024-06-11T11:40:12Z",
    "pdf_url": "http://arxiv.org/pdf/2406.07177v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2205.12615v1",
    "title": "Autoformalization with Large Language Models",
    "authors": [
      "Yuhuai Wu",
      "Albert Q. Jiang",
      "Wenda Li",
      "Markus N. Rabe",
      "Charles Staats",
      "Mateja Jamnik",
      "Christian Szegedy"
    ],
    "abstract": "Autoformalization is the process of automatically translating from natural\nlanguage mathematics to formal specifications and proofs. A successful\nautoformalization system could advance the fields of formal verification,\nprogram synthesis, and artificial intelligence. While the long-term goal of\nautoformalization seemed elusive for a long time, we show large language models\nprovide new prospects towards this goal. We make the surprising observation\nthat LLMs can correctly translate a significant portion ($25.3\\%$) of\nmathematical competition problems perfectly to formal specifications in\nIsabelle/HOL. We demonstrate the usefulness of this process by improving a\npreviously introduced neural theorem prover via training on these\nautoformalized theorems. Our methodology results in a new state-of-the-art\nresult on the MiniF2F theorem proving benchmark, improving the proof rate from\n$29.6\\%$ to $35.2\\%$.",
    "published": "2022-05-25T09:53:30Z",
    "pdf_url": "http://arxiv.org/pdf/2205.12615v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.LO",
      "cs.SE"
    ]
  },
  {
    "arxiv_id": "2501.06271v1",
    "title": "Large Language Models for Bioinformatics",
    "authors": [
      "Wei Ruan",
      "Yanjun Lyu",
      "Jing Zhang",
      "Jiazhang Cai",
      "Peng Shu",
      "Yang Ge",
      "Yao Lu",
      "Shang Gao",
      "Yue Wang",
      "Peilong Wang",
      "Lin Zhao",
      "Tao Wang",
      "Yufang Liu",
      "Luyang Fang",
      "Ziyu Liu",
      "Zhengliang Liu",
      "Yiwei Li",
      "Zihao Wu",
      "Junhao Chen",
      "Hanqi Jiang",
      "Yi Pan",
      "Zhenyuan Yang",
      "Jingyuan Chen",
      "Shizhe Liang",
      "Wei Zhang",
      "Terry Ma",
      "Yuan Dou",
      "Jianli Zhang",
      "Xinyu Gong",
      "Qi Gan",
      "Yusong Zou",
      "Zebang Chen",
      "Yuanxin Qian",
      "Shuo Yu",
      "Jin Lu",
      "Kenan Song",
      "Xianqiao Wang",
      "Andrea Sikora",
      "Gang Li",
      "Xiang Li",
      "Quanzheng Li",
      "Yingfeng Wang",
      "Lu Zhang",
      "Yohannes Abate",
      "Lifang He",
      "Wenxuan Zhong",
      "Rongjie Liu",
      "Chao Huang",
      "Wei Liu",
      "Ye Shen",
      "Ping Ma",
      "Hongtu Zhu",
      "Yajun Yan",
      "Dajiang Zhu",
      "Tianming Liu"
    ],
    "abstract": "With the rapid advancements in large language model (LLM) technology and the\nemergence of bioinformatics-specific language models (BioLMs), there is a\ngrowing need for a comprehensive analysis of the current landscape,\ncomputational characteristics, and diverse applications. This survey aims to\naddress this need by providing a thorough review of BioLMs, focusing on their\nevolution, classification, and distinguishing features, alongside a detailed\nexamination of training methodologies, datasets, and evaluation frameworks. We\nexplore the wide-ranging applications of BioLMs in critical areas such as\ndisease diagnosis, drug discovery, and vaccine development, highlighting their\nimpact and transformative potential in bioinformatics. We identify key\nchallenges and limitations inherent in BioLMs, including data privacy and\nsecurity concerns, interpretability issues, biases in training data and model\noutputs, and domain adaptation complexities. Finally, we highlight emerging\ntrends and future directions, offering valuable insights to guide researchers\nand clinicians toward advancing BioLMs for increasingly sophisticated\nbiological and clinical applications.",
    "published": "2025-01-10T01:43:05Z",
    "pdf_url": "http://arxiv.org/pdf/2501.06271v1",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.CE"
    ]
  },
  {
    "arxiv_id": "2311.07484v3",
    "title": "Psychometric Predictive Power of Large Language Models",
    "authors": [
      "Tatsuki Kuribayashi",
      "Yohei Oseki",
      "Timothy Baldwin"
    ],
    "abstract": "Instruction tuning aligns the response of large language models (LLMs) with\nhuman preferences. Despite such efforts in human--LLM alignment, we find that\ninstruction tuning does not always make LLMs human-like from a cognitive\nmodeling perspective. More specifically, next-word probabilities estimated by\ninstruction-tuned LLMs are often worse at simulating human reading behavior\nthan those estimated by base LLMs. In addition, we explore prompting\nmethodologies for simulating human reading behavior with LLMs. Our results show\nthat prompts reflecting a particular linguistic hypothesis improve psychometric\npredictive power, but are still inferior to small base models. These findings\nhighlight that recent advancements in LLMs, i.e., instruction tuning and\nprompting, do not offer better estimates than direct probability measurements\nfrom base LLMs in cognitive modeling. In other words, pure next-word\nprobability remains a strong predictor for human reading behavior, even in the\nage of LLMs.",
    "published": "2023-11-13T17:19:14Z",
    "pdf_url": "http://arxiv.org/pdf/2311.07484v3",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2403.17688v2",
    "title": "Large Language Models Enhanced Collaborative Filtering",
    "authors": [
      "Zhongxiang Sun",
      "Zihua Si",
      "Xiaoxue Zang",
      "Kai Zheng",
      "Yang Song",
      "Xiao Zhang",
      "Jun Xu"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have attracted\nconsiderable interest among researchers to leverage these models to enhance\nRecommender Systems (RSs). Existing work predominantly utilizes LLMs to\ngenerate knowledge-rich texts or utilizes LLM-derived embeddings as features to\nimprove RSs. Although the extensive world knowledge embedded in LLMs generally\nbenefits RSs, the application can only take limited number of users and items\nas inputs, without adequately exploiting collaborative filtering information.\nConsidering its crucial role in RSs, one key challenge in enhancing RSs with\nLLMs lies in providing better collaborative filtering information through LLMs.\nIn this paper, drawing inspiration from the in-context learning and chain of\nthought reasoning in LLMs, we propose the Large Language Models enhanced\nCollaborative Filtering (LLM-CF) framework, which distils the world knowledge\nand reasoning capabilities of LLMs into collaborative filtering. We also\nexplored a concise and efficient instruction-tuning method, which improves the\nrecommendation capabilities of LLMs while preserving their general\nfunctionalities (e.g., not decreasing on the LLM benchmark). Comprehensive\nexperiments on three real-world datasets demonstrate that LLM-CF significantly\nenhances several backbone recommendation models and consistently outperforms\ncompetitive baselines, showcasing its effectiveness in distilling the world\nknowledge and reasoning capabilities of LLM into collaborative filtering.",
    "published": "2024-03-26T13:31:33Z",
    "pdf_url": "http://arxiv.org/pdf/2403.17688v2",
    "categories": [
      "cs.IR"
    ]
  },
  {
    "arxiv_id": "2401.07102v1",
    "title": "Evolving Code with A Large Language Model",
    "authors": [
      "Erik Hemberg",
      "Stephen Moskal",
      "Una-May O'Reilly"
    ],
    "abstract": "Algorithms that use Large Language Models (LLMs) to evolve code arrived on\nthe Genetic Programming (GP) scene very recently. We present LLM GP, a\nformalized LLM-based evolutionary algorithm designed to evolve code. Like GP,\nit uses evolutionary operators, but its designs and implementations of those\noperators radically differ from GP's because they enlist an LLM, using\nprompting and the LLM's pre-trained pattern matching and sequence completion\ncapability. We also present a demonstration-level variant of LLM GP and share\nits code. By addressing algorithms that range from the formal to hands-on, we\ncover design and LLM-usage considerations as well as the scientific challenges\nthat arise when using an LLM for genetic programming.",
    "published": "2024-01-13T15:57:54Z",
    "pdf_url": "http://arxiv.org/pdf/2401.07102v1",
    "categories": [
      "cs.NE",
      "cs.AI",
      "I.2.8"
    ]
  },
  {
    "arxiv_id": "2407.04307v1",
    "title": "Crafting Large Language Models for Enhanced Interpretability",
    "authors": [
      "Chung-En Sun",
      "Tuomas Oikarinen",
      "Tsui-Wei Weng"
    ],
    "abstract": "We introduce the Concept Bottleneck Large Language Model (CB-LLM), a\npioneering approach to creating inherently interpretable Large Language Models\n(LLMs). Unlike traditional black-box LLMs that rely on post-hoc interpretation\nmethods with limited neuron function insights, CB-LLM sets a new standard with\nits built-in interpretability, scalability, and ability to provide clear,\naccurate explanations. This innovation not only advances transparency in\nlanguage models but also enhances their effectiveness. Our unique Automatic\nConcept Correction (ACC) strategy successfully narrows the performance gap with\nconventional black-box LLMs, positioning CB-LLM as a model that combines the\nhigh accuracy of traditional LLMs with the added benefit of clear\ninterpretability -- a feature markedly absent in existing LLMs.",
    "published": "2024-07-05T07:22:44Z",
    "pdf_url": "http://arxiv.org/pdf/2407.04307v1",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2310.19736v3",
    "title": "Evaluating Large Language Models: A Comprehensive Survey",
    "authors": [
      "Zishan Guo",
      "Renren Jin",
      "Chuang Liu",
      "Yufei Huang",
      "Dan Shi",
      "Supryadi",
      "Linhao Yu",
      "Yan Liu",
      "Jiaxuan Li",
      "Bojian Xiong",
      "Deyi Xiong"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities across\na broad spectrum of tasks. They have attracted significant attention and been\ndeployed in numerous downstream applications. Nevertheless, akin to a\ndouble-edged sword, LLMs also present potential risks. They could suffer from\nprivate data leaks or yield inappropriate, harmful, or misleading content.\nAdditionally, the rapid progress of LLMs raises concerns about the potential\nemergence of superintelligent systems without adequate safeguards. To\neffectively capitalize on LLM capacities as well as ensure their safe and\nbeneficial development, it is critical to conduct a rigorous and comprehensive\nevaluation of LLMs.\n  This survey endeavors to offer a panoramic perspective on the evaluation of\nLLMs. We categorize the evaluation of LLMs into three major groups: knowledge\nand capability evaluation, alignment evaluation and safety evaluation. In\naddition to the comprehensive review on the evaluation methodologies and\nbenchmarks on these three aspects, we collate a compendium of evaluations\npertaining to LLMs' performance in specialized domains, and discuss the\nconstruction of comprehensive evaluation platforms that cover LLM evaluations\non capabilities, alignment, safety, and applicability.\n  We hope that this comprehensive overview will stimulate further research\ninterests in the evaluation of LLMs, with the ultimate goal of making\nevaluation serve as a cornerstone in guiding the responsible development of\nLLMs. We envision that this will channel their evolution into a direction that\nmaximizes societal benefit while minimizing potential risks. A curated list of\nrelated papers has been publicly available at\nhttps://github.com/tjunlp-lab/Awesome-LLMs-Evaluation-Papers.",
    "published": "2023-10-30T17:00:52Z",
    "pdf_url": "http://arxiv.org/pdf/2310.19736v3",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2407.14112v2",
    "title": "Large-Language-Model Enabled Semantic Communication Systems",
    "authors": [
      "Zhenyi Wang",
      "Li Zou",
      "Shengyun Wei",
      "Kai Li",
      "Feifan Liao",
      "Haibo Mi",
      "Rongxuan Lai"
    ],
    "abstract": "Large language models (LLMs) have recently demonstrated state-of-the-art\nperformance across various natural language processing (NLP) tasks, achieving\nnear-human levels in multiple language understanding challenges and aligning\nclosely with the core principles of semantic communication. Inspired by LLMs'\nadvancements in semantic processing, we propose an innovative LLM-enabled\nsemantic communication system framework, named LLM-SC, that applies LLMs\ndirectly to the physical layer coding and decoding for the first time. By\nanalyzing the relationship between the training process of LLMs and the\noptimization objectives of semantic communication, we propose training a\nsemantic encoder through LLMs' tokenizer training and establishing a semantic\nknowledge base via the LLMs' unsupervised pre-training process. This knowledge\nbase aids in constructing the optimal decoder by providing the prior\nprobability of the transmitted language sequence. Based on this foundation, we\nderive the optimal decoding criterion for the receiver and introduce the beam\nsearch algorithm to further reduce the complexity. Furthermore, we assert that\nexisting LLMs can be employed directly for LLM-SC without additional\nre-training or fine-tuning. Simulation results demonstrate that LLM-SC\noutperforms classical DeepSC at signal-to-noise ratios (SNR) exceeding 3 dB,\nenabling error-free transmission of semantic information under high SNR, which\nis unattainable by DeepSC. In addition to semantic-level performance, LLM-SC\ndemonstrates compatibility with technical-level performance, achieving\napproximately 8 dB coding gain for a bit error ratio (BER) of $10^{-3}$ without\nany channel coding while maintaining the same joint source-channel coding rate\nas traditional communication systems.",
    "published": "2024-07-19T08:29:23Z",
    "pdf_url": "http://arxiv.org/pdf/2407.14112v2",
    "categories": [
      "eess.SP"
    ]
  },
  {
    "arxiv_id": "2405.10098v1",
    "title": "When Large Language Model Meets Optimization",
    "authors": [
      "Sen Huang",
      "Kaixiang Yang",
      "Sheng Qi",
      "Rui Wang"
    ],
    "abstract": "Optimization algorithms and large language models (LLMs) enhance\ndecision-making in dynamic environments by integrating artificial intelligence\nwith traditional techniques. LLMs, with extensive domain knowledge, facilitate\nintelligent modeling and strategic decision-making in optimization, while\noptimization algorithms refine LLM architectures and output quality. This\nsynergy offers novel approaches for advancing general AI, addressing both the\ncomputational challenges of complex problems and the application of LLMs in\npractical scenarios. This review outlines the progress and potential of\ncombining LLMs with optimization algorithms, providing insights for future\nresearch directions.",
    "published": "2024-05-16T13:54:37Z",
    "pdf_url": "http://arxiv.org/pdf/2405.10098v1",
    "categories": [
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "2401.01735v1",
    "title": "Economics Arena for Large Language Models",
    "authors": [
      "Shangmin Guo",
      "Haoran Bu",
      "Haochuan Wang",
      "Yi Ren",
      "Dianbo Sui",
      "Yuming Shang",
      "Siting Lu"
    ],
    "abstract": "Large language models (LLMs) have been extensively used as the backbones for\ngeneral-purpose agents, and some economics literature suggest that LLMs are\ncapable of playing various types of economics games. Following these works, to\novercome the limitation of evaluating LLMs using static benchmarks, we propose\nto explore competitive games as an evaluation for LLMs to incorporate\nmulti-players and dynamicise the environment. By varying the game history\nrevealed to LLMs-based players, we find that most of LLMs are rational in that\nthey play strategies that can increase their payoffs, but not as rational as\nindicated by Nash Equilibria (NEs). Moreover, when game history are available,\ncertain types of LLMs, such as GPT-4, can converge faster to the NE strategies,\nwhich suggests higher rationality level in comparison to other models. In the\nmeantime, certain types of LLMs can win more often when game history are\navailable, and we argue that the winning rate reflects the reasoning ability\nwith respect to the strategies of other players. Throughout all our\nexperiments, we observe that the ability to strictly follow the game rules\ndescribed by natural languages also vary among the LLMs we tested. In this\nwork, we provide an economics arena for the LLMs research community as a\ndynamic simulation to test the above-mentioned abilities of LLMs, i.e.\nrationality, strategic reasoning ability, and instruction-following capability.",
    "published": "2024-01-03T13:18:24Z",
    "pdf_url": "http://arxiv.org/pdf/2401.01735v1",
    "categories": [
      "cs.GT"
    ]
  },
  {
    "arxiv_id": "2310.14540v3",
    "title": "Evaluating Spatial Understanding of Large Language Models",
    "authors": [
      "Yutaro Yamada",
      "Yihan Bao",
      "Andrew K. Lampinen",
      "Jungo Kasai",
      "Ilker Yildirim"
    ],
    "abstract": "Large language models (LLMs) show remarkable capabilities across a variety of\ntasks. Despite the models only seeing text in training, several recent studies\nsuggest that LLM representations implicitly capture aspects of the underlying\ngrounded concepts. Here, we explore LLM representations of a particularly\nsalient kind of grounded knowledge -- spatial relationships. We design\nnatural-language navigation tasks and evaluate the ability of LLMs, in\nparticular GPT-3.5-turbo, GPT-4, and Llama2 series models, to represent and\nreason about spatial structures. These tasks reveal substantial variability in\nLLM performance across different spatial structures, including square,\nhexagonal, and triangular grids, rings, and trees. In extensive error analysis,\nwe find that LLMs' mistakes reflect both spatial and non-spatial factors. These\nfindings suggest that LLMs appear to capture certain aspects of spatial\nstructure implicitly, but room for improvement remains.",
    "published": "2023-10-23T03:44:40Z",
    "pdf_url": "http://arxiv.org/pdf/2310.14540v3",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2405.13055v1",
    "title": "Large Language Models for Medicine: A Survey",
    "authors": [
      "Yanxin Zheng",
      "Wensheng Gan",
      "Zefeng Chen",
      "Zhenlian Qi",
      "Qian Liang",
      "Philip S. Yu"
    ],
    "abstract": "To address challenges in the digital economy's landscape of digital\nintelligence, large language models (LLMs) have been developed. Improvements in\ncomputational power and available resources have significantly advanced LLMs,\nallowing their integration into diverse domains for human life. Medical LLMs\nare essential application tools with potential across various medical\nscenarios. In this paper, we review LLM developments, focusing on the\nrequirements and applications of medical LLMs. We provide a concise overview of\nexisting models, aiming to explore advanced research directions and benefit\nresearchers for future medical applications. We emphasize the advantages of\nmedical LLMs in applications, as well as the challenges encountered during\ntheir development. Finally, we suggest directions for technical integration to\nmitigate challenges and potential research directions for the future of medical\nLLMs, aiming to meet the demands of the medical field better.",
    "published": "2024-05-20T02:32:26Z",
    "pdf_url": "http://arxiv.org/pdf/2405.13055v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "2406.05335v2",
    "title": "Critical Phase Transition in Large Language Models",
    "authors": [
      "Kai Nakaishi",
      "Yoshihiko Nishikawa",
      "Koji Hukushima"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated impressive performance. To\nunderstand their behaviors, we need to consider the fact that LLMs sometimes\nshow qualitative changes. The natural world also presents such changes called\nphase transitions, which are defined by singular, divergent statistical\nquantities. Therefore, an intriguing question is whether qualitative changes in\nLLMs are phase transitions. In this work, we have conducted extensive analysis\non texts generated by LLMs and suggested that a phase transition occurs in LLMs\nwhen varying the temperature parameter. Specifically, statistical quantities\nhave divergent properties just at the point between the low-temperature regime,\nwhere LLMs generate sentences with clear repetitive structures, and the\nhigh-temperature regime, where generated sentences are often incomprehensible.\nIn addition, critical behaviors near the phase transition point, such as a\npower-law decay of correlation and slow convergence toward the stationary\nstate, are similar to those in natural languages. Our results suggest a\nmeaningful analogy between LLMs and natural phenomena.",
    "published": "2024-06-08T03:37:05Z",
    "pdf_url": "http://arxiv.org/pdf/2406.05335v2",
    "categories": [
      "cond-mat.dis-nn",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2409.19450v2",
    "title": "Secret Use of Large Language Model (LLM)",
    "authors": [
      "Zhiping Zhang",
      "Chenxinran Shen",
      "Bingsheng Yao",
      "Dakuo Wang",
      "Tianshi Li"
    ],
    "abstract": "The advancements of Large Language Models (LLMs) have decentralized the\nresponsibility for the transparency of AI usage. Specifically, LLM users are\nnow encouraged or required to disclose the use of LLM-generated content for\nvaried types of real-world tasks. However, an emerging phenomenon, users'\nsecret use of LLM, raises challenges in ensuring end users adhere to the\ntransparency requirement. Our study used mixed-methods with an exploratory\nsurvey (125 real-world secret use cases reported) and a controlled experiment\namong 300 users to investigate the contexts and causes behind the secret use of\nLLMs. We found that such secretive behavior is often triggered by certain\ntasks, transcending demographic and personality differences among users. Task\ntypes were found to affect users' intentions to use secretive behavior,\nprimarily through influencing perceived external judgment regarding LLM usage.\nOur results yield important insights for future work on designing interventions\nto encourage more transparent disclosure of the use of LLMs or other AI\ntechnologies.",
    "published": "2024-09-28T20:31:53Z",
    "pdf_url": "http://arxiv.org/pdf/2409.19450v2",
    "categories": [
      "cs.HC",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2412.10606v2",
    "title": "Do Large Language Models Speak Scientific Workflows?",
    "authors": [
      "Orcun Yildiz",
      "Tom Peterka"
    ],
    "abstract": "With the advent of large language models (LLMs), there is a growing interest\nin applying LLMs to scientific tasks. In this work, we conduct an experimental\nstudy to explore applicability of LLMs for configuring, annotating,\ntranslating, explaining, and generating scientific workflows. We use 5\ndifferent workflow specific experiments and evaluate several open- and\nclosed-source language models using state-of-the-art workflow systems. Our\nstudies reveal that LLMs often struggle with workflow related tasks due to\ntheir lack of knowledge of scientific workflows. We further observe that the\nperformance of LLMs varies across experiments and workflow systems. Our\nfindings can help workflow developers and users in understanding LLMs\ncapabilities in scientific workflows, and motivate further research applying\nLLMs to workflows.",
    "published": "2024-12-13T23:19:21Z",
    "pdf_url": "http://arxiv.org/pdf/2412.10606v2",
    "categories": [
      "cs.HC"
    ]
  },
  {
    "arxiv_id": "2311.08398v2",
    "title": "Are Large Language Models Temporally Grounded?",
    "authors": [
      "Yifu Qiu",
      "Zheng Zhao",
      "Yftah Ziser",
      "Anna Korhonen",
      "Edoardo M. Ponti",
      "Shay B. Cohen"
    ],
    "abstract": "Are Large language models (LLMs) temporally grounded? Since LLMs cannot\nperceive and interact with the environment, it is impossible to answer this\nquestion directly. Instead, we provide LLMs with textual narratives and probe\nthem with respect to their common-sense knowledge of the structure and duration\nof events, their ability to order events along a timeline, and self-consistency\nwithin their temporal model (e.g., temporal relations such as after and before\nare mutually exclusive for any pair of events). We evaluate state-of-the-art\nLLMs (such as LLaMA 2 and GPT-4) on three tasks reflecting these abilities.\nGenerally, we find that LLMs lag significantly behind both human performance as\nwell as small-scale, specialised LMs. In-context learning, instruction tuning,\nand chain-of-thought prompting reduce this gap only to a limited degree.\nCrucially, LLMs struggle the most with self-consistency, displaying incoherent\nbehaviour in at least 27.23% of their predictions. Contrary to expectations, we\nalso find that scaling the model size does not guarantee positive gains in\nperformance. To explain these results, we study the sources from which LLMs may\ngather temporal information: we find that sentence ordering in unlabelled\ntexts, available during pre-training, is only weakly correlated with event\nordering. Moreover, public instruction tuning mixtures contain few temporal\ntasks. Hence, we conclude that current LLMs lack a consistent temporal model of\ntextual narratives. Code, datasets, and LLM outputs are available at\nhttps://github.com/yfqiu-nlp/temporal-llms.",
    "published": "2023-11-14T18:57:15Z",
    "pdf_url": "http://arxiv.org/pdf/2311.08398v2",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2401.10491v2",
    "title": "Knowledge Fusion of Large Language Models",
    "authors": [
      "Fanqi Wan",
      "Xinting Huang",
      "Deng Cai",
      "Xiaojun Quan",
      "Wei Bi",
      "Shuming Shi"
    ],
    "abstract": "While training large language models (LLMs) from scratch can generate models\nwith distinct functionalities and strengths, it comes at significant costs and\nmay result in redundant capabilities. Alternatively, a cost-effective and\ncompelling approach is to merge existing pre-trained LLMs into a more potent\nmodel. However, due to the varying architectures of these LLMs, directly\nblending their weights is impractical. In this paper, we introduce the notion\nof knowledge fusion for LLMs, aimed at combining the capabilities of existing\nLLMs and transferring them into a single LLM. By leveraging the generative\ndistributions of source LLMs, we externalize their collective knowledge and\nunique strengths, thereby potentially elevating the capabilities of the target\nmodel beyond those of any individual source LLM. We validate our approach using\nthree popular LLMs with different architectures--Llama-2, MPT, and\nOpenLLaMA--across various benchmarks and tasks. Our findings confirm that the\nfusion of LLMs can improve the performance of the target model across a range\nof capabilities such as reasoning, commonsense, and code generation. Our code,\nmodel weights, and data are public at\n\\url{https://github.com/fanqiwan/FuseLLM}.",
    "published": "2024-01-19T05:02:46Z",
    "pdf_url": "http://arxiv.org/pdf/2401.10491v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2404.17785v4",
    "title": "Temporal Scaling Law for Large Language Models",
    "authors": [
      "Yizhe Xiong",
      "Xiansheng Chen",
      "Xin Ye",
      "Hui Chen",
      "Zijia Lin",
      "Haoran Lian",
      "Zhenpeng Su",
      "Wei Huang",
      "Jianwei Niu",
      "Jungong Han",
      "Guiguang Ding"
    ],
    "abstract": "Recently, Large Language Models (LLMs) have been widely adopted in a wide\nrange of tasks, leading to increasing attention towards the research on how\nscaling LLMs affects their performance. Existing works, termed Scaling Laws,\nhave discovered that the final test loss of LLMs scales as power-laws with\nmodel size, computational budget, and dataset size. However, the temporal\nchange of the test loss of an LLM throughout its pre-training process remains\nunexplored, though it is valuable in many aspects, such as selecting better\nhyperparameters \\textit{directly} on the target LLM. In this paper, we propose\nthe novel concept of Temporal Scaling Law, studying how the test loss of an LLM\nevolves as the training steps scale up. In contrast to modeling the test loss\nas a whole in a coarse-grained manner, we break it down and dive into the\nfine-grained test loss of each token position, and further develop a dynamic\nhyperbolic-law. Afterwards, we derive the much more precise temporal scaling\nlaw by studying the temporal patterns of the parameters in the dynamic\nhyperbolic-law. Results on both in-distribution (ID) and out-of-distribution\n(OOD) validation datasets demonstrate that our temporal scaling law accurately\npredicts the test loss of LLMs across training steps. Our temporal scaling law\nhas broad practical applications. First, it enables direct and efficient\nhyperparameter selection on the target LLM, such as data mixture proportions.\nSecondly, viewing the LLM pre-training dynamics from the token position\ngranularity provides some insights to enhance the understanding of LLM\npre-training.",
    "published": "2024-04-27T05:49:11Z",
    "pdf_url": "http://arxiv.org/pdf/2404.17785v4",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2502.01118v1",
    "title": "Large Language Model-Enhanced Multi-Armed Bandits",
    "authors": [
      "Jiahang Sun",
      "Zhiyong Wang",
      "Runhan Yang",
      "Chenjun Xiao",
      "John C. S. Lui",
      "Zhongxiang Dai"
    ],
    "abstract": "Large language models (LLMs) have been adopted to solve sequential\ndecision-making tasks such as multi-armed bandits (MAB), in which an LLM is\ndirectly instructed to select the arms to pull in every iteration. However,\nthis paradigm of direct arm selection using LLMs has been shown to be\nsuboptimal in many MAB tasks. Therefore, we propose an alternative approach\nwhich combines the strengths of classical MAB and LLMs. Specifically, we adopt\na classical MAB algorithm as the high-level framework and leverage the strong\nin-context learning capability of LLMs to perform the sub-task of reward\nprediction. Firstly, we incorporate the LLM-based reward predictor into the\nclassical Thompson sampling (TS) algorithm and adopt a decaying schedule for\nthe LLM temperature to ensure a transition from exploration to exploitation.\nNext, we incorporate the LLM-based reward predictor (with a temperature of 0)\ninto a regression oracle-based MAB algorithm equipped with an explicit\nexploration mechanism. We also extend our TS-based algorithm to dueling bandits\nwhere only the preference feedback between pairs of arms is available, which\nrequires non-trivial algorithmic modifications. We conduct empirical\nevaluations using both synthetic MAB tasks and experiments designed using\nreal-world text datasets, in which the results show that our algorithms\nconsistently outperform previous baseline methods based on direct arm\nselection. Interestingly, we also demonstrate that in challenging tasks where\nthe arms lack semantic meanings that can be exploited by the LLM, our approach\nachieves considerably better performance than LLM-based direct arm selection.",
    "published": "2025-02-03T07:19:05Z",
    "pdf_url": "http://arxiv.org/pdf/2502.01118v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2502.17129v1",
    "title": "Thus Spake Long-Context Large Language Model",
    "authors": [
      "Xiaoran Liu",
      "Ruixiao Li",
      "Mianqiu Huang",
      "Zhigeng Liu",
      "Yuerong Song",
      "Qipeng Guo",
      "Siyang He",
      "Qiqi Wang",
      "Linlin Li",
      "Qun Liu",
      "Yaqian Zhou",
      "Xuanjing Huang",
      "Xipeng Qiu"
    ],
    "abstract": "Long context is an important topic in Natural Language Processing (NLP),\nrunning through the development of NLP architectures, and offers immense\nopportunities for Large Language Models (LLMs) giving LLMs the lifelong\nlearning potential akin to humans. Unfortunately, the pursuit of a long context\nis accompanied by numerous obstacles. Nevertheless, long context remains a core\ncompetitive advantage for LLMs. In the past two years, the context length of\nLLMs has achieved a breakthrough extension to millions of tokens. Moreover, the\nresearch on long-context LLMs has expanded from length extrapolation to a\ncomprehensive focus on architecture, infrastructure, training, and evaluation\ntechnologies.\n  Inspired by the symphonic poem, Thus Spake Zarathustra, we draw an analogy\nbetween the journey of extending the context of LLM and the attempts of humans\nto transcend its mortality. In this survey, We will illustrate how LLM\nstruggles between the tremendous need for a longer context and its equal need\nto accept the fact that it is ultimately finite. To achieve this, we give a\nglobal picture of the lifecycle of long-context LLMs from four perspectives:\narchitecture, infrastructure, training, and evaluation, showcasing the full\nspectrum of long-context technologies. At the end of this survey, we will\npresent 10 unanswered questions currently faced by long-context LLMs. We hope\nthis survey can serve as a systematic introduction to the research on\nlong-context LLMs.",
    "published": "2025-02-24T13:19:33Z",
    "pdf_url": "http://arxiv.org/pdf/2502.17129v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2505.13205v2",
    "title": "Quantum Knowledge Distillation for Large Language Models",
    "authors": [
      "Lingxiao Li",
      "Yihao Wang",
      "Jiacheng Fan",
      "Jing Li",
      "Sujuan Qin",
      "Qiaoyan Wen",
      "Fei Gao"
    ],
    "abstract": "As foundational tools in natural language processing, Large Language Models\n(LLMs) have immense parameter scales, which makes deployment and inference\nincreasingly prohibitive, especially in resource-constrained devices.\nTherefore, knowledge distillation for LLMs, i.e., compressing the LLM to a\nsmaller model, is meaningful. With strong parameter representation capacity,\nquantum computing is regarded as a promising solution. Here, we propose a\nQuantum knowledge Distillation model for LLMs (QD-LLM) that leverages\nvariational quantum circuits to learn from LLMs. In classical simulation,\nQD-LLM outperforms several mainstream distillation methods on multiple text\nclassification tasks in terms of both accuracy and efficiency using only 11\nqubits. The results reveal an interesting phenomenon that the simulation of\nquantum student models may be regarded as a new class of quantum-inspired\nclassical algorithms. Remarkably, we deploy the obtained circuits on the Baihua\nsuperconducting quantum processor via the Quafu platform to assess practical\nfeasibility. The model maintains stable inference performance despite hardware\nconstraints such as decoherence and finite sampling. In summary, QD-LLM marks a\nfoundational step in connecting quantum computing with LLMs, demonstrating the\nfeasibility of quantum-native approaches that aim to compress and deploy models\nof increasingly larger scales. The code of this article has been open-sourced\nat https://github.com/Lilingxiao-bupt/QD-LLM.",
    "published": "2025-05-19T14:56:24Z",
    "pdf_url": "http://arxiv.org/pdf/2505.13205v2",
    "categories": [
      "quant-ph"
    ]
  },
  {
    "arxiv_id": "2506.01042v2",
    "title": "Probing Neural Topology of Large Language Models",
    "authors": [
      "Yu Zheng",
      "Yuan Yuan",
      "Yue Zhuo",
      "Yong Li",
      "Paolo Santi"
    ],
    "abstract": "Probing large language models (LLMs) has yielded valuable insights into their\ninternal mechanisms by linking neural activations to interpretable semantics.\nHowever, the complex mechanisms that link neuron's functional co-activation\nwith the emergent model capabilities remains largely unknown, hindering a\ndeeper understanding and safer development of LLMs. In this work, we introduce\ngraph probing, a method for uncovering the functional connectivity of LLM\nneurons and relating it to language generation performance. By probing models\nacross diverse LLM families and scales, we discover a universal predictability\nof next-token prediction performance using only neural topology, which persists\neven when retaining just 1% of neuron connections. Strikingly, probing on\ntopology outperforms probing on activation by up to 130.4%, suggesting that\nneural topology contains orders of richer information of LLM performance than\nneural activation, which can be easily extracted with simple linear or MLP\nprobes. To explain the dependence between neural topology and language\nperformance, we identify default networks and hub neurons in LLMs and provide\ncausal evidence by interventional experiments on multiple benchmarks, showing\nthat LLMs actually exploit these topological information. Further analyses\nsuggest that neural topology can be effectively leveraged to improve the\nefficiency, reliability, and safety of LLMs through proof-of-concept\napplications in model pruning, hallucination detection, and LLM fingerprinting.\nCodes and data for the graph probing toolbox are available at\nhttps://github.com/DavyMorgan/llm-graph-probing.",
    "published": "2025-06-01T14:57:03Z",
    "pdf_url": "http://arxiv.org/pdf/2506.01042v2",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2506.05725v1",
    "title": "Large Language Models are Good Relational Learners",
    "authors": [
      "Fang Wu",
      "Vijay Prakash Dwivedi",
      "Jure Leskovec"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities across\nvarious domains, yet their application to relational deep learning (RDL)\nremains underexplored. Existing approaches adapt LLMs by traversing relational\nlinks between entities in a database and converting the structured data into\nflat text documents. Still, this text-based serialization disregards critical\nrelational structures, introduces redundancy, and often exceeds standard LLM\ncontext lengths. We introduce Rel-LLM, a novel architecture that utilizes a\ngraph neural network (GNN)- based encoder to generate structured relational\nprompts for LLMs within a retrieval-augmented generation (RAG) framework.\nUnlike traditional text-based serialization approaches, our method preserves\nthe inherent relational structure of databases while enabling LLMs to\neffectively process and reason over complex entity relationships. Specifically,\nthe GNN encoder extracts a local subgraph around an entity to build feature\nrepresentations that contain relevant entity relationships and temporal\ndependencies. These representations are transformed into structured prompts\nusing a denormalization process, effectively allowing the LLM to reason over\nrelational structures. Through extensive experiments, we demonstrate that\nRel-LLM outperforms existing methods on key RDL tasks, offering a scalable and\nefficient approach to integrating LLMs with structured data sources. Code is\navailable at https://github.com/smiles724/Rel-LLM.",
    "published": "2025-06-06T04:07:55Z",
    "pdf_url": "http://arxiv.org/pdf/2506.05725v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2305.18456v1",
    "title": "Baselines for Identifying Watermarked Large Language Models",
    "authors": [
      "Leonard Tang",
      "Gavin Uberti",
      "Tom Shlomi"
    ],
    "abstract": "We consider the emerging problem of identifying the presence and use of\nwatermarking schemes in widely used, publicly hosted, closed source large\nlanguage models (LLMs). We introduce a suite of baseline algorithms for\nidentifying watermarks in LLMs that rely on analyzing distributions of output\ntokens and logits generated by watermarked and unmarked LLMs. Notably,\nwatermarked LLMs tend to produce distributions that diverge qualitatively and\nidentifiably from standard models. Furthermore, we investigate the\nidentifiability of watermarks at varying strengths and consider the tradeoffs\nof each of our identification mechanisms with respect to watermarking scenario.\nAlong the way, we formalize the specific problem of identifying watermarks in\nLLMs, as well as LLM watermarks and watermark detection in general, providing a\nframework and foundations for studying them.",
    "published": "2023-05-29T04:26:16Z",
    "pdf_url": "http://arxiv.org/pdf/2305.18456v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "2210.11610v2",
    "title": "Large Language Models Can Self-Improve",
    "authors": [
      "Jiaxin Huang",
      "Shixiang Shane Gu",
      "Le Hou",
      "Yuexin Wu",
      "Xuezhi Wang",
      "Hongkun Yu",
      "Jiawei Han"
    ],
    "abstract": "Large Language Models (LLMs) have achieved excellent performances in various\ntasks. However, fine-tuning an LLM requires extensive supervision. Human, on\nthe other hand, may improve their reasoning abilities by self-thinking without\nexternal inputs. In this work, we demonstrate that an LLM is also capable of\nself-improving with only unlabeled datasets. We use a pre-trained LLM to\ngenerate \"high-confidence\" rationale-augmented answers for unlabeled questions\nusing Chain-of-Thought prompting and self-consistency, and fine-tune the LLM\nusing those self-generated solutions as target outputs. We show that our\napproach improves the general reasoning ability of a 540B-parameter LLM\n(74.4%->82.1% on GSM8K, 78.2%->83.0% on DROP, 90.0%->94.4% on OpenBookQA, and\n63.4%->67.9% on ANLI-A3) and achieves state-of-the-art-level performance,\nwithout any ground truth label. We conduct ablation studies and show that\nfine-tuning on reasoning is critical for self-improvement.",
    "published": "2022-10-20T21:53:54Z",
    "pdf_url": "http://arxiv.org/pdf/2210.11610v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2307.00524v1",
    "title": "Large Language Models Enable Few-Shot Clustering",
    "authors": [
      "Vijay Viswanathan",
      "Kiril Gashteovski",
      "Carolin Lawrence",
      "Tongshuang Wu",
      "Graham Neubig"
    ],
    "abstract": "Unlike traditional unsupervised clustering, semi-supervised clustering allows\nusers to provide meaningful structure to the data, which helps the clustering\nalgorithm to match the user's intent. Existing approaches to semi-supervised\nclustering require a significant amount of feedback from an expert to improve\nthe clusters. In this paper, we ask whether a large language model can amplify\nan expert's guidance to enable query-efficient, few-shot semi-supervised text\nclustering. We show that LLMs are surprisingly effective at improving\nclustering. We explore three stages where LLMs can be incorporated into\nclustering: before clustering (improving input features), during clustering (by\nproviding constraints to the clusterer), and after clustering (using LLMs\npost-correction). We find incorporating LLMs in the first two stages can\nroutinely provide significant improvements in cluster quality, and that LLMs\nenable a user to make trade-offs between cost and accuracy to produce desired\nclusters. We release our code and LLM prompts for the public to use.",
    "published": "2023-07-02T09:17:11Z",
    "pdf_url": "http://arxiv.org/pdf/2307.00524v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2310.05204v3",
    "title": "Towards Optimizing with Large Language Models",
    "authors": [
      "Pei-Fu Guo",
      "Ying-Hsuan Chen",
      "Yun-Da Tsai",
      "Shou-De Lin"
    ],
    "abstract": "In this work, we conduct an assessment of the optimization capabilities of\nLLMs across various tasks and data sizes. Each of these tasks corresponds to\nunique optimization domains, and LLMs are required to execute these tasks with\ninteractive prompting. That is, in each optimization step, the LLM generates\nnew solutions from the past generated solutions with their values, and then the\nnew solutions are evaluated and considered in the next optimization step.\nAdditionally, we introduce three distinct metrics for a comprehensive\nassessment of task performance from various perspectives. These metrics offer\nthe advantage of being applicable for evaluating LLM performance across a broad\nspectrum of optimization tasks and are less sensitive to variations in test\nsamples. By applying these metrics, we observe that LLMs exhibit strong\noptimization capabilities when dealing with small-sized samples. However, their\nperformance is significantly influenced by factors like data size and values,\nunderscoring the importance of further research in the domain of optimization\ntasks for LLMs.",
    "published": "2023-10-08T15:35:00Z",
    "pdf_url": "http://arxiv.org/pdf/2310.05204v3",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2311.01866v1",
    "title": "Towards Concept-Aware Large Language Models",
    "authors": [
      "Chen Shani",
      "Jilles Vreeken",
      "Dafna Shahaf"
    ],
    "abstract": "Concepts play a pivotal role in various human cognitive functions, including\nlearning, reasoning and communication. However, there is very little work on\nendowing machines with the ability to form and reason with concepts. In\nparticular, state-of-the-art large language models (LLMs) work at the level of\ntokens, not concepts.\n  In this work, we analyze how well contemporary LLMs capture human concepts\nand their structure. We then discuss ways to develop concept-aware LLMs, taking\nplace at different stages of the pipeline. We sketch a method for pretraining\nLLMs using concepts, and also explore the simpler approach that uses the output\nof existing LLMs. Despite its simplicity, our proof-of-concept is shown to\nbetter match human intuition, as well as improve the robustness of predictions.\nThese preliminary results underscore the promise of concept-aware LLMs.",
    "published": "2023-11-03T12:19:22Z",
    "pdf_url": "http://arxiv.org/pdf/2311.01866v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2311.08838v2",
    "title": "Disinformation Capabilities of Large Language Models",
    "authors": [
      "Ivan Vykopal",
      "Matúš Pikuliak",
      "Ivan Srba",
      "Robert Moro",
      "Dominik Macko",
      "Maria Bielikova"
    ],
    "abstract": "Automated disinformation generation is often listed as an important risk\nassociated with large language models (LLMs). The theoretical ability to flood\nthe information space with disinformation content might have dramatic\nconsequences for societies around the world. This paper presents a\ncomprehensive study of the disinformation capabilities of the current\ngeneration of LLMs to generate false news articles in the English language. In\nour study, we evaluated the capabilities of 10 LLMs using 20 disinformation\nnarratives. We evaluated several aspects of the LLMs: how good they are at\ngenerating news articles, how strongly they tend to agree or disagree with the\ndisinformation narratives, how often they generate safety warnings, etc. We\nalso evaluated the abilities of detection models to detect these articles as\nLLM-generated. We conclude that LLMs are able to generate convincing news\narticles that agree with dangerous disinformation narratives.",
    "published": "2023-11-15T10:25:30Z",
    "pdf_url": "http://arxiv.org/pdf/2311.08838v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2402.01719v3",
    "title": "Measuring Moral Inconsistencies in Large Language Models",
    "authors": [
      "Vamshi Krishna Bonagiri",
      "Sreeram Vennam",
      "Manas Gaur",
      "Ponnurangam Kumaraguru"
    ],
    "abstract": "A Large Language Model (LLM) is considered consistent if semantically\nequivalent prompts produce semantically equivalent responses. Despite recent\nadvancements showcasing the impressive capabilities of LLMs in conversational\nsystems, we show that even state-of-the-art LLMs are highly inconsistent in\ntheir generations, questioning their reliability. Prior research has tried to\nmeasure this with task-specific accuracy. However, this approach is unsuitable\nfor moral scenarios, such as the trolley problem, with no \"correct\" answer. To\naddress this issue, we propose a novel information-theoretic measure called\nSemantic Graph Entropy (SGE) to measure the consistency of an LLM in moral\nscenarios. We leverage \"Rules of Thumb\" (RoTs) to explain a model's\ndecision-making strategies and further enhance our metric. Compared to existing\nconsistency metrics, SGE correlates better with human judgments across five\nLLMs. In the future, we aim to investigate the root causes of LLM\ninconsistencies and propose improvements.",
    "published": "2024-01-26T18:05:47Z",
    "pdf_url": "http://arxiv.org/pdf/2402.01719v3",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2404.01475v2",
    "title": "Are large language models superhuman chemists?",
    "authors": [
      "Adrian Mirza",
      "Nawaf Alampara",
      "Sreekanth Kunchapu",
      "Martiño Ríos-García",
      "Benedict Emoekabu",
      "Aswanth Krishnan",
      "Tanya Gupta",
      "Mara Schilling-Wilhelmi",
      "Macjonathan Okereke",
      "Anagha Aneesh",
      "Amir Mohammad Elahi",
      "Mehrdad Asgari",
      "Juliane Eberhardt",
      "Hani M. Elbeheiry",
      "María Victoria Gil",
      "Maximilian Greiner",
      "Caroline T. Holick",
      "Christina Glaubitz",
      "Tim Hoffmann",
      "Abdelrahman Ibrahim",
      "Lea C. Klepsch",
      "Yannik Köster",
      "Fabian Alexander Kreth",
      "Jakob Meyer",
      "Santiago Miret",
      "Jan Matthias Peschel",
      "Michael Ringleb",
      "Nicole Roesner",
      "Johanna Schreiber",
      "Ulrich S. Schubert",
      "Leanne M. Stafast",
      "Dinga Wonanke",
      "Michael Pieler",
      "Philippe Schwaller",
      "Kevin Maik Jablonka"
    ],
    "abstract": "Large language models (LLMs) have gained widespread interest due to their\nability to process human language and perform tasks on which they have not been\nexplicitly trained.\n  However, we possess only a limited systematic understanding of the chemical\ncapabilities of LLMs, which would be required to improve models and mitigate\npotential harm. Here, we introduce \"ChemBench,\" an automated framework for\nevaluating the chemical knowledge and reasoning abilities of state-of-the-art\nLLMs against the expertise of chemists.\n  We curated more than 2,700 question-answer pairs, evaluated leading open- and\nclosed-source LLMs, and found that the best models outperformed the best human\nchemists in our study on average. However, the models struggle with some basic\ntasks and provide overconfident predictions.\n  These findings reveal LLMs' impressive chemical capabilities while\nemphasizing the need for further research to improve their safety and\nusefulness. They also suggest adapting chemistry education and show the value\nof benchmarking frameworks for evaluating LLMs in specific domains.",
    "published": "2024-04-01T20:56:25Z",
    "pdf_url": "http://arxiv.org/pdf/2404.01475v2",
    "categories": [
      "cs.LG",
      "cond-mat.mtrl-sci",
      "cs.AI",
      "physics.chem-ph"
    ]
  },
  {
    "arxiv_id": "2405.06808v2",
    "title": "Large Language Model in Financial Regulatory Interpretation",
    "authors": [
      "Zhiyu Cao",
      "Zachary Feinstein"
    ],
    "abstract": "This study explores the innovative use of Large Language Models (LLMs) as\nanalytical tools for interpreting complex financial regulations. The primary\nobjective is to design effective prompts that guide LLMs in distilling verbose\nand intricate regulatory texts, such as the Basel III capital requirement\nregulations, into a concise mathematical framework that can be subsequently\ntranslated into actionable code. This novel approach aims to streamline the\nimplementation of regulatory mandates within the financial reporting and risk\nmanagement systems of global banking institutions. A case study was conducted\nto assess the performance of various LLMs, demonstrating that GPT-4 outperforms\nother models in processing and collecting necessary information, as well as\nexecuting mathematical calculations. The case study utilized numerical\nsimulations with asset holdings -- including fixed income, equities, currency\npairs, and commodities -- to demonstrate how LLMs can effectively implement the\nBasel III capital adequacy requirements.\n  Keywords: Large Language Models, Prompt Engineering, LLMs in Finance, Basel\nIII, Minimum Capital Requirements, LLM Ethics",
    "published": "2024-05-10T20:45:40Z",
    "pdf_url": "http://arxiv.org/pdf/2405.06808v2",
    "categories": [
      "q-fin.RM",
      "cs.AI",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2407.19807v2",
    "title": "Cool-Fusion: Fuse Large Language Models without Training",
    "authors": [
      "Cong Liu",
      "Xiaojun Quan",
      "Yan Pan",
      "Liang Lin",
      "Weigang Wu",
      "Xu Chen"
    ],
    "abstract": "We focus on the problem of fusing two or more heterogeneous large language\nmodels (LLMs) to leverage their complementary strengths. One of the challenges\nof model fusion is high computational load, specifically in fine-tuning or\naligning vocabularies. To address this, we propose Cool-Fusion, a simple yet\neffective approach that fuses the knowledge of source LLMs, which does not\nrequire training. Unlike ensemble methods, Cool-Fusion is applicable to any set\nof source LLMs that have different vocabularies. To overcome the vocabulary\ndiscrepancies among LLMs, we ensemble LLMs on text level, allowing them to\nrerank the generated texts by each other with different granularities.\nExtensive experiments have been conducted across a variety of benchmark\ndatasets. On GSM8K, Cool-Fusion increases accuracy from three strong source\nLLMs by a significant margin of 17.4\\%.",
    "published": "2024-07-29T09:02:19Z",
    "pdf_url": "http://arxiv.org/pdf/2407.19807v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2408.14380v1",
    "title": "Probing Causality Manipulation of Large Language Models",
    "authors": [
      "Chenyang Zhang",
      "Haibo Tong",
      "Bin Zhang",
      "Dongyu Zhang"
    ],
    "abstract": "Large language models (LLMs) have shown various ability on natural language\nprocessing, including problems about causality. It is not intuitive for LLMs to\ncommand causality, since pretrained models usually work on statistical\nassociations, and do not focus on causes and effects in sentences. So that\nprobing internal manipulation of causality is necessary for LLMs. This paper\nproposes a novel approach to probe causality manipulation hierarchically, by\nproviding different shortcuts to models and observe behaviors. We exploit\nretrieval augmented generation (RAG) and in-context learning (ICL) for models\non a designed causality classification task. We conduct experiments on\nmainstream LLMs, including GPT-4 and some smaller and domain-specific models.\nOur results suggest that LLMs can detect entities related to causality and\nrecognize direct causal relationships. However, LLMs lack specialized cognition\nfor causality, merely treating them as part of the global semantic of the\nsentence.",
    "published": "2024-08-26T16:00:41Z",
    "pdf_url": "http://arxiv.org/pdf/2408.14380v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2410.06617v5",
    "title": "Learning Evolving Tools for Large Language Models",
    "authors": [
      "Guoxin Chen",
      "Zhong Zhang",
      "Xin Cong",
      "Fangda Guo",
      "Yesai Wu",
      "Yankai Lin",
      "Wenzheng Feng",
      "Yasheng Wang"
    ],
    "abstract": "Tool learning enables large language models (LLMs) to interact with external\ntools and APIs, greatly expanding the application scope of LLMs. However, due\nto the dynamic nature of external environments, these tools and APIs may become\noutdated over time, preventing LLMs from correctly invoking tools. Existing\nresearch primarily focuses on static environments and overlooks this issue,\nlimiting the adaptability of LLMs in real-world applications. In this paper, we\npropose ToolEVO, a novel framework designed to enhance the adaptive and\nreflective capabilities of LLMs against tool variability. By leveraging Monte\nCarlo Tree Search, ToolEVO facilitates active exploration and interaction of\nLLMs within dynamic environments, allowing for autonomous self-reflection and\nself-updating of tool usage based on environmental feedback. Additionally, we\nintroduce ToolQA-D, a benchmark specifically designed to evaluate the impact of\ntool variability. Extensive experiments demonstrate the effectiveness and\nstability of our approach, highlighting the importance of adaptability to tool\nvariability for effective tool learning. Code:\nhttps://github.com/Chen-GX/ToolEVO",
    "published": "2024-10-09T07:14:45Z",
    "pdf_url": "http://arxiv.org/pdf/2410.06617v5",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2410.09817v2",
    "title": "Reverse Modeling in Large Language Models",
    "authors": [
      "Sicheng Yu",
      "Yuanchen Xu",
      "Cunxiao Du",
      "Yanying Zhou",
      "Minghui Qiu",
      "Qianru Sun",
      "Hao Zhang",
      "Jiawei Wu"
    ],
    "abstract": "Humans are accustomed to reading and writing in a forward manner, and this\nnatural bias extends to text understanding in auto-regressive large language\nmodels (LLMs). This paper investigates whether LLMs, like humans, struggle with\nreverse modeling, specifically with reversed text inputs. We found that\npublicly available pre-trained LLMs cannot understand such inputs. However,\nLLMs trained from scratch with both forward and reverse texts can understand\nthem equally well during inference across multiple languages. Our case study\nshows that different-content texts result in different losses if input (to\nLLMs) in different directions -- some get lower losses for forward while some\nfor reverse. This leads us to a simple and nice solution for data selection\nbased on the loss differences between forward and reverse directions. Using our\nselected data in continued pretraining can boost LLMs' performance by a large\nmargin across different language understanding benchmarks.",
    "published": "2024-10-13T12:24:03Z",
    "pdf_url": "http://arxiv.org/pdf/2410.09817v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2502.02289v1",
    "title": "Evalita-LLM: Benchmarking Large Language Models on Italian",
    "authors": [
      "Bernardo Magnini",
      "Roberto Zanoli",
      "Michele Resta",
      "Martin Cimmino",
      "Paolo Albano",
      "Marco Madeddu",
      "Viviana Patti"
    ],
    "abstract": "We describe Evalita-LLM, a new benchmark designed to evaluate Large Language\nModels (LLMs) on Italian tasks. The distinguishing and innovative features of\nEvalita-LLM are the following: (i) all tasks are native Italian, avoiding\nissues of translating from Italian and potential cultural biases; (ii) in\naddition to well established multiple-choice tasks, the benchmark includes\ngenerative tasks, enabling more natural interaction with LLMs; (iii) all tasks\nare evaluated against multiple prompts, this way mitigating the model\nsensitivity to specific prompts and allowing a fairer and objective evaluation.\nWe propose an iterative methodology, where candidate tasks and candidate\nprompts are validated against a set of LLMs used for development. We report\nexperimental results from the benchmark's development phase, and provide\nperformance statistics for several state-of-the-art LLMs.",
    "published": "2025-02-04T12:58:19Z",
    "pdf_url": "http://arxiv.org/pdf/2502.02289v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2501.02486v2",
    "title": "LLMPC: Large Language Model Predictive Control",
    "authors": [
      "Gabriel Maher"
    ],
    "abstract": "Recent advancements in prompting techniques for Large Language Models (LLMs)\nhave improved their reasoning, planning, and action abilities. This paper\nexamines these prompting techniques through the lens of model predictive\ncontrol (MPC). We show that LLMs act as implicit planning cost function\nminimizers when planning prompts are used. We propose a unified MPC framework\nfor planning with LLMs and demonstrate improved performance over few shot\nprompting on several planning benchmarks.",
    "published": "2025-01-05T09:37:23Z",
    "pdf_url": "http://arxiv.org/pdf/2501.02486v2",
    "categories": [
      "cs.AI",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2504.03931v2",
    "title": "NAACL2025 Tutorial: Adaptation of Large Language Models",
    "authors": [
      "Zixuan Ke",
      "Yifei Ming",
      "Shafiq Joty"
    ],
    "abstract": "This tutorial on adaptation of LLMs is designed to address the growing demand\nfor models that go beyond the static capabilities of generic LLMs by providing\nan overview of dynamic, domain-specific, and task-adaptive LLM adaptation\ntechniques. While general LLMs have demonstrated strong generalization across a\nvariety of tasks, they often struggle to perform well in specialized domains\nsuch as finance, healthcare, and code generation for underrepresented\nlanguages. Additionally, their static nature limits their ability to evolve\nwith the changing world, and they are often extremely large in size, making\nthem impractical and costly to deploy at scale. As a result, the adaptation of\nLLMs has drawn much attention since the birth of LLMs and is of core\nimportance, both for industry, which focuses on serving its targeted users, and\nacademia, which can greatly benefit from small but powerful LLMs. To address\nthis gap, this tutorial aims to provide an overview of the LLM adaptation\ntechniques. We start with an introduction to LLM adaptation, from both the data\nperspective and the model perspective. We then emphasize how the evaluation\nmetrics and benchmarks are different from other techniques. After establishing\nthe problems, we explore various adaptation techniques. We categorize\nadaptation techniques into two main families. The first is parametric knowledge\nadaptation, which focuses on updating the parametric knowledge within LLMs.\nAdditionally, we will discuss real-time adaptation techniques, including model\nediting, which allows LLMs to be updated dynamically in production\nenvironments. The second kind of adaptation is semi-parametric knowledge\nadaptation, where the goal is to update LLM parameters to better leverage\nexternal knowledge or tools through techniques like retrieval-augmented\ngeneration (RAG) and agent-based systems.",
    "published": "2025-04-04T20:57:41Z",
    "pdf_url": "http://arxiv.org/pdf/2504.03931v2",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2302.11957v1",
    "title": "Sentence Simplification via Large Language Models",
    "authors": [
      "Yutao Feng",
      "Jipeng Qiang",
      "Yun Li",
      "Yunhao Yuan",
      "Yi Zhu"
    ],
    "abstract": "Sentence Simplification aims to rephrase complex sentences into simpler\nsentences while retaining original meaning. Large Language models (LLMs) have\ndemonstrated the ability to perform a variety of natural language processing\ntasks. However, it is not yet known whether LLMs can be served as a\nhigh-quality sentence simplification system. In this work, we empirically\nanalyze the zero-/few-shot learning ability of LLMs by evaluating them on a\nnumber of benchmark test sets. Experimental results show LLMs outperform\nstate-of-the-art sentence simplification methods, and are judged to be on a par\nwith human annotators.",
    "published": "2023-02-23T12:11:58Z",
    "pdf_url": "http://arxiv.org/pdf/2302.11957v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2304.10436v1",
    "title": "Safety Assessment of Chinese Large Language Models",
    "authors": [
      "Hao Sun",
      "Zhexin Zhang",
      "Jiawen Deng",
      "Jiale Cheng",
      "Minlie Huang"
    ],
    "abstract": "With the rapid popularity of large language models such as ChatGPT and GPT-4,\na growing amount of attention is paid to their safety concerns. These models\nmay generate insulting and discriminatory content, reflect incorrect social\nvalues, and may be used for malicious purposes such as fraud and dissemination\nof misleading information. Evaluating and enhancing their safety is\nparticularly essential for the wide application of large language models\n(LLMs). To further promote the safe deployment of LLMs, we develop a Chinese\nLLM safety assessment benchmark. Our benchmark explores the comprehensive\nsafety performance of LLMs from two perspectives: 8 kinds of typical safety\nscenarios and 6 types of more challenging instruction attacks. Our benchmark is\nbased on a straightforward process in which it provides the test prompts and\nevaluates the safety of the generated responses from the evaluated model. In\nevaluation, we utilize the LLM's strong evaluation ability and develop it as a\nsafety evaluator by prompting. On top of this benchmark, we conduct safety\nassessments and analyze 15 LLMs including the OpenAI GPT series and other\nwell-known Chinese LLMs, where we observe some interesting findings. For\nexample, we find that instruction attacks are more likely to expose safety\nissues of all LLMs. Moreover, to promote the development and deployment of\nsafe, responsible, and ethical AI, we publicly release SafetyPrompts including\n100k augmented prompts and responses by LLMs.",
    "published": "2023-04-20T16:27:35Z",
    "pdf_url": "http://arxiv.org/pdf/2304.10436v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2307.06435v10",
    "title": "A Comprehensive Overview of Large Language Models",
    "authors": [
      "Humza Naveed",
      "Asad Ullah Khan",
      "Shi Qiu",
      "Muhammad Saqib",
      "Saeed Anwar",
      "Muhammad Usman",
      "Naveed Akhtar",
      "Nick Barnes",
      "Ajmal Mian"
    ],
    "abstract": "Large Language Models (LLMs) have recently demonstrated remarkable\ncapabilities in natural language processing tasks and beyond. This success of\nLLMs has led to a large influx of research contributions in this direction.\nThese works encompass diverse topics such as architectural innovations, better\ntraining strategies, context length improvements, fine-tuning, multi-modal\nLLMs, robotics, datasets, benchmarking, efficiency, and more. With the rapid\ndevelopment of techniques and regular breakthroughs in LLM research, it has\nbecome considerably challenging to perceive the bigger picture of the advances\nin this direction. Considering the rapidly emerging plethora of literature on\nLLMs, it is imperative that the research community is able to benefit from a\nconcise yet comprehensive overview of the recent developments in this field.\nThis article provides an overview of the existing literature on a broad range\nof LLM-related concepts. Our self-contained comprehensive overview of LLMs\ndiscusses relevant background concepts along with covering the advanced topics\nat the frontier of research in LLMs. This review article is intended to not\nonly provide a systematic survey but also a quick comprehensive reference for\nthe researchers and practitioners to draw insights from extensive informative\nsummaries of the existing works to advance the LLM research.",
    "published": "2023-07-12T20:01:52Z",
    "pdf_url": "http://arxiv.org/pdf/2307.06435v10",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2308.16361v2",
    "title": "Large Language Models as Data Preprocessors",
    "authors": [
      "Haochen Zhang",
      "Yuyang Dong",
      "Chuan Xiao",
      "Masafumi Oyamada"
    ],
    "abstract": "Large Language Models (LLMs), typified by OpenAI's GPT, have marked a\nsignificant advancement in artificial intelligence. Trained on vast amounts of\ntext data, LLMs are capable of understanding and generating human-like text\nacross a diverse range of topics. This study expands on the applications of\nLLMs, exploring their potential in data preprocessing, a critical stage in data\nmining and analytics applications. Aiming at tabular data, we delve into the\napplicability of state-of-the-art LLMs such as GPT-4 and GPT-4o for a series of\npreprocessing tasks, including error detection, data imputation, schema\nmatching, and entity matching. Alongside showcasing the inherent capabilities\nof LLMs, we highlight their limitations, particularly in terms of computational\nexpense and inefficiency. We propose an LLM-based framework for data\npreprocessing, which integrates cutting-edge prompt engineering techniques,\ncoupled with traditional methods like contextualization and feature selection,\nto improve the performance and efficiency of these models. The effectiveness of\nLLMs in data preprocessing is evaluated through an experimental study spanning\na variety of public datasets. GPT-4 emerged as a standout, achieving 100\\%\naccuracy or F1 score on 4 of these datasets, suggesting LLMs' immense potential\nin these tasks. Despite certain limitations, our study underscores the promise\nof LLMs in this domain and anticipates future developments to overcome current\nhurdles.",
    "published": "2023-08-30T23:28:43Z",
    "pdf_url": "http://arxiv.org/pdf/2308.16361v2",
    "categories": [
      "cs.AI",
      "cs.DB"
    ]
  },
  {
    "arxiv_id": "2310.00034v2",
    "title": "PB-LLM: Partially Binarized Large Language Models",
    "authors": [
      "Yuzhang Shang",
      "Zhihang Yuan",
      "Qiang Wu",
      "Zhen Dong"
    ],
    "abstract": "This paper explores network binarization, a radical form of quantization,\ncompressing model weights to a single bit, specifically for Large Language\nModels (LLMs) compression. Due to previous binarization methods collapsing\nLLMs, we propose a novel approach, Partially-Binarized LLM (PB-LLM), which can\nachieve extreme low-bit quantization while maintaining the linguistic reasoning\ncapacity of quantized LLMs. Specifically, our exploration first uncovers the\nineffectiveness of naive applications of existing binarization algorithms and\nhighlights the imperative role of salient weights in achieving low-bit\nquantization. Thus, PB-LLM filters a small ratio of salient weights during\nbinarization, allocating them to higher-bit storage, i.e.,\npartially-binarization. PB-LLM is extended to recover the capacities of\nquantized LMMs, by analyzing from the perspective of post-training quantization\n(PTQ) and quantization-aware training (QAT). Under PTQ, combining the concepts\nfrom GPTQ, we reconstruct the binarized weight matrix guided by the Hessian\nmatrix and successfully recover the reasoning capacity of PB-LLM in low-bit.\nUnder QAT, we freeze the salient weights during training, explore the\nderivation of optimal scaling factors crucial for minimizing the quantization\nerror, and propose a scaling mechanism based on this derived scaling strategy\nfor residual binarized weights. Those explorations and the developed\nmethodologies significantly contribute to rejuvenating the performance of\nlow-bit quantized LLMs and present substantial advancements in the field of\nnetwork binarization for LLMs.The code is available at\nhttps://github.com/hahnyuan/BinaryLLM.",
    "published": "2023-09-29T14:35:27Z",
    "pdf_url": "http://arxiv.org/pdf/2310.00034v2",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2310.07554v2",
    "title": "Retrieve Anything To Augment Large Language Models",
    "authors": [
      "Peitian Zhang",
      "Shitao Xiao",
      "Zheng Liu",
      "Zhicheng Dou",
      "Jian-Yun Nie"
    ],
    "abstract": "Large language models (LLMs) face significant challenges stemming from their\ninherent limitations in knowledge, memory, alignment, and action. These\nchallenges cannot be addressed by LLMs alone, but should rely on assistance\nfrom the external world, such as knowledge base, memory store, demonstration\nexamples, and tools. Retrieval augmentation stands as a vital mechanism for\nbridging the gap between LLMs and the external assistance. However,\nconventional methods encounter two pressing issues. On the one hand, the\ngeneral-purpose retrievers are not properly optimized for the retrieval\naugmentation of LLMs. On the other hand, the task-specific retrievers lack the\nrequired versatility, hindering their performance across the diverse retrieval\naugmentation scenarios.\n  In this work, we present a novel approach, the LLM-Embedder, which\ncomprehensively supports the diverse retrieval augmentation needs of LLMs with\none unified embedding model. Training such a unified model is non-trivial, as\nvarious retrieval tasks aim to capture distinct semantic relationships, often\nsubject to mutual interference. To address this challenge, we systematically\noptimize our training methodology. This includes reward formulation based on\nLLMs' feedback, the stabilization of knowledge distillation, multi-task\nfine-tuning with explicit instructions, and homogeneous in-batch negative\nsampling. These optimization strategies contribute to the outstanding empirical\nperformance of the LLM-Embedder. Notably, it yields remarkable enhancements in\nretrieval augmentation for LLMs, surpassing both general-purpose and\ntask-specific retrievers in various evaluation scenarios. Our checkpoint and\nsource code are publicly available at\nhttps://github.com/FlagOpen/FlagEmbedding.",
    "published": "2023-10-11T14:59:53Z",
    "pdf_url": "http://arxiv.org/pdf/2310.07554v2",
    "categories": [
      "cs.IR"
    ]
  },
  {
    "arxiv_id": "2311.07226v1",
    "title": "Large Language Models for Robotics: A Survey",
    "authors": [
      "Fanlong Zeng",
      "Wensheng Gan",
      "Yongheng Wang",
      "Ning Liu",
      "Philip S. Yu"
    ],
    "abstract": "The human ability to learn, generalize, and control complex manipulation\ntasks through multi-modality feedback suggests a unique capability, which we\nrefer to as dexterity intelligence. Understanding and assessing this\nintelligence is a complex task. Amidst the swift progress and extensive\nproliferation of large language models (LLMs), their applications in the field\nof robotics have garnered increasing attention. LLMs possess the ability to\nprocess and generate natural language, facilitating efficient interaction and\ncollaboration with robots. Researchers and engineers in the field of robotics\nhave recognized the immense potential of LLMs in enhancing robot intelligence,\nhuman-robot interaction, and autonomy. Therefore, this comprehensive review\naims to summarize the applications of LLMs in robotics, delving into their\nimpact and contributions to key areas such as robot control, perception,\ndecision-making, and path planning. We first provide an overview of the\nbackground and development of LLMs for robotics, followed by a description of\nthe benefits of LLMs for robotics and recent advancements in robotics models\nbased on LLMs. We then delve into the various techniques used in the model,\nincluding those employed in perception, decision-making, control, and\ninteraction. Finally, we explore the applications of LLMs in robotics and some\npotential challenges they may face in the near future. Embodied intelligence is\nthe future of intelligent science, and LLMs-based robotics is one of the\npromising but challenging paths to achieve this.",
    "published": "2023-11-13T10:46:35Z",
    "pdf_url": "http://arxiv.org/pdf/2311.07226v1",
    "categories": [
      "cs.RO",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2312.15922v1",
    "title": "Towards Probing Contact Center Large Language Models",
    "authors": [
      "Varun Nathan",
      "Ayush Kumar",
      "Digvijay Ingle",
      "Jithendra Vepa"
    ],
    "abstract": "Fine-tuning large language models (LLMs) with domain-specific instructions\nhas emerged as an effective method to enhance their domain-specific\nunderstanding. Yet, there is limited work that examines the core\ncharacteristics acquired during this process. In this study, we benchmark the\nfundamental characteristics learned by contact-center (CC) specific instruction\nfine-tuned LLMs with out-of-the-box (OOB) LLMs via probing tasks encompassing\nconversational, channel, and automatic speech recognition (ASR) properties. We\nexplore different LLM architectures (Flan-T5 and Llama), sizes (3B, 7B, 11B,\n13B), and fine-tuning paradigms (full fine-tuning vs PEFT). Our findings reveal\nremarkable effectiveness of CC-LLMs on the in-domain downstream tasks, with\nimprovement in response acceptability by over 48% compared to OOB-LLMs.\nAdditionally, we compare the performance of OOB-LLMs and CC-LLMs on the widely\nused SentEval dataset, and assess their capabilities in terms of surface,\nsyntactic, and semantic information through probing tasks. Intriguingly, we\nnote a relatively consistent performance of probing classifiers on the set of\nprobing tasks. Our observations indicate that CC-LLMs, while outperforming\ntheir out-of-the-box counterparts, exhibit a tendency to rely less on encoding\nsurface, syntactic, and semantic properties, highlighting the intricate\ninterplay between domain-specific adaptation and probing task performance\nopening up opportunities to explore behavior of fine-tuned language models in\nspecialized contexts.",
    "published": "2023-12-26T07:34:39Z",
    "pdf_url": "http://arxiv.org/pdf/2312.15922v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2401.02789v1",
    "title": "Large Language Models in Plant Biology",
    "authors": [
      "Hilbert Yuen In Lam",
      "Xing Er Ong",
      "Marek Mutwil"
    ],
    "abstract": "Large Language Models (LLMs), such as ChatGPT, have taken the world by storm\nand have passed certain forms of the Turing test. However, LLMs are not limited\nto human language and analyze sequential data, such as DNA, protein, and gene\nexpression. The resulting foundation models can be repurposed to identify the\ncomplex patterns within the data, resulting in powerful, multi-purpose\nprediction tools able to explain cellular systems. This review outlines the\ndifferent types of LLMs and showcases their recent uses in biology. Since LLMs\nhave not yet been embraced by the plant community, we also cover how these\nmodels can be deployed for the plant kingdom.",
    "published": "2024-01-05T12:59:20Z",
    "pdf_url": "http://arxiv.org/pdf/2401.02789v1",
    "categories": [
      "q-bio.GN",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2404.00806v4",
    "title": "Algorithmic Collusion by Large Language Models",
    "authors": [
      "Sara Fish",
      "Yannai A. Gonczarowski",
      "Ran I. Shorrer"
    ],
    "abstract": "The rise of algorithmic pricing raises concerns of algorithmic collusion. We\nconduct experiments with algorithmic pricing agents based on Large Language\nModels (LLMs). We find that LLM-based pricing agents quickly and autonomously\nreach supracompetitive prices and profits in oligopoly settings and that\nvariation in seemingly innocuous phrases in LLM instructions (\"prompts\") may\nsubstantially influence the degree of supracompetitive pricing. Off-path\nanalysis using novel techniques uncovers price-war concerns as contributing to\nthese phenomena. Our results extend to auction settings. Our findings uncover\nunique challenges to any future regulation of LLM-based pricing agents, and\nAI-based pricing agents more broadly.",
    "published": "2024-03-31T21:43:05Z",
    "pdf_url": "http://arxiv.org/pdf/2404.00806v4",
    "categories": [
      "econ.GN",
      "cs.AI",
      "cs.GT",
      "q-fin.EC"
    ]
  },
  {
    "arxiv_id": "2404.08706v2",
    "title": "Game Generation via Large Language Models",
    "authors": [
      "Chengpeng Hu",
      "Yunlong Zhao",
      "Jialin Liu"
    ],
    "abstract": "Recently, the emergence of large language models (LLMs) has unlocked new\nopportunities for procedural content generation. However, recent attempts\nmainly focus on level generation for specific games with defined game rules\nsuch as Super Mario Bros. and Zelda. This paper investigates the game\ngeneration via LLMs. Based on video game description language, this paper\nproposes an LLM-based framework to generate game rules and levels\nsimultaneously. Experiments demonstrate how the framework works with prompts\nconsidering different combinations of context. Our findings extend the current\napplications of LLMs and offer new insights for generating new games in the\narea of procedural content generation.",
    "published": "2024-04-11T10:06:05Z",
    "pdf_url": "http://arxiv.org/pdf/2404.08706v2",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2405.03695v1",
    "title": "Evaluating Large Language Models for Material Selection",
    "authors": [
      "Daniele Grandi",
      "Yash Patawari Jain",
      "Allin Groom",
      "Brandon Cramer",
      "Christopher McComb"
    ],
    "abstract": "Material selection is a crucial step in conceptual design due to its\nsignificant impact on the functionality, aesthetics, manufacturability, and\nsustainability impact of the final product. This study investigates the use of\nLarge Language Models (LLMs) for material selection in the product design\nprocess and compares the performance of LLMs against expert choices for various\ndesign scenarios. By collecting a dataset of expert material preferences, the\nstudy provides a basis for evaluating how well LLMs can align with expert\nrecommendations through prompt engineering and hyperparameter tuning. The\ndivergence between LLM and expert recommendations is measured across different\nmodel configurations, prompt strategies, and temperature settings. This\napproach allows for a detailed analysis of factors influencing the LLMs'\neffectiveness in recommending materials. The results from this study highlight\ntwo failure modes, and identify parallel prompting as a useful\nprompt-engineering method when using LLMs for material selection. The findings\nfurther suggest that, while LLMs can provide valuable assistance, their\nrecommendations often vary significantly from those of human experts. This\ndiscrepancy underscores the need for further research into how LLMs can be\nbetter tailored to replicate expert decision-making in material selection. This\nwork contributes to the growing body of knowledge on how LLMs can be integrated\ninto the design process, offering insights into their current limitations and\npotential for future improvements.",
    "published": "2024-04-23T18:53:33Z",
    "pdf_url": "http://arxiv.org/pdf/2405.03695v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2407.15071v1",
    "title": "Relational Database Augmented Large Language Model",
    "authors": [
      "Zongyue Qin",
      "Chen Luo",
      "Zhengyang Wang",
      "Haoming Jiang",
      "Yizhou Sun"
    ],
    "abstract": "Large language models (LLMs) excel in many natural language processing (NLP)\ntasks. However, since LLMs can only incorporate new knowledge through training\nor supervised fine-tuning processes, they are unsuitable for applications that\ndemand precise, up-to-date, and private information not available in the\ntraining corpora. This precise, up-to-date, and private information is\ntypically stored in relational databases. Thus, a promising solution is to\naugment LLMs with the inclusion of relational databases as external memory.\nThis can ensure the timeliness, correctness, and consistency of data, and\nassist LLMs in performing complex arithmetic operations beyond their inherent\ncapabilities. However, bridging the gap between LLMs and relational databases\nis challenging. It requires the awareness of databases and data values stored\nin databases to select correct databases and issue correct SQL queries.\nBesides, it is necessary for the external memory to be independent of the LLM\nto meet the needs of real-world applications. We introduce a novel LLM-agnostic\nmemory architecture comprising a database selection memory, a data value\nmemory, and relational databases. And we design an elegant pipeline to retrieve\ninformation from it. Besides, we carefully design the prompts to instruct the\nLLM to maximize the framework's potential. To evaluate our method, we compose a\nnew dataset with various types of questions. Experimental results show that our\nframework enables LLMs to effectively answer database-related questions, which\nis beyond their direct ability.",
    "published": "2024-07-21T06:19:10Z",
    "pdf_url": "http://arxiv.org/pdf/2407.15071v1",
    "categories": [
      "cs.DB",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2408.08707v2",
    "title": "Beam Prediction based on Large Language Models",
    "authors": [
      "Yucheng Sheng",
      "Kai Huang",
      "Le Liang",
      "Peng Liu",
      "Shi Jin",
      "Geoffrey Ye Li"
    ],
    "abstract": "In this letter, we use large language models (LLMs) to develop a\nhigh-performing and robust beam prediction method. We formulate the millimeter\nwave (mmWave) beam prediction problem as a time series forecasting task, where\nthe historical observations are aggregated through cross-variable attention and\nthen transformed into text-based representations using a trainable tokenizer.\nBy leveraging the prompt-as-prefix (PaP) technique for contextual enrichment,\nour method harnesses the power of LLMs to predict future optimal beams.\nSimulation results demonstrate that our LLM-based approach outperforms\ntraditional learning-based models in prediction accuracy as well as robustness,\nhighlighting the significant potential of LLMs in enhancing wireless\ncommunication systems.",
    "published": "2024-08-16T12:40:01Z",
    "pdf_url": "http://arxiv.org/pdf/2408.08707v2",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2411.00027v3",
    "title": "Personalization of Large Language Models: A Survey",
    "authors": [
      "Zhehao Zhang",
      "Ryan A. Rossi",
      "Branislav Kveton",
      "Yijia Shao",
      "Diyi Yang",
      "Hamed Zamani",
      "Franck Dernoncourt",
      "Joe Barrow",
      "Tong Yu",
      "Sungchul Kim",
      "Ruiyi Zhang",
      "Jiuxiang Gu",
      "Tyler Derr",
      "Hongjie Chen",
      "Junda Wu",
      "Xiang Chen",
      "Zichao Wang",
      "Subrata Mitra",
      "Nedim Lipka",
      "Nesreen Ahmed",
      "Yu Wang"
    ],
    "abstract": "Personalization of Large Language Models (LLMs) has recently become\nincreasingly important with a wide range of applications. Despite the\nimportance and recent progress, most existing works on personalized LLMs have\nfocused either entirely on (a) personalized text generation or (b) leveraging\nLLMs for personalization-related downstream applications, such as\nrecommendation systems. In this work, we bridge the gap between these two\nseparate main directions for the first time by introducing a taxonomy for\npersonalized LLM usage and summarizing the key differences and challenges. We\nprovide a formalization of the foundations of personalized LLMs that\nconsolidates and expands notions of personalization of LLMs, defining and\ndiscussing novel facets of personalization, usage, and desiderata of\npersonalized LLMs. We then unify the literature across these diverse fields and\nusage scenarios by proposing systematic taxonomies for the granularity of\npersonalization, personalization techniques, datasets, evaluation methods, and\napplications of personalized LLMs. Finally, we highlight challenges and\nimportant open problems that remain to be addressed. By unifying and surveying\nrecent research using the proposed taxonomies, we aim to provide a clear guide\nto the existing literature and different facets of personalization in LLMs,\nempowering both researchers and practitioners.",
    "published": "2024-10-29T04:01:11Z",
    "pdf_url": "http://arxiv.org/pdf/2411.00027v3",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2412.07031v2",
    "title": "Large Language Models: An Applied Econometric Framework",
    "authors": [
      "Jens Ludwig",
      "Sendhil Mullainathan",
      "Ashesh Rambachan"
    ],
    "abstract": "How can we use the novel capacities of large language models (LLMs) in\nempirical research? And how can we do so while accounting for their\nlimitations, which are themselves only poorly understood? We develop an\neconometric framework to answer this question that distinguishes between two\ntypes of empirical tasks. Using LLMs for prediction problems (including\nhypothesis generation) is valid under one condition: no ``leakage'' between the\nLLM's training dataset and the researcher's sample. No leakage can be ensured\nby using open-source LLMs with documented training data and published weights.\nUsing LLM outputs for estimation problems to automate the measurement of some\neconomic concept (expressed either by some text or from human subjects)\nrequires the researcher to collect at least some validation data: without such\ndata, the errors of the LLM's automation cannot be assessed and accounted for.\nAs long as these steps are taken, LLM outputs can be used in empirical research\nwith the familiar econometric guarantees we desire. Using two illustrative\napplications to finance and political economy, we find that these requirements\nare stringent; when they are violated, the limitations of LLMs now result in\nunreliable empirical estimates. Our results suggest the excitement around the\nempirical uses of LLMs is warranted -- they allow researchers to effectively\nuse even small amounts of language data for both prediction and estimation --\nbut only with these safeguards in place.",
    "published": "2024-12-09T22:37:48Z",
    "pdf_url": "http://arxiv.org/pdf/2412.07031v2",
    "categories": [
      "econ.EM",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2503.23037v2",
    "title": "Agentic Large Language Models, a survey",
    "authors": [
      "Aske Plaat",
      "Max van Duijn",
      "Niki van Stein",
      "Mike Preuss",
      "Peter van der Putten",
      "Kees Joost Batenburg"
    ],
    "abstract": "There is great interest in agentic LLMs, large language models that act as\nagents. We review the growing body of work in this area and provide a research\nagenda. Agentic LLMs are LLMs that (1) reason, (2) act, and (3) interact. We\norganize the literature according to these three categories. The research in\nthe first category focuses on reasoning, reflection, and retrieval, aiming to\nimprove decision making; the second category focuses on action models, robots,\nand tools, aiming for agents that act as useful assistants; the third category\nfocuses on multi-agent systems, aiming for collaborative task solving and\nsimulating interaction to study emergent social behavior. We find that works\nmutually benefit from results in other categories: retrieval enables tool use,\nreflection improves multi-agent collaboration, and reasoning benefits all\ncategories. We discuss applications of agentic LLMs and provide an agenda for\nfurther research. Important applications are in medical diagnosis, logistics\nand financial market analysis. Meanwhile, self-reflective agents playing roles\nand interacting with one another augment the process of scientific research\nitself. Further, agentic LLMs may provide a solution for the problem of LLMs\nrunning out of training data: inference-time behavior generates new training\nstates, such that LLMs can keep learning without needing ever larger datasets.\nWe note that there is risk associated with LLM assistants taking action in the\nreal world, while agentic LLMs are also likely to benefit society.",
    "published": "2025-03-29T11:02:20Z",
    "pdf_url": "http://arxiv.org/pdf/2503.23037v2",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2505.00467v2",
    "title": "Red Teaming Large Language Models for Healthcare",
    "authors": [
      "Vahid Balazadeh",
      "Michael Cooper",
      "David Pellow",
      "Atousa Assadi",
      "Jennifer Bell",
      "Mark Coatsworth",
      "Kaivalya Deshpande",
      "Jim Fackler",
      "Gabriel Funingana",
      "Spencer Gable-Cook",
      "Anirudh Gangadhar",
      "Abhishek Jaiswal",
      "Sumanth Kaja",
      "Christopher Khoury",
      "Amrit Krishnan",
      "Randy Lin",
      "Kaden McKeen",
      "Sara Naimimohasses",
      "Khashayar Namdar",
      "Aviraj Newatia",
      "Allan Pang",
      "Anshul Pattoo",
      "Sameer Peesapati",
      "Diana Prepelita",
      "Bogdana Rakova",
      "Saba Sadatamin",
      "Rafael Schulman",
      "Ajay Shah",
      "Syed Azhar Shah",
      "Syed Ahmar Shah",
      "Babak Taati",
      "Balagopal Unnikrishnan",
      "Iñigo Urteaga",
      "Stephanie Williams",
      "Rahul G Krishnan"
    ],
    "abstract": "We present the design process and findings of the pre-conference workshop at\nthe Machine Learning for Healthcare Conference (2024) entitled Red Teaming\nLarge Language Models for Healthcare, which took place on August 15, 2024.\nConference participants, comprising a mix of computational and clinical\nexpertise, attempted to discover vulnerabilities -- realistic clinical prompts\nfor which a large language model (LLM) outputs a response that could cause\nclinical harm. Red-teaming with clinicians enables the identification of LLM\nvulnerabilities that may not be recognised by LLM developers lacking clinical\nexpertise. We report the vulnerabilities found, categorise them, and present\nthe results of a replication study assessing the vulnerabilities across all\nLLMs provided.",
    "published": "2025-05-01T11:43:27Z",
    "pdf_url": "http://arxiv.org/pdf/2505.00467v2",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2505.13452v2",
    "title": "Large Language Model Powered Symbolic Execution",
    "authors": [
      "Yihe Li",
      "Ruijie Meng",
      "Gregory J. Duck"
    ],
    "abstract": "Large Language Models (LLMs) have emerged as a promising alternative to\ntraditional static program analysis methods, such as symbolic execution,\noffering the ability to reason over code directly without relying on theorem\nprovers or SMT solvers. However, LLMs are also inherently approximate by\nnature, and therefore face significant challenges in relation to the accuracy\nand scale of analysis in real-world applications. Such issues often necessitate\nthe use of larger LLMs with higher token limits, but this requires\nenterprise-grade hardware (GPUs) and thus limits accessibility for many users.\nIn this paper, we propose LLM-based symbolic execution -- a novel approach that\nenhances LLM inference via a path-based decomposition of the program analysis\ntasks into smaller (more tractable) subtasks. The core idea is to generalize\npath constraints using a generic code-based representation that the LLM can\ndirectly reason over, and without translation into another (less-expressive)\nformal language. We implement our approach in the form of AutoBug, an LLM-based\nsymbolic execution engine that is lightweight and language-agnostic, making it\na practical tool for analyzing code that is challenging for traditional\napproaches. We show that AutoBug can improve both the accuracy and scale of\nLLM-based program analysis, especially for smaller LLMs that can run on\nconsumer-grade hardware.",
    "published": "2025-04-02T05:14:25Z",
    "pdf_url": "http://arxiv.org/pdf/2505.13452v2",
    "categories": [
      "cs.PL"
    ]
  },
  {
    "arxiv_id": "2507.05448v1",
    "title": "On the Semantics of Large Language Models",
    "authors": [
      "Martin Schuele"
    ],
    "abstract": "Large Language Models (LLMs) such as ChatGPT demonstrated the potential to\nreplicate human language abilities through technology, ranging from text\ngeneration to engaging in conversations. However, it remains controversial to\nwhat extent these systems truly understand language. We examine this issue by\nnarrowing the question down to the semantics of LLMs at the word and sentence\nlevel. By examining the inner workings of LLMs and their generated\nrepresentation of language and by drawing on classical semantic theories by\nFrege and Russell, we get a more nuanced picture of the potential semantic\ncapabilities of LLMs.",
    "published": "2025-07-07T20:02:57Z",
    "pdf_url": "http://arxiv.org/pdf/2507.05448v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2509.12574v2",
    "title": "Yet Another Watermark for Large Language Models",
    "authors": [
      "Siyuan Bao",
      "Ying Shi",
      "Zhiguang Yang",
      "Hanzhou Wu",
      "Xinpeng Zhang"
    ],
    "abstract": "Existing watermarking methods for large language models (LLMs) mainly embed\nwatermark by adjusting the token sampling prediction or post-processing,\nlacking intrinsic coupling with LLMs, which may significantly reduce the\nsemantic quality of the generated marked texts. Traditional watermarking\nmethods based on training or fine-tuning may be extendable to LLMs. However,\nmost of them are limited to the white-box scenario, or very time-consuming due\nto the massive parameters of LLMs. In this paper, we present a new watermarking\nframework for LLMs, where the watermark is embedded into the LLM by\nmanipulating the internal parameters of the LLM, and can be extracted from the\ngenerated text without accessing the LLM. Comparing with related methods, the\nproposed method entangles the watermark with the intrinsic parameters of the\nLLM, which better balances the robustness and imperceptibility of the\nwatermark. Moreover, the proposed method enables us to extract the watermark\nunder the black-box scenario, which is computationally efficient for use.\nExperimental results have also verified the feasibility, superiority and\npracticality. This work provides a new perspective different from mainstream\nworks, which may shed light on future research.",
    "published": "2025-09-16T02:04:55Z",
    "pdf_url": "http://arxiv.org/pdf/2509.12574v2",
    "categories": [
      "cs.CR",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2401.05561v6",
    "title": "TrustLLM: Trustworthiness in Large Language Models",
    "authors": [
      "Yue Huang",
      "Lichao Sun",
      "Haoran Wang",
      "Siyuan Wu",
      "Qihui Zhang",
      "Yuan Li",
      "Chujie Gao",
      "Yixin Huang",
      "Wenhan Lyu",
      "Yixuan Zhang",
      "Xiner Li",
      "Zhengliang Liu",
      "Yixin Liu",
      "Yijue Wang",
      "Zhikun Zhang",
      "Bertie Vidgen",
      "Bhavya Kailkhura",
      "Caiming Xiong",
      "Chaowei Xiao",
      "Chunyuan Li",
      "Eric Xing",
      "Furong Huang",
      "Hao Liu",
      "Heng Ji",
      "Hongyi Wang",
      "Huan Zhang",
      "Huaxiu Yao",
      "Manolis Kellis",
      "Marinka Zitnik",
      "Meng Jiang",
      "Mohit Bansal",
      "James Zou",
      "Jian Pei",
      "Jian Liu",
      "Jianfeng Gao",
      "Jiawei Han",
      "Jieyu Zhao",
      "Jiliang Tang",
      "Jindong Wang",
      "Joaquin Vanschoren",
      "John Mitchell",
      "Kai Shu",
      "Kaidi Xu",
      "Kai-Wei Chang",
      "Lifang He",
      "Lifu Huang",
      "Michael Backes",
      "Neil Zhenqiang Gong",
      "Philip S. Yu",
      "Pin-Yu Chen",
      "Quanquan Gu",
      "Ran Xu",
      "Rex Ying",
      "Shuiwang Ji",
      "Suman Jana",
      "Tianlong Chen",
      "Tianming Liu",
      "Tianyi Zhou",
      "William Wang",
      "Xiang Li",
      "Xiangliang Zhang",
      "Xiao Wang",
      "Xing Xie",
      "Xun Chen",
      "Xuyu Wang",
      "Yan Liu",
      "Yanfang Ye",
      "Yinzhi Cao",
      "Yong Chen",
      "Yue Zhao"
    ],
    "abstract": "Large language models (LLMs), exemplified by ChatGPT, have gained\nconsiderable attention for their excellent natural language processing\ncapabilities. Nonetheless, these LLMs present many challenges, particularly in\nthe realm of trustworthiness. Therefore, ensuring the trustworthiness of LLMs\nemerges as an important topic. This paper introduces TrustLLM, a comprehensive\nstudy of trustworthiness in LLMs, including principles for different dimensions\nof trustworthiness, established benchmark, evaluation, and analysis of\ntrustworthiness for mainstream LLMs, and discussion of open challenges and\nfuture directions. Specifically, we first propose a set of principles for\ntrustworthy LLMs that span eight different dimensions. Based on these\nprinciples, we further establish a benchmark across six dimensions including\ntruthfulness, safety, fairness, robustness, privacy, and machine ethics. We\nthen present a study evaluating 16 mainstream LLMs in TrustLLM, consisting of\nover 30 datasets. Our findings firstly show that in general trustworthiness and\nutility (i.e., functional effectiveness) are positively related. Secondly, our\nobservations reveal that proprietary LLMs generally outperform most open-source\ncounterparts in terms of trustworthiness, raising concerns about the potential\nrisks of widely accessible open-source LLMs. However, a few open-source LLMs\ncome very close to proprietary ones. Thirdly, it is important to note that some\nLLMs may be overly calibrated towards exhibiting trustworthiness, to the extent\nthat they compromise their utility by mistakenly treating benign prompts as\nharmful and consequently not responding. Finally, we emphasize the importance\nof ensuring transparency not only in the models themselves but also in the\ntechnologies that underpin trustworthiness. Knowing the specific trustworthy\ntechnologies that have been employed is crucial for analyzing their\neffectiveness.",
    "published": "2024-01-10T22:07:21Z",
    "pdf_url": "http://arxiv.org/pdf/2401.05561v6",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2412.17614v1",
    "title": "Emerging Security Challenges of Large Language Models",
    "authors": [
      "Herve Debar",
      "Sven Dietrich",
      "Pavel Laskov",
      "Emil C. Lupu",
      "Eirini Ntoutsi"
    ],
    "abstract": "Large language models (LLMs) have achieved record adoption in a short period\nof time across many different sectors including high importance areas such as\neducation [4] and healthcare [23]. LLMs are open-ended models trained on\ndiverse data without being tailored for specific downstream tasks, enabling\nbroad applicability across various domains. They are commonly used for text\ngeneration, but also widely used to assist with code generation [3], and even\nanalysis of security information, as Microsoft Security Copilot demonstrates\n[18]. Traditional Machine Learning (ML) models are vulnerable to adversarial\nattacks [9]. So the concerns on the potential security implications of such\nwide scale adoption of LLMs have led to the creation of this working group on\nthe security of LLMs. During the Dagstuhl seminar on \"Network Attack Detection\nand Defense - AI-Powered Threats and Responses\", the working group discussions\nfocused on the vulnerability of LLMs to adversarial attacks, rather than their\npotential use in generating malware or enabling cyberattacks. Although we note\nthe potential threat represented by the latter, the role of the LLMs in such\nuses is mostly as an accelerator for development, similar to what it is in\nbenign use. To make the analysis more specific, the working group employed\nChatGPT as a concrete example of an LLM and addressed the following points,\nwhich also form the structure of this report: 1. How do LLMs differ in\nvulnerabilities from traditional ML models? 2. What are the attack objectives\nin LLMs? 3. How complex it is to assess the risks posed by the vulnerabilities\nof LLMs? 4. What is the supply chain in LLMs, how data flow in and out of\nsystems and what are the security implications? We conclude with an overview of\nopen challenges and outlook.",
    "published": "2024-12-23T14:36:37Z",
    "pdf_url": "http://arxiv.org/pdf/2412.17614v1",
    "categories": [
      "cs.CR",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2412.17686v1",
    "title": "Large Language Model Safety: A Holistic Survey",
    "authors": [
      "Dan Shi",
      "Tianhao Shen",
      "Yufei Huang",
      "Zhigen Li",
      "Yongqi Leng",
      "Renren Jin",
      "Chuang Liu",
      "Xinwei Wu",
      "Zishan Guo",
      "Linhao Yu",
      "Ling Shi",
      "Bojian Jiang",
      "Deyi Xiong"
    ],
    "abstract": "The rapid development and deployment of large language models (LLMs) have\nintroduced a new frontier in artificial intelligence, marked by unprecedented\ncapabilities in natural language understanding and generation. However, the\nincreasing integration of these models into critical applications raises\nsubstantial safety concerns, necessitating a thorough examination of their\npotential risks and associated mitigation strategies.\n  This survey provides a comprehensive overview of the current landscape of LLM\nsafety, covering four major categories: value misalignment, robustness to\nadversarial attacks, misuse, and autonomous AI risks. In addition to the\ncomprehensive review of the mitigation methodologies and evaluation resources\non these four aspects, we further explore four topics related to LLM safety:\nthe safety implications of LLM agents, the role of interpretability in\nenhancing LLM safety, the technology roadmaps proposed and abided by a list of\nAI companies and institutes for LLM safety, and AI governance aimed at LLM\nsafety with discussions on international cooperation, policy proposals, and\nprospective regulatory directions.\n  Our findings underscore the necessity for a proactive, multifaceted approach\nto LLM safety, emphasizing the integration of technical solutions, ethical\nconsiderations, and robust governance frameworks. This survey is intended to\nserve as a foundational resource for academy researchers, industry\npractitioners, and policymakers, offering insights into the challenges and\nopportunities associated with the safe integration of LLMs into society.\nUltimately, it seeks to contribute to the safe and beneficial development of\nLLMs, aligning with the overarching goal of harnessing AI for societal\nadvancement and well-being. A curated list of related papers has been publicly\navailable at https://github.com/tjunlp-lab/Awesome-LLM-Safety-Papers.",
    "published": "2024-12-23T16:11:27Z",
    "pdf_url": "http://arxiv.org/pdf/2412.17686v1",
    "categories": [
      "cs.AI",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2509.22297v1",
    "title": "Large Language Models as Nondeterministic Causal Models",
    "authors": [
      "Sander Beckers"
    ],
    "abstract": "Recent work by Chatzi et al. and Ravfogel et al. has developed, for the first\ntime, a method for generating counterfactuals of probabilistic Large Language\nModels. Such counterfactuals tell us what would - or might - have been the\noutput of an LLM if some factual prompt ${\\bf x}$ had been ${\\bf x}^*$ instead.\nThe ability to generate such counterfactuals is an important necessary step\ntowards explaining, evaluating, and comparing, the behavior of LLMs. I argue,\nhowever, that the existing method rests on an ambiguous interpretation of LLMs:\nit does not interpret LLMs literally, for the method involves the assumption\nthat one can change the implementation of an LLM's sampling process without\nchanging the LLM itself, nor does it interpret LLMs as intended, for the method\ninvolves explicitly representing a nondeterministic LLM as a deterministic\ncausal model. I here present a much simpler method for generating\ncounterfactuals that is based on an LLM's intended interpretation by\nrepresenting it as a nondeterministic causal model instead. The advantage of my\nsimpler method is that it is directly applicable to any black-box LLM without\nmodification, as it is agnostic to any implementation details. The advantage of\nthe existing method, on the other hand, is that it directly implements the\ngeneration of a specific type of counterfactuals that is useful for certain\npurposes, but not for others. I clarify how both methods relate by offering a\ntheoretical foundation for reasoning about counterfactuals in LLMs based on\ntheir intended semantics, thereby laying the groundwork for novel\napplication-specific methods for generating counterfactuals.",
    "published": "2025-09-26T12:59:41Z",
    "pdf_url": "http://arxiv.org/pdf/2509.22297v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2305.10519v2",
    "title": "Statistical Knowledge Assessment for Large Language Models",
    "authors": [
      "Qingxiu Dong",
      "Jingjing Xu",
      "Lingpeng Kong",
      "Zhifang Sui",
      "Lei Li"
    ],
    "abstract": "Given varying prompts regarding a factoid question, can a large language\nmodel (LLM) reliably generate factually correct answers? Existing LLMs may\ngenerate distinct responses for different prompts. In this paper, we study the\nproblem of quantifying knowledge contained in an LLM regarding a given set of\nfacts. We propose KaRR, a statistical approach to assess factual knowledge for\nLLMs. The main idea is to estimate the ratio of LLM generating text\ncorresponding to the answer entity given diverse prompts of the subject and the\nquerying relation, versus it generating by random chances. Our assessment suite\ncontains a comprehensive set of 994,123 entities and 600 relations, with\n1,395,905 text aliases. We use our method to evaluate 20 LLMs of various sizes,\nincluding LLaMA, Alpaca, OPT, etc. Experiments show that our results have a\nstrong correlation (0.43 Kendall's $\\tau$) with the results of human assessment\non LLMs. Our results reveal that the knowledge in LLMs with the same backbone\narchitecture adheres to the scaling law, while tuning on instruction-following\ndata sometimes compromises the model's capability to generate factually correct\ntext reliably.",
    "published": "2023-05-17T18:54:37Z",
    "pdf_url": "http://arxiv.org/pdf/2305.10519v2",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2307.00184v4",
    "title": "Personality Traits in Large Language Models",
    "authors": [
      "Greg Serapio-García",
      "Mustafa Safdari",
      "Clément Crepy",
      "Luning Sun",
      "Stephen Fitz",
      "Peter Romero",
      "Marwa Abdulhai",
      "Aleksandra Faust",
      "Maja Matarić"
    ],
    "abstract": "The advent of large language models (LLMs) has revolutionized natural\nlanguage processing, enabling the generation of coherent and contextually\nrelevant human-like text. As LLMs increasingly powerconversational agents used\nby the general public world-wide, the synthetic personality traits embedded in\nthese models, by virtue of training on large amounts of human data, is becoming\nincreasingly important. Since personality is a key factor determining the\neffectiveness of communication, we present a novel and comprehensive\npsychometrically valid and reliable methodology for administering and\nvalidating personality tests on widely-used LLMs, as well as for shaping\npersonality in the generated text of such LLMs. Applying this method to 18\nLLMs, we found: 1) personality measurements in the outputs of some LLMs under\nspecific prompting configurations are reliable and valid; 2) evidence of\nreliability and validity of synthetic LLM personality is stronger for larger\nand instruction fine-tuned models; and 3) personality in LLM outputs can be\nshaped along desired dimensions to mimic specific human personality profiles.\nWe discuss the application and ethical implications of the measurement and\nshaping method, in particular regarding responsible AI.",
    "published": "2023-07-01T00:58:51Z",
    "pdf_url": "http://arxiv.org/pdf/2307.00184v4",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "68T35",
      "I.2.7"
    ]
  },
  {
    "arxiv_id": "2307.00457v2",
    "title": "GenRec: Large Language Model for Generative Recommendation",
    "authors": [
      "Jianchao Ji",
      "Zelong Li",
      "Shuyuan Xu",
      "Wenyue Hua",
      "Yingqiang Ge",
      "Juntao Tan",
      "Yongfeng Zhang"
    ],
    "abstract": "In recent years, large language models (LLM) have emerged as powerful tools\nfor diverse natural language processing tasks. However, their potential for\nrecommender systems under the generative recommendation paradigm remains\nrelatively unexplored. This paper presents an innovative approach to\nrecommendation systems using large language models (LLMs) based on text data.\nIn this paper, we present a novel LLM for generative recommendation (GenRec)\nthat utilized the expressive power of LLM to directly generate the target item\nto recommend, rather than calculating ranking score for each candidate item one\nby one as in traditional discriminative recommendation. GenRec uses LLM's\nunderstanding ability to interpret context, learn user preferences, and\ngenerate relevant recommendation. Our proposed approach leverages the vast\nknowledge encoded in large language models to accomplish recommendation tasks.\nWe first we formulate specialized prompts to enhance the ability of LLM to\ncomprehend recommendation tasks. Subsequently, we use these prompts to\nfine-tune the LLaMA backbone LLM on a dataset of user-item interactions,\nrepresented by textual data, to capture user preferences and item\ncharacteristics. Our research underscores the potential of LLM-based generative\nrecommendation in revolutionizing the domain of recommendation systems and\noffers a foundational framework for future explorations in this field. We\nconduct extensive experiments on benchmark datasets, and the experiments shows\nthat our GenRec has significant better results on large dataset.",
    "published": "2023-07-02T02:37:07Z",
    "pdf_url": "http://arxiv.org/pdf/2307.00457v2",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2307.09042v2",
    "title": "Emotional Intelligence of Large Language Models",
    "authors": [
      "Xuena Wang",
      "Xueting Li",
      "Zi Yin",
      "Yue Wu",
      "Liu Jia"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable abilities across\nnumerous disciplines, primarily assessed through tasks in language generation,\nknowledge utilization, and complex reasoning. However, their alignment with\nhuman emotions and values, which is critical for real-world applications, has\nnot been systematically evaluated. Here, we assessed LLMs' Emotional\nIntelligence (EI), encompassing emotion recognition, interpretation, and\nunderstanding, which is necessary for effective communication and social\ninteractions. Specifically, we first developed a novel psychometric assessment\nfocusing on Emotion Understanding (EU), a core component of EI, suitable for\nboth humans and LLMs. This test requires evaluating complex emotions (e.g.,\nsurprised, joyful, puzzled, proud) in realistic scenarios (e.g., despite\nfeeling underperformed, John surprisingly achieved a top score). With a\nreference frame constructed from over 500 adults, we tested a variety of\nmainstream LLMs. Most achieved above-average EQ scores, with GPT-4 exceeding\n89% of human participants with an EQ of 117. Interestingly, a multivariate\npattern analysis revealed that some LLMs apparently did not reply on the\nhuman-like mechanism to achieve human-level performance, as their\nrepresentational patterns were qualitatively distinct from humans. In addition,\nwe discussed the impact of factors such as model size, training method, and\narchitecture on LLMs' EQ. In summary, our study presents one of the first\npsychometric evaluations of the human-like characteristics of LLMs, which may\nshed light on the future development of LLMs aiming for both high intellectual\nand emotional intelligence. Project website:\nhttps://emotional-intelligence.github.io/",
    "published": "2023-07-18T07:49:38Z",
    "pdf_url": "http://arxiv.org/pdf/2307.09042v2",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2307.16513v2",
    "title": "Deception Abilities Emerged in Large Language Models",
    "authors": [
      "Thilo Hagendorff"
    ],
    "abstract": "Large language models (LLMs) are currently at the forefront of intertwining\nartificial intelligence (AI) systems with human communication and everyday\nlife. Thus, aligning them with human values is of great importance. However,\ngiven the steady increase in reasoning abilities, future LLMs are under\nsuspicion of becoming able to deceive human operators and utilizing this\nability to bypass monitoring efforts. As a prerequisite to this, LLMs need to\npossess a conceptual understanding of deception strategies. This study reveals\nthat such strategies emerged in state-of-the-art LLMs, such as GPT-4, but were\nnon-existent in earlier LLMs. We conduct a series of experiments showing that\nstate-of-the-art LLMs are able to understand and induce false beliefs in other\nagents, that their performance in complex deception scenarios can be amplified\nutilizing chain-of-thought reasoning, and that eliciting Machiavellianism in\nLLMs can alter their propensity to deceive. In sum, revealing hitherto unknown\nmachine behavior in LLMs, our study contributes to the nascent field of machine\npsychology.",
    "published": "2023-07-31T09:27:01Z",
    "pdf_url": "http://arxiv.org/pdf/2307.16513v2",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2307.16645v1",
    "title": "Scaling Sentence Embeddings with Large Language Models",
    "authors": [
      "Ting Jiang",
      "Shaohan Huang",
      "Zhongzhi Luan",
      "Deqing Wang",
      "Fuzhen Zhuang"
    ],
    "abstract": "Large language models (LLMs) have recently garnered significant interest.\nWith in-context learning, LLMs achieve impressive results in various natural\nlanguage tasks. However, the application of LLMs to sentence embeddings remains\nan area of ongoing research. In this work, we propose an in-context\nlearning-based method aimed at improving sentence embeddings performance. Our\napproach involves adapting the previous prompt-based representation method for\nautoregressive models, constructing a demonstration set that enables LLMs to\nperform in-context learning, and scaling up the LLMs to different model sizes.\nThrough extensive experiments, in-context learning enables LLMs to generate\nhigh-quality sentence embeddings without any fine-tuning. It helps LLMs achieve\nperformance comparable to current contrastive learning methods. By scaling\nmodel size, we find scaling to more than tens of billion parameters harms the\nperformance on semantic textual similarity (STS) tasks. However, the largest\nmodel outperforms other counterparts and achieves the new state-of-the-art\nresult on transfer tasks. We also fine-tune LLMs with current contrastive\nlearning approach, and the 2.7B OPT model, incorporating our prompt-based\nmethod, surpasses the performance of 4.8B ST5, achieving the new\nstate-of-the-art results on STS tasks. Our code is available at\nhttps://github.com/kongds/scaling_sentemb.",
    "published": "2023-07-31T13:26:03Z",
    "pdf_url": "http://arxiv.org/pdf/2307.16645v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2310.00935v3",
    "title": "Resolving Knowledge Conflicts in Large Language Models",
    "authors": [
      "Yike Wang",
      "Shangbin Feng",
      "Heng Wang",
      "Weijia Shi",
      "Vidhisha Balachandran",
      "Tianxing He",
      "Yulia Tsvetkov"
    ],
    "abstract": "Large language models (LLMs) often encounter knowledge conflicts, scenarios\nwhere discrepancy arises between the internal parametric knowledge of LLMs and\nnon-parametric information provided in the prompt context. In this work we ask\nwhat are the desiderata for LLMs when a knowledge conflict arises and whether\nexisting LLMs fulfill them. We posit that LLMs should 1) identify knowledge\nconflicts, 2) pinpoint conflicting information segments, and 3) provide\ndistinct answers or viewpoints in conflicting scenarios. To this end, we\nintroduce an evaluation framework for simulating contextual knowledge conflicts\nand quantitatively evaluating to what extent LLMs achieve these goals. It\nincludes diverse and complex situations of knowledge conflict, knowledge from\ndiverse entities and domains, two synthetic conflict creation methods, and\nsettings with progressively increasing difficulty to reflect realistic\nknowledge conflicts. Extensive experiments with the framework reveal that while\nLLMs perform well in identifying the existence of knowledge conflicts, they\nstruggle to determine the specific conflicting knowledge and produce a response\nwith distinct answers amidst conflicting information. To address these\nchallenges, we propose new instruction-based approaches that augment LLMs to\nbetter achieve the three goals. Further analysis shows that abilities to tackle\nknowledge conflicts are greatly impacted by factors such as knowledge domain,\nwhile generating robust responses to knowledge conflict scenarios remains an\nopen research question.",
    "published": "2023-10-02T06:57:45Z",
    "pdf_url": "http://arxiv.org/pdf/2310.00935v3",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2310.09690v2",
    "title": "Configuration Validation with Large Language Models",
    "authors": [
      "Xinyu Lian",
      "Yinfang Chen",
      "Runxiang Cheng",
      "Jie Huang",
      "Parth Thakkar",
      "Minjia Zhang",
      "Tianyin Xu"
    ],
    "abstract": "Misconfigurations are major causes of software failures. Existing practices\nrely on developer-written rules or test cases to validate configurations, which\nare expensive. Machine learning (ML) for configuration validation is considered\na promising direction, but has been facing challenges such as the need of\nlarge-scale field data and system-specific models. Recent advances in Large\nLanguage Models (LLMs) show promise in addressing some of the long-lasting\nlimitations of ML-based configuration validation. We present a first analysis\non the feasibility and effectiveness of using LLMs for configuration\nvalidation. We empirically evaluate LLMs as configuration validators by\ndeveloping a generic LLM-based configuration validation framework, named Ciri.\nCiri employs effective prompt engineering with few-shot learning based on both\nvalid configuration and misconfiguration data. Ciri checks outputs from LLMs\nwhen producing results, addressing hallucination and nondeterminism of LLMs. We\nevaluate Ciri's validation effectiveness on eight popular LLMs using\nconfiguration data of ten widely deployed open-source systems. Our analysis (1)\nconfirms the potential of using LLMs for configuration validation, (2) explores\ndesign space of LLMbased validators like Ciri, and (3) reveals open challenges\nsuch as ineffectiveness in detecting certain types of misconfigurations and\nbiases towards popular configuration parameters.",
    "published": "2023-10-15T00:50:27Z",
    "pdf_url": "http://arxiv.org/pdf/2310.09690v2",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.OS"
    ]
  },
  {
    "arxiv_id": "2311.10723v2",
    "title": "Large Language Models in Finance: A Survey",
    "authors": [
      "Yinheng Li",
      "Shaofei Wang",
      "Han Ding",
      "Hang Chen"
    ],
    "abstract": "Recent advances in large language models (LLMs) have opened new possibilities\nfor artificial intelligence applications in finance. In this paper, we provide\na practical survey focused on two key aspects of utilizing LLMs for financial\ntasks: existing solutions and guidance for adoption.\n  First, we review current approaches employing LLMs in finance, including\nleveraging pretrained models via zero-shot or few-shot learning, fine-tuning on\ndomain-specific data, and training custom LLMs from scratch. We summarize key\nmodels and evaluate their performance improvements on financial natural\nlanguage processing tasks.\n  Second, we propose a decision framework to guide financial professionals in\nselecting the appropriate LLM solution based on their use case constraints\naround data, compute, and performance needs. The framework provides a pathway\nfrom lightweight experimentation to heavy investment in customized LLMs.\n  Lastly, we discuss limitations and challenges around leveraging LLMs in\nfinancial applications. Overall, this survey aims to synthesize the\nstate-of-the-art and provide a roadmap for responsibly applying LLMs to advance\nfinancial AI.",
    "published": "2023-09-28T06:04:04Z",
    "pdf_url": "http://arxiv.org/pdf/2311.10723v2",
    "categories": [
      "q-fin.GN",
      "cs.AI",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2402.08392v1",
    "title": "Large Language Models as Minecraft Agents",
    "authors": [
      "Chris Madge",
      "Massimo Poesio"
    ],
    "abstract": "In this work we examine the use of Large Language Models (LLMs) in the\nchallenging setting of acting as a Minecraft agent. We apply and evaluate LLMs\nin the builder and architect settings, introduce clarification questions and\nexamining the challenges and opportunities for improvement. In addition, we\npresent a platform for online interaction with the agents and an evaluation\nagainst previous works.",
    "published": "2024-02-13T11:37:30Z",
    "pdf_url": "http://arxiv.org/pdf/2402.08392v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2402.08787v6",
    "title": "Rethinking Machine Unlearning for Large Language Models",
    "authors": [
      "Sijia Liu",
      "Yuanshun Yao",
      "Jinghan Jia",
      "Stephen Casper",
      "Nathalie Baracaldo",
      "Peter Hase",
      "Yuguang Yao",
      "Chris Yuhao Liu",
      "Xiaojun Xu",
      "Hang Li",
      "Kush R. Varshney",
      "Mohit Bansal",
      "Sanmi Koyejo",
      "Yang Liu"
    ],
    "abstract": "We explore machine unlearning (MU) in the domain of large language models\n(LLMs), referred to as LLM unlearning. This initiative aims to eliminate\nundesirable data influence (e.g., sensitive or illegal information) and the\nassociated model capabilities, while maintaining the integrity of essential\nknowledge generation and not affecting causally unrelated information. We\nenvision LLM unlearning becoming a pivotal element in the life-cycle management\nof LLMs, potentially standing as an essential foundation for developing\ngenerative AI that is not only safe, secure, and trustworthy, but also\nresource-efficient without the need of full retraining. We navigate the\nunlearning landscape in LLMs from conceptual formulation, methodologies,\nmetrics, and applications. In particular, we highlight the often-overlooked\naspects of existing LLM unlearning research, e.g., unlearning scope, data-model\ninteraction, and multifaceted efficacy assessment. We also draw connections\nbetween LLM unlearning and related areas such as model editing, influence\nfunctions, model explanation, adversarial training, and reinforcement learning.\nFurthermore, we outline an effective assessment framework for LLM unlearning\nand explore its applications in copyright and privacy safeguards and\nsociotechnical harm reduction.",
    "published": "2024-02-13T20:51:58Z",
    "pdf_url": "http://arxiv.org/pdf/2402.08787v6",
    "categories": [
      "cs.LG",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2402.14700v3",
    "title": "Unveiling Linguistic Regions in Large Language Models",
    "authors": [
      "Zhihao Zhang",
      "Jun Zhao",
      "Qi Zhang",
      "Tao Gui",
      "Xuanjing Huang"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated considerable cross-lingual\nalignment and generalization ability. Current research primarily focuses on\nimproving LLMs' cross-lingual generalization capabilities. However, there is\nstill a lack of research on the intrinsic mechanisms of how LLMs achieve\ncross-lingual alignment. From the perspective of region partitioning, this\npaper conducts several investigations on the linguistic competence of LLMs. We\ndiscover a core region in LLMs that corresponds to linguistic competence,\naccounting for approximately 1% of the total model parameters. Removing this\ncore region by setting parameters to zero results in a significant performance\ndecrease across 30 different languages. Furthermore, this core region exhibits\nsignificant dimensional dependence, perturbations to even a single parameter on\nspecific dimensions leading to a loss of linguistic competence. Moreover, we\ndiscover that distinct monolingual regions exist for different languages, and\ndisruption to these specific regions substantially reduces the LLMs'\nproficiency in those corresponding languages. Our research also indicates that\nfreezing the core linguistic region during further pre-training can mitigate\nthe issue of catastrophic forgetting (CF), a common phenomenon observed during\nfurther pre-training of LLMs. Overall, exploring the LLMs' functional regions\nprovides insights into the foundation of their intelligence.",
    "published": "2024-02-22T16:56:13Z",
    "pdf_url": "http://arxiv.org/pdf/2402.14700v3",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2404.00245v1",
    "title": "Aligning Large Language Models with Recommendation Knowledge",
    "authors": [
      "Yuwei Cao",
      "Nikhil Mehta",
      "Xinyang Yi",
      "Raghunandan Keshavan",
      "Lukasz Heldt",
      "Lichan Hong",
      "Ed H. Chi",
      "Maheswaran Sathiamoorthy"
    ],
    "abstract": "Large language models (LLMs) have recently been used as backbones for\nrecommender systems. However, their performance often lags behind conventional\nmethods in standard tasks like retrieval. We attribute this to a mismatch\nbetween LLMs' knowledge and the knowledge crucial for effective\nrecommendations. While LLMs excel at natural language reasoning, they cannot\nmodel complex user-item interactions inherent in recommendation tasks. We\npropose bridging the knowledge gap and equipping LLMs with\nrecommendation-specific knowledge to address this. Operations such as Masked\nItem Modeling (MIM) and Bayesian Personalized Ranking (BPR) have found success\nin conventional recommender systems. Inspired by this, we simulate these\noperations through natural language to generate auxiliary-task data samples\nthat encode item correlations and user preferences. Fine-tuning LLMs on such\nauxiliary-task data samples and incorporating more informative\nrecommendation-task data samples facilitates the injection of\nrecommendation-specific knowledge into LLMs. Extensive experiments across\nretrieval, ranking, and rating prediction tasks on LLMs such as FLAN-T5-Base\nand FLAN-T5-XL show the effectiveness of our technique in domains such as\nAmazon Toys & Games, Beauty, and Sports & Outdoors. Notably, our method\noutperforms conventional and LLM-based baselines, including the current SOTA,\nby significant margins in retrieval, showcasing its potential for enhancing\nrecommendation quality.",
    "published": "2024-03-30T04:46:16Z",
    "pdf_url": "http://arxiv.org/pdf/2404.00245v1",
    "categories": [
      "cs.IR"
    ]
  },
  {
    "arxiv_id": "2405.12819v2",
    "title": "Large Language Models Meet NLP: A Survey",
    "authors": [
      "Libo Qin",
      "Qiguang Chen",
      "Xiachong Feng",
      "Yang Wu",
      "Yongheng Zhang",
      "Yinghui Li",
      "Min Li",
      "Wanxiang Che",
      "Philip S. Yu"
    ],
    "abstract": "While large language models (LLMs) like ChatGPT have shown impressive\ncapabilities in Natural Language Processing (NLP) tasks, a systematic\ninvestigation of their potential in this field remains largely unexplored. This\nstudy aims to address this gap by exploring the following questions: (1) How\nare LLMs currently applied to NLP tasks in the literature? (2) Have traditional\nNLP tasks already been solved with LLMs? (3) What is the future of the LLMs for\nNLP? To answer these questions, we take the first step to provide a\ncomprehensive overview of LLMs in NLP. Specifically, we first introduce a\nunified taxonomy including (1) parameter-frozen paradigm and (2)\nparameter-tuning paradigm to offer a unified perspective for understanding the\ncurrent progress of LLMs in NLP. Furthermore, we summarize the new frontiers\nand the corresponding challenges, aiming to inspire further groundbreaking\nadvancements. We hope this work offers valuable insights into the potential and\nlimitations of LLMs, while also serving as a practical guide for building\neffective LLMs in NLP.",
    "published": "2024-05-21T14:24:01Z",
    "pdf_url": "http://arxiv.org/pdf/2405.12819v2",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2405.13001v1",
    "title": "Large Language Models for Education: A Survey",
    "authors": [
      "Hanyi Xu",
      "Wensheng Gan",
      "Zhenlian Qi",
      "Jiayang Wu",
      "Philip S. Yu"
    ],
    "abstract": "Artificial intelligence (AI) has a profound impact on traditional education.\nIn recent years, large language models (LLMs) have been increasingly used in\nvarious applications such as natural language processing, computer vision,\nspeech recognition, and autonomous driving. LLMs have also been applied in many\nfields, including recommendation, finance, government, education, legal\naffairs, and finance. As powerful auxiliary tools, LLMs incorporate various\ntechnologies such as deep learning, pre-training, fine-tuning, and\nreinforcement learning. The use of LLMs for smart education (LLMEdu) has been a\nsignificant strategic direction for countries worldwide. While LLMs have shown\ngreat promise in improving teaching quality, changing education models, and\nmodifying teacher roles, the technologies are still facing several challenges.\nIn this paper, we conduct a systematic review of LLMEdu, focusing on current\ntechnologies, challenges, and future developments. We first summarize the\ncurrent state of LLMEdu and then introduce the characteristics of LLMs and\neducation, as well as the benefits of integrating LLMs into education. We also\nreview the process of integrating LLMs into the education industry, as well as\nthe introduction of related technologies. Finally, we discuss the challenges\nand problems faced by LLMEdu, as well as prospects for future optimization of\nLLMEdu.",
    "published": "2024-05-12T01:50:01Z",
    "pdf_url": "http://arxiv.org/pdf/2405.13001v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "2405.13041v3",
    "title": "Assessing Political Bias in Large Language Models",
    "authors": [
      "Luca Rettenberger",
      "Markus Reischl",
      "Mark Schutera"
    ],
    "abstract": "The assessment of bias within Large Language Models (LLMs) has emerged as a\ncritical concern in the contemporary discourse surrounding Artificial\nIntelligence (AI) in the context of their potential impact on societal\ndynamics. Recognizing and considering political bias within LLM applications is\nespecially important when closing in on the tipping point toward performative\nprediction. Then, being educated about potential effects and the societal\nbehavior LLMs can drive at scale due to their interplay with human operators.\nIn this way, the upcoming elections of the European Parliament will not remain\nunaffected by LLMs. We evaluate the political bias of the currently most\npopular open-source LLMs (instruct or assistant models) concerning political\nissues within the European Union (EU) from a German voter's perspective. To do\nso, we use the \"Wahl-O-Mat,\" a voting advice application used in Germany. From\nthe voting advice of the \"Wahl-O-Mat\" we quantize the degree of alignment of\nLLMs with German political parties. We show that larger models, such as\nLlama3-70B, tend to align more closely with left-leaning political parties,\nwhile smaller models often remain neutral, particularly when prompted in\nEnglish. The central finding is that LLMs are similarly biased, with low\nvariances in the alignment concerning a specific party. Our findings underline\nthe importance of rigorously assessing and making bias transparent in LLMs to\nsafeguard the integrity and trustworthiness of applications that employ the\ncapabilities of performative prediction and the invisible hand of machine\nlearning prediction and language generation.",
    "published": "2024-05-17T15:30:18Z",
    "pdf_url": "http://arxiv.org/pdf/2405.13041v3",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2406.07815v2",
    "title": "Are Large Language Models Good Statisticians?",
    "authors": [
      "Yizhang Zhu",
      "Shiyin Du",
      "Boyan Li",
      "Yuyu Luo",
      "Nan Tang"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across\na range of scientific tasks including mathematics, physics, and chemistry.\nDespite their successes, the effectiveness of LLMs in handling complex\nstatistical tasks remains systematically under-explored. To bridge this gap, we\nintroduce StatQA, a new benchmark designed for statistical analysis tasks.\nStatQA comprises 11,623 examples tailored to evaluate LLMs' proficiency in\nspecialized statistical tasks and their applicability assessment capabilities,\nparticularly for hypothesis testing methods. We systematically experiment with\nrepresentative LLMs using various prompting strategies and show that even\nstate-of-the-art models such as GPT-4o achieve a best performance of only\n64.83%, indicating significant room for improvement. Notably, while open-source\nLLMs (e.g. LLaMA-3) show limited capability, those fine-tuned ones exhibit\nmarked improvements, outperforming all in-context learning-based methods (e.g.\nGPT-4o). Moreover, our comparative human experiments highlight a striking\ncontrast in error types between LLMs and humans: LLMs primarily make\napplicability errors, whereas humans mostly make statistical task confusion\nerrors. This divergence highlights distinct areas of proficiency and\ndeficiency, suggesting that combining LLM and human expertise could lead to\ncomplementary strengths, inviting further investigation into their\ncollaborative potential. Our source code and data are available at\nhttps://statqa.github.io/.",
    "published": "2024-06-12T02:23:51Z",
    "pdf_url": "http://arxiv.org/pdf/2406.07815v2",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2407.01235v1",
    "title": "A Fingerprint for Large Language Models",
    "authors": [
      "Zhiguang Yang",
      "Hanzhou Wu"
    ],
    "abstract": "Recent advances show that scaling a pre-trained language model could achieve\nstate-of-the-art performance on many downstream tasks, prompting large language\nmodels (LLMs) to become a hot research topic in the field of artificial\nintelligence. However, due to the resource-intensive nature of training LLMs\nfrom scratch, it is urgent and crucial to protect the intellectual property of\nLLMs against infringement. This has motivated the authors in this paper to\npropose a novel black-box fingerprinting technique for LLMs, which requires\nneither model training nor model fine-tuning. We first demonstrate that the\noutputs of LLMs span a unique vector space associated with each model. We model\nthe problem of ownership authentication as the task of evaluating the\nsimilarity between the victim model's space and the output's space of the\nsuspect model. To deal with this problem, we propose two solutions, where the\nfirst solution involves verifying whether the outputs of the suspected large\nmodel are in the same space as those of the victim model, enabling rapid\nidentification of model infringement, and the second one reconstructs the union\nof the vector spaces for LLM outputs and the victim model to address situations\nwhere the victim model has undergone the Parameter-Efficient Fine-Tuning (PEFT)\nattacks. Experimental results indicate that the proposed technique achieves\nsuperior performance in ownership verification and robustness against PEFT\nattacks. This work reveals inherent characteristics of LLMs and provides a\npromising solution for ownership verification of LLMs in black-box scenarios,\nensuring efficiency, generality and practicality.",
    "published": "2024-07-01T12:25:42Z",
    "pdf_url": "http://arxiv.org/pdf/2407.01235v1",
    "categories": [
      "cs.CR"
    ]
  },
  {
    "arxiv_id": "2407.08564v1",
    "title": "The Career Interests of Large Language Models",
    "authors": [
      "Meng Hua",
      "Yuan Cheng",
      "Hengshu Zhu"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have significantly\nextended their capabilities, evolving from basic text generation to complex,\nhuman-like interactions. In light of the possibilities that LLMs could assume\nsignificant workplace responsibilities, it becomes imminently necessary to\nexplore LLMs' capacities as professional assistants. This study focuses on the\naspect of career interests by applying the Occupation Network's Interest\nProfiler short form to LLMs as if they were human participants and investigates\ntheir hypothetical career interests and competence, examining how these vary\nwith language changes and model advancements. We analyzed the answers using a\ngeneral linear mixed model approach and found distinct career interest\ninclinations among LLMs, particularly towards the social and artistic domains.\nInterestingly, these preferences did not align with the occupations where LLMs\nexhibited higher competence. This novel approach of using psychometric\ninstruments and sophisticated statistical tools on LLMs unveils fresh\nperspectives on their integration into professional environments, highlighting\nhuman-like tendencies and promoting a reevaluation of LLMs' self-perception and\ncompetency alignment in the workforce.",
    "published": "2024-07-11T14:54:46Z",
    "pdf_url": "http://arxiv.org/pdf/2407.08564v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2408.05568v1",
    "title": "Metacognitive Myopia in Large Language Models",
    "authors": [
      "Florian Scholten",
      "Tobias R. Rebholz",
      "Mandy Hütter"
    ],
    "abstract": "Large Language Models (LLMs) exhibit potentially harmful biases that\nreinforce culturally inherent stereotypes, cloud moral judgments, or amplify\npositive evaluations of majority groups. Previous explanations mainly\nattributed bias in LLMs to human annotators and the selection of training data.\nConsequently, they have typically been addressed with bottom-up approaches such\nas reinforcement learning or debiasing corpora. However, these methods only\ntreat the effects of LLM biases by indirectly influencing the model\narchitecture, but do not address the underlying causes in the computational\nprocess. Here, we propose metacognitive myopia as a cognitive-ecological\nframework that can account for a conglomerate of established and emerging LLM\nbiases and provide a lever to address problems in powerful but vulnerable\ntools. Our theoretical framework posits that a lack of the two components of\nmetacognition, monitoring and control, causes five symptoms of metacognitive\nmyopia in LLMs: integration of invalid tokens and embeddings, susceptibility to\nredundant information, neglect of base rates in conditional computation,\ndecision rules based on frequency, and inappropriate higher-order statistical\ninference for nested data structures. As a result, LLMs produce erroneous\noutput that reaches into the daily high-stakes decisions of humans. By\nintroducing metacognitive regulatory processes into LLMs, engineers and\nscientists can develop precise remedies for the underlying causes of these\nbiases. Our theory sheds new light on flawed human-machine interactions and\nraises ethical concerns regarding the increasing, imprudent implementation of\nLLMs in organizational structures.",
    "published": "2024-08-10T14:43:57Z",
    "pdf_url": "http://arxiv.org/pdf/2408.05568v1",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "stat.AP"
    ]
  },
  {
    "arxiv_id": "2408.16098v1",
    "title": "Structured Event Reasoning with Large Language Models",
    "authors": [
      "Li Zhang"
    ],
    "abstract": "Reasoning about real-life events is a unifying challenge in AI and NLP that\nhas profound utility in a variety of domains, while fallacy in high-stake\napplications could be catastrophic. Able to work with diverse text in these\ndomains, large language models (LLMs) have proven capable of answering\nquestions and solving problems. However, I show that end-to-end LLMs still\nsystematically fail to reason about complex events, and they lack\ninterpretability due to their black-box nature. To address these issues, I\npropose three general approaches to use LLMs in conjunction with a structured\nrepresentation of events. The first is a language-based representation\ninvolving relations of sub-events that can be learned by LLMs via fine-tuning.\nThe second is a semi-symbolic representation involving states of entities that\ncan be predicted and leveraged by LLMs via few-shot prompting. The third is a\nfully symbolic representation that can be predicted by LLMs trained with\nstructured data and be executed by symbolic solvers. On a suite of event\nreasoning tasks spanning common-sense inference and planning, I show that each\napproach greatly outperforms end-to-end LLMs with more interpretability. These\nresults suggest manners of synergy between LLMs and structured representations\nfor event reasoning and beyond.",
    "published": "2024-08-28T19:03:41Z",
    "pdf_url": "http://arxiv.org/pdf/2408.16098v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2412.14501v2",
    "title": "Do Large Language Models Advocate for Inferentialism?",
    "authors": [
      "Yuzuki Arai",
      "Sho Tsugawa"
    ],
    "abstract": "The emergence of large language models (LLMs) such as ChatGPT and Claude\npresents new challenges for philosophy of language, particularly regarding the\nnature of linguistic meaning and representation. While LLMs have traditionally\nbeen understood through distributional semantics, this paper explores Robert\nBrandom's inferential semantics as an alternative foundational framework for\nunderstanding these systems. We examine how key features of inferential\nsemantics -- including its anti-representationalist stance, logical\nexpressivism, and quasi-compositional approach -- align with the architectural\nand functional characteristics of Transformer-based LLMs. Through analysis of\nthe ISA (Inference, Substitution, Anaphora) approach, we demonstrate that LLMs\nexhibit fundamentally anti-representationalist properties in their processing\nof language. We further develop a consensus theory of truth appropriate for\nLLMs, grounded in their interactive and normative dimensions through mechanisms\nlike RLHF. While acknowledging significant tensions between inferentialism's\nphilosophical commitments and LLMs' sub-symbolic processing, this paper argues\nthat inferential semantics provides valuable insights into how LLMs generate\nmeaning without reference to external world representations. Our analysis\nsuggests that LLMs may challenge traditional assumptions in philosophy of\nlanguage, including strict compositionality and semantic externalism, though\nfurther empirical investigation is needed to fully substantiate these\ntheoretical claims.",
    "published": "2024-12-19T03:48:40Z",
    "pdf_url": "http://arxiv.org/pdf/2412.14501v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2503.03135v2",
    "title": "Bridging Molecular Graphs and Large Language Models",
    "authors": [
      "Runze Wang",
      "Mingqi Yang",
      "Yanming Shen"
    ],
    "abstract": "While Large Language Models (LLMs) have shown exceptional generalization\ncapabilities, their ability to process graph data, such as molecular\nstructures, remains limited. To bridge this gap, this paper proposes\nGraph2Token, an efficient solution that aligns graph tokens to LLM tokens. The\nkey idea is to represent a graph token with the LLM token vocabulary, without\nfine-tuning the LLM backbone. To achieve this goal, we first construct a\nmolecule-text paired dataset from multisources, including CHEBI and HMDB, to\ntrain a graph structure encoder, which reduces the distance between graphs and\ntexts representations in the feature space. Then, we propose a novel alignment\nstrategy that associates a graph token with LLM tokens. To further unleash the\npotential of LLMs, we collect molecular IUPAC name identifiers, which are\nincorporated into the LLM prompts. By aligning molecular graphs as special\ntokens, we can activate LLM generalization ability to molecular few-shot\nlearning. Extensive experiments on molecular classification and regression\ntasks demonstrate the effectiveness of our proposed Graph2Token.",
    "published": "2025-03-05T03:15:38Z",
    "pdf_url": "http://arxiv.org/pdf/2503.03135v2",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2503.07627v1",
    "title": "Psychological Counseling Ability of Large Language Models",
    "authors": [
      "Fangyu Peng",
      "Jingxin Nie"
    ],
    "abstract": "With the development of science and the continuous progress of artificial\nintelligence technology, Large Language Models (LLMs) have begun to be widely\nutilized across various fields. However, in the field of psychological\ncounseling, the ability of LLMs have not been systematically assessed. In this\nstudy, we assessed the psychological counseling ability of mainstream LLMs\nusing 1096 psychological counseling skill questions which were selected from\nthe Chinese National Counselor Level 3 Examination, including Knowledge-based,\nAnalytical-based, and Application-based question types. The analysis showed\nthat the correctness rates of the LLMs for Chinese questions, in descending\norder, were GLM-3 (46.5%), GPT-4 (46.1%), Gemini (45.0%), ERNIE-3.5 (45.7%) and\nGPT-3.5 (32.9%). The correctness rates of the LLMs for English questions, in\ndescending order, were ERNIE-3.5 (43.9%), GPT-4 (40.6%), Gemini (36.6%), GLM-3\n(29.9%) and GPT-3.5 (29.5%). A chi-square test indicated significant\ndifferences in the LLMs' performance on Chinese and English questions.\nFurthermore, we subsequently utilized the Counselor's Guidebook (Level 3) as a\nreference for ERNIE-3.5, resulting in a new correctness rate of 59.6%, a 13.8%\nimprovement over its initial rate of 45.8%. In conclusion, the study assessed\nthe psychological counseling ability of LLMs for the first time, which may\nprovide insights for future enhancement and improvement of psychological\ncounseling ability of LLMs.",
    "published": "2025-03-01T08:01:25Z",
    "pdf_url": "http://arxiv.org/pdf/2503.07627v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "2505.00662v1",
    "title": "DeepCritic: Deliberate Critique with Large Language Models",
    "authors": [
      "Wenkai Yang",
      "Jingwen Chen",
      "Yankai Lin",
      "Ji-Rong Wen"
    ],
    "abstract": "As Large Language Models (LLMs) are rapidly evolving, providing accurate\nfeedback and scalable oversight on their outputs becomes an urgent and critical\nproblem. Leveraging LLMs as critique models to achieve automated supervision is\na promising solution. In this work, we focus on studying and enhancing the math\ncritique ability of LLMs. Current LLM critics provide critiques that are too\nshallow and superficial on each step, leading to low judgment accuracy and\nstruggling to offer sufficient feedback for the LLM generator to correct\nmistakes. To tackle this issue, we propose a novel and effective two-stage\nframework to develop LLM critics that are capable of deliberately critiquing on\neach reasoning step of math solutions. In the first stage, we utilize\nQwen2.5-72B-Instruct to generate 4.5K long-form critiques as seed data for\nsupervised fine-tuning. Each seed critique consists of deliberate step-wise\ncritiques that includes multi-perspective verifications as well as in-depth\ncritiques of initial critiques for each reasoning step. Then, we perform\nreinforcement learning on the fine-tuned model with either existing\nhuman-labeled data from PRM800K or our automatically annotated data obtained\nvia Monte Carlo sampling-based correctness estimation, to further incentivize\nits critique ability. Our developed critique model built on Qwen2.5-7B-Instruct\nnot only significantly outperforms existing LLM critics (including the\nsame-sized DeepSeek-R1-distill models and GPT-4o) on various error\nidentification benchmarks, but also more effectively helps the LLM generator\nrefine erroneous steps through more detailed feedback.",
    "published": "2025-05-01T17:03:17Z",
    "pdf_url": "http://arxiv.org/pdf/2505.00662v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2305.16867v2",
    "title": "Playing repeated games with Large Language Models",
    "authors": [
      "Elif Akata",
      "Lion Schulz",
      "Julian Coda-Forno",
      "Seong Joon Oh",
      "Matthias Bethge",
      "Eric Schulz"
    ],
    "abstract": "LLMs are increasingly used in applications where they interact with humans\nand other agents. We propose to use behavioural game theory to study LLM's\ncooperation and coordination behaviour. We let different LLMs play finitely\nrepeated $2\\times2$ games with each other, with human-like strategies, and\nactual human players. Our results show that LLMs perform particularly well at\nself-interested games like the iterated Prisoner's Dilemma family. However,\nthey behave sub-optimally in games that require coordination, like the Battle\nof the Sexes. We verify that these behavioural signatures are stable across\nrobustness checks. We additionally show how GPT-4's behaviour can be modulated\nby providing additional information about its opponent and by using a \"social\nchain-of-thought\" (SCoT) strategy. This also leads to better scores and more\nsuccessful coordination when interacting with human players. These results\nenrich our understanding of LLM's social behaviour and pave the way for a\nbehavioural game theory for machines.",
    "published": "2023-05-26T12:17:59Z",
    "pdf_url": "http://arxiv.org/pdf/2305.16867v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2205.13621v2",
    "title": "Differentially Private Decoding in Large Language Models",
    "authors": [
      "Jimit Majmudar",
      "Christophe Dupuy",
      "Charith Peris",
      "Sami Smaili",
      "Rahul Gupta",
      "Richard Zemel"
    ],
    "abstract": "Recent large-scale natural language processing (NLP) systems use a\npre-trained Large Language Model (LLM) on massive and diverse corpora as a\nheadstart. In practice, the pre-trained model is adapted to a wide array of\ntasks via fine-tuning on task-specific datasets. LLMs, while effective, have\nbeen shown to memorize instances of training data thereby potentially revealing\nprivate information processed during pre-training. The potential leakage might\nfurther propagate to the downstream tasks for which LLMs are fine-tuned. On the\nother hand, privacy-preserving algorithms usually involve retraining from\nscratch, which is prohibitively expensive for LLMs. In this work, we propose a\nsimple, easy to interpret, and computationally lightweight perturbation\nmechanism to be applied to an already trained model at the decoding stage. Our\nperturbation mechanism is model-agnostic and can be used in conjunction with\nany LLM. We provide theoretical analysis showing that the proposed mechanism is\ndifferentially private, and experimental results showing a privacy-utility\ntrade-off.",
    "published": "2022-05-26T20:50:58Z",
    "pdf_url": "http://arxiv.org/pdf/2205.13621v2",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2211.15458v2",
    "title": "Validating Large Language Models with ReLM",
    "authors": [
      "Michael Kuchnik",
      "Virginia Smith",
      "George Amvrosiadis"
    ],
    "abstract": "Although large language models (LLMs) have been touted for their ability to\ngenerate natural-sounding text, there are growing concerns around possible\nnegative effects of LLMs such as data memorization, bias, and inappropriate\nlanguage. Unfortunately, the complexity and generation capacities of LLMs make\nvalidating (and correcting) such concerns difficult. In this work, we introduce\nReLM, a system for validating and querying LLMs using standard regular\nexpressions. ReLM formalizes and enables a broad range of language model\nevaluations, reducing complex evaluation rules to simple regular expression\nqueries. Our results exploring queries surrounding memorization, gender bias,\ntoxicity, and language understanding show that ReLM achieves up to 15x higher\nsystem efficiency, 2.5x data efficiency, and increased statistical and\nprompt-tuning coverage compared to state-of-the-art ad-hoc queries. ReLM offers\na competitive and general baseline for the increasingly important problem of\nLLM validation.",
    "published": "2022-11-21T21:40:35Z",
    "pdf_url": "http://arxiv.org/pdf/2211.15458v2",
    "categories": [
      "cs.LG",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2302.05817v2",
    "title": "Level Generation Through Large Language Models",
    "authors": [
      "Graham Todd",
      "Sam Earle",
      "Muhammad Umair Nasir",
      "Michael Cerny Green",
      "Julian Togelius"
    ],
    "abstract": "Large Language Models (LLMs) are powerful tools, capable of leveraging their\ntraining on natural language to write stories, generate code, and answer\nquestions. But can they generate functional video game levels? Game levels,\nwith their complex functional constraints and spatial relationships in more\nthan one dimension, are very different from the kinds of data an LLM typically\nsees during training. Datasets of game levels are also hard to come by,\npotentially taxing the abilities of these data-hungry models. We investigate\nthe use of LLMs to generate levels for the game Sokoban, finding that LLMs are\nindeed capable of doing so, and that their performance scales dramatically with\ndataset size. We also perform preliminary experiments on controlling LLM level\ngenerators and discuss promising areas for future work.",
    "published": "2023-02-11T23:34:42Z",
    "pdf_url": "http://arxiv.org/pdf/2302.05817v2",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "2304.00116v1",
    "title": "Enhancing Large Language Models with Climate Resources",
    "authors": [
      "Mathias Kraus",
      "Julia Anna Bingler",
      "Markus Leippold",
      "Tobias Schimanski",
      "Chiara Colesanti Senni",
      "Dominik Stammbach",
      "Saeid Ashraf Vaghefi",
      "Nicolas Webersinke"
    ],
    "abstract": "Large language models (LLMs) have significantly transformed the landscape of\nartificial intelligence by demonstrating their ability in generating human-like\ntext across diverse topics. However, despite their impressive capabilities,\nLLMs lack recent information and often employ imprecise language, which can be\ndetrimental in domains where accuracy is crucial, such as climate change. In\nthis study, we make use of recent ideas to harness the potential of LLMs by\nviewing them as agents that access multiple sources, including databases\ncontaining recent and precise information about organizations, institutions,\nand companies. We demonstrate the effectiveness of our method through a\nprototype agent that retrieves emission data from ClimateWatch\n(https://www.climatewatchdata.org/) and leverages general Google search. By\nintegrating these resources with LLMs, our approach overcomes the limitations\nassociated with imprecise language and delivers more reliable and accurate\ninformation in the critical domain of climate change. This work paves the way\nfor future advancements in LLMs and their application in domains where\nprecision is of paramount importance.",
    "published": "2023-03-31T20:24:14Z",
    "pdf_url": "http://arxiv.org/pdf/2304.00116v1",
    "categories": [
      "cs.CL",
      "cs.IR"
    ]
  },
  {
    "arxiv_id": "2306.09597v4",
    "title": "Clickbait Detection via Large Language Models",
    "authors": [
      "Han Wang",
      "Yi Zhu",
      "Ye Wang",
      "Yun Li",
      "Yunhao Yuan",
      "Jipeng Qiang"
    ],
    "abstract": "Clickbait, which aims to induce users with some surprising and even thrilling\nheadlines for increasing click-through rates, permeates almost all online\ncontent publishers, such as news portals and social media. Recently, Large\nLanguage Models (LLMs) have emerged as a powerful instrument and achieved\ntremendous success in a series of NLP downstream tasks. However, it is not yet\nknown whether LLMs can be served as a high-quality clickbait detection system.\nIn this paper, we analyze the performance of LLMs in the few-shot and zero-shot\nscenarios on several English and Chinese benchmark datasets. Experimental\nresults show that LLMs cannot achieve the best results compared to the\nstate-of-the-art deep and fine-tuning PLMs methods. Different from human\nintuition, the experiments demonstrated that LLMs cannot make satisfied\nclickbait detection just by the headlines.",
    "published": "2023-06-16T02:49:20Z",
    "pdf_url": "http://arxiv.org/pdf/2306.09597v4",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2310.02932v2",
    "title": "Assessing Large Language Models on Climate Information",
    "authors": [
      "Jannis Bulian",
      "Mike S. Schäfer",
      "Afra Amini",
      "Heidi Lam",
      "Massimiliano Ciaramita",
      "Ben Gaiarin",
      "Michelle Chen Hübscher",
      "Christian Buck",
      "Niels G. Mede",
      "Markus Leippold",
      "Nadine Strauß"
    ],
    "abstract": "As Large Language Models (LLMs) rise in popularity, it is necessary to assess\ntheir capability in critically relevant domains. We present a comprehensive\nevaluation framework, grounded in science communication research, to assess LLM\nresponses to questions about climate change. Our framework emphasizes both\npresentational and epistemological adequacy, offering a fine-grained analysis\nof LLM generations spanning 8 dimensions and 30 issues. Our evaluation task is\na real-world example of a growing number of challenging problems where AI can\ncomplement and lift human performance. We introduce a novel protocol for\nscalable oversight that relies on AI Assistance and raters with relevant\neducation. We evaluate several recent LLMs on a set of diverse climate\nquestions. Our results point to a significant gap between surface and\nepistemological qualities of LLMs in the realm of climate communication.",
    "published": "2023-10-04T16:09:48Z",
    "pdf_url": "http://arxiv.org/pdf/2310.02932v2",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2310.13002v1",
    "title": "Are Large Language Models Geospatially Knowledgeable?",
    "authors": [
      "Prabin Bhandari",
      "Antonios Anastasopoulos",
      "Dieter Pfoser"
    ],
    "abstract": "Despite the impressive performance of Large Language Models (LLM) for various\nnatural language processing tasks, little is known about their comprehension of\ngeographic data and related ability to facilitate informed geospatial\ndecision-making. This paper investigates the extent of geospatial knowledge,\nawareness, and reasoning abilities encoded within such pretrained LLMs. With a\nfocus on autoregressive language models, we devise experimental approaches\nrelated to (i) probing LLMs for geo-coordinates to assess geospatial knowledge,\n(ii) using geospatial and non-geospatial prepositions to gauge their geospatial\nawareness, and (iii) utilizing a multidimensional scaling (MDS) experiment to\nassess the models' geospatial reasoning capabilities and to determine locations\nof cities based on prompting. Our results confirm that it does not only take\nlarger, but also more sophisticated LLMs to synthesize geospatial knowledge\nfrom textual information. As such, this research contributes to understanding\nthe potential and limitations of LLMs in dealing with geospatial information.",
    "published": "2023-10-09T17:20:11Z",
    "pdf_url": "http://arxiv.org/pdf/2310.13002v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2312.04528v2",
    "title": "Using Large Language Models for Hyperparameter Optimization",
    "authors": [
      "Michael R. Zhang",
      "Nishkrit Desai",
      "Juhan Bae",
      "Jonathan Lorraine",
      "Jimmy Ba"
    ],
    "abstract": "This paper explores the use of foundational large language models (LLMs) in\nhyperparameter optimization (HPO). Hyperparameters are critical in determining\nthe effectiveness of machine learning models, yet their optimization often\nrelies on manual approaches in limited-budget settings. By prompting LLMs with\ndataset and model descriptions, we develop a methodology where LLMs suggest\nhyperparameter configurations, which are iteratively refined based on model\nperformance. Our empirical evaluations on standard benchmarks reveal that\nwithin constrained search budgets, LLMs can match or outperform traditional HPO\nmethods like Bayesian optimization across different models on standard\nbenchmarks. Furthermore, we propose to treat the code specifying our model as a\nhyperparameter, which the LLM outputs and affords greater flexibility than\nexisting HPO approaches.",
    "published": "2023-12-07T18:46:50Z",
    "pdf_url": "http://arxiv.org/pdf/2312.04528v2",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2312.05516v3",
    "title": "Stateful Large Language Model Serving with Pensieve",
    "authors": [
      "Lingfan Yu",
      "Jinkun Lin",
      "Jinyang Li"
    ],
    "abstract": "Large Language Models (LLMs) are wildly popular today and it is important to\nserve them efficiently. Existing LLM serving systems are stateless across\nrequests. Consequently, when LLMs are used in the common setting of multi-turn\nconversations, a growing log of the conversation history must be processed\nalongside any request by the serving system at each turn, resulting in repeated\nprocessing.\n  In this paper, we design $Pensieve$, a system optimized for multi-turn\nconversation LLM serving. $Pensieve$ maintains the conversation state across\nrequests by caching previously processed history to avoid duplicate processing.\n$Pensieve$'s multi-tier caching strategy can utilize both GPU and CPU memory to\nefficiently store and retrieve cached data. $Pensieve$ also generalizes the\nrecent PagedAttention kernel to support attention between multiple input tokens\nwith a GPU cache spread over non-contiguous memory. Our evaluation shows that\n$Pensieve$ can achieve $1.14$-$3.0\\times$ the throughput of vLLM and\nTensorRT-LLM and significantly reduce latency.",
    "published": "2023-12-09T09:55:07Z",
    "pdf_url": "http://arxiv.org/pdf/2312.05516v3",
    "categories": [
      "cs.LG",
      "cs.DC"
    ]
  },
  {
    "arxiv_id": "2402.03147v1",
    "title": "Detecting Scams Using Large Language Models",
    "authors": [
      "Liming Jiang"
    ],
    "abstract": "Large Language Models (LLMs) have gained prominence in various applications,\nincluding security. This paper explores the utility of LLMs in scam detection,\na critical aspect of cybersecurity. Unlike traditional applications, we propose\na novel use case for LLMs to identify scams, such as phishing, advance fee\nfraud, and romance scams. We present notable security applications of LLMs and\ndiscuss the unique challenges posed by scams. Specifically, we outline the key\nsteps involved in building an effective scam detector using LLMs, emphasizing\ndata collection, preprocessing, model selection, training, and integration into\ntarget systems. Additionally, we conduct a preliminary evaluation using GPT-3.5\nand GPT-4 on a duplicated email, highlighting their proficiency in identifying\ncommon signs of phishing or scam emails. The results demonstrate the models'\neffectiveness in recognizing suspicious elements, but we emphasize the need for\na comprehensive assessment across various language tasks. The paper concludes\nby underlining the importance of ongoing refinement and collaboration with\ncybersecurity experts to adapt to evolving threats.",
    "published": "2024-02-05T16:13:54Z",
    "pdf_url": "http://arxiv.org/pdf/2402.03147v1",
    "categories": [
      "cs.CR"
    ]
  },
  {
    "arxiv_id": "2403.05063v2",
    "title": "Aligning Large Language Models for Controllable Recommendations",
    "authors": [
      "Wensheng Lu",
      "Jianxun Lian",
      "Wei Zhang",
      "Guanghua Li",
      "Mingyang Zhou",
      "Hao Liao",
      "Xing Xie"
    ],
    "abstract": "Inspired by the exceptional general intelligence of Large Language Models\n(LLMs), researchers have begun to explore their application in pioneering the\nnext generation of recommender systems - systems that are conversational,\nexplainable, and controllable. However, existing literature primarily\nconcentrates on integrating domain-specific knowledge into LLMs to enhance\naccuracy, often neglecting the ability to follow instructions. To address this\ngap, we initially introduce a collection of supervised learning tasks,\naugmented with labels derived from a conventional recommender model, aimed at\nexplicitly improving LLMs' proficiency in adhering to recommendation-specific\ninstructions. Subsequently, we develop a reinforcement learning-based alignment\nprocedure to further strengthen LLMs' aptitude in responding to users'\nintentions and mitigating formatting errors. Through extensive experiments on\ntwo real-world datasets, our method markedly advances the capability of LLMs to\ncomply with instructions within recommender systems, while sustaining a high\nlevel of accuracy performance.",
    "published": "2024-03-08T05:23:27Z",
    "pdf_url": "http://arxiv.org/pdf/2403.05063v2",
    "categories": [
      "cs.IR",
      "cs.AI",
      "68T50"
    ]
  },
  {
    "arxiv_id": "2403.06259v2",
    "title": "Editing Conceptual Knowledge for Large Language Models",
    "authors": [
      "Xiaohan Wang",
      "Shengyu Mao",
      "Ningyu Zhang",
      "Shumin Deng",
      "Yunzhi Yao",
      "Yue Shen",
      "Lei Liang",
      "Jinjie Gu",
      "Huajun Chen"
    ],
    "abstract": "Recently, there has been a growing interest in knowledge editing for Large\nLanguage Models (LLMs). Current approaches and evaluations merely explore the\ninstance-level editing, while whether LLMs possess the capability to modify\nconcepts remains unclear. This paper pioneers the investigation of editing\nconceptual knowledge for LLMs, by constructing a novel benchmark dataset\nConceptEdit and establishing a suite of new metrics for evaluation. The\nexperimental results reveal that, although existing editing methods can\nefficiently modify concept-level definition to some extent, they also have the\npotential to distort the related instantial knowledge in LLMs, leading to poor\nperformance. We anticipate this can inspire further progress in better\nunderstanding LLMs. Our project homepage is available at\nhttps://zjunlp.github.io/project/ConceptEdit.",
    "published": "2024-03-10T16:57:10Z",
    "pdf_url": "http://arxiv.org/pdf/2403.06259v2",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB",
      "cs.IR",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2404.16841v1",
    "title": "Machine Unlearning in Large Language Models",
    "authors": [
      "Kongyang Chen",
      "Zixin Wang",
      "Bing Mi",
      "Waixi Liu",
      "Shaowei Wang",
      "Xiaojun Ren",
      "Jiaxing Shen"
    ],
    "abstract": "Recently, large language models (LLMs) have emerged as a notable field,\nattracting significant attention for its ability to automatically generate\nintelligent contents for various application domains. However, LLMs still\nsuffer from significant security and privacy issues. For example, LLMs might\nexpose user privacy from hacking attacks or targeted prompts. To address this\nproblem, this paper introduces a novel machine unlearning framework into LLMs.\nOur objectives are to make LLMs not produce harmful, hallucinatory, or\nprivacy-compromising responses, while retaining their standard output\ncapabilities. To accomplish this, we use an evaluative model to pinpoint\ndialogues needing unlearning. We also establish a distance loss to function as\nthe model's negative loss, diverting it from previous undesirable outputs.\nFurthermore, we determine the expected output's cluster mean to formulate a\npositive loss, directing the model's outputs toward preferable outcomes without\ncompromising its reasoning abilities and performance. Experimental results show\nthat our approach effectively meets unlearning objectives without substantially\ncompromising model performance.",
    "published": "2024-02-03T05:14:56Z",
    "pdf_url": "http://arxiv.org/pdf/2404.16841v1",
    "categories": [
      "cs.CR"
    ]
  },
  {
    "arxiv_id": "2405.11581v2",
    "title": "DOLLmC: DevOps for Large Language model Customization",
    "authors": [
      "Panos Fitsilis",
      "Vyron Damasiotis",
      "Vasileios Kyriatzis",
      "Paraskevi Tsoutsa"
    ],
    "abstract": "The rapid integration of Large Language Models (LLMs) into various industries\npresents both revolutionary opportunities and unique challenges. This research\naims to establish a scalable and efficient framework for LLM customization,\nexploring how DevOps practices should be adapted to meet the specific demands\nof LLM customization. By integrating ontologies, knowledge maps, and prompt\nengineering into the DevOps pipeline, we propose a robust framework that\nenhances continuous learning, seamless deployment, and rigorous version control\nof LLMs. This methodology is demonstrated through the development of a\ndomain-specific chatbot for the agricultural sector, utilizing heterogeneous\ndata to deliver actionable insights. The proposed methodology, so called\nDOLLmC, not only addresses the immediate challenges of LLM customization but\nalso promotes scalability and operational efficiency. However, the\nmethodology's primary limitation lies in the need for extensive testing,\nvalidation, and broader adoption across different domains.",
    "published": "2024-05-19T15:20:27Z",
    "pdf_url": "http://arxiv.org/pdf/2405.11581v2",
    "categories": [
      "cs.SE",
      "D.2.9"
    ]
  },
  {
    "arxiv_id": "2405.19563v1",
    "title": "Unlearning Climate Misinformation in Large Language Models",
    "authors": [
      "Michael Fore",
      "Simranjit Singh",
      "Chaehong Lee",
      "Amritanshu Pandey",
      "Antonios Anastasopoulos",
      "Dimitrios Stamoulis"
    ],
    "abstract": "Misinformation regarding climate change is a key roadblock in addressing one\nof the most serious threats to humanity. This paper investigates factual\naccuracy in large language models (LLMs) regarding climate information. Using\ntrue/false labeled Q&A data for fine-tuning and evaluating LLMs on\nclimate-related claims, we compare open-source models, assessing their ability\nto generate truthful responses to climate change questions. We investigate the\ndetectability of models intentionally poisoned with false climate information,\nfinding that such poisoning may not affect the accuracy of a model's responses\nin other domains. Furthermore, we compare the effectiveness of unlearning\nalgorithms, fine-tuning, and Retrieval-Augmented Generation (RAG) for factually\ngrounding LLMs on climate change topics. Our evaluation reveals that unlearning\nalgorithms can be effective for nuanced conceptual claims, despite previous\nfindings suggesting their inefficacy in privacy contexts. These insights aim to\nguide the development of more factually reliable LLMs and highlight the need\nfor additional work to secure LLMs against misinformation attacks.",
    "published": "2024-05-29T23:11:53Z",
    "pdf_url": "http://arxiv.org/pdf/2405.19563v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2406.07914v2",
    "title": "Can Large Language Models Understand Spatial Audio?",
    "authors": [
      "Changli Tang",
      "Wenyi Yu",
      "Guangzhi Sun",
      "Xianzhao Chen",
      "Tian Tan",
      "Wei Li",
      "Jun Zhang",
      "Lu Lu",
      "Zejun Ma",
      "Yuxuan Wang",
      "Chao Zhang"
    ],
    "abstract": "This paper explores enabling large language models (LLMs) to understand\nspatial information from multichannel audio, a skill currently lacking in\nauditory LLMs. By leveraging LLMs' advanced cognitive and inferential\nabilities, the aim is to enhance understanding of 3D environments via audio. We\nstudy 3 spatial audio tasks: sound source localization (SSL), far-field speech\nrecognition (FSR), and localisation-informed speech extraction (LSE), achieving\nnotable progress in each task. For SSL, our approach achieves an MAE of\n$2.70^{\\circ}$ on the Spatial LibriSpeech dataset, substantially surpassing the\nprior benchmark of about $6.60^{\\circ}$. Moreover, our model can employ spatial\ncues to improve FSR accuracy and execute LSE by selectively attending to sounds\noriginating from a specified direction via text prompts, even amidst\noverlapping speech. These findings highlight the potential of adapting LLMs to\ngrasp physical audio concepts, paving the way for LLM-based agents in 3D\nenvironments.",
    "published": "2024-06-12T06:34:21Z",
    "pdf_url": "http://arxiv.org/pdf/2406.07914v2",
    "categories": [
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2406.18616v1",
    "title": "Towards Large Language Model Aided Program Refinement",
    "authors": [
      "Yufan Cai",
      "Zhe Hou",
      "Xiaokun Luan",
      "David Miguel Sanan Baena",
      "Yun Lin",
      "Jun Sun",
      "Jin Song Dong"
    ],
    "abstract": "Program refinement involves correctness-preserving transformations from\nformal high-level specification statements into executable programs.\nTraditional verification tool support for program refinement is highly\ninteractive and lacks automation. On the other hand, the emergence of large\nlanguage models (LLMs) enables automatic code generations from informal natural\nlanguage specifications. However, code generated by LLMs is often unreliable.\nMoreover, the opaque procedure from specification to code provided by LLM is an\nuncontrolled black box. We propose LLM4PR, a tool that combines formal program\nrefinement techniques with informal LLM-based methods to (1) transform the\nspecification to preconditions and postconditions, (2) automatically build\nprompts based on refinement calculus, (3) interact with LLM to generate code,\nand finally, (4) verify that the generated code satisfies the conditions of\nrefinement calculus, thus guaranteeing the correctness of the code. We have\nimplemented our tool using GPT4, Coq, and Coqhammer, and evaluated it on the\nHumanEval and EvalPlus datasets.",
    "published": "2024-06-26T04:29:27Z",
    "pdf_url": "http://arxiv.org/pdf/2406.18616v1",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "K.6.3"
    ]
  },
  {
    "arxiv_id": "2407.15847v4",
    "title": "LLMmap: Fingerprinting For Large Language Models",
    "authors": [
      "Dario Pasquini",
      "Evgenios M. Kornaropoulos",
      "Giuseppe Ateniese"
    ],
    "abstract": "We introduce LLMmap, a first-generation fingerprinting technique targeted at\nLLM-integrated applications. LLMmap employs an active fingerprinting approach,\nsending carefully crafted queries to the application and analyzing the\nresponses to identify the specific LLM version in use. Our query selection is\ninformed by domain expertise on how LLMs generate uniquely identifiable\nresponses to thematically varied prompts. With as few as 8 interactions, LLMmap\ncan accurately identify 42 different LLM versions with over 95% accuracy. More\nimportantly, LLMmap is designed to be robust across different application\nlayers, allowing it to identify LLM versions--whether open-source or\nproprietary--from various vendors, operating under various unknown system\nprompts, stochastic sampling hyperparameters, and even complex generation\nframeworks such as RAG or Chain-of-Thought. We discuss potential mitigations\nand demonstrate that, against resourceful adversaries, effective\ncountermeasures may be challenging or even unrealizable.",
    "published": "2024-07-22T17:59:45Z",
    "pdf_url": "http://arxiv.org/pdf/2407.15847v4",
    "categories": [
      "cs.CR",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2408.11316v2",
    "title": "Probabilistic Medical Predictions of Large Language Models",
    "authors": [
      "Bowen Gu",
      "Rishi J. Desai",
      "Kueiyu Joshua Lin",
      "Jie Yang"
    ],
    "abstract": "Large Language Models (LLMs) have shown promise in clinical applications\nthrough prompt engineering, allowing flexible clinical predictions. However,\nthey struggle to produce reliable prediction probabilities, which are crucial\nfor transparency and decision-making. While explicit prompts can lead LLMs to\ngenerate probability estimates, their numerical reasoning limitations raise\nconcerns about reliability. We compared explicit probabilities from text\ngeneration to implicit probabilities derived from the likelihood of predicting\nthe correct label token. Across six advanced open-source LLMs and five medical\ndatasets, explicit probabilities consistently underperformed implicit\nprobabilities in discrimination, precision, and recall. This discrepancy is\nmore pronounced with smaller LLMs and imbalanced datasets, highlighting the\nneed for cautious interpretation, improved probability estimation methods, and\nfurther research for clinical use of LLMs.",
    "published": "2024-08-21T03:47:17Z",
    "pdf_url": "http://arxiv.org/pdf/2408.11316v2",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2410.02724v2",
    "title": "Large Language Models as Markov Chains",
    "authors": [
      "Oussama Zekri",
      "Ambroise Odonnat",
      "Abdelhakim Benechehab",
      "Linus Bleistein",
      "Nicolas Boullé",
      "Ievgen Redko"
    ],
    "abstract": "Large language models (LLMs) are remarkably efficient across a wide range of\nnatural language processing tasks and well beyond them. However, a\ncomprehensive theoretical analysis of the LLMs' generalization capabilities\nremains elusive. In our paper, we approach this task by drawing an equivalence\nbetween autoregressive transformer-based language models and Markov chains\ndefined on a finite state space. This allows us to study the multi-step\ninference mechanism of LLMs from first principles. We relate the obtained\nresults to the pathological behavior observed with LLMs such as repetitions and\nincoherent replies with high temperature. Finally, we leverage the proposed\nformalization to derive pre-training and in-context learning generalization\nbounds for LLMs under realistic data and model assumptions. Experiments with\nthe most recent Llama and Gemma herds of models show that our theory correctly\ncaptures their behavior in practice.",
    "published": "2024-10-03T17:45:31Z",
    "pdf_url": "http://arxiv.org/pdf/2410.02724v2",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2411.14513v1",
    "title": "Towards a Middleware for Large Language Models",
    "authors": [
      "Narcisa Guran",
      "Florian Knauf",
      "Man Ngo",
      "Stefan Petrescu",
      "Jan S. Rellermeyer"
    ],
    "abstract": "Large language models have gained widespread popularity for their ability to\nprocess natural language inputs and generate insights derived from their\ntraining data, nearing the qualities of true artificial intelligence. This\nadvancement has prompted enterprises worldwide to integrate LLMs into their\nservices. So far, this effort is dominated by commercial cloud-based solutions\nlike OpenAI's ChatGPT and Microsoft Azure. As the technology matures, however,\nthere is a strong incentive for independence from major cloud providers through\nself-hosting \"LLM as a Service\", driven by privacy, cost, and customization\nneeds. In practice, hosting LLMs independently presents significant challenges\ndue to their complexity and integration issues with existing systems. In this\npaper, we discuss our vision for a forward-looking middleware system\narchitecture that facilitates the deployment and adoption of LLMs in\nenterprises, even for advanced use cases in which we foresee LLMs to serve as\ngateways to a complete application ecosystem and, to some degree, absorb\nfunctionality traditionally attributed to the middleware.",
    "published": "2024-11-21T13:55:24Z",
    "pdf_url": "http://arxiv.org/pdf/2411.14513v1",
    "categories": [
      "cs.SE",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2412.10271v2",
    "title": "Benchmarking Linguistic Diversity of Large Language Models",
    "authors": [
      "Yanzhu Guo",
      "Guokan Shang",
      "Chloé Clavel"
    ],
    "abstract": "The development and evaluation of Large Language Models (LLMs) has primarily\nfocused on their task-solving capabilities, with recent models even surpassing\nhuman performance in some areas. However, this focus often neglects whether\nmachine-generated language matches the human level of diversity, in terms of\nvocabulary choice, syntactic construction, and expression of meaning, raising\nquestions about whether the fundamentals of language generation have been fully\naddressed. This paper emphasizes the importance of examining the preservation\nof human linguistic richness by language models, given the concerning surge in\nonline content produced or aided by LLMs. We propose a comprehensive framework\nfor evaluating LLMs from various linguistic diversity perspectives including\nlexical, syntactic, and semantic dimensions. Using this framework, we benchmark\nseveral state-of-the-art LLMs across all diversity dimensions, and conduct an\nin-depth case study for syntactic diversity. Finally, we analyze how different\ndevelopment and deployment choices impact the linguistic diversity of LLM\noutputs.",
    "published": "2024-12-13T16:46:03Z",
    "pdf_url": "http://arxiv.org/pdf/2412.10271v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2501.13720v2",
    "title": "Musical ethnocentrism in Large Language Models",
    "authors": [
      "Anna Kruspe"
    ],
    "abstract": "Large Language Models (LLMs) reflect the biases in their training data and,\nby extension, those of the people who created this training data. Detecting,\nanalyzing, and mitigating such biases is becoming a focus of research. One type\nof bias that has been understudied so far are geocultural biases. Those can be\ncaused by an imbalance in the representation of different geographic regions\nand cultures in the training data, but also by value judgments contained\ntherein. In this paper, we make a first step towards analyzing musical biases\nin LLMs, particularly ChatGPT and Mixtral. We conduct two experiments. In the\nfirst, we prompt LLMs to provide lists of the \"Top 100\" musical contributors of\nvarious categories and analyze their countries of origin. In the second\nexperiment, we ask the LLMs to numerically rate various aspects of the musical\ncultures of different countries. Our results indicate a strong preference of\nthe LLMs for Western music cultures in both experiments.",
    "published": "2025-01-23T14:50:37Z",
    "pdf_url": "http://arxiv.org/pdf/2501.13720v2",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2502.06065v1",
    "title": "Benchmarking Prompt Sensitivity in Large Language Models",
    "authors": [
      "Amirhossein Razavi",
      "Mina Soltangheis",
      "Negar Arabzadeh",
      "Sara Salamat",
      "Morteza Zihayat",
      "Ebrahim Bagheri"
    ],
    "abstract": "Large language Models (LLMs) are highly sensitive to variations in prompt\nformulation, which can significantly impact their ability to generate accurate\nresponses. In this paper, we introduce a new task, Prompt Sensitivity\nPrediction, and a dataset PromptSET designed to investigate the effects of\nslight prompt variations on LLM performance. Using TriviaQA and HotpotQA\ndatasets as the foundation of our work, we generate prompt variations and\nevaluate their effectiveness across multiple LLMs. We benchmark the prompt\nsensitivity prediction task employing state-of-the-art methods from related\ntasks, including LLM-based self-evaluation, text classification, and query\nperformance prediction techniques. Our findings reveal that existing methods\nstruggle to effectively address prompt sensitivity prediction, underscoring the\nneed to understand how information needs should be phrased for accurate LLM\nresponses.",
    "published": "2025-02-09T23:01:03Z",
    "pdf_url": "http://arxiv.org/pdf/2502.06065v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ]
  },
  {
    "arxiv_id": "2502.17504v2",
    "title": "Protein Large Language Models: A Comprehensive Survey",
    "authors": [
      "Yijia Xiao",
      "Wanjia Zhao",
      "Junkai Zhang",
      "Yiqiao Jin",
      "Han Zhang",
      "Zhicheng Ren",
      "Renliang Sun",
      "Haixin Wang",
      "Guancheng Wan",
      "Pan Lu",
      "Xiao Luo",
      "Yu Zhang",
      "James Zou",
      "Yizhou Sun",
      "Wei Wang"
    ],
    "abstract": "Protein-specific large language models (Protein LLMs) are revolutionizing\nprotein science by enabling more efficient protein structure prediction,\nfunction annotation, and design. While existing surveys focus on specific\naspects or applications, this work provides the first comprehensive overview of\nProtein LLMs, covering their architectures, training datasets, evaluation\nmetrics, and diverse applications. Through a systematic analysis of over 100\narticles, we propose a structured taxonomy of state-of-the-art Protein LLMs,\nanalyze how they leverage large-scale protein sequence data for improved\naccuracy, and explore their potential in advancing protein engineering and\nbiomedical research. Additionally, we discuss key challenges and future\ndirections, positioning Protein LLMs as essential tools for scientific\ndiscovery in protein science. Resources are maintained at\nhttps://github.com/Yijia-Xiao/Protein-LLM-Survey.",
    "published": "2025-02-21T19:22:10Z",
    "pdf_url": "http://arxiv.org/pdf/2502.17504v2",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.CE",
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2505.20993v1",
    "title": "Who Reasons in the Large Language Models?",
    "authors": [
      "Jie Shao",
      "Jianxin Wu"
    ],
    "abstract": "Despite the impressive performance of large language models (LLMs), the\nprocess of endowing them with new capabilities--such as mathematical\nreasoning--remains largely empirical and opaque. A critical open question is\nwhether reasoning abilities stem from the entire model, specific modules, or\nare merely artifacts of overfitting. In this work, we hypothesize that the\nreasoning capabilities in well-trained LLMs are primarily attributed to the\noutput projection module (oproj) in the Transformer's multi-head self-attention\n(MHSA) mechanism. To support this hypothesis, we introduce Stethoscope for\nNetworks (SfN), a suite of diagnostic tools designed to probe and analyze the\ninternal behaviors of LLMs. Using SfN, we provide both circumstantial and\nempirical evidence suggesting that oproj plays a central role in enabling\nreasoning, whereas other modules contribute more to fluent dialogue. These\nfindings offer a new perspective on LLM interpretability and open avenues for\nmore targeted training strategies, potentially enabling more efficient and\nspecialized LLMs.",
    "published": "2025-05-27T10:26:47Z",
    "pdf_url": "http://arxiv.org/pdf/2505.20993v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2506.20241v1",
    "title": "Enhancing Large Language Models through Structured Reasoning",
    "authors": [
      "Yubo Dong",
      "Hehe Fan"
    ],
    "abstract": "Recent Large Language Models (LLMs) have significantly advanced natural\nlanguage processing and automated decision-making. However, these models still\nencounter difficulties when performing complex reasoning tasks involving\nlogical deduction and systematic planning, primarily due to their reliance on\nimplicit statistical relationships without structured knowledge\nrepresentation.Inspired by cognitive science and neurosymbolic AI, we introduce\na novel approach to enhance LLMs through explicit structured reasoning. First,\nwe convert unstructured data into structured formats by explicitly annotating\nreasoning steps. We then employ this structured dataset to train LLMs through\nSupervised Fine-Tuning (SFT). Additionally, we enhance the structured reasoning\ncapabilities of LLMs using Group Relative Policy Optimization (GRPO),\nincorporating two innovative algorithms--MAX-Flow and Longest Common\nSubsequence (LCS)--which notably improve reasoning effectiveness and reduce\ncomputational complexity. Experimental results from fine-tuning a\nDeepSeek-R1-Distill-Qwen-1.5B model demonstrate concise reasoning, robust\nperformance across various scenarios, and improved compatibility with\noptimization techniques, validating the efficacy of structured reasoning\nintegration in LLMs.",
    "published": "2025-06-25T08:36:12Z",
    "pdf_url": "http://arxiv.org/pdf/2506.20241v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2506.20274v1",
    "title": "Enterprise Large Language Model Evaluation Benchmark",
    "authors": [
      "Liya Wang",
      "David Yi",
      "Damien Jose",
      "John Passarelli",
      "James Gao",
      "Jordan Leventis",
      "Kang Li"
    ],
    "abstract": "Large Language Models (LLMs) ) have demonstrated promise in boosting\nproductivity across AI-powered tools, yet existing benchmarks like Massive\nMultitask Language Understanding (MMLU) inadequately assess enterprise-specific\ntask complexities. We propose a 14-task framework grounded in Bloom's Taxonomy\nto holistically evaluate LLM capabilities in enterprise contexts. To address\nchallenges of noisy data and costly annotation, we develop a scalable pipeline\ncombining LLM-as-a-Labeler, LLM-as-a-Judge, and corrective retrieval-augmented\ngeneration (CRAG), curating a robust 9,700-sample benchmark. Evaluation of six\nleading models shows open-source contenders like DeepSeek R1 rival proprietary\nmodels in reasoning tasks but lag in judgment-based scenarios, likely due to\noverthinking. Our benchmark reveals critical enterprise performance gaps and\noffers actionable insights for model optimization. This work provides\nenterprises a blueprint for tailored evaluations and advances practical LLM\ndeployment.",
    "published": "2025-06-25T09:34:25Z",
    "pdf_url": "http://arxiv.org/pdf/2506.20274v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2508.17953v1",
    "title": "Understanding Subword Compositionality of Large Language Models",
    "authors": [
      "Qiwei Peng",
      "Yekun Chai",
      "Anders Søgaard"
    ],
    "abstract": "Large language models (LLMs) take sequences of subwords as input, requiring\nthem to effective compose subword representations into meaningful word-level\nrepresentations. In this paper, we present a comprehensive set of experiments\nto probe how LLMs compose subword information, focusing on three key aspects:\nstructural similarity, semantic decomposability, and form retention. Our\nanalysis of the experiments suggests that these five LLM families can be\nclassified into three distinct groups, likely reflecting difference in their\nunderlying composition strategies. Specifically, we observe (i) three distinct\npatterns in the evolution of structural similarity between subword compositions\nand whole-word representations across layers; (ii) great performance when\nprobing layer by layer their sensitivity to semantic decompositionality; and\n(iii) three distinct patterns when probing sensitivity to formal features,\ne.g., character sequence length. These findings provide valuable insights into\nthe compositional dynamics of LLMs and highlight different compositional\npattens in how LLMs encode and integrate subword information.",
    "published": "2025-08-25T12:16:56Z",
    "pdf_url": "http://arxiv.org/pdf/2508.17953v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2305.06972v3",
    "title": "Spear Phishing With Large Language Models",
    "authors": [
      "Julian Hazell"
    ],
    "abstract": "Recent progress in artificial intelligence (AI), particularly in the domain\nof large language models (LLMs), has resulted in powerful and versatile\ndual-use systems. This intelligence can be put towards a wide variety of\nbeneficial tasks, yet it can also be used to cause harm. This study explores\none such harm by examining how LLMs can be used for spear phishing, a form of\ncybercrime that involves manipulating targets into divulging sensitive\ninformation. I first explore LLMs' ability to assist with the reconnaissance\nand message generation stages of a spear phishing attack, where I find that\nLLMs are capable of assisting with the email generation phase of a spear\nphishing attack. To explore how LLMs could potentially be harnessed to scale\nspear phishing campaigns, I then create unique spear phishing messages for over\n600 British Members of Parliament using OpenAI's GPT-3.5 and GPT-4 models. My\nfindings provide some evidence that these messages are not only realistic but\nalso cost-effective, with each email costing only a fraction of a cent to\ngenerate. Next, I demonstrate how basic prompt engineering can circumvent\nsafeguards installed in LLMs, highlighting the need for further research into\nrobust interventions that can help prevent models from being misused. To\nfurther address these evolving risks, I explore two potential solutions:\nstructured access schemes, such as application programming interfaces, and\nLLM-based defensive systems.",
    "published": "2023-05-11T16:55:19Z",
    "pdf_url": "http://arxiv.org/pdf/2305.06972v3",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CR"
    ]
  },
  {
    "arxiv_id": "2210.03945v2",
    "title": "Understanding HTML with Large Language Models",
    "authors": [
      "Izzeddin Gur",
      "Ofir Nachum",
      "Yingjie Miao",
      "Mustafa Safdari",
      "Austin Huang",
      "Aakanksha Chowdhery",
      "Sharan Narang",
      "Noah Fiedel",
      "Aleksandra Faust"
    ],
    "abstract": "Large language models (LLMs) have shown exceptional performance on a variety\nof natural language tasks. Yet, their capabilities for HTML understanding --\ni.e., parsing the raw HTML of a webpage, with applications to automation of\nweb-based tasks, crawling, and browser-assisted retrieval -- have not been\nfully explored. We contribute HTML understanding models (fine-tuned LLMs) and\nan in-depth analysis of their capabilities under three tasks: (i) Semantic\nClassification of HTML elements, (ii) Description Generation for HTML inputs,\nand (iii) Autonomous Web Navigation of HTML pages. While previous work has\ndeveloped dedicated architectures and training procedures for HTML\nunderstanding, we show that LLMs pretrained on standard natural language\ncorpora transfer remarkably well to HTML understanding tasks. For instance,\nfine-tuned LLMs are 12% more accurate at semantic classification compared to\nmodels trained exclusively on the task dataset. Moreover, when fine-tuned on\ndata from the MiniWoB benchmark, LLMs successfully complete 50% more tasks\nusing 192x less data compared to the previous best supervised model. Out of the\nLLMs we evaluate, we show evidence that T5-based models are ideal due to their\nbidirectional encoder-decoder architecture. To promote further research on LLMs\nfor HTML understanding, we create and open-source a large-scale HTML dataset\ndistilled and auto-labeled from CommonCrawl.",
    "published": "2022-10-08T07:27:17Z",
    "pdf_url": "http://arxiv.org/pdf/2210.03945v2",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2304.00472v3",
    "title": "Querying Large Language Models with SQL",
    "authors": [
      "Mohammed Saeed",
      "Nicola De Cao",
      "Paolo Papotti"
    ],
    "abstract": "In many use-cases, information is stored in text but not available in\nstructured data. However, extracting data from natural language text to\nprecisely fit a schema, and thus enable querying, is a challenging task. With\nthe rise of pre-trained Large Language Models (LLMs), there is now an effective\nsolution to store and use information extracted from massive corpora of text\ndocuments. Thus, we envision the use of SQL queries to cover a broad range of\ndata that is not captured by traditional databases by tapping the information\nin LLMs. To ground this vision, we present Galois, a prototype based on a\ntraditional database architecture, but with new physical operators for querying\nthe underlying LLM. The main idea is to execute some operators of the the query\nplan with prompts that retrieve data from the LLM. For a large class of SQL\nqueries, querying LLMs returns well structured relations, with encouraging\nqualitative results. Preliminary experimental results make pre-trained LLMs a\npromising addition to the field of database systems, introducing a new\ndirection for hybrid query processing. However, we pinpoint several research\nchallenges that must be addressed to build a DBMS that exploits LLMs. While\nsome of these challenges necessitate integrating concepts from the NLP\nliterature, others offer novel research avenues for the DB community.",
    "published": "2023-04-02T06:58:14Z",
    "pdf_url": "http://arxiv.org/pdf/2304.00472v3",
    "categories": [
      "cs.DB",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2309.15025v1",
    "title": "Large Language Model Alignment: A Survey",
    "authors": [
      "Tianhao Shen",
      "Renren Jin",
      "Yufei Huang",
      "Chuang Liu",
      "Weilong Dong",
      "Zishan Guo",
      "Xinwei Wu",
      "Yan Liu",
      "Deyi Xiong"
    ],
    "abstract": "Recent years have witnessed remarkable progress made in large language models\n(LLMs). Such advancements, while garnering significant attention, have\nconcurrently elicited various concerns. The potential of these models is\nundeniably vast; however, they may yield texts that are imprecise, misleading,\nor even detrimental. Consequently, it becomes paramount to employ alignment\ntechniques to ensure these models to exhibit behaviors consistent with human\nvalues.\n  This survey endeavors to furnish an extensive exploration of alignment\nmethodologies designed for LLMs, in conjunction with the extant capability\nresearch in this domain. Adopting the lens of AI alignment, we categorize the\nprevailing methods and emergent proposals for the alignment of LLMs into outer\nand inner alignment. We also probe into salient issues including the models'\ninterpretability, and potential vulnerabilities to adversarial attacks. To\nassess LLM alignment, we present a wide variety of benchmarks and evaluation\nmethodologies. After discussing the state of alignment research for LLMs, we\nfinally cast a vision toward the future, contemplating the promising avenues of\nresearch that lie ahead.\n  Our aspiration for this survey extends beyond merely spurring research\ninterests in this realm. We also envision bridging the gap between the AI\nalignment research community and the researchers engrossed in the capability\nexploration of LLMs for both capable and safe LLMs.",
    "published": "2023-09-26T15:49:23Z",
    "pdf_url": "http://arxiv.org/pdf/2309.15025v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2310.03025v2",
    "title": "Retrieval meets Long Context Large Language Models",
    "authors": [
      "Peng Xu",
      "Wei Ping",
      "Xianchao Wu",
      "Lawrence McAfee",
      "Chen Zhu",
      "Zihan Liu",
      "Sandeep Subramanian",
      "Evelina Bakhturina",
      "Mohammad Shoeybi",
      "Bryan Catanzaro"
    ],
    "abstract": "Extending the context window of large language models (LLMs) is getting\npopular recently, while the solution of augmenting LLMs with retrieval has\nexisted for years. The natural questions are: i) Retrieval-augmentation versus\nlong context window, which one is better for downstream tasks? ii) Can both\nmethods be combined to get the best of both worlds? In this work, we answer\nthese questions by studying both solutions using two state-of-the-art\npretrained LLMs, i.e., a proprietary 43B GPT and Llama2-70B. Perhaps\nsurprisingly, we find that LLM with 4K context window using simple\nretrieval-augmentation at generation can achieve comparable performance to\nfinetuned LLM with 16K context window via positional interpolation on long\ncontext tasks, while taking much less computation. More importantly, we\ndemonstrate that retrieval can significantly improve the performance of LLMs\nregardless of their extended context window sizes. Our best model,\nretrieval-augmented Llama2-70B with 32K context window, outperforms\nGPT-3.5-turbo-16k and Davinci003 in terms of average score on nine long context\ntasks including question answering, query-based summarization, and in-context\nfew-shot learning tasks. It also outperforms its non-retrieval Llama2-70B-32k\nbaseline by a margin, while being much faster at generation. Our study provides\ngeneral insights on the choice of retrieval-augmentation versus long context\nextension of LLM for practitioners.",
    "published": "2023-10-04T17:59:41Z",
    "pdf_url": "http://arxiv.org/pdf/2310.03025v2",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2310.05177v1",
    "title": "Do Large Language Models Know about Facts?",
    "authors": [
      "Xuming Hu",
      "Junzhe Chen",
      "Xiaochuan Li",
      "Yufei Guo",
      "Lijie Wen",
      "Philip S. Yu",
      "Zhijiang Guo"
    ],
    "abstract": "Large language models (LLMs) have recently driven striking performance\nimprovements across a range of natural language processing tasks. The factual\nknowledge acquired during pretraining and instruction tuning can be useful in\nvarious downstream tasks, such as question answering, and language generation.\nUnlike conventional Knowledge Bases (KBs) that explicitly store factual\nknowledge, LLMs implicitly store facts in their parameters. Content generated\nby the LLMs can often exhibit inaccuracies or deviations from the truth, due to\nfacts that can be incorrectly induced or become obsolete over time. To this\nend, we aim to comprehensively evaluate the extent and scope of factual\nknowledge within LLMs by designing the benchmark Pinocchio. Pinocchio contains\n20K diverse factual questions that span different sources, timelines, domains,\nregions, and languages. Furthermore, we investigate whether LLMs are able to\ncompose multiple facts, update factual knowledge temporally, reason over\nmultiple pieces of facts, identify subtle factual differences, and resist\nadversarial examples. Extensive experiments on different sizes and types of\nLLMs show that existing LLMs still lack factual knowledge and suffer from\nvarious spurious correlations. We believe this is a critical bottleneck for\nrealizing trustworthy artificial intelligence. The dataset Pinocchio and our\ncodes will be publicly available.",
    "published": "2023-10-08T14:26:55Z",
    "pdf_url": "http://arxiv.org/pdf/2310.05177v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2310.17784v2",
    "title": "Data-Centric Financial Large Language Models",
    "authors": [
      "Zhixuan Chu",
      "Huaiyu Guo",
      "Xinyuan Zhou",
      "Yijia Wang",
      "Fei Yu",
      "Hong Chen",
      "Wanqing Xu",
      "Xin Lu",
      "Qing Cui",
      "Longfei Li",
      "Jun Zhou",
      "Sheng Li"
    ],
    "abstract": "Large language models (LLMs) show promise for natural language tasks but\nstruggle when applied directly to complex domains like finance. LLMs have\ndifficulty reasoning about and integrating all relevant information. We propose\na data-centric approach to enable LLMs to better handle financial tasks. Our\nkey insight is that rather than overloading the LLM with everything at once, it\nis more effective to preprocess and pre-understand the data. We create a\nfinancial LLM (FLLM) using multitask prompt-based finetuning to achieve data\npre-processing and pre-understanding. However, labeled data is scarce for each\ntask. To overcome manual annotation costs, we employ abductive augmentation\nreasoning (AAR) to automatically generate training data by modifying the pseudo\nlabels from FLLM's own outputs. Experiments show our data-centric FLLM with AAR\nsubstantially outperforms baseline financial LLMs designed for raw text,\nachieving state-of-the-art on financial analysis and interpretation tasks. We\nalso open source a new benchmark for financial analysis and interpretation. Our\nmethodology provides a promising path to unlock LLMs' potential for complex\nreal-world domains.",
    "published": "2023-10-07T04:53:31Z",
    "pdf_url": "http://arxiv.org/pdf/2310.17784v2",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2310.19046v3",
    "title": "Large Language Models as Evolutionary Optimizers",
    "authors": [
      "Shengcai Liu",
      "Caishun Chen",
      "Xinghua Qu",
      "Ke Tang",
      "Yew-Soon Ong"
    ],
    "abstract": "Evolutionary algorithms (EAs) have achieved remarkable success in tackling\ncomplex combinatorial optimization problems. However, EAs often demand\ncarefully-designed operators with the aid of domain expertise to achieve\nsatisfactory performance. In this work, we present the first study on large\nlanguage models (LLMs) as evolutionary combinatorial optimizers. The main\nadvantage is that it requires minimal domain knowledge and human efforts, as\nwell as no additional training of the model. This approach is referred to as\nLLM-driven EA (LMEA). Specifically, in each generation of the evolutionary\nsearch, LMEA instructs the LLM to select parent solutions from current\npopulation, and perform crossover and mutation to generate offspring solutions.\nThen, LMEA evaluates these new solutions and include them into the population\nfor the next generation. LMEA is equipped with a self-adaptation mechanism that\ncontrols the temperature of the LLM. This enables it to balance between\nexploration and exploitation and prevents the search from getting stuck in\nlocal optima. We investigate the power of LMEA on the classical traveling\nsalesman problems (TSPs) widely used in combinatorial optimization research.\nNotably, the results show that LMEA performs competitively to traditional\nheuristics in finding high-quality solutions on TSP instances with up to 20\nnodes. Additionally, we also study the effectiveness of LLM-driven\ncrossover/mutation and the self-adaptation mechanism in evolutionary search. In\nsummary, our results reveal the great potentials of LLMs as evolutionary\noptimizers for solving combinatorial problems. We hope our research shall\ninspire future explorations on LLM-driven EAs for complex optimization\nchallenges.",
    "published": "2023-10-29T15:44:52Z",
    "pdf_url": "http://arxiv.org/pdf/2310.19046v3",
    "categories": [
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "2312.04906v1",
    "title": "Ophtha-LLaMA2: A Large Language Model for Ophthalmology",
    "authors": [
      "Huan Zhao",
      "Qian Ling",
      "Yi Pan",
      "Tianyang Zhong",
      "Jin-Yu Hu",
      "Junjie Yao",
      "Fengqian Xiao",
      "Zhenxiang Xiao",
      "Yutong Zhang",
      "San-Hua Xu",
      "Shi-Nan Wu",
      "Min Kang",
      "Zihao Wu",
      "Zhengliang Liu",
      "Xi Jiang",
      "Tianming Liu",
      "Yi Shao"
    ],
    "abstract": "In recent years, pre-trained large language models (LLMs) have achieved\ntremendous success in the field of Natural Language Processing (NLP). Prior\nstudies have primarily focused on general and generic domains, with relatively\nless research on specialized LLMs in the medical field. The specialization and\nhigh accuracy requirements for diagnosis in the medical field, as well as the\nchallenges in collecting large-scale data, have constrained the application and\ndevelopment of LLMs in medical scenarios. In the field of ophthalmology,\nclinical diagnosis mainly relies on doctors' interpretation of reports and\nmaking diagnostic decisions. In order to take advantage of LLMs to provide\ndecision support for doctors, we collected three modalities of ophthalmic\nreport data and fine-tuned the LLaMA2 model, successfully constructing an LLM\ntermed the \"Ophtha-LLaMA2\" specifically tailored for ophthalmic disease\ndiagnosis. Inference test results show that even with a smaller fine-tuning\ndataset, Ophtha-LLaMA2 performs significantly better in ophthalmic diagnosis\ncompared to other LLMs. It demonstrates that the Ophtha-LLaMA2 exhibits\nsatisfying accuracy and efficiency in ophthalmic disease diagnosis, making it a\nvaluable tool for ophthalmologists to provide improved diagnostic support for\npatients. This research provides a useful reference for the application of LLMs\nin the field of ophthalmology, while showcasing the immense potential and\nprospects in this domain.",
    "published": "2023-12-08T08:43:46Z",
    "pdf_url": "http://arxiv.org/pdf/2312.04906v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2401.08273v3",
    "title": "Large Language Models are Null-Shot Learners",
    "authors": [
      "Pittawat Taveekitworachai",
      "Febri Abdullah",
      "Ruck Thawonmas"
    ],
    "abstract": "This paper presents null-shot prompting. Null-shot prompting exploits\nhallucination in large language models (LLMs) by instructing LLMs to utilize\ninformation from the \"Examples\" section that never exists within the provided\ncontext to perform a task. While reducing hallucination is crucial and\nnon-negligible for daily and critical uses of LLMs, we propose that in the\ncurrent landscape in which these LLMs still hallucinate, it is possible, in\nfact, to exploit hallucination to increase performance in performing tasks\ncompared to standard zero-shot prompting. Experiments with eight LLMs show\nimprovements in performance across the majority of eight datasets, including\nreading comprehension, arithmetic reasoning, and closed-book question\nanswering. The observed inconsistency in increased relative performance across\nthe LLMs also potentially indicates a different degree of inherent\nhallucination in each model. These differences show that it is possible to\nutilize null-shot prompting as a way to detect degrees of hallucination in LLMs\nusing existing benchmarking datasets. We also perform ablation studies,\nincluding experimenting with a modified version of null-shot prompting that\nincorporates ideas from zero-shot chain-of-thought prompting, which shows\ndifferent trends of results.",
    "published": "2024-01-16T10:53:11Z",
    "pdf_url": "http://arxiv.org/pdf/2401.08273v3",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2402.02338v3",
    "title": "NetLLM: Adapting Large Language Models for Networking",
    "authors": [
      "Duo Wu",
      "Xianda Wang",
      "Yaqi Qiao",
      "Zhi Wang",
      "Junchen Jiang",
      "Shuguang Cui",
      "Fangxin Wang"
    ],
    "abstract": "Many networking tasks now employ deep learning (DL) to solve complex\nprediction and optimization problems. However, current design philosophy of\nDL-based algorithms entails intensive engineering overhead due to the manual\ndesign of deep neural networks (DNNs) for different networking tasks. Besides,\nDNNs tend to achieve poor generalization performance on unseen data\ndistributions/environments.\n  Motivated by the recent success of large language models (LLMs), this work\nstudies the LLM adaptation for networking to explore a more sustainable design\nphilosophy. With the powerful pre-trained knowledge, the LLM is promising to\nserve as the foundation model to achieve \"one model for all tasks\" with even\nbetter performance and stronger generalization. In pursuit of this vision, we\npresent NetLLM, the first framework that provides a coherent design to harness\nthe powerful capabilities of LLMs with low efforts to solve networking\nproblems. Specifically, NetLLM empowers the LLM to effectively process\nmultimodal data in networking and efficiently generate task-specific answers.\nBesides, NetLLM drastically reduces the costs of fine-tuning the LLM to acquire\ndomain knowledge for networking. Across three networking-related use cases -\nviewport prediction, adaptive bitrate streaming and cluster job scheduling, we\nshowcase that the NetLLM-adapted LLM significantly outperforms state-of-the-art\nalgorithms.",
    "published": "2024-02-04T04:21:34Z",
    "pdf_url": "http://arxiv.org/pdf/2402.02338v3",
    "categories": [
      "cs.NI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2403.08213v2",
    "title": "Can Large Language Models Identify Authorship?",
    "authors": [
      "Baixiang Huang",
      "Canyu Chen",
      "Kai Shu"
    ],
    "abstract": "The ability to accurately identify authorship is crucial for verifying\ncontent authenticity and mitigating misinformation. Large Language Models\n(LLMs) have demonstrated an exceptional capacity for reasoning and\nproblem-solving. However, their potential in authorship analysis remains\nunder-explored. Traditional studies have depended on hand-crafted stylistic\nfeatures, whereas state-of-the-art approaches leverage text embeddings from\npre-trained language models. These methods, which typically require fine-tuning\non labeled data, often suffer from performance degradation in cross-domain\napplications and provide limited explainability. This work seeks to address\nthree research questions: (1) Can LLMs perform zero-shot, end-to-end authorship\nverification effectively? (2) Are LLMs capable of accurately attributing\nauthorship among multiple candidates authors (e.g., 10 and 20)? (3) Can LLMs\nprovide explainability in authorship analysis, particularly through the role of\nlinguistic features? Moreover, we investigate the integration of explicit\nlinguistic features to guide LLMs in their reasoning processes. Our assessment\ndemonstrates LLMs' proficiency in both tasks without the need for\ndomain-specific fine-tuning, providing explanations into their decision making\nvia a detailed analysis of linguistic features. This establishes a new\nbenchmark for future research on LLM-based authorship analysis.",
    "published": "2024-03-13T03:22:02Z",
    "pdf_url": "http://arxiv.org/pdf/2403.08213v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2403.14469v1",
    "title": "ChatGPT Alternative Solutions: Large Language Models Survey",
    "authors": [
      "Hanieh Alipour",
      "Nick Pendar",
      "Kohinoor Roy"
    ],
    "abstract": "In recent times, the grandeur of Large Language Models (LLMs) has not only\nshone in the realm of natural language processing but has also cast its\nbrilliance across a vast array of applications. This remarkable display of LLM\ncapabilities has ignited a surge in research contributions within this domain,\nspanning a diverse spectrum of topics. These contributions encompass\nadvancements in neural network architecture, context length enhancements, model\nalignment, training datasets, benchmarking, efficiency improvements, and more.\nRecent years have witnessed a dynamic synergy between academia and industry,\npropelling the field of LLM research to new heights. A notable milestone in\nthis journey is the introduction of ChatGPT, a powerful AI chatbot grounded in\nLLMs, which has garnered widespread societal attention. The evolving technology\nof LLMs has begun to reshape the landscape of the entire AI community,\npromising a revolutionary shift in the way we create and employ AI algorithms.\nGiven this swift-paced technical evolution, our survey embarks on a journey to\nencapsulate the recent strides made in the world of LLMs. Through an\nexploration of the background, key discoveries, and prevailing methodologies,\nwe offer an up-to-the-minute review of the literature. By examining multiple\nLLM models, our paper not only presents a comprehensive overview but also\ncharts a course that identifies existing challenges and points toward potential\nfuture research trajectories. This survey furnishes a well-rounded perspective\non the current state of generative AI, shedding light on opportunities for\nfurther exploration, enhancement, and innovation.",
    "published": "2024-03-21T15:16:50Z",
    "pdf_url": "http://arxiv.org/pdf/2403.14469v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2404.10229v2",
    "title": "Generative Text Steganography with Large Language Model",
    "authors": [
      "Jiaxuan Wu",
      "Zhengxian Wu",
      "Yiming Xue",
      "Juan Wen",
      "Wanli Peng"
    ],
    "abstract": "Recent advances in large language models (LLMs) have blurred the boundary of\nhigh-quality text generation between humans and machines, which is favorable\nfor generative text steganography. While, current advanced steganographic\nmapping is not suitable for LLMs since most users are restricted to accessing\nonly the black-box API or user interface of the LLMs, thereby lacking access to\nthe training vocabulary and its sampling probabilities. In this paper, we\nexplore a black-box generative text steganographic method based on the user\ninterfaces of large language models, which is called LLM-Stega. The main goal\nof LLM-Stega is that the secure covert communication between Alice (sender) and\nBob (receiver) is conducted by using the user interfaces of LLMs. Specifically,\nWe first construct a keyword set and design a new encrypted steganographic\nmapping to embed secret messages. Furthermore, to guarantee accurate extraction\nof secret messages and rich semantics of generated stego texts, an optimization\nmechanism based on reject sampling is proposed. Comprehensive experiments\ndemonstrate that the proposed LLM-Stega outperforms current state-of-the-art\nmethods.",
    "published": "2024-04-16T02:19:28Z",
    "pdf_url": "http://arxiv.org/pdf/2404.10229v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2405.16127v2",
    "title": "Finetuning Large Language Model for Personalized Ranking",
    "authors": [
      "Zhuoxi Bai",
      "Ning Wu",
      "Fengyu Cai",
      "Xinyi Zhu",
      "Yun Xiong"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across\nvarious domains, motivating researchers to investigate their potential use in\nrecommendation systems. However, directly applying LLMs to recommendation tasks\nhas proven challenging due to the significant disparity between the data used\nfor pre-training LLMs and the specific requirements of recommendation tasks. In\nthis study, we introduce Direct Multi-Preference Optimization (DMPO), a\nstreamlined framework designed to bridge the gap and enhance the alignment of\nLLMs for recommendation tasks. DMPO enhances the performance of LLM-based\nrecommenders by simultaneously maximizing the probability of positive samples\nand minimizing the probability of multiple negative samples. We conducted\nexperimental evaluations to compare DMPO against traditional recommendation\nmethods and other LLM-based recommendation approaches. The results demonstrate\nthat DMPO significantly improves the recommendation capabilities of LLMs across\nthree real-world public datasets in few-shot scenarios. Additionally, the\nexperiments indicate that DMPO exhibits superior generalization ability in\ncross-domain recommendations. A case study elucidates the reasons behind these\nconsistent improvements and also underscores DMPO's potential as an explainable\nrecommendation system.",
    "published": "2024-05-25T08:36:15Z",
    "pdf_url": "http://arxiv.org/pdf/2405.16127v2",
    "categories": [
      "cs.IR"
    ]
  },
  {
    "arxiv_id": "2406.13261v3",
    "title": "BeHonest: Benchmarking Honesty in Large Language Models",
    "authors": [
      "Steffi Chern",
      "Zhulin Hu",
      "Yuqing Yang",
      "Ethan Chern",
      "Yuan Guo",
      "Jiahe Jin",
      "Binjie Wang",
      "Pengfei Liu"
    ],
    "abstract": "Previous works on Large Language Models (LLMs) have mainly focused on\nevaluating their helpfulness or harmlessness. However, honesty, another crucial\nalignment criterion, has received relatively less attention. Dishonest\nbehaviors in LLMs, such as spreading misinformation and defrauding users,\npresent severe risks that intensify as these models approach superintelligent\nlevels. Enhancing honesty in LLMs addresses critical limitations and helps\nuncover latent capabilities that are not readily expressed. This underscores\nthe urgent need for reliable methods and benchmarks to effectively ensure and\nevaluate the honesty of LLMs.\n  In this paper, we introduce BeHonest, a pioneering benchmark specifically\ndesigned to assess honesty in LLMs comprehensively. BeHonest evaluates three\nessential aspects of honesty: awareness of knowledge boundaries, avoidance of\ndeceit, and consistency in responses. Building on this foundation, we designed\n10 scenarios to evaluate and analyze 9 popular LLMs on the market, including\nboth closed-source and open-source models from different model families with\nvaried model sizes. Our findings indicate that there is still significant room\nfor improvement in the honesty of LLMs. We encourage the AI community to\nprioritize honesty alignment in these models, which can harness their full\npotential to benefit society while preventing them from causing harm through\ndeception or inconsistency. Our benchmark and code can be found at:\n\\url{https://github.com/GAIR-NLP/BeHonest}.",
    "published": "2024-06-19T06:46:59Z",
    "pdf_url": "http://arxiv.org/pdf/2406.13261v3",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2407.06564v1",
    "title": "Combining Knowledge Graphs and Large Language Models",
    "authors": [
      "Amanda Kau",
      "Xuzeng He",
      "Aishwarya Nambissan",
      "Aland Astudillo",
      "Hui Yin",
      "Amir Aryani"
    ],
    "abstract": "In recent years, Natural Language Processing (NLP) has played a significant\nrole in various Artificial Intelligence (AI) applications such as chatbots,\ntext generation, and language translation. The emergence of large language\nmodels (LLMs) has greatly improved the performance of these applications,\nshowing astonishing results in language understanding and generation. However,\nthey still show some disadvantages, such as hallucinations and lack of\ndomain-specific knowledge, that affect their performance in real-world tasks.\nThese issues can be effectively mitigated by incorporating knowledge graphs\n(KGs), which organise information in structured formats that capture\nrelationships between entities in a versatile and interpretable fashion.\nLikewise, the construction and validation of KGs present challenges that LLMs\ncan help resolve. The complementary relationship between LLMs and KGs has led\nto a trend that combines these technologies to achieve trustworthy results.\nThis work collected 28 papers outlining methods for KG-powered LLMs, LLM-based\nKGs, and LLM-KG hybrid approaches. We systematically analysed and compared\nthese approaches to provide a comprehensive overview highlighting key trends,\ninnovative techniques, and common challenges. This synthesis will benefit\nresearchers new to the field and those seeking to deepen their understanding of\nhow KGs and LLMs can be effectively combined to enhance AI applications\ncapabilities.",
    "published": "2024-07-09T05:42:53Z",
    "pdf_url": "http://arxiv.org/pdf/2407.06564v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2407.17866v3",
    "title": "Financial Statement Analysis with Large Language Models",
    "authors": [
      "Alex Kim",
      "Maximilian Muhn",
      "Valeri Nikolaev"
    ],
    "abstract": "We investigate whether large language models (LLMs) can successfully perform\nfinancial statement analysis in a way similar to a professional human analyst.\nWe provide standardized and anonymous financial statements to GPT4 and instruct\nthe model to analyze them to determine the direction of firms' future earnings.\nEven without narrative or industry-specific information, the LLM outperforms\nfinancial analysts in its ability to predict earnings changes directionally.\nThe LLM exhibits a relative advantage over human analysts in situations when\nthe analysts tend to struggle. Furthermore, we find that the prediction\naccuracy of the LLM is on par with a narrowly trained state-of-the-art ML\nmodel. LLM prediction does not stem from its training memory. Instead, we find\nthat the LLM generates useful narrative insights about a company's future\nperformance. Lastly, our trading strategies based on GPT's predictions yield a\nhigher Sharpe ratio and alphas than strategies based on other models. Our\nresults suggest that LLMs may take a central role in analysis and\ndecision-making.",
    "published": "2024-07-25T08:36:58Z",
    "pdf_url": "http://arxiv.org/pdf/2407.17866v3",
    "categories": [
      "q-fin.ST",
      "cs.AI",
      "cs.CL",
      "q-fin.GN",
      "q-fin.PM"
    ]
  },
  {
    "arxiv_id": "2408.09895v4",
    "title": "Performance Law of Large Language Models",
    "authors": [
      "Chuhan Wu",
      "Ruiming Tang"
    ],
    "abstract": "Guided by the belief of the scaling law, large language models (LLMs) have\nachieved impressive performance in recent years. However, scaling law only\ngives a qualitative estimation of loss, which is influenced by various factors\nsuch as model architectures, data distributions, tokenizers, and computation\nprecision. Thus, estimating the real performance of LLMs with different\ntraining settings rather than loss may be quite useful in practical\ndevelopment. In this article, we present an empirical equation named\n\"Performance Law\" to directly predict the MMLU score of an LLM, which is a\nwidely used metric to indicate the general capability of LLMs in real-world\nconversations and applications. Based on only a few key hyperparameters of the\nLLM architecture and the size of training data, we obtain a quite accurate MMLU\nprediction of various LLMs with diverse sizes and architectures developed by\ndifferent organizations in different years. Performance law can be used to\nguide the choice of LLM architecture and the effective allocation of\ncomputational resources without extensive experiments.",
    "published": "2024-08-19T11:09:12Z",
    "pdf_url": "http://arxiv.org/pdf/2408.09895v4",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2408.15879v2",
    "title": "Persuasion Games using Large Language Models",
    "authors": [
      "Ganesh Prasath Ramani",
      "Shirish Karande",
      "Santhosh V",
      "Yash Bhatia"
    ],
    "abstract": "Large Language Models (LLMs) have emerged as formidable instruments capable\nof comprehending and producing human-like text. This paper explores the\npotential of LLMs, to shape user perspectives and subsequently influence their\ndecisions on particular tasks. This capability finds applications in diverse\ndomains such as Investment, Credit cards and Insurance, wherein they assist\nusers in selecting appropriate insurance policies, investment plans, Credit\ncards, Retail, as well as in Behavioral Change Support Systems (BCSS).\n  We present a sophisticated multi-agent framework wherein a consortium of\nagents operate in collaborative manner. The primary agent engages directly with\nuser agents through persuasive dialogue, while the auxiliary agents perform\ntasks such as information retrieval, response analysis, development of\npersuasion strategies, and validation of facts. Empirical evidence from our\nexperiments demonstrates that this collaborative methodology significantly\nenhances the persuasive efficacy of the LLM. We continuously analyze the\nresistance of the user agent to persuasive efforts and counteract it by\nemploying a combination of rule-based and LLM-based resistance-persuasion\nmapping techniques.\n  We employ simulated personas and generate conversations in insurance,\nbanking, and retail domains to evaluate the proficiency of large language\nmodels (LLMs) in recognizing, adjusting to, and influencing various personality\ntypes. Concurrently, we examine the resistance mechanisms employed by LLM\nsimulated personas. Persuasion is quantified via measurable surveys before and\nafter interaction, LLM-generated scores on conversation, and user decisions\n(purchase or non-purchase).",
    "published": "2024-08-28T15:50:41Z",
    "pdf_url": "http://arxiv.org/pdf/2408.15879v2",
    "categories": [
      "cs.AI",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2409.05925v2",
    "title": "Assessing SPARQL capabilities of Large Language Models",
    "authors": [
      "Lars-Peter Meyer",
      "Johannes Frey",
      "Felix Brei",
      "Natanael Arndt"
    ],
    "abstract": "The integration of Large Language Models (LLMs) with Knowledge Graphs (KGs)\noffers significant synergistic potential for knowledge-driven applications. One\npossible integration is the interpretation and generation of formal languages,\nsuch as those used in the Semantic Web, with SPARQL being a core technology for\naccessing KGs. In this paper, we focus on measuring out-of-the box capabilities\nof LLMs to work with SPARQL and more specifically with SPARQL SELECT queries\napplying a quantitative approach.\n  We implemented various benchmarking tasks in the LLM-KG-Bench framework for\nautomated execution and evaluation with several LLMs. The tasks assess\ncapabilities along the dimensions of syntax, semantic read, semantic create,\nand the role of knowledge graph prompt inclusion.\n  With this new benchmarking tasks, we evaluated a selection of GPT, Gemini,\nand Claude models. Our findings indicate that working with SPARQL SELECT\nqueries is still challenging for LLMs and heavily depends on the specific LLM\nas well as the complexity of the task. While fixing basic syntax errors seems\nto pose no problems for the best of the current LLMs evaluated, creating\nsemantically correct SPARQL SELECT queries is difficult in several cases.",
    "published": "2024-09-09T08:29:39Z",
    "pdf_url": "http://arxiv.org/pdf/2409.05925v2",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ]
  },
  {
    "arxiv_id": "2409.17372v2",
    "title": "Search for Efficient Large Language Models",
    "authors": [
      "Xuan Shen",
      "Pu Zhao",
      "Yifan Gong",
      "Zhenglun Kong",
      "Zheng Zhan",
      "Yushu Wu",
      "Ming Lin",
      "Chao Wu",
      "Xue Lin",
      "Yanzhi Wang"
    ],
    "abstract": "Large Language Models (LLMs) have long held sway in the realms of artificial\nintelligence research. Numerous efficient techniques, including weight pruning,\nquantization, and distillation, have been embraced to compress LLMs, targeting\nmemory reduction and inference acceleration, which underscore the redundancy in\nLLMs. However, most model compression techniques concentrate on weight\noptimization, overlooking the exploration of optimal architectures. Besides,\ntraditional architecture search methods, limited by the elevated complexity\nwith extensive parameters, struggle to demonstrate their effectiveness on LLMs.\nIn this paper, we propose a training-free architecture search framework to\nidentify optimal subnets that preserve the fundamental strengths of the\noriginal LLMs while achieving inference acceleration. Furthermore, after\ngenerating subnets that inherit specific weights from the original LLMs, we\nintroduce a reformation algorithm that utilizes the omitted weights to rectify\nthe inherited weights with a small amount of calibration data. Compared with\nSOTA training-free structured pruning works that can generate smaller networks,\nour method demonstrates superior performance across standard benchmarks.\nFurthermore, our generated subnets can directly reduce the usage of GPU memory\nand achieve inference acceleration. Code:\nhttps://github.com/shawnricecake/search-llm",
    "published": "2024-09-25T21:32:12Z",
    "pdf_url": "http://arxiv.org/pdf/2409.17372v2",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2411.10813v1",
    "title": "Information Anxiety in Large Language Models",
    "authors": [
      "Prasoon Bajpai",
      "Sarah Masud",
      "Tanmoy Chakraborty"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated strong performance as\nknowledge repositories, enabling models to understand user queries and generate\naccurate and context-aware responses. Extensive evaluation setups have\ncorroborated the positive correlation between the retrieval capability of LLMs\nand the frequency of entities in their pretraining corpus. We take the\ninvestigation further by conducting a comprehensive analysis of the internal\nreasoning and retrieval mechanisms of LLMs. Our work focuses on three critical\ndimensions - the impact of entity popularity, the models' sensitivity to\nlexical variations in query formulation, and the progression of hidden state\nrepresentations across LLM layers. Our preliminary findings reveal that popular\nquestions facilitate early convergence of internal states toward the correct\nanswer. However, as the popularity of a query increases, retrieved attributes\nacross lexical variations become increasingly dissimilar and less accurate.\nInterestingly, we find that LLMs struggle to disentangle facts, grounded in\ndistinct relations, from their parametric memory when dealing with highly\npopular subjects. Through a case study, we explore these latent strains within\nLLMs when processing highly popular queries, a phenomenon we term information\nanxiety. The emergence of information anxiety in LLMs underscores the\nadversarial injection in the form of linguistic variations and calls for a more\nholistic evaluation of frequently occurring entities.",
    "published": "2024-11-16T14:28:33Z",
    "pdf_url": "http://arxiv.org/pdf/2411.10813v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2412.06864v1",
    "title": "Political-LLM: Large Language Models in Political Science",
    "authors": [
      "Lincan Li",
      "Jiaqi Li",
      "Catherine Chen",
      "Fred Gui",
      "Hongjia Yang",
      "Chenxiao Yu",
      "Zhengguang Wang",
      "Jianing Cai",
      "Junlong Aaron Zhou",
      "Bolin Shen",
      "Alex Qian",
      "Weixin Chen",
      "Zhongkai Xue",
      "Lichao Sun",
      "Lifang He",
      "Hanjie Chen",
      "Kaize Ding",
      "Zijian Du",
      "Fangzhou Mu",
      "Jiaxin Pei",
      "Jieyu Zhao",
      "Swabha Swayamdipta",
      "Willie Neiswanger",
      "Hua Wei",
      "Xiyang Hu",
      "Shixiang Zhu",
      "Tianlong Chen",
      "Yingzhou Lu",
      "Yang Shi",
      "Lianhui Qin",
      "Tianfan Fu",
      "Zhengzhong Tu",
      "Yuzhe Yang",
      "Jaemin Yoo",
      "Jiaheng Zhang",
      "Ryan Rossi",
      "Liang Zhan",
      "Liang Zhao",
      "Emilio Ferrara",
      "Yan Liu",
      "Furong Huang",
      "Xiangliang Zhang",
      "Lawrence Rothenberg",
      "Shuiwang Ji",
      "Philip S. Yu",
      "Yue Zhao",
      "Yushun Dong"
    ],
    "abstract": "In recent years, large language models (LLMs) have been widely adopted in\npolitical science tasks such as election prediction, sentiment analysis, policy\nimpact assessment, and misinformation detection. Meanwhile, the need to\nsystematically understand how LLMs can further revolutionize the field also\nbecomes urgent. In this work, we--a multidisciplinary team of researchers\nspanning computer science and political science--present the first principled\nframework termed Political-LLM to advance the comprehensive understanding of\nintegrating LLMs into computational political science. Specifically, we first\nintroduce a fundamental taxonomy classifying the existing explorations into two\nperspectives: political science and computational methodologies. In particular,\nfrom the political science perspective, we highlight the role of LLMs in\nautomating predictive and generative tasks, simulating behavior dynamics, and\nimproving causal inference through tools like counterfactual generation; from a\ncomputational perspective, we introduce advancements in data preparation,\nfine-tuning, and evaluation methods for LLMs that are tailored to political\ncontexts. We identify key challenges and future directions, emphasizing the\ndevelopment of domain-specific datasets, addressing issues of bias and\nfairness, incorporating human expertise, and redefining evaluation criteria to\nalign with the unique requirements of computational political science.\nPolitical-LLM seeks to serve as a guidebook for researchers to foster an\ninformed, ethical, and impactful use of Artificial Intelligence in political\nscience. Our online resource is available at: http://political-llm.org/.",
    "published": "2024-12-09T08:47:50Z",
    "pdf_url": "http://arxiv.org/pdf/2412.06864v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2501.12619v3",
    "title": "Quantification of Large Language Model Distillation",
    "authors": [
      "Sunbowen Lee",
      "Junting Zhou",
      "Chang Ao",
      "Kaige Li",
      "Xinrun Du",
      "Sirui He",
      "Haihong Wu",
      "Tianci Liu",
      "Jiaheng Liu",
      "Hamid Alinejad-Rokny",
      "Min Yang",
      "Yitao Liang",
      "Zhoufutu Wen",
      "Shiwen Ni"
    ],
    "abstract": "Model distillation is a fundamental technique in building large language\nmodels (LLMs), transferring knowledge from a teacher model to a student model.\nHowever, distillation can lead to model homogenization, reducing diversity\namong models and impairing their ability to robustly handle complex or novel\ntasks. These limitations underscore the need to systematically quantify the\ndistillation process and its impact. In this work, we propose a framework to\nevaluate and quantify model distillation. Our method addresses two key aspects:\n(1) Identifying identity cognition contradictions to assess discrepancies in\nhow models perceive and represent identity-related information, and (2)\nAnalyzing multi-granularity response similarities across models to measure the\nextent of homogenization. Experimental results demonstrate two key insights:\n(1) Well-known closed-source and open-source LLMs usually exhibit high\ndistillation degrees, except for Claude, Doubao, and Gemini. (2) Base LLMs show\nhigher distillation degrees compared to aligned LLMs. By offering a systematic\napproach to improve the transparency of LLM data distillation, we call for LLMs\nwith more independent development and more transparent technical reports to\nimprove LLMs' robustness and safety. The code and data are available under\nhttps://github.com/Aegis1863/LLMs-Distillation-Quantification.",
    "published": "2025-01-22T03:57:52Z",
    "pdf_url": "http://arxiv.org/pdf/2501.12619v3",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2502.16790v1",
    "title": "Are Large Language Models Good Data Preprocessors?",
    "authors": [
      "Elyas Meguellati",
      "Nardiena Pratama",
      "Shazia Sadiq",
      "Gianluca Demartini"
    ],
    "abstract": "High-quality textual training data is essential for the success of multimodal\ndata processing tasks, yet outputs from image captioning models like BLIP and\nGIT often contain errors and anomalies that are difficult to rectify using\nrule-based methods. While recent work addressing this issue has predominantly\nfocused on using GPT models for data preprocessing on relatively simple public\ndatasets, there is a need to explore a broader range of Large Language Models\n(LLMs) and tackle more challenging and diverse datasets.\n  In this study, we investigate the use of multiple LLMs, including LLaMA 3.1\n70B, GPT-4 Turbo, and Sonnet 3.5 v2, to refine and clean the textual outputs of\nBLIP and GIT. We assess the impact of LLM-assisted data cleaning by comparing\ndownstream-task (SemEval 2024 Subtask \"Multilabel Persuasion Detection in\nMemes\") models trained on cleaned versus non-cleaned data. While our\nexperimental results show improvements when using LLM-cleaned captions,\nstatistical tests reveal that most of these improvements are not significant.\nThis suggests that while LLMs have the potential to enhance data cleaning and\nrepairing, their effectiveness may be limited depending on the context they are\napplied to, the complexity of the task, and the level of noise in the text.\n  Our findings highlight the need for further research into the capabilities\nand limitations of LLMs in data preprocessing pipelines, especially when\ndealing with challenging datasets, contributing empirical evidence to the\nongoing discussion about integrating LLMs into data preprocessing pipelines.",
    "published": "2025-02-24T02:57:21Z",
    "pdf_url": "http://arxiv.org/pdf/2502.16790v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2503.21383v1",
    "title": "Controlling Large Language Model with Latent Actions",
    "authors": [
      "Chengxing Jia",
      "Ziniu Li",
      "Pengyuan Wang",
      "Yi-Chen Li",
      "Zhenyu Hou",
      "Yuxiao Dong",
      "Yang Yu"
    ],
    "abstract": "Adapting Large Language Models (LLMs) to downstream tasks using Reinforcement\nLearning (RL) has proven to be an effective approach. However, LLMs do not\ninherently define the structure of an agent for RL training, particularly in\nterms of defining the action space. This paper studies learning a compact\nlatent action space to enhance the controllability and exploration of RL for\nLLMs. We propose Controlling Large Language Models with Latent Actions (CoLA),\na framework that integrates a latent action space into pre-trained LLMs. We\napply CoLA to the Llama-3.1-8B model. Our experiments demonstrate that,\ncompared to RL with token-level actions, CoLA's latent action enables greater\nsemantic diversity in text generation. For enhancing downstream tasks, we show\nthat CoLA with RL achieves a score of 42.4 on the math500 benchmark, surpassing\nthe baseline score of 38.2, and reaches 68.2 when augmented with a Monte Carlo\nTree Search variant. Furthermore, CoLA with RL consistently improves\nperformance on agent-based tasks without degrading the pre-trained LLM's\ncapabilities, unlike the baseline. Finally, CoLA reduces computation time by\nhalf in tasks involving enhanced thinking prompts for LLMs by RL. These results\nhighlight CoLA's potential to advance RL-based adaptation of LLMs for\ndownstream applications.",
    "published": "2025-03-27T11:25:22Z",
    "pdf_url": "http://arxiv.org/pdf/2503.21383v1",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2504.04342v1",
    "title": "Compression Laws for Large Language Models",
    "authors": [
      "Ayan Sengupta",
      "Siddhant Chaudhary",
      "Tanmoy Chakraborty"
    ],
    "abstract": "We introduce compression laws for language language models (LLMs). While\nrecent scaling laws have sought to understand how LLMs scale with respect to\nmodel size, pre-training data, and computational resources, we focus on\nunderstanding how model compression affects the performance of a pre-trained\nLLM on downstream tasks. We empirically examine the effects of structured model\ncompression on LLMs through over $1000$ experiments across eight models with\nsizes ranging from $0.5B$ to $14B$ parameters. Our findings indicate that the\ntest cross-entropy loss increases quadratically with the compression ratio,\nwhereas performance on downstream tasks declines only linearly. Our study\nemphasizes the importance of recovery fine-tuning in enhancing generation loss,\nshowing that the test loss of compressed LLMs can improve by up to 55% with\nrecovery fine-tuning. At higher compression ratios (up to 90%), compressed LLMs\ndemonstrate a speed increase of 60% during inference compared to their\nuncompressed counterparts, compensating for the performance degradation at this\nlevel. However, for smaller models ($\\le 7B$), the computational gains are\nlimited, peaking at just 35%. We conclude that model compression can be highly\nbeneficial for larger models, especially when a smaller model within the same\ncomputational budget is not available. These insights provide the practical\nguidelines for utilizing model compression techniques for adopting LLMs in\nreal-life applications in resource-constrained settings.",
    "published": "2025-04-06T03:39:34Z",
    "pdf_url": "http://arxiv.org/pdf/2504.04342v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2505.20633v1",
    "title": "Test-Time Learning for Large Language Models",
    "authors": [
      "Jinwu Hu",
      "Zhitian Zhang",
      "Guohao Chen",
      "Xutao Wen",
      "Chao Shuai",
      "Wei Luo",
      "Bin Xiao",
      "Yuanqing Li",
      "Mingkui Tan"
    ],
    "abstract": "While Large Language Models (LLMs) have exhibited remarkable emergent\ncapabilities through extensive pre-training, they still face critical\nlimitations in generalizing to specialized domains and handling diverse\nlinguistic variations, known as distribution shifts. In this paper, we propose\na Test-Time Learning (TTL) paradigm for LLMs, namely TLM, which dynamically\nadapts LLMs to target domains using only unlabeled test data during testing.\nSpecifically, we first provide empirical evidence and theoretical insights to\nreveal that more accurate predictions from LLMs can be achieved by minimizing\nthe input perplexity of the unlabeled test data. Based on this insight, we\nformulate the Test-Time Learning process of LLMs as input perplexity\nminimization, enabling self-supervised enhancement of LLM performance.\nFurthermore, we observe that high-perplexity samples tend to be more\ninformative for model optimization. Accordingly, we introduce a Sample\nEfficient Learning Strategy that actively selects and emphasizes these\nhigh-perplexity samples for test-time updates. Lastly, to mitigate catastrophic\nforgetting and ensure adaptation stability, we adopt Low-Rank Adaptation (LoRA)\ninstead of full-parameter optimization, which allows lightweight model updates\nwhile preserving more original knowledge from the model. We introduce the\nAdaptEval benchmark for TTL and demonstrate through experiments that TLM\nimproves performance by at least 20% compared to original LLMs on domain\nknowledge adaptation.",
    "published": "2025-05-27T02:18:59Z",
    "pdf_url": "http://arxiv.org/pdf/2505.20633v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2506.02658v2",
    "title": "Computational Thinking Reasoning in Large Language Models",
    "authors": [
      "Kechi Zhang",
      "Ge Li",
      "Jia Li",
      "Huangzhao Zhang",
      "Jingjing Xu",
      "Hao Zhu",
      "Lecheng Wang",
      "Jia Li",
      "Yihong Dong",
      "Jing Mai",
      "Bin Gu",
      "Zhi Jin"
    ],
    "abstract": "While large language models (LLMs) have demonstrated remarkable reasoning\ncapabilities, they often struggle with complex tasks that require specific\nthinking paradigms, such as divide-and-conquer and procedural deduction, \\etc\nPrevious researches integrate external, reliable tools to alleviate logical\ninconsistencies and hallucinations in LLMs' problem-solving processes. However,\nwe argue that the root challenge is more profound: LLMs lack the complex\nthinking paradigms (\\ie, computational thinking) during reasoning. In this\npaper, we propose Computational Thinking Model (CTM), a novel framework that\nincorporates computational thinking paradigms into LLMs. This framework enables\nLLMs to reformulate complex problems through decomposition, abstraction,\nreduction, and simulation, among other techniques. Specifically, live code\nexecution is seamlessly integrated into the reasoning process, allowing CTM to\nthink by computing. CTM directly instills computational thinking objectives\ninto LLMs through tailored reinforcement learning rewards, which encourages\nproblem simplification, modular planning, and iterative verification. We\nconduct extensive evaluations on multiple code generation and mathematical\nbenchmarks. The results demonstrate that CTM outperforms conventional reasoning\nmodels and tool-augmented baselines in terms of accuracy, interpretability, and\ngeneralizability. We hope this study offers valuable insights for AI reasoning,\nwhere LLMs can transform problems into robust, verifiable, and scalable\ncomputational workflows, much like computer scientists do.",
    "published": "2025-06-03T09:11:15Z",
    "pdf_url": "http://arxiv.org/pdf/2506.02658v2",
    "categories": [
      "cs.SE"
    ]
  },
  {
    "arxiv_id": "2506.06921v1",
    "title": "Teaching Astronomy with Large Language Models",
    "authors": [
      "Yuan-Sen Ting",
      "Teaghan O'Briain"
    ],
    "abstract": "We present a study of LLM integration in final-year undergraduate astronomy\neducation, examining how students develop AI literacy through structured\nguidance and documentation requirements. We developed AstroTutor, a\ndomain-specific astronomy tutoring system enhanced with curated arXiv content,\nand deployed it alongside general-purpose LLMs in the course. Students\ndocumented their AI usage through homework reflections and post-course surveys.\nWe analyzed student evolution in AI interaction strategies and conducted\nexperimental comparisons of LLM-assisted versus traditional grading methods.\nLLM grading showed strong correlation with human evaluation while providing\nmore detailed and consistent feedback. We also piloted LLM-facilitated\ninterview-based examinations as a scalable alternative to traditional\nassessments, demonstrating potential for individualized evaluation that\naddresses common testing limitations. Students experienced decreased rather\nthan increased reliance on LLMs over the semester, developing critical\nevaluation skills and strategic tool selection. They evolved from basic\nassistance-seeking to verification workflows, with documentation requirements\nfostering metacognitive awareness. Students developed effective prompting\nstrategies, contextual enrichment techniques, and cross-verification practices.\nOur findings suggest that structured LLM integration with transparency\nrequirements and domain-specific tools can enhance astronomy education while\nbuilding essential AI literacy skills. We provide implementation guidelines for\neducators and make our AstroTutor repository freely available.",
    "published": "2025-06-07T21:00:01Z",
    "pdf_url": "http://arxiv.org/pdf/2506.06921v1",
    "categories": [
      "physics.ed-ph",
      "astro-ph.CO",
      "astro-ph.GA",
      "astro-ph.IM",
      "astro-ph.SR"
    ]
  },
  {
    "arxiv_id": "2507.08151v1",
    "title": "Distilling Empathy from Large Language Models",
    "authors": [
      "Henry J. Xie",
      "Jinghan Zhang",
      "Xinhao Zhang",
      "Kunpeng Liu"
    ],
    "abstract": "The distillation of knowledge from Large Language Models (LLMs) into Smaller\nLanguage Models (SLMs), preserving the capabilities and performance of LLMs\nwhile reducing model size, has played a key role in the proliferation of LLMs.\nBecause SLMs are considerably smaller than LLMs, they are often utilized in\ndomains where human interaction is frequent but resources are highly\nconstrained, e.g., smart phones. Therefore, it is crucial to ensure that\nempathy, a fundamental aspect of positive human interactions, already instilled\ninto LLMs, is retained by SLMs after distillation. In this paper, we develop a\ncomprehensive approach for effective empathy distillation from LLMs into SLMs.\nOur approach features a two-step fine-tuning process that fully leverages\ndatasets of empathetic dialogue responses distilled from LLMs. We explore\nseveral distillation methods beyond basic direct prompting and propose four\nunique sets of prompts for targeted empathy improvement to significantly\nenhance the empathy distillation process. Our evaluations demonstrate that SLMs\nfine-tuned through the two-step fine-tuning process with distillation datasets\nenhanced by the targeted empathy improvement prompts significantly outperform\nthe base SLM at generating empathetic responses with a win rate of 90%. Our\ntargeted empathy improvement prompts substantially outperform the basic direct\nprompting with a 10% improvement in win rate.",
    "published": "2025-07-10T20:20:02Z",
    "pdf_url": "http://arxiv.org/pdf/2507.08151v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2410.13138v1",
    "title": "Data Defenses Against Large Language Models",
    "authors": [
      "William Agnew",
      "Harry H. Jiang",
      "Cella Sum",
      "Maarten Sap",
      "Sauvik Das"
    ],
    "abstract": "Large language models excel at performing inference over text to extract\ninformation, summarize information, or generate additional text. These\ninference capabilities are implicated in a variety of ethical harms spanning\nsurveillance, labor displacement, and IP/copyright theft. While many policy,\nlegal, and technical mitigations have been proposed to counteract these harms,\nthese mitigations typically require cooperation from institutions that move\nslower than technical advances (i.e., governments) or that have few incentives\nto act to counteract these harms (i.e., the corporations that create and profit\nfrom these LLMs). In this paper, we define and build \"data defenses\" -- a novel\nstrategy that directly empowers data owners to block LLMs from performing\ninference on their data. We create data defenses by developing a method to\nautomatically generate adversarial prompt injections that, when added to input\ntext, significantly reduce the ability of LLMs to accurately infer personally\nidentifying information about the subject of the input text or to use\ncopyrighted text in inference. We examine the ethics of enabling such direct\nresistance to LLM inference, and argue that making data defenses that resist\nand subvert LLMs enables the realization of important values such as data\nownership, data sovereignty, and democratic control over AI systems. We verify\nthat our data defenses are cheap and fast to generate, work on the latest\ncommercial and open-source LLMs, resistance to countermeasures, and are robust\nto several different attack settings. Finally, we consider the security\nimplications of LLM data defenses and outline several future research\ndirections in this area. Our code is available at\nhttps://github.com/wagnew3/LLMDataDefenses and a tool for using our defenses to\nprotect text against LLM inference is at\nhttps://wagnew3.github.io/LLM-Data-Defenses/.",
    "published": "2024-10-17T01:51:56Z",
    "pdf_url": "http://arxiv.org/pdf/2410.13138v1",
    "categories": [
      "cs.CL",
      "cs.CR",
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "2303.05279v2",
    "title": "Can large language models build causal graphs?",
    "authors": [
      "Stephanie Long",
      "Tibor Schuster",
      "Alexandre Piché"
    ],
    "abstract": "Building causal graphs can be a laborious process. To ensure all relevant\ncausal pathways have been captured, researchers often have to discuss with\nclinicians and experts while also reviewing extensive relevant medical\nliterature. By encoding common and medical knowledge, large language models\n(LLMs) represent an opportunity to ease this process by automatically scoring\nedges (i.e., connections between two variables) in potential graphs. LLMs\nhowever have been shown to be brittle to the choice of probing words, context,\nand prompts that the user employs. In this work, we evaluate if LLMs can be a\nuseful tool in complementing causal graph development.",
    "published": "2023-03-07T22:05:31Z",
    "pdf_url": "http://arxiv.org/pdf/2303.05279v2",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2310.10826v3",
    "title": "Mechanism Design for Large Language Models",
    "authors": [
      "Paul Duetting",
      "Vahab Mirrokni",
      "Renato Paes Leme",
      "Haifeng Xu",
      "Song Zuo"
    ],
    "abstract": "We investigate auction mechanisms for AI-generated content, focusing on\napplications like ad creative generation. In our model, agents' preferences\nover stochastically generated content are encoded as large language models\n(LLMs). We propose an auction format that operates on a token-by-token basis,\nand allows LLM agents to influence content creation through single dimensional\nbids. We formulate two desirable incentive properties and prove their\nequivalence to a monotonicity condition on output aggregation. This equivalence\nenables a second-price rule design, even absent explicit agent valuation\nfunctions. Our design is supported by demonstrations on a publicly available\nLLM.",
    "published": "2023-10-16T21:01:12Z",
    "pdf_url": "http://arxiv.org/pdf/2310.10826v3",
    "categories": [
      "cs.GT",
      "econ.TH"
    ]
  },
  {
    "arxiv_id": "2310.16673v1",
    "title": "Exploring Large Language Models for Code Explanation",
    "authors": [
      "Paheli Bhattacharya",
      "Manojit Chakraborty",
      "Kartheek N S N Palepu",
      "Vikas Pandey",
      "Ishan Dindorkar",
      "Rakesh Rajpurohit",
      "Rishabh Gupta"
    ],
    "abstract": "Automating code documentation through explanatory text can prove highly\nbeneficial in code understanding. Large Language Models (LLMs) have made\nremarkable strides in Natural Language Processing, especially within software\nengineering tasks such as code generation and code summarization. This study\nspecifically delves into the task of generating natural-language summaries for\ncode snippets, using various LLMs. The findings indicate that Code LLMs\noutperform their generic counterparts, and zero-shot methods yield superior\nresults when dealing with datasets with dissimilar distributions between\ntraining and testing sets.",
    "published": "2023-10-25T14:38:40Z",
    "pdf_url": "http://arxiv.org/pdf/2310.16673v1",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.IR",
      "D.2.3; I.7"
    ]
  },
  {
    "arxiv_id": "2401.02509v2",
    "title": "Memory, Consciousness and Large Language Model",
    "authors": [
      "Jitang Li",
      "Jinzheng Li"
    ],
    "abstract": "With the development in cognitive science and Large Language Models (LLMs),\nincreasing connections have come to light between these two distinct fields.\nBuilding upon these connections, we propose a conjecture suggesting the\nexistence of a duality between LLMs and Tulving's theory of memory. We identify\na potential correspondence between Tulving's synergistic ecphory model (SEM) of\nretrieval and the emergent abilities observed in LLMs, serving as supporting\nevidence for our conjecture. Furthermore, we speculate that consciousness may\nbe considered a form of emergent ability based on this duality. We also discuss\nhow other theories of consciousness intersect with our research.",
    "published": "2024-01-04T19:44:03Z",
    "pdf_url": "http://arxiv.org/pdf/2401.02509v2",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2402.17762v2",
    "title": "Massive Activations in Large Language Models",
    "authors": [
      "Mingjie Sun",
      "Xinlei Chen",
      "J. Zico Kolter",
      "Zhuang Liu"
    ],
    "abstract": "We observe an empirical phenomenon in Large Language Models (LLMs) -- very\nfew activations exhibit significantly larger values than others (e.g., 100,000\ntimes larger). We call them massive activations. First, we demonstrate the\nwidespread existence of massive activations across various LLMs and\ncharacterize their locations. Second, we find their values largely stay\nconstant regardless of the input, and they function as indispensable bias terms\nin LLMs. Third, these massive activations lead to the concentration of\nattention probabilities to their corresponding tokens, and further, implicit\nbias terms in the self-attention output. Last, we also study massive\nactivations in Vision Transformers. Code is available at\nhttps://github.com/locuslab/massive-activations.",
    "published": "2024-02-27T18:55:17Z",
    "pdf_url": "http://arxiv.org/pdf/2402.17762v2",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2405.20624v1",
    "title": "Leveraging Large Language Models for Entity Matching",
    "authors": [
      "Qianyu Huang",
      "Tongfang Zhao"
    ],
    "abstract": "Entity matching (EM) is a critical task in data integration, aiming to\nidentify records across different datasets that refer to the same real-world\nentities. Traditional methods often rely on manually engineered features and\nrule-based systems, which struggle with diverse and unstructured data. The\nemergence of Large Language Models (LLMs) such as GPT-4 offers transformative\npotential for EM, leveraging their advanced semantic understanding and\ncontextual capabilities. This vision paper explores the application of LLMs to\nEM, discussing their advantages, challenges, and future research directions.\nAdditionally, we review related work on applying weak supervision and\nunsupervised approaches to EM, highlighting how LLMs can enhance these methods.",
    "published": "2024-05-31T05:22:07Z",
    "pdf_url": "http://arxiv.org/pdf/2405.20624v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2411.04223v3",
    "title": "Diversity Helps Jailbreak Large Language Models",
    "authors": [
      "Weiliang Zhao",
      "Daniel Ben-Levi",
      "Wei Hao",
      "Junfeng Yang",
      "Chengzhi Mao"
    ],
    "abstract": "We have uncovered a powerful jailbreak technique that leverages large\nlanguage models' ability to diverge from prior context, enabling them to bypass\nsafety constraints and generate harmful outputs. By simply instructing the LLM\nto deviate and obfuscate previous attacks, our method dramatically outperforms\nexisting approaches, achieving up to a 62.83% higher success rate in\ncompromising ten leading chatbots, including GPT-4, Gemini, and Llama, while\nusing only 12.9% of the queries. This revelation exposes a critical flaw in\ncurrent LLM safety training, suggesting that existing methods may merely mask\nvulnerabilities rather than eliminate them. Our findings sound an urgent alarm\nfor the need to revolutionize testing methodologies to ensure robust and\nreliable LLM security.",
    "published": "2024-11-06T19:39:48Z",
    "pdf_url": "http://arxiv.org/pdf/2411.04223v3",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2412.16653v1",
    "title": "Internalized Self-Correction for Large Language Models",
    "authors": [
      "Nishanth Upadhyaya",
      "Raghavendra Sridharamurthy"
    ],
    "abstract": "In this article, we introduce 'Internalized Self-Correction' (InSeC) for\nlarge language models (LLMs). While many approaches exist for self-reflection\nat inference time, we propose a novel method that combines ideas from negative\nsampling, self-reflection during training, and inference time. InSeC allows\nLLMs to correct themselves by introducing mistakes and their corresponding\ncorrections during training, thereby converting the learning process into a\ntrue supervised learning task with both positive and negative examples. This\napproach can be extended to improve instruction following and correct\nhallucinations or incorrect sentences generated by LLMs.",
    "published": "2024-12-21T14:53:13Z",
    "pdf_url": "http://arxiv.org/pdf/2412.16653v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2501.06911v1",
    "title": "Risk-Averse Finetuning of Large Language Models",
    "authors": [
      "Sapana Chaudhary",
      "Ujwal Dinesha",
      "Dileep Kalathil",
      "Srinivas Shakkottai"
    ],
    "abstract": "We consider the challenge of mitigating the generation of negative or toxic\ncontent by the Large Language Models (LLMs) in response to certain prompts. We\npropose integrating risk-averse principles into LLM fine-tuning to minimize the\noccurrence of harmful outputs, particularly rare but significant events. By\noptimizing the risk measure of Conditional Value at Risk (CVaR), our\nmethodology trains LLMs to exhibit superior performance in avoiding toxic\noutputs while maintaining effectiveness in generative tasks. Empirical\nevaluations on sentiment modification and toxicity mitigation tasks demonstrate\nthe efficacy of risk-averse reinforcement learning with human feedback (RLHF)\nin promoting a safer and more constructive online discourse environment.",
    "published": "2025-01-12T19:48:21Z",
    "pdf_url": "http://arxiv.org/pdf/2501.06911v1",
    "categories": [
      "cs.AI",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2509.08480v1",
    "title": "Acquiescence Bias in Large Language Models",
    "authors": [
      "Daniel Braun"
    ],
    "abstract": "Acquiescence bias, i.e. the tendency of humans to agree with statements in\nsurveys, independent of their actual beliefs, is well researched and\ndocumented. Since Large Language Models (LLMs) have been shown to be very\ninfluenceable by relatively small changes in input and are trained on\nhuman-generated data, it is reasonable to assume that they could show a similar\ntendency. We present a study investigating the presence of acquiescence bias in\nLLMs across different models, tasks, and languages (English, German, and\nPolish). Our results indicate that, contrary to humans, LLMs display a bias\ntowards answering no, regardless of whether it indicates agreement or\ndisagreement.",
    "published": "2025-09-10T10:39:24Z",
    "pdf_url": "http://arxiv.org/pdf/2509.08480v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2301.13848v1",
    "title": "Benchmarking Large Language Models for News Summarization",
    "authors": [
      "Tianyi Zhang",
      "Faisal Ladhak",
      "Esin Durmus",
      "Percy Liang",
      "Kathleen McKeown",
      "Tatsunori B. Hashimoto"
    ],
    "abstract": "Large language models (LLMs) have shown promise for automatic summarization\nbut the reasons behind their successes are poorly understood. By conducting a\nhuman evaluation on ten LLMs across different pretraining methods, prompts, and\nmodel scales, we make two important observations. First, we find instruction\ntuning, and not model size, is the key to the LLM's zero-shot summarization\ncapability. Second, existing studies have been limited by low-quality\nreferences, leading to underestimates of human performance and lower few-shot\nand finetuning performance. To better evaluate LLMs, we perform human\nevaluation over high-quality summaries we collect from freelance writers.\nDespite major stylistic differences such as the amount of paraphrasing, we find\nthat LMM summaries are judged to be on par with human written summaries.",
    "published": "2023-01-31T18:46:19Z",
    "pdf_url": "http://arxiv.org/pdf/2301.13848v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2304.00008v5",
    "title": "On the Creativity of Large Language Models",
    "authors": [
      "Giorgio Franceschelli",
      "Mirco Musolesi"
    ],
    "abstract": "Large Language Models (LLMs) are revolutionizing several areas of Artificial\nIntelligence. One of the most remarkable applications is creative writing,\ne.g., poetry or storytelling: the generated outputs are often of astonishing\nquality. However, a natural question arises: can LLMs be really considered\ncreative? In this article, we first analyze the development of LLMs under the\nlens of creativity theories, investigating the key open questions and\nchallenges. In particular, we focus our discussion on the dimensions of value,\nnovelty, and surprise as proposed by Margaret Boden in her work. Then, we\nconsider different classic perspectives, namely product, process, press, and\nperson. We discuss a set of ``easy'' and ``hard'' problems in machine\ncreativity, presenting them in relation to LLMs. Finally, we examine the\nsocietal impact of these technologies with a particular focus on the creative\nindustries, analyzing the opportunities offered, the challenges arising from\nthem, and the potential associated risks, from both legal and ethical points of\nview.",
    "published": "2023-03-27T18:00:01Z",
    "pdf_url": "http://arxiv.org/pdf/2304.00008v5",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "2307.16648v2",
    "title": "LLMs4OL: Large Language Models for Ontology Learning",
    "authors": [
      "Hamed Babaei Giglou",
      "Jennifer D'Souza",
      "Sören Auer"
    ],
    "abstract": "We propose the LLMs4OL approach, which utilizes Large Language Models (LLMs)\nfor Ontology Learning (OL). LLMs have shown significant advancements in natural\nlanguage processing, demonstrating their ability to capture complex language\npatterns in different knowledge domains. Our LLMs4OL paradigm investigates the\nfollowing hypothesis: \\textit{Can LLMs effectively apply their language pattern\ncapturing capability to OL, which involves automatically extracting and\nstructuring knowledge from natural language text?} To test this hypothesis, we\nconduct a comprehensive evaluation using the zero-shot prompting method. We\nevaluate nine different LLM model families for three main OL tasks: term\ntyping, taxonomy discovery, and extraction of non-taxonomic relations.\nAdditionally, the evaluations encompass diverse genres of ontological\nknowledge, including lexicosemantic knowledge in WordNet, geographical\nknowledge in GeoNames, and medical knowledge in UMLS.",
    "published": "2023-07-31T13:27:21Z",
    "pdf_url": "http://arxiv.org/pdf/2307.16648v2",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ]
  },
  {
    "arxiv_id": "2308.07505v2",
    "title": "Data Race Detection Using Large Language Models",
    "authors": [
      "Le Chen",
      "Xianzhong Ding",
      "Murali Emani",
      "Tristan Vanderbruggen",
      "Pei-hung Lin",
      "Chuanhua Liao"
    ],
    "abstract": "Large language models (LLMs) are demonstrating significant promise as an\nalternate strategy to facilitate analyses and optimizations of high-performance\ncomputing programs, circumventing the need for resource-intensive manual tool\ncreation. In this paper, we explore a novel LLM-based data race detection\napproach combining prompting engineering and fine-tuning techniques. We create\na dedicated dataset named DRB-ML, which is derived from DataRaceBench, with\nfine-grain labels showing the presence of data race pairs and their associated\nvariables, line numbers, and read/write information. DRB-ML is then used to\nevaluate representative LLMs and fine-tune open-source ones. Our experiment\nshows that LLMs can be a viable approach to data race detection. However, they\nstill cannot compete with traditional data race detection tools when we need\ndetailed information about variable pairs causing data races.",
    "published": "2023-08-15T00:08:43Z",
    "pdf_url": "http://arxiv.org/pdf/2308.07505v2",
    "categories": [
      "cs.LG",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2309.02884v2",
    "title": "Aligning Large Language Models for Clinical Tasks",
    "authors": [
      "Supun Manathunga",
      "Isuru Hettigoda"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable adaptability,\nshowcasing their capacity to excel in tasks for which they were not explicitly\ntrained. However, despite their impressive natural language processing (NLP)\ncapabilities, effective alignment of LLMs remains a crucial challenge when\ndeploying them for specific clinical applications. The ability to generate\nresponses with factually accurate content and to engage in non-trivial\nreasoning steps are crucial for the LLMs to be eligible for applications in\nclinical medicine. Employing a combination of techniques including\ninstruction-tuning and in-prompt strategies like few-shot and chain-of-thought\nprompting has significantly enhanced the performance of LLMs. Our proposed\nalignment strategy for medical question-answering, known as\n'expand-guess-refine', offers a parameter and data-efficient solution. A\npreliminary analysis of this method demonstrated outstanding performance,\nachieving a score of 70.63% on a subset of questions sourced from the USMLE\ndataset.",
    "published": "2023-09-06T10:20:06Z",
    "pdf_url": "http://arxiv.org/pdf/2309.02884v2",
    "categories": [
      "cs.CL",
      "I.2, I.7, J.3"
    ]
  },
  {
    "arxiv_id": "2405.10369v1",
    "title": "Reinforcement learning",
    "authors": [
      "Sarod Yatawatta"
    ],
    "abstract": "Observing celestial objects and advancing our scientific knowledge about them\ninvolves tedious planning, scheduling, data collection and data\npost-processing. Many of these operational aspects of astronomy are guided and\nexecuted by expert astronomers. Reinforcement learning is a mechanism where we\n(as humans and astronomers) can teach agents of artificial intelligence to\nperform some of these tedious tasks. In this paper, we will present a state of\nthe art overview of reinforcement learning and how it can benefit astronomy.",
    "published": "2024-05-16T18:03:17Z",
    "pdf_url": "http://arxiv.org/pdf/2405.10369v1",
    "categories": [
      "astro-ph.IM",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2005.14419v2",
    "title": "Reinforcement Learning",
    "authors": [
      "Olivier Buffet",
      "Olivier Pietquin",
      "Paul Weng"
    ],
    "abstract": "Reinforcement learning (RL) is a general framework for adaptive control,\nwhich has proven to be efficient in many domains, e.g., board games, video\ngames or autonomous vehicles. In such problems, an agent faces a sequential\ndecision-making problem where, at every time step, it observes its state,\nperforms an action, receives a reward and moves to a new state. An RL agent\nlearns by trial and error a good policy (or controller) based on observations\nand numeric reward feedback on the previously performed action. In this\nchapter, we present the basic framework of RL and recall the two main families\nof approaches that have been developed to learn a good policy. The first one,\nwhich is value-based, consists in estimating the value of an optimal policy,\nvalue from which a policy can be recovered, while the other, called policy\nsearch, directly works in a policy space. Actor-critic methods can be seen as a\npolicy search technique where the policy value that is learned guides the\npolicy improvement. Besides, we give an overview of some extensions of the\nstandard RL framework, notably when risk-averse behavior needs to be taken into\naccount or when rewards are not available or not known.",
    "published": "2020-05-29T06:53:29Z",
    "pdf_url": "http://arxiv.org/pdf/2005.14419v2",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2307.16348v2",
    "title": "Rating-based Reinforcement Learning",
    "authors": [
      "Devin White",
      "Mingkang Wu",
      "Ellen Novoseller",
      "Vernon J. Lawhern",
      "Nicholas Waytowich",
      "Yongcan Cao"
    ],
    "abstract": "This paper develops a novel rating-based reinforcement learning approach that\nuses human ratings to obtain human guidance in reinforcement learning.\nDifferent from the existing preference-based and ranking-based reinforcement\nlearning paradigms, based on human relative preferences over sample pairs, the\nproposed rating-based reinforcement learning approach is based on human\nevaluation of individual trajectories without relative comparisons between\nsample pairs. The rating-based reinforcement learning approach builds on a new\nprediction model for human ratings and a novel multi-class loss function. We\nconduct several experimental studies based on synthetic ratings and real human\nratings to evaluate the effectiveness and benefits of the new rating-based\nreinforcement learning approach.",
    "published": "2023-07-30T23:54:22Z",
    "pdf_url": "http://arxiv.org/pdf/2307.16348v2",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ]
  },
  {
    "arxiv_id": "2010.14616v1",
    "title": "Lineage Evolution Reinforcement Learning",
    "authors": [
      "Zeyu Zhang",
      "Guisheng Yin"
    ],
    "abstract": "We propose a general agent population learning system, and on this basis, we\npropose lineage evolution reinforcement learning algorithm. Lineage evolution\nreinforcement learning is a kind of derivative algorithm which accords with the\ngeneral agent population learning system. We take the agents in DQN and its\nrelated variants as the basic agents in the population, and add the selection,\nmutation and crossover modules in the genetic algorithm to the reinforcement\nlearning algorithm. In the process of agent evolution, we refer to the\ncharacteristics of natural genetic behavior, add lineage factor to ensure the\nretention of potential performance of agent, and comprehensively consider the\ncurrent performance and lineage value when evaluating the performance of agent.\nWithout changing the parameters of the original reinforcement learning\nalgorithm, lineage evolution reinforcement learning can optimize different\nreinforcement learning algorithms. Our experiments show that the idea of\nevolution with lineage improves the performance of original reinforcement\nlearning algorithm in some games in Atari 2600.",
    "published": "2020-09-26T11:58:16Z",
    "pdf_url": "http://arxiv.org/pdf/2010.14616v1",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ]
  },
  {
    "arxiv_id": "2304.10098v2",
    "title": "Two-Memory Reinforcement Learning",
    "authors": [
      "Zhao Yang",
      "Thomas. M. Moerland",
      "Mike Preuss",
      "Aske Plaat"
    ],
    "abstract": "While deep reinforcement learning has shown important empirical success, it\ntends to learn relatively slow due to slow propagation of rewards information\nand slow update of parametric neural networks. Non-parametric episodic memory,\non the other hand, provides a faster learning alternative that does not require\nrepresentation learning and uses maximum episodic return as state-action values\nfor action selection. Episodic memory and reinforcement learning both have\ntheir own strengths and weaknesses. Notably, humans can leverage multiple\nmemory systems concurrently during learning and benefit from all of them. In\nthis work, we propose a method called Two-Memory reinforcement learning agent\n(2M) that combines episodic memory and reinforcement learning to distill both\nof their strengths. The 2M agent exploits the speed of the episodic memory part\nand the optimality and the generalization capacity of the reinforcement\nlearning part to complement each other. Our experiments demonstrate that the 2M\nagent is more data efficient and outperforms both pure episodic memory and pure\nreinforcement learning, as well as a state-of-the-art memory-augmented RL\nagent. Moreover, the proposed approach provides a general framework that can be\nused to combine any episodic memory agent with other off-policy reinforcement\nlearning algorithms.",
    "published": "2023-04-20T05:39:25Z",
    "pdf_url": "http://arxiv.org/pdf/2304.10098v2",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "9605103v1",
    "title": "Reinforcement Learning: A Survey",
    "authors": [
      "L. P. Kaelbling",
      "M. L. Littman",
      "A. W. Moore"
    ],
    "abstract": "This paper surveys the field of reinforcement learning from a\ncomputer-science perspective. It is written to be accessible to researchers\nfamiliar with machine learning. Both the historical basis of the field and a\nbroad selection of current work are summarized. Reinforcement learning is the\nproblem faced by an agent that learns behavior through trial-and-error\ninteractions with a dynamic environment. The work described here has a\nresemblance to work in psychology, but differs considerably in the details and\nin the use of the word ``reinforcement.'' The paper discusses central issues of\nreinforcement learning, including trading off exploration and exploitation,\nestablishing the foundations of the field via Markov decision theory, learning\nfrom delayed reinforcement, constructing empirical models to accelerate\nlearning, making use of generalization and hierarchy, and coping with hidden\nstate. It concludes with a survey of some implemented systems and an assessment\nof the practical utility of current methods for reinforcement learning.",
    "published": "1996-05-01T00:00:00Z",
    "pdf_url": "http://arxiv.org/pdf/cs/9605103v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1812.07019v2",
    "title": "Malthusian Reinforcement Learning",
    "authors": [
      "Joel Z. Leibo",
      "Julien Perolat",
      "Edward Hughes",
      "Steven Wheelwright",
      "Adam H. Marblestone",
      "Edgar Duéñez-Guzmán",
      "Peter Sunehag",
      "Iain Dunning",
      "Thore Graepel"
    ],
    "abstract": "Here we explore a new algorithmic framework for multi-agent reinforcement\nlearning, called Malthusian reinforcement learning, which extends self-play to\ninclude fitness-linked population size dynamics that drive ongoing innovation.\nIn Malthusian RL, increases in a subpopulation's average return drive\nsubsequent increases in its size, just as Thomas Malthus argued in 1798 was the\nrelationship between preindustrial income levels and population growth.\nMalthusian reinforcement learning harnesses the competitive pressures arising\nfrom growing and shrinking population size to drive agents to explore regions\nof state and policy spaces that they could not otherwise reach. Furthermore, in\nenvironments where there are potential gains from specialization and division\nof labor, we show that Malthusian reinforcement learning is better positioned\nto take advantage of such synergies than algorithms based on self-play.",
    "published": "2018-12-17T19:36:14Z",
    "pdf_url": "http://arxiv.org/pdf/1812.07019v2",
    "categories": [
      "cs.NE",
      "cs.MA",
      "q-bio.PE"
    ]
  },
  {
    "arxiv_id": "1905.02005v2",
    "title": "Deep Ordinal Reinforcement Learning",
    "authors": [
      "Alexander Zap",
      "Tobias Joppen",
      "Johannes Fürnkranz"
    ],
    "abstract": "Reinforcement learning usually makes use of numerical rewards, which have\nnice properties but also come with drawbacks and difficulties. Using rewards on\nan ordinal scale (ordinal rewards) is an alternative to numerical rewards that\nhas received more attention in recent years. In this paper, a general approach\nto adapting reinforcement learning problems to the use of ordinal rewards is\npresented and motivated. We show how to convert common reinforcement learning\nalgorithms to an ordinal variation by the example of Q-learning and introduce\nOrdinal Deep Q-Networks, which adapt deep reinforcement learning to ordinal\nrewards. Additionally, we run evaluations on problems provided by the OpenAI\nGym framework, showing that our ordinal variants exhibit a performance that is\ncomparable to the numerical variations for a number of problems. We also give\nfirst evidence that our ordinal variant is able to produce better results for\nproblems with less engineered and simpler-to-design reward signals.",
    "published": "2019-05-06T12:54:22Z",
    "pdf_url": "http://arxiv.org/pdf/1905.02005v2",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1901.08277v3",
    "title": "Federated Deep Reinforcement Learning",
    "authors": [
      "Hankz Hankui Zhuo",
      "Wenfeng Feng",
      "Yufeng Lin",
      "Qian Xu",
      "Qiang Yang"
    ],
    "abstract": "In deep reinforcement learning, building policies of high-quality is\nchallenging when the feature space of states is small and the training data is\nlimited. Despite the success of previous transfer learning approaches in deep\nreinforcement learning, directly transferring data or models from an agent to\nanother agent is often not allowed due to the privacy of data and/or models in\nmany privacy-aware applications. In this paper, we propose a novel deep\nreinforcement learning framework to federatively build models of high-quality\nfor agents with consideration of their privacies, namely Federated deep\nReinforcement Learning (FedRL). To protect the privacy of data and models, we\nexploit Gausian differentials on the information shared with each other when\nupdating their local models. In the experiment, we evaluate our FedRL framework\nin two diverse domains, Grid-world and Text2Action domains, by comparing to\nvarious baselines.",
    "published": "2019-01-24T08:25:29Z",
    "pdf_url": "http://arxiv.org/pdf/1901.08277v3",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1611.00862v1",
    "title": "Quantile Reinforcement Learning",
    "authors": [
      "Hugo Gilbert",
      "Paul Weng"
    ],
    "abstract": "In reinforcement learning, the standard criterion to evaluate policies in a\nstate is the expectation of (discounted) sum of rewards. However, this\ncriterion may not always be suitable, we consider an alternative criterion\nbased on the notion of quantiles. In the case of episodic reinforcement\nlearning problems, we propose an algorithm based on stochastic approximation\nwith two timescales. We evaluate our proposition on a simple model of the TV\nshow, Who wants to be a millionaire.",
    "published": "2016-11-03T02:28:53Z",
    "pdf_url": "http://arxiv.org/pdf/1611.00862v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1904.10729v2",
    "title": "Neural Logic Reinforcement Learning",
    "authors": [
      "Zhengyao Jiang",
      "Shan Luo"
    ],
    "abstract": "Deep reinforcement learning (DRL) has achieved significant breakthroughs in\nvarious tasks. However, most DRL algorithms suffer a problem of generalizing\nthe learned policy which makes the learning performance largely affected even\nby minor modifications of the training environment. Except that, the use of\ndeep neural networks makes the learned policies hard to be interpretable. To\naddress these two challenges, we propose a novel algorithm named Neural Logic\nReinforcement Learning (NLRL) to represent the policies in reinforcement\nlearning by first-order logic. NLRL is based on policy gradient methods and\ndifferentiable inductive logic programming that have demonstrated significant\nadvantages in terms of interpretability and generalisability in supervised\ntasks. Extensive experiments conducted on cliff-walking and blocks manipulation\ntasks demonstrate that NLRL can induce interpretable policies achieving\nnear-optimal performance while demonstrating good generalisability to\nenvironments of different initial states and problem sizes.",
    "published": "2019-04-24T10:24:35Z",
    "pdf_url": "http://arxiv.org/pdf/1904.10729v2",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1907.13196v4",
    "title": "Wasserstein Robust Reinforcement Learning",
    "authors": [
      "Mohammed Amin Abdullah",
      "Hang Ren",
      "Haitham Bou Ammar",
      "Vladimir Milenkovic",
      "Rui Luo",
      "Mingtian Zhang",
      "Jun Wang"
    ],
    "abstract": "Reinforcement learning algorithms, though successful, tend to over-fit to\ntraining environments hampering their application to the real-world. This paper\nproposes $\\text{W}\\text{R}^{2}\\text{L}$ -- a robust reinforcement learning\nalgorithm with significant robust performance on low and high-dimensional\ncontrol tasks. Our method formalises robust reinforcement learning as a novel\nmin-max game with a Wasserstein constraint for a correct and convergent solver.\nApart from the formulation, we also propose an efficient and scalable solver\nfollowing a novel zero-order optimisation method that we believe can be useful\nto numerical optimisation in general. We empirically demonstrate significant\ngains compared to standard and robust state-of-the-art algorithms on\nhigh-dimensional MuJuCo environments.",
    "published": "2019-07-30T19:42:52Z",
    "pdf_url": "http://arxiv.org/pdf/1907.13196v4",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2210.13504v1",
    "title": "Opportunistic Episodic Reinforcement Learning",
    "authors": [
      "Xiaoxiao Wang",
      "Nader Bouacida",
      "Xueying Guo",
      "Xin Liu"
    ],
    "abstract": "In this paper, we propose and study opportunistic reinforcement learning - a\nnew variant of reinforcement learning problems where the regret of selecting a\nsuboptimal action varies under an external environmental condition known as the\nvariation factor. When the variation factor is low, so is the regret of\nselecting a suboptimal action and vice versa. Our intuition is to exploit more\nwhen the variation factor is high, and explore more when the variation factor\nis low. We demonstrate the benefit of this novel framework for finite-horizon\nepisodic MDPs by designing and evaluating OppUCRL2 and OppPSRL algorithms. Our\nalgorithms dynamically balance the exploration-exploitation trade-off for\nreinforcement learning by introducing variation factor-dependent optimism to\nguide exploration. We establish an $\\tilde{O}(HS \\sqrt{AT})$ regret bound for\nthe OppUCRL2 algorithm and show through simulations that both OppUCRL2 and\nOppPSRL algorithm outperform their original corresponding algorithms.",
    "published": "2022-10-24T18:02:33Z",
    "pdf_url": "http://arxiv.org/pdf/2210.13504v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2212.14214v4",
    "title": "Backward Curriculum Reinforcement Learning",
    "authors": [
      "KyungMin Ko"
    ],
    "abstract": "Current reinforcement learning algorithms train an agent using\nforward-generated trajectories, which provide little guidance so that the agent\ncan explore as much as possible. While realizing the value of reinforcement\nlearning results from sufficient exploration, this approach leads to a\ntrade-off in losing sample efficiency, an essential factor impacting algorithm\nperformance. Previous tasks use reward-shaping techniques and network structure\nmodification to increase sample efficiency. However, these methods require many\nsteps to implement. In this work, we propose novel backward curriculum\nreinforcement learning that begins training the agent using the backward\ntrajectory of the episode instead of the original forward trajectory. This\napproach provides the agent with a strong reward signal, enabling more\nsample-efficient learning. Moreover, our method only requires a minor change in\nthe algorithm of reversing the order of the trajectory before agent training,\nallowing a straightforward application to any state-of-the-art algorithm.",
    "published": "2022-12-29T08:23:39Z",
    "pdf_url": "http://arxiv.org/pdf/2212.14214v4",
    "categories": [
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2305.19922v2",
    "title": "Representation-Driven Reinforcement Learning",
    "authors": [
      "Ofir Nabati",
      "Guy Tennenholtz",
      "Shie Mannor"
    ],
    "abstract": "We present a representation-driven framework for reinforcement learning. By\nrepresenting policies as estimates of their expected values, we leverage\ntechniques from contextual bandits to guide exploration and exploitation.\nParticularly, embedding a policy network into a linear feature space allows us\nto reframe the exploration-exploitation problem as a\nrepresentation-exploitation problem, where good policy representations enable\noptimal exploration. We demonstrate the effectiveness of this framework through\nits application to evolutionary and policy gradient-based approaches, leading\nto significantly improved performance compared to traditional methods. Our\nframework provides a new perspective on reinforcement learning, highlighting\nthe importance of policy representation in determining optimal\nexploration-exploitation strategies.",
    "published": "2023-05-31T14:59:12Z",
    "pdf_url": "http://arxiv.org/pdf/2305.19922v2",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2109.02145v3",
    "title": "Temporal Shift Reinforcement Learning",
    "authors": [
      "Deepak George Thomas",
      "Tichakorn Wongpiromsarn",
      "Ali Jannesari"
    ],
    "abstract": "The function approximators employed by traditional image-based Deep\nReinforcement Learning (DRL) algorithms usually lack a temporal learning\ncomponent and instead focus on learning the spatial component. We propose a\ntechnique, Temporal Shift Reinforcement Learning (TSRL), wherein both temporal,\nas well as spatial components are jointly learned. Moreover, TSRL does not\nrequire additional parameters to perform temporal learning. We show that TSRL\noutperforms the commonly used frame stacking heuristic on both of the Atari\nenvironments we test on while beating the SOTA for one of them. This\ninvestigation has implications in the robotics as well as sequential\ndecision-making domains.",
    "published": "2021-09-05T18:47:13Z",
    "pdf_url": "http://arxiv.org/pdf/2109.02145v3",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2303.14623v4",
    "title": "Inverse Reinforcement Learning without Reinforcement Learning",
    "authors": [
      "Gokul Swamy",
      "Sanjiban Choudhury",
      "J. Andrew Bagnell",
      "Zhiwei Steven Wu"
    ],
    "abstract": "Inverse Reinforcement Learning (IRL) is a powerful set of techniques for\nimitation learning that aims to learn a reward function that rationalizes\nexpert demonstrations. Unfortunately, traditional IRL methods suffer from a\ncomputational weakness: they require repeatedly solving a hard reinforcement\nlearning (RL) problem as a subroutine. This is counter-intuitive from the\nviewpoint of reductions: we have reduced the easier problem of imitation\nlearning to repeatedly solving the harder problem of RL. Another thread of work\nhas proved that access to the side-information of the distribution of states\nwhere a strong policy spends time can dramatically reduce the sample and\ncomputational complexities of solving an RL problem. In this work, we\ndemonstrate for the first time a more informed imitation learning reduction\nwhere we utilize the state distribution of the expert to alleviate the global\nexploration component of the RL subroutine, providing an exponential speedup in\ntheory. In practice, we find that we are able to significantly speed up the\nprior art on continuous control tasks.",
    "published": "2023-03-26T04:35:53Z",
    "pdf_url": "http://arxiv.org/pdf/2303.14623v4",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1810.00240v1",
    "title": "Reinforcement Learning in R",
    "authors": [
      "Nicolas Pröllochs",
      "Stefan Feuerriegel"
    ],
    "abstract": "Reinforcement learning refers to a group of methods from artificial\nintelligence where an agent performs learning through trial and error. It\ndiffers from supervised learning, since reinforcement learning requires no\nexplicit labels; instead, the agent interacts continuously with its\nenvironment. That is, the agent starts in a specific state and then performs an\naction, based on which it transitions to a new state and, depending on the\noutcome, receives a reward. Different strategies (e.g. Q-learning) have been\nproposed to maximize the overall reward, resulting in a so-called policy, which\ndefines the best possible action in each state. Mathematically, this process\ncan be formalized by a Markov decision process and it has been implemented by\npackages in R; however, there is currently no package available for\nreinforcement learning. As a remedy, this paper demonstrates how to perform\nreinforcement learning in R and, for this purpose, introduces the\nReinforcementLearning package. The package provides a remarkably flexible\nframework and is easily applied to a wide range of different problems. We\ndemonstrate its use by drawing upon common examples from the literature (e.g.\nfinding optimal game strategies).",
    "published": "2018-09-29T17:25:40Z",
    "pdf_url": "http://arxiv.org/pdf/1810.00240v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1908.06973v1",
    "title": "Reinforcement Learning Applications",
    "authors": [
      "Yuxi Li"
    ],
    "abstract": "We start with a brief introduction to reinforcement learning (RL), about its\nsuccessful stories, basics, an example, issues, the ICML 2019 Workshop on RL\nfor Real Life, how to use it, study material and an outlook. Then we discuss a\nselection of RL applications, including recommender systems, computer systems,\nenergy, finance, healthcare, robotics, and transportation.",
    "published": "2019-08-19T09:47:22Z",
    "pdf_url": "http://arxiv.org/pdf/1908.06973v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2207.00046v2",
    "title": "Performative Reinforcement Learning",
    "authors": [
      "Debmalya Mandal",
      "Stelios Triantafyllou",
      "Goran Radanovic"
    ],
    "abstract": "We introduce the framework of performative reinforcement learning where the\npolicy chosen by the learner affects the underlying reward and transition\ndynamics of the environment. Following the recent literature on performative\nprediction~\\cite{Perdomo et. al., 2020}, we introduce the concept of\nperformatively stable policy. We then consider a regularized version of the\nreinforcement learning problem and show that repeatedly optimizing this\nobjective converges to a performatively stable policy under reasonable\nassumptions on the transition dynamics. Our proof utilizes the dual perspective\nof the reinforcement learning problem and may be of independent interest in\nanalyzing the convergence of other algorithms with decision-dependent\nenvironments. We then extend our results for the setting where the learner just\nperforms gradient ascent steps instead of fully optimizing the objective, and\nfor the setting where the learner has access to a finite number of trajectories\nfrom the changed environment. For both settings, we leverage the dual\nformulation of performative reinforcement learning and establish convergence to\na stable solution. Finally, through extensive experiments on a grid-world\nenvironment, we demonstrate the dependence of convergence on various parameters\ne.g. regularization, smoothness, and the number of samples.",
    "published": "2022-06-30T18:26:03Z",
    "pdf_url": "http://arxiv.org/pdf/2207.00046v2",
    "categories": [
      "cs.LG",
      "cs.GT"
    ]
  },
  {
    "arxiv_id": "2201.09746v1",
    "title": "Reinforcement Learning Textbook",
    "authors": [
      "Sergey Ivanov"
    ],
    "abstract": "This textbook covers principles behind main modern deep reinforcement\nlearning algorithms that achieved breakthrough results in many domains from\ngame AI to robotics. All required theory is explained with proofs using unified\nnotation and emphasize on the differences between different types of algorithms\nand the reasons why they are constructed the way they are.",
    "published": "2022-01-19T15:54:39Z",
    "pdf_url": "http://arxiv.org/pdf/2201.09746v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "cs.RO"
    ]
  },
  {
    "arxiv_id": "2405.17287v2",
    "title": "Opinion-Guided Reinforcement Learning",
    "authors": [
      "Kyanna Dagenais",
      "Istvan David"
    ],
    "abstract": "Human guidance is often desired in reinforcement learning to improve the\nperformance of the learning agent. However, human insights are often mere\nopinions and educated guesses rather than well-formulated arguments. While\nopinions are subject to uncertainty, e.g., due to partial informedness or\nignorance about a problem, they also emerge earlier than hard evidence can be\nproduced. Thus, guiding reinforcement learning agents by way of opinions offers\nthe potential for more performant learning processes, but comes with the\nchallenge of modeling and managing opinions in a formal way. In this article,\nwe present a method to guide reinforcement learning agents through opinions. To\nthis end, we provide an end-to-end method to model and manage advisors'\nopinions. To assess the utility of the approach, we evaluate it with synthetic\n(oracle) and human advisors, at different levels of uncertainty, and under\nmultiple advice strategies. Our results indicate that opinions, even if\nuncertain, improve the performance of reinforcement learning agents, resulting\nin higher rewards, more efficient exploration, and a better reinforced policy.\nAlthough we demonstrate our approach through a two-dimensional topological\nrunning example, our approach is applicable to complex problems with higher\ndimensions as well.",
    "published": "2024-05-27T15:52:27Z",
    "pdf_url": "http://arxiv.org/pdf/2405.17287v2",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2412.05265v4",
    "title": "Reinforcement Learning: An Overview",
    "authors": [
      "Kevin Murphy"
    ],
    "abstract": "This manuscript gives a big-picture, up-to-date overview of the field of\n(deep) reinforcement learning and sequential decision making, covering\nvalue-based methods, policy-based methods, model-based methods, multi-agent RL,\nLLMs and RL, and various other topics (e.g., offline RL, hierarchical RL,\nintrinsic reward).",
    "published": "2024-12-06T18:53:49Z",
    "pdf_url": "http://arxiv.org/pdf/2412.05265v4",
    "categories": [
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1809.06064v1",
    "title": "Object-sensitive Deep Reinforcement Learning",
    "authors": [
      "Yuezhang Li",
      "Katia Sycara",
      "Rahul Iyer"
    ],
    "abstract": "Deep reinforcement learning has become popular over recent years, showing\nsuperiority on different visual-input tasks such as playing Atari games and\nrobot navigation. Although objects are important image elements, few work\nconsiders enhancing deep reinforcement learning with object characteristics. In\nthis paper, we propose a novel method that can incorporate object recognition\nprocessing to deep reinforcement learning models. This approach can be adapted\nto any existing deep reinforcement learning frameworks. State-of-the-art\nresults are shown in experiments on Atari games. We also propose a new approach\ncalled \"object saliency maps\" to visually explain the actions made by deep\nreinforcement learning agents.",
    "published": "2018-09-17T07:59:36Z",
    "pdf_url": "http://arxiv.org/pdf/1809.06064v1",
    "categories": [
      "cs.LG",
      "cs.CV",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1303.6977v4",
    "title": "ABC Reinforcement Learning",
    "authors": [
      "Christos Dimitrakakis",
      "Nikolaos Tziortziotis"
    ],
    "abstract": "This paper introduces a simple, general framework for likelihood-free\nBayesian reinforcement learning, through Approximate Bayesian Computation\n(ABC). The main advantage is that we only require a prior distribution on a\nclass of simulators (generative models). This is useful in domains where an\nanalytical probabilistic model of the underlying process is too complex to\nformulate, but where detailed simulation models are available. ABC-RL allows\nthe use of any Bayesian reinforcement learning technique, even in this case. In\naddition, it can be seen as an extension of rollout algorithms to the case\nwhere we do not know what the correct model to draw rollouts from is. We\nexperimentally demonstrate the potential of this approach in a comparison with\nLSPI. Finally, we introduce a theorem showing that ABC is a sound methodology\nin principle, even when non-sufficient statistics are used.",
    "published": "2013-03-27T20:51:33Z",
    "pdf_url": "http://arxiv.org/pdf/1303.6977v4",
    "categories": [
      "stat.ML",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1810.06339v1",
    "title": "Deep Reinforcement Learning",
    "authors": [
      "Yuxi Li"
    ],
    "abstract": "We discuss deep reinforcement learning in an overview style. We draw a big\npicture, filled with details. We discuss six core elements, six important\nmechanisms, and twelve applications, focusing on contemporary work, and in\nhistorical contexts. We start with background of artificial intelligence,\nmachine learning, deep learning, and reinforcement learning (RL), with\nresources. Next we discuss RL core elements, including value function, policy,\nreward, model, exploration vs. exploitation, and representation. Then we\ndiscuss important mechanisms for RL, including attention and memory,\nunsupervised learning, hierarchical RL, multi-agent RL, relational RL, and\nlearning to learn. After that, we discuss RL applications, including games,\nrobotics, natural language processing (NLP), computer vision, finance, business\nmanagement, healthcare, education, energy, transportation, computer systems,\nand, science, engineering, and art. Finally we summarize briefly, discuss\nchallenges and opportunities, and close with an epilogue.",
    "published": "2018-10-15T13:20:56Z",
    "pdf_url": "http://arxiv.org/pdf/1810.06339v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1905.08513v8",
    "title": "Stochastic Inverse Reinforcement Learning",
    "authors": [
      "Ce Ju"
    ],
    "abstract": "The goal of the inverse reinforcement learning (IRL) problem is to recover\nthe reward functions from expert demonstrations. However, the IRL problem like\nany ill-posed inverse problem suffers the congenital defect that the policy may\nbe optimal for many reward functions, and expert demonstrations may be optimal\nfor many policies. In this work, we generalize the IRL problem to a well-posed\nexpectation optimization problem stochastic inverse reinforcement learning\n(SIRL) to recover the probability distribution over reward functions. We adopt\nthe Monte Carlo expectation-maximization (MCEM) method to estimate the\nparameter of the probability distribution as the first solution to the SIRL\nproblem. The solution is succinct, robust, and transferable for a learning task\nand can generate alternative solutions to the IRL problem. Through our\nformulation, it is possible to observe the intrinsic property of the IRL\nproblem from a global viewpoint, and our approach achieves a considerable\nperformance on the objectworld.",
    "published": "2019-05-21T09:29:18Z",
    "pdf_url": "http://arxiv.org/pdf/1905.08513v8",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML",
      "I.2.6"
    ]
  },
  {
    "arxiv_id": "2209.06866v1",
    "title": "Robust Constrained Reinforcement Learning",
    "authors": [
      "Yue Wang",
      "Fei Miao",
      "Shaofeng Zou"
    ],
    "abstract": "Constrained reinforcement learning is to maximize the expected reward subject\nto constraints on utilities/costs. However, the training environment may not be\nthe same as the test one, due to, e.g., modeling error, adversarial attack,\nnon-stationarity, resulting in severe performance degradation and more\nimportantly constraint violation. We propose a framework of robust constrained\nreinforcement learning under model uncertainty, where the MDP is not fixed but\nlies in some uncertainty set, the goal is to guarantee that constraints on\nutilities/costs are satisfied for all MDPs in the uncertainty set, and to\nmaximize the worst-case reward performance over the uncertainty set. We design\na robust primal-dual approach, and further theoretically develop guarantee on\nits convergence, complexity and robust feasibility. We then investigate a\nconcrete example of $\\delta$-contamination uncertainty set, design an online\nand model-free algorithm and theoretically characterize its sample complexity.",
    "published": "2022-09-14T18:29:02Z",
    "pdf_url": "http://arxiv.org/pdf/2209.06866v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1902.04178v1",
    "title": "Stochastic Reinforcement Learning",
    "authors": [
      "Nikki Lijing Kuang",
      "Clement H. C. Leung",
      "Vienne W. K. Sung"
    ],
    "abstract": "In reinforcement learning episodes, the rewards and punishments are often\nnon-deterministic, and there are invariably stochastic elements governing the\nunderlying situation. Such stochastic elements are often numerous and cannot be\nknown in advance, and they have a tendency to obscure the underlying rewards\nand punishments patterns. Indeed, if stochastic elements were absent, the same\noutcome would occur every time and the learning problems involved could be\ngreatly simplified. In addition, in most practical situations, the cost of an\nobservation to receive either a reward or punishment can be significant, and\none would wish to arrive at the correct learning conclusion by incurring\nminimum cost. In this paper, we present a stochastic approach to reinforcement\nlearning which explicitly models the variability present in the learning\nenvironment and the cost of observation. Criteria and rules for learning\nsuccess are quantitatively analyzed, and probabilities of exceeding the\nobservation cost bounds are also obtained.",
    "published": "2019-02-11T23:13:32Z",
    "pdf_url": "http://arxiv.org/pdf/1902.04178v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2402.07157v2",
    "title": "Natural Language Reinforcement Learning",
    "authors": [
      "Xidong Feng",
      "Ziyu Wan",
      "Mengyue Yang",
      "Ziyan Wang",
      "Girish A. Koushik",
      "Yali Du",
      "Ying Wen",
      "Jun Wang"
    ],
    "abstract": "Reinforcement Learning (RL) has shown remarkable abilities in learning\npolicies for decision-making tasks. However, RL is often hindered by issues\nsuch as low sample efficiency, lack of interpretability, and sparse supervision\nsignals. To tackle these limitations, we take inspiration from the human\nlearning process and introduce Natural Language Reinforcement Learning (NLRL),\nwhich innovatively combines RL principles with natural language representation.\nSpecifically, NLRL redefines RL concepts like task objectives, policy, value\nfunction, Bellman equation, and policy iteration in natural language space. We\npresent how NLRL can be practically implemented with the latest advancements in\nlarge language models (LLMs) like GPT-4. Initial experiments over tabular MDPs\ndemonstrate the effectiveness, efficiency, and also interpretability of the\nNLRL framework.",
    "published": "2024-02-11T11:03:04Z",
    "pdf_url": "http://arxiv.org/pdf/2402.07157v2",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2411.14251v3",
    "title": "Natural Language Reinforcement Learning",
    "authors": [
      "Xidong Feng",
      "Bo Liu",
      "Yan Song",
      "Haotian Fu",
      "Ziyu Wan",
      "Girish A. Koushik",
      "Zhiyuan Hu",
      "Mengyue Yang",
      "Ying Wen",
      "Jun Wang"
    ],
    "abstract": "Artificial intelligence progresses towards the \"Era of Experience,\" where\nagents are expected to learn from continuous, grounded interaction. We argue\nthat traditional Reinforcement Learning (RL), which typically represents value\nas a scalar, can restrict agent's deep understanding of environments and\nhinders the active, deliberative learning crucial for navigating this new\nparadigm. To address the issue, we introduce Natural Language Reinforcement\nLearning (NLRL), a framework that extends RL principles into natural language\ncounterparts. Central to NLRL is the Language Value Function (LVF), which\nredefines value as an interpretable linguistic narrative articulating the\nrationale behind an evaluation. NLRL further extends this concept to core RL\ncomponents, including policy, the Bellman equation, and policy iteration.\nLeveraging recent advancements in Large Language Models (LLMs), NLRL can be\npractically implemented to achieve RL-like policy and value training through\nunsupervised environment interactions. Experiments over 4 multi-step agentic\ntasks demonstrate NLRL's effectiveness, efficiency, and its potential to foster\ndeeper understanding and more active learning strategies.",
    "published": "2024-11-21T15:57:02Z",
    "pdf_url": "http://arxiv.org/pdf/2411.14251v3",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2501.15893v2",
    "title": "Benchmarking Quantum Reinforcement Learning",
    "authors": [
      "Nico Meyer",
      "Christian Ufrecht",
      "George Yammine",
      "Georgios Kontes",
      "Christopher Mutschler",
      "Daniel D. Scherer"
    ],
    "abstract": "Benchmarking and establishing proper statistical validation metrics for\nreinforcement learning (RL) remain ongoing challenges, where no consensus has\nbeen established yet. The emergence of quantum computing and its potential\napplications in quantum reinforcement learning (QRL) further complicate\nbenchmarking efforts. To enable valid performance comparisons and to streamline\ncurrent research in this area, we propose a novel benchmarking methodology,\nwhich is based on a statistical estimator for sample complexity and a\ndefinition of statistical outperformance. Furthermore, considering QRL, our\nmethodology casts doubt on some previous claims regarding its superiority. We\nconducted experiments on a novel benchmarking environment with flexible levels\nof complexity. While we still identify possible advantages, our findings are\nmore nuanced overall. We discuss the potential limitations of these results and\nexplore their implications for empirical research on quantum advantage in QRL.",
    "published": "2025-01-27T09:40:18Z",
    "pdf_url": "http://arxiv.org/pdf/2501.15893v2",
    "categories": [
      "quant-ph",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2504.16417v1",
    "title": "Anytime Safe Reinforcement Learning",
    "authors": [
      "Pol Mestres",
      "Arnau Marzabal",
      "Jorge Cortés"
    ],
    "abstract": "This paper considers the problem of solving constrained\n  reinforcement learning problems with anytime guarantees, meaning\n  that the algorithmic solution returns a safe policy regardless of\n  when it is terminated. Drawing inspiration from anytime constrained\n  optimization, we introduce Reinforcement Learning-based Safe\n  Gradient Flow (RL-SGF), an on-policy algorithm which employs\n  estimates of the value functions and their respective gradients\n  associated with the objective and safety constraints for the current\n  policy, and updates the policy parameters by solving a convex\n  quadratically constrained quadratic program. We show that if the\n  estimates are computed with a sufficiently large number of episodes\n  (for which we provide an explicit bound), safe policies are updated\n  to safe policies with a probability higher than a prescribed\n  tolerance. We also show that iterates asymptotically converge to a\n  neighborhood of a KKT point, whose size can be arbitrarily reduced\n  by refining the estimates of the value function and their gradients.\n  We illustrate the performance of RL-SGF in a navigation example.",
    "published": "2025-04-23T04:51:31Z",
    "pdf_url": "http://arxiv.org/pdf/2504.16417v1",
    "categories": [
      "eess.SY",
      "cs.SY"
    ]
  },
  {
    "arxiv_id": "2506.00458v1",
    "title": "Reinforcement Learning for Hanabi",
    "authors": [
      "Nina Cohen",
      "Kordel K. France"
    ],
    "abstract": "Hanabi has become a popular game for research when it comes to reinforcement\nlearning (RL) as it is one of the few cooperative card games where you have\nincomplete knowledge of the entire environment, thus presenting a challenge for\na RL agent. We explored different tabular and deep reinforcement learning\nalgorithms to see which had the best performance both against an agent of the\nsame type and also against other types of agents. We establish that certain\nagents played their highest scoring games against specific agents while others\nexhibited higher scores on average by adapting to the opposing agent's\nbehavior. We attempted to quantify the conditions under which each algorithm\nprovides the best advantage and identified the most interesting interactions\nbetween agents of different types. In the end, we found that temporal\ndifference (TD) algorithms had better overall performance and balancing of play\ntypes compared to tabular agents. Specifically, tabular Expected SARSA and deep\nQ-Learning agents showed the best performance.",
    "published": "2025-05-31T08:24:16Z",
    "pdf_url": "http://arxiv.org/pdf/2506.00458v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT",
      "cs.MA"
    ]
  },
  {
    "arxiv_id": "1905.01072v3",
    "title": "Deep Residual Reinforcement Learning",
    "authors": [
      "Shangtong Zhang",
      "Wendelin Boehmer",
      "Shimon Whiteson"
    ],
    "abstract": "We revisit residual algorithms in both model-free and model-based\nreinforcement learning settings. We propose the bidirectional target network\ntechnique to stabilize residual algorithms, yielding a residual version of DDPG\nthat significantly outperforms vanilla DDPG in the DeepMind Control Suite\nbenchmark. Moreover, we find the residual algorithm an effective approach to\nthe distribution mismatch problem in model-based planning. Compared with the\nexisting TD($k$) method, our residual-based method makes weaker assumptions\nabout the model and yields a greater performance boost.",
    "published": "2019-05-03T08:38:35Z",
    "pdf_url": "http://arxiv.org/pdf/1905.01072v3",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1908.08773v2",
    "title": "Opponent Aware Reinforcement Learning",
    "authors": [
      "Victor Gallego",
      "Roi Naveiro",
      "David Rios Insua",
      "David Gomez-Ullate Oteiza"
    ],
    "abstract": "We introduce Threatened Markov Decision Processes (TMDPs) as an extension of\nthe classical Markov Decision Process framework for Reinforcement Learning\n(RL). TMDPs allow suporting a decision maker against potential opponents in a\nRL context. We also propose a level-k thinking scheme resulting in a novel\nlearning approach to deal with TMDPs. After introducing our framework and\nderiving theoretical results, relevant empirical evidence is given via\nextensive experiments, showing the benefits of accounting for adversaries in RL\nwhile the agent learns",
    "published": "2019-08-22T04:19:12Z",
    "pdf_url": "http://arxiv.org/pdf/1908.08773v2",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2210.08263v1",
    "title": "Reinforcement Learning for ConnectX",
    "authors": [
      "Sheel Shah",
      "Shubham Gupta"
    ],
    "abstract": "ConnectX is a two-player game that generalizes the popular game Connect 4.\nThe objective is to get X coins across a row, column, or diagonal of an M x N\nboard. The first player to do so wins the game. The parameters (M, N, X) are\nallowed to change in each game, making ConnectX a novel and challenging\nproblem. In this paper, we present our work on the implementation and\nmodification of various reinforcement learning algorithms to play ConnectX.",
    "published": "2022-10-15T11:38:19Z",
    "pdf_url": "http://arxiv.org/pdf/2210.08263v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1804.02477v3",
    "title": "Programmatically Interpretable Reinforcement Learning",
    "authors": [
      "Abhinav Verma",
      "Vijayaraghavan Murali",
      "Rishabh Singh",
      "Pushmeet Kohli",
      "Swarat Chaudhuri"
    ],
    "abstract": "We present a reinforcement learning framework, called Programmatically\nInterpretable Reinforcement Learning (PIRL), that is designed to generate\ninterpretable and verifiable agent policies. Unlike the popular Deep\nReinforcement Learning (DRL) paradigm, which represents policies by neural\nnetworks, PIRL represents policies using a high-level, domain-specific\nprogramming language. Such programmatic policies have the benefits of being\nmore easily interpreted than neural networks, and being amenable to\nverification by symbolic methods. We propose a new method, called Neurally\nDirected Program Search (NDPS), for solving the challenging nonsmooth\noptimization problem of finding a programmatic policy with maximal reward. NDPS\nworks by first learning a neural policy network using DRL, and then performing\na local search over programmatic policies that seeks to minimize a distance\nfrom this neural \"oracle\". We evaluate NDPS on the task of learning to drive a\nsimulated car in the TORCS car-racing environment. We demonstrate that NDPS is\nable to discover human-readable policies that pass some significant performance\nbars. We also show that PIRL policies can have smoother trajectories, and can\nbe more easily transferred to environments not encountered during training,\nthan corresponding policies discovered by DRL.",
    "published": "2018-04-06T22:17:18Z",
    "pdf_url": "http://arxiv.org/pdf/1804.02477v3",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PL",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2202.05135v5",
    "title": "Group-Agent Reinforcement Learning",
    "authors": [
      "Kaiyue Wu",
      "Xiao-Jun Zeng"
    ],
    "abstract": "It can largely benefit the reinforcement learning (RL) process of each agent\nif multiple geographically distributed agents perform their separate RL tasks\ncooperatively. Different from multi-agent reinforcement learning (MARL) where\nmultiple agents are in a common environment and should learn to cooperate or\ncompete with each other, in this case each agent has its separate environment\nand only communicates with others to share knowledge without any cooperative or\ncompetitive behaviour as a learning outcome. In fact, this scenario exists\nwidely in real life whose concept can be utilised in many applications, but is\nnot well understood yet and not well formulated. As the first effort, we\npropose group-agent system for RL as a formulation of this scenario and the\nthird type of RL system with respect to single-agent and multi-agent systems.\nWe then propose a distributed RL framework called DDAL (Decentralised\nDistributed Asynchronous Learning) designed for group-agent reinforcement\nlearning (GARL). We show through experiments that DDAL achieved desirable\nperformance with very stable training and has good scalability.",
    "published": "2022-02-10T16:40:59Z",
    "pdf_url": "http://arxiv.org/pdf/2202.05135v5",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2110.07940v1",
    "title": "Wasserstein Unsupervised Reinforcement Learning",
    "authors": [
      "Shuncheng He",
      "Yuhang Jiang",
      "Hongchang Zhang",
      "Jianzhun Shao",
      "Xiangyang Ji"
    ],
    "abstract": "Unsupervised reinforcement learning aims to train agents to learn a handful\nof policies or skills in environments without external reward. These\npre-trained policies can accelerate learning when endowed with external reward,\nand can also be used as primitive options in hierarchical reinforcement\nlearning. Conventional approaches of unsupervised skill discovery feed a latent\nvariable to the agent and shed its empowerment on agent's behavior by mutual\ninformation (MI) maximization. However, the policies learned by MI-based\nmethods cannot sufficiently explore the state space, despite they can be\nsuccessfully identified from each other. Therefore we propose a new framework\nWasserstein unsupervised reinforcement learning (WURL) where we directly\nmaximize the distance of state distributions induced by different policies.\nAdditionally, we overcome difficulties in simultaneously training N(N >2)\npolicies, and amortizing the overall reward to each step. Experiments show\npolicies learned by our approach outperform MI-based methods on the metric of\nWasserstein distance while keeping high discriminability. Furthermore, the\nagents trained by WURL can sufficiently explore the state space in mazes and\nMuJoCo tasks and the pre-trained policies can be applied to downstream tasks by\nhierarchical learning.",
    "published": "2021-10-15T08:41:51Z",
    "pdf_url": "http://arxiv.org/pdf/2110.07940v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2204.02372v2",
    "title": "Jump-Start Reinforcement Learning",
    "authors": [
      "Ikechukwu Uchendu",
      "Ted Xiao",
      "Yao Lu",
      "Banghua Zhu",
      "Mengyuan Yan",
      "Joséphine Simon",
      "Matthew Bennice",
      "Chuyuan Fu",
      "Cong Ma",
      "Jiantao Jiao",
      "Sergey Levine",
      "Karol Hausman"
    ],
    "abstract": "Reinforcement learning (RL) provides a theoretical framework for continuously\nimproving an agent's behavior via trial and error. However, efficiently\nlearning policies from scratch can be very difficult, particularly for tasks\nwith exploration challenges. In such settings, it might be desirable to\ninitialize RL with an existing policy, offline data, or demonstrations.\nHowever, naively performing such initialization in RL often works poorly,\nespecially for value-based methods. In this paper, we present a meta algorithm\nthat can use offline data, demonstrations, or a pre-existing policy to\ninitialize an RL policy, and is compatible with any RL approach. In particular,\nwe propose Jump-Start Reinforcement Learning (JSRL), an algorithm that employs\ntwo policies to solve tasks: a guide-policy, and an exploration-policy. By\nusing the guide-policy to form a curriculum of starting states for the\nexploration-policy, we are able to efficiently improve performance on a set of\nsimulated robotic tasks. We show via experiments that JSRL is able to\nsignificantly outperform existing imitation and reinforcement learning\nalgorithms, particularly in the small-data regime. In addition, we provide an\nupper bound on the sample complexity of JSRL and show that with the help of a\nguide-policy, one can improve the sample complexity for non-optimism\nexploration methods from exponential in horizon to polynomial.",
    "published": "2022-04-05T17:25:22Z",
    "pdf_url": "http://arxiv.org/pdf/2204.02372v2",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2309.15293v5",
    "title": "Maximum diffusion reinforcement learning",
    "authors": [
      "Thomas A. Berrueta",
      "Allison Pinosky",
      "Todd D. Murphey"
    ],
    "abstract": "Robots and animals both experience the world through their bodies and senses.\nTheir embodiment constrains their experiences, ensuring they unfold\ncontinuously in space and time. As a result, the experiences of embodied agents\nare intrinsically correlated. Correlations create fundamental challenges for\nmachine learning, as most techniques rely on the assumption that data are\nindependent and identically distributed. In reinforcement learning, where data\nare directly collected from an agent's sequential experiences, violations of\nthis assumption are often unavoidable. Here, we derive a method that overcomes\nthis issue by exploiting the statistical mechanics of ergodic processes, which\nwe term maximum diffusion reinforcement learning. By decorrelating agent\nexperiences, our approach provably enables single-shot learning in continuous\ndeployments over the course of individual task attempts. Moreover, we prove our\napproach generalizes well-known maximum entropy techniques, and robustly\nexceeds state-of-the-art performance across popular benchmarks. Our results at\nthe nexus of physics, learning, and control form a foundation for transparent\nand reliable decision-making in embodied reinforcement learning agents.",
    "published": "2023-09-26T22:14:56Z",
    "pdf_url": "http://arxiv.org/pdf/2309.15293v5",
    "categories": [
      "cs.LG",
      "cond-mat.stat-mech",
      "cs.AI",
      "cs.RO"
    ]
  },
  {
    "arxiv_id": "2003.10903v2",
    "title": "Distributional Reinforcement Learning with Ensembles",
    "authors": [
      "Björn Lindenberg",
      "Jonas Nordqvist",
      "Karl-Olof Lindahl"
    ],
    "abstract": "It is well known that ensemble methods often provide enhanced performance in\nreinforcement learning. In this paper, we explore this concept further by using\ngroup-aided training within the distributional reinforcement learning paradigm.\nSpecifically, we propose an extension to categorical reinforcement learning,\nwhere distributional learning targets are implicitly based on the total\ninformation gathered by an ensemble. We empirically show that this may lead to\nmuch more robust initial learning, a stronger individual performance level, and\ngood efficiency on a per-sample basis.",
    "published": "2020-03-24T14:59:54Z",
    "pdf_url": "http://arxiv.org/pdf/2003.10903v2",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA",
      "stat.ML",
      "I.2.11; I.2.8"
    ]
  },
  {
    "arxiv_id": "2307.01452v2",
    "title": "Causal Reinforcement Learning: A Survey",
    "authors": [
      "Zhihong Deng",
      "Jing Jiang",
      "Guodong Long",
      "Chengqi Zhang"
    ],
    "abstract": "Reinforcement learning is an essential paradigm for solving sequential\ndecision problems under uncertainty. Despite many remarkable achievements in\nrecent decades, applying reinforcement learning methods in the real world\nremains challenging. One of the main obstacles is that reinforcement learning\nagents lack a fundamental understanding of the world and must therefore learn\nfrom scratch through numerous trial-and-error interactions. They may also face\nchallenges in providing explanations for their decisions and generalizing the\nacquired knowledge. Causality, however, offers a notable advantage as it can\nformalize knowledge in a systematic manner and leverage invariance for\neffective knowledge transfer. This has led to the emergence of causal\nreinforcement learning, a subfield of reinforcement learning that seeks to\nenhance existing algorithms by incorporating causal relationships into the\nlearning process. In this survey, we comprehensively review the literature on\ncausal reinforcement learning. We first introduce the basic concepts of\ncausality and reinforcement learning, and then explain how causality can\naddress core challenges in non-causal reinforcement learning. We categorize and\nsystematically review existing causal reinforcement learning approaches based\non their target problems and methodologies. Finally, we outline open issues and\nfuture directions in this emerging field.",
    "published": "2023-07-04T03:00:43Z",
    "pdf_url": "http://arxiv.org/pdf/2307.01452v2",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1903.02710v1",
    "title": "Concurrent Meta Reinforcement Learning",
    "authors": [
      "Emilio Parisotto",
      "Soham Ghosh",
      "Sai Bhargav Yalamanchi",
      "Varsha Chinnaobireddy",
      "Yuhuai Wu",
      "Ruslan Salakhutdinov"
    ],
    "abstract": "State-of-the-art meta reinforcement learning algorithms typically assume the\nsetting of a single agent interacting with its environment in a sequential\nmanner. A negative side-effect of this sequential execution paradigm is that,\nas the environment becomes more and more challenging, and thus requiring more\ninteraction episodes for the meta-learner, it needs the agent to reason over\nlonger and longer time-scales. To combat the difficulty of long time-scale\ncredit assignment, we propose an alternative parallel framework, which we name\n\"Concurrent Meta-Reinforcement Learning\" (CMRL), that transforms the temporal\ncredit assignment problem into a multi-agent reinforcement learning one. In\nthis multi-agent setting, a set of parallel agents are executed in the same\nenvironment and each of these \"rollout\" agents are given the means to\ncommunicate with each other. The goal of the communication is to coordinate, in\na collaborative manner, the most efficient exploration of the shared task the\nagents are currently assigned. This coordination therefore represents the\nmeta-learning aspect of the framework, as each agent can be assigned or assign\nitself a particular section of the current task's state space. This framework\nis in contrast to standard RL methods that assume that each parallel rollout\noccurs independently, which can potentially waste computation if many of the\nrollouts end up sampling the same part of the state space. Furthermore, the\nparallel setting enables us to define several reward sharing functions and\nauxiliary losses that are non-trivial to apply in the sequential setting. We\ndemonstrate the effectiveness of our proposed CMRL at improving over sequential\nmethods in a variety of challenging tasks.",
    "published": "2019-03-07T03:28:41Z",
    "pdf_url": "http://arxiv.org/pdf/1903.02710v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1611.03071v4",
    "title": "Fairness in Reinforcement Learning",
    "authors": [
      "Shahin Jabbari",
      "Matthew Joseph",
      "Michael Kearns",
      "Jamie Morgenstern",
      "Aaron Roth"
    ],
    "abstract": "We initiate the study of fairness in reinforcement learning, where the\nactions of a learning algorithm may affect its environment and future rewards.\nOur fairness constraint requires that an algorithm never prefers one action\nover another if the long-term (discounted) reward of choosing the latter action\nis higher. Our first result is negative: despite the fact that fairness is\nconsistent with the optimal policy, any learning algorithm satisfying fairness\nmust take time exponential in the number of states to achieve non-trivial\napproximation to the optimal policy. We then provide a provably fair polynomial\ntime algorithm under an approximate notion of fairness, thus establishing an\nexponential gap between exact and approximate fairness",
    "published": "2016-11-09T20:19:45Z",
    "pdf_url": "http://arxiv.org/pdf/1611.03071v4",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1705.05427v3",
    "title": "Repeated Inverse Reinforcement Learning",
    "authors": [
      "Kareem Amin",
      "Nan Jiang",
      "Satinder Singh"
    ],
    "abstract": "We introduce a novel repeated Inverse Reinforcement Learning problem: the\nagent has to act on behalf of a human in a sequence of tasks and wishes to\nminimize the number of tasks that it surprises the human by acting suboptimally\nwith respect to how the human would have acted. Each time the human is\nsurprised, the agent is provided a demonstration of the desired behavior by the\nhuman. We formalize this problem, including how the sequence of tasks is\nchosen, in a few different ways and provide some foundational results.",
    "published": "2017-05-15T20:06:35Z",
    "pdf_url": "http://arxiv.org/pdf/1705.05427v3",
    "categories": [
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1809.01560v2",
    "title": "Reinforcement Learning under Threats",
    "authors": [
      "Victor Gallego",
      "Roi Naveiro",
      "David Rios Insua"
    ],
    "abstract": "In several reinforcement learning (RL) scenarios, mainly in security\nsettings, there may be adversaries trying to interfere with the reward\ngenerating process. In this paper, we introduce Threatened Markov Decision\nProcesses (TMDPs), which provide a framework to support a decision maker\nagainst a potential adversary in RL. Furthermore, we propose a level-$k$\nthinking scheme resulting in a new learning framework to deal with TMDPs. After\nintroducing our framework and deriving theoretical results, relevant empirical\nevidence is given via extensive experiments, showing the benefits of accounting\nfor adversaries while the agent learns.",
    "published": "2018-09-05T14:56:09Z",
    "pdf_url": "http://arxiv.org/pdf/1809.01560v2",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1912.06085v1",
    "title": "Control-Tutored Reinforcement Learning",
    "authors": [
      "Francesco De Lellis",
      "Fabrizia Auletta",
      "Giovanni Russo",
      "Piero De Lellis",
      "Mario di Bernardo"
    ],
    "abstract": "We introduce a control-tutored reinforcement learning (CTRL) algorithm. The\nidea is to enhance tabular learning algorithms so as to improve the exploration\nof the state-space, and substantially reduce learning times by leveraging some\nlimited knowledge of the plant encoded into a tutoring model-based control\nstrategy. We illustrate the benefits of our novel approach and its\neffectiveness by using the problem of controlling one or more agents to herd\nand contain within a goal region a set of target free-roving agents in the\nplane.",
    "published": "2019-12-12T17:14:15Z",
    "pdf_url": "http://arxiv.org/pdf/1912.06085v1",
    "categories": [
      "math.OC",
      "cs.LG",
      "cs.MA",
      "cs.SY",
      "eess.SY",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2001.05411v3",
    "title": "Lipschitz Lifelong Reinforcement Learning",
    "authors": [
      "Erwan Lecarpentier",
      "David Abel",
      "Kavosh Asadi",
      "Yuu Jinnai",
      "Emmanuel Rachelson",
      "Michael L. Littman"
    ],
    "abstract": "We consider the problem of knowledge transfer when an agent is facing a\nseries of Reinforcement Learning (RL) tasks. We introduce a novel metric\nbetween Markov Decision Processes (MDPs) and establish that close MDPs have\nclose optimal value functions. Formally, the optimal value functions are\nLipschitz continuous with respect to the tasks space. These theoretical results\nlead us to a value-transfer method for Lifelong RL, which we use to build a\nPAC-MDP algorithm with improved convergence rate. Further, we show the method\nto experience no negative transfer with high probability. We illustrate the\nbenefits of the method in Lifelong RL experiments.",
    "published": "2020-01-15T16:29:30Z",
    "pdf_url": "http://arxiv.org/pdf/2001.05411v3",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1907.10323v1",
    "title": "Fairness in Reinforcement Learning",
    "authors": [
      "Paul Weng"
    ],
    "abstract": "Decision support systems (e.g., for ecological conservation) and autonomous\nsystems (e.g., adaptive controllers in smart cities) start to be deployed in\nreal applications. Although their operations often impact many users or\nstakeholders, no fairness consideration is generally taken into account in\ntheir design, which could lead to completely unfair outcomes for some users or\nstakeholders. To tackle this issue, we advocate for the use of social welfare\nfunctions that encode fairness and present this general novel problem in the\ncontext of (deep) reinforcement learning, although it could possibly be\nextended to other machine learning tasks.",
    "published": "2019-07-24T09:27:11Z",
    "pdf_url": "http://arxiv.org/pdf/1907.10323v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1910.08285v1",
    "title": "Multi-View Reinforcement Learning",
    "authors": [
      "Minne Li",
      "Lisheng Wu",
      "Haitham Bou Ammar",
      "Jun Wang"
    ],
    "abstract": "This paper is concerned with multi-view reinforcement learning (MVRL), which\nallows for decision making when agents share common dynamics but adhere to\ndifferent observation models. We define the MVRL framework by extending\npartially observable Markov decision processes (POMDPs) to support more than\none observation model and propose two solution methods through observation\naugmentation and cross-view policy transfer. We empirically evaluate our method\nand demonstrate its effectiveness in a variety of environments. Specifically,\nwe show reductions in sample complexities and computational time for acquiring\npolicies that handle multi-view environments.",
    "published": "2019-10-18T07:14:46Z",
    "pdf_url": "http://arxiv.org/pdf/1910.08285v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1910.09322v2",
    "title": "Momentum in Reinforcement Learning",
    "authors": [
      "Nino Vieillard",
      "Bruno Scherrer",
      "Olivier Pietquin",
      "Matthieu Geist"
    ],
    "abstract": "We adapt the optimization's concept of momentum to reinforcement learning.\nSeeing the state-action value functions as an analog to the gradients in\noptimization, we interpret momentum as an average of consecutive $q$-functions.\nWe derive Momentum Value Iteration (MoVI), a variation of Value Iteration that\nincorporates this momentum idea. Our analysis shows that this allows MoVI to\naverage errors over successive iterations. We show that the proposed approach\ncan be readily extended to deep learning. Specifically, we propose a simple\nimprovement on DQN based on MoVI, and experiment it on Atari games.",
    "published": "2019-10-21T12:51:38Z",
    "pdf_url": "http://arxiv.org/pdf/1910.09322v2",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2102.07097v1",
    "title": "Domain Adversarial Reinforcement Learning",
    "authors": [
      "Bonnie Li",
      "Vincent François-Lavet",
      "Thang Doan",
      "Joelle Pineau"
    ],
    "abstract": "We consider the problem of generalization in reinforcement learning where\nvisual aspects of the observations might differ, e.g. when there are different\nbackgrounds or change in contrast, brightness, etc. We assume that our agent\nhas access to only a few of the MDPs from the MDP distribution during training.\nThe performance of the agent is then reported on new unknown test domains drawn\nfrom the distribution (e.g. unseen backgrounds). For this \"zero-shot RL\" task,\nwe enforce invariance of the learned representations to visual domains via a\ndomain adversarial optimization process. We empirically show that this approach\nallows achieving a significant generalization improvement to new unseen\ndomains.",
    "published": "2021-02-14T07:58:41Z",
    "pdf_url": "http://arxiv.org/pdf/2102.07097v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2102.13446v1",
    "title": "Safe Distributional Reinforcement Learning",
    "authors": [
      "Jianyi Zhang",
      "Paul Weng"
    ],
    "abstract": "Safety in reinforcement learning (RL) is a key property in both training and\nexecution in many domains such as autonomous driving or finance. In this paper,\nwe formalize it with a constrained RL formulation in the distributional RL\nsetting. Our general model accepts various definitions of safety(e.g., bounds\non expected performance, CVaR, variance, or probability of reaching bad\nstates). To ensure safety during learning, we extend a safe policy optimization\nmethod to solve our problem. The distributional RL perspective leads to a more\nefficient algorithm while additionally catering for natural safe constraints.\nWe empirically validate our propositions on artificial and real domains against\nappropriate state-of-the-art safe RL algorithms.",
    "published": "2021-02-26T13:03:27Z",
    "pdf_url": "http://arxiv.org/pdf/2102.13446v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2302.10831v1",
    "title": "Minimax-Bayes Reinforcement Learning",
    "authors": [
      "Thomas Kleine Buening",
      "Christos Dimitrakakis",
      "Hannes Eriksson",
      "Divya Grover",
      "Emilio Jorge"
    ],
    "abstract": "While the Bayesian decision-theoretic framework offers an elegant solution to\nthe problem of decision making under uncertainty, one question is how to\nappropriately select the prior distribution. One idea is to employ a worst-case\nprior. However, this is not as easy to specify in sequential decision making as\nin simple statistical estimation problems. This paper studies (sometimes\napproximate) minimax-Bayes solutions for various reinforcement learning\nproblems to gain insights into the properties of the corresponding priors and\npolicies. We find that while the worst-case prior depends on the setting, the\ncorresponding minimax policies are more robust than those that assume a\nstandard (i.e. uniform) prior.",
    "published": "2023-02-21T17:10:21Z",
    "pdf_url": "http://arxiv.org/pdf/2302.10831v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2406.13127v2",
    "title": "Oralytics Reinforcement Learning Algorithm",
    "authors": [
      "Anna L. Trella",
      "Kelly W. Zhang",
      "Stephanie M. Carpenter",
      "David Elashoff",
      "Zara M. Greer",
      "Inbal Nahum-Shani",
      "Dennis Ruenger",
      "Vivek Shetty",
      "Susan A. Murphy"
    ],
    "abstract": "Dental disease is still one of the most common chronic diseases in the United\nStates. While dental disease is preventable through healthy oral self-care\nbehaviors (OSCB), this basic behavior is not consistently practiced. We have\ndeveloped Oralytics, an online, reinforcement learning (RL) algorithm that\noptimizes the delivery of personalized intervention prompts to improve OSCB. In\nthis paper, we offer a full overview of algorithm design decisions made using\nprior data, domain expertise, and experiments in a simulation test bed. The\nfinalized RL algorithm was deployed in the Oralytics clinical trial, conducted\nfrom fall 2023 to summer 2024.",
    "published": "2024-06-19T00:44:11Z",
    "pdf_url": "http://arxiv.org/pdf/2406.13127v2",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2412.02931v1",
    "title": "Inverse Delayed Reinforcement Learning",
    "authors": [
      "Simon Sinong Zhan",
      "Qingyuan Wu",
      "Zhian Ruan",
      "Frank Yang",
      "Philip Wang",
      "Yixuan Wang",
      "Ruochen Jiao",
      "Chao Huang",
      "Qi Zhu"
    ],
    "abstract": "Inverse Reinforcement Learning (IRL) has demonstrated effectiveness in a\nvariety of imitation tasks. In this paper, we introduce an IRL framework\ndesigned to extract rewarding features from expert trajectories affected by\ndelayed disturbances. Instead of relying on direct observations, our approach\nemploys an efficient off-policy adversarial training framework to derive expert\nfeatures and recover optimal policies from augmented delayed observations.\nEmpirical evaluations in the MuJoCo environment under diverse delay settings\nvalidate the effectiveness of our method. Furthermore, we provide a theoretical\nanalysis showing that recovering expert policies from augmented delayed\nobservations outperforms using direct delayed observations.",
    "published": "2024-12-04T00:53:55Z",
    "pdf_url": "http://arxiv.org/pdf/2412.02931v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ]
  },
  {
    "arxiv_id": "1606.02396v1",
    "title": "Deep Successor Reinforcement Learning",
    "authors": [
      "Tejas D. Kulkarni",
      "Ardavan Saeedi",
      "Simanta Gautam",
      "Samuel J. Gershman"
    ],
    "abstract": "Learning robust value functions given raw observations and rewards is now\npossible with model-free and model-based deep reinforcement learning\nalgorithms. There is a third alternative, called Successor Representations\n(SR), which decomposes the value function into two components -- a reward\npredictor and a successor map. The successor map represents the expected future\nstate occupancy from any given state and the reward predictor maps states to\nscalar rewards. The value function of a state can be computed as the inner\nproduct between the successor map and the reward weights. In this paper, we\npresent DSR, which generalizes SR within an end-to-end deep reinforcement\nlearning framework. DSR has several appealing properties including: increased\nsensitivity to distal reward changes due to factorization of reward and world\ndynamics, and the ability to extract bottleneck states (subgoals) given\nsuccessor maps trained under a random policy. We show the efficacy of our\napproach on two diverse environments given raw pixel observations -- simple\ngrid-world domains (MazeBase) and the Doom game engine.",
    "published": "2016-06-08T04:48:49Z",
    "pdf_url": "http://arxiv.org/pdf/1606.02396v1",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "1611.05763v3",
    "title": "Learning to reinforcement learn",
    "authors": [
      "Jane X Wang",
      "Zeb Kurth-Nelson",
      "Dhruva Tirumala",
      "Hubert Soyer",
      "Joel Z Leibo",
      "Remi Munos",
      "Charles Blundell",
      "Dharshan Kumaran",
      "Matt Botvinick"
    ],
    "abstract": "In recent years deep reinforcement learning (RL) systems have attained\nsuperhuman performance in a number of challenging task domains. However, a\nmajor limitation of such applications is their demand for massive amounts of\ntraining data. A critical present objective is thus to develop deep RL methods\nthat can adapt rapidly to new tasks. In the present work we introduce a novel\napproach to this challenge, which we refer to as deep meta-reinforcement\nlearning. Previous work has shown that recurrent networks can support\nmeta-learning in a fully supervised context. We extend this approach to the RL\nsetting. What emerges is a system that is trained using one RL algorithm, but\nwhose recurrent dynamics implement a second, quite separate RL procedure. This\nsecond, learned RL algorithm can differ from the original one in arbitrary\nways. Importantly, because it is learned, it is configured to exploit structure\nin the training domain. We unpack these points in a series of seven\nproof-of-concept experiments, each of which examines a key aspect of deep\nmeta-RL. We consider prospects for extending and scaling up the approach, and\nalso point out some potentially important implications for neuroscience.",
    "published": "2016-11-17T16:29:11Z",
    "pdf_url": "http://arxiv.org/pdf/1611.05763v3",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1702.05796v1",
    "title": "Collaborative Deep Reinforcement Learning",
    "authors": [
      "Kaixiang Lin",
      "Shu Wang",
      "Jiayu Zhou"
    ],
    "abstract": "Besides independent learning, human learning process is highly improved by\nsummarizing what has been learned, communicating it with peers, and\nsubsequently fusing knowledge from different sources to assist the current\nlearning goal. This collaborative learning procedure ensures that the knowledge\nis shared, continuously refined, and concluded from different perspectives to\nconstruct a more profound understanding. The idea of knowledge transfer has led\nto many advances in machine learning and data mining, but significant\nchallenges remain, especially when it comes to reinforcement learning,\nheterogeneous model structures, and different learning tasks. Motivated by\nhuman collaborative learning, in this paper we propose a collaborative deep\nreinforcement learning (CDRL) framework that performs adaptive knowledge\ntransfer among heterogeneous learning agents. Specifically, the proposed CDRL\nconducts a novel deep knowledge distillation method to address the\nheterogeneity among different learning tasks with a deep alignment network.\nFurthermore, we present an efficient collaborative Asynchronous Advantage\nActor-Critic (cA3C) algorithm to incorporate deep knowledge distillation into\nthe online training of agents, and demonstrate the effectiveness of the CDRL\nframework using extensive empirical evaluation on OpenAI gym.",
    "published": "2017-02-19T21:13:45Z",
    "pdf_url": "http://arxiv.org/pdf/1702.05796v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1703.02702v1",
    "title": "Robust Adversarial Reinforcement Learning",
    "authors": [
      "Lerrel Pinto",
      "James Davidson",
      "Rahul Sukthankar",
      "Abhinav Gupta"
    ],
    "abstract": "Deep neural networks coupled with fast simulation and improved computation\nhave led to recent successes in the field of reinforcement learning (RL).\nHowever, most current RL-based approaches fail to generalize since: (a) the gap\nbetween simulation and real world is so large that policy-learning approaches\nfail to transfer; (b) even if policy learning is done in real world, the data\nscarcity leads to failed generalization from training to test scenarios (e.g.,\ndue to different friction or object masses). Inspired from H-infinity control\nmethods, we note that both modeling errors and differences in training and test\nscenarios can be viewed as extra forces/disturbances in the system. This paper\nproposes the idea of robust adversarial reinforcement learning (RARL), where we\ntrain an agent to operate in the presence of a destabilizing adversary that\napplies disturbance forces to the system. The jointly trained adversary is\nreinforced -- that is, it learns an optimal destabilization policy. We\nformulate the policy learning as a zero-sum, minimax objective function.\nExtensive experiments in multiple environments (InvertedPendulum, HalfCheetah,\nSwimmer, Hopper and Walker2d) conclusively demonstrate that our method (a)\nimproves training stability; (b) is robust to differences in training/test\nconditions; and c) outperform the baseline even in the absence of the\nadversary.",
    "published": "2017-03-08T04:58:51Z",
    "pdf_url": "http://arxiv.org/pdf/1703.02702v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA",
      "cs.RO"
    ]
  },
  {
    "arxiv_id": "1803.10227v1",
    "title": "Forward-Backward Reinforcement Learning",
    "authors": [
      "Ashley D. Edwards",
      "Laura Downs",
      "James C. Davidson"
    ],
    "abstract": "Goals for reinforcement learning problems are typically defined through\nhand-specified rewards. To design such problems, developers of learning\nalgorithms must inherently be aware of what the task goals are, yet we often\nrequire agents to discover them on their own without any supervision beyond\nthese sparse rewards. While much of the power of reinforcement learning derives\nfrom the concept that agents can learn with little guidance, this requirement\ngreatly burdens the training process. If we relax this one restriction and\nendow the agent with knowledge of the reward function, and in particular of the\ngoal, we can leverage backwards induction to accelerate training. To achieve\nthis, we propose training a model to learn to take imagined reversal steps from\nknown goal states. Rather than training an agent exclusively to determine how\nto reach a goal while moving forwards in time, our approach travels backwards\nto jointly predict how we got there. We evaluate our work in Gridworld and\nTowers of Hanoi and empirically demonstrate that it yields better performance\nthan standard DDQN.",
    "published": "2018-03-27T04:33:08Z",
    "pdf_url": "http://arxiv.org/pdf/1803.10227v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1805.09801v1",
    "title": "Meta-Gradient Reinforcement Learning",
    "authors": [
      "Zhongwen Xu",
      "Hado van Hasselt",
      "David Silver"
    ],
    "abstract": "The goal of reinforcement learning algorithms is to estimate and/or optimise\nthe value function. However, unlike supervised learning, no teacher or oracle\nis available to provide the true value function. Instead, the majority of\nreinforcement learning algorithms estimate and/or optimise a proxy for the\nvalue function. This proxy is typically based on a sampled and bootstrapped\napproximation to the true value function, known as a return. The particular\nchoice of return is one of the chief components determining the nature of the\nalgorithm: the rate at which future rewards are discounted; when and how values\nshould be bootstrapped; or even the nature of the rewards themselves. It is\nwell-known that these decisions are crucial to the overall success of RL\nalgorithms. We discuss a gradient-based meta-learning algorithm that is able to\nadapt the nature of the return, online, whilst interacting and learning from\nthe environment. When applied to 57 games on the Atari 2600 environment over\n200 million frames, our algorithm achieved a new state-of-the-art performance.",
    "published": "2018-05-24T17:45:11Z",
    "pdf_url": "http://arxiv.org/pdf/1805.09801v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1905.00976v2",
    "title": "Collaborative Evolutionary Reinforcement Learning",
    "authors": [
      "Shauharda Khadka",
      "Somdeb Majumdar",
      "Tarek Nassar",
      "Zach Dwiel",
      "Evren Tumer",
      "Santiago Miret",
      "Yinyin Liu",
      "Kagan Tumer"
    ],
    "abstract": "Deep reinforcement learning algorithms have been successfully applied to a\nrange of challenging control tasks. However, these methods typically struggle\nwith achieving effective exploration and are extremely sensitive to the choice\nof hyperparameters. One reason is that most approaches use a noisy version of\ntheir operating policy to explore - thereby limiting the range of exploration.\nIn this paper, we introduce Collaborative Evolutionary Reinforcement Learning\n(CERL), a scalable framework that comprises a portfolio of policies that\nsimultaneously explore and exploit diverse regions of the solution space. A\ncollection of learners - typically proven algorithms like TD3 - optimize over\nvarying time-horizons leading to this diverse portfolio. All learners\ncontribute to and use a shared replay buffer to achieve greater sample\nefficiency. Computational resources are dynamically distributed to favor the\nbest learners as a form of online algorithm selection. Neuroevolution binds\nthis entire process to generate a single emergent learner that exceeds the\ncapabilities of any individual learner. Experiments in a range of continuous\ncontrol benchmarks demonstrate that the emergent learner significantly\noutperforms its composite learners while remaining overall more\nsample-efficient - notably solving the Mujoco Humanoid benchmark where all of\nits composite learners (TD3) fail entirely in isolation.",
    "published": "2019-05-02T21:45:03Z",
    "pdf_url": "http://arxiv.org/pdf/1905.00976v2",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2005.12108v1",
    "title": "Gradient Monitored Reinforcement Learning",
    "authors": [
      "Mohammed Sharafath Abdul Hameed",
      "Gavneet Singh Chadha",
      "Andreas Schwung",
      "Steven X. Ding"
    ],
    "abstract": "This paper presents a novel neural network training approach for faster\nconvergence and better generalization abilities in deep reinforcement learning.\nParticularly, we focus on the enhancement of training and evaluation\nperformance in reinforcement learning algorithms by systematically reducing\ngradient's variance and thereby providing a more targeted learning process. The\nproposed method which we term as Gradient Monitoring(GM), is an approach to\nsteer the learning in the weight parameters of a neural network based on the\ndynamic development and feedback from the training process itself. We propose\ndifferent variants of the GM methodology which have been proven to increase the\nunderlying performance of the model. The one of the proposed variant, Momentum\nwith Gradient Monitoring (M-WGM), allows for a continuous adjustment of the\nquantum of back-propagated gradients in the network based on certain learning\nparameters. We further enhance the method with Adaptive Momentum with Gradient\nMonitoring (AM-WGM) method which allows for automatic adjustment between\nfocused learning of certain weights versus a more dispersed learning depending\non the feedback from the rewards collected. As a by-product, it also allows for\nautomatic derivation of the required deep network sizes during training as the\nalgorithm automatically freezes trained weights. The approach is applied to two\ndiscrete (Multi-Robot Co-ordination problem and Atari games) and one continuous\ncontrol task (MuJoCo) using Advantage Actor-Critic (A2C) and Proximal Policy\nOptimization (PPO) respectively. The results obtained particularly underline\nthe applicability and performance improvements of the methods in terms of\ngeneralization capability.",
    "published": "2020-05-25T13:45:47Z",
    "pdf_url": "http://arxiv.org/pdf/2005.12108v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1911.08363v3",
    "title": "Attention-Privileged Reinforcement Learning",
    "authors": [
      "Sasha Salter",
      "Dushyant Rao",
      "Markus Wulfmeier",
      "Raia Hadsell",
      "Ingmar Posner"
    ],
    "abstract": "Image-based Reinforcement Learning is known to suffer from poor sample\nefficiency and generalisation to unseen visuals such as distractors\n(task-independent aspects of the observation space). Visual domain\nrandomisation encourages transfer by training over visual factors of variation\nthat may be encountered in the target domain. This increases learning\ncomplexity, can negatively impact learning rate and performance, and requires\nknowledge of potential variations during deployment. In this paper, we\nintroduce Attention-Privileged Reinforcement Learning (APRiL) which uses a\nself-supervised attention mechanism to significantly alleviate these drawbacks:\nby focusing on task-relevant aspects of the observations, attention provides\nrobustness to distractors as well as significantly increased learning\nefficiency. APRiL trains two attention-augmented actor-critic agents: one\npurely based on image observations, available across training and transfer\ndomains; and one with access to privileged information (such as environment\nstates) available only during training. Experience is shared between both\nagents and their attention mechanisms are aligned. The image-based policy can\nthen be deployed without access to privileged information. We experimentally\ndemonstrate accelerated and more robust learning on a diverse set of domains,\nleading to improved final performance for environments both within and outside\nthe training distribution.",
    "published": "2019-11-19T15:49:29Z",
    "pdf_url": "http://arxiv.org/pdf/1911.08363v3",
    "categories": [
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "0810.3828v1",
    "title": "Quantum reinforcement learning",
    "authors": [
      "Daoyi Dong",
      "Chunlin Chen",
      "Hanxiong Li",
      "Tzyh-Jong Tarn"
    ],
    "abstract": "The key approaches for machine learning, especially learning in unknown\nprobabilistic environments are new representations and computation mechanisms.\nIn this paper, a novel quantum reinforcement learning (QRL) method is proposed\nby combining quantum theory and reinforcement learning (RL). Inspired by the\nstate superposition principle and quantum parallelism, a framework of value\nupdating algorithm is introduced. The state (action) in traditional RL is\nidentified as the eigen state (eigen action) in QRL. The state (action) set can\nbe represented with a quantum superposition state and the eigen state (eigen\naction) can be obtained by randomly observing the simulated quantum state\naccording to the collapse postulate of quantum measurement. The probability of\nthe eigen action is determined by the probability amplitude, which is\nparallelly updated according to rewards. Some related characteristics of QRL\nsuch as convergence, optimality and balancing between exploration and\nexploitation are also analyzed, which shows that this approach makes a good\ntradeoff between exploration and exploitation using the probability amplitude\nand can speed up learning through the quantum parallelism. To evaluate the\nperformance and practicability of QRL, several simulated experiments are given\nand the results demonstrate the effectiveness and superiority of QRL algorithm\nfor some complex problems. The present work is also an effective exploration on\nthe application of quantum computation to artificial intelligence.",
    "published": "2008-10-21T13:38:33Z",
    "pdf_url": "http://arxiv.org/pdf/0810.3828v1",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2302.08854v4",
    "title": "Post Reinforcement Learning Inference",
    "authors": [
      "Vasilis Syrgkanis",
      "Ruohan Zhan"
    ],
    "abstract": "We consider estimation and inference using data collected from reinforcement\nlearning algorithms. These algorithms, characterized by their adaptive\nexperimentation, interact with individual units over multiple stages,\ndynamically adjusting their strategies based on previous interactions. Our goal\nis to evaluate a counterfactual policy post-data collection and estimate\nstructural parameters, like dynamic treatment effects, which can be used for\ncredit assignment and determining the effect of earlier actions on final\noutcomes. Such parameters of interest can be framed as solutions to moment\nequations, but not minimizers of a population loss function, leading to\nZ-estimation approaches for static data. However, in the adaptive data\ncollection environment of reinforcement learning, where algorithms deploy\nnonstationary behavior policies, standard estimators do not achieve asymptotic\nnormality due to the fluctuating variance. We propose a weighted Z-estimation\napproach with carefully designed adaptive weights to stabilize the time-varying\nestimation variance. We identify proper weighting schemes to restore the\nconsistency and asymptotic normality of the weighted Z-estimators for target\nparameters, which allows for hypothesis testing and constructing uniform\nconfidence regions. Primary applications include dynamic treatment effect\nestimation and dynamic off-policy evaluation.",
    "published": "2023-02-17T12:53:15Z",
    "pdf_url": "http://arxiv.org/pdf/2302.08854v4",
    "categories": [
      "stat.ML",
      "cs.LG",
      "econ.EM"
    ]
  },
  {
    "arxiv_id": "2304.05099v6",
    "title": "Feudal Graph Reinforcement Learning",
    "authors": [
      "Tommaso Marzi",
      "Arshjot Khehra",
      "Andrea Cini",
      "Cesare Alippi"
    ],
    "abstract": "Graph-based representations and message-passing modular policies constitute\nprominent approaches to tackling composable control problems in reinforcement\nlearning (RL). However, as shown by recent graph deep learning literature, such\nlocal message-passing operators can create information bottlenecks and hinder\nglobal coordination. The issue becomes more serious in tasks requiring\nhigh-level planning. In this work, we propose a novel methodology, named Feudal\nGraph Reinforcement Learning (FGRL), that addresses such challenges by relying\non hierarchical RL and a pyramidal message-passing architecture. In particular,\nFGRL defines a hierarchy of policies where high-level commands are propagated\nfrom the top of the hierarchy down through a layered graph structure. The\nbottom layers mimic the morphology of the physical system, while the upper\nlayers correspond to higher-order sub-modules. The resulting agents are then\ncharacterized by a committee of policies where actions at a certain level set\ngoals for the level below, thus implementing a hierarchical decision-making\nstructure that can naturally implement task decomposition. We evaluate the\nproposed framework on a graph clustering problem and MuJoCo locomotion tasks;\nsimulation results show that FGRL compares favorably against relevant\nbaselines. Furthermore, an in-depth analysis of the command propagation\nmechanism provides evidence that the introduced message-passing scheme favors\nlearning hierarchical decision-making policies.",
    "published": "2023-04-11T09:51:13Z",
    "pdf_url": "http://arxiv.org/pdf/2304.05099v6",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2304.09870v2",
    "title": "Heterogeneous-Agent Reinforcement Learning",
    "authors": [
      "Yifan Zhong",
      "Jakub Grudzien Kuba",
      "Xidong Feng",
      "Siyi Hu",
      "Jiaming Ji",
      "Yaodong Yang"
    ],
    "abstract": "The necessity for cooperation among intelligent machines has popularised\ncooperative multi-agent reinforcement learning (MARL) in AI research. However,\nmany research endeavours heavily rely on parameter sharing among agents, which\nconfines them to only homogeneous-agent setting and leads to training\ninstability and lack of convergence guarantees. To achieve effective\ncooperation in the general heterogeneous-agent setting, we propose\nHeterogeneous-Agent Reinforcement Learning (HARL) algorithms that resolve the\naforementioned issues. Central to our findings are the multi-agent advantage\ndecomposition lemma and the sequential update scheme. Based on these, we\ndevelop the provably correct Heterogeneous-Agent Trust Region Learning (HATRL),\nand derive HATRPO and HAPPO by tractable approximations. Furthermore, we\ndiscover a novel framework named Heterogeneous-Agent Mirror Learning (HAML),\nwhich strengthens theoretical guarantees for HATRPO and HAPPO and provides a\ngeneral template for cooperative MARL algorithmic designs. We prove that all\nalgorithms derived from HAML inherently enjoy monotonic improvement of joint\nreturn and convergence to Nash Equilibrium. As its natural outcome, HAML\nvalidates more novel algorithms in addition to HATRPO and HAPPO, including\nHAA2C, HADDPG, and HATD3, which generally outperform their existing\nMA-counterparts. We comprehensively test HARL algorithms on six challenging\nbenchmarks and demonstrate their superior effectiveness and stability for\ncoordinating heterogeneous agents compared to strong baselines such as MAPPO\nand QMIX.",
    "published": "2023-04-19T05:08:02Z",
    "pdf_url": "http://arxiv.org/pdf/2304.09870v2",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ]
  },
  {
    "arxiv_id": "2311.02198v6",
    "title": "Imitation Bootstrapped Reinforcement Learning",
    "authors": [
      "Hengyuan Hu",
      "Suvir Mirchandani",
      "Dorsa Sadigh"
    ],
    "abstract": "Despite the considerable potential of reinforcement learning (RL), robotic\ncontrol tasks predominantly rely on imitation learning (IL) due to its better\nsample efficiency. However, it is costly to collect comprehensive expert\ndemonstrations that enable IL to generalize to all possible scenarios, and any\ndistribution shift would require recollecting data for finetuning. Therefore,\nRL is appealing if it can build upon IL as an efficient autonomous\nself-improvement procedure. We propose imitation bootstrapped reinforcement\nlearning (IBRL), a novel framework for sample-efficient RL with demonstrations\nthat first trains an IL policy on the provided demonstrations and then uses it\nto propose alternative actions for both online exploration and bootstrapping\ntarget values. Compared to prior works that oversample the demonstrations or\nregularize RL with an additional imitation loss, IBRL is able to utilize high\nquality actions from IL policies since the beginning of training, which greatly\naccelerates exploration and training efficiency. We evaluate IBRL on 6\nsimulation and 3 real-world tasks spanning various difficulty levels. IBRL\nsignificantly outperforms prior methods and the improvement is particularly\nmore prominent in harder tasks.",
    "published": "2023-11-03T19:03:20Z",
    "pdf_url": "http://arxiv.org/pdf/2311.02198v6",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2402.08848v2",
    "title": "Hybrid Inverse Reinforcement Learning",
    "authors": [
      "Juntao Ren",
      "Gokul Swamy",
      "Zhiwei Steven Wu",
      "J. Andrew Bagnell",
      "Sanjiban Choudhury"
    ],
    "abstract": "The inverse reinforcement learning approach to imitation learning is a\ndouble-edged sword. On the one hand, it can enable learning from a smaller\nnumber of expert demonstrations with more robustness to error compounding than\nbehavioral cloning approaches. On the other hand, it requires that the learner\nrepeatedly solve a computationally expensive reinforcement learning (RL)\nproblem. Often, much of this computation is wasted searching over policies very\ndissimilar to the expert's. In this work, we propose using hybrid RL --\ntraining on a mixture of online and expert data -- to curtail unnecessary\nexploration. Intuitively, the expert data focuses the learner on good states\nduring training, which reduces the amount of exploration required to compute a\nstrong policy. Notably, such an approach doesn't need the ability to reset the\nlearner to arbitrary states in the environment, a requirement of prior work in\nefficient inverse RL. More formally, we derive a reduction from inverse RL to\nexpert-competitive RL (rather than globally optimal RL) that allows us to\ndramatically reduce interaction during the inner policy search loop while\nmaintaining the benefits of the IRL approach. This allows us to derive both\nmodel-free and model-based hybrid inverse RL algorithms with strong policy\nperformance guarantees. Empirically, we find that our approaches are\nsignificantly more sample efficient than standard inverse RL and several other\nbaselines on a suite of continuous control tasks.",
    "published": "2024-02-13T23:29:09Z",
    "pdf_url": "http://arxiv.org/pdf/2402.08848v2",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2403.02290v1",
    "title": "Koopman-Assisted Reinforcement Learning",
    "authors": [
      "Preston Rozwood",
      "Edward Mehrez",
      "Ludger Paehler",
      "Wen Sun",
      "Steven L. Brunton"
    ],
    "abstract": "The Bellman equation and its continuous form, the Hamilton-Jacobi-Bellman\n(HJB) equation, are ubiquitous in reinforcement learning (RL) and control\ntheory. However, these equations quickly become intractable for systems with\nhigh-dimensional states and nonlinearity. This paper explores the connection\nbetween the data-driven Koopman operator and Markov Decision Processes (MDPs),\nresulting in the development of two new RL algorithms to address these\nlimitations. We leverage Koopman operator techniques to lift a nonlinear system\ninto new coordinates where the dynamics become approximately linear, and where\nHJB-based methods are more tractable. In particular, the Koopman operator is\nable to capture the expectation of the time evolution of the value function of\na given system via linear dynamics in the lifted coordinates. By parameterizing\nthe Koopman operator with the control actions, we construct a ``Koopman\ntensor'' that facilitates the estimation of the optimal value function. Then, a\ntransformation of Bellman's framework in terms of the Koopman tensor enables us\nto reformulate two max-entropy RL algorithms: soft value iteration and soft\nactor-critic (SAC). This highly flexible framework can be used for\ndeterministic or stochastic systems as well as for discrete or continuous-time\ndynamics. Finally, we show that these Koopman Assisted Reinforcement Learning\n(KARL) algorithms attain state-of-the-art (SOTA) performance with respect to\ntraditional neural network-based SAC and linear quadratic regulator (LQR)\nbaselines on four controlled dynamical systems: a linear state-space system,\nthe Lorenz system, fluid flow past a cylinder, and a double-well potential with\nnon-isotropic stochastic forcing.",
    "published": "2024-03-04T18:19:48Z",
    "pdf_url": "http://arxiv.org/pdf/2403.02290v1",
    "categories": [
      "cs.AI",
      "cs.LG",
      "math.DS",
      "math.OC"
    ]
  },
  {
    "arxiv_id": "2407.08250v2",
    "title": "Gradient Boosting Reinforcement Learning",
    "authors": [
      "Benjamin Fuhrer",
      "Chen Tessler",
      "Gal Dalal"
    ],
    "abstract": "We present Gradient Boosting Reinforcement Learning (GBRL), a framework that\nadapts the strengths of gradient boosting trees (GBT) to reinforcement learning\n(RL) tasks. While neural networks (NNs) have become the de facto choice for RL,\nthey face significant challenges with structured and categorical features and\ntend to generalize poorly to out-of-distribution samples. These are challenges\nfor which GBTs have traditionally excelled in supervised learning. However,\nGBT's application in RL has been limited. The design of traditional GBT\nlibraries is optimized for static datasets with fixed labels, making them\nincompatible with RL's dynamic nature, where both state distributions and\nreward signals evolve during training. GBRL overcomes this limitation by\ncontinuously interleaving tree construction with environment interaction.\nThrough extensive experiments, we demonstrate that GBRL outperforms NNs in\ndomains with structured observations and categorical features while maintaining\ncompetitive performance on standard continuous control benchmarks. Like its\nsupervised learning counterpart, GBRL demonstrates superior robustness to\nout-of-distribution samples and better handles irregular state-action\nrelationships.",
    "published": "2024-07-11T07:52:33Z",
    "pdf_url": "http://arxiv.org/pdf/2407.08250v2",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2502.04909v2",
    "title": "Benchmarking Quantum Reinforcement Learning",
    "authors": [
      "Georg Kruse",
      "Rodrigo Coelho",
      "Andreas Rosskopf",
      "Robert Wille",
      "Jeanette Miriam Lorenz"
    ],
    "abstract": "Quantum Reinforcement Learning (QRL) has emerged as a promising research\nfield, leveraging the principles of quantum mechanics to enhance the\nperformance of reinforcement learning (RL) algorithms. However, despite its\ngrowing interest, QRL still faces significant challenges. It is still uncertain\nif QRL can show any advantage over classical RL beyond artificial problem\nformulations. Additionally, it is not yet clear which streams of QRL research\nshow the greatest potential. The lack of a unified benchmark and the need to\nevaluate the reliance on quantum principles of QRL approaches are pressing\nquestions. This work aims to address these challenges by providing a\ncomprehensive comparison of three major QRL classes: Parameterized Quantum\nCircuit based QRL (PQC-QRL) (with one policy gradient (QPG) and one Q-Learning\n(QDQN) algorithm), Free Energy based QRL (FE-QRL), and Amplitude Amplification\nbased QRL (AA-QRL). We introduce a set of metrics to evaluate the QRL\nalgorithms on the widely applicable benchmark of gridworld games. Our results\nprovide a detailed analysis of the strengths and weaknesses of the QRL classes,\nshedding light on the role of quantum principles in QRL and paving the way for\nfuture research in this field.",
    "published": "2025-02-07T13:28:20Z",
    "pdf_url": "http://arxiv.org/pdf/2502.04909v2",
    "categories": [
      "quant-ph"
    ]
  },
  {
    "arxiv_id": "2509.19464v1",
    "title": "Evaluation-Aware Reinforcement Learning",
    "authors": [
      "Shripad Vilasrao Deshmukh",
      "Will Schwarzer",
      "Scott Niekum"
    ],
    "abstract": "Policy evaluation is often a prerequisite for deploying safety- and\nperformance-critical systems. Existing evaluation approaches frequently suffer\nfrom high variance due to limited data and long-horizon tasks, or high bias due\nto unequal support or inaccurate environmental models. We posit that these\nchallenges arise, in part, from the standard reinforcement learning (RL)\nparadigm of policy learning without explicit consideration of evaluation. As an\nalternative, we propose evaluation-aware reinforcement learning (EvA-RL), in\nwhich a policy is trained to maximize expected return while simultaneously\nminimizing expected evaluation error under a given value prediction scheme --\nin other words, being \"easy\" to evaluate. We formalize a framework for EvA-RL\nand design an instantiation that enables accurate policy evaluation,\nconditioned on a small number of rollouts in an assessment environment that can\nbe different than the deployment environment. However, our theoretical analysis\nand empirical results show that there is often a tradeoff between evaluation\naccuracy and policy performance when using a fixed value-prediction scheme\nwithin EvA-RL. To mitigate this tradeoff, we extend our approach to co-learn an\nassessment-conditioned state-value predictor alongside the policy. Empirical\nresults across diverse discrete and continuous action domains demonstrate that\nEvA-RL can substantially reduce evaluation error while maintaining competitive\nreturns. This work lays the foundation for a broad new class of RL methods that\ntreat reliable evaluation as a first-class principle during training.",
    "published": "2025-09-23T18:17:21Z",
    "pdf_url": "http://arxiv.org/pdf/2509.19464v1",
    "categories": [
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1805.01907v2",
    "title": "Exploration by Distributional Reinforcement Learning",
    "authors": [
      "Yunhao Tang",
      "Shipra Agrawal"
    ],
    "abstract": "We propose a framework based on distributional reinforcement learning and\nrecent attempts to combine Bayesian parameter updates with deep reinforcement\nlearning. We show that our proposed framework conceptually unifies multiple\nprevious methods in exploration. We also derive a practical algorithm that\nachieves efficient exploration on challenging control tasks.",
    "published": "2018-05-04T18:07:21Z",
    "pdf_url": "http://arxiv.org/pdf/1805.01907v2",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1806.06798v2",
    "title": "Implicit Policy for Reinforcement Learning",
    "authors": [
      "Yunhao Tang",
      "Shipra Agrawal"
    ],
    "abstract": "We introduce Implicit Policy, a general class of expressive policies that can\nflexibly represent complex action distributions in reinforcement learning, with\nefficient algorithms to compute entropy regularized policy gradients. We\nempirically show that, despite its simplicity in implementation, entropy\nregularization combined with a rich policy class can attain desirable\nproperties displayed under maximum entropy reinforcement learning framework,\nsuch as robustness and multi-modality.",
    "published": "2018-06-10T08:24:36Z",
    "pdf_url": "http://arxiv.org/pdf/1806.06798v2",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1906.10025v2",
    "title": "Modern Deep Reinforcement Learning Algorithms",
    "authors": [
      "Sergey Ivanov",
      "Alexander D'yakonov"
    ],
    "abstract": "Recent advances in Reinforcement Learning, grounded on combining classical\ntheoretical results with Deep Learning paradigm, led to breakthroughs in many\nartificial intelligence tasks and gave birth to Deep Reinforcement Learning\n(DRL) as a field of research. In this work latest DRL algorithms are reviewed\nwith a focus on their theoretical justification, practical limitations and\nobserved empirical properties.",
    "published": "2019-06-24T15:27:51Z",
    "pdf_url": "http://arxiv.org/pdf/1906.10025v2",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1710.08070v2",
    "title": "Accelerated Reinforcement Learning",
    "authors": [
      "K. Lakshmanan"
    ],
    "abstract": "Policy gradient methods are widely used in reinforcement learning algorithms\nto search for better policies in the parameterized policy space. They do\ngradient search in the policy space and are known to converge very slowly.\nNesterov developed an accelerated gradient search algorithm for convex\noptimization problems. This has been recently extended for non-convex and also\nstochastic optimization. We use Nesterov's acceleration for policy gradient\nsearch in the well-known actor-critic algorithm and show the convergence using\nODE method. We tested this algorithm on a scheduling problem. Here an incoming\njob is scheduled into one of the four queues based on the queue lengths. We see\nfrom experimental results that algorithm using Nesterov's acceleration has\nsignificantly better performance compared to algorithm which do not use\nacceleration. To the best of our knowledge this is the first time Nesterov's\nacceleration has been used with actor-critic algorithm.",
    "published": "2017-10-23T02:45:31Z",
    "pdf_url": "http://arxiv.org/pdf/1710.08070v2",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1803.03835v1",
    "title": "Kickstarting Deep Reinforcement Learning",
    "authors": [
      "Simon Schmitt",
      "Jonathan J. Hudson",
      "Augustin Zidek",
      "Simon Osindero",
      "Carl Doersch",
      "Wojciech M. Czarnecki",
      "Joel Z. Leibo",
      "Heinrich Kuttler",
      "Andrew Zisserman",
      "Karen Simonyan",
      "S. M. Ali Eslami"
    ],
    "abstract": "We present a method for using previously-trained 'teacher' agents to\nkickstart the training of a new 'student' agent. To this end, we leverage ideas\nfrom policy distillation and population based training. Our method places no\nconstraints on the architecture of the teacher or student agents, and it\nregulates itself to allow the students to surpass their teachers in\nperformance. We show that, on a challenging and computationally-intensive\nmulti-task benchmark (DMLab-30), kickstarted training improves the data\nefficiency of new agents, making it significantly easier to iterate on their\ndesign. We also show that the same kickstarting pipeline can allow a single\nstudent agent to leverage multiple 'expert' teachers which specialize on\nindividual tasks. In this setting kickstarting yields surprisingly large gains,\nwith the kickstarted agent matching the performance of an agent trained from\nscratch in almost 10x fewer steps, and surpassing its final performance by 42\npercent. Kickstarting is conceptually simple and can easily be incorporated\ninto reinforcement learning experiments.",
    "published": "2018-03-10T16:45:00Z",
    "pdf_url": "http://arxiv.org/pdf/1803.03835v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1810.09202v5",
    "title": "Graph Convolutional Reinforcement Learning",
    "authors": [
      "Jiechuan Jiang",
      "Chen Dun",
      "Tiejun Huang",
      "Zongqing Lu"
    ],
    "abstract": "Learning to cooperate is crucially important in multi-agent environments. The\nkey is to understand the mutual interplay between agents. However, multi-agent\nenvironments are highly dynamic, where agents keep moving and their neighbors\nchange quickly. This makes it hard to learn abstract representations of mutual\ninterplay between agents. To tackle these difficulties, we propose graph\nconvolutional reinforcement learning, where graph convolution adapts to the\ndynamics of the underlying graph of the multi-agent environment, and relation\nkernels capture the interplay between agents by their relation representations.\nLatent features produced by convolutional layers from gradually increased\nreceptive fields are exploited to learn cooperation, and cooperation is further\nimproved by temporal relation regularization for consistency. Empirically, we\nshow that our method substantially outperforms existing methods in a variety of\ncooperative scenarios.",
    "published": "2018-10-22T12:17:40Z",
    "pdf_url": "http://arxiv.org/pdf/1810.09202v5",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2004.08600v1",
    "title": "Time Adaptive Reinforcement Learning",
    "authors": [
      "Chris Reinke"
    ],
    "abstract": "Reinforcement learning (RL) allows to solve complex tasks such as Go often\nwith a stronger performance than humans. However, the learned behaviors are\nusually fixed to specific tasks and unable to adapt to different contexts. Here\nwe consider the case of adapting RL agents to different time restrictions, such\nas finishing a task with a given time limit that might change from one task\nexecution to the next. We define such problems as Time Adaptive Markov Decision\nProcesses and introduce two model-free, value-based algorithms: the Independent\nGamma-Ensemble and the n-Step Ensemble. In difference to classical approaches,\nthey allow a zero-shot adaptation between different time restrictions. The\nproposed approaches represent general mechanisms to handle time adaptive tasks\nmaking them compatible with many existing RL methods, algorithms, and\nscenarios.",
    "published": "2020-04-18T11:52:07Z",
    "pdf_url": "http://arxiv.org/pdf/2004.08600v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML",
      "I.2.6"
    ]
  },
  {
    "arxiv_id": "2101.03958v6",
    "title": "Evolving Reinforcement Learning Algorithms",
    "authors": [
      "John D. Co-Reyes",
      "Yingjie Miao",
      "Daiyi Peng",
      "Esteban Real",
      "Sergey Levine",
      "Quoc V. Le",
      "Honglak Lee",
      "Aleksandra Faust"
    ],
    "abstract": "We propose a method for meta-learning reinforcement learning algorithms by\nsearching over the space of computational graphs which compute the loss\nfunction for a value-based model-free RL agent to optimize. The learned\nalgorithms are domain-agnostic and can generalize to new environments not seen\nduring training. Our method can both learn from scratch and bootstrap off known\nexisting algorithms, like DQN, enabling interpretable modifications which\nimprove performance. Learning from scratch on simple classical control and\ngridworld tasks, our method rediscovers the temporal-difference (TD) algorithm.\nBootstrapped from DQN, we highlight two learned algorithms which obtain good\ngeneralization performance over other classical control tasks, gridworld type\ntasks, and Atari games. The analysis of the learned algorithm behavior shows\nresemblance to recently proposed RL algorithms that address overestimation in\nvalue-based methods.",
    "published": "2021-01-08T18:55:07Z",
    "pdf_url": "http://arxiv.org/pdf/2101.03958v6",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "2202.07995v2",
    "title": "Branching Reinforcement Learning",
    "authors": [
      "Yihan Du",
      "Wei Chen"
    ],
    "abstract": "In this paper, we propose a novel Branching Reinforcement Learning (Branching\nRL) model, and investigate both Regret Minimization (RM) and Reward-Free\nExploration (RFE) metrics for this model. Unlike standard RL where the\ntrajectory of each episode is a single $H$-step path, branching RL allows an\nagent to take multiple base actions in a state such that transitions branch out\nto multiple successor states correspondingly, and thus it generates a\ntree-structured trajectory. This model finds important applications in\nhierarchical recommendation systems and online advertising. For branching RL,\nwe establish new Bellman equations and key lemmas, i.e., branching value\ndifference lemma and branching law of total variance, and also bound the total\nvariance by only $O(H^2)$ under an exponentially-large trajectory. For RM and\nRFE metrics, we propose computationally efficient algorithms BranchVI and\nBranchRFE, respectively, and derive nearly matching upper and lower bounds. Our\nresults are only polynomial in problem parameters despite exponentially-large\ntrajectories.",
    "published": "2022-02-16T11:19:03Z",
    "pdf_url": "http://arxiv.org/pdf/2202.07995v2",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2207.00461v1",
    "title": "Lifelong Inverse Reinforcement Learning",
    "authors": [
      "Jorge A. Mendez",
      "Shashank Shivkumar",
      "Eric Eaton"
    ],
    "abstract": "Methods for learning from demonstration (LfD) have shown success in acquiring\nbehavior policies by imitating a user. However, even for a single task, LfD may\nrequire numerous demonstrations. For versatile agents that must learn many\ntasks via demonstration, this process would substantially burden the user if\neach task were learned in isolation. To address this challenge, we introduce\nthe novel problem of lifelong learning from demonstration, which allows the\nagent to continually build upon knowledge learned from previously demonstrated\ntasks to accelerate the learning of new tasks, reducing the amount of\ndemonstrations required. As one solution to this problem, we propose the first\nlifelong learning approach to inverse reinforcement learning, which learns\nconsecutive tasks via demonstration, continually transferring knowledge between\ntasks to improve performance.",
    "published": "2022-07-01T14:36:02Z",
    "pdf_url": "http://arxiv.org/pdf/2207.00461v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2010.03691v2",
    "title": "Regularized Inverse Reinforcement Learning",
    "authors": [
      "Wonseok Jeon",
      "Chen-Yang Su",
      "Paul Barde",
      "Thang Doan",
      "Derek Nowrouzezahrai",
      "Joelle Pineau"
    ],
    "abstract": "Inverse Reinforcement Learning (IRL) aims to facilitate a learner's ability\nto imitate expert behavior by acquiring reward functions that explain the\nexpert's decisions. Regularized IRL applies strongly convex regularizers to the\nlearner's policy in order to avoid the expert's behavior being rationalized by\narbitrary constant rewards, also known as degenerate solutions. We propose\ntractable solutions, and practical methods to obtain them, for regularized IRL.\nCurrent methods are restricted to the maximum-entropy IRL framework, limiting\nthem to Shannon-entropy regularizers, as well as proposing the solutions that\nare intractable in practice. We present theoretical backing for our proposed\nIRL method's applicability for both discrete and continuous controls,\nempirically validating our performance on a variety of tasks.",
    "published": "2020-10-07T23:38:47Z",
    "pdf_url": "http://arxiv.org/pdf/2010.03691v2",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2011.09999v3",
    "title": "Inverse Constrained Reinforcement Learning",
    "authors": [
      "Usman Anwar",
      "Shehryar Malik",
      "Alireza Aghasi",
      "Ali Ahmed"
    ],
    "abstract": "In real world settings, numerous constraints are present which are hard to\nspecify mathematically. However, for the real world deployment of reinforcement\nlearning (RL), it is critical that RL agents are aware of these constraints, so\nthat they can act safely. In this work, we consider the problem of learning\nconstraints from demonstrations of a constraint-abiding agent's behavior. We\nexperimentally validate our approach and show that our framework can\nsuccessfully learn the most likely constraints that the agent respects. We\nfurther show that these learned constraints are \\textit{transferable} to new\nagents that may have different morphologies and/or reward functions. Previous\nworks in this regard have either mainly been restricted to tabular (discrete)\nsettings, specific types of constraints or assume the environment's transition\ndynamics. In contrast, our framework is able to learn arbitrary\n\\textit{Markovian} constraints in high-dimensions in a completely model-free\nsetting. The code can be found it:\n\\url{https://github.com/shehryar-malik/icrl}.",
    "published": "2020-11-19T17:56:33Z",
    "pdf_url": "http://arxiv.org/pdf/2011.09999v3",
    "categories": [
      "cs.LG",
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ]
  },
  {
    "arxiv_id": "2305.15284v4",
    "title": "Replicable Reinforcement Learning",
    "authors": [
      "Eric Eaton",
      "Marcel Hussing",
      "Michael Kearns",
      "Jessica Sorrell"
    ],
    "abstract": "The replicability crisis in the social, behavioral, and data sciences has led\nto the formulation of algorithm frameworks for replicability -- i.e., a\nrequirement that an algorithm produce identical outputs (with high probability)\nwhen run on two different samples from the same underlying distribution. While\nstill in its infancy, provably replicable algorithms have been developed for\nmany fundamental tasks in machine learning and statistics, including\nstatistical query learning, the heavy hitters problem, and distribution\ntesting. In this work we initiate the study of replicable reinforcement\nlearning, providing a provably replicable algorithm for parallel value\niteration, and a provably replicable version of R-max in the episodic setting.\nThese are the first formal replicability results for control problems, which\npresent different challenges for replication than batch learning settings.",
    "published": "2023-05-24T16:05:15Z",
    "pdf_url": "http://arxiv.org/pdf/2305.15284v4",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1806.01830v2",
    "title": "Relational Deep Reinforcement Learning",
    "authors": [
      "Vinicius Zambaldi",
      "David Raposo",
      "Adam Santoro",
      "Victor Bapst",
      "Yujia Li",
      "Igor Babuschkin",
      "Karl Tuyls",
      "David Reichert",
      "Timothy Lillicrap",
      "Edward Lockhart",
      "Murray Shanahan",
      "Victoria Langston",
      "Razvan Pascanu",
      "Matthew Botvinick",
      "Oriol Vinyals",
      "Peter Battaglia"
    ],
    "abstract": "We introduce an approach for deep reinforcement learning (RL) that improves\nupon the efficiency, generalization capacity, and interpretability of\nconventional approaches through structured perception and relational reasoning.\nIt uses self-attention to iteratively reason about the relations between\nentities in a scene and to guide a model-free policy. Our results show that in\na novel navigation and planning task called Box-World, our agent finds\ninterpretable solutions that improve upon baselines in terms of sample\ncomplexity, ability to generalize to more complex scenes than experienced\nduring training, and overall performance. In the StarCraft II Learning\nEnvironment, our agent achieves state-of-the-art performance on six mini-games\n-- surpassing human grandmaster performance on four. By considering\narchitectural inductive biases, our work opens new directions for overcoming\nimportant, but stubborn, challenges in deep RL.",
    "published": "2018-06-05T17:39:12Z",
    "pdf_url": "http://arxiv.org/pdf/1806.01830v2",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1906.02457v1",
    "title": "Clustered Reinforcement Learning",
    "authors": [
      "Xiao Ma",
      "Shen-Yi Zhao",
      "Wu-Jun Li"
    ],
    "abstract": "Exploration strategy design is one of the challenging problems in\nreinforcement learning~(RL), especially when the environment contains a large\nstate space or sparse rewards. During exploration, the agent tries to discover\nnovel areas or high reward~(quality) areas. In most existing methods, the\nnovelty and quality in the neighboring area of the current state are not well\nutilized to guide the exploration of the agent. To tackle this problem, we\npropose a novel RL framework, called \\underline{c}lustered\n\\underline{r}einforcement \\underline{l}earning~(CRL), for efficient exploration\nin RL. CRL adopts clustering to divide the collected states into several\nclusters, based on which a bonus reward reflecting both novelty and quality in\nthe neighboring area~(cluster) of the current state is given to the agent.\nExperiments on a continuous control task and several \\emph{Atari 2600} games\nshow that CRL can outperform other state-of-the-art methods to achieve the best\nperformance in most cases.",
    "published": "2019-06-06T07:35:02Z",
    "pdf_url": "http://arxiv.org/pdf/1906.02457v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2007.14430v3",
    "title": "Munchausen Reinforcement Learning",
    "authors": [
      "Nino Vieillard",
      "Olivier Pietquin",
      "Matthieu Geist"
    ],
    "abstract": "Bootstrapping is a core mechanism in Reinforcement Learning (RL). Most\nalgorithms, based on temporal differences, replace the true value of a\ntransiting state by their current estimate of this value. Yet, another estimate\ncould be leveraged to bootstrap RL: the current policy. Our core contribution\nstands in a very simple idea: adding the scaled log-policy to the immediate\nreward. We show that slightly modifying Deep Q-Network (DQN) in that way\nprovides an agent that is competitive with distributional methods on Atari\ngames, without making use of distributional RL, n-step returns or prioritized\nreplay. To demonstrate the versatility of this idea, we also use it together\nwith an Implicit Quantile Network (IQN). The resulting agent outperforms\nRainbow on Atari, installing a new State of the Art with very little\nmodifications to the original algorithm. To add to this empirical study, we\nprovide strong theoretical insights on what happens under the hood -- implicit\nKullback-Leibler regularization and increase of the action-gap.",
    "published": "2020-07-28T18:30:23Z",
    "pdf_url": "http://arxiv.org/pdf/2007.14430v3",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2112.03636v1",
    "title": "Godot Reinforcement Learning Agents",
    "authors": [
      "Edward Beeching",
      "Jilles Debangoye",
      "Olivier Simonin",
      "Christian Wolf"
    ],
    "abstract": "We present Godot Reinforcement Learning (RL) Agents, an open-source interface\nfor developing environments and agents in the Godot Game Engine. The Godot RL\nAgents interface allows the design, creation and learning of agent behaviors in\nchallenging 2D and 3D environments with various on-policy and off-policy Deep\nRL algorithms. We provide a standard Gym interface, with wrappers for learning\nin the Ray RLlib and Stable Baselines RL frameworks. This allows users access\nto over 20 state of the art on-policy, off-policy and multi-agent RL\nalgorithms. The framework is a versatile tool that allows researchers and game\ndesigners the ability to create environments with discrete, continuous and\nmixed action spaces. The interface is relatively performant, with 12k\ninteractions per second on a high end laptop computer, when parallized on 4 CPU\ncores. An overview video is available here: https://youtu.be/g1MlZSFqIj4",
    "published": "2021-12-07T11:24:34Z",
    "pdf_url": "http://arxiv.org/pdf/2112.03636v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2205.07467v1",
    "title": "$q$-Munchausen Reinforcement Learning",
    "authors": [
      "Lingwei Zhu",
      "Zheng Chen",
      "Eiji Uchibe",
      "Takamitsu Matsubara"
    ],
    "abstract": "The recently successful Munchausen Reinforcement Learning (M-RL) features\nimplicit Kullback-Leibler (KL) regularization by augmenting the reward function\nwith logarithm of the current stochastic policy. Though significant improvement\nhas been shown with the Boltzmann softmax policy, when the Tsallis sparsemax\npolicy is considered, the augmentation leads to a flat learning curve for\nalmost every problem considered. We show that it is due to the mismatch between\nthe conventional logarithm and the non-logarithmic (generalized) nature of\nTsallis entropy. Drawing inspiration from the Tsallis statistics literature, we\npropose to correct the mismatch of M-RL with the help of\n$q$-logarithm/exponential functions. The proposed formulation leads to implicit\nTsallis KL regularization under the maximum Tsallis entropy framework. We show\nsuch formulation of M-RL again achieves superior performance on benchmark\nproblems and sheds light on more general M-RL with various entropic indices\n$q$.",
    "published": "2022-05-16T06:26:10Z",
    "pdf_url": "http://arxiv.org/pdf/2205.07467v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2208.09322v2",
    "title": "Entropy Augmented Reinforcement Learning",
    "authors": [
      "Jianfei Ma"
    ],
    "abstract": "Deep reinforcement learning was instigated with the presence of trust region\nmethods, being scalable and efficient. However, the pessimism of such\nalgorithms, among which it forces to constrain in a trust region by all means,\nhas been proven to suppress the exploration and harm the performance.\nExploratory algorithm such as SAC, while utilizes the entropy to encourage\nexploration, implicitly optimizing another objective yet. We first observed\nthis inconsistency, and therefore put forward an analogous augmentation\ntechnique, which combines well with the on-policy algorithms, when a value\ncritic is involved. Surprisingly, the proposed method consistently satisfies\nthe soft policy improvement theorem, while being more extensible. As the\nanalysis advises, it is crucial to control the temperature coefficient to\nbalance the exploration and exploitation. Empirical tests on MuJoCo benchmark\ntasks show that the agent is heartened towards higher reward regions, and\nenjoys a finer performance. Furthermore, we verify the exploration bonus of our\nmethod on a set of custom environments.",
    "published": "2022-08-19T13:09:32Z",
    "pdf_url": "http://arxiv.org/pdf/2208.09322v2",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2308.15911v1",
    "title": "Cyclophobic Reinforcement Learning",
    "authors": [
      "Stefan Sylvius Wagner",
      "Peter Arndt",
      "Jan Robine",
      "Stefan Harmeling"
    ],
    "abstract": "In environments with sparse rewards, finding a good inductive bias for\nexploration is crucial to the agent's success. However, there are two competing\ngoals: novelty search and systematic exploration. While existing approaches\nsuch as curiosity-driven exploration find novelty, they sometimes do not\nsystematically explore the whole state space, akin to depth-first-search vs\nbreadth-first-search. In this paper, we propose a new intrinsic reward that is\ncyclophobic, i.e., it does not reward novelty, but punishes redundancy by\navoiding cycles. Augmenting the cyclophobic intrinsic reward with a sequence of\nhierarchical representations based on the agent's cropped observations we are\nable to achieve excellent results in the MiniGrid and MiniHack environments.\nBoth are particularly hard, as they require complex interactions with different\nobjects in order to be solved. Detailed comparisons with previous approaches\nand thorough ablation studies show that our newly proposed cyclophobic\nreinforcement learning is more sample efficient than other state of the art\nmethods in a variety of tasks.",
    "published": "2023-08-30T09:38:44Z",
    "pdf_url": "http://arxiv.org/pdf/2308.15911v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ]
  },
  {
    "arxiv_id": "2405.20772v1",
    "title": "Reinforcement Learning for Sociohydrology",
    "authors": [
      "Tirthankar Roy",
      "Shivendra Srivastava",
      "Beichen Zhang"
    ],
    "abstract": "In this study, we discuss how reinforcement learning (RL) provides an\neffective and efficient framework for solving sociohydrology problems. The\nefficacy of RL for these types of problems is evident because of its ability to\nupdate policies in an iterative manner - something that is also foundational to\nsociohydrology, where we are interested in representing the co-evolution of\nhuman-water interactions. We present a simple case study to demonstrate the\nimplementation of RL in a problem of runoff reduction through management\ndecisions related to changes in land-use land-cover (LULC). We then discuss the\nbenefits of RL for these types of problems and share our perspectives on the\nfuture research directions in this area.",
    "published": "2024-05-31T13:28:37Z",
    "pdf_url": "http://arxiv.org/pdf/2405.20772v1",
    "categories": [
      "cs.LG",
      "cs.CY"
    ]
  },
  {
    "arxiv_id": "2406.13961v1",
    "title": "Equivariant Offline Reinforcement Learning",
    "authors": [
      "Arsh Tangri",
      "Ondrej Biza",
      "Dian Wang",
      "David Klee",
      "Owen Howell",
      "Robert Platt"
    ],
    "abstract": "Sample efficiency is critical when applying learning-based methods to robotic\nmanipulation due to the high cost of collecting expert demonstrations and the\nchallenges of on-robot policy learning through online Reinforcement Learning\n(RL). Offline RL addresses this issue by enabling policy learning from an\noffline dataset collected using any behavioral policy, regardless of its\nquality. However, recent advancements in offline RL have predominantly focused\non learning from large datasets. Given that many robotic manipulation tasks can\nbe formulated as rotation-symmetric problems, we investigate the use of\n$SO(2)$-equivariant neural networks for offline RL with a limited number of\ndemonstrations. Our experimental results show that equivariant versions of\nConservative Q-Learning (CQL) and Implicit Q-Learning (IQL) outperform their\nnon-equivariant counterparts. We provide empirical evidence demonstrating how\nequivariance improves offline learning algorithms in the low-data regime.",
    "published": "2024-06-20T03:02:49Z",
    "pdf_url": "http://arxiv.org/pdf/2406.13961v1",
    "categories": [
      "cs.LG",
      "cs.RO"
    ]
  },
  {
    "arxiv_id": "2408.07712v3",
    "title": "Introduction to Reinforcement Learning",
    "authors": [
      "Majid Ghasemi",
      "Dariush Ebrahimi"
    ],
    "abstract": "Reinforcement Learning (RL), a subfield of Artificial Intelligence (AI),\nfocuses on training agents to make decisions by interacting with their\nenvironment to maximize cumulative rewards. This paper provides an overview of\nRL, covering its core concepts, methodologies, and resources for further\nlearning. It offers a thorough explanation of fundamental components such as\nstates, actions, policies, and reward signals, ensuring readers develop a solid\nfoundational understanding. Additionally, the paper presents a variety of RL\nalgorithms, categorized based on the key factors such as model-free,\nmodel-based, value-based, policy-based, and other key factors. Resources for\nlearning and implementing RL, such as books, courses, and online communities\nare also provided. By offering a clear, structured introduction, this paper\naims to simplify the complexities of RL for beginners, providing a\nstraightforward pathway to understanding.",
    "published": "2024-08-13T23:08:06Z",
    "pdf_url": "http://arxiv.org/pdf/2408.07712v3",
    "categories": [
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2408.15076v1",
    "title": "MiWaves Reinforcement Learning Algorithm",
    "authors": [
      "Susobhan Ghosh",
      "Yongyi Guo",
      "Pei-Yao Hung",
      "Lara Coughlin",
      "Erin Bonar",
      "Inbal Nahum-Shani",
      "Maureen Walton",
      "Susan Murphy"
    ],
    "abstract": "The escalating prevalence of cannabis use poses a significant public health\nchallenge globally. In the U.S., cannabis use is more prevalent among emerging\nadults (EAs) (ages 18-25) than any other age group, with legalization in the\nmultiple states contributing to a public perception that cannabis is less risky\nthan in prior decades. To address this growing concern, we developed MiWaves, a\nreinforcement learning (RL) algorithm designed to optimize the delivery of\npersonalized intervention prompts to reduce cannabis use among EAs. MiWaves\nleverages domain expertise and prior data to tailor the likelihood of delivery\nof intervention messages. This paper presents a comprehensive overview of the\nalgorithm's design, including key decisions and experimental outcomes. The\nfinalized MiWaves RL algorithm was deployed in a clinical trial from March to\nMay 2024.",
    "published": "2024-08-27T14:04:04Z",
    "pdf_url": "http://arxiv.org/pdf/2408.15076v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2006.12478v1",
    "title": "Ecological Reinforcement Learning",
    "authors": [
      "John D. Co-Reyes",
      "Suvansh Sanjeev",
      "Glen Berseth",
      "Abhishek Gupta",
      "Sergey Levine"
    ],
    "abstract": "Much of the current work on reinforcement learning studies episodic settings,\nwhere the agent is reset between trials to an initial state distribution, often\nwith well-shaped reward functions. Non-episodic settings, where the agent must\nlearn through continuous interaction with the world without resets, and where\nthe agent receives only delayed and sparse reward signals, is substantially\nmore difficult, but arguably more realistic considering real-world environments\ndo not present the learner with a convenient \"reset mechanism\" and easy reward\nshaping. In this paper, instead of studying algorithmic improvements that can\naddress such non-episodic and sparse reward settings, we instead study the\nkinds of environment properties that can make learning under such conditions\neasier. Understanding how properties of the environment impact the performance\nof reinforcement learning agents can help us to structure our tasks in ways\nthat make learning tractable. We first discuss what we term \"environment\nshaping\" -- modifications to the environment that provide an alternative to\nreward shaping, and may be easier to implement. We then discuss an even simpler\nproperty that we refer to as \"dynamism,\" which describes the degree to which\nthe environment changes independent of the agent's actions and can be measured\nby environment transition entropy. Surprisingly, we find that even this\nproperty can substantially alleviate the challenges associated with\nnon-episodic RL in sparse reward settings. We provide an empirical evaluation\non a set of new tasks focused on non-episodic learning with sparse rewards.\nThrough this study, we hope to shift the focus of the community towards\nanalyzing how properties of the environment can affect learning and the\nultimate type of behavior that is learned via RL.",
    "published": "2020-06-22T17:55:03Z",
    "pdf_url": "http://arxiv.org/pdf/2006.12478v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1106.0221v1",
    "title": "Evolutionary Algorithms for Reinforcement Learning",
    "authors": [
      "J. J. Grefenstette",
      "D. E. Moriarty",
      "A. C. Schultz"
    ],
    "abstract": "There are two distinct approaches to solving reinforcement learning problems,\nnamely, searching in value function space and searching in policy space.\nTemporal difference methods and evolutionary algorithms are well-known examples\nof these approaches. Kaelbling, Littman and Moore recently provided an\ninformative survey of temporal difference methods. This article focuses on the\napplication of evolutionary algorithms to the reinforcement learning problem,\nemphasizing alternative policy representations, credit assignment methods, and\nproblem-specific genetic operators. Strengths and weaknesses of the\nevolutionary approach to reinforcement learning are presented, along with a\nsurvey of representative applications.",
    "published": "2011-06-01T16:16:14Z",
    "pdf_url": "http://arxiv.org/pdf/1106.0221v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "1806.08894v1",
    "title": "Deep Reinforcement Learning: An Overview",
    "authors": [
      "Seyed Sajad Mousavi",
      "Michael Schukat",
      "Enda Howley"
    ],
    "abstract": "In recent years, a specific machine learning method called deep learning has\ngained huge attraction, as it has obtained astonishing results in broad\napplications such as pattern recognition, speech recognition, computer vision,\nand natural language processing. Recent research has also been shown that deep\nlearning techniques can be combined with reinforcement learning methods to\nlearn useful representations for the problems with high dimensional raw data\ninput. This chapter reviews the recent advances in deep reinforcement learning\nwith a focus on the most used deep architectures such as autoencoders,\nconvolutional neural networks and recurrent neural networks which have\nsuccessfully been come together with the reinforcement learning framework.",
    "published": "2018-06-23T02:18:26Z",
    "pdf_url": "http://arxiv.org/pdf/1806.08894v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "0703138v1",
    "title": "Reinforcement Learning for Adaptive Routing",
    "authors": [
      "Leonid Peshkin",
      "Virginia Savova"
    ],
    "abstract": "Reinforcement learning means learning a policy--a mapping of observations\ninto actions--based on feedback from the environment. The learning can be\nviewed as browsing a set of policies while evaluating them by trial through\ninteraction with the environment. We present an application of gradient ascent\nalgorithm for reinforcement learning to a complex domain of packet routing in\nnetwork communication and compare the performance of this algorithm to other\nrouting methods on a benchmark problem.",
    "published": "2007-03-28T04:41:54Z",
    "pdf_url": "http://arxiv.org/pdf/cs/0703138v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI",
      "C.2.1; C.2.2; C.2.4; C.2.6; F.1.1; I.2.6; I.2.8; I.2.9"
    ]
  },
  {
    "arxiv_id": "1811.10732v2",
    "title": "Environments for Lifelong Reinforcement Learning",
    "authors": [
      "Khimya Khetarpal",
      "Shagun Sodhani",
      "Sarath Chandar",
      "Doina Precup"
    ],
    "abstract": "To achieve general artificial intelligence, reinforcement learning (RL)\nagents should learn not only to optimize returns for one specific task but also\nto constantly build more complex skills and scaffold their knowledge about the\nworld, without forgetting what has already been learned. In this paper, we\ndiscuss the desired characteristics of environments that can support the\ntraining and evaluation of lifelong reinforcement learning agents, review\nexisting environments from this perspective, and propose recommendations for\ndevising suitable environments in the future.",
    "published": "2018-11-26T23:01:49Z",
    "pdf_url": "http://arxiv.org/pdf/1811.10732v2",
    "categories": [
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2111.08009v1",
    "title": "Piano Fingering with Reinforcement Learning",
    "authors": [
      "Pedro Ramoneda",
      "Marius Miron",
      "Xavier Serra"
    ],
    "abstract": "Hand and finger movements are a mainstay of piano technique. Automatic\nFingering from symbolic music data allows us to simulate finger and hand\nmovements. Previous proposals achieve automatic piano fingering based on\nknowledge-driven or data-driven techniques. We combine both approaches with\ndeep reinforcement learning techniques to derive piano fingering. Finally, we\nexplore how to incorporate past experience into reinforcement learning-based\npiano fingering in further work.",
    "published": "2021-11-15T09:51:29Z",
    "pdf_url": "http://arxiv.org/pdf/2111.08009v1",
    "categories": [
      "cs.OH"
    ]
  },
  {
    "arxiv_id": "2410.03706v1",
    "title": "Topological Foundations of Reinforcement Learning",
    "authors": [
      "David Krame Kadurha"
    ],
    "abstract": "The goal of this work is to serve as a foundation for deep studies of the\ntopology of state, action, and policy spaces in reinforcement learning. By\nstudying these spaces from a mathematical perspective, we expect to gain more\ninsight into how to build better algorithms to solve decision problems.\nTherefore, we focus on presenting the connection between the Banach fixed point\ntheorem and the convergence of reinforcement learning algorithms, and we\nillustrate how the insights gained from this can practically help in designing\nmore efficient algorithms. Before doing so, however, we first introduce\nrelevant concepts such as metric spaces, normed spaces and Banach spaces for\nbetter understanding, before expressing the entire reinforcement learning\nproblem in terms of Markov decision processes. This allows us to properly\nintroduce the Banach contraction principle in a language suitable for\nreinforcement learning, and to write the Bellman equations in terms of\noperators on Banach spaces to show why reinforcement learning algorithms\nconverge. Finally, we show how the insights gained from the mathematical study\nof convergence are helpful in reasoning about the best ways to make\nreinforcement learning algorithms more efficient.",
    "published": "2024-09-25T21:21:23Z",
    "pdf_url": "http://arxiv.org/pdf/2410.03706v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.FA",
      "68T05"
    ]
  },
  {
    "arxiv_id": "1311.2097v3",
    "title": "Risk-sensitive Reinforcement Learning",
    "authors": [
      "Yun Shen",
      "Michael J. Tobia",
      "Tobias Sommer",
      "Klaus Obermayer"
    ],
    "abstract": "We derive a family of risk-sensitive reinforcement learning methods for\nagents, who face sequential decision-making tasks in uncertain environments. By\napplying a utility function to the temporal difference (TD) error, nonlinear\ntransformations are effectively applied not only to the received rewards but\nalso to the true transition probabilities of the underlying Markov decision\nprocess. When appropriate utility functions are chosen, the agents' behaviors\nexpress key features of human behavior as predicted by prospect theory\n(Kahneman and Tversky, 1979), for example different risk-preferences for gains\nand losses as well as the shape of subjective probability curves. We derive a\nrisk-sensitive Q-learning algorithm, which is necessary for modeling human\nbehavior when transition probabilities are unknown, and prove its convergence.\nAs a proof of principle for the applicability of the new framework we apply it\nto quantify human behavior in a sequential investment task. We find, that the\nrisk-sensitive variant provides a significantly better fit to the behavioral\ndata and that it leads to an interpretation of the subject's responses which is\nindeed consistent with prospect theory. The analysis of simultaneously measured\nfMRI signals show a significant correlation of the risk-sensitive TD error with\nBOLD signal change in the ventral striatum. In addition we find a significant\ncorrelation of the risk-sensitive Q-values with neural activity in the\nstriatum, cingulate cortex and insula, which is not present if standard\nQ-values are used.",
    "published": "2013-11-08T22:25:26Z",
    "pdf_url": "http://arxiv.org/pdf/1311.2097v3",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1606.03137v4",
    "title": "Cooperative Inverse Reinforcement Learning",
    "authors": [
      "Dylan Hadfield-Menell",
      "Anca Dragan",
      "Pieter Abbeel",
      "Stuart Russell"
    ],
    "abstract": "For an autonomous system to be helpful to humans and to pose no unwarranted\nrisks, it needs to align its values with those of the humans in its environment\nin such a way that its actions contribute to the maximization of value for the\nhumans. We propose a formal definition of the value alignment problem as\ncooperative inverse reinforcement learning (CIRL). A CIRL problem is a\ncooperative, partial-information game with two agents, human and robot; both\nare rewarded according to the human's reward function, but the robot does not\ninitially know what this is. In contrast to classical IRL, where the human is\nassumed to act optimally in isolation, optimal CIRL solutions produce behaviors\nsuch as active teaching, active learning, and communicative actions that are\nmore effective in achieving value alignment. We show that computing optimal\njoint policies in CIRL games can be reduced to solving a POMDP, prove that\noptimality in isolation is suboptimal in CIRL, and derive an approximate CIRL\nalgorithm.",
    "published": "2016-06-09T22:39:54Z",
    "pdf_url": "http://arxiv.org/pdf/1606.03137v4",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1805.11447v1",
    "title": "Virtuously Safe Reinforcement Learning",
    "authors": [
      "Henrik Aslund",
      "El Mahdi El Mhamdi",
      "Rachid Guerraoui",
      "Alexandre Maurer"
    ],
    "abstract": "We show that when a third party, the adversary, steps into the two-party\nsetting (agent and operator) of safely interruptible reinforcement learning, a\ntrade-off has to be made between the probability of following the optimal\npolicy in the limit, and the probability of escaping a dangerous situation\ncreated by the adversary. So far, the work on safely interruptible agents has\nassumed a perfect perception of the agent about its environment (no adversary),\nand therefore implicitly set the second probability to zero, by explicitly\nseeking a value of one for the first probability. We show that (1) agents can\nbe made both interruptible and adversary-resilient, and (2) the\ninterruptibility can be made safe in the sense that the agent itself will not\nseek to avoid it. We also solve the problem that arises when the agent does not\ngo completely greedy, i.e. issues with safe exploration in the limit.\nResilience to perturbed perception, safe exploration in the limit, and safe\ninterruptibility are the three pillars of what we call \\emph{virtuously safe\nreinforcement learning}.",
    "published": "2018-05-29T13:34:39Z",
    "pdf_url": "http://arxiv.org/pdf/1805.11447v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2104.00540v1",
    "title": "Reinforcement Learning Beyond Expectation",
    "authors": [
      "Bhaskar Ramasubramanian",
      "Luyao Niu",
      "Andrew Clark",
      "Radha Poovendran"
    ],
    "abstract": "The inputs and preferences of human users are important considerations in\nsituations where these users interact with autonomous cyber or cyber-physical\nsystems. In these scenarios, one is often interested in aligning behaviors of\nthe system with the preferences of one or more human users. Cumulative prospect\ntheory (CPT) is a paradigm that has been empirically shown to model a tendency\nof humans to view gains and losses differently. In this paper, we consider a\nsetting where an autonomous agent has to learn behaviors in an unknown\nenvironment. In traditional reinforcement learning, these behaviors are learned\nthrough repeated interactions with the environment by optimizing an expected\nutility. In order to endow the agent with the ability to closely mimic the\nbehavior of human users, we optimize a CPT-based cost. We introduce the notion\nof the CPT-value of an action taken in a state, and establish the convergence\nof an iterative dynamic programming-based approach to estimate this quantity.\nWe develop two algorithms to enable agents to learn policies to optimize the\nCPT-vale, and evaluate these algorithms in environments where a target state\nhas to be reached while avoiding obstacles. We demonstrate that behaviors of\nthe agent learned using these algorithms are better aligned with that of a\nhuman user who might be placed in the same environment, and is significantly\nimproved over a baseline that optimizes an expected utility.",
    "published": "2021-03-29T20:35:25Z",
    "pdf_url": "http://arxiv.org/pdf/2104.00540v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY",
      "math.OC"
    ]
  },
  {
    "arxiv_id": "1701.08810v3",
    "title": "Reinforcement Learning Algorithm Selection",
    "authors": [
      "Romain Laroche",
      "Raphael Feraud"
    ],
    "abstract": "This paper formalises the problem of online algorithm selection in the\ncontext of Reinforcement Learning. The setup is as follows: given an episodic\ntask and a finite number of off-policy RL algorithms, a meta-algorithm has to\ndecide which RL algorithm is in control during the next episode so as to\nmaximize the expected return. The article presents a novel meta-algorithm,\ncalled Epochal Stochastic Bandit Algorithm Selection (ESBAS). Its principle is\nto freeze the policy updates at each epoch, and to leave a rebooted stochastic\nbandit in charge of the algorithm selection. Under some assumptions, a thorough\ntheoretical analysis demonstrates its near-optimality considering the\nstructural sampling budget limitations. ESBAS is first empirically evaluated on\na dialogue task where it is shown to outperform each individual algorithm in\nmost configurations. ESBAS is then adapted to a true online setting where\nalgorithms update their policies after each transition, which we call SSBAS.\nSSBAS is evaluated on a fruit collection task where it is shown to adapt the\nstepsize parameter more efficiently than the classical hyperbolic decay, and on\nan Atari game, where it improves the performance by a wide margin.",
    "published": "2017-01-30T20:13:17Z",
    "pdf_url": "http://arxiv.org/pdf/1701.08810v3",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "math.OC"
    ]
  },
  {
    "arxiv_id": "1907.06725v3",
    "title": "Mutual Reinforcement Learning",
    "authors": [
      "Sayanti Roy",
      "Emily Kieson",
      "Charles Abramson",
      "Christopher Crick"
    ],
    "abstract": "Recently, collaborative robots have begun to train humans to achieve complex\ntasks, and the mutual information exchange between them can lead to successful\nrobot-human collaborations. In this paper we demonstrate the application and\neffectiveness of a new approach called mutual reinforcement learning (MRL),\nwhere both humans and autonomous agents act as reinforcement learners in a\nskill transfer scenario over continuous communication and feedback. An\nautonomous agent initially acts as an instructor who can teach a novice human\nparticipant complex skills using the MRL strategy. While teaching skills in a\nphysical (block-building) ($n=34$) or simulated (Tetris) environment ($n=31$),\nthe expert tries to identify appropriate reward channels preferred by each\nindividual and adapts itself accordingly using an exploration-exploitation\nstrategy. These reward channel preferences can identify important behaviors of\nthe human participants, because they may well exercise the same behaviors in\nsimilar situations later. In this way, skill transfer takes place between an\nexpert system and a novice human operator. We divided the subject population\ninto three groups and observed the skill transfer phenomenon, analyzing it with\nSimpson\"s psychometric model. 5-point Likert scales were also used to identify\nthe cognitive models of the human participants. We obtained a shared cognitive\nmodel which not only improves human cognition but enhances the robot's\ncognitive strategy to understand the mental model of its human partners while\nbuilding a successful robot-human collaborative framework.",
    "published": "2019-07-15T20:10:29Z",
    "pdf_url": "http://arxiv.org/pdf/1907.06725v3",
    "categories": [
      "cs.RO",
      "cs.HC",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1911.04448v4",
    "title": "Real-Time Reinforcement Learning",
    "authors": [
      "Simon Ramstedt",
      "Christopher Pal"
    ],
    "abstract": "Markov Decision Processes (MDPs), the mathematical framework underlying most\nalgorithms in Reinforcement Learning (RL), are often used in a way that\nwrongfully assumes that the state of an agent's environment does not change\nduring action selection. As RL systems based on MDPs begin to find application\nin real-world safety critical situations, this mismatch between the assumptions\nunderlying classical MDPs and the reality of real-time computation may lead to\nundesirable outcomes. In this paper, we introduce a new framework, in which\nstates and actions evolve simultaneously and show how it is related to the\nclassical MDP formulation. We analyze existing algorithms under the new\nreal-time formulation and show why they are suboptimal when used in real-time.\nWe then use those insights to create a new algorithm Real-Time Actor-Critic\n(RTAC) that outperforms the existing state-of-the-art continuous control\nalgorithm Soft Actor-Critic both in real-time and non-real-time settings. Code\nand videos can be found at https://github.com/rmst/rtrl.",
    "published": "2019-11-11T18:52:04Z",
    "pdf_url": "http://arxiv.org/pdf/1911.04448v4",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2011.04018v4",
    "title": "Online Sparse Reinforcement Learning",
    "authors": [
      "Botao Hao",
      "Tor Lattimore",
      "Csaba Szepesvári",
      "Mengdi Wang"
    ],
    "abstract": "We investigate the hardness of online reinforcement learning in fixed\nhorizon, sparse linear Markov decision process (MDP), with a special focus on\nthe high-dimensional regime where the ambient dimension is larger than the\nnumber of episodes. Our contribution is two-fold. First, we provide a lower\nbound showing that linear regret is generally unavoidable in this case, even if\nthere exists a policy that collects well-conditioned data. The lower bound\nconstruction uses an MDP with a fixed number of states while the number of\nactions scales with the ambient dimension. Note that when the horizon is fixed\nto one, the case of linear stochastic bandits, the linear regret can be\navoided. Second, we show that if the learner has oracle access to a policy that\ncollects well-conditioned data then a variant of Lasso fitted Q-iteration\nenjoys a nearly dimension-free regret of $\\tilde{O}( s^{2/3} N^{2/3})$ where\n$N$ is the number of episodes and $s$ is the sparsity level. This shows that in\nthe large-action setting, the difficulty of learning can be attributed to the\ndifficulty of finding a good exploratory policy.",
    "published": "2020-11-08T16:47:42Z",
    "pdf_url": "http://arxiv.org/pdf/2011.04018v4",
    "categories": [
      "cs.LG",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ]
  },
  {
    "arxiv_id": "2209.09344v1",
    "title": "Understanding reinforcement learned crowds",
    "authors": [
      "Ariel Kwiatkowski",
      "Vicky Kalogeiton",
      "Julien Pettré",
      "Marie-Paule Cani"
    ],
    "abstract": "Simulating trajectories of virtual crowds is a commonly encountered task in\nComputer Graphics. Several recent works have applied Reinforcement Learning\nmethods to animate virtual agents, however they often make different design\nchoices when it comes to the fundamental simulation setup. Each of these\nchoices comes with a reasonable justification for its use, so it is not obvious\nwhat is their real impact, and how they affect the results. In this work, we\nanalyze some of these arbitrary choices in terms of their impact on the\nlearning performance, as well as the quality of the resulting simulation\nmeasured in terms of the energy efficiency. We perform a theoretical analysis\nof the properties of the reward function design, and empirically evaluate the\nimpact of using certain observation and action spaces on a variety of\nscenarios, with the reward function and energy usage as metrics. We show that\ndirectly using the neighboring agents' information as observation generally\noutperforms the more widely used raycasting. Similarly, using nonholonomic\ncontrols with egocentric observations tends to produce more efficient behaviors\nthan holonomic controls with absolute observations. Each of these choices has a\nsignificant, and potentially nontrivial impact on the results, and so\nresearchers should be mindful about choosing and reporting them in their work.",
    "published": "2022-09-19T20:47:49Z",
    "pdf_url": "http://arxiv.org/pdf/2209.09344v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GR",
      "68Q32",
      "I.2.6; I.3.8"
    ]
  },
  {
    "arxiv_id": "1806.09605v1",
    "title": "Many-Goals Reinforcement Learning",
    "authors": [
      "Vivek Veeriah",
      "Junhyuk Oh",
      "Satinder Singh"
    ],
    "abstract": "All-goals updating exploits the off-policy nature of Q-learning to update all\npossible goals an agent could have from each transition in the world, and was\nintroduced into Reinforcement Learning (RL) by Kaelbling (1993). In prior work\nthis was mostly explored in small-state RL problems that allowed tabular\nrepresentations and where all possible goals could be explicitly enumerated and\nlearned separately. In this paper we empirically explore 3 different extensions\nof the idea of updating many (instead of all) goals in the context of RL with\ndeep neural networks (or DeepRL for short). First, in a direct adaptation of\nKaelbling's approach we explore if many-goals updating can be used to achieve\nmastery in non-tabular visual-observation domains. Second, we explore whether\nmany-goals updating can be used to pre-train a network to subsequently learn\nfaster and better on a single main task of interest. Third, we explore whether\nmany-goals updating can be used to provide auxiliary task updates in training a\nnetwork to learn faster and better on a single main task of interest. We\nprovide comparisons to baselines for each of the 3 extensions.",
    "published": "2018-06-22T18:31:24Z",
    "pdf_url": "http://arxiv.org/pdf/1806.09605v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2007.06159v2",
    "title": "Implicit Distributional Reinforcement Learning",
    "authors": [
      "Yuguang Yue",
      "Zhendong Wang",
      "Mingyuan Zhou"
    ],
    "abstract": "To improve the sample efficiency of policy-gradient based reinforcement\nlearning algorithms, we propose implicit distributional actor-critic (IDAC)\nthat consists of a distributional critic, built on two deep generator networks\n(DGNs), and a semi-implicit actor (SIA), powered by a flexible policy\ndistribution. We adopt a distributional perspective on the discounted\ncumulative return and model it with a state-action-dependent implicit\ndistribution, which is approximated by the DGNs that take state-action pairs\nand random noises as their input. Moreover, we use the SIA to provide a\nsemi-implicit policy distribution, which mixes the policy parameters with a\nreparameterizable distribution that is not constrained by an analytic density\nfunction. In this way, the policy's marginal distribution is implicit,\nproviding the potential to model complex properties such as covariance\nstructure and skewness, but its parameter and entropy can still be estimated.\nWe incorporate these features with an off-policy algorithm framework to solve\nproblems with continuous action space and compare IDAC with state-of-the-art\nalgorithms on representative OpenAI Gym environments. We observe that IDAC\noutperforms these baselines in most tasks. Python code is provided.",
    "published": "2020-07-13T02:52:18Z",
    "pdf_url": "http://arxiv.org/pdf/2007.06159v2",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2007.08794v3",
    "title": "Discovering Reinforcement Learning Algorithms",
    "authors": [
      "Junhyuk Oh",
      "Matteo Hessel",
      "Wojciech M. Czarnecki",
      "Zhongwen Xu",
      "Hado van Hasselt",
      "Satinder Singh",
      "David Silver"
    ],
    "abstract": "Reinforcement learning (RL) algorithms update an agent's parameters according\nto one of several possible rules, discovered manually through years of\nresearch. Automating the discovery of update rules from data could lead to more\nefficient algorithms, or algorithms that are better adapted to specific\nenvironments. Although there have been prior attempts at addressing this\nsignificant scientific challenge, it remains an open question whether it is\nfeasible to discover alternatives to fundamental concepts of RL such as value\nfunctions and temporal-difference learning. This paper introduces a new\nmeta-learning approach that discovers an entire update rule which includes both\n'what to predict' (e.g. value functions) and 'how to learn from it' (e.g.\nbootstrapping) by interacting with a set of environments. The output of this\nmethod is an RL algorithm that we call Learned Policy Gradient (LPG). Empirical\nresults show that our method discovers its own alternative to the concept of\nvalue functions. Furthermore it discovers a bootstrapping mechanism to maintain\nand use its predictions. Surprisingly, when trained solely on toy environments,\nLPG generalises effectively to complex Atari games and achieves non-trivial\nperformance. This shows the potential to discover general RL algorithms from\ndata.",
    "published": "2020-07-17T07:38:39Z",
    "pdf_url": "http://arxiv.org/pdf/2007.08794v3",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2106.02757v2",
    "title": "Heuristic-Guided Reinforcement Learning",
    "authors": [
      "Ching-An Cheng",
      "Andrey Kolobov",
      "Adith Swaminathan"
    ],
    "abstract": "We provide a framework for accelerating reinforcement learning (RL)\nalgorithms by heuristics constructed from domain knowledge or offline data.\nTabula rasa RL algorithms require environment interactions or computation that\nscales with the horizon of the sequential decision-making task. Using our\nframework, we show how heuristic-guided RL induces a much shorter-horizon\nsubproblem that provably solves the original task. Our framework can be viewed\nas a horizon-based regularization for controlling bias and variance in RL under\na finite interaction budget. On the theoretical side, we characterize\nproperties of a good heuristic and its impact on RL acceleration. In\nparticular, we introduce the novel concept of an improvable heuristic, a\nheuristic that allows an RL agent to extrapolate beyond its prior knowledge. On\nthe empirical side, we instantiate our framework to accelerate several\nstate-of-the-art algorithms in simulated robotic control tasks and procedurally\ngenerated games. Our framework complements the rich literature on warm-starting\nRL with expert demonstrations or exploratory datasets, and introduces a\nprincipled method for injecting prior knowledge into RL.",
    "published": "2021-06-05T00:04:09Z",
    "pdf_url": "http://arxiv.org/pdf/2106.02757v2",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2106.12764v1",
    "title": "Density Constrained Reinforcement Learning",
    "authors": [
      "Zengyi Qin",
      "Yuxiao Chen",
      "Chuchu Fan"
    ],
    "abstract": "We study constrained reinforcement learning (CRL) from a novel perspective by\nsetting constraints directly on state density functions, rather than the value\nfunctions considered by previous works. State density has a clear physical and\nmathematical interpretation, and is able to express a wide variety of\nconstraints such as resource limits and safety requirements. Density\nconstraints can also avoid the time-consuming process of designing and tuning\ncost functions required by value function-based constraints to encode system\nspecifications. We leverage the duality between density functions and Q\nfunctions to develop an effective algorithm to solve the density constrained RL\nproblem optimally and the constrains are guaranteed to be satisfied. We prove\nthat the proposed algorithm converges to a near-optimal solution with a bounded\nerror even when the policy update is imperfect. We use a set of comprehensive\nexperiments to demonstrate the advantages of our approach over state-of-the-art\nCRL methods, with a wide range of density constrained tasks as well as standard\nCRL benchmarks such as Safety-Gym.",
    "published": "2021-06-24T04:22:03Z",
    "pdf_url": "http://arxiv.org/pdf/2106.12764v1",
    "categories": [
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ]
  },
  {
    "arxiv_id": "2205.07536v2",
    "title": "Reachability Constrained Reinforcement Learning",
    "authors": [
      "Dongjie Yu",
      "Haitong Ma",
      "Shengbo Eben Li",
      "Jianyu Chen"
    ],
    "abstract": "Constrained reinforcement learning (CRL) has gained significant interest\nrecently, since safety constraints satisfaction is critical for real-world\nproblems. However, existing CRL methods constraining discounted cumulative\ncosts generally lack rigorous definition and guarantee of safety. In contrast,\nin the safe control research, safety is defined as persistently satisfying\ncertain state constraints. Such persistent safety is possible only on a subset\nof the state space, called feasible set, where an optimal largest feasible set\nexists for a given environment. Recent studies incorporate feasible sets into\nCRL with energy-based methods such as control barrier function (CBF), safety\nindex (SI), and leverage prior conservative estimations of feasible sets, which\nharms the performance of the learned policy. To deal with this problem, this\npaper proposes the reachability CRL (RCRL) method by using reachability\nanalysis to establish the novel self-consistency condition and characterize the\nfeasible sets. The feasible sets are represented by the safety value function,\nwhich is used as the constraint in CRL. We use the multi-time scale stochastic\napproximation theory to prove that the proposed algorithm converges to a local\noptimum, where the largest feasible set can be guaranteed. Empirical results on\ndifferent benchmarks validate the learned feasible set, the policy performance,\nand constraint satisfaction of RCRL, compared to CRL and safe control\nbaselines.",
    "published": "2022-05-16T09:32:45Z",
    "pdf_url": "http://arxiv.org/pdf/2205.07536v2",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ]
  },
  {
    "arxiv_id": "2206.05581v3",
    "title": "Federated Offline Reinforcement Learning",
    "authors": [
      "Doudou Zhou",
      "Yufeng Zhang",
      "Aaron Sonabend-W",
      "Zhaoran Wang",
      "Junwei Lu",
      "Tianxi Cai"
    ],
    "abstract": "Evidence-based or data-driven dynamic treatment regimes are essential for\npersonalized medicine, which can benefit from offline reinforcement learning\n(RL). Although massive healthcare data are available across medical\ninstitutions, they are prohibited from sharing due to privacy constraints.\nBesides, heterogeneity exists in different sites. As a result, federated\noffline RL algorithms are necessary and promising to deal with the problems. In\nthis paper, we propose a multi-site Markov decision process model that allows\nfor both homogeneous and heterogeneous effects across sites. The proposed model\nmakes the analysis of the site-level features possible. We design the first\nfederated policy optimization algorithm for offline RL with sample complexity.\nThe proposed algorithm is communication-efficient, which requires only a single\nround of communication interaction by exchanging summary statistics. We give a\ntheoretical guarantee for the proposed algorithm, where the suboptimality for\nthe learned policies is comparable to the rate as if data is not distributed.\nExtensive simulations demonstrate the effectiveness of the proposed algorithm.\nThe method is applied to a sepsis dataset in multiple sites to illustrate its\nuse in clinical settings.",
    "published": "2022-06-11T18:03:26Z",
    "pdf_url": "http://arxiv.org/pdf/2206.05581v3",
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.ME"
    ]
  },
  {
    "arxiv_id": "2206.11430v1",
    "title": "Recursive Reinforcement Learning",
    "authors": [
      "Ernst Moritz Hahn",
      "Mateo Perez",
      "Sven Schewe",
      "Fabio Somenzi",
      "Ashutosh Trivedi",
      "Dominik Wojtczak"
    ],
    "abstract": "Recursion is the fundamental paradigm to finitely describe potentially\ninfinite objects. As state-of-the-art reinforcement learning (RL) algorithms\ncannot directly reason about recursion, they must rely on the practitioner's\ningenuity in designing a suitable \"flat\" representation of the environment. The\nresulting manual feature constructions and approximations are cumbersome and\nerror-prone; their lack of transparency hampers scalability. To overcome these\nchallenges, we develop RL algorithms capable of computing optimal policies in\nenvironments described as a collection of Markov decision processes (MDPs) that\ncan recursively invoke one another. Each constituent MDP is characterized by\nseveral entry and exit points that correspond to input and output values of\nthese invocations. These recursive MDPs (or RMDPs) are expressively equivalent\nto probabilistic pushdown systems (with call-stack playing the role of the\npushdown stack), and can model probabilistic programs with recursive procedural\ncalls. We introduce Recursive Q-learning -- a model-free RL algorithm for RMDPs\n-- and prove that it converges for finite, single-exit and deterministic\nmulti-exit RMDPs under mild assumptions.",
    "published": "2022-06-23T00:29:42Z",
    "pdf_url": "http://arxiv.org/pdf/2206.11430v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2208.12584v2",
    "title": "Socially Fair Reinforcement Learning",
    "authors": [
      "Debmalya Mandal",
      "Jiarui Gan"
    ],
    "abstract": "We consider the problem of episodic reinforcement learning where there are\nmultiple stakeholders with different reward functions. Our goal is to output a\npolicy that is socially fair with respect to different reward functions. Prior\nworks have proposed different objectives that a fair policy must optimize\nincluding minimum welfare, and generalized Gini welfare. We first take an\naxiomatic view of the problem, and propose four axioms that any such fair\nobjective must satisfy. We show that the Nash social welfare is the unique\nobjective that uniquely satisfies all four objectives, whereas prior objectives\nfail to satisfy all four axioms. We then consider the learning version of the\nproblem where the underlying model i.e. Markov decision process is unknown. We\nconsider the problem of minimizing regret with respect to the fair policies\nmaximizing three different fair objectives -- minimum welfare, generalized Gini\nwelfare, and Nash social welfare. Based on optimistic planning, we propose a\ngeneric learning algorithm and derive its regret bound with respect to the\nthree different policies. For the objective of Nash social welfare, we also\nderive a lower bound in regret that grows exponentially with $n$, the number of\nagents. Finally, we show that for the objective of minimum welfare, one can\nimprove regret by a factor of $O(H)$ for a weaker notion of regret.",
    "published": "2022-08-26T11:01:55Z",
    "pdf_url": "http://arxiv.org/pdf/2208.12584v2",
    "categories": [
      "cs.LG",
      "cs.CY",
      "cs.GT",
      "cs.MA"
    ]
  },
  {
    "arxiv_id": "2208.14863v1",
    "title": "Style-Agnostic Reinforcement Learning",
    "authors": [
      "Juyong Lee",
      "Seokjun Ahn",
      "Jaesik Park"
    ],
    "abstract": "We present a novel method of learning style-agnostic representation using\nboth style transfer and adversarial learning in the reinforcement learning\nframework. The style, here, refers to task-irrelevant details such as the color\nof the background in the images, where generalizing the learned policy across\nenvironments with different styles is still a challenge. Focusing on learning\nstyle-agnostic representations, our method trains the actor with diverse image\nstyles generated from an inherent adversarial style perturbation generator,\nwhich plays a min-max game between the actor and the generator, without\ndemanding expert knowledge for data augmentation or additional class labels for\nadversarial training. We verify that our method achieves competitive or better\nperformances than the state-of-the-art approaches on Procgen and Distracting\nControl Suite benchmarks, and further investigate the features extracted from\nour model, showing that the model better captures the invariants and is less\ndistracted by the shifted style. The code is available at\nhttps://github.com/POSTECH-CVLab/style-agnostic-RL.",
    "published": "2022-08-31T13:45:00Z",
    "pdf_url": "http://arxiv.org/pdf/2208.14863v1",
    "categories": [
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2210.01542v1",
    "title": "Hyperbolic Deep Reinforcement Learning",
    "authors": [
      "Edoardo Cetin",
      "Benjamin Chamberlain",
      "Michael Bronstein",
      "Jonathan J Hunt"
    ],
    "abstract": "We propose a new class of deep reinforcement learning (RL) algorithms that\nmodel latent representations in hyperbolic space. Sequential decision-making\nrequires reasoning about the possible future consequences of current behavior.\nConsequently, capturing the relationship between key evolving features for a\ngiven task is conducive to recovering effective policies. To this end,\nhyperbolic geometry provides deep RL models with a natural basis to precisely\nencode this inherently hierarchical information. However, applying existing\nmethodologies from the hyperbolic deep learning literature leads to fatal\noptimization instabilities due to the non-stationarity and variance\ncharacterizing RL gradient estimators. Hence, we design a new general method\nthat counteracts such optimization challenges and enables stable end-to-end\nlearning with deep hyperbolic representations. We empirically validate our\nframework by applying it to popular on-policy and off-policy RL algorithms on\nthe Procgen and Atari 100K benchmarks, attaining near universal performance and\ngeneralization benefits. Given its natural fit, we hope future RL research will\nconsider hyperbolic representations as a standard tool.",
    "published": "2022-10-04T12:03:04Z",
    "pdf_url": "http://arxiv.org/pdf/2210.01542v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2211.03983v3",
    "title": "Doubly Inhomogeneous Reinforcement Learning",
    "authors": [
      "Liyuan Hu",
      "Mengbing Li",
      "Chengchun Shi",
      "Zhenke Wu",
      "Piotr Fryzlewicz"
    ],
    "abstract": "This paper studies reinforcement learning (RL) in doubly inhomogeneous\nenvironments under temporal non-stationarity and subject heterogeneity. In a\nnumber of applications, it is commonplace to encounter datasets generated by\nsystem dynamics that may change over time and population, challenging\nhigh-quality sequential decision making. Nonetheless, most existing RL\nsolutions require either temporal stationarity or subject homogeneity, which\nwould result in sub-optimal policies if both assumptions were violated. To\naddress both challenges simultaneously, we propose an original algorithm to\ndetermine the ``best data chunks\" that display similar dynamics over time and\nacross individuals for policy learning, which alternates between most recent\nchange point detection and cluster identification. Our method is general, and\nworks with a wide range of clustering and change point detection algorithms. It\nis multiply robust in the sense that it takes multiple initial estimators as\ninput and only requires one of them to be consistent. Moreover, by borrowing\ninformation over time and population, it allows us to detect weaker signals and\nhas better convergence properties when compared to applying the clustering\nalgorithm per time or the change point detection algorithm per subject.\nEmpirically, we demonstrate the usefulness of our method through extensive\nsimulations and a real data application.",
    "published": "2022-11-08T03:41:14Z",
    "pdf_url": "http://arxiv.org/pdf/2211.03983v3",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2302.00270v3",
    "title": "Internally Rewarded Reinforcement Learning",
    "authors": [
      "Mengdi Li",
      "Xufeng Zhao",
      "Jae Hee Lee",
      "Cornelius Weber",
      "Stefan Wermter"
    ],
    "abstract": "We study a class of reinforcement learning problems where the reward signals\nfor policy learning are generated by an internal reward model that is dependent\non and jointly optimized with the policy. This interdependence between the\npolicy and the reward model leads to an unstable learning process because\nreward signals from an immature reward model are noisy and impede policy\nlearning, and conversely, an under-optimized policy impedes reward estimation\nlearning. We call this learning setting $\\textit{Internally Rewarded\nReinforcement Learning}$ (IRRL) as the reward is not provided directly by the\nenvironment but $\\textit{internally}$ by a reward model. In this paper, we\nformally formulate IRRL and present a class of problems that belong to IRRL. We\ntheoretically derive and empirically analyze the effect of the reward function\nin IRRL and based on these analyses propose the clipped linear reward function.\nExperimental results show that the proposed reward function can consistently\nstabilize the training process by reducing the impact of reward noise, which\nleads to faster convergence and higher performance compared with baselines in\ndiverse tasks.",
    "published": "2023-02-01T06:25:46Z",
    "pdf_url": "http://arxiv.org/pdf/2302.00270v3",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2307.13372v2",
    "title": "Submodular Reinforcement Learning",
    "authors": [
      "Manish Prajapat",
      "Mojmír Mutný",
      "Melanie N. Zeilinger",
      "Andreas Krause"
    ],
    "abstract": "In reinforcement learning (RL), rewards of states are typically considered\nadditive, and following the Markov assumption, they are $\\textit{independent}$\nof states visited previously. In many important applications, such as coverage\ncontrol, experiment design and informative path planning, rewards naturally\nhave diminishing returns, i.e., their value decreases in light of similar\nstates visited previously. To tackle this, we propose $\\textit{submodular RL}$\n(SubRL), a paradigm which seeks to optimize more general, non-additive (and\nhistory-dependent) rewards modelled via submodular set functions which capture\ndiminishing returns. Unfortunately, in general, even in tabular settings, we\nshow that the resulting optimization problem is hard to approximate. On the\nother hand, motivated by the success of greedy algorithms in classical\nsubmodular optimization, we propose SubPO, a simple policy gradient-based\nalgorithm for SubRL that handles non-additive rewards by greedily maximizing\nmarginal gains. Indeed, under some assumptions on the underlying Markov\nDecision Process (MDP), SubPO recovers optimal constant factor approximations\nof submodular bandits. Moreover, we derive a natural policy gradient approach\nfor locally optimizing SubRL instances even in large state- and action- spaces.\nWe showcase the versatility of our approach by applying SubPO to several\napplications, such as biodiversity monitoring, Bayesian experiment design,\ninformative path planning, and coverage maximization. Our results demonstrate\nsample efficiency, as well as scalability to high-dimensional state-action\nspaces.",
    "published": "2023-07-25T09:46:02Z",
    "pdf_url": "http://arxiv.org/pdf/2307.13372v2",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2308.07843v6",
    "title": "Dyadic Reinforcement Learning",
    "authors": [
      "Shuangning Li",
      "Lluis Salvat Niell",
      "Sung Won Choi",
      "Inbal Nahum-Shani",
      "Guy Shani",
      "Susan Murphy"
    ],
    "abstract": "Mobile health aims to enhance health outcomes by delivering interventions to\nindividuals as they go about their daily life. The involvement of care partners\nand social support networks often proves crucial in helping individuals\nmanaging burdensome medical conditions. This presents opportunities in mobile\nhealth to design interventions that target the dyadic relationship -- the\nrelationship between a target person and their care partner -- with the aim of\nenhancing social support. In this paper, we develop dyadic RL, an online\nreinforcement learning algorithm designed to personalize intervention delivery\nbased on contextual factors and past responses of a target person and their\ncare partner. Here, multiple sets of interventions impact the dyad across\nmultiple time intervals. The developed dyadic RL is Bayesian and hierarchical.\nWe formally introduce the problem setup, develop dyadic RL and establish a\nregret bound. We demonstrate dyadic RL's empirical performance through\nsimulation studies on both toy scenarios and on a realistic test bed\nconstructed from data collected in a mobile health study.",
    "published": "2023-08-15T15:43:12Z",
    "pdf_url": "http://arxiv.org/pdf/2308.07843v6",
    "categories": [
      "cs.LG",
      "stat.AP",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2309.11096v1",
    "title": "Delays in Reinforcement Learning",
    "authors": [
      "Pierre Liotet"
    ],
    "abstract": "Delays are inherent to most dynamical systems. Besides shifting the process\nin time, they can significantly affect their performance. For this reason, it\nis usually valuable to study the delay and account for it. Because they are\ndynamical systems, it is of no surprise that sequential decision-making\nproblems such as Markov decision processes (MDP) can also be affected by\ndelays. These processes are the foundational framework of reinforcement\nlearning (RL), a paradigm whose goal is to create artificial agents capable of\nlearning to maximise their utility by interacting with their environment.\n  RL has achieved strong, sometimes astonishing, empirical results, but delays\nare seldom explicitly accounted for. The understanding of the impact of delay\non the MDP is limited. In this dissertation, we propose to study the delay in\nthe agent's observation of the state of the environment or in the execution of\nthe agent's actions. We will repeatedly change our point of view on the problem\nto reveal some of its structure and peculiarities. A wide spectrum of delays\nwill be considered, and potential solutions will be presented. This\ndissertation also aims to draw links between celebrated frameworks of the RL\nliterature and the one of delays.",
    "published": "2023-09-20T07:04:46Z",
    "pdf_url": "http://arxiv.org/pdf/2309.11096v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2312.17194v2",
    "title": "Resilient Constrained Reinforcement Learning",
    "authors": [
      "Dongsheng Ding",
      "Zhengyan Huan",
      "Alejandro Ribeiro"
    ],
    "abstract": "We study a class of constrained reinforcement learning (RL) problems in which\nmultiple constraint specifications are not identified before training. It is\nchallenging to identify appropriate constraint specifications due to the\nundefined trade-off between the reward maximization objective and the\nconstraint satisfaction, which is ubiquitous in constrained decision-making. To\ntackle this issue, we propose a new constrained RL approach that searches for\npolicy and constraint specifications together. This method features the\nadaptation of relaxing the constraint according to a relaxation cost introduced\nin the learning objective. Since this feature mimics how ecological systems\nadapt to disruptions by altering operation, our approach is termed as resilient\nconstrained RL. Specifically, we provide a set of sufficient conditions that\nbalance the constraint satisfaction and the reward maximization in notion of\nresilient equilibrium, propose a tractable formulation of resilient constrained\npolicy optimization that takes this equilibrium as an optimal solution, and\nadvocate two resilient constrained policy search algorithms with non-asymptotic\nconvergence guarantees on the optimality gap and constraint satisfaction.\nFurthermore, we demonstrate the merits and the effectiveness of our approach in\ncomputational experiments.",
    "published": "2023-12-28T18:28:23Z",
    "pdf_url": "http://arxiv.org/pdf/2312.17194v2",
    "categories": [
      "math.OC",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ]
  },
  {
    "arxiv_id": "2405.18289v1",
    "title": "Highway Reinforcement Learning",
    "authors": [
      "Yuhui Wang",
      "Miroslav Strupl",
      "Francesco Faccio",
      "Qingyuan Wu",
      "Haozhe Liu",
      "Michał Grudzień",
      "Xiaoyang Tan",
      "Jürgen Schmidhuber"
    ],
    "abstract": "Learning from multi-step off-policy data collected by a set of policies is a\ncore problem of reinforcement learning (RL). Approaches based on importance\nsampling (IS) often suffer from large variances due to products of IS ratios.\nTypical IS-free methods, such as $n$-step Q-learning, look ahead for $n$ time\nsteps along the trajectory of actions (where $n$ is called the lookahead depth)\nand utilize off-policy data directly without any additional adjustment. They\nwork well for proper choices of $n$. We show, however, that such IS-free\nmethods underestimate the optimal value function (VF), especially for large\n$n$, restricting their capacity to efficiently utilize information from distant\nfuture time steps. To overcome this problem, we introduce a novel, IS-free,\nmulti-step off-policy method that avoids the underestimation issue and\nconverges to the optimal VF. At its core lies a simple but non-trivial\n\\emph{highway gate}, which controls the information flow from the distant\nfuture by comparing it to a threshold. The highway gate guarantees convergence\nto the optimal VF for arbitrary $n$ and arbitrary behavioral policies. It gives\nrise to a novel family of off-policy RL algorithms that safely learn even when\n$n$ is very large, facilitating rapid credit assignment from the far future to\nthe past. On tasks with greatly delayed rewards, including video games where\nthe reward is given only at the end of the game, our new methods outperform\nmany existing multi-step off-policy algorithms.",
    "published": "2024-05-28T15:42:45Z",
    "pdf_url": "http://arxiv.org/pdf/2405.18289v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2505.19002v1",
    "title": "Semi-pessimistic Reinforcement Learning",
    "authors": [
      "Jin Zhu",
      "Xin Zhou",
      "Jiaang Yao",
      "Gholamali Aminian",
      "Omar Rivasplata",
      "Simon Little",
      "Lexin Li",
      "Chengchun Shi"
    ],
    "abstract": "Offline reinforcement learning (RL) aims to learn an optimal policy from\npre-collected data. However, it faces challenges of distributional shift, where\nthe learned policy may encounter unseen scenarios not covered in the offline\ndata. Additionally, numerous applications suffer from a scarcity of labeled\nreward data. Relying on labeled data alone often leads to a narrow state-action\ndistribution, further amplifying the distributional shift, and resulting in\nsuboptimal policy learning. To address these issues, we first recognize that\nthe volume of unlabeled data is typically substantially larger than that of\nlabeled data. We then propose a semi-pessimistic RL method to effectively\nleverage abundant unlabeled data. Our approach offers several advantages. It\nconsiderably simplifies the learning process, as it seeks a lower bound of the\nreward function, rather than that of the Q-function or state transition\nfunction. It is highly flexible, and can be integrated with a range of\nmodel-free and model-based RL algorithms. It enjoys the guaranteed improvement\nwhen utilizing vast unlabeled data, but requires much less restrictive\nconditions. We compare our method with a number of alternative solutions, both\nanalytically and numerically, and demonstrate its clear competitiveness. We\nfurther illustrate with an application to adaptive deep brain stimulation for\nParkinson's disease.",
    "published": "2025-05-25T06:47:36Z",
    "pdf_url": "http://arxiv.org/pdf/2505.19002v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2201.02135v5",
    "title": "Deep Reinforcement Learning, a textbook",
    "authors": [
      "Aske Plaat"
    ],
    "abstract": "Deep reinforcement learning has gathered much attention recently. Impressive\nresults were achieved in activities as diverse as autonomous driving, game\nplaying, molecular recombination, and robotics. In all these fields, computer\nprograms have taught themselves to solve difficult problems. They have learned\nto fly model helicopters and perform aerobatic manoeuvers such as loops and\nrolls. In some applications they have even become better than the best humans,\nsuch as in Atari, Go, poker and StarCraft. The way in which deep reinforcement\nlearning explores complex environments reminds us of how children learn, by\nplayfully trying out things, getting feedback, and trying again. The computer\nseems to truly possess aspects of human learning; this goes to the heart of the\ndream of artificial intelligence. The successes in research have not gone\nunnoticed by educators, and universities have started to offer courses on the\nsubject. The aim of this book is to provide a comprehensive overview of the\nfield of deep reinforcement learning. The book is written for graduate students\nof artificial intelligence, and for researchers and practitioners who wish to\nbetter understand deep reinforcement learning methods and their challenges. We\nassume an undergraduate-level of understanding of computer science and\nartificial intelligence; the programming language of this book is Python. We\ndescribe the foundations, the algorithms and the applications of deep\nreinforcement learning. We cover the established model-free and model-based\nmethods that form the basis of the field. Developments go quickly, and we also\ncover advanced topics: deep multi-agent reinforcement learning, deep\nhierarchical reinforcement learning, and deep meta learning.",
    "published": "2022-01-04T11:47:21Z",
    "pdf_url": "http://arxiv.org/pdf/2201.02135v5",
    "categories": [
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1611.08944v1",
    "title": "Nonparametric General Reinforcement Learning",
    "authors": [
      "Jan Leike"
    ],
    "abstract": "Reinforcement learning (RL) problems are often phrased in terms of Markov\ndecision processes (MDPs). In this thesis we go beyond MDPs and consider RL in\nenvironments that are non-Markovian, non-ergodic and only partially observable.\nOur focus is not on practical algorithms, but rather on the fundamental\nunderlying problems: How do we balance exploration and exploitation? How do we\nexplore optimally? When is an agent optimal? We follow the nonparametric\nrealizable paradigm.\n  We establish negative results on Bayesian RL agents, in particular AIXI. We\nshow that unlucky or adversarial choices of the prior cause the agent to\nmisbehave drastically. Therefore Legg-Hutter intelligence and balanced Pareto\noptimality, which depend crucially on the choice of the prior, are entirely\nsubjective. Moreover, in the class of all computable environments every policy\nis Pareto optimal. This undermines all existing optimality properties for AIXI.\nHowever, there are Bayesian approaches to general RL that satisfy objective\noptimality guarantees: We prove that Thompson sampling is asymptotically\noptimal in stochastic environments in the sense that its value converges to the\nvalue of the optimal policy. We connect asymptotic optimality to regret given a\nrecoverability assumption on the environment that allows the agent to recover\nfrom mistakes. Hence Thompson sampling achieves sublinear regret in these\nenvironments.\n  Our results culminate in a formal solution to the grain of truth problem: A\nBayesian agent acting in a multi-agent environment learns to predict the other\nagents' policies if its prior assigns positive probability to them (the prior\ncontains a grain of truth). We construct a large but limit computable class\ncontaining a grain of truth and show that agents based on Thompson sampling\nover this class converge to play Nash equilibria in arbitrary unknown\ncomputable multi-agent environments.",
    "published": "2016-11-28T00:36:40Z",
    "pdf_url": "http://arxiv.org/pdf/1611.08944v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2202.08417v4",
    "title": "Retrieval-Augmented Reinforcement Learning",
    "authors": [
      "Anirudh Goyal",
      "Abram L. Friesen",
      "Andrea Banino",
      "Theophane Weber",
      "Nan Rosemary Ke",
      "Adria Puigdomenech Badia",
      "Arthur Guez",
      "Mehdi Mirza",
      "Peter C. Humphreys",
      "Ksenia Konyushkova",
      "Laurent Sifre",
      "Michal Valko",
      "Simon Osindero",
      "Timothy Lillicrap",
      "Nicolas Heess",
      "Charles Blundell"
    ],
    "abstract": "Most deep reinforcement learning (RL) algorithms distill experience into\nparametric behavior policies or value functions via gradient updates. While\neffective, this approach has several disadvantages: (1) it is computationally\nexpensive, (2) it can take many updates to integrate experiences into the\nparametric model, (3) experiences that are not fully integrated do not\nappropriately influence the agent's behavior, and (4) behavior is limited by\nthe capacity of the model. In this paper we explore an alternative paradigm in\nwhich we train a network to map a dataset of past experiences to optimal\nbehavior. Specifically, we augment an RL agent with a retrieval process\n(parameterized as a neural network) that has direct access to a dataset of\nexperiences. This dataset can come from the agent's past experiences, expert\ndemonstrations, or any other relevant source. The retrieval process is trained\nto retrieve information from the dataset that may be useful in the current\ncontext, to help the agent achieve its goal faster and more efficiently. he\nproposed method facilitates learning agents that at test-time can condition\ntheir behavior on the entire dataset and not only the current state, or current\ntrajectory. We integrate our method into two different RL agents: an offline\nDQN agent and an online R2D2 agent. In offline multi-task problems, we show\nthat the retrieval-augmented DQN agent avoids task interference and learns\nfaster than the baseline DQN agent. On Atari, we show that retrieval-augmented\nR2D2 learns significantly faster than the baseline R2D2 agent and achieves\nhigher scores. We run extensive ablations to measure the contributions of the\ncomponents of our proposed method.",
    "published": "2022-02-17T02:44:05Z",
    "pdf_url": "http://arxiv.org/pdf/2202.08417v4",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2305.19562v2",
    "title": "Replicability in Reinforcement Learning",
    "authors": [
      "Amin Karbasi",
      "Grigoris Velegkas",
      "Lin F. Yang",
      "Felix Zhou"
    ],
    "abstract": "We initiate the mathematical study of replicability as an algorithmic\nproperty in the context of reinforcement learning (RL). We focus on the\nfundamental setting of discounted tabular MDPs with access to a generative\nmodel. Inspired by Impagliazzo et al. [2022], we say that an RL algorithm is\nreplicable if, with high probability, it outputs the exact same policy after\ntwo executions on i.i.d. samples drawn from the generator when its internal\nrandomness is the same. We first provide an efficient $\\rho$-replicable\nalgorithm for $(\\varepsilon, \\delta)$-optimal policy estimation with sample and\ntime complexity $\\widetilde\nO\\left(\\frac{N^3\\cdot\\log(1/\\delta)}{(1-\\gamma)^5\\cdot\\varepsilon^2\\cdot\\rho^2}\\right)$,\nwhere $N$ is the number of state-action pairs. Next, for the subclass of\ndeterministic algorithms, we provide a lower bound of order\n$\\Omega\\left(\\frac{N^3}{(1-\\gamma)^3\\cdot\\varepsilon^2\\cdot\\rho^2}\\right)$.\nThen, we study a relaxed version of replicability proposed by Kalavasis et al.\n[2023] called TV indistinguishability. We design a computationally efficient TV\nindistinguishable algorithm for policy estimation whose sample complexity is\n$\\widetilde\nO\\left(\\frac{N^2\\cdot\\log(1/\\delta)}{(1-\\gamma)^5\\cdot\\varepsilon^2\\cdot\\rho^2}\\right)$.\nAt the cost of $\\exp(N)$ running time, we transform these TV indistinguishable\nalgorithms to $\\rho$-replicable ones without increasing their sample\ncomplexity. Finally, we introduce the notion of approximate-replicability where\nwe only require that two outputted policies are close under an appropriate\nstatistical divergence (e.g., Renyi) and show an improved sample complexity of\n$\\widetilde\nO\\left(\\frac{N\\cdot\\log(1/\\delta)}{(1-\\gamma)^5\\cdot\\varepsilon^2\\cdot\\rho^2}\\right)$.",
    "published": "2023-05-31T05:16:23Z",
    "pdf_url": "http://arxiv.org/pdf/2305.19562v2",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1801.08099v8",
    "title": "Logically-Constrained Reinforcement Learning",
    "authors": [
      "Mohammadhosein Hasanbeig",
      "Alessandro Abate",
      "Daniel Kroening"
    ],
    "abstract": "We present the first model-free Reinforcement Learning (RL) algorithm to\nsynthesise policies for an unknown Markov Decision Process (MDP), such that a\nlinear time property is satisfied. The given temporal property is converted\ninto a Limit Deterministic Buchi Automaton (LDBA) and a robust reward function\nis defined over the state-action pairs of the MDP according to the resulting\nLDBA. With this reward function, the policy synthesis procedure is\n\"constrained\" by the given specification. These constraints guide the MDP\nexploration so as to minimize the solution time by only considering the portion\nof the MDP that is relevant to satisfaction of the LTL property. This improves\nperformance and scalability of the proposed method by avoiding an exhaustive\nupdate over the whole state space while the efficiency of standard methods such\nas dynamic programming is hindered by excessive memory requirements, caused by\nthe need to store a full-model in memory. Additionally, we show that the RL\nprocedure sets up a local value iteration method to efficiently calculate the\nmaximum probability of satisfying the given property, at any given state of the\nMDP. We prove that our algorithm is guaranteed to find a policy whose traces\nprobabilistically satisfy the LTL property if such a policy exists, and\nadditionally we show that our method produces reasonable control policies even\nwhen the LTL property cannot be satisfied. The performance of the algorithm is\nevaluated via a set of numerical examples. We observe an improvement of one\norder of magnitude in the number of iterations required for the synthesis\ncompared to existing approaches.",
    "published": "2018-01-24T17:50:30Z",
    "pdf_url": "http://arxiv.org/pdf/1801.08099v8",
    "categories": [
      "cs.LG",
      "cs.LO"
    ]
  },
  {
    "arxiv_id": "2401.15480v2",
    "title": "Social Interpretable Reinforcement Learning",
    "authors": [
      "Leonardo Lucio Custode",
      "Giovanni Iacca"
    ],
    "abstract": "Reinforcement Learning (RL) bears the promise of being a game-changer in many\napplications. However, since most of the literature in the field is currently\nfocused on opaque models, the use of RL in high-stakes scenarios, where\ninterpretability is crucial, is still limited. Recently, some approaches to\ninterpretable RL, e.g., based on Decision Trees, have been proposed, but one of\nthe main limitations of these techniques is their training cost. To overcome\nthis limitation, we propose a new method, called Social Interpretable RL\n(SIRL), that can substantially reduce the number of episodes needed for\ntraining. Our method mimics a social learning process, where each agent in a\ngroup learns to solve a given task based both on its own individual experience\nas well as the experience acquired together with its peers. Our approach is\ndivided into the following two phases. (1) In the collaborative phase, all the\nagents in the population interact with a shared instance of the environment,\nwhere each agent observes the state and independently proposes an action. Then,\nvoting is performed to choose the action that will actually be deployed in the\nenvironment. (2) In the individual phase, then, each agent refines its\nindividual performance by interacting with its own instance of the environment.\nThis mechanism makes the agents experience a larger number of episodes with\nlittle impact on the computational cost of the process. Our results (on 6\nwidely-known RL benchmarks) show that SIRL not only reduces the computational\ncost by a factor varying from a minimum of 43% to a maximum 76%, but it also\nincreases the convergence speed and, often, improves the quality of the\nsolutions.",
    "published": "2024-01-27T19:05:21Z",
    "pdf_url": "http://arxiv.org/pdf/2401.15480v2",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA",
      "I.2.6; I.2.8"
    ]
  },
  {
    "arxiv_id": "1909.11939v6",
    "title": "MERL: Multi-Head Reinforcement Learning",
    "authors": [
      "Yannis Flet-Berliac",
      "Philippe Preux"
    ],
    "abstract": "A common challenge in reinforcement learning is how to convert the agent's\ninteractions with an environment into fast and robust learning. For instance,\nearlier work makes use of domain knowledge to improve existing reinforcement\nlearning algorithms in complex tasks. While promising, previously acquired\nknowledge is often costly and challenging to scale up. Instead, we decide to\nconsider problem knowledge with signals from quantities relevant to solve any\ntask, e.g., self-performance assessment and accurate expectations.\n$\\mathcal{V}^{ex}$ is such a quantity. It is the fraction of variance explained\nby the value function $V$ and measures the discrepancy between $V$ and the\nreturns. Taking advantage of $\\mathcal{V}^{ex}$, we propose MERL, a general\nframework for structuring reinforcement learning by injecting problem knowledge\ninto policy gradient updates. As a result, the agent is not only optimized for\na reward but learns using problem-focused quantities provided by MERL,\napplicable out-of-the-box to any task. In this paper: (a) We introduce and\ndefine MERL, the multi-head reinforcement learning framework we use throughout\nthis work. (b) We conduct experiments across a variety of standard benchmark\nenvironments, including 9 continuous control tasks, where results show improved\nperformance. (c) We demonstrate that MERL also improves transfer learning on a\nset of challenging pixel-based tasks. (d) We ponder how MERL tackles the\nproblem of reward sparsity and better conditions the feature space of\nreinforcement learning agents.",
    "published": "2019-09-26T06:57:51Z",
    "pdf_url": "http://arxiv.org/pdf/1909.11939v6",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2007.04725v2",
    "title": "EVO-RL: Evolutionary-Driven Reinforcement Learning",
    "authors": [
      "Ahmed Hallawa",
      "Thorsten Born",
      "Anke Schmeink",
      "Guido Dartmann",
      "Arne Peine",
      "Lukas Martin",
      "Giovanni Iacca",
      "A. E. Eiben",
      "Gerd Ascheid"
    ],
    "abstract": "In this work, we propose a novel approach for reinforcement learning driven\nby evolutionary computation. Our algorithm, dubbed as Evolutionary-Driven\nReinforcement Learning (evo-RL), embeds the reinforcement learning algorithm in\nan evolutionary cycle, where we distinctly differentiate between purely\nevolvable (instinctive) behaviour versus purely learnable behaviour.\nFurthermore, we propose that this distinction is decided by the evolutionary\nprocess, thus allowing evo-RL to be adaptive to different environments. In\naddition, evo-RL facilitates learning on environments with rewardless states,\nwhich makes it more suited for real-world problems with incomplete information.\nTo show that evo-RL leads to state-of-the-art performance, we present the\nperformance of different state-of-the-art reinforcement learning algorithms\nwhen operating within evo-RL and compare it with the case when these same\nalgorithms are executed independently. Results show that reinforcement learning\nalgorithms embedded within our evo-RL approach significantly outperform the\nstand-alone versions of the same RL algorithms on OpenAI Gym control problems\nwith rewardless states constrained by the same computational budget.",
    "published": "2020-07-09T11:52:19Z",
    "pdf_url": "http://arxiv.org/pdf/2007.04725v2",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1703.09842v3",
    "title": "Inverse Risk-Sensitive Reinforcement Learning",
    "authors": [
      "Lillian J. Ratliff",
      "Eric Mazumdar"
    ],
    "abstract": "We address the problem of inverse reinforcement learning in Markov decision\nprocesses where the agent is risk-sensitive. In particular, we model\nrisk-sensitivity in a reinforcement learning framework by making use of models\nof human decision-making having their origins in behavioral psychology,\nbehavioral economics, and neuroscience. We propose a gradient-based inverse\nreinforcement learning algorithm that minimizes a loss function defined on the\nobserved behavior. We demonstrate the performance of the proposed technique on\ntwo examples, the first of which is the canonical Grid World example and the\nsecond of which is a Markov decision process modeling passengers' decisions\nregarding ride-sharing. In the latter, we use pricing and travel time data from\na ride-sharing company to construct the transition probabilities and rewards of\nthe Markov decision process.",
    "published": "2017-03-29T00:10:17Z",
    "pdf_url": "http://arxiv.org/pdf/1703.09842v3",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1701.07274v6",
    "title": "Deep Reinforcement Learning: An Overview",
    "authors": [
      "Yuxi Li"
    ],
    "abstract": "We give an overview of recent exciting achievements of deep reinforcement\nlearning (RL). We discuss six core elements, six important mechanisms, and\ntwelve applications. We start with background of machine learning, deep\nlearning and reinforcement learning. Next we discuss core RL elements,\nincluding value function, in particular, Deep Q-Network (DQN), policy, reward,\nmodel, planning, and exploration. After that, we discuss important mechanisms\nfor RL, including attention and memory, unsupervised learning, transfer\nlearning, multi-agent RL, hierarchical RL, and learning to learn. Then we\ndiscuss various applications of RL, including games, in particular, AlphaGo,\nrobotics, natural language processing, including dialogue systems, machine\ntranslation, and text generation, computer vision, neural architecture design,\nbusiness management, finance, healthcare, Industry 4.0, smart grid, intelligent\ntransportation systems, and computer systems. We mention topics not reviewed\nyet, and list a collection of RL resources. After presenting a brief summary,\nwe close with discussions.\n  Please see Deep Reinforcement Learning, arXiv:1810.06339, for a significant\nupdate.",
    "published": "2017-01-25T11:52:11Z",
    "pdf_url": "http://arxiv.org/pdf/1701.07274v6",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2305.04843v1",
    "title": "Reinforcement Learning for Topic Models",
    "authors": [
      "Jeremy Costello",
      "Marek Z. Reformat"
    ],
    "abstract": "We apply reinforcement learning techniques to topic modeling by replacing the\nvariational autoencoder in ProdLDA with a continuous action space reinforcement\nlearning policy. We train the system with a policy gradient algorithm\nREINFORCE. Additionally, we introduced several modifications: modernize the\nneural network architecture, weight the ELBO loss, use contextual embeddings,\nand monitor the learning process via computing topic diversity and coherence\nfor each training step. Experiments are performed on 11 data sets. Our\nunsupervised model outperforms all other unsupervised models and performs on\npar with or better than most models using supervised labeling. Our model is\noutperformed on certain data sets by a model using supervised labeling and\ncontrastive learning. We have also conducted an ablation study to provide\nempirical evidence of performance improvements from changes we made to ProdLDA\nand found that the reinforcement learning formulation boosts performance.",
    "published": "2023-05-08T16:41:08Z",
    "pdf_url": "http://arxiv.org/pdf/2305.04843v1",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2007.00425v1",
    "title": "Interaction-limited Inverse Reinforcement Learning",
    "authors": [
      "Martin Troussard",
      "Emmanuel Pignat",
      "Parameswaran Kamalaruban",
      "Sylvain Calinon",
      "Volkan Cevher"
    ],
    "abstract": "This paper proposes an inverse reinforcement learning (IRL) framework to\naccelerate learning when the learner-teacher \\textit{interaction} is\n\\textit{limited} during training. Our setting is motivated by the realistic\nscenarios where a helpful teacher is not available or when the teacher cannot\naccess the learning dynamics of the student. We present two different training\nstrategies: Curriculum Inverse Reinforcement Learning (CIRL) covering the\nteacher's perspective, and Self-Paced Inverse Reinforcement Learning (SPIRL)\nfocusing on the learner's perspective. Using experiments in simulations and\nexperiments with a real robot learning a task from a human demonstrator, we\nshow that our training strategies can allow a faster training than a random\nteacher for CIRL and than a batch learner for SPIRL.",
    "published": "2020-07-01T12:31:52Z",
    "pdf_url": "http://arxiv.org/pdf/2007.00425v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2311.04830v3",
    "title": "Real-Time Recurrent Reinforcement Learning",
    "authors": [
      "Julian Lemmel",
      "Radu Grosu"
    ],
    "abstract": "We introduce a biologically plausible RL framework for solving tasks in\npartially observable Markov decision processes (POMDPs). The proposed algorithm\ncombines three integral parts: (1) A Meta-RL architecture, resembling the\nmammalian basal ganglia; (2) A biologically plausible reinforcement learning\nalgorithm, exploiting temporal difference learning and eligibility traces to\ntrain the policy and the value-function; (3) An online automatic\ndifferentiation algorithm for computing the gradients with respect to\nparameters of a shared recurrent network backbone. Our experimental results\nshow that the method is capable of solving a diverse set of partially\nobservable reinforcement learning tasks. The algorithm we call real-time\nrecurrent reinforcement learning (RTRRL) serves as a model of learning in\nbiological neural networks, mimicking reward pathways in the basal ganglia.",
    "published": "2023-11-08T16:56:16Z",
    "pdf_url": "http://arxiv.org/pdf/2311.04830v3",
    "categories": [
      "cs.LG",
      "cs.NE",
      "cs.SY",
      "eess.SY"
    ]
  },
  {
    "arxiv_id": "2405.13574v1",
    "title": "Reinforcement Learning for Adaptive MCMC",
    "authors": [
      "Congye Wang",
      "Wilson Chen",
      "Heishiro Kanagawa",
      "Chris. J. Oates"
    ],
    "abstract": "An informal observation, made by several authors, is that the adaptive design\nof a Markov transition kernel has the flavour of a reinforcement learning task.\nYet, to-date it has remained unclear how to actually exploit modern\nreinforcement learning technologies for adaptive MCMC. The aim of this paper is\nto set out a general framework, called Reinforcement Learning\nMetropolis--Hastings, that is theoretically supported and empirically\nvalidated. Our principal focus is on learning fast-mixing Metropolis--Hastings\ntransition kernels, which we cast as deterministic policies and optimise via a\npolicy gradient. Control of the learning rate provably ensures conditions for\nergodicity are satisfied. The methodology is used to construct a gradient-free\nsampler that out-performs a popular gradient-free adaptive Metropolis--Hastings\nalgorithm on $\\approx 90 \\%$ of tasks in the PosteriorDB benchmark.",
    "published": "2024-05-22T12:11:12Z",
    "pdf_url": "http://arxiv.org/pdf/2405.13574v1",
    "categories": [
      "stat.CO",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2406.08406v1",
    "title": "RRLS : Robust Reinforcement Learning Suite",
    "authors": [
      "Adil Zouitine",
      "David Bertoin",
      "Pierre Clavier",
      "Matthieu Geist",
      "Emmanuel Rachelson"
    ],
    "abstract": "Robust reinforcement learning is the problem of learning control policies\nthat provide optimal worst-case performance against a span of adversarial\nenvironments. It is a crucial ingredient for deploying algorithms in real-world\nscenarios with prevalent environmental uncertainties and has been a\nlong-standing object of attention in the community, without a standardized set\nof benchmarks. This contribution endeavors to fill this gap. We introduce the\nRobust Reinforcement Learning Suite (RRLS), a benchmark suite based on Mujoco\nenvironments. RRLS provides six continuous control tasks with two types of\nuncertainty sets for training and evaluation. Our benchmark aims to standardize\nrobust reinforcement learning tasks, facilitating reproducible and comparable\nexperiments, in particular those from recent state-of-the-art contributions,\nfor which we demonstrate the use of RRLS. It is also designed to be easily\nexpandable to new environments. The source code is available at\n\\href{https://github.com/SuReLI/RRLS}{https://github.com/SuReLI/RRLS}.",
    "published": "2024-06-12T16:53:51Z",
    "pdf_url": "http://arxiv.org/pdf/2406.08406v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2407.10583v1",
    "title": "Three Dogmas of Reinforcement Learning",
    "authors": [
      "David Abel",
      "Mark K. Ho",
      "Anna Harutyunyan"
    ],
    "abstract": "Modern reinforcement learning has been conditioned by at least three dogmas.\nThe first is the environment spotlight, which refers to our tendency to focus\non modeling environments rather than agents. The second is our treatment of\nlearning as finding the solution to a task, rather than adaptation. The third\nis the reward hypothesis, which states that all goals and purposes can be well\nthought of as maximization of a reward signal. These three dogmas shape much of\nwhat we think of as the science of reinforcement learning. While each of the\ndogmas have played an important role in developing the field, it is time we\nbring them to the surface and reflect on whether they belong as basic\ningredients of our scientific paradigm. In order to realize the potential of\nreinforcement learning as a canonical frame for researching intelligent agents,\nwe suggest that it is time we shed dogmas one and two entirely, and embrace a\nnuanced approach to the third.",
    "published": "2024-07-15T10:03:24Z",
    "pdf_url": "http://arxiv.org/pdf/2407.10583v1",
    "categories": [
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2508.00106v1",
    "title": "Hyperproperty-Constrained Secure Reinforcement Learning",
    "authors": [
      "Ernest Bonnah",
      "Luan Viet Nguyen",
      "Khaza Anuarul Hoque"
    ],
    "abstract": "Hyperproperties for Time Window Temporal Logic (HyperTWTL) is a\ndomain-specific formal specification language known for its effectiveness in\ncompactly representing security, opacity, and concurrency properties for\nrobotics applications. This paper focuses on HyperTWTL-constrained secure\nreinforcement learning (SecRL). Although temporal logic-constrained safe\nreinforcement learning (SRL) is an evolving research problem with several\nexisting literature, there is a significant research gap in exploring\nsecurity-aware reinforcement learning (RL) using hyperproperties. Given the\ndynamics of an agent as a Markov Decision Process (MDP) and opacity/security\nconstraints formalized as HyperTWTL, we propose an approach for learning\nsecurity-aware optimal policies using dynamic Boltzmann softmax RL while\nsatisfying the HyperTWTL constraints. The effectiveness and scalability of our\nproposed approach are demonstrated using a pick-up and delivery robotic mission\ncase study. We also compare our results with two other baseline RL algorithms,\nshowing that our proposed method outperforms them.",
    "published": "2025-07-31T18:57:18Z",
    "pdf_url": "http://arxiv.org/pdf/2508.00106v1",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.LO",
      "cs.SY",
      "eess.SY"
    ]
  },
  {
    "arxiv_id": "1305.1809v2",
    "title": "Cover Tree Bayesian Reinforcement Learning",
    "authors": [
      "Nikolaos Tziortziotis",
      "Christos Dimitrakakis",
      "Konstantinos Blekas"
    ],
    "abstract": "This paper proposes an online tree-based Bayesian approach for reinforcement\nlearning. For inference, we employ a generalised context tree model. This\ndefines a distribution on multivariate Gaussian piecewise-linear models, which\ncan be updated in closed form. The tree structure itself is constructed using\nthe cover tree method, which remains efficient in high dimensional spaces. We\ncombine the model with Thompson sampling and approximate dynamic programming to\nobtain effective exploration policies in unknown environments. The flexibility\nand computational simplicity of the model render it suitable for many\nreinforcement learning problems in continuous state spaces. We demonstrate this\nin an experimental comparison with least squares policy iteration.",
    "published": "2013-05-08T13:11:52Z",
    "pdf_url": "http://arxiv.org/pdf/1305.1809v2",
    "categories": [
      "stat.ML",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1809.09501v1",
    "title": "Anderson Acceleration for Reinforcement Learning",
    "authors": [
      "Matthieu Geist",
      "Bruno Scherrer"
    ],
    "abstract": "Anderson acceleration is an old and simple method for accelerating the\ncomputation of a fixed point. However, as far as we know and quite\nsurprisingly, it has never been applied to dynamic programming or reinforcement\nlearning. In this paper, we explain briefly what Anderson acceleration is and\nhow it can be applied to value iteration, this being supported by preliminary\nexperiments showing a significant speed up of convergence, that we critically\ndiscuss. We also discuss how this idea could be applied more generally to\n(deep) reinforcement learning.",
    "published": "2018-09-25T14:04:25Z",
    "pdf_url": "http://arxiv.org/pdf/1809.09501v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1610.02707v1",
    "title": "Multi-Objective Deep Reinforcement Learning",
    "authors": [
      "Hossam Mossalam",
      "Yannis M. Assael",
      "Diederik M. Roijers",
      "Shimon Whiteson"
    ],
    "abstract": "We propose Deep Optimistic Linear Support Learning (DOL) to solve\nhigh-dimensional multi-objective decision problems where the relative\nimportances of the objectives are not known a priori. Using features from the\nhigh-dimensional inputs, DOL computes the convex coverage set containing all\npotential optimal solutions of the convex combinations of the objectives. To\nour knowledge, this is the first time that deep reinforcement learning has\nsucceeded in learning multi-objective policies. In addition, we provide a\ntestbed with two experiments to be used as a benchmark for deep multi-objective\nreinforcement learning.",
    "published": "2016-10-09T19:08:36Z",
    "pdf_url": "http://arxiv.org/pdf/1610.02707v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1809.06995v1",
    "title": "Interpretable Reinforcement Learning with Ensemble Methods",
    "authors": [
      "Alexander Brown",
      "Marek Petrik"
    ],
    "abstract": "We propose to use boosted regression trees as a way to compute\nhuman-interpretable solutions to reinforcement learning problems. Boosting\ncombines several regression trees to improve their accuracy without\nsignificantly reducing their inherent interpretability. Prior work has focused\nindependently on reinforcement learning and on interpretable machine learning,\nbut there has been little progress in interpretable reinforcement learning. Our\nexperimental results show that boosted regression trees compute solutions that\nare both interpretable and match the quality of leading reinforcement learning\nmethods.",
    "published": "2018-09-19T03:23:35Z",
    "pdf_url": "http://arxiv.org/pdf/1809.06995v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2001.09608v1",
    "title": "Some Insights into Lifelong Reinforcement Learning Systems",
    "authors": [
      "Changjian Li"
    ],
    "abstract": "A lifelong reinforcement learning system is a learning system that has the\nability to learn through trail-and-error interaction with the environment over\nits lifetime. In this paper, I give some arguments to show that the traditional\nreinforcement learning paradigm fails to model this type of learning system.\nSome insights into lifelong reinforcement learning are provided, along with a\nsimplistic prototype lifelong reinforcement learning system.",
    "published": "2020-01-27T07:26:12Z",
    "pdf_url": "http://arxiv.org/pdf/2001.09608v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1608.02971v1",
    "title": "Neuroevolution-Based Inverse Reinforcement Learning",
    "authors": [
      "Karan K. Budhraja",
      "Tim Oates"
    ],
    "abstract": "The problem of Learning from Demonstration is targeted at learning to perform\ntasks based on observed examples. One approach to Learning from Demonstration\nis Inverse Reinforcement Learning, in which actions are observed to infer\nrewards. This work combines a feature based state evaluation approach to\nInverse Reinforcement Learning with neuroevolution, a paradigm for modifying\nneural networks based on their performance on a given task. Neural networks are\nused to learn from a demonstrated expert policy and are evolved to generate a\npolicy similar to the demonstration. The algorithm is discussed and evaluated\nagainst competitive feature-based Inverse Reinforcement Learning approaches. At\nthe cost of execution time, neural networks allow for non-linear combinations\nof features in state evaluations. These valuations may correspond to state\nvalue or state reward. This results in better correspondence to observed\nexamples as opposed to using linear combinations. This work also extends\nexisting work on Bayesian Non-Parametric Feature Construction for Inverse\nReinforcement Learning by using non-linear combinations of intermediate data to\nimprove performance. The algorithm is observed to be specifically suitable for\na linearly solvable non-deterministic Markov Decision Processes in which\nmultiple rewards are sparsely scattered in state space. A conclusive\nperformance hierarchy between evaluated algorithms is presented.",
    "published": "2016-08-09T20:04:40Z",
    "pdf_url": "http://arxiv.org/pdf/1608.02971v1",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1908.11494v4",
    "title": "Reinforcement learning with world model",
    "authors": [
      "Jingbin Liu",
      "Xinyang Gu",
      "Shuai Liu"
    ],
    "abstract": "Nowadays, model-free reinforcement learning algorithms have achieved\nremarkable performance on many decision making and control tasks, but high\nsample complexity and low sample efficiency still hinder the wide use of\nmodel-free reinforcement learning algorithms. In this paper, we argue that if\nwe intend to design an intelligent agent that learns fast and transfers well,\nthe agent must be able to reflect key elements of intelligence, like intuition,\nMemory, PredictionandCuriosity. We propose an agent framework that integrates\noff-policy reinforcement learning with world model learning, so as to embody\nthe important features of intelligence in our algorithm design. We adopt the\nstate-of-art model-free reinforcement learning algorithm, Soft Actor-Critic, as\nthe agent intuition, and world model learning through RNN to endow the agent\nwith memory, curiosity, and the ability to predict. We show that these ideas\ncan work collaboratively with each other and our agent (RMC) can give new\nstate-of-art results while maintaining sample efficiency and training\nstability. Moreover, our agent framework can be easily extended from MDP to\nPOMDP problems without performance loss.",
    "published": "2019-08-30T00:29:32Z",
    "pdf_url": "http://arxiv.org/pdf/1908.11494v4",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2202.05839v3",
    "title": "Abstraction for Deep Reinforcement Learning",
    "authors": [
      "Murray Shanahan",
      "Melanie Mitchell"
    ],
    "abstract": "We characterise the problem of abstraction in the context of deep\nreinforcement learning. Various well established approaches to analogical\nreasoning and associative memory might be brought to bear on this issue, but\nthey present difficulties because of the need for end-to-end differentiability.\nWe review developments in AI and machine learning that could facilitate their\nadoption.",
    "published": "2022-02-10T23:49:13Z",
    "pdf_url": "http://arxiv.org/pdf/2202.05839v3",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2304.01315v2",
    "title": "Empirical Design in Reinforcement Learning",
    "authors": [
      "Andrew Patterson",
      "Samuel Neumann",
      "Martha White",
      "Adam White"
    ],
    "abstract": "Empirical design in reinforcement learning is no small task. Running good\nexperiments requires attention to detail and at times significant computational\nresources. While compute resources available per dollar have continued to grow\nrapidly, so have the scale of typical experiments in reinforcement learning. It\nis now common to benchmark agents with millions of parameters against dozens of\ntasks, each using the equivalent of 30 days of experience. The scale of these\nexperiments often conflict with the need for proper statistical evidence,\nespecially when comparing algorithms. Recent studies have highlighted how\npopular algorithms are sensitive to hyper-parameter settings and implementation\ndetails, and that common empirical practice leads to weak statistical evidence\n(Machado et al., 2018; Henderson et al., 2018). Here we take this one step\nfurther.\n  This manuscript represents both a call to action, and a comprehensive\nresource for how to do good experiments in reinforcement learning. In\nparticular, we cover: the statistical assumptions underlying common performance\nmeasures, how to properly characterize performance variation and stability,\nhypothesis testing, special considerations for comparing multiple agents,\nbaseline and illustrative example construction, and how to deal with\nhyper-parameters and experimenter bias. Throughout we highlight common mistakes\nfound in the literature and the statistical consequences of those in example\nexperiments. The objective of this document is to provide answers on how we can\nuse our unprecedented compute to do good science in reinforcement learning, as\nwell as stay alert to potential pitfalls in our empirical design.",
    "published": "2023-04-03T19:32:24Z",
    "pdf_url": "http://arxiv.org/pdf/2304.01315v2",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2410.00704v1",
    "title": "Contrastive Abstraction for Reinforcement Learning",
    "authors": [
      "Vihang Patil",
      "Markus Hofmarcher",
      "Elisabeth Rumetshofer",
      "Sepp Hochreiter"
    ],
    "abstract": "Learning agents with reinforcement learning is difficult when dealing with\nlong trajectories that involve a large number of states. To address these\nlearning problems effectively, the number of states can be reduced by abstract\nrepresentations that cluster states. In principle, deep reinforcement learning\ncan find abstract states, but end-to-end learning is unstable. We propose\ncontrastive abstraction learning to find abstract states, where we assume that\nsuccessive states in a trajectory belong to the same abstract state. Such\nabstract states may be basic locations, achieved subgoals, inventory, or health\nconditions. Contrastive abstraction learning first constructs clusters of state\nrepresentations by contrastive learning and then applies modern Hopfield\nnetworks to determine the abstract states. The first phase of contrastive\nabstraction learning is self-supervised learning, where contrastive learning\nforces states with sequential proximity to have similar representations. The\nsecond phase uses modern Hopfield networks to map similar state representations\nto the same fixed point, i.e.\\ to an abstract state. The level of abstraction\ncan be adjusted by determining the number of fixed points of the modern\nHopfield network. Furthermore, \\textit{contrastive abstraction learning} does\nnot require rewards and facilitates efficient reinforcement learning for a wide\nrange of downstream tasks. Our experiments demonstrate the effectiveness of\ncontrastive abstraction learning for reinforcement learning.",
    "published": "2024-10-01T13:56:09Z",
    "pdf_url": "http://arxiv.org/pdf/2410.00704v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1709.05067v1",
    "title": "Deep Reinforcement Learning for Conversational AI",
    "authors": [
      "Mahipal Jadeja",
      "Neelanshi Varia",
      "Agam Shah"
    ],
    "abstract": "Deep reinforcement learning is revolutionizing the artificial intelligence\nfield. Currently, it serves as a good starting point for constructing\nintelligent autonomous systems which offer a better knowledge of the visual\nworld. It is possible to scale deep reinforcement learning with the use of deep\nlearning and do amazing tasks such as use of pixels in playing video games. In\nthis paper, key concepts of deep reinforcement learning including reward\nfunction, differences between reinforcement learning and supervised learning\nand models for implementation of reinforcement are discussed. Key challenges\nrelated to the implementation of reinforcement learning in conversational AI\ndomain are identified as well as discussed in detail. Various conversational\nmodels which are based on deep reinforcement learning (as well as deep\nlearning) are also discussed. In summary, this paper discusses key aspects of\ndeep reinforcement learning which are crucial for designing an efficient\nconversational AI.",
    "published": "2017-09-15T06:18:33Z",
    "pdf_url": "http://arxiv.org/pdf/1709.05067v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2203.16464v3",
    "title": "Towards Interpretable Deep Reinforcement Learning Models via Inverse\n  Reinforcement Learning",
    "authors": [
      "Sean Xie",
      "Soroush Vosoughi",
      "Saeed Hassanpour"
    ],
    "abstract": "Artificial intelligence, particularly through recent advancements in deep\nlearning, has achieved exceptional performances in many tasks in fields such as\nnatural language processing and computer vision. In addition to desirable\nevaluation metrics, a high level of interpretability is often required for\nthese models to be reliably utilized. Therefore, explanations that offer\ninsight into the process by which a model maps its inputs onto its outputs are\nmuch sought-after. Unfortunately, the current black box nature of machine\nlearning models is still an unresolved issue and this very nature prevents\nresearchers from learning and providing explicative descriptions for a model's\nbehavior and final predictions. In this work, we propose a novel framework\nutilizing Adversarial Inverse Reinforcement Learning that can provide global\nexplanations for decisions made by a Reinforcement Learning model and capture\nintuitive tendencies that the model follows by summarizing the model's\ndecision-making process.",
    "published": "2022-03-30T17:01:59Z",
    "pdf_url": "http://arxiv.org/pdf/2203.16464v3",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1007.2049v1",
    "title": "Reinforcement Learning via AIXI Approximation",
    "authors": [
      "Joel Veness",
      "Kee Siong Ng",
      "Marcus Hutter",
      "David Silver"
    ],
    "abstract": "This paper introduces a principled approach for the design of a scalable\ngeneral reinforcement learning agent. This approach is based on a direct\napproximation of AIXI, a Bayesian optimality notion for general reinforcement\nlearning agents. Previously, it has been unclear whether the theory of AIXI\ncould motivate the design of practical algorithms. We answer this hitherto open\nquestion in the affirmative, by providing the first computationally feasible\napproximation to the AIXI agent. To develop our approximation, we introduce a\nMonte Carlo Tree Search algorithm along with an agent-specific extension of the\nContext Tree Weighting algorithm. Empirically, we present a set of encouraging\nresults on a number of stochastic, unknown, and partially observable domains.",
    "published": "2010-07-13T08:48:18Z",
    "pdf_url": "http://arxiv.org/pdf/1007.2049v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1108.3614v1",
    "title": "Feature Reinforcement Learning In Practice",
    "authors": [
      "Phuong Nguyen",
      "Peter Sunehag",
      "Marcus Hutter"
    ],
    "abstract": "Following a recent surge in using history-based methods for resolving\nperceptual aliasing in reinforcement learning, we introduce an algorithm based\non the feature reinforcement learning framework called PhiMDP. To create a\npractical algorithm we devise a stochastic search procedure for a class of\ncontext trees based on parallel tempering and a specialized proposal\ndistribution. We provide the first empirical evaluation for PhiMDP. Our\nproposed algorithm achieves superior performance to the classical U-tree\nalgorithm and the recent active-LZ algorithm, and is competitive with\nMC-AIXI-CTW that maintains a bayesian mixture over all context trees up to a\nchosen depth.We are encouraged by our ability to compete with this\nsophisticated method using an algorithm that simply picks one single model, and\nuses Q-learning on the corresponding MDP. Our PhiMDP algorithm is much simpler,\nyet consumes less time and memory. These results show promise for our future\nwork on attacking more complex and larger problems.",
    "published": "2011-08-18T03:50:35Z",
    "pdf_url": "http://arxiv.org/pdf/1108.3614v1",
    "categories": [
      "cs.AI",
      "cs.RO"
    ]
  },
  {
    "arxiv_id": "1206.6449v1",
    "title": "Monte Carlo Bayesian Reinforcement Learning",
    "authors": [
      "Yi Wang",
      "Kok Sung Won",
      "David Hsu",
      "Wee Sun Lee"
    ],
    "abstract": "Bayesian reinforcement learning (BRL) encodes prior knowledge of the world in\na model and represents uncertainty in model parameters by maintaining a\nprobability distribution over them. This paper presents Monte Carlo BRL\n(MC-BRL), a simple and general approach to BRL. MC-BRL samples a priori a\nfinite set of hypotheses for the model parameter values and forms a discrete\npartially observable Markov decision process (POMDP) whose state space is a\ncross product of the state space for the reinforcement learning task and the\nsampled model parameter space. The POMDP does not require conjugate\ndistributions for belief representation, as earlier works do, and can be solved\nrelatively easily with point-based approximation algorithms. MC-BRL naturally\nhandles both fully and partially observable worlds. Theoretical and\nexperimental results show that the discrete POMDP approximates the underlying\nBRL task well with guaranteed performance.",
    "published": "2012-06-27T19:59:59Z",
    "pdf_url": "http://arxiv.org/pdf/1206.6449v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1706.04711v2",
    "title": "Reinforcement Learning under Model Mismatch",
    "authors": [
      "Aurko Roy",
      "Huan Xu",
      "Sebastian Pokutta"
    ],
    "abstract": "We study reinforcement learning under model misspecification, where we do not\nhave access to the true environment but only to a reasonably close\napproximation to it. We address this problem by extending the framework of\nrobust MDPs to the model-free Reinforcement Learning setting, where we do not\nhave access to the model parameters, but can only sample states from it. We\ndefine robust versions of Q-learning, SARSA, and TD-learning and prove\nconvergence to an approximately optimal robust policy and approximate value\nfunction respectively. We scale up the robust algorithms to large MDPs via\nfunction approximation and prove convergence under two different settings. We\nprove convergence of robust approximate policy iteration and robust approximate\nvalue iteration for linear architectures (under mild assumptions). We also\ndefine a robust loss function, the mean squared robust projected Bellman error\nand give stochastic gradient descent algorithms that are guaranteed to converge\nto a local minimum.",
    "published": "2017-06-15T01:06:05Z",
    "pdf_url": "http://arxiv.org/pdf/1706.04711v2",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1803.00590v2",
    "title": "Hierarchical Imitation and Reinforcement Learning",
    "authors": [
      "Hoang M. Le",
      "Nan Jiang",
      "Alekh Agarwal",
      "Miroslav Dudík",
      "Yisong Yue",
      "Hal Daumé III"
    ],
    "abstract": "We study how to effectively leverage expert feedback to learn sequential\ndecision-making policies. We focus on problems with sparse rewards and long\ntime horizons, which typically pose significant challenges in reinforcement\nlearning. We propose an algorithmic framework, called hierarchical guidance,\nthat leverages the hierarchical structure of the underlying problem to\nintegrate different modes of expert interaction. Our framework can incorporate\ndifferent combinations of imitation learning (IL) and reinforcement learning\n(RL) at different levels, leading to dramatic reductions in both expert effort\nand cost of exploration. Using long-horizon benchmarks, including Montezuma's\nRevenge, we demonstrate that our approach can learn significantly faster than\nhierarchical RL, and be significantly more label-efficient than standard IL. We\nalso theoretically analyze labeling cost for certain instantiations of our\nframework.",
    "published": "2018-03-01T19:12:27Z",
    "pdf_url": "http://arxiv.org/pdf/1803.00590v2",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1805.07563v1",
    "title": "Reinforcement Learning of Theorem Proving",
    "authors": [
      "Cezary Kaliszyk",
      "Josef Urban",
      "Henryk Michalewski",
      "Mirek Olšák"
    ],
    "abstract": "We introduce a theorem proving algorithm that uses practically no domain\nheuristics for guiding its connection-style proof search. Instead, it runs many\nMonte-Carlo simulations guided by reinforcement learning from previous proof\nattempts. We produce several versions of the prover, parameterized by different\nlearning and guiding algorithms. The strongest version of the system is trained\non a large corpus of mathematical problems and evaluated on previously unseen\nproblems. The trained system solves within the same number of inferences over\n40% more problems than a baseline prover, which is an unusually high\nimprovement in this hard AI domain. To our knowledge this is the first time\nreinforcement learning has been convincingly applied to solving general\nmathematical problems on a large scale.",
    "published": "2018-05-19T10:05:43Z",
    "pdf_url": "http://arxiv.org/pdf/1805.07563v1",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.LO"
    ]
  },
  {
    "arxiv_id": "1812.05551v3",
    "title": "Exploration Conscious Reinforcement Learning Revisited",
    "authors": [
      "Lior Shani",
      "Yonathan Efroni",
      "Shie Mannor"
    ],
    "abstract": "The Exploration-Exploitation tradeoff arises in Reinforcement Learning when\none cannot tell if a policy is optimal. Then, there is a constant need to\nexplore new actions instead of exploiting past experience. In practice, it is\ncommon to resolve the tradeoff by using a fixed exploration mechanism, such as\n$\\epsilon$-greedy exploration or by adding Gaussian noise, while still trying\nto learn an optimal policy. In this work, we take a different approach and\nstudy exploration-conscious criteria, that result in optimal policies with\nrespect to the exploration mechanism. Solving these criteria, as we establish,\namounts to solving a surrogate Markov Decision Process. We continue and analyze\nproperties of exploration-conscious optimal policies and characterize two\ngeneral approaches to solve such criteria. Building on the approaches, we apply\nsimple changes in existing tabular and deep Reinforcement Learning algorithms\nand empirically demonstrate superior performance relatively to their\nnon-exploration-conscious counterparts, both for discrete and continuous action\nspaces.",
    "published": "2018-12-13T18:08:04Z",
    "pdf_url": "http://arxiv.org/pdf/1812.05551v3",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1908.03568v3",
    "title": "Behaviour Suite for Reinforcement Learning",
    "authors": [
      "Ian Osband",
      "Yotam Doron",
      "Matteo Hessel",
      "John Aslanides",
      "Eren Sezener",
      "Andre Saraiva",
      "Katrina McKinney",
      "Tor Lattimore",
      "Csaba Szepesvari",
      "Satinder Singh",
      "Benjamin Van Roy",
      "Richard Sutton",
      "David Silver",
      "Hado Van Hasselt"
    ],
    "abstract": "This paper introduces the Behaviour Suite for Reinforcement Learning, or\nbsuite for short. bsuite is a collection of carefully-designed experiments that\ninvestigate core capabilities of reinforcement learning (RL) agents with two\nobjectives. First, to collect clear, informative and scalable problems that\ncapture key issues in the design of general and efficient learning algorithms.\nSecond, to study agent behaviour through their performance on these shared\nbenchmarks. To complement this effort, we open source\ngithub.com/deepmind/bsuite, which automates evaluation and analysis of any\nagent on bsuite. This library facilitates reproducible and accessible research\non the core issues in RL, and ultimately the design of superior learning\nalgorithms. Our code is Python, and easy to use within existing projects. We\ninclude examples with OpenAI Baselines, Dopamine as well as new reference\nimplementations. Going forward, we hope to incorporate more excellent\nexperiments from the research community, and commit to a periodic review of\nbsuite from a committee of prominent researchers.",
    "published": "2019-08-09T08:34:08Z",
    "pdf_url": "http://arxiv.org/pdf/1908.03568v3",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1908.06012v1",
    "title": "Model-based Lookahead Reinforcement Learning",
    "authors": [
      "Zhang-Wei Hong",
      "Joni Pajarinen",
      "Jan Peters"
    ],
    "abstract": "Model-based Reinforcement Learning (MBRL) allows data-efficient learning\nwhich is required in real world applications such as robotics. However, despite\nthe impressive data-efficiency, MBRL does not achieve the final performance of\nstate-of-the-art Model-free Reinforcement Learning (MFRL) methods. We leverage\nthe strengths of both realms and propose an approach that obtains high\nperformance with a small amount of data. In particular, we combine MFRL and\nModel Predictive Control (MPC). While MFRL's strength in exploration allows us\nto train a better forward dynamics model for MPC, MPC improves the performance\nof the MFRL policy by sampling-based planning. The experimental results in\nstandard continuous control benchmarks show that our approach can achieve\nMFRL`s level of performance while being as data-efficient as MBRL.",
    "published": "2019-08-15T04:10:13Z",
    "pdf_url": "http://arxiv.org/pdf/1908.06012v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2004.11812v5",
    "title": "Self-Paced Deep Reinforcement Learning",
    "authors": [
      "Pascal Klink",
      "Carlo D'Eramo",
      "Jan Peters",
      "Joni Pajarinen"
    ],
    "abstract": "Curriculum reinforcement learning (CRL) improves the learning speed and\nstability of an agent by exposing it to a tailored series of tasks throughout\nlearning. Despite empirical successes, an open question in CRL is how to\nautomatically generate a curriculum for a given reinforcement learning (RL)\nagent, avoiding manual design. In this paper, we propose an answer by\ninterpreting the curriculum generation as an inference problem, where\ndistributions over tasks are progressively learned to approach the target task.\nThis approach leads to an automatic curriculum generation, whose pace is\ncontrolled by the agent, with solid theoretical motivation and easily\nintegrated with deep RL algorithms. In the conducted experiments, the curricula\ngenerated with the proposed algorithm significantly improve learning\nperformance across several environments and deep RL algorithms, matching or\noutperforming state-of-the-art existing CRL algorithms.",
    "published": "2020-04-24T15:48:07Z",
    "pdf_url": "http://arxiv.org/pdf/2004.11812v5",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2108.02323v3",
    "title": "Active Reinforcement Learning over MDPs",
    "authors": [
      "Qi Yang",
      "Peng Yang",
      "Ke Tang"
    ],
    "abstract": "The past decade has seen the rapid development of Reinforcement Learning,\nwhich acquires impressive performance with numerous training resources.\nHowever, one of the greatest challenges in RL is generalization efficiency\n(i.e., generalization performance in a unit time). This paper proposes a\nframework of Active Reinforcement Learning (ARL) over MDPs to improve\ngeneralization efficiency in a limited resource by instance selection. Given a\nnumber of instances, the algorithm chooses out valuable instances as training\nsets while training the policy, thereby costing fewer resources. Unlike\nexisting approaches, we attempt to actively select and use training data rather\nthan train on all the given data, thereby costing fewer resources. Furthermore,\nwe introduce a general instance evaluation metrics and selection mechanism into\nthe framework. Experiments results reveal that the proposed framework with\nProximal Policy Optimization as policy optimizer can effectively improve\ngeneralization efficiency than unselect-ed and unbiased selected methods.",
    "published": "2021-08-05T00:18:11Z",
    "pdf_url": "http://arxiv.org/pdf/2108.02323v3",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2001.11718v1",
    "title": "Locally Private Distributed Reinforcement Learning",
    "authors": [
      "Hajime Ono",
      "Tsubasa Takahashi"
    ],
    "abstract": "We study locally differentially private algorithms for reinforcement learning\nto obtain a robust policy that performs well across distributed private\nenvironments. Our algorithm protects the information of local agents' models\nfrom being exploited by adversarial reverse engineering. Since a local policy\nis strongly being affected by the individual environment, the output of the\nagent may release the private information unconsciously. In our proposed\nalgorithm, local agents update the model in their environments and report noisy\ngradients designed to satisfy local differential privacy (LDP) that gives a\nrigorous local privacy guarantee. By utilizing a set of reported noisy\ngradients, a central aggregator updates its model and delivers it to different\nlocal agents. In our empirical evaluation, we demonstrate how our method\nperforms well under LDP. To the best of our knowledge, this is the first work\nthat actualizes distributed reinforcement learning under LDP. This work enables\nus to obtain a robust agent that performs well across distributed private\nenvironments.",
    "published": "2020-01-31T09:03:23Z",
    "pdf_url": "http://arxiv.org/pdf/2001.11718v1",
    "categories": [
      "cs.LG",
      "cs.CR",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2202.04337v1",
    "title": "Scenario-Assisted Deep Reinforcement Learning",
    "authors": [
      "Raz Yerushalmi",
      "Guy Amir",
      "Achiya Elyasaf",
      "David Harel",
      "Guy Katz",
      "Assaf Marron"
    ],
    "abstract": "Deep reinforcement learning has proven remarkably useful in training agents\nfrom unstructured data. However, the opacity of the produced agents makes it\ndifficult to ensure that they adhere to various requirements posed by human\nengineers. In this work-in-progress report, we propose a technique for\nenhancing the reinforcement learning training process (specifically, its reward\ncalculation), in a way that allows human engineers to directly contribute their\nexpert knowledge, making the agent under training more likely to comply with\nvarious relevant constraints. Moreover, our proposed approach allows\nformulating these constraints using advanced model engineering techniques, such\nas scenario-based modeling. This mix of black-box learning-based tools with\nclassical modeling approaches could produce systems that are effective and\nefficient, but are also more transparent and maintainable. We evaluated our\ntechnique using a case-study from the domain of internet congestion control,\nobtaining promising results.",
    "published": "2022-02-09T08:46:13Z",
    "pdf_url": "http://arxiv.org/pdf/2202.04337v1",
    "categories": [
      "cs.LG",
      "cs.SE",
      "cs.SY",
      "eess.SY"
    ]
  },
  {
    "arxiv_id": "1709.02349v2",
    "title": "A Deep Reinforcement Learning Chatbot",
    "authors": [
      "Iulian V. Serban",
      "Chinnadhurai Sankar",
      "Mathieu Germain",
      "Saizheng Zhang",
      "Zhouhan Lin",
      "Sandeep Subramanian",
      "Taesup Kim",
      "Michael Pieper",
      "Sarath Chandar",
      "Nan Rosemary Ke",
      "Sai Rajeshwar",
      "Alexandre de Brebisson",
      "Jose M. R. Sotelo",
      "Dendi Suhubdy",
      "Vincent Michalski",
      "Alexandre Nguyen",
      "Joelle Pineau",
      "Yoshua Bengio"
    ],
    "abstract": "We present MILABOT: a deep reinforcement learning chatbot developed by the\nMontreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prize\ncompetition. MILABOT is capable of conversing with humans on popular small talk\ntopics through both speech and text. The system consists of an ensemble of\nnatural language generation and retrieval models, including template-based\nmodels, bag-of-words models, sequence-to-sequence neural network and latent\nvariable neural network models. By applying reinforcement learning to\ncrowdsourced data and real-world user interactions, the system has been trained\nto select an appropriate response from the models in its ensemble. The system\nhas been evaluated through A/B testing with real-world users, where it\nperformed significantly better than many competing systems. Due to its machine\nlearning architecture, the system is likely to improve with additional data.",
    "published": "2017-09-07T16:51:09Z",
    "pdf_url": "http://arxiv.org/pdf/1709.02349v2",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.NE",
      "stat.ML",
      "I.5.1; I.2.7"
    ]
  },
  {
    "arxiv_id": "1907.07503v1",
    "title": "Photonic architecture for reinforcement learning",
    "authors": [
      "Fulvio Flamini",
      "Arne Hamann",
      "Sofiène Jerbi",
      "Lea M. Trenkwalder",
      "Hendrik Poulsen Nautrup",
      "Hans J. Briegel"
    ],
    "abstract": "The last decade has seen an unprecedented growth in artificial intelligence\nand photonic technologies, both of which drive the limits of modern-day\ncomputing devices. In line with these recent developments, this work brings\ntogether the state of the art of both fields within the framework of\nreinforcement learning. We present the blueprint for a photonic implementation\nof an active learning machine incorporating contemporary algorithms such as\nSARSA, Q-learning, and projective simulation. We numerically investigate its\nperformance within typical reinforcement learning environments, showing that\nrealistic levels of experimental noise can be tolerated or even be beneficial\nfor the learning process. Remarkably, the architecture itself enables\nmechanisms of abstraction and generalization, two features which are often\nconsidered key ingredients for artificial intelligence. The proposed\narchitecture, based on single-photon evolution on a mesh of tunable\nbeamsplitters, is simple, scalable, and a first integration in portable systems\nappears to be within the reach of near-term technology.",
    "published": "2019-07-17T13:23:58Z",
    "pdf_url": "http://arxiv.org/pdf/1907.07503v1",
    "categories": [
      "quant-ph",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1909.04751v1",
    "title": "Reinforcement Learning and Video Games",
    "authors": [
      "Yue Zheng"
    ],
    "abstract": "Reinforcement learning has exceeded human-level performance in game playing\nAI with deep learning methods according to the experiments from DeepMind on Go\nand Atari games. Deep learning solves high dimension input problems which stop\nthe development of reinforcement for many years. This study uses both two\ntechniques to create several agents with different algorithms that successfully\nlearn to play T-rex Runner. Deep Q network algorithm and three types of\nimprovements are implemented to train the agent. The results from some of them\nare far from satisfactory but others are better than human experts. Batch\nnormalization is a method to solve internal covariate shift problems in deep\nneural network. The positive influence of this on reinforcement learning has\nalso been proved in this study.",
    "published": "2019-09-10T20:51:42Z",
    "pdf_url": "http://arxiv.org/pdf/1909.04751v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1910.02826v1",
    "title": "Self-Paced Contextual Reinforcement Learning",
    "authors": [
      "Pascal Klink",
      "Hany Abdulsamad",
      "Boris Belousov",
      "Jan Peters"
    ],
    "abstract": "Generalization and adaptation of learned skills to novel situations is a core\nrequirement for intelligent autonomous robots. Although contextual\nreinforcement learning provides a principled framework for learning and\ngeneralization of behaviors across related tasks, it generally relies on\nuninformed sampling of environments from an unknown, uncontrolled context\ndistribution, thus missing the benefits of structured, sequential learning. We\nintroduce a novel relative entropy reinforcement learning algorithm that gives\nthe agent the freedom to control the intermediate task distribution, allowing\nfor its gradual progression towards the target context distribution. Empirical\nevaluation shows that the proposed curriculum learning scheme drastically\nimproves sample efficiency and enables learning in scenarios with both broad\nand sharp target context distributions in which classical approaches perform\nsub-optimally.",
    "published": "2019-10-07T14:40:53Z",
    "pdf_url": "http://arxiv.org/pdf/1910.02826v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2011.00791v1",
    "title": "Cooperative Heterogeneous Deep Reinforcement Learning",
    "authors": [
      "Han Zheng",
      "Pengfei Wei",
      "Jing Jiang",
      "Guodong Long",
      "Qinghua Lu",
      "Chengqi Zhang"
    ],
    "abstract": "Numerous deep reinforcement learning agents have been proposed, and each of\nthem has its strengths and flaws. In this work, we present a Cooperative\nHeterogeneous Deep Reinforcement Learning (CHDRL) framework that can learn a\npolicy by integrating the advantages of heterogeneous agents. Specifically, we\npropose a cooperative learning framework that classifies heterogeneous agents\ninto two classes: global agents and local agents. Global agents are off-policy\nagents that can utilize experiences from the other agents. Local agents are\neither on-policy agents or population-based evolutionary algorithms (EAs)\nagents that can explore the local area effectively. We employ global agents,\nwhich are sample-efficient, to guide the learning of local agents so that local\nagents can benefit from sample-efficient agents and simultaneously maintain\ntheir advantages, e.g., stability. Global agents also benefit from effective\nlocal searches. Experimental studies on a range of continuous control tasks\nfrom the Mujoco benchmark show that CHDRL achieves better performance compared\nwith state-of-the-art baselines.",
    "published": "2020-11-02T07:39:09Z",
    "pdf_url": "http://arxiv.org/pdf/2011.00791v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1902.03079v4",
    "title": "Reinforcement Learning from Hierarchical Critics",
    "authors": [
      "Zehong Cao",
      "Chin-Teng Lin"
    ],
    "abstract": "In this study, we investigate the use of global information to speed up the\nlearning process and increase the cumulative rewards of reinforcement learning\n(RL) in competition tasks. Within the actor-critic RL, we introduce multiple\ncooperative critics from two levels of the hierarchy and propose a\nreinforcement learning from hierarchical critics (RLHC) algorithm. In our\napproach, each agent receives value information from local and global critics\nregarding a competition task and accesses multiple cooperative critics in a\ntop-down hierarchy. Thus, each agent not only receives low-level details but\nalso considers coordination from higher levels, thereby obtaining global\ninformation to improve the training performance. Then, we test the proposed\nRLHC algorithm against the benchmark algorithm, proximal policy optimisation\n(PPO), for two experimental scenarios performed in a Unity environment\nconsisting of tennis and soccer agents' competitions. The results showed that\nRLHC outperforms the benchmark on both competition tasks.",
    "published": "2019-02-08T13:55:11Z",
    "pdf_url": "http://arxiv.org/pdf/1902.03079v4",
    "categories": [
      "cs.LG",
      "cs.MA",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1906.00131v1",
    "title": "Decision-Making in Reinforcement Learning",
    "authors": [
      "Arsh Javed Rehman",
      "Pradeep Tomar"
    ],
    "abstract": "In this research work, probabilistic decision-making approaches are studied,\ne.g. Bayesian and Boltzmann strategies, along with various deterministic\nexploration strategies, e.g. greedy, epsilon-Greedy and random approaches. In\nthis research work, a comparative study has been done between probabilistic and\ndeterministic decision-making approaches, the experiments are performed in\nOpenAI gym environment, solving Cart Pole problem. This research work discusses\nabout the Bayesian approach to decision-making in deep reinforcement learning,\nand about dropout, how it can reduce the computational cost. All the\nexploration approaches are compared. It also discusses about the importance of\nexploration in deep reinforcement learning, and how improving exploration\nstrategies may help in science and technology. This research work shows how\nprobabilistic decision-making approaches are better in the long run as compared\nto the deterministic approaches. When there is uncertainty, Bayesian dropout\napproach proved to be better than all other approaches in this research work.",
    "published": "2019-06-01T02:36:42Z",
    "pdf_url": "http://arxiv.org/pdf/1906.00131v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2007.09998v3",
    "title": "Lagrangian Duality in Reinforcement Learning",
    "authors": [
      "Pranay Pasula"
    ],
    "abstract": "Although duality is used extensively in certain fields, such as supervised\nlearning in machine learning, it has been much less explored in others, such as\nreinforcement learning (RL). In this paper, we show how duality is involved in\na variety of RL work, from that which spearheaded the field, such as Richard\nBellman's value iteration, to that which was done within just the past few\nyears yet has already had significant impact, such as TRPO, A3C, and GAIL. We\nshow that duality is not uncommon in reinforcement learning, especially when\nvalue iteration, or dynamic programming, is used or when first or second order\napproximations are made to transform initially intractable problems into\ntractable convex programs.",
    "published": "2020-07-20T10:55:12Z",
    "pdf_url": "http://arxiv.org/pdf/2007.09998v3",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2008.06036v2",
    "title": "Reinforcement Learning with Trajectory Feedback",
    "authors": [
      "Yonathan Efroni",
      "Nadav Merlis",
      "Shie Mannor"
    ],
    "abstract": "The standard feedback model of reinforcement learning requires revealing the\nreward of every visited state-action pair. However, in practice, it is often\nthe case that such frequent feedback is not available. In this work, we take a\nfirst step towards relaxing this assumption and require a weaker form of\nfeedback, which we refer to as \\emph{trajectory feedback}. Instead of observing\nthe reward obtained after every action, we assume we only receive a score that\nrepresents the quality of the whole trajectory observed by the agent, namely,\nthe sum of all rewards obtained over this trajectory. We extend reinforcement\nlearning algorithms to this setting, based on least-squares estimation of the\nunknown reward, for both the known and unknown transition model cases, and\nstudy the performance of these algorithms by analyzing their regret. For cases\nwhere the transition model is unknown, we offer a hybrid optimistic-Thompson\nSampling approach that results in a tractable algorithm.",
    "published": "2020-08-13T17:49:18Z",
    "pdf_url": "http://arxiv.org/pdf/2008.06036v2",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2102.11329v2",
    "title": "Action Redundancy in Reinforcement Learning",
    "authors": [
      "Nir Baram",
      "Guy Tennenholtz",
      "Shie Mannor"
    ],
    "abstract": "Maximum Entropy (MaxEnt) reinforcement learning is a powerful learning\nparadigm which seeks to maximize return under entropy regularization. However,\naction entropy does not necessarily coincide with state entropy, e.g., when\nmultiple actions produce the same transition. Instead, we propose to maximize\nthe transition entropy, i.e., the entropy of next states. We show that\ntransition entropy can be described by two terms; namely, model-dependent\ntransition entropy and action redundancy. Particularly, we explore the latter\nin both deterministic and stochastic settings and develop tractable\napproximation methods in a near model-free setup. We construct algorithms to\nminimize action redundancy and demonstrate their effectiveness on a synthetic\nenvironment with multiple redundant actions as well as contemporary benchmarks\nin Atari and Mujoco. Our results suggest that action redundancy is a\nfundamental problem in reinforcement learning.",
    "published": "2021-02-22T19:47:26Z",
    "pdf_url": "http://arxiv.org/pdf/2102.11329v2",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2109.09037v1",
    "title": "Dual Behavior Regularized Reinforcement Learning",
    "authors": [
      "Chapman Siu",
      "Jason Traish",
      "Richard Yi Da Xu"
    ],
    "abstract": "Reinforcement learning has been shown to perform a range of complex tasks\nthrough interaction with an environment or collected leveraging experience.\nHowever, many of these approaches presume optimal or near optimal experiences\nor the presence of a consistent environment. In this work we propose dual,\nadvantage-based behavior policy based on counterfactual regret minimization. We\ndemonstrate the flexibility of this approach and how it can be adapted to\nonline contexts where the environment is available to collect experiences and a\nvariety of other contexts. We demonstrate this new algorithm can outperform\nseveral strong baseline models in different contexts based on a range of\ncontinuous environments. Additional ablations provide insights into how our\ndual behavior regularized reinforcement learning approach is designed compared\nwith other plausible modifications and demonstrates its ability to generalize.",
    "published": "2021-09-19T00:47:18Z",
    "pdf_url": "http://arxiv.org/pdf/2109.09037v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2110.15191v1",
    "title": "URLB: Unsupervised Reinforcement Learning Benchmark",
    "authors": [
      "Michael Laskin",
      "Denis Yarats",
      "Hao Liu",
      "Kimin Lee",
      "Albert Zhan",
      "Kevin Lu",
      "Catherine Cang",
      "Lerrel Pinto",
      "Pieter Abbeel"
    ],
    "abstract": "Deep Reinforcement Learning (RL) has emerged as a powerful paradigm to solve\na range of complex yet specific control tasks. Yet training generalist agents\nthat can quickly adapt to new tasks remains an outstanding challenge. Recent\nadvances in unsupervised RL have shown that pre-training RL agents with\nself-supervised intrinsic rewards can result in efficient adaptation. However,\nthese algorithms have been hard to compare and develop due to the lack of a\nunified benchmark. To this end, we introduce the Unsupervised Reinforcement\nLearning Benchmark (URLB). URLB consists of two phases: reward-free\npre-training and downstream task adaptation with extrinsic rewards. Building on\nthe DeepMind Control Suite, we provide twelve continuous control tasks from\nthree domains for evaluation and open-source code for eight leading\nunsupervised RL methods. We find that the implemented baselines make progress\nbut are not able to solve URLB and propose directions for future research.",
    "published": "2021-10-28T15:07:01Z",
    "pdf_url": "http://arxiv.org/pdf/2110.15191v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ]
  },
  {
    "arxiv_id": "2204.03973v1",
    "title": "Gradient dynamics in reinforcement learning",
    "authors": [
      "Riccardo Fabbricatore",
      "Vladimir V. Palyulin"
    ],
    "abstract": "Despite the success achieved by the analysis of supervised learning\nalgorithms in the framework of statistical mechanics, reinforcement learning\nhas remained largely untouched. Here we move towards closing the gap by\nanalyzing the dynamics of the policy gradient algorithm. For a convex problem,\nwe show that it obeys a drift-diffusion motion with coeffcients tuned by\nlearning rate. Furthermore, we propose a mapping between a non-convex\nreinforcement learning problem and a disordered system. This mapping enables us\nto show how the learning rate acts as an effective temperature and thus is\ncapable of smoothing rough landscapes, corroborating what is displayed by the\ndrift-diffusive description and paving the way for physics-inspired algorithmic\noptimization based on annealing procedures in disordered systems.",
    "published": "2022-04-08T10:01:54Z",
    "pdf_url": "http://arxiv.org/pdf/2204.03973v1",
    "categories": [
      "cond-mat.stat-mech",
      "cond-mat.dis-nn",
      "physics.comp-ph"
    ]
  },
  {
    "arxiv_id": "2205.05569v1",
    "title": "Delayed Reinforcement Learning by Imitation",
    "authors": [
      "Pierre Liotet",
      "Davide Maran",
      "Lorenzo Bisi",
      "Marcello Restelli"
    ],
    "abstract": "When the agent's observations or interactions are delayed, classic\nreinforcement learning tools usually fail. In this paper, we propose a simple\nyet new and efficient solution to this problem. We assume that, in the\nundelayed environment, an efficient policy is known or can be easily learned,\nbut the task may suffer from delays in practice and we thus want to take them\ninto account. We present a novel algorithm, Delayed Imitation with Dataset\nAggregation (DIDA), which builds upon imitation learning methods to learn how\nto act in a delayed environment from undelayed demonstrations. We provide a\ntheoretical analysis of the approach that will guide the practical design of\nDIDA. These results are also of general interest in the delayed reinforcement\nlearning literature by providing bounds on the performance between delayed and\nundelayed tasks, under smoothness conditions. We show empirically that DIDA\nobtains high performances with a remarkable sample efficiency on a variety of\ntasks, including robotic locomotion, classic control, and trading.",
    "published": "2022-05-11T15:27:33Z",
    "pdf_url": "http://arxiv.org/pdf/2205.05569v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2212.13769v1",
    "title": "Lexicographic Multi-Objective Reinforcement Learning",
    "authors": [
      "Joar Skalse",
      "Lewis Hammond",
      "Charlie Griffin",
      "Alessandro Abate"
    ],
    "abstract": "In this work we introduce reinforcement learning techniques for solving\nlexicographic multi-objective problems. These are problems that involve\nmultiple reward signals, and where the goal is to learn a policy that maximises\nthe first reward signal, and subject to this constraint also maximises the\nsecond reward signal, and so on. We present a family of both action-value and\npolicy gradient algorithms that can be used to solve such problems, and prove\nthat they converge to policies that are lexicographically optimal. We evaluate\nthe scalability and performance of these algorithms empirically, demonstrating\ntheir practical applicability. As a more specific application, we show how our\nalgorithms can be used to impose safety constraints on the behaviour of an\nagent, and compare their performance in this context with that of other\nconstrained reinforcement learning algorithms.",
    "published": "2022-12-28T10:22:36Z",
    "pdf_url": "http://arxiv.org/pdf/2212.13769v1",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2302.14176v1",
    "title": "Reinforcement Learning with Depreciating Assets",
    "authors": [
      "Taylor Dohmen",
      "Ashutosh Trivedi"
    ],
    "abstract": "A basic assumption of traditional reinforcement learning is that the value of\na reward does not change once it is received by an agent. The present work\nforgoes this assumption and considers the situation where the value of a reward\ndecays proportionally to the time elapsed since it was obtained. Emphasizing\nthe inflection point occurring at the time of payment, we use the term asset to\nrefer to a reward that is currently in the possession of an agent. Adopting\nthis language, we initiate the study of depreciating assets within the\nframework of infinite-horizon quantitative optimization. In particular, we\npropose a notion of asset depreciation, inspired by classical exponential\ndiscounting, where the value of an asset is scaled by a fixed discount factor\nat each time step after it is obtained by the agent. We formulate a\nBellman-style equational characterization of optimality in this context and\ndevelop a model-free reinforcement learning approach to obtain optimal\npolicies.",
    "published": "2023-02-27T22:28:58Z",
    "pdf_url": "http://arxiv.org/pdf/2302.14176v1",
    "categories": [
      "cs.AI",
      "cs.CE",
      "math.OC"
    ]
  },
  {
    "arxiv_id": "2304.09869v1",
    "title": "Evolving Constrained Reinforcement Learning Policy",
    "authors": [
      "Chengpeng Hu",
      "Jiyuan Pei",
      "Jialin Liu",
      "Xin Yao"
    ],
    "abstract": "Evolutionary algorithms have been used to evolve a population of actors to\ngenerate diverse experiences for training reinforcement learning agents, which\nhelps to tackle the temporal credit assignment problem and improves the\nexploration efficiency. However, when adapting this approach to address\nconstrained problems, balancing the trade-off between the reward and constraint\nviolation is hard. In this paper, we propose a novel evolutionary constrained\nreinforcement learning (ECRL) algorithm, which adaptively balances the reward\nand constraint violation with stochastic ranking, and at the same time,\nrestricts the policy's behaviour by maintaining a set of Lagrange relaxation\ncoefficients with a constraint buffer. Extensive experiments on robotic control\nbenchmarks show that our ECRL achieves outstanding performance compared to\nstate-of-the-art algorithms. Ablation analysis shows the benefits of\nintroducing stochastic ranking and constraint buffer.",
    "published": "2023-04-19T03:54:31Z",
    "pdf_url": "http://arxiv.org/pdf/2304.09869v1",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2304.14421v1",
    "title": "One-Step Distributional Reinforcement Learning",
    "authors": [
      "Mastane Achab",
      "Reda Alami",
      "Yasser Abdelaziz Dahou Djilali",
      "Kirill Fedyanin",
      "Eric Moulines"
    ],
    "abstract": "Reinforcement learning (RL) allows an agent interacting sequentially with an\nenvironment to maximize its long-term expected return. In the distributional RL\n(DistrRL) paradigm, the agent goes beyond the limit of the expected value, to\ncapture the underlying probability distribution of the return across all time\nsteps. The set of DistrRL algorithms has led to improved empirical performance.\nNevertheless, the theory of DistrRL is still not fully understood, especially\nin the control case. In this paper, we present the simpler one-step\ndistributional reinforcement learning (OS-DistrRL) framework encompassing only\nthe randomness induced by the one-step dynamics of the environment. Contrary to\nDistrRL, we show that our approach comes with a unified theory for both policy\nevaluation and control. Indeed, we propose two OS-DistrRL algorithms for which\nwe provide an almost sure convergence analysis. The proposed approach compares\nfavorably with categorical DistrRL on various environments.",
    "published": "2023-04-27T06:57:00Z",
    "pdf_url": "http://arxiv.org/pdf/2304.14421v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2402.09900v3",
    "title": "Recurrent Reinforcement Learning with Memoroids",
    "authors": [
      "Steven Morad",
      "Chris Lu",
      "Ryan Kortvelesy",
      "Stephan Liwicki",
      "Jakob Foerster",
      "Amanda Prorok"
    ],
    "abstract": "Memory models such as Recurrent Neural Networks (RNNs) and Transformers\naddress Partially Observable Markov Decision Processes (POMDPs) by mapping\ntrajectories to latent Markov states. Neither model scales particularly well to\nlong sequences, especially compared to an emerging class of memory models\ncalled Linear Recurrent Models. We discover that the recurrent update of these\nmodels resembles a monoid, leading us to reformulate existing models using a\nnovel monoid-based framework that we call memoroids. We revisit the traditional\napproach to batching in recurrent reinforcement learning, highlighting\ntheoretical and empirical deficiencies. We leverage memoroids to propose a\nbatching method that improves sample efficiency, increases the return, and\nsimplifies the implementation of recurrent loss functions in reinforcement\nlearning.",
    "published": "2024-02-15T11:56:53Z",
    "pdf_url": "http://arxiv.org/pdf/2402.09900v3",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2411.04225v2",
    "title": "Approximate Equivariance in Reinforcement Learning",
    "authors": [
      "Jung Yeon Park",
      "Sujay Bhatt",
      "Sihan Zeng",
      "Lawson L. S. Wong",
      "Alec Koppel",
      "Sumitra Ganesh",
      "Robin Walters"
    ],
    "abstract": "Equivariant neural networks have shown great success in reinforcement\nlearning, improving sample efficiency and generalization when there is symmetry\nin the task. However, in many problems, only approximate symmetry is present,\nwhich makes imposing exact symmetry inappropriate. Recently, approximately\nequivariant networks have been proposed for supervised classification and\nmodeling physical systems. In this work, we develop approximately equivariant\nalgorithms in reinforcement learning (RL). We define approximately equivariant\nMDPs and theoretically characterize the effect of approximate equivariance on\nthe optimal $Q$ function. We propose novel RL architectures using relaxed group\nand steerable convolutions and experiment on several continuous control domains\nand stock trading with real financial data. Our results demonstrate that the\napproximately equivariant network performs on par with exactly equivariant\nnetworks when exact symmetries are present, and outperforms them when the\ndomains exhibit approximate symmetry. As an added byproduct of these\ntechniques, we observe increased robustness to noise at test time. Our code is\navailable at https://github.com/jypark0/approx_equiv_rl.",
    "published": "2024-11-06T19:44:46Z",
    "pdf_url": "http://arxiv.org/pdf/2411.04225v2",
    "categories": [
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2411.06389v1",
    "title": "Optimal Execution with Reinforcement Learning",
    "authors": [
      "Yadh Hafsi",
      "Edoardo Vittori"
    ],
    "abstract": "This study investigates the development of an optimal execution strategy\nthrough reinforcement learning, aiming to determine the most effective approach\nfor traders to buy and sell inventory within a limited time frame. Our proposed\nmodel leverages input features derived from the current state of the limit\norder book.\n  To simulate this environment and overcome the limitations associated with\nrelying on historical data, we utilize the multi-agent market simulator ABIDES,\nwhich provides a diverse range of depth levels within the limit order book.\n  We present a custom MDP formulation followed by the results of our\nmethodology and benchmark the performance against standard execution\nstrategies. Our findings suggest that the reinforcement learning-based approach\ndemonstrates significant potential.",
    "published": "2024-11-10T08:21:03Z",
    "pdf_url": "http://arxiv.org/pdf/2411.06389v1",
    "categories": [
      "q-fin.TR",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2503.02612v2",
    "title": "Reinforcement Learning-based Threat Assessment",
    "authors": [
      "Wuzhou Sun",
      "Siyi Li",
      "Qingxiang Zou",
      "Zixing Liao"
    ],
    "abstract": "In some game scenarios, due to the uncertainty of the number of enemy units\nand the priority of various attributes, the evaluation of the threat level of\nenemy units as well as the screening has been a challenging research topic, and\nthe core difficulty lies in how to reasonably set the priority of different\nattributes in order to achieve quantitative evaluation of the threat. In this\npaper, we innovatively transform the problem of threat assessment into a\nreinforcement learning problem, and through systematic reinforcement learning\ntraining, we successfully construct an efficient neural network evaluator. The\nevaluator can not only comprehensively integrate the multidimensional attribute\nfeatures of the enemy, but also effectively combine our state information, thus\nrealizing a more accurate and scientific threat assessment.",
    "published": "2025-03-04T13:32:40Z",
    "pdf_url": "http://arxiv.org/pdf/2503.02612v2",
    "categories": [
      "cs.LG",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2102.09114v1",
    "title": "Echo State Speech Recognition",
    "authors": [
      "Harsh Shrivastava",
      "Ankush Garg",
      "Yuan Cao",
      "Yu Zhang",
      "Tara Sainath"
    ],
    "abstract": "We propose automatic speech recognition (ASR) models inspired by echo state\nnetwork (ESN), in which a subset of recurrent neural networks (RNN) layers in\nthe models are randomly initialized and untrained. Our study focuses on RNN-T\nand Conformer models, and we show that model quality does not drop even when\nthe decoder is fully randomized. Furthermore, such models can be trained more\nefficiently as the decoders do not require to be updated. By contrast,\nrandomizing encoders hurts model quality, indicating that optimizing encoders\nand learn proper representations for acoustic inputs are more vital for speech\nrecognition. Overall, we challenge the common practice of training ASR models\nfor all components, and demonstrate that ESN-based models can perform equally\nwell but enable more efficient training and storage than fully-trainable\ncounterparts.",
    "published": "2021-02-18T02:04:14Z",
    "pdf_url": "http://arxiv.org/pdf/2102.09114v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2105.11084v3",
    "title": "Unsupervised Speech Recognition",
    "authors": [
      "Alexei Baevski",
      "Wei-Ning Hsu",
      "Alexis Conneau",
      "Michael Auli"
    ],
    "abstract": "Despite rapid progress in the recent past, current speech recognition systems\nstill require labeled training data which limits this technology to a small\nfraction of the languages spoken around the globe. This paper describes\nwav2vec-U, short for wav2vec Unsupervised, a method to train speech recognition\nmodels without any labeled data. We leverage self-supervised speech\nrepresentations to segment unlabeled audio and learn a mapping from these\nrepresentations to phonemes via adversarial training. The right representations\nare key to the success of our method. Compared to the best previous\nunsupervised work, wav2vec-U reduces the phoneme error rate on the TIMIT\nbenchmark from 26.1 to 11.3. On the larger English Librispeech benchmark,\nwav2vec-U achieves a word error rate of 5.9 on test-other, rivaling some of the\nbest published systems trained on 960 hours of labeled data from only two years\nago. We also experiment on nine other languages, including low-resource\nlanguages such as Kyrgyz, Swahili and Tatar.",
    "published": "2021-05-24T04:10:47Z",
    "pdf_url": "http://arxiv.org/pdf/2105.11084v3",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2309.09843v1",
    "title": "Instruction-Following Speech Recognition",
    "authors": [
      "Cheng-I Jeff Lai",
      "Zhiyun Lu",
      "Liangliang Cao",
      "Ruoming Pang"
    ],
    "abstract": "Conventional end-to-end Automatic Speech Recognition (ASR) models primarily\nfocus on exact transcription tasks, lacking flexibility for nuanced user\ninteractions. With the advent of Large Language Models (LLMs) in speech\nprocessing, more organic, text-prompt-based interactions have become possible.\nHowever, the mechanisms behind these models' speech understanding and\n\"reasoning\" capabilities remain underexplored. To study this question from the\ndata perspective, we introduce instruction-following speech recognition,\ntraining a Listen-Attend-Spell model to understand and execute a diverse set of\nfree-form text instructions. This enables a multitude of speech recognition\ntasks -- ranging from transcript manipulation to summarization -- without\nrelying on predefined command sets. Remarkably, our model, trained from scratch\non Librispeech, interprets and executes simple instructions without requiring\nLLMs or pre-trained speech modules. It also offers selective transcription\noptions based on instructions like \"transcribe first half and then turn off\nlistening,\" providing an additional layer of privacy and safety compared to\nexisting LLMs. Our findings highlight the significant potential of\ninstruction-following training to advance speech foundation models.",
    "published": "2023-09-18T14:59:10Z",
    "pdf_url": "http://arxiv.org/pdf/2309.09843v1",
    "categories": [
      "cs.CL",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "1409.1411v1",
    "title": "Visual Speech Recognition",
    "authors": [
      "Ahmad B. A. Hassanat"
    ],
    "abstract": "Lip reading is used to understand or interpret speech without hearing it, a\ntechnique especially mastered by people with hearing difficulties. The ability\nto lip read enables a person with a hearing impairment to communicate with\nothers and to engage in social activities, which otherwise would be difficult.\nRecent advances in the fields of computer vision, pattern recognition, and\nsignal processing has led to a growing interest in automating this challenging\ntask of lip reading. Indeed, automating the human ability to lip read, a\nprocess referred to as visual speech recognition (VSR) (or sometimes speech\nreading), could open the door for other novel related applications. VSR has\nreceived a great deal of attention in the last decade for its potential use in\napplications such as human-computer interaction (HCI), audio-visual speech\nrecognition (AVSR), speaker recognition, talking heads, sign language\nrecognition and video surveillance. Its main aim is to recognise spoken word(s)\nby using only the visual signal that is produced during speech. Hence, VSR\ndeals with the visual domain of speech and involves image processing,\nartificial intelligence, object detection, pattern recognition, statistical\nmodelling, etc.",
    "published": "2014-09-03T00:19:42Z",
    "pdf_url": "http://arxiv.org/pdf/1409.1411v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "2402.04254v1",
    "title": "Large Vocabulary Spontaneous Speech Recognition for Tigrigna",
    "authors": [
      "Ataklti Kahsu",
      "Solomon Teferra"
    ],
    "abstract": "This thesis proposes and describes a research attempt at designing and\ndeveloping a speaker independent spontaneous automatic speech recognition\nsystem for Tigrigna The acoustic model of the Speech Recognition System is\ndeveloped using Carnegie Mellon University Automatic Speech Recognition\ndevelopment tool (Sphinx) while the SRIM tool is used for the development of\nthe language model.\n  Keywords Automatic Speech Recognition Tigrigna language",
    "published": "2023-10-15T13:07:41Z",
    "pdf_url": "http://arxiv.org/pdf/2402.04254v1",
    "categories": [
      "eess.AS",
      "cs.LG",
      "cs.SD",
      "68T50 (Primary)",
      "H.1.2"
    ]
  },
  {
    "arxiv_id": "1812.06864v2",
    "title": "Fully Convolutional Speech Recognition",
    "authors": [
      "Neil Zeghidour",
      "Qiantong Xu",
      "Vitaliy Liptchinsky",
      "Nicolas Usunier",
      "Gabriel Synnaeve",
      "Ronan Collobert"
    ],
    "abstract": "Current state-of-the-art speech recognition systems build on recurrent neural\nnetworks for acoustic and/or language modeling, and rely on feature extraction\npipelines to extract mel-filterbanks or cepstral coefficients. In this paper we\npresent an alternative approach based solely on convolutional neural networks,\nleveraging recent advances in acoustic models from the raw waveform and\nlanguage modeling. This fully convolutional approach is trained end-to-end to\npredict characters from the raw waveform, removing the feature extraction step\naltogether. An external convolutional language model is used to decode words.\nOn Wall Street Journal, our model matches the current state-of-the-art. On\nLibrispeech, we report state-of-the-art performance among end-to-end models,\nincluding Deep Speech 2 trained with 12 times more acoustic data and\nsignificantly more linguistic data.",
    "published": "2018-12-17T16:07:12Z",
    "pdf_url": "http://arxiv.org/pdf/1812.06864v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2410.10434v2",
    "title": "In-Materia Speech Recognition",
    "authors": [
      "Mohamadreza Zolfagharinejad",
      "Julian Büchel",
      "Lorenzo Cassola",
      "Sachin Kinge",
      "Ghazi Sarwat Syed",
      "Abu Sebastian",
      "Wilfred G. van der Wiel"
    ],
    "abstract": "With the rise of decentralized computing, as in the Internet of Things,\nautonomous driving, and personalized healthcare, it is increasingly important\nto process time-dependent signals at the edge efficiently: right at the place\nwhere the temporal data are collected, avoiding time-consuming, insecure, and\ncostly communication with a centralized computing facility (or cloud). However,\nmodern-day processors often cannot meet the restrained power and time budgets\nof edge systems because of intrinsic limitations imposed by their architecture\n(von Neumann bottleneck) or domain conversions (analogue-to-digital and\ntime-to-frequency). Here, we propose an edge temporal-signal processor based on\ntwo in-materia computing systems for both feature extraction and\nclassification, reaching a software-level accuracy of 96.2% for the TI-46-Word\nspeech-recognition task. First, a nonlinear, room-temperature\ndopant-network-processing-unit (DNPU) layer realizes analogue, time-domain\nfeature extraction from the raw audio signals, similar to the human cochlea.\nSecond, an analogue in-memory computing (AIMC) chip, consisting of memristive\ncrossbar arrays, implements a compact neural network trained on the extracted\nfeatures for classification. With the DNPU feature extraction consuming 100s nW\nand AIMC-based classification having the potential for less than 10 fJ per\nmultiply-accumulate operation, our findings offer a promising avenue for\nadvancing the compactness, efficiency, and performance of heterogeneous smart\nedge processors through in-materia computing hardware.",
    "published": "2024-10-14T12:26:59Z",
    "pdf_url": "http://arxiv.org/pdf/2410.10434v2",
    "categories": [
      "eess.AS",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "2504.16213v1",
    "title": "TinyML for Speech Recognition",
    "authors": [
      "Andrew Barovic",
      "Armin Moin"
    ],
    "abstract": "We train and deploy a quantized 1D convolutional neural network model to\nconduct speech recognition on a highly resource-constrained IoT edge device.\nThis can be useful in various Internet of Things (IoT) applications, such as\nsmart homes and ambient assisted living for the elderly and people with\ndisabilities, just to name a few examples. In this paper, we first create a new\ndataset with over one hour of audio data that enables our research and will be\nuseful to future studies in this field. Second, we utilize the technologies\nprovided by Edge Impulse to enhance our model's performance and achieve a high\nAccuracy of up to 97% on our dataset. For the validation, we implement our\nprototype using the Arduino Nano 33 BLE Sense microcontroller board. This\nmicrocontroller board is specifically designed for IoT and AI applications,\nmaking it an ideal choice for our target use case scenarios. While most\nexisting research focuses on a limited set of keywords, our model can process\n23 different keywords, enabling complex commands.",
    "published": "2025-04-22T19:00:40Z",
    "pdf_url": "http://arxiv.org/pdf/2504.16213v1",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "1711.07274v2",
    "title": "Speech recognition for medical conversations",
    "authors": [
      "Chung-Cheng Chiu",
      "Anshuman Tripathi",
      "Katherine Chou",
      "Chris Co",
      "Navdeep Jaitly",
      "Diana Jaunzeikare",
      "Anjuli Kannan",
      "Patrick Nguyen",
      "Hasim Sak",
      "Ananth Sankar",
      "Justin Tansuwan",
      "Nathan Wan",
      "Yonghui Wu",
      "Xuedong Zhang"
    ],
    "abstract": "In this work we explored building automatic speech recognition models for\ntranscribing doctor patient conversation. We collected a large scale dataset of\nclinical conversations ($14,000$ hr), designed the task to represent the real\nword scenario, and explored several alignment approaches to iteratively improve\ndata quality. We explored both CTC and LAS systems for building speech\nrecognition models. The LAS was more resilient to noisy data and CTC required\nmore data clean up. A detailed analysis is provided for understanding the\nperformance for clinical tasks. Our analysis showed the speech recognition\nmodels performed well on important medical utterances, while errors occurred in\ncausal conversations. Overall we believe the resulting models can provide\nreasonable quality in practice.",
    "published": "2017-11-20T12:07:22Z",
    "pdf_url": "http://arxiv.org/pdf/1711.07274v2",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1908.02119v1",
    "title": "Practical Speech Recognition with HTK",
    "authors": [
      "Zulkarnaen Hatala"
    ],
    "abstract": "The practical aspects of developing an Automatic Speech Recognition System\n(ASR) with HTK are reviewed. Steps are explained concerning hardware, software,\nlibraries, applications and computer programs used. The common procedure to\nrapidly apply speech recognition system is summarized. The procedure is\nillustrated, to implement a speech based electrical switch in home automation\nfor the Indonesian language. The main key of the procedure is to match the\nenvironment for training and testing using the training data recorded from the\ntesting program, HVite. Often the silence detector of HTK is wrongly triggered\nby noises because the microphone is too sensitive. This problem is mitigated by\nsimply scaling down the volume. In this sub-word phone-based speech\nrecognition, noise is included in the training database and labelled\nparticularly. Illustration of the procedure is applied to a home automation\napplication. Electrical switches are controlled by Indonesian speech\nrecognizer. The results show 100% command completion rate.",
    "published": "2019-08-06T13:12:57Z",
    "pdf_url": "http://arxiv.org/pdf/1908.02119v1",
    "categories": [
      "eess.AS",
      "cs.HC",
      "cs.LG",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "1912.07730v5",
    "title": "Continuous Speech Recognition using EEG and Video",
    "authors": [
      "Gautam Krishna",
      "Mason Carnahan",
      "Co Tran",
      "Ahmed H Tewfik"
    ],
    "abstract": "In this paper we investigate whether electroencephalography (EEG) features\ncan be used to improve the performance of continuous visual speech recognition\nsystems. We implemented a connectionist temporal classification (CTC) based\nend-to-end automatic speech recognition (ASR) model for performing recognition.\nOur results demonstrate that EEG features are helpful in enhancing the\nperformance of continuous visual speech recognition systems.",
    "published": "2019-12-16T22:16:19Z",
    "pdf_url": "http://arxiv.org/pdf/1912.07730v5",
    "categories": [
      "cs.LG",
      "eess.AS",
      "eess.IV",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2104.10747v2",
    "title": "Accented Speech Recognition: A Survey",
    "authors": [
      "Arthur Hinsvark",
      "Natalie Delworth",
      "Miguel Del Rio",
      "Quinten McNamara",
      "Joshua Dong",
      "Ryan Westerman",
      "Michelle Huang",
      "Joseph Palakapilly",
      "Jennifer Drexler",
      "Ilya Pirkin",
      "Nishchal Bhandari",
      "Miguel Jette"
    ],
    "abstract": "Automatic Speech Recognition (ASR) systems generalize poorly on accented\nspeech. The phonetic and linguistic variability of accents present hard\nchallenges for ASR systems today in both data collection and modeling\nstrategies. The resulting bias in ASR performance across accents comes at a\ncost to both users and providers of ASR.\n  We present a survey of current promising approaches to accented speech\nrecognition and highlight the key challenges in the space. Approaches mostly\nfocus on single model generalization and accent feature engineering. Among the\nchallenges, lack of a standard benchmark makes research and comparison\nespecially difficult.",
    "published": "2021-04-21T20:21:06Z",
    "pdf_url": "http://arxiv.org/pdf/2104.10747v2",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2005.05592v2",
    "title": "Discriminative Multi-modality Speech Recognition",
    "authors": [
      "Bo Xu",
      "Cheng Lu",
      "Yandong Guo",
      "Jacob Wang"
    ],
    "abstract": "Vision is often used as a complementary modality for audio speech recognition\n(ASR), especially in the noisy environment where performance of solo audio\nmodality significantly deteriorates. After combining visual modality, ASR is\nupgraded to the multi-modality speech recognition (MSR). In this paper, we\npropose a two-stage speech recognition model. In the first stage, the target\nvoice is separated from background noises with help from the corresponding\nvisual information of lip movements, making the model 'listen' clearly. At the\nsecond stage, the audio modality combines visual modality again to better\nunderstand the speech by a MSR sub-network, further improving the recognition\nrate. There are some other key contributions: we introduce a pseudo-3D residual\nconvolution (P3D)-based visual front-end to extract more discriminative\nfeatures; we upgrade the temporal convolution block from 1D ResNet with the\ntemporal convolutional network (TCN), which is more suitable for the temporal\ntasks; the MSR sub-network is built on the top of Element-wise-Attention Gated\nRecurrent Unit (EleAtt-GRU), which is more effective than Transformer in long\nsequences. We conducted extensive experiments on the LRS3-TED and the LRW\ndatasets. Our two-stage model (audio enhanced multi-modality speech\nrecognition, AE-MSR) consistently achieves the state-of-the-art performance by\na significant margin, which demonstrates the necessity and effectiveness of\nAE-MSR.",
    "published": "2020-05-12T07:56:03Z",
    "pdf_url": "http://arxiv.org/pdf/2005.05592v2",
    "categories": [
      "cs.CV",
      "cs.CL",
      "cs.SD",
      "eess.AS",
      "eess.IV"
    ]
  },
  {
    "arxiv_id": "1809.02108v2",
    "title": "Deep Audio-Visual Speech Recognition",
    "authors": [
      "Triantafyllos Afouras",
      "Joon Son Chung",
      "Andrew Senior",
      "Oriol Vinyals",
      "Andrew Zisserman"
    ],
    "abstract": "The goal of this work is to recognise phrases and sentences being spoken by a\ntalking face, with or without the audio. Unlike previous works that have\nfocussed on recognising a limited number of words or phrases, we tackle lip\nreading as an open-world problem - unconstrained natural language sentences,\nand in the wild videos. Our key contributions are: (1) we compare two models\nfor lip reading, one using a CTC loss, and the other using a\nsequence-to-sequence loss. Both models are built on top of the transformer\nself-attention architecture; (2) we investigate to what extent lip reading is\ncomplementary to audio speech recognition, especially when the audio signal is\nnoisy; (3) we introduce and publicly release a new dataset for audio-visual\nspeech recognition, LRS2-BBC, consisting of thousands of natural sentences from\nBritish television. The models that we train surpass the performance of all\nprevious work on a lip reading benchmark dataset by a significant margin.",
    "published": "2018-09-06T17:34:27Z",
    "pdf_url": "http://arxiv.org/pdf/1809.02108v2",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1904.02210v1",
    "title": "Massively Multilingual Adversarial Speech Recognition",
    "authors": [
      "Oliver Adams",
      "Matthew Wiesner",
      "Shinji Watanabe",
      "David Yarowsky"
    ],
    "abstract": "We report on adaptation of multilingual end-to-end speech recognition models\ntrained on as many as 100 languages. Our findings shed light on the relative\nimportance of similarity between the target and pretraining languages along the\ndimensions of phonetics, phonology, language family, geographical location, and\northography. In this context, experiments demonstrate the effectiveness of two\nadditional pretraining objectives in encouraging language-independent encoder\nrepresentations: a context-independent phoneme objective paired with a\nlanguage-adversarial classification objective.",
    "published": "2019-04-03T19:28:53Z",
    "pdf_url": "http://arxiv.org/pdf/1904.02210v1",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2406.18135v1",
    "title": "Automatic Speech Recognition for Hindi",
    "authors": [
      "Anish Saha",
      "A. G. Ramakrishnan"
    ],
    "abstract": "Automatic speech recognition (ASR) is a key area in computational\nlinguistics, focusing on developing technologies that enable computers to\nconvert spoken language into text. This field combines linguistics and machine\nlearning. ASR models, which map speech audio to transcripts through supervised\nlearning, require handling real and unrestricted text. Text-to-speech systems\ndirectly work with real text, while ASR systems rely on language models trained\non large text corpora. High-quality transcribed data is essential for training\npredictive models. The research involved two main components: developing a web\napplication and designing a web interface for speech recognition. The web\napplication, created with JavaScript and Node.js, manages large volumes of\naudio files and their transcriptions, facilitating collaborative human\ncorrection of ASR transcripts. It operates in real-time using a client-server\narchitecture. The web interface for speech recognition records 16 kHz mono\naudio from any device running the web app, performs voice activity detection\n(VAD), and sends the audio to the recognition engine. VAD detects human speech\npresence, aiding efficient speech processing and reducing unnecessary\nprocessing during non-speech intervals, thus saving computation and network\nbandwidth in VoIP applications. The final phase of the research tested a neural\nnetwork for accurately aligning the speech signal to hidden Markov model (HMM)\nstates. This included implementing a novel backpropagation method that utilizes\nprior statistics of node co-activations.",
    "published": "2024-06-26T07:39:20Z",
    "pdf_url": "http://arxiv.org/pdf/2406.18135v1",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "0704.2201v1",
    "title": "Arabic Speech Recognition System using CMU-Sphinx4",
    "authors": [
      "H. Satori",
      "M. Harti",
      "N. Chenfour"
    ],
    "abstract": "In this paper we present the creation of an Arabic version of Automated\nSpeech Recognition System (ASR). This system is based on the open source\nSphinx-4, from the Carnegie Mellon University. Which is a speech recognition\nsystem based on discrete hidden Markov models (HMMs). We investigate the\nchanges that must be made to the model to adapt Arabic voice recognition.\n  Keywords: Speech recognition, Acoustic model, Arabic language, HMMs,\nCMUSphinx-4, Artificial intelligence.",
    "published": "2007-04-17T17:04:26Z",
    "pdf_url": "http://arxiv.org/pdf/0704.2201v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ]
  },
  {
    "arxiv_id": "2002.03851v7",
    "title": "Continuous Silent Speech Recognition using EEG",
    "authors": [
      "Gautam Krishna",
      "Co Tran",
      "Mason Carnahan",
      "Ahmed Tewfik"
    ],
    "abstract": "In this paper we explore continuous silent speech recognition using\nelectroencephalography (EEG) signals. We implemented a connectionist temporal\nclassification (CTC) automatic speech recognition (ASR) model to translate EEG\nsignals recorded in parallel while subjects were reading English sentences in\ntheir mind without producing any voice to text. Our results demonstrate the\nfeasibility of using EEG signals for performing continuous silent speech\nrecognition. We demonstrate our results for a limited English vocabulary\nconsisting of 30 unique sentences.",
    "published": "2020-02-06T18:28:45Z",
    "pdf_url": "http://arxiv.org/pdf/2002.03851v7",
    "categories": [
      "eess.AS",
      "cs.LG",
      "cs.SD",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2009.09395v1",
    "title": "Far-Field Automatic Speech Recognition",
    "authors": [
      "Reinhold Haeb-Umbach",
      "Jahn Heymann",
      "Lukas Drude",
      "Shinji Watanabe",
      "Marc Delcroix",
      "Tomohiro Nakatani"
    ],
    "abstract": "The machine recognition of speech spoken at a distance from the microphones,\nknown as far-field automatic speech recognition (ASR), has received a\nsignificant increase of attention in science and industry, which caused or was\ncaused by an equally significant improvement in recognition accuracy. Meanwhile\nit has entered the consumer market with digital home assistants with a spoken\nlanguage interface being its most prominent application. Speech recorded at a\ndistance is affected by various acoustic distortions and, consequently, quite\ndifferent processing pipelines have emerged compared to ASR for close-talk\nspeech. A signal enhancement front-end for dereverberation, source separation\nand acoustic beamforming is employed to clean up the speech, and the back-end\nASR engine is robustified by multi-condition training and adaptation. We will\nalso describe the so-called end-to-end approach to ASR, which is a new\npromising architecture that has recently been extended to the far-field\nscenario. This tutorial article gives an account of the algorithms used to\nenable accurate speech recognition from a distance, and it will be seen that,\nalthough deep learning has a significant share in the technological\nbreakthroughs, a clever combination with traditional signal processing can lead\nto surprisingly effective solutions.",
    "published": "2020-09-20T09:31:59Z",
    "pdf_url": "http://arxiv.org/pdf/2009.09395v1",
    "categories": [
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2107.11190v3",
    "title": "Semantic Communications for Speech Recognition",
    "authors": [
      "Zhenzi Weng",
      "Zhijin Qin",
      "Geoffrey Ye Li"
    ],
    "abstract": "The traditional communications transmit all the source data represented by\nbits, regardless of the content of source and the semantic information required\nby the receiver. However, in some applications, the receiver only needs part of\nthe source data that represents critical semantic information, which prompts to\ntransmit the application-related information, especially when bandwidth\nresources are limited. In this paper, we consider a semantic communication\nsystem for speech recognition by designing the transceiver as an end-to-end\n(E2E) system. Particularly, a deep learning (DL)-enabled semantic communication\nsystem, named DeepSC-SR, is developed to learn and extract text-related\nsemantic features at the transmitter, which motivates the system to transmit\nmuch less than the source speech data without performance degradation.\nMoreover, in order to facilitate the proposed DeepSC-SR for dynamic channel\nenvironments, we investigate a robust model to cope with various channel\nenvironments without requiring retraining. The simulation results demonstrate\nthat our proposed DeepSC-SR outperforms the traditional communication systems\nin terms of the speech recognition metrics, such as character-error-rate and\nword-error-rate, and is more robust to channel variations, especially in the\nlow signal-to-noise (SNR) regime.",
    "published": "2021-07-22T11:08:08Z",
    "pdf_url": "http://arxiv.org/pdf/2107.11190v3",
    "categories": [
      "eess.AS",
      "cs.SD",
      "eess.SP"
    ]
  },
  {
    "arxiv_id": "1807.05162v3",
    "title": "Large-Scale Visual Speech Recognition",
    "authors": [
      "Brendan Shillingford",
      "Yannis Assael",
      "Matthew W. Hoffman",
      "Thomas Paine",
      "Cían Hughes",
      "Utsav Prabhu",
      "Hank Liao",
      "Hasim Sak",
      "Kanishka Rao",
      "Lorrayne Bennett",
      "Marie Mulville",
      "Ben Coppin",
      "Ben Laurie",
      "Andrew Senior",
      "Nando de Freitas"
    ],
    "abstract": "This work presents a scalable solution to open-vocabulary visual speech\nrecognition. To achieve this, we constructed the largest existing visual speech\nrecognition dataset, consisting of pairs of text and video clips of faces\nspeaking (3,886 hours of video). In tandem, we designed and trained an\nintegrated lipreading system, consisting of a video processing pipeline that\nmaps raw video to stable videos of lips and sequences of phonemes, a scalable\ndeep neural network that maps the lip videos to sequences of phoneme\ndistributions, and a production-level speech decoder that outputs sequences of\nwords. The proposed system achieves a word error rate (WER) of 40.9% as\nmeasured on a held-out set. In comparison, professional lipreaders achieve\neither 86.4% or 92.9% WER on the same dataset when having access to additional\ntypes of contextual information. Our approach significantly improves on other\nlipreading approaches, including variants of LipNet and of Watch, Attend, and\nSpell (WAS), which are only capable of 89.8% and 76.8% WER respectively.",
    "published": "2018-07-13T16:21:34Z",
    "pdf_url": "http://arxiv.org/pdf/1807.05162v3",
    "categories": [
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2112.14678v1",
    "title": "Multi-Dialect Arabic Speech Recognition",
    "authors": [
      "Abbas Raza Ali"
    ],
    "abstract": "This paper presents the design and development of multi-dialect automatic\nspeech recognition for Arabic. Deep neural networks are becoming an effective\ntool to solve sequential data problems, particularly, adopting an end-to-end\ntraining of the system. Arabic speech recognition is a complex task because of\nthe existence of multiple dialects, non-availability of large corpora, and\nmissing vocalization. Thus, the first contribution of this work is the\ndevelopment of a large multi-dialectal corpus with either full or at least\npartially vocalized transcription. Additionally, the open-source corpus has\nbeen gathered from multiple sources that bring non-standard Arabic alphabets in\ntranscription which are normalized by defining a common character-set. The\nsecond contribution is the development of a framework to train an acoustic\nmodel achieving state-of-the-art performance. The network architecture\ncomprises of a combination of convolutional and recurrent layers. The\nspectrogram features of the audio data are extracted in the frequency vs time\ndomain and fed in the network. The output frames, produced by the recurrent\nmodel, are further trained to align the audio features with its corresponding\ntranscription sequences. The sequence alignment is performed using a beam\nsearch decoder with a tetra-gram language model. The proposed system achieved a\n14% error rate which outperforms previous systems.",
    "published": "2021-12-25T20:55:57Z",
    "pdf_url": "http://arxiv.org/pdf/2112.14678v1",
    "categories": [
      "eess.AS",
      "cs.LG",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "1904.04479v4",
    "title": "Who Needs Words? Lexicon-Free Speech Recognition",
    "authors": [
      "Tatiana Likhomanenko",
      "Gabriel Synnaeve",
      "Ronan Collobert"
    ],
    "abstract": "Lexicon-free speech recognition naturally deals with the problem of\nout-of-vocabulary (OOV) words. In this paper, we show that character-based\nlanguage models (LM) can perform as well as word-based LMs for speech\nrecognition, in word error rates (WER), even without restricting the decoding\nto a lexicon. We study character-based LMs and show that convolutional LMs can\neffectively leverage large (character) contexts, which is key for good speech\nrecognition performance downstream. We specifically show that the lexicon-free\ndecoding performance (WER) on utterances with OOV words using character-based\nLMs is better than lexicon-based decoding, both with character or word-based\nLMs.",
    "published": "2019-04-09T06:06:54Z",
    "pdf_url": "http://arxiv.org/pdf/1904.04479v4",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2204.02492v2",
    "title": "Towards End-to-end Unsupervised Speech Recognition",
    "authors": [
      "Alexander H. Liu",
      "Wei-Ning Hsu",
      "Michael Auli",
      "Alexei Baevski"
    ],
    "abstract": "Unsupervised speech recognition has shown great potential to make Automatic\nSpeech Recognition (ASR) systems accessible to every language. However,\nexisting methods still heavily rely on hand-crafted pre-processing. Similar to\nthe trend of making supervised speech recognition end-to-end, we introduce\nwav2vec-U 2.0 which does away with all audio-side pre-processing and improves\naccuracy through better architecture. In addition, we introduce an auxiliary\nself-supervised objective that ties model predictions back to the input.\nExperiments show that wav2vec-U 2.0 improves unsupervised recognition results\nacross different languages while being conceptually simpler.",
    "published": "2022-04-05T21:22:38Z",
    "pdf_url": "http://arxiv.org/pdf/2204.02492v2",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "1901.04699v1",
    "title": "Phoneme-Based Persian Speech Recognition",
    "authors": [
      "Saber Malekzadeh"
    ],
    "abstract": "Undoubtedly, one of the most important issues in computer science is\nintelligent speech recognition. In these systems, computers try to detect and\nrespond to the speeches they are listening to, like humans. In this research,\npresenting of a suitable method for the diagnosis of Persian phonemes by AI\nusing the signal processing and classification algorithms have tried. For this\npurpose, the STFT algorithm has been used to process the audio signals, as well\nas to detect and classify the signals processed by the deep artificial neural\nnetwork. At first, educational samples were provided as two phonological\nphrases in Persian language and then signal processing operations were\nperformed on them. Then the results for the data training have been given to\nthe artificial deep neural network. At the final stage, the experiment was\nconducted on new sounds.",
    "published": "2019-01-15T08:07:48Z",
    "pdf_url": "http://arxiv.org/pdf/1901.04699v1",
    "categories": [
      "cs.SD",
      "cs.LG",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2302.12369v1",
    "title": "Factual Consistency Oriented Speech Recognition",
    "authors": [
      "Naoyuki Kanda",
      "Takuya Yoshioka",
      "Yang Liu"
    ],
    "abstract": "This paper presents a novel optimization framework for automatic speech\nrecognition (ASR) with the aim of reducing hallucinations produced by an ASR\nmodel. The proposed framework optimizes the ASR model to maximize an expected\nfactual consistency score between ASR hypotheses and ground-truth\ntranscriptions, where the factual consistency score is computed by a separately\ntrained estimator. Experimental results using the AMI meeting corpus and the\nVoxPopuli corpus show that the ASR model trained with the proposed framework\ngenerates ASR hypotheses that have significantly higher consistency scores with\nground-truth transcriptions while maintaining the word error rates close to\nthose of cross entropy-trained ASR models. Furthermore, it is shown that\ntraining the ASR models with the proposed framework improves the speech\nsummarization quality as measured by the factual consistency of meeting\nconversation summaries generated by a large language model.",
    "published": "2023-02-24T00:01:41Z",
    "pdf_url": "http://arxiv.org/pdf/2302.12369v1",
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "2307.01672v1",
    "title": "Boosting Norwegian Automatic Speech Recognition",
    "authors": [
      "Javier de la Rosa",
      "Rolv-Arild Braaten",
      "Per Egil Kummervold",
      "Freddy Wetjen",
      "Svein Arne Brygfjeld"
    ],
    "abstract": "In this paper, we present several baselines for automatic speech recognition\n(ASR) models for the two official written languages in Norway: Bokm{\\aa}l and\nNynorsk. We compare the performance of models of varying sizes and pre-training\napproaches on multiple Norwegian speech datasets. Additionally, we measure the\nperformance of these models against previous state-of-the-art ASR models, as\nwell as on out-of-domain datasets. We improve the state of the art on the\nNorwegian Parliamentary Speech Corpus (NPSC) from a word error rate (WER) of\n17.10\\% to 7.60\\%, with models achieving 5.81\\% for Bokm{\\aa}l and 11.54\\% for\nNynorsk. We also discuss the challenges and potential solutions for further\nimproving ASR models for Norwegian.",
    "published": "2023-07-04T12:05:15Z",
    "pdf_url": "http://arxiv.org/pdf/2307.01672v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2001.00501v3",
    "title": "EEG based Continuous Speech Recognition using Transformers",
    "authors": [
      "Gautam Krishna",
      "Co Tran",
      "Mason Carnahan",
      "Ahmed H Tewfik"
    ],
    "abstract": "In this paper we investigate continuous speech recognition using\nelectroencephalography (EEG) features using recently introduced end-to-end\ntransformer based automatic speech recognition (ASR) model. Our results\ndemonstrate that transformer based model demonstrate faster training compared\nto recurrent neural network (RNN) based sequence-to-sequence EEG models and\nbetter performance during inference time for smaller test set vocabulary but as\nwe increase the vocabulary size, the performance of the RNN based models were\nbetter than transformer based model on a limited English vocabulary.",
    "published": "2019-12-31T08:36:59Z",
    "pdf_url": "http://arxiv.org/pdf/2001.00501v3",
    "categories": [
      "eess.AS",
      "cs.LG",
      "cs.SD",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2003.01787v1",
    "title": "Untangling in Invariant Speech Recognition",
    "authors": [
      "Cory Stephenson",
      "Jenelle Feather",
      "Suchismita Padhy",
      "Oguz Elibol",
      "Hanlin Tang",
      "Josh McDermott",
      "SueYeon Chung"
    ],
    "abstract": "Encouraged by the success of deep neural networks on a variety of visual\ntasks, much theoretical and experimental work has been aimed at understanding\nand interpreting how vision networks operate. Meanwhile, deep neural networks\nhave also achieved impressive performance in audio processing applications,\nboth as sub-components of larger systems and as complete end-to-end systems by\nthemselves. Despite their empirical successes, comparatively little is\nunderstood about how these audio models accomplish these tasks. In this work,\nwe employ a recently developed statistical mechanical theory that connects\ngeometric properties of network representations and the separability of classes\nto probe how information is untangled within neural networks trained to\nrecognize speech. We observe that speaker-specific nuisance variations are\ndiscarded by the network's hierarchy, whereas task-relevant properties such as\nwords and phonemes are untangled in later layers. Higher level concepts such as\nparts-of-speech and context dependence also emerge in the later layers of the\nnetwork. Finally, we find that the deep representations carry out significant\ntemporal untangling by efficiently extracting task-relevant features at each\ntime step of the computation. Taken together, these findings shed light on how\ndeep auditory models process time dependent input signals to achieve invariant\nspeech recognition, and show how different concepts emerge through the layers\nof the network.",
    "published": "2020-03-03T20:48:43Z",
    "pdf_url": "http://arxiv.org/pdf/2003.01787v1",
    "categories": [
      "cs.LG",
      "cond-mat.dis-nn",
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2206.07684v1",
    "title": "AVATAR: Unconstrained Audiovisual Speech Recognition",
    "authors": [
      "Valentin Gabeur",
      "Paul Hongsuck Seo",
      "Arsha Nagrani",
      "Chen Sun",
      "Karteek Alahari",
      "Cordelia Schmid"
    ],
    "abstract": "Audio-visual automatic speech recognition (AV-ASR) is an extension of ASR\nthat incorporates visual cues, often from the movements of a speaker's mouth.\nUnlike works that simply focus on the lip motion, we investigate the\ncontribution of entire visual frames (visual actions, objects, background\netc.). This is particularly useful for unconstrained videos, where the speaker\nis not necessarily visible. To solve this task, we propose a new\nsequence-to-sequence AudioVisual ASR TrAnsformeR (AVATAR) which is trained\nend-to-end from spectrograms and full-frame RGB. To prevent the audio stream\nfrom dominating training, we propose different word-masking strategies, thereby\nencouraging our model to pay attention to the visual stream. We demonstrate the\ncontribution of the visual modality on the How2 AV-ASR benchmark, especially in\nthe presence of simulated noise, and show that our model outperforms all other\nprior work by a large margin. Finally, we also create a new, real-world test\nbed for AV-ASR called VisSpeech, which demonstrates the contribution of the\nvisual modality under challenging audio conditions.",
    "published": "2022-06-15T17:33:19Z",
    "pdf_url": "http://arxiv.org/pdf/2206.07684v1",
    "categories": [
      "cs.CV",
      "cs.MM",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "1001.2267v1",
    "title": "Speech Recognition by Machine, A Review",
    "authors": [
      "M. A. Anusuya",
      "S. K. Katti"
    ],
    "abstract": "This paper presents a brief survey on Automatic Speech Recognition and\ndiscusses the major themes and advances made in the past 60 years of research,\nso as to provide a technological perspective and an appreciation of the\nfundamental progress that has been accomplished in this important area of\nspeech communication. After years of research and development the accuracy of\nautomatic speech recognition remains one of the important research challenges\n(e.g., variations of the context, speakers, and environment).The design of\nSpeech Recognition system requires careful attentions to the following issues:\nDefinition of various types of speech classes, speech representation, feature\nextraction techniques, speech classifiers, database and performance evaluation.\nThe problems that are existing in ASR and the various techniques to solve these\nproblems constructed by various research workers have been presented in a\nchronological order. Hence authors hope that this work shall be a contribution\nin the area of speech recognition. The objective of this review paper is to\nsummarize and compare some of the well known methods used in various stages of\nspeech recognition system and identify research topic and applications which\nare at the forefront of this exciting and challenging field.",
    "published": "2010-01-13T19:02:18Z",
    "pdf_url": "http://arxiv.org/pdf/1001.2267v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "1710.07168v2",
    "title": "Combining Multiple Views for Visual Speech Recognition",
    "authors": [
      "Marina Zimmermann",
      "Mostafa Mehdipour Ghazi",
      "Hazım Kemal Ekenel",
      "Jean-Philippe Thiran"
    ],
    "abstract": "Visual speech recognition is a challenging research problem with a particular\npractical application of aiding audio speech recognition in noisy scenarios.\nMultiple camera setups can be beneficial for the visual speech recognition\nsystems in terms of improved performance and robustness. In this paper, we\nexplore this aspect and provide a comprehensive study on combining multiple\nviews for visual speech recognition. The thorough analysis covers fusion of all\npossible view angle combinations both at feature level and decision level. The\nemployed visual speech recognition system in this study extracts features\nthrough a PCA-based convolutional neural network, followed by an LSTM network.\nFinally, these features are processed in a tandem system, being fed into a\nGMM-HMM scheme. The decision fusion acts after this point by combining the\nViterbi path log-likelihoods. The results show that the complementary\ninformation contained in recordings from different view angles improves the\nresults significantly. For example, the sentence correctness on the test set is\nincreased from 76% for the highest performing single view ($30^\\circ$) to up to\n83% when combining this view with the frontal and $60^\\circ$ view angles.",
    "published": "2017-10-19T14:52:34Z",
    "pdf_url": "http://arxiv.org/pdf/1710.07168v2",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1305.2846v1",
    "title": "Opportunities & Challenges In Automatic Speech Recognition",
    "authors": [
      "Rashmi Makhijani",
      "Urmila Shrawankar",
      "V M Thakare"
    ],
    "abstract": "Automatic speech recognition enables a wide range of current and emerging\napplications such as automatic transcription, multimedia content analysis, and\nnatural human-computer interfaces. This paper provides a glimpse of the\nopportunities and challenges that parallelism provides for automatic speech\nrecognition and related application research from the point of view of speech\nresearchers. The increasing parallelism in computing platforms opens three\nmajor possibilities for speech recognition systems: improving recognition\naccuracy in non-ideal, everyday noisy environments; increasing recognition\nthroughput in batch processing of speech data; and reducing recognition latency\nin realtime usage scenarios. This paper describes technical challenges,\napproaches taken, and possible directions for future research to guide the\ndesign of efficient parallel software and hardware infrastructures.",
    "published": "2013-05-09T08:42:26Z",
    "pdf_url": "http://arxiv.org/pdf/1305.2846v1",
    "categories": [
      "cs.CL",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "2107.11414v3",
    "title": "Brazilian Portuguese Speech Recognition Using Wav2vec 2.0",
    "authors": [
      "Lucas Rafael Stefanel Gris",
      "Edresson Casanova",
      "Frederico Santos de Oliveira",
      "Anderson da Silva Soares",
      "Arnaldo Candido Junior"
    ],
    "abstract": "Deep learning techniques have been shown to be efficient in various tasks,\nespecially in the development of speech recognition systems, that is, systems\nthat aim to transcribe an audio sentence in a sequence of written words.\nDespite the progress in the area, speech recognition can still be considered\ndifficult, especially for languages lacking available data, such as Brazilian\nPortuguese (BP). In this sense, this work presents the development of an public\nAutomatic Speech Recognition (ASR) system using only open available audio data,\nfrom the fine-tuning of the Wav2vec 2.0 XLSR-53 model pre-trained in many\nlanguages, over BP data. The final model presents an average word error rate of\n12.4% over 7 different datasets (10.5% when applying a language model).\nAccording to our knowledge, the obtained error is the lowest among open\nend-to-end (E2E) ASR models for BP.",
    "published": "2021-07-23T18:54:39Z",
    "pdf_url": "http://arxiv.org/pdf/2107.11414v3",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2202.08883v1",
    "title": "Curriculum optimization for low-resource speech recognition",
    "authors": [
      "Anastasia Kuznetsova",
      "Anurag Kumar",
      "Jennifer Drexler Fox",
      "Francis Tyers"
    ],
    "abstract": "Modern end-to-end speech recognition models show astonishing results in\ntranscribing audio signals into written text. However, conventional data\nfeeding pipelines may be sub-optimal for low-resource speech recognition, which\nstill remains a challenging task. We propose an automated curriculum learning\napproach to optimize the sequence of training examples based on both the\nprogress of the model while training and prior knowledge about the difficulty\nof the training examples. We introduce a new difficulty measure called\ncompression ratio that can be used as a scoring function for raw audio in\nvarious noise conditions. The proposed method improves speech recognition Word\nError Rate performance by up to 33% relative over the baseline system",
    "published": "2022-02-17T19:47:50Z",
    "pdf_url": "http://arxiv.org/pdf/2202.08883v1",
    "categories": [
      "eess.AS",
      "cs.LG",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "1909.11699v1",
    "title": "Speech Recognition with Augmented Synthesized Speech",
    "authors": [
      "Andrew Rosenberg",
      "Yu Zhang",
      "Bhuvana Ramabhadran",
      "Ye Jia",
      "Pedro Moreno",
      "Yonghui Wu",
      "Zelin Wu"
    ],
    "abstract": "Recent success of the Tacotron speech synthesis architecture and its variants\nin producing natural sounding multi-speaker synthesized speech has raised the\nexciting possibility of replacing expensive, manually transcribed,\ndomain-specific, human speech that is used to train speech recognizers. The\nmulti-speaker speech synthesis architecture can learn latent embedding spaces\nof prosody, speaker and style variations derived from input acoustic\nrepresentations thereby allowing for manipulation of the synthesized speech. In\nthis paper, we evaluate the feasibility of enhancing speech recognition\nperformance using speech synthesis using two corpora from different domains. We\nexplore algorithms to provide the necessary acoustic and lexical diversity\nneeded for robust speech recognition. Finally, we demonstrate the feasibility\nof this approach as a data augmentation strategy for domain-transfer.\n  We find that improvements to speech recognition performance is achievable by\naugmenting training data with synthesized material. However, there remains a\nsubstantial gap in performance between recognizers trained on human speech\nthose trained on synthesized speech.",
    "published": "2019-09-25T18:32:50Z",
    "pdf_url": "http://arxiv.org/pdf/1909.11699v1",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "1911.04571v1",
    "title": "Long-span language modeling for speech recognition",
    "authors": [
      "Sarangarajan Parthasarathy",
      "William Gale",
      "Xie Chen",
      "George Polovets",
      "Shuangyu Chang"
    ],
    "abstract": "We explore neural language modeling for speech recognition where the context\nspans multiple sentences. Rather than encode history beyond the current\nsentence using a cache of words or document-level features, we focus our study\non the ability of LSTM and Transformer language models to implicitly learn to\ncarry over context across sentence boundaries. We introduce a new architecture\nthat incorporates an attention mechanism into LSTM to combine the benefits of\nrecurrent and attention architectures. We conduct language modeling and speech\nrecognition experiments on the publicly available LibriSpeech corpus. We show\nthat conventional training on a paragraph-level corpus results in significant\nreductions in perplexity compared to training on a sentence-level corpus. We\nalso describe speech recognition experiments using long-span language models in\nsecond-pass re-ranking, and provide insights into the ability of such models to\ntake advantage of context beyond the current sentence.",
    "published": "2019-11-11T21:18:53Z",
    "pdf_url": "http://arxiv.org/pdf/1911.04571v1",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2210.11588v3",
    "title": "Anchored Speech Recognition with Neural Transducers",
    "authors": [
      "Desh Raj",
      "Junteng Jia",
      "Jay Mahadeokar",
      "Chunyang Wu",
      "Niko Moritz",
      "Xiaohui Zhang",
      "Ozlem Kalinli"
    ],
    "abstract": "Neural transducers have achieved human level performance on standard speech\nrecognition benchmarks. However, their performance significantly degrades in\nthe presence of cross-talk, especially when the primary speaker has a low\nsignal-to-noise ratio. Anchored speech recognition refers to a class of methods\nthat use information from an anchor segment (e.g., wake-words) to recognize\ndevice-directed speech while ignoring interfering background speech. In this\npaper, we investigate anchored speech recognition to make neural transducers\nrobust to background speech. We extract context information from the anchor\nsegment with a tiny auxiliary network, and use encoder biasing and joiner\ngating to guide the transducer towards the target speech. Moreover, to improve\nthe robustness of context embedding extraction, we propose auxiliary training\nobjectives to disentangle lexical content from speaking style. We evaluate our\nmethods on synthetic LibriSpeech-based mixtures comprising several SNR and\noverlap conditions; they improve relative word error rates by 19.6% over a\nstrong baseline, when averaged over all conditions.",
    "published": "2022-10-20T21:00:42Z",
    "pdf_url": "http://arxiv.org/pdf/2210.11588v3",
    "categories": [
      "eess.AS",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "9607023v1",
    "title": "Phonological modeling for continuous speech recognition in Korean",
    "authors": [
      "WonIl Lee",
      "Geunbae Lee",
      "Jong-Hyeok Lee"
    ],
    "abstract": "A new scheme to represent phonological changes during continuous speech\nrecognition is suggested. A phonological tag coupled with its morphological tag\nis designed to represent the conditions of Korean phonological changes. A\npairwise language model of these morphological and phonological tags is\nimplemented in Korean speech recognition system. Performance of the model is\nverified through the TDNN-based speech recognition experiments.",
    "published": "1996-07-18T01:56:13Z",
    "pdf_url": "http://arxiv.org/pdf/cmp-lg/9607023v1",
    "categories": [
      "cmp-lg",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "1711.01567v1",
    "title": "Robust Speech Recognition Using Generative Adversarial Networks",
    "authors": [
      "Anuroop Sriram",
      "Heewoo Jun",
      "Yashesh Gaur",
      "Sanjeev Satheesh"
    ],
    "abstract": "This paper describes a general, scalable, end-to-end framework that uses the\ngenerative adversarial network (GAN) objective to enable robust speech\nrecognition. Encoders trained with the proposed approach enjoy improved\ninvariance by learning to map noisy audio to the same embedding space as that\nof clean audio. Unlike previous methods, the new framework does not rely on\ndomain expertise or simplifying assumptions as are often needed in signal\nprocessing, and directly encourages robustness in a data-driven way. We show\nthe new approach improves simulated far-field speech recognition of vanilla\nsequence-to-sequence models without specialized front-ends or preprocessing.",
    "published": "2017-11-05T12:00:18Z",
    "pdf_url": "http://arxiv.org/pdf/1711.01567v1",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1905.03828v2",
    "title": "Universal Adversarial Perturbations for Speech Recognition Systems",
    "authors": [
      "Paarth Neekhara",
      "Shehzeen Hussain",
      "Prakhar Pandey",
      "Shlomo Dubnov",
      "Julian McAuley",
      "Farinaz Koushanfar"
    ],
    "abstract": "In this work, we demonstrate the existence of universal adversarial audio\nperturbations that cause mis-transcription of audio signals by automatic speech\nrecognition (ASR) systems. We propose an algorithm to find a single\nquasi-imperceptible perturbation, which when added to any arbitrary speech\nsignal, will most likely fool the victim speech recognition model. Our\nexperiments demonstrate the application of our proposed technique by crafting\naudio-agnostic universal perturbations for the state-of-the-art ASR system --\nMozilla DeepSpeech. Additionally, we show that such perturbations generalize to\na significant extent across models that are not available during training, by\nperforming a transferability test on a WaveNet based ASR system.",
    "published": "2019-05-09T19:35:30Z",
    "pdf_url": "http://arxiv.org/pdf/1905.03828v2",
    "categories": [
      "cs.LG",
      "cs.SD",
      "eess.AS",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1911.11610v6",
    "title": "Improving EEG based Continuous Speech Recognition",
    "authors": [
      "Gautam Krishna",
      "Co Tran",
      "Mason Carnahan",
      "Yan Han",
      "Ahmed H Tewfik"
    ],
    "abstract": "In this paper we introduce various techniques to improve the performance of\nelectroencephalography (EEG) features based continuous speech recognition (CSR)\nsystems. A connectionist temporal classification (CTC) based automatic speech\nrecognition (ASR) system was implemented for performing recognition. We\nintroduce techniques to initialize the weights of the recurrent layers in the\nencoder of the CTC model with more meaningful weights rather than with random\nweights and we make use of an external language model to improve the beam\nsearch during decoding time.\n  We finally study the problem of predicting articulatory features from EEG\nfeatures in this paper.",
    "published": "2019-11-24T16:00:49Z",
    "pdf_url": "http://arxiv.org/pdf/1911.11610v6",
    "categories": [
      "eess.AS",
      "cs.LG",
      "cs.SD",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1801.00061v1",
    "title": "Multichannel Robot Speech Recognition Database: MChRSR",
    "authors": [
      "José Novoa",
      "Juan Pablo Escudero",
      "Josué Fredes",
      "Jorge Wuth",
      "Rodrigo Mahu",
      "Néstor Becerra Yoma"
    ],
    "abstract": "In real human robot interaction (HRI) scenarios, speech recognition\nrepresents a major challenge due to robot noise, background noise and\ntime-varying acoustic channel. This document describes the procedure used to\nobtain the Multichannel Robot Speech Recognition Database (MChRSR). It is\ncomposed of 12 hours of multichannel evaluation data recorded in a real mobile\nHRI scenario. This database was recorded with a PR2 robot performing different\ntranslational and azimuthal movements. Accordingly, 16 evaluation sets were\nobtained re-recording the clean set of the Aurora 4 database in different\nmovement conditions.",
    "published": "2017-12-30T00:01:08Z",
    "pdf_url": "http://arxiv.org/pdf/1801.00061v1",
    "categories": [
      "cs.HC",
      "cs.RO"
    ]
  },
  {
    "arxiv_id": "2309.17395v1",
    "title": "AV-CPL: Continuous Pseudo-Labeling for Audio-Visual Speech Recognition",
    "authors": [
      "Andrew Rouditchenko",
      "Ronan Collobert",
      "Tatiana Likhomanenko"
    ],
    "abstract": "Audio-visual speech contains synchronized audio and visual information that\nprovides cross-modal supervision to learn representations for both automatic\nspeech recognition (ASR) and visual speech recognition (VSR). We introduce\ncontinuous pseudo-labeling for audio-visual speech recognition (AV-CPL), a\nsemi-supervised method to train an audio-visual speech recognition (AVSR) model\non a combination of labeled and unlabeled videos with continuously regenerated\npseudo-labels. Our models are trained for speech recognition from audio-visual\ninputs and can perform speech recognition using both audio and visual\nmodalities, or only one modality. Our method uses the same audio-visual model\nfor both supervised training and pseudo-label generation, mitigating the need\nfor external speech recognition models to generate pseudo-labels. AV-CPL\nobtains significant improvements in VSR performance on the LRS3 dataset while\nmaintaining practical ASR and AVSR performance. Finally, using visual-only\nspeech data, our method is able to leverage unlabeled visual speech to improve\nVSR.",
    "published": "2023-09-29T16:57:21Z",
    "pdf_url": "http://arxiv.org/pdf/2309.17395v1",
    "categories": [
      "cs.LG",
      "cs.SD",
      "eess.AS",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2406.02555v1",
    "title": "PhoWhisper: Automatic Speech Recognition for Vietnamese",
    "authors": [
      "Thanh-Thien Le",
      "Linh The Nguyen",
      "Dat Quoc Nguyen"
    ],
    "abstract": "We introduce PhoWhisper in five versions for Vietnamese automatic speech\nrecognition. PhoWhisper's robustness is achieved through fine-tuning the\nWhisper model on an 844-hour dataset that encompasses diverse Vietnamese\naccents. Our experimental study demonstrates state-of-the-art performances of\nPhoWhisper on benchmark Vietnamese ASR datasets. We have open-sourced\nPhoWhisper at: https://github.com/VinAIResearch/PhoWhisper",
    "published": "2024-03-27T13:10:06Z",
    "pdf_url": "http://arxiv.org/pdf/2406.02555v1",
    "categories": [
      "eess.AS",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2012.07467v1",
    "title": "AV Taris: Online Audio-Visual Speech Recognition",
    "authors": [
      "George Sterpu",
      "Naomi Harte"
    ],
    "abstract": "In recent years, Automatic Speech Recognition (ASR) technology has approached\nhuman-level performance on conversational speech under relatively clean\nlistening conditions. In more demanding situations involving distant\nmicrophones, overlapped speech, background noise, or natural dialogue\nstructures, the ASR error rate is at least an order of magnitude higher. The\nvisual modality of speech carries the potential to partially overcome these\nchallenges and contribute to the sub-tasks of speaker diarisation, voice\nactivity detection, and the recovery of the place of articulation, and can\ncompensate for up to 15dB of noise on average. This article develops AV Taris,\na fully differentiable neural network model capable of decoding audio-visual\nspeech in real time. We achieve this by connecting two recently proposed models\nfor audio-visual speech integration and online speech recognition, namely AV\nAlign and Taris. We evaluate AV Taris under the same conditions as AV Align and\nTaris on one of the largest publicly available audio-visual speech datasets,\nLRS2. Our results show that AV Taris is superior to the audio-only variant of\nTaris, demonstrating the utility of the visual modality to speech recognition\nwithin the real time decoding framework defined by Taris. Compared to an\nequivalent Transformer-based AV Align model that takes advantage of full\nsentences without meeting the real-time requirement, we report an absolute\ndegradation of approximately 3% with AV Taris. As opposed to the more popular\nalternative for online speech recognition, namely the RNN Transducer, Taris\noffers a greatly simplified fully differentiable training pipeline. As a\nconsequence, AV Taris has the potential to popularise the adoption of\nAudio-Visual Speech Recognition (AVSR) technology and overcome the inherent\nlimitations of the audio modality in less optimal listening conditions.",
    "published": "2020-12-14T12:39:02Z",
    "pdf_url": "http://arxiv.org/pdf/2012.07467v1",
    "categories": [
      "eess.AS",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "9608018v2",
    "title": "Algorithms for Speech Recognition and Language Processing",
    "authors": [
      "Mehryar Mohri",
      "Michael Riley",
      "Richard Sproat"
    ],
    "abstract": "Speech processing requires very efficient methods and algorithms.\nFinite-state transducers have been shown recently both to constitute a very\nuseful abstract model and to lead to highly efficient time and space algorithms\nin this field. We present these methods and algorithms and illustrate them in\nthe case of speech recognition. In addition to classical techniques, we\ndescribe many new algorithms such as minimization, global and local on-the-fly\ndeterminization of weighted automata, and efficient composition of transducers.\nThese methods are currently used in large vocabulary speech recognition\nsystems. We then show how the same formalism and algorithms can be used in\ntext-to-speech applications and related areas of language processing such as\nmorphology, syntax, and local grammars, in a very efficient way. The tutorial\nis self-contained and requires no specific computational or linguistic\nknowledge other than classical results.",
    "published": "1996-08-27T21:32:40Z",
    "pdf_url": "http://arxiv.org/pdf/cmp-lg/9608018v2",
    "categories": [
      "cmp-lg",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "1305.2847v1",
    "title": "An Overview of Hindi Speech Recognition",
    "authors": [
      "Neema Mishra",
      "Urmila Shrawankar",
      "V M Thakare"
    ],
    "abstract": "In this age of information technology, information access in a convenient\nmanner has gained importance. Since speech is a primary mode of communication\namong human beings, it is natural for people to expect to be able to carry out\nspoken dialogue with computer. Speech recognition system permits ordinary\npeople to speak to the computer to retrieve information. It is desirable to\nhave a human computer dialogue in local language. Hindi being the most widely\nspoken Language in India is the natural primary human language candidate for\nhuman machine interaction. There are five pairs of vowels in Hindi languages;\none member is longer than the other one. This paper describes an overview of\nspeech recognition system that includes how speech is produced and the\nproperties and characteristics of Hindi Phoneme.",
    "published": "2013-05-09T08:44:58Z",
    "pdf_url": "http://arxiv.org/pdf/1305.2847v1",
    "categories": [
      "cs.CL",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "1601.02553v2",
    "title": "Environmental Noise Embeddings for Robust Speech Recognition",
    "authors": [
      "Suyoun Kim",
      "Bhiksha Raj",
      "Ian Lane"
    ],
    "abstract": "We propose a novel deep neural network architecture for speech recognition\nthat explicitly employs knowledge of the background environmental noise within\na deep neural network acoustic model. A deep neural network is used to predict\nthe acoustic environment in which the system in being used. The discriminative\nembedding generated at the bottleneck layer of this network is then\nconcatenated with traditional acoustic features as input to a deep neural\nnetwork acoustic model. Through a series of experiments on Resource Management,\nCHiME-3 task, and Aurora4, we show that the proposed approach significantly\nimproves speech recognition accuracy in noisy and highly reverberant\nenvironments, outperforming multi-condition training, noise-aware training,\ni-vector framework, and multi-task learning on both in-domain noise and unseen\nnoise.",
    "published": "2016-01-11T18:38:18Z",
    "pdf_url": "http://arxiv.org/pdf/1601.02553v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "1703.04783v1",
    "title": "Multichannel End-to-end Speech Recognition",
    "authors": [
      "Tsubasa Ochiai",
      "Shinji Watanabe",
      "Takaaki Hori",
      "John R. Hershey"
    ],
    "abstract": "The field of speech recognition is in the midst of a paradigm shift:\nend-to-end neural networks are challenging the dominance of hidden Markov\nmodels as a core technology. Using an attention mechanism in a recurrent\nencoder-decoder architecture solves the dynamic time alignment problem,\nallowing joint end-to-end training of the acoustic and language modeling\ncomponents. In this paper we extend the end-to-end framework to encompass\nmicrophone array signal processing for noise suppression and speech enhancement\nwithin the acoustic encoding network. This allows the beamforming components to\nbe optimized jointly within the recognition architecture to improve the\nend-to-end speech recognition objective. Experiments on the noisy speech\nbenchmarks (CHiME-4 and AMI) show that our multichannel end-to-end system\noutperformed the attention-based baseline with input from a conventional\nadaptive beamformer.",
    "published": "2017-03-14T22:28:51Z",
    "pdf_url": "http://arxiv.org/pdf/1703.04783v1",
    "categories": [
      "cs.SD",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "1708.06073v2",
    "title": "The Microsoft 2017 Conversational Speech Recognition System",
    "authors": [
      "W. Xiong",
      "L. Wu",
      "F. Alleva",
      "J. Droppo",
      "X. Huang",
      "A. Stolcke"
    ],
    "abstract": "We describe the 2017 version of Microsoft's conversational speech recognition\nsystem, in which we update our 2016 system with recent developments in\nneural-network-based acoustic and language modeling to further advance the\nstate of the art on the Switchboard speech recognition task. The system adds a\nCNN-BLSTM acoustic model to the set of model architectures we combined\npreviously, and includes character-based and dialog session aware LSTM language\nmodels in rescoring. For system combination we adopt a two-stage approach,\nwhereby subsets of acoustic models are first combined at the senone/frame\nlevel, followed by a word-level voting via confusion networks. We also added a\nconfusion network rescoring step after system combination. The resulting system\nyields a 5.1\\% word error rate on the 2000 Switchboard evaluation set.",
    "published": "2017-08-21T03:17:23Z",
    "pdf_url": "http://arxiv.org/pdf/1708.06073v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "1710.11201v1",
    "title": "Deep word embeddings for visual speech recognition",
    "authors": [
      "Themos Stafylakis",
      "Georgios Tzimiropoulos"
    ],
    "abstract": "In this paper we present a deep learning architecture for extracting word\nembeddings for visual speech recognition. The embeddings summarize the\ninformation of the mouth region that is relevant to the problem of word\nrecognition, while suppressing other types of variability such as speaker, pose\nand illumination. The system is comprised of a spatiotemporal convolutional\nlayer, a Residual Network and bidirectional LSTMs and is trained on the\nLipreading in-the-wild database. We first show that the proposed architecture\ngoes beyond state-of-the-art on closed-set word identification, by attaining\n11.92% error rate on a vocabulary of 500 words. We then examine the capacity of\nthe embeddings in modelling words unseen during training. We deploy\nProbabilistic Linear Discriminant Analysis (PLDA) to model the embeddings and\nperform low-shot learning experiments on words unseen during training. The\nexperiments demonstrate that word-level visual speech recognition is feasible\neven in cases where the target words are not included in the training set.",
    "published": "2017-10-30T19:09:29Z",
    "pdf_url": "http://arxiv.org/pdf/1710.11201v1",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1803.03759v2",
    "title": "Speech Recognition: Keyword Spotting Through Image Recognition",
    "authors": [
      "Sanjay Krishna Gouda",
      "Salil Kanetkar",
      "David Harrison",
      "Manfred K Warmuth"
    ],
    "abstract": "The problem of identifying voice commands has always been a challenge due to\nthe presence of noise and variability in speed, pitch, etc. We will compare the\nefficacies of several neural network architectures for the speech recognition\nproblem. In particular, we will build a model to determine whether a one second\naudio clip contains a particular word (out of a set of 10), an unknown word, or\nsilence. The models to be implemented are a CNN recommended by the Tensorflow\nSpeech Recognition tutorial, a low-latency CNN, and an adversarially trained\nCNN. The result is a demonstration of how to convert a problem in audio\nrecognition to the better-studied domain of image classification, where the\npowerful techniques of convolutional neural networks are fully developed.\nAdditionally, we demonstrate the applicability of the technique of Virtual\nAdversarial Training (VAT) to this problem domain, functioning as a powerful\nregularizer with promising potential future applications.",
    "published": "2018-03-10T05:16:18Z",
    "pdf_url": "http://arxiv.org/pdf/1803.03759v2",
    "categories": [
      "stat.ML",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2107.00921v1",
    "title": "Supervised Contrastive Learning for Accented Speech Recognition",
    "authors": [
      "Tao Han",
      "Hantao Huang",
      "Ziang Yang",
      "Wei Han"
    ],
    "abstract": "Neural network based speech recognition systems suffer from performance\ndegradation due to accented speech, especially unfamiliar accents. In this\npaper, we study the supervised contrastive learning framework for accented\nspeech recognition. To build different views (similar \"positive\" data samples)\nfor contrastive learning, three data augmentation techniques including noise\ninjection, spectrogram augmentation and TTS-same-sentence generation are\nfurther investigated. From the experiments on the Common Voice dataset, we have\nshown that contrastive learning helps to build data-augmentation invariant and\npronunciation invariant representations, which significantly outperforms\ntraditional joint training methods in both zero-shot and full-shot settings.\nExperiments show that contrastive learning can improve accuracy by 3.66%\n(zero-shot) and 3.78% (full-shot) on average, comparing to the joint training\nmethod.",
    "published": "2021-07-02T09:23:33Z",
    "pdf_url": "http://arxiv.org/pdf/2107.00921v1",
    "categories": [
      "cs.SD",
      "cs.LG",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "1912.08639v2",
    "title": "Detecting Adversarial Attacks On Audiovisual Speech Recognition",
    "authors": [
      "Pingchuan Ma",
      "Stavros Petridis",
      "Maja Pantic"
    ],
    "abstract": "Adversarial attacks pose a threat to deep learning models. However, research\non adversarial detection methods, especially in the multi-modal domain, is very\nlimited. In this work, we propose an efficient and straightforward detection\nmethod based on the temporal correlation between audio and video streams. The\nmain idea is that the correlation between audio and video in adversarial\nexamples will be lower than benign examples due to added adversarial noise. We\nuse the synchronisation confidence score as a proxy for audiovisual correlation\nand based on it we can detect adversarial attacks. To the best of our\nknowledge, this is the first work on detection of adversarial attacks on\naudiovisual speech recognition models. We apply recent adversarial attacks on\ntwo audiovisual speech recognition models trained on the GRID and LRW datasets.\nThe experimental results demonstrate that the proposed approach is an effective\nway for detecting such attacks.",
    "published": "2019-12-18T14:43:43Z",
    "pdf_url": "http://arxiv.org/pdf/1912.08639v2",
    "categories": [
      "cs.CV",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2005.08100v1",
    "title": "Conformer: Convolution-augmented Transformer for Speech Recognition",
    "authors": [
      "Anmol Gulati",
      "James Qin",
      "Chung-Cheng Chiu",
      "Niki Parmar",
      "Yu Zhang",
      "Jiahui Yu",
      "Wei Han",
      "Shibo Wang",
      "Zhengdong Zhang",
      "Yonghui Wu",
      "Ruoming Pang"
    ],
    "abstract": "Recently Transformer and Convolution neural network (CNN) based models have\nshown promising results in Automatic Speech Recognition (ASR), outperforming\nRecurrent neural networks (RNNs). Transformer models are good at capturing\ncontent-based global interactions, while CNNs exploit local features\neffectively. In this work, we achieve the best of both worlds by studying how\nto combine convolution neural networks and transformers to model both local and\nglobal dependencies of an audio sequence in a parameter-efficient way. To this\nregard, we propose the convolution-augmented transformer for speech\nrecognition, named Conformer. Conformer significantly outperforms the previous\nTransformer and CNN based models achieving state-of-the-art accuracies. On the\nwidely used LibriSpeech benchmark, our model achieves WER of 2.1%/4.3% without\nusing a language model and 1.9%/3.9% with an external language model on\ntest/testother. We also observe competitive performance of 2.7%/6.3% with a\nsmall model of only 10M parameters.",
    "published": "2020-05-16T20:56:25Z",
    "pdf_url": "http://arxiv.org/pdf/2005.08100v1",
    "categories": [
      "eess.AS",
      "cs.LG",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "2104.10757v1",
    "title": "Scene-aware Far-field Automatic Speech Recognition",
    "authors": [
      "Zhenyu Tang",
      "Dinesh Manocha"
    ],
    "abstract": "We propose a novel method for generating scene-aware training data for\nfar-field automatic speech recognition. We use a deep learning-based estimator\nto non-intrusively compute the sub-band reverberation time of an environment\nfrom its speech samples. We model the acoustic characteristics of a scene with\nits reverberation time and represent it using a multivariate Gaussian\ndistribution. We use this distribution to select acoustic impulse responses\nfrom a large real-world dataset for augmenting speech data. The speech\nrecognition system trained on our scene-aware data consistently outperforms the\nsystem trained using many more random acoustic impulse responses on the REVERB\nand the AMI far-field benchmarks. In practice, we obtain 2.64% absolute\nimprovement in word error rate compared with using training data of the same\nsize with uniformly distributed reverberation times.",
    "published": "2021-04-21T20:58:30Z",
    "pdf_url": "http://arxiv.org/pdf/2104.10757v1",
    "categories": [
      "eess.AS",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "1909.12408v3",
    "title": "Optimizing Speech Recognition For The Edge",
    "authors": [
      "Yuan Shangguan",
      "Jian Li",
      "Qiao Liang",
      "Raziel Alvarez",
      "Ian McGraw"
    ],
    "abstract": "While most deployed speech recognition systems today still run on servers, we\nare in the midst of a transition towards deployments on edge devices. This leap\nto the edge is powered by the progression from traditional speech recognition\npipelines to end-to-end (E2E) neural architectures, and the parallel\ndevelopment of more efficient neural network topologies and optimization\ntechniques. Thus, we are now able to create highly accurate speech recognizers\nthat are both small and fast enough to execute on typical mobile devices. In\nthis paper, we begin with a baseline RNN-Transducer architecture comprised of\nLong Short-Term Memory (LSTM) layers. We then experiment with a variety of more\ncomputationally efficient layer types, as well as apply optimization techniques\nlike neural connection pruning and parameter quantization to construct a small,\nhigh quality, on-device speech recognizer that is an order of magnitude smaller\nthan the baseline system without any optimizations.",
    "published": "2019-09-26T21:43:53Z",
    "pdf_url": "http://arxiv.org/pdf/1909.12408v3",
    "categories": [
      "cs.CL",
      "cs.LG",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2011.01570v1",
    "title": "Dynamic latency speech recognition with asynchronous revision",
    "authors": [
      "Mingkun Huang",
      "Meng Cai",
      "Jun Zhang",
      "Yang Zhang",
      "Yongbin You",
      "Yi He",
      "Zejun Ma"
    ],
    "abstract": "In this work we propose an inference technique, asynchronous revision, to\nunify streaming and non-streaming speech recognition models. Specifically, we\nachieve dynamic latency with only one model by using arbitrary right context\nduring inference. The model is composed of a stack of convolutional layers for\naudio encoding. In inference stage, the history states of encoder and decoder\ncan be asynchronously revised to trade off between the latency and the accuracy\nof the model. To alleviate training and inference mismatch, we propose a\ntraining technique, segment cropping, which randomly splits input utterances\ninto several segments with forward connections. This allows us to have dynamic\nlatency speech recognition results with large improvements in accuracy.\nExperiments show that our dynamic latency model with asynchronous revision\ngives 8\\%-14\\% relative improvements over the streaming models.",
    "published": "2020-11-03T08:50:43Z",
    "pdf_url": "http://arxiv.org/pdf/2011.01570v1",
    "categories": [
      "eess.AS",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "1610.05256v2",
    "title": "Achieving Human Parity in Conversational Speech Recognition",
    "authors": [
      "W. Xiong",
      "J. Droppo",
      "X. Huang",
      "F. Seide",
      "M. Seltzer",
      "A. Stolcke",
      "D. Yu",
      "G. Zweig"
    ],
    "abstract": "Conversational speech recognition has served as a flagship speech recognition\ntask since the release of the Switchboard corpus in the 1990s. In this paper,\nwe measure the human error rate on the widely used NIST 2000 test set, and find\nthat our latest automated system has reached human parity. The error rate of\nprofessional transcribers is 5.9% for the Switchboard portion of the data, in\nwhich newly acquainted pairs of people discuss an assigned topic, and 11.3% for\nthe CallHome portion where friends and family members have open-ended\nconversations. In both cases, our automated system establishes a new state of\nthe art, and edges past the human benchmark, achieving error rates of 5.8% and\n11.0%, respectively. The key to our system's performance is the use of various\nconvolutional and LSTM acoustic model architectures, combined with a novel\nspatial smoothing method and lattice-free MMI acoustic training, multiple\nrecurrent neural network language modeling approaches, and a systematic use of\nsystem combination.",
    "published": "2016-10-17T18:40:50Z",
    "pdf_url": "http://arxiv.org/pdf/1610.05256v2",
    "categories": [
      "cs.CL",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "1806.02786v1",
    "title": "Domain Adversarial Training for Accented Speech Recognition",
    "authors": [
      "Sining Sun",
      "Ching-Feng Yeh",
      "Mei-Yuh Hwang",
      "Mari Ostendorf",
      "Lei Xie"
    ],
    "abstract": "In this paper, we propose a domain adversarial training (DAT) algorithm to\nalleviate the accented speech recognition problem. In order to reduce the\nmismatch between labeled source domain data (\"standard\" accent) and unlabeled\ntarget domain data (with heavy accents), we augment the learning objective for\na Kaldi TDNN network with a domain adversarial training (DAT) objective to\nencourage the model to learn accent-invariant features. In experiments with\nthree Mandarin accents, we show that DAT yields up to 7.45% relative character\nerror rate reduction when we do not have transcriptions of the accented speech,\ncompared with the baseline trained on standard accent data only. We also find a\nbenefit from DAT when used in combination with training from automatic\ntranscriptions on the accented data. Furthermore, we find that DAT is superior\nto multi-task learning for accented speech recognition.",
    "published": "2018-06-07T17:02:54Z",
    "pdf_url": "http://arxiv.org/pdf/1806.02786v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2102.00291v1",
    "title": "Speech Recognition by Simply Fine-tuning BERT",
    "authors": [
      "Wen-Chin Huang",
      "Chia-Hua Wu",
      "Shang-Bao Luo",
      "Kuan-Yu Chen",
      "Hsin-Min Wang",
      "Tomoki Toda"
    ],
    "abstract": "We propose a simple method for automatic speech recognition (ASR) by\nfine-tuning BERT, which is a language model (LM) trained on large-scale\nunlabeled text data and can generate rich contextual representations. Our\nassumption is that given a history context sequence, a powerful LM can narrow\nthe range of possible choices and the speech signal can be used as a simple\nclue. Hence, comparing to conventional ASR systems that train a powerful\nacoustic model (AM) from scratch, we believe that speech recognition is\npossible by simply fine-tuning a BERT model. As an initial study, we\ndemonstrate the effectiveness of the proposed idea on the AISHELL dataset and\nshow that stacking a very simple AM on top of BERT can yield reasonable\nperformance.",
    "published": "2021-01-30T19:06:14Z",
    "pdf_url": "http://arxiv.org/pdf/2102.00291v1",
    "categories": [
      "cs.SD",
      "cs.CL",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2106.04897v2",
    "title": "Unsupervised Automatic Speech Recognition: A Review",
    "authors": [
      "Hanan Aldarmaki",
      "Asad Ullah",
      "Nazar Zaki"
    ],
    "abstract": "Automatic Speech Recognition (ASR) systems can be trained to achieve\nremarkable performance given large amounts of manually transcribed speech, but\nlarge labeled data sets can be difficult or expensive to acquire for all\nlanguages of interest. In this paper, we review the research literature to\nidentify models and ideas that could lead to fully unsupervised ASR, including\nunsupervised segmentation of the speech signal, unsupervised mapping from\nspeech segments to text, and semi-supervised models with nominal amounts of\nlabeled examples. The objective of the study is to identify the limitations of\nwhat can be learned from speech data alone and to understand the minimum\nrequirements for speech recognition. Identifying these limitations would help\noptimize the resources and efforts in ASR development for low-resource\nlanguages.",
    "published": "2021-06-09T08:33:20Z",
    "pdf_url": "http://arxiv.org/pdf/2106.04897v2",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2111.00161v3",
    "title": "Pseudo-Labeling for Massively Multilingual Speech Recognition",
    "authors": [
      "Loren Lugosch",
      "Tatiana Likhomanenko",
      "Gabriel Synnaeve",
      "Ronan Collobert"
    ],
    "abstract": "Semi-supervised learning through pseudo-labeling has become a staple of\nstate-of-the-art monolingual speech recognition systems. In this work, we\nextend pseudo-labeling to massively multilingual speech recognition with 60\nlanguages. We propose a simple pseudo-labeling recipe that works well even with\nlow-resource languages: train a supervised multilingual model, fine-tune it\nwith semi-supervised learning on a target language, generate pseudo-labels for\nthat language, and train a final model using pseudo-labels for all languages,\neither from scratch or by fine-tuning. Experiments on the labeled Common Voice\nand unlabeled VoxPopuli datasets show that our recipe can yield a model with\nbetter performance for many languages that also transfers well to LibriSpeech.",
    "published": "2021-10-30T03:30:17Z",
    "pdf_url": "http://arxiv.org/pdf/2111.00161v3",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2201.01763v3",
    "title": "Robust Self-Supervised Audio-Visual Speech Recognition",
    "authors": [
      "Bowen Shi",
      "Wei-Ning Hsu",
      "Abdelrahman Mohamed"
    ],
    "abstract": "Audio-based automatic speech recognition (ASR) degrades significantly in\nnoisy environments and is particularly vulnerable to interfering speech, as the\nmodel cannot determine which speaker to transcribe. Audio-visual speech\nrecognition (AVSR) systems improve robustness by complementing the audio stream\nwith the visual information that is invariant to noise and helps the model\nfocus on the desired speaker. However, previous AVSR work focused solely on the\nsupervised learning setup; hence the progress was hindered by the amount of\nlabeled data available. In this work, we present a self-supervised AVSR\nframework built upon Audio-Visual HuBERT (AV-HuBERT), a state-of-the-art\naudio-visual speech representation learning model. On the largest available\nAVSR benchmark dataset LRS3, our approach outperforms prior state-of-the-art by\n~50% (28.0% vs. 14.1%) using less than 10% of labeled data (433hr vs. 30hr) in\nthe presence of babble noise, while reducing the WER of an audio-based model by\nover 75% (25.8% vs. 5.8%) on average.",
    "published": "2022-01-05T18:50:50Z",
    "pdf_url": "http://arxiv.org/pdf/2201.01763v3",
    "categories": [
      "cs.SD",
      "cs.CV",
      "cs.LG",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2306.07926v1",
    "title": "A Theory of Unsupervised Speech Recognition",
    "authors": [
      "Liming Wang",
      "Mark Hasegawa-Johnson",
      "Chang D. Yoo"
    ],
    "abstract": "Unsupervised speech recognition (ASR-U) is the problem of learning automatic\nspeech recognition (ASR) systems from unpaired speech-only and text-only\ncorpora. While various algorithms exist to solve this problem, a theoretical\nframework is missing from studying their properties and addressing such issues\nas sensitivity to hyperparameters and training instability. In this paper, we\nproposed a general theoretical framework to study the properties of ASR-U\nsystems based on random matrix theory and the theory of neural tangent kernels.\nSuch a framework allows us to prove various learnability conditions and sample\ncomplexity bounds of ASR-U. Extensive ASR-U experiments on synthetic languages\nwith three classes of transition graphs provide strong empirical evidence for\nour theory (code available at cactuswiththoughts/UnsupASRTheory.git).",
    "published": "2023-06-09T08:12:27Z",
    "pdf_url": "http://arxiv.org/pdf/2306.07926v1",
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.LG",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "2312.06558v1",
    "title": "Deep Photonic Reservoir Computer for Speech Recognition",
    "authors": [
      "Enrico Picco",
      "Alessandro Lupo",
      "Serge Massar"
    ],
    "abstract": "Speech recognition is a critical task in the field of artificial intelligence\nand has witnessed remarkable advancements thanks to large and complex neural\nnetworks, whose training process typically requires massive amounts of labeled\ndata and computationally intensive operations. An alternative paradigm,\nreservoir computing, is energy efficient and is well adapted to implementation\nin physical substrates, but exhibits limitations in performance when compared\nto more resource-intensive machine learning algorithms. In this work we address\nthis challenge by investigating different architectures of interconnected\nreservoirs, all falling under the umbrella of deep reservoir computing. We\npropose a photonic-based deep reservoir computer and evaluate its effectiveness\non different speech recognition tasks. We show specific design choices that aim\nto simplify the practical implementation of a reservoir computer while\nsimultaneously achieving high-speed processing of high-dimensional audio\nsignals. Overall, with the present work we hope to help the advancement of\nlow-power and high-performance neuromorphic hardware.",
    "published": "2023-12-11T17:43:58Z",
    "pdf_url": "http://arxiv.org/pdf/2312.06558v1",
    "categories": [
      "cs.NE",
      "cs.SD",
      "eess.AS",
      "physics.optics"
    ]
  },
  {
    "arxiv_id": "2406.00038v1",
    "title": "ViSpeR: Multilingual Audio-Visual Speech Recognition",
    "authors": [
      "Sanath Narayan",
      "Yasser Abdelaziz Dahou Djilali",
      "Ankit Singh",
      "Eustache Le Bihan",
      "Hakim Hacid"
    ],
    "abstract": "This work presents an extensive and detailed study on Audio-Visual Speech\nRecognition (AVSR) for five widely spoken languages: Chinese, Spanish, English,\nArabic, and French. We have collected large-scale datasets for each language\nexcept for English, and have engaged in the training of supervised learning\nmodels. Our model, ViSpeR, is trained in a multi-lingual setting, resulting in\ncompetitive performance on newly established benchmarks for each language. The\ndatasets and models are released to the community with an aim to serve as a\nfoundation for triggering and feeding further research work and exploration on\nAudio-Visual Speech Recognition, an increasingly important area of research.\nCode available at\n\\href{https://github.com/YasserdahouML/visper}{https://github.com/YasserdahouML/visper}.",
    "published": "2024-05-27T14:48:51Z",
    "pdf_url": "http://arxiv.org/pdf/2406.00038v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "2406.13431v2",
    "title": "Children's Speech Recognition through Discrete Token Enhancement",
    "authors": [
      "Vrunda N. Sukhadia",
      "Shammur Absar Chowdhury"
    ],
    "abstract": "Children's speech recognition is considered a low-resource task mainly due to\nthe lack of publicly available data. There are several reasons for such data\nscarcity, including expensive data collection and annotation processes, and\ndata privacy, among others. Transforming speech signals into discrete tokens\nthat do not carry sensitive information but capture both linguistic and\nacoustic information could be a solution for privacy concerns. In this study,\nwe investigate the integration of discrete speech tokens into children's speech\nrecognition systems as input without significantly degrading the ASR\nperformance. Additionally, we explored single-view and multi-view strategies\nfor creating these discrete labels. Furthermore, we tested the models for\ngeneralization capabilities with unseen domain and nativity dataset. Results\nreveal that the discrete token ASR for children achieves nearly equivalent\nperformance with an approximate 83% reduction in parameters.",
    "published": "2024-06-19T10:45:12Z",
    "pdf_url": "http://arxiv.org/pdf/2406.13431v2",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2409.07210v1",
    "title": "Enhancing CTC-Based Visual Speech Recognition",
    "authors": [
      "Hendrik Laux",
      "Anke Schmeink"
    ],
    "abstract": "This paper presents LiteVSR2, an enhanced version of our previously\nintroduced efficient approach to Visual Speech Recognition (VSR). Building upon\nour knowledge distillation framework from a pre-trained Automatic Speech\nRecognition (ASR) model, we introduce two key improvements: a stabilized video\npreprocessing technique and feature normalization in the distillation process.\nThese improvements yield substantial performance gains on the LRS2 and LRS3\nbenchmarks, positioning LiteVSR2 as the current best CTC-based VSR model\nwithout increasing the volume of training data or computational resources\nutilized. Furthermore, we explore the scalability of our approach by examining\nperformance metrics across varying model complexities and training data\nvolumes. LiteVSR2 maintains the efficiency of its predecessor while\nsignificantly enhancing accuracy, thereby demonstrating the potential for\nresource-efficient advancements in VSR technology.",
    "published": "2024-09-11T12:02:42Z",
    "pdf_url": "http://arxiv.org/pdf/2409.07210v1",
    "categories": [
      "cs.CV",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2410.03752v1",
    "title": "Efficient Streaming LLM for Speech Recognition",
    "authors": [
      "Junteng Jia",
      "Gil Keren",
      "Wei Zhou",
      "Egor Lakomkin",
      "Xiaohui Zhang",
      "Chunyang Wu",
      "Frank Seide",
      "Jay Mahadeokar",
      "Ozlem Kalinli"
    ],
    "abstract": "Recent works have shown that prompting large language models with audio\nencodings can unlock speech recognition capabilities. However, existing\ntechniques do not scale efficiently, especially while handling long form\nstreaming audio inputs -- not only do they extrapolate poorly beyond the audio\nlength seen during training, but they are also computationally inefficient due\nto the quadratic cost of attention.\n  In this work, we introduce SpeechLLM-XL, a linear scaling decoder-only model\nfor streaming speech recognition. We process audios in configurable chunks\nusing limited attention window for reduced computation, and the text tokens for\neach audio chunk are generated auto-regressively until an EOS is predicted.\nDuring training, the transcript is segmented into chunks, using a CTC forced\nalignment estimated from encoder output. SpeechLLM-XL with 1.28 seconds chunk\nsize achieves 2.7%/6.7% WER on LibriSpeech test clean/other, and it shows no\nquality degradation on long form utterances 10x longer than the training\nutterances.",
    "published": "2024-10-02T01:54:35Z",
    "pdf_url": "http://arxiv.org/pdf/2410.03752v1",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2506.02178v1",
    "title": "Cocktail-Party Audio-Visual Speech Recognition",
    "authors": [
      "Thai-Binh Nguyen",
      "Ngoc-Quan Pham",
      "Alexander Waibel"
    ],
    "abstract": "Audio-Visual Speech Recognition (AVSR) offers a robust solution for speech\nrecognition in challenging environments, such as cocktail-party scenarios,\nwhere relying solely on audio proves insufficient. However, current AVSR models\nare often optimized for idealized scenarios with consistently active speakers,\noverlooking the complexities of real-world settings that include both speaking\nand silent facial segments. This study addresses this gap by introducing a\nnovel audio-visual cocktail-party dataset designed to benchmark current AVSR\nsystems and highlight the limitations of prior approaches in realistic noisy\nconditions. Additionally, we contribute a 1526-hour AVSR dataset comprising\nboth talking-face and silent-face segments, enabling significant performance\ngains in cocktail-party environments. Our approach reduces WER by 67% relative\nto the state-of-the-art, reducing WER from 119% to 39.2% in extreme noise,\nwithout relying on explicit segmentation cues.",
    "published": "2025-06-02T19:07:51Z",
    "pdf_url": "http://arxiv.org/pdf/2506.02178v1",
    "categories": [
      "cs.SD",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2509.01939v1",
    "title": "Group Relative Policy Optimization for Speech Recognition",
    "authors": [
      "Prashanth Gurunath Shivakumar",
      "Yile Gu",
      "Ankur Gandhe",
      "Ivan Bulyko"
    ],
    "abstract": "Speech Recognition has seen a dramatic shift towards adopting Large Language\nModels (LLMs). This shift is partly driven by good scalability properties\ndemonstrated by LLMs, ability to leverage large amounts of labelled, unlabelled\nspeech and text data, streaming capabilities with auto-regressive framework and\nmulti-tasking with instruction following characteristics of LLMs. However,\nsimple next-token prediction objective, typically employed with LLMs, have\ncertain limitations in performance and challenges with hallucinations. In this\npaper, we propose application of Group Relative Policy Optimization (GRPO) to\nenable reinforcement learning from human feedback for automatic speech\nrecognition (ASR). We design simple rule based reward functions to guide the\npolicy updates. We demonstrate significant improvements in word error rate\n(upto 18.4% relative), reduction in hallucinations, increased robustness on\nout-of-domain datasets and effectiveness in domain adaptation.",
    "published": "2025-09-02T04:20:12Z",
    "pdf_url": "http://arxiv.org/pdf/2509.01939v1",
    "categories": [
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2108.00084v1",
    "title": "The History of Speech Recognition to the Year 2030",
    "authors": [
      "Awni Hannun"
    ],
    "abstract": "The decade from 2010 to 2020 saw remarkable improvements in automatic speech\nrecognition. Many people now use speech recognition on a daily basis, for\nexample to perform voice search queries, send text messages, and interact with\nvoice assistants like Amazon Alexa and Siri by Apple. Before 2010 most people\nrarely used speech recognition. Given the remarkable changes in the state of\nspeech recognition over the previous decade, what can we expect over the coming\ndecade? I attempt to forecast the state of speech recognition research and\napplications by the year 2030. While the changes to general speech recognition\naccuracy will not be as dramatic as in the previous decade, I suggest we have\nan exciting decade of progress in speech technology ahead of us.",
    "published": "2021-07-30T21:19:33Z",
    "pdf_url": "http://arxiv.org/pdf/2108.00084v1",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2312.10959v1",
    "title": "Speaker Mask Transformer for Multi-talker Overlapped Speech Recognition",
    "authors": [
      "Peng Shen",
      "Xugang Lu",
      "Hisashi Kawai"
    ],
    "abstract": "Multi-talker overlapped speech recognition remains a significant challenge,\nrequiring not only speech recognition but also speaker diarization tasks to be\naddressed. In this paper, to better address these tasks, we first introduce\nspeaker labels into an autoregressive transformer-based speech recognition\nmodel to support multi-speaker overlapped speech recognition. Then, to improve\nspeaker diarization, we propose a novel speaker mask branch to detection the\nspeech segments of individual speakers. With the proposed model, we can perform\nboth speech recognition and speaker diarization tasks simultaneously using a\nsingle model. Experimental results on the LibriSpeech-based overlapped dataset\ndemonstrate the effectiveness of the proposed method in both speech recognition\nand speaker diarization tasks, particularly enhancing the accuracy of speaker\ndiarization in relatively complex multi-talker scenarios.",
    "published": "2023-12-18T06:29:53Z",
    "pdf_url": "http://arxiv.org/pdf/2312.10959v1",
    "categories": [
      "cs.SD",
      "cs.CL",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "0001023v1",
    "title": "Structured Language Modeling for Speech Recognition",
    "authors": [
      "Ciprian Chelba",
      "Frederick Jelinek"
    ],
    "abstract": "A new language model for speech recognition is presented. The model develops\nhidden hierarchical syntactic-like structure incrementally and uses it to\nextract meaningful information from the word history, thus complementing the\nlocality of currently used trigram models. The structured language model (SLM)\nand its performance in a two-pass speech recognizer --- lattice decoding ---\nare presented. Experiments on the WSJ corpus show an improvement in both\nperplexity (PPL) and word error rate (WER) over conventional trigram models.",
    "published": "2000-01-25T19:35:01Z",
    "pdf_url": "http://arxiv.org/pdf/cs/0001023v1",
    "categories": [
      "cs.CL",
      "G.3, I.2.7, I.5.1, I.5.4"
    ]
  },
  {
    "arxiv_id": "1711.10271v1",
    "title": "Exploiting Nontrivial Connectivity for Automatic Speech Recognition",
    "authors": [
      "Marius Paraschiv",
      "Lasse Borgholt",
      "Tycho Max Sylvester Tax",
      "Marco Singh",
      "Lars Maaløe"
    ],
    "abstract": "Nontrivial connectivity has allowed the training of very deep networks by\naddressing the problem of vanishing gradients and offering a more efficient\nmethod of reusing parameters. In this paper we make a comparison between\nresidual networks, densely-connected networks and highway networks on an image\nclassification task. Next, we show that these methodologies can easily be\ndeployed into automatic speech recognition and provide significant improvements\nto existing models.",
    "published": "2017-11-28T13:13:41Z",
    "pdf_url": "http://arxiv.org/pdf/1711.10271v1",
    "categories": [
      "cs.SD",
      "eess.AS",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2108.12953v1",
    "title": "Multi-Channel Transformer Transducer for Speech Recognition",
    "authors": [
      "Feng-Ju Chang",
      "Martin Radfar",
      "Athanasios Mouchtaris",
      "Maurizio Omologo"
    ],
    "abstract": "Multi-channel inputs offer several advantages over single-channel, to improve\nthe robustness of on-device speech recognition systems. Recent work on\nmulti-channel transformer, has proposed a way to incorporate such inputs into\nend-to-end ASR for improved accuracy. However, this approach is characterized\nby a high computational complexity, which prevents it from being deployed in\non-device systems. In this paper, we present a novel speech recognition model,\nMulti-Channel Transformer Transducer (MCTT), which features end-to-end\nmulti-channel training, low computation cost, and low latency so that it is\nsuitable for streaming decoding in on-device speech recognition. In a far-field\nin-house dataset, our MCTT outperforms stagewise multi-channel models with\ntransformer-transducer up to 6.01% relative WER improvement (WERR). In\naddition, MCTT outperforms the multi-channel transformer up to 11.62% WERR, and\nis 15.8 times faster in terms of inference speed. We further show that we can\nimprove the computational cost of MCTT by constraining the future and previous\ncontext in attention computations.",
    "published": "2021-08-30T01:50:51Z",
    "pdf_url": "http://arxiv.org/pdf/2108.12953v1",
    "categories": [
      "eess.AS",
      "cs.LG",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "2010.10682v3",
    "title": "VenoMave: Targeted Poisoning Against Speech Recognition",
    "authors": [
      "Hojjat Aghakhani",
      "Lea Schönherr",
      "Thorsten Eisenhofer",
      "Dorothea Kolossa",
      "Thorsten Holz",
      "Christopher Kruegel",
      "Giovanni Vigna"
    ],
    "abstract": "Despite remarkable improvements, automatic speech recognition is susceptible\nto adversarial perturbations. Compared to standard machine learning\narchitectures, these attacks are significantly more challenging, especially\nsince the inputs to a speech recognition system are time series that contain\nboth acoustic and linguistic properties of speech. Extracting all\nrecognition-relevant information requires more complex pipelines and an\nensemble of specialized components. Consequently, an attacker needs to consider\nthe entire pipeline. In this paper, we present VENOMAVE, the first\ntraining-time poisoning attack against speech recognition. Similar to the\npredominantly studied evasion attacks, we pursue the same goal: leading the\nsystem to an incorrect and attacker-chosen transcription of a target audio\nwaveform. In contrast to evasion attacks, however, we assume that the attacker\ncan only manipulate a small part of the training data without altering the\ntarget audio waveform at runtime. We evaluate our attack on two datasets:\nTIDIGITS and Speech Commands. When poisoning less than 0.17% of the dataset,\nVENOMAVE achieves attack success rates of more than 80.0%, without access to\nthe victim's network architecture or hyperparameters. In a more realistic\nscenario, when the target audio waveform is played over the air in different\nrooms, VENOMAVE maintains a success rate of up to 73.3%. Finally, VENOMAVE\nachieves an attack transferability rate of 36.4% between two different model\narchitectures.",
    "published": "2020-10-21T00:30:08Z",
    "pdf_url": "http://arxiv.org/pdf/2010.10682v3",
    "categories": [
      "cs.SD",
      "cs.CR",
      "cs.LG",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2210.06472v1",
    "title": "Inner speech recognition through electroencephalographic signals",
    "authors": [
      "Francesca Gasparini",
      "Elisa Cazzaniga",
      "Aurora Saibene"
    ],
    "abstract": "This work focuses on inner speech recognition starting from EEG signals.\nInner speech recognition is defined as the internalized process in which the\nperson thinks in pure meanings, generally associated with an auditory imagery\nof own inner \"voice\". The decoding of the EEG into text should be understood as\nthe classification of a limited number of words (commands) or the presence of\nphonemes (units of sound that make up words). Speech-related BCIs provide\neffective vocal communication strategies for controlling devices through speech\ncommands interpreted from brain signals, improving the quality of life of\npeople who have lost the capability to speak, by restoring communication with\ntheir environment. Two public inner speech datasets are analysed. Using this\ndata, some classification models are studied and implemented starting from\nbasic methods such as Support Vector Machines, to ensemble methods such as the\neXtreme Gradient Boosting classifier up to the use of neural networks such as\nLong Short Term Memory (LSTM) and Bidirectional Long Short Term Memory\n(BiLSTM). With the LSTM and BiLSTM models, generally not used in the literature\nof inner speech recognition, results in line with or superior to those present\nin the stateof-the-art are obtained.",
    "published": "2022-10-11T08:29:12Z",
    "pdf_url": "http://arxiv.org/pdf/2210.06472v1",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.SD",
      "eess.AS",
      "q-bio.NC"
    ]
  },
  {
    "arxiv_id": "2211.08726v2",
    "title": "Streaming Joint Speech Recognition and Disfluency Detection",
    "authors": [
      "Hayato Futami",
      "Emiru Tsunoo",
      "Kentaro Shibata",
      "Yosuke Kashiwagi",
      "Takao Okuda",
      "Siddhant Arora",
      "Shinji Watanabe"
    ],
    "abstract": "Disfluency detection has mainly been solved in a pipeline approach, as\npost-processing of speech recognition. In this study, we propose\nTransformer-based encoder-decoder models that jointly solve speech recognition\nand disfluency detection, which work in a streaming manner. Compared to\npipeline approaches, the joint models can leverage acoustic information that\nmakes disfluency detection robust to recognition errors and provide non-verbal\nclues. Moreover, joint modeling results in low-latency and lightweight\ninference. We investigate two joint model variants for streaming disfluency\ndetection: a transcript-enriched model and a multi-task model. The\ntranscript-enriched model is trained on text with special tags indicating the\nstarting and ending points of the disfluent part. However, it has problems with\nlatency and standard language model adaptation, which arise from the additional\ndisfluency tags. We propose a multi-task model to solve such problems, which\nhas two output layers at the Transformer decoder; one for speech recognition\nand the other for disfluency detection. It is modeled to be conditioned on the\ncurrently recognized token with an additional token-dependency mechanism. We\nshow that the proposed joint models outperformed a BERT-based pipeline approach\nin both accuracy and latency, on both the Switchboard and the corpus of\nspontaneous Japanese.",
    "published": "2022-11-16T07:34:20Z",
    "pdf_url": "http://arxiv.org/pdf/2211.08726v2",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "1903.00739v1",
    "title": "Speech Recognition with no speech or with noisy speech",
    "authors": [
      "Gautam Krishna",
      "Co Tran",
      "Jianguo Yu",
      "Ahmed H Tewfik"
    ],
    "abstract": "The performance of automatic speech recognition systems(ASR) degrades in the\npresence of noisy speech. This paper demonstrates that using\nelectroencephalography (EEG) can help automatic speech recognition systems\novercome performance loss in the presence of noise. The paper also shows that\ndistillation training of automatic speech recognition systems using EEG\nfeatures will increase their performance. Finally, we demonstrate the ability\nto recognize words from EEG with no speech signal on a limited English\nvocabulary with high accuracy.",
    "published": "2019-03-02T17:53:49Z",
    "pdf_url": "http://arxiv.org/pdf/1903.00739v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2104.00259v1",
    "title": "Interactive spatial speech recognition maps based on simulated speech\n  recognition experiments",
    "authors": [
      "Marc René Schädler"
    ],
    "abstract": "In their everyday life, the speech recognition performance of human listeners\nis influenced by diverse factors, such as the acoustic environment, the talker\nand listener positions, possibly impaired hearing, and optional hearing\ndevices. Prediction models come closer to considering all required factors\nsimultaneously to predict the individual speech recognition performance in\ncomplex acoustic environments. While such predictions may still not be\nsufficiently accurate for serious applications, they can already be performed\nand demand an accessible representation. In this contribution, an interactive\nrepresentation of speech recognition performance is proposed, which focuses on\nthe listeners head orientation and the spatial dimensions of an acoustic scene.\nA exemplary modeling toolchain, including an acoustic rendering model, a\nhearing device model, and a listener model, was used to generate a data set for\ndemonstration purposes. Using the spatial speech recognition maps to explore\nthis data set demonstrated the suitability of the approach to observe possibly\nrelevant behavior. The proposed representation provides a suitable target to\ncompare and validate different modeling approaches in ecologically relevant\ncontexts. Eventually, it may serve as a tool to use validated prediction models\nin the design of spaces and devices which take speech communication into\naccount.",
    "published": "2021-04-01T05:35:46Z",
    "pdf_url": "http://arxiv.org/pdf/2104.00259v1",
    "categories": [
      "eess.AS",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "0703049v1",
    "title": "Algorithm of Segment-Syllabic Synthesis in Speech Recognition Problem",
    "authors": [
      "Oleg N. Karpov",
      "Olga A. Savenkova"
    ],
    "abstract": "Speech recognition based on the syllable segment is discussed in this paper.\nThe principal search methods in space of states for the speech recognition\nproblem by segment-syllabic parameters trajectory synthesis are investigated.\nRecognition as comparison the parameters trajectories in chosen speech units on\nthe sections of the segmented speech is realized. Some experimental results are\ngiven and discussed.",
    "published": "2007-03-10T23:59:55Z",
    "pdf_url": "http://arxiv.org/pdf/cs/0703049v1",
    "categories": [
      "cs.SD",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "1906.08871v9",
    "title": "Advancing Speech Recognition With No Speech Or With Noisy Speech",
    "authors": [
      "Gautam Krishna",
      "Co Tran",
      "Mason Carnahan",
      "Ahmed H Tewfik"
    ],
    "abstract": "In this paper we demonstrate end-to-end continuous speech recognition (CSR)\nusing electroencephalography (EEG) signals with no speech signal as input. An\nattention model based automatic speech recognition (ASR) and connectionist\ntemporal classification (CTC) based ASR systems were implemented for performing\nrecognition. We further demonstrate CSR for noisy speech by fusing with EEG\nfeatures.",
    "published": "2019-06-17T23:06:51Z",
    "pdf_url": "http://arxiv.org/pdf/1906.08871v9",
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.LG",
      "cs.SD",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2410.22903v1",
    "title": "Augmenting Polish Automatic Speech Recognition System With Synthetic\n  Data",
    "authors": [
      "Łukasz Bondaruk",
      "Jakub Kubiak",
      "Mateusz Czyżnikiewicz"
    ],
    "abstract": "This paper presents a system developed for submission to Poleval 2024, Task\n3: Polish Automatic Speech Recognition Challenge. We describe Voicebox-based\nspeech synthesis pipeline and utilize it to augment Conformer and Whisper\nspeech recognition models with synthetic data. We show that addition of\nsynthetic speech to training improves achieved results significantly. We also\npresent final results achieved by our models in the competition.",
    "published": "2024-10-30T11:02:57Z",
    "pdf_url": "http://arxiv.org/pdf/2410.22903v1",
    "categories": [
      "eess.AS",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "1501.05530v1",
    "title": "Belief Hidden Markov Model for speech recognition",
    "authors": [
      "Siwar Jendoubi",
      "Boutheina Ben Yaghlane",
      "Arnaud Martin"
    ],
    "abstract": "Speech Recognition searches to predict the spoken words automatically. These\nsystems are known to be very expensive because of using several pre-recorded\nhours of speech. Hence, building a model that minimizes the cost of the\nrecognizer will be very interesting. In this paper, we present a new approach\nfor recognizing speech based on belief HMMs instead of proba-bilistic HMMs.\nExperiments shows that our belief recognizer is insensitive to the lack of the\ndata and it can be trained using only one exemplary of each acoustic unit and\nit gives a good recognition rates. Consequently, using the belief HMM\nrecognizer can greatly minimize the cost of these systems.",
    "published": "2015-01-22T15:20:28Z",
    "pdf_url": "http://arxiv.org/pdf/1501.05530v1",
    "categories": [
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1612.04675v2",
    "title": "Recurrent Deep Stacking Networks for Speech Recognition",
    "authors": [
      "Peidong Wang",
      "Zhongqiu Wang",
      "Deliang Wang"
    ],
    "abstract": "This paper presented our work on applying Recurrent Deep Stacking Networks\n(RDSNs) to Robust Automatic Speech Recognition (ASR) tasks. In the paper, we\nalso proposed a more efficient yet comparable substitute to RDSN, Bi- Pass\nStacking Network (BPSN). The main idea of these two models is to add\nphoneme-level information into acoustic models, transforming an acoustic model\nto the combination of an acoustic model and a phoneme-level N-gram model.\nExperiments showed that RDSN and BPsn can substantially improve the\nperformances over conventional DNNs.",
    "published": "2016-12-14T15:07:51Z",
    "pdf_url": "http://arxiv.org/pdf/1612.04675v2",
    "categories": [
      "cs.CL",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "1808.03570v1",
    "title": "Densely Connected Convolutional Networks for Speech Recognition",
    "authors": [
      "Chia Yu Li",
      "Ngoc Thang Vu"
    ],
    "abstract": "This paper presents our latest investigation on Densely Connected\nConvolutional Networks (DenseNets) for acoustic modelling (AM) in automatic\nspeech recognition. DenseN-ets are very deep, compact convolutional neural\nnetworks, which have demonstrated incredible improvements over the\nstate-of-the-art results on several data sets in computer vision. Our\nexperimental results show that DenseNet can be used for AM significantly\noutperforming other neural-based models such as DNNs, CNNs, VGGs. Furthermore,\nresults on Wall Street Journal revealed that with only a half of the training\ndata DenseNet was able to outperform other models trained with the full data\nset by a large margin.",
    "published": "2018-08-10T14:54:10Z",
    "pdf_url": "http://arxiv.org/pdf/1808.03570v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2001.09727v1",
    "title": "Scaling Up Online Speech Recognition Using ConvNets",
    "authors": [
      "Vineel Pratap",
      "Qiantong Xu",
      "Jacob Kahn",
      "Gilad Avidov",
      "Tatiana Likhomanenko",
      "Awni Hannun",
      "Vitaliy Liptchinsky",
      "Gabriel Synnaeve",
      "Ronan Collobert"
    ],
    "abstract": "We design an online end-to-end speech recognition system based on Time-Depth\nSeparable (TDS) convolutions and Connectionist Temporal Classification (CTC).\nWe improve the core TDS architecture in order to limit the future context and\nhence reduce latency while maintaining accuracy. The system has almost three\ntimes the throughput of a well tuned hybrid ASR baseline while also having\nlower latency and a better word error rate. Also important to the efficiency of\nthe recognizer is our highly optimized beam search decoder. To show the impact\nof our design choices, we analyze throughput, latency, accuracy, and discuss\nhow these metrics can be tuned based on the user requirements.",
    "published": "2020-01-27T12:55:02Z",
    "pdf_url": "http://arxiv.org/pdf/2001.09727v1",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2001.11360v1",
    "title": "BUT Opensat 2019 Speech Recognition System",
    "authors": [
      "Martin Karafiát",
      "Murali Karthick Baskar",
      "Igor Szöke",
      "Hari Krishna Vydana",
      "Karel Veselý",
      "Jan \"Honza'' Černocký"
    ],
    "abstract": "The paper describes the BUT Automatic Speech Recognition (ASR) systems\nsubmitted for OpenSAT evaluations under two domain categories such as low\nresourced languages and public safety communications. The first was challenging\ndue to lack of training data, therefore various architectures and multilingual\napproaches were employed. The combination led to superior performance. The\nsecond domain was challenging due to recording in extreme conditions such as\nspecific channel, speaker under stress and high levels of noise. Data\naugmentation process was inevitable to get reasonably good performance.",
    "published": "2020-01-30T14:35:34Z",
    "pdf_url": "http://arxiv.org/pdf/2001.11360v1",
    "categories": [
      "eess.AS",
      "cs.LG",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "2303.13559v1",
    "title": "Enhancing Unsupervised Speech Recognition with Diffusion GANs",
    "authors": [
      "Xianchao Wu"
    ],
    "abstract": "We enhance the vanilla adversarial training method for unsupervised Automatic\nSpeech Recognition (ASR) by a diffusion-GAN. Our model (1) injects instance\nnoises of various intensities to the generator's output and unlabeled reference\ntext which are sampled from pretrained phoneme language models with a length\nconstraint, (2) asks diffusion timestep-dependent discriminators to separate\nthem, and (3) back-propagates the gradients to update the generator.\nWord/phoneme error rate comparisons with wav2vec-U under Librispeech (3.1% for\ntest-clean and 5.6% for test-other), TIMIT and MLS datasets, show that our\nenhancement strategies work effectively.",
    "published": "2023-03-23T02:54:00Z",
    "pdf_url": "http://arxiv.org/pdf/2303.13559v1",
    "categories": [
      "cs.CL",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2306.03778v1",
    "title": "Streaming Speech-to-Confusion Network Speech Recognition",
    "authors": [
      "Denis Filimonov",
      "Prabhat Pandey",
      "Ariya Rastrow",
      "Ankur Gandhe",
      "Andreas Stolcke"
    ],
    "abstract": "In interactive automatic speech recognition (ASR) systems, low-latency\nrequirements limit the amount of search space that can be explored during\ndecoding, particularly in end-to-end neural ASR. In this paper, we present a\nnovel streaming ASR architecture that outputs a confusion network while\nmaintaining limited latency, as needed for interactive applications. We show\nthat 1-best results of our model are on par with a comparable RNN-T system,\nwhile the richer hypothesis set allows second-pass rescoring to achieve 10-20\\%\nlower word error rate on the LibriSpeech task. We also show that our model\noutperforms a strong RNN-T baseline on a far-field voice assistant task.",
    "published": "2023-06-02T20:28:14Z",
    "pdf_url": "http://arxiv.org/pdf/2306.03778v1",
    "categories": [
      "eess.AS",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2410.00822v2",
    "title": "VHASR: A Multimodal Speech Recognition System With Vision Hotwords",
    "authors": [
      "Jiliang Hu",
      "Zuchao Li",
      "Ping Wang",
      "Haojun Ai",
      "Lefei Zhang",
      "Hai Zhao"
    ],
    "abstract": "The image-based multimodal automatic speech recognition (ASR) model enhances\nspeech recognition performance by incorporating audio-related image. However,\nsome works suggest that introducing image information to model does not help\nimproving ASR performance. In this paper, we propose a novel approach\neffectively utilizing audio-related image information and set up VHASR, a\nmultimodal speech recognition system that uses vision as hotwords to strengthen\nthe model's speech recognition capability. Our system utilizes a dual-stream\narchitecture, which firstly transcribes the text on the two streams separately,\nand then combines the outputs. We evaluate the proposed model on four datasets:\nFlickr8k, ADE20k, COCO, and OpenImages. The experimental results show that\nVHASR can effectively utilize key information in images to enhance the model's\nspeech recognition ability. Its performance not only surpasses unimodal ASR,\nbut also achieves SOTA among existing image-based multimodal ASR.",
    "published": "2024-10-01T16:06:02Z",
    "pdf_url": "http://arxiv.org/pdf/2410.00822v2",
    "categories": [
      "cs.SD",
      "cs.CL",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2011.04547v1",
    "title": "Data Augmentation For Children's Speech Recognition -- The \"Ethiopian\"\n  System For The SLT 2021 Children Speech Recognition Challenge",
    "authors": [
      "Guoguo Chen",
      "Xingyu Na",
      "Yongqing Wang",
      "Zhiyong Yan",
      "Junbo Zhang",
      "Sifan Ma",
      "Yujun Wang"
    ],
    "abstract": "This paper presents the \"Ethiopian\" system for the SLT 2021 Children Speech\nRecognition Challenge. Various data processing and augmentation techniques are\nproposed to tackle children's speech recognition problem, especially the lack\nof the children's speech recognition training data issue. Detailed experiments\nare designed and conducted to show the effectiveness of each technique, across\ndifferent speech recognition toolkits and model architectures. Step by step, we\nexplain how we come up with our final system, which provides the\nstate-of-the-art results in the SLT 2021 Children Speech Recognition Challenge,\nwith 21.66% CER on the Track 1 evaluation set (4th place overall), and 16.53%\nCER on the Track 2 evaluation set (1st place overall). Post-challenge analysis\nshows that our system actually achieves 18.82% CER on the Track 1 evaluation\nset, but we submitted the wrong version to the challenge organizer for Track 1.",
    "published": "2020-11-09T16:44:47Z",
    "pdf_url": "http://arxiv.org/pdf/2011.04547v1",
    "categories": [
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "1811.05097v2",
    "title": "Exploring RNN-Transducer for Chinese Speech Recognition",
    "authors": [
      "Senmao Wang",
      "Pan Zhou",
      "Wei Chen",
      "Jia Jia",
      "Lei Xie"
    ],
    "abstract": "End-to-end approaches have drawn much attention recently for significantly\nsimplifying the construction of an automatic speech recognition (ASR) system.\nRNN transducer (RNN-T) is one of the popular end-to-end methods. Previous\nstudies have shown that RNN-T is difficult to train and a very complex training\nprocess is needed for a reasonable performance. In this paper, we explore RNN-T\nfor a Chinese large vocabulary continuous speech recognition (LVCSR) task and\naim to simplify the training process while maintaining performance. First, a\nnew strategy of learning rate decay is proposed to accelerate the model\nconvergence. Second, we find that adding convolutional layers at the beginning\nof the network and using ordered data can discard the pre-training process of\nthe encoder without loss of performance. Besides, we design experiments to find\na balance among the usage of GPU memory, training circle and model performance.\nFinally, we achieve 16.9% character error rate (CER) on our test set which is\n2% absolute improvement from a strong BLSTM CE system with language model\ntrained on the same text corpus.",
    "published": "2018-11-13T04:37:11Z",
    "pdf_url": "http://arxiv.org/pdf/1811.05097v2",
    "categories": [
      "cs.CL",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "1811.09678v1",
    "title": "Speech recognition with quaternion neural networks",
    "authors": [
      "Titouan Parcollet",
      "Mirco Ravanelli",
      "Mohamed Morchid",
      "Georges Linarès",
      "Renato De Mori"
    ],
    "abstract": "Neural network architectures are at the core of powerful automatic speech\nrecognition systems (ASR). However, while recent researches focus on novel\nmodel architectures, the acoustic input features remain almost unchanged.\nTraditional ASR systems rely on multidimensional acoustic features such as the\nMel filter bank energies alongside with the first, and second order derivatives\nto characterize time-frames that compose the signal sequence. Considering that\nthese components describe three different views of the same element, neural\nnetworks have to learn both the internal relations that exist within these\nfeatures, and external or global dependencies that exist between the\ntime-frames. Quaternion-valued neural networks (QNN), recently received an\nimportant interest from researchers to process and learn such relations in\nmultidimensional spaces. Indeed, quaternion numbers and QNNs have shown their\nefficiency to process multidimensional inputs as entities, to encode internal\ndependencies, and to solve many tasks with up to four times less learning\nparameters than real-valued models. We propose to investigate modern\nquaternion-valued models such as convolutional and recurrent quaternion neural\nnetworks in the context of speech recognition with the TIMIT dataset. The\nexperiments show that QNNs always outperform real-valued equivalent models with\nway less free parameters, leading to a more efficient, compact, and expressive\nrepresentation of the relevant information.",
    "published": "2018-11-21T10:27:02Z",
    "pdf_url": "http://arxiv.org/pdf/1811.09678v1",
    "categories": [
      "eess.AS",
      "cs.SD",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1908.10992v1",
    "title": "Two-Pass End-to-End Speech Recognition",
    "authors": [
      "Tara N. Sainath",
      "Ruoming Pang",
      "David Rybach",
      "Yanzhang He",
      "Rohit Prabhavalkar",
      "Wei Li",
      "Mirkó Visontai",
      "Qiao Liang",
      "Trevor Strohman",
      "Yonghui Wu",
      "Ian McGraw",
      "Chung-Cheng Chiu"
    ],
    "abstract": "The requirements for many applications of state-of-the-art speech recognition\nsystems include not only low word error rate (WER) but also low latency.\nSpecifically, for many use-cases, the system must be able to decode utterances\nin a streaming fashion and faster than real-time. Recently, a streaming\nrecurrent neural network transducer (RNN-T) end-to-end (E2E) model has shown to\nbe a good candidate for on-device speech recognition, with improved WER and\nlatency metrics compared to conventional on-device models [1]. However, this\nmodel still lags behind a large state-of-the-art conventional model in quality\n[2]. On the other hand, a non-streaming E2E Listen, Attend and Spell (LAS)\nmodel has shown comparable quality to large conventional models [3]. This work\naims to bring the quality of an E2E streaming model closer to that of a\nconventional system by incorporating a LAS network as a second-pass component,\nwhile still abiding by latency constraints. Our proposed two-pass model\nachieves a 17%-22% relative reduction in WER compared to RNN-T alone and\nincreases latency by a small fraction over RNN-T.",
    "published": "2019-08-29T00:18:05Z",
    "pdf_url": "http://arxiv.org/pdf/1908.10992v1",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2005.09684v2",
    "title": "Exploring Transformers for Large-Scale Speech Recognition",
    "authors": [
      "Liang Lu",
      "Changliang Liu",
      "Jinyu Li",
      "Yifan Gong"
    ],
    "abstract": "While recurrent neural networks still largely define state-of-the-art speech\nrecognition systems, the Transformer network has been proven to be a\ncompetitive alternative, especially in the offline condition. Most studies with\nTransformers have been constrained in a relatively small scale setting, and\nsome forms of data argumentation approaches are usually applied to combat the\ndata sparsity issue. In this paper, we aim at understanding the behaviors of\nTransformers in the large-scale speech recognition setting, where we have used\naround 65,000 hours of training data. We investigated various aspects on\nscaling up Transformers, including model initialization, warmup training as\nwell as different Layer Normalization strategies. In the streaming condition,\nwe compared the widely used attention mask based future context lookahead\napproach to the Transformer-XL network. From our experiments, we show that\nTransformers can achieve around 6% relative word error rate (WER) reduction\ncompared to the BLSTM baseline in the offline fashion, while in the streaming\nfashion, Transformer-XL is comparable to LC-BLSTM with 800 millisecond latency\nconstraint.",
    "published": "2020-05-19T18:07:14Z",
    "pdf_url": "http://arxiv.org/pdf/2005.09684v2",
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "2202.01405v1",
    "title": "Joint Speech Recognition and Audio Captioning",
    "authors": [
      "Chaitanya Narisetty",
      "Emiru Tsunoo",
      "Xuankai Chang",
      "Yosuke Kashiwagi",
      "Michael Hentschel",
      "Shinji Watanabe"
    ],
    "abstract": "Speech samples recorded in both indoor and outdoor environments are often\ncontaminated with secondary audio sources. Most end-to-end monaural speech\nrecognition systems either remove these background sounds using speech\nenhancement or train noise-robust models. For better model interpretability and\nholistic understanding, we aim to bring together the growing field of automated\naudio captioning (AAC) and the thoroughly studied automatic speech recognition\n(ASR). The goal of AAC is to generate natural language descriptions of contents\nin audio samples. We propose several approaches for end-to-end joint modeling\nof ASR and AAC tasks and demonstrate their advantages over traditional\napproaches, which model these tasks independently. A major hurdle in evaluating\nour proposed approach is the lack of labeled audio datasets with both speech\ntranscriptions and audio captions. Therefore we also create a multi-task\ndataset by mixing the clean speech Wall Street Journal corpus with multiple\nlevels of background noises chosen from the AudioCaps dataset. We also perform\nextensive experimental evaluation and show improvements of our proposed methods\nas compared to existing state-of-the-art ASR and AAC methods.",
    "published": "2022-02-03T04:42:43Z",
    "pdf_url": "http://arxiv.org/pdf/2202.01405v1",
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "2010.02384v1",
    "title": "Fine-Grained Grounding for Multimodal Speech Recognition",
    "authors": [
      "Tejas Srinivasan",
      "Ramon Sanabria",
      "Florian Metze",
      "Desmond Elliott"
    ],
    "abstract": "Multimodal automatic speech recognition systems integrate information from\nimages to improve speech recognition quality, by grounding the speech in the\nvisual context. While visual signals have been shown to be useful for\nrecovering entities that have been masked in the audio, these models should be\ncapable of recovering a broader range of word types. Existing systems rely on\nglobal visual features that represent the entire image, but localizing the\nrelevant regions of the image will make it possible to recover a larger set of\nwords, such as adjectives and verbs. In this paper, we propose a model that\nuses finer-grained visual information from different parts of the image, using\nautomatic object proposals. In experiments on the Flickr8K Audio Captions\nCorpus, we find that our model improves over approaches that use global visual\nfeatures, that the proposals enable the model to recover entities and other\nrelated words, such as adjectives, and that improvements are due to the model's\nability to localize the correct proposals.",
    "published": "2020-10-05T23:06:24Z",
    "pdf_url": "http://arxiv.org/pdf/2010.02384v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2011.15023v2",
    "title": "Transformer-Transducers for Code-Switched Speech Recognition",
    "authors": [
      "Siddharth Dalmia",
      "Yuzong Liu",
      "Srikanth Ronanki",
      "Katrin Kirchhoff"
    ],
    "abstract": "We live in a world where 60% of the population can speak two or more\nlanguages fluently. Members of these communities constantly switch between\nlanguages when having a conversation. As automatic speech recognition (ASR)\nsystems are being deployed to the real-world, there is a need for practical\nsystems that can handle multiple languages both within an utterance or across\nutterances. In this paper, we present an end-to-end ASR system using a\ntransformer-transducer model architecture for code-switched speech recognition.\nWe propose three modifications over the vanilla model in order to handle\nvarious aspects of code-switching. First, we introduce two auxiliary loss\nfunctions to handle the low-resource scenario of code-switching. Second, we\npropose a novel mask-based training strategy with language ID information to\nimprove the label encoder training towards intra-sentential code-switching.\nFinally, we propose a multi-label/multi-audio encoder structure to leverage the\nvast monolingual speech corpora towards code-switching. We demonstrate the\nefficacy of our proposed approaches on the SEAME dataset, a public\nMandarin-English code-switching corpus, achieving a mixed error rate of 18.5%\nand 26.3% on test_man and test_sge sets respectively.",
    "published": "2020-11-30T17:27:41Z",
    "pdf_url": "http://arxiv.org/pdf/2011.15023v2",
    "categories": [
      "cs.CL",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "1906.08043v1",
    "title": "Real to H-space Encoder for Speech Recognition",
    "authors": [
      "Titouan Parcollet",
      "Mohamed Morchid",
      "Georges Linarès",
      "Renato De Mori"
    ],
    "abstract": "Deep neural networks (DNNs) and more precisely recurrent neural networks\n(RNNs) are at the core of modern automatic speech recognition systems, due to\ntheir efficiency to process input sequences. Recently, it has been shown that\ndifferent input representations, based on multidimensional algebras, such as\ncomplex and quaternion numbers, are able to bring to neural networks a more\nnatural, compressive and powerful representation of the input signal by\noutperforming common real-valued NNs. Indeed, quaternion-valued neural networks\n(QNNs) better learn both internal dependencies, such as the relation between\nthe Mel-filter-bank value of a specific time frame and its time derivatives,\nand global dependencies, describing the relations that exist between time\nframes. Nonetheless, QNNs are limited to quaternion-valued input signals, and\nit is difficult to benefit from this powerful representation with real-valued\ninput data. This paper proposes to tackle this weakness by introducing a\nreal-to-quaternion encoder that allows QNNs to process any one dimensional\ninput features, such as traditional Mel-filter-banks for automatic speech\nrecognition.",
    "published": "2019-06-17T20:07:45Z",
    "pdf_url": "http://arxiv.org/pdf/1906.08043v1",
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "1906.10834v1",
    "title": "Essence Knowledge Distillation for Speech Recognition",
    "authors": [
      "Zhenchuan Yang",
      "Chun Zhang",
      "Weibin Zhang",
      "Jianxiu Jin",
      "Dongpeng Chen"
    ],
    "abstract": "It is well known that a speech recognition system that combines multiple\nacoustic models trained on the same data significantly outperforms a\nsingle-model system. Unfortunately, real time speech recognition using a whole\nensemble of models is too computationally expensive. In this paper, we propose\nto distill the knowledge of essence in an ensemble of models (i.e. the teacher\nmodel) to a single model (i.e. the student model) that needs much less\ncomputation to deploy. Previously, all the soften outputs of the teacher model\nare used to optimize the student model. We argue that not all the outputs of\nthe ensemble are necessary to be distilled. Some of the outputs may even\ncontain noisy information that is useless or even harmful to the training of\nthe student model. In addition, we propose to train the student model with a\nmultitask learning approach by utilizing both the soften outputs of the teacher\nmodel and the correct hard labels. The proposed method achieves some surprising\nresults on the Switchboard data set. When the student model is trained together\nwith the correct labels and the essence knowledge from the teacher model, it\nnot only significantly outperforms another single model with the same\narchitecture that is trained only with the correct labels, but also\nconsistently outperforms the teacher model that is used to generate the soft\nlabels.",
    "published": "2019-06-26T03:58:29Z",
    "pdf_url": "http://arxiv.org/pdf/1906.10834v1",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2203.11325v2",
    "title": "Enhancing Speech Recognition Decoding via Layer Aggregation",
    "authors": [
      "Tomer Wullach",
      "Shlomo E. Chazan"
    ],
    "abstract": "Recently proposed speech recognition systems are designed to predict using\nrepresentations generated by their top layers, employing greedy decoding which\nisolates each timestep from the rest of the sequence. Aiming for improved\nperformance, a beam search algorithm is frequently utilized and a language\nmodel is incorporated to assist with ranking the top candidates. In this work,\nwe experiment with several speech recognition models and find that logits\npredicted using the top layers may hamper beam search from achieving optimal\nresults. Specifically, we show that fined-tuned Wav2Vec 2.0 and HuBERT yield\nhighly confident predictions, and hypothesize that the predictions are based on\nlocal information and may not take full advantage of the information encoded in\nintermediate layers. To this end, we perform a layer analysis to reveal and\nvisualize how predictions evolve throughout the inference flow. We then propose\na prediction method that aggregates the top M layers, potentially leveraging\nuseful information encoded in intermediate layers and relaxing model\nconfidence. We showcase the effectiveness of our approach via beam search\ndecoding, conducting our experiments on Librispeech test and dev sets and\nachieving WER, and CER reduction of up to 10% and 22%, respectively.",
    "published": "2022-03-21T20:28:06Z",
    "pdf_url": "http://arxiv.org/pdf/2203.11325v2",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2203.13687v3",
    "title": "Chain-based Discriminative Autoencoders for Speech Recognition",
    "authors": [
      "Hung-Shin Lee",
      "Pin-Tuan Huang",
      "Yao-Fei Cheng",
      "Hsin-Min Wang"
    ],
    "abstract": "In our previous work, we proposed a discriminative autoencoder (DcAE) for\nspeech recognition. DcAE combines two training schemes into one. First, since\nDcAE aims to learn encoder-decoder mappings, the squared error between the\nreconstructed speech and the input speech is minimized. Second, in the code\nlayer, frame-based phonetic embeddings are obtained by minimizing the\ncategorical cross-entropy between ground truth labels and predicted\ntriphone-state scores. DcAE is developed based on the Kaldi toolkit by treating\nvarious TDNN models as encoders. In this paper, we further propose three new\nversions of DcAE. First, a new objective function that considers both\ncategorical cross-entropy and mutual information between ground truth and\npredicted triphone-state sequences is used. The resulting DcAE is called a\nchain-based DcAE (c-DcAE). For application to robust speech recognition, we\nfurther extend c-DcAE to hierarchical and parallel structures, resulting in\nhc-DcAE and pc-DcAE. In these two models, both the error between the\nreconstructed noisy speech and the input noisy speech and the error between the\nenhanced speech and the reference clean speech are taken into the objective\nfunction. Experimental results on the WSJ and Aurora-4 corpora show that our\nDcAE models outperform baseline systems.",
    "published": "2022-03-25T14:51:48Z",
    "pdf_url": "http://arxiv.org/pdf/2203.13687v3",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MM",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2210.16238v1",
    "title": "Contextual-Utterance Training for Automatic Speech Recognition",
    "authors": [
      "Alejandro Gomez-Alanis",
      "Lukas Drude",
      "Andreas Schwarz",
      "Rupak Vignesh Swaminathan",
      "Simon Wiesler"
    ],
    "abstract": "Recent studies of streaming automatic speech recognition (ASR) recurrent\nneural network transducer (RNN-T)-based systems have fed the encoder with past\ncontextual information in order to improve its word error rate (WER)\nperformance. In this paper, we first propose a contextual-utterance training\ntechnique which makes use of the previous and future contextual utterances in\norder to do an implicit adaptation to the speaker, topic and acoustic\nenvironment. Also, we propose a dual-mode contextual-utterance training\ntechnique for streaming automatic speech recognition (ASR) systems. This\nproposed approach allows to make a better use of the available acoustic context\nin streaming models by distilling \"in-place\" the knowledge of a teacher, which\nis able to see both past and future contextual utterances, to the student which\ncan only see the current and past contextual utterances. The experimental\nresults show that a conformer-transducer system trained with the proposed\ntechniques outperforms the same system trained with the classical RNN-T loss.\nSpecifically, the proposed technique is able to reduce both the WER and the\naverage last token emission latency by more than 6% and 40ms relative,\nrespectively.",
    "published": "2022-10-27T08:10:44Z",
    "pdf_url": "http://arxiv.org/pdf/2210.16238v1",
    "categories": [
      "eess.AS",
      "cs.LG",
      "cs.SD",
      "eess.SP"
    ]
  },
  {
    "arxiv_id": "2404.13362v1",
    "title": "Semantically Corrected Amharic Automatic Speech Recognition",
    "authors": [
      "Samuael Adnew",
      "Paul Pu Liang"
    ],
    "abstract": "Automatic Speech Recognition (ASR) can play a crucial role in enhancing the\naccessibility of spoken languages worldwide. In this paper, we build a set of\nASR tools for Amharic, a language spoken by more than 50 million people\nprimarily in eastern Africa. Amharic is written in the Ge'ez script, a sequence\nof graphemes with spacings denoting word boundaries. This makes computational\nprocessing of Amharic challenging since the location of spacings can\nsignificantly impact the meaning of formed sentences. We find that existing\nbenchmarks for Amharic ASR do not account for these spacings and only measure\nindividual grapheme error rates, leading to significantly inflated measurements\nof in-the-wild performance. In this paper, we first release corrected\ntranscriptions of existing Amharic ASR test datasets, enabling the community to\naccurately evaluate progress. Furthermore, we introduce a post-processing\napproach using a transformer encoder-decoder architecture to organize raw ASR\noutputs into a grammatically complete and semantically meaningful Amharic\nsentence. Through experiments on the corrected test dataset, our model enhances\nthe semantic correctness of Amharic speech recognition systems, achieving a\nCharacter Error Rate (CER) of 5.5\\% and a Word Error Rate (WER) of 23.3\\%.",
    "published": "2024-04-20T12:08:00Z",
    "pdf_url": "http://arxiv.org/pdf/2404.13362v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2504.07229v1",
    "title": "Visual-Aware Speech Recognition for Noisy Scenarios",
    "authors": [
      "Lakshmipathi Balaji",
      "Karan Singla"
    ],
    "abstract": "Humans have the ability to utilize visual cues, such as lip movements and\nvisual scenes, to enhance auditory perception, particularly in noisy\nenvironments. However, current Automatic Speech Recognition (ASR) or\nAudio-Visual Speech Recognition (AVSR) models often struggle in noisy\nscenarios. To solve this task, we propose a model that improves transcription\nby correlating noise sources to visual cues. Unlike works that rely on lip\nmotion and require the speaker's visibility, we exploit broader visual\ninformation from the environment. This allows our model to naturally filter\nspeech from noise and improve transcription, much like humans do in noisy\nscenarios. Our method re-purposes pretrained speech and visual encoders,\nlinking them with multi-headed attention. This approach enables the\ntranscription of speech and the prediction of noise labels in video inputs. We\nintroduce a scalable pipeline to develop audio-visual datasets, where visual\ncues correlate to noise in the audio. We show significant improvements over\nexisting audio-only models in noisy scenarios. Results also highlight that\nvisual cues play a vital role in improved transcription accuracy.",
    "published": "2025-04-09T19:09:54Z",
    "pdf_url": "http://arxiv.org/pdf/2504.07229v1",
    "categories": [
      "cs.CL",
      "eess.AS",
      "eess.SP"
    ]
  },
  {
    "arxiv_id": "0704.2083v1",
    "title": "Introduction to Arabic Speech Recognition Using CMUSphinx System",
    "authors": [
      "H. Satori",
      "M. Harti",
      "N. Chenfour"
    ],
    "abstract": "In this paper Arabic was investigated from the speech recognition problem\npoint of view. We propose a novel approach to build an Arabic Automated Speech\nRecognition System (ASR). This system is based on the open source CMU Sphinx-4,\nfrom the Carnegie Mellon University. CMU Sphinx is a large-vocabulary;\nspeaker-independent, continuous speech recognition system based on discrete\nHidden Markov Models (HMMs). We build a model using utilities from the\nOpenSource CMU Sphinx. We will demonstrate the possible adaptability of this\nsystem to Arabic voice recognition.",
    "published": "2007-04-17T01:04:01Z",
    "pdf_url": "http://arxiv.org/pdf/0704.2083v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ]
  },
  {
    "arxiv_id": "2205.13674v1",
    "title": "Global Normalization for Streaming Speech Recognition in a Modular\n  Framework",
    "authors": [
      "Ehsan Variani",
      "Ke Wu",
      "Michael Riley",
      "David Rybach",
      "Matt Shannon",
      "Cyril Allauzen"
    ],
    "abstract": "We introduce the Globally Normalized Autoregressive Transducer (GNAT) for\naddressing the label bias problem in streaming speech recognition. Our solution\nadmits a tractable exact computation of the denominator for the sequence-level\nnormalization. Through theoretical and empirical results, we demonstrate that\nby switching to a globally normalized model, the word error rate gap between\nstreaming and non-streaming speech-recognition models can be greatly reduced\n(by more than 50\\% on the Librispeech dataset). This model is developed in a\nmodular framework which encompasses all the common neural speech recognition\nmodels. The modularity of this framework enables controlled comparison of\nmodelling choices and creation of new models.",
    "published": "2022-05-26T23:34:21Z",
    "pdf_url": "http://arxiv.org/pdf/2205.13674v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2502.00583v1",
    "title": "Data-Driven Mispronunciation Pattern Discovery for Robust Speech\n  Recognition",
    "authors": [
      "Anna Seo Gyeong Choi",
      "Jonghyeon Park",
      "Myungwoo Oh"
    ],
    "abstract": "Recent advancements in machine learning have significantly improved speech\nrecognition, but recognizing speech from non-fluent or accented speakers\nremains a challenge. Previous efforts, relying on rule-based pronunciation\npatterns, have struggled to fully capture non-native errors. We propose two\ndata-driven approaches using speech corpora to automatically detect\nmispronunciation patterns. By aligning non-native phones with their native\ncounterparts using attention maps, we achieved a 5.7% improvement in speech\nrecognition on native English datasets and a 12.8% improvement for non-native\nEnglish speakers, particularly Korean speakers. Our method offers practical\nadvancements for robust Automatic Speech Recognition (ASR) systems particularly\nfor situations where prior linguistic knowledge is not applicable.",
    "published": "2025-02-01T22:41:43Z",
    "pdf_url": "http://arxiv.org/pdf/2502.00583v1",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "1303.5778v1",
    "title": "Speech Recognition with Deep Recurrent Neural Networks",
    "authors": [
      "Alex Graves",
      "Abdel-rahman Mohamed",
      "Geoffrey Hinton"
    ],
    "abstract": "Recurrent neural networks (RNNs) are a powerful model for sequential data.\nEnd-to-end training methods such as Connectionist Temporal Classification make\nit possible to train RNNs for sequence labelling problems where the\ninput-output alignment is unknown. The combination of these methods with the\nLong Short-term Memory RNN architecture has proved particularly fruitful,\ndelivering state-of-the-art results in cursive handwriting recognition. However\nRNN performance in speech recognition has so far been disappointing, with\nbetter results returned by deep feedforward networks. This paper investigates\n\\emph{deep recurrent neural networks}, which combine the multiple levels of\nrepresentation that have proved so effective in deep networks with the flexible\nuse of long range context that empowers RNNs. When trained end-to-end with\nsuitable regularisation, we find that deep Long Short-term Memory RNNs achieve\na test set error of 17.7% on the TIMIT phoneme recognition benchmark, which to\nour knowledge is the best recorded score.",
    "published": "2013-03-22T20:55:48Z",
    "pdf_url": "http://arxiv.org/pdf/1303.5778v1",
    "categories": [
      "cs.NE",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "1608.00929v1",
    "title": "Efficient Segmental Cascades for Speech Recognition",
    "authors": [
      "Hao Tang",
      "Weiran Wang",
      "Kevin Gimpel",
      "Karen Livescu"
    ],
    "abstract": "Discriminative segmental models offer a way to incorporate flexible feature\nfunctions into speech recognition. However, their appeal has been limited by\ntheir computational requirements, due to the large number of possible segments\nto consider. Multi-pass cascades of segmental models introduce features of\nincreasing complexity in different passes, where in each pass a segmental model\nrescores lattices produced by a previous (simpler) segmental model. In this\npaper, we explore several ways of making segmental cascades efficient and\npractical: reducing the feature set in the first pass, frame subsampling, and\nvarious pruning approaches. In experiments on phonetic recognition, we find\nthat with a combination of such techniques, it is possible to maintain\ncompetitive performance while greatly reducing decoding, pruning, and training\ntime.",
    "published": "2016-08-02T18:45:53Z",
    "pdf_url": "http://arxiv.org/pdf/1608.00929v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "1609.03528v2",
    "title": "The Microsoft 2016 Conversational Speech Recognition System",
    "authors": [
      "W. Xiong",
      "J. Droppo",
      "X. Huang",
      "F. Seide",
      "M. Seltzer",
      "A. Stolcke",
      "D. Yu",
      "G. Zweig"
    ],
    "abstract": "We describe Microsoft's conversational speech recognition system, in which we\ncombine recent developments in neural-network-based acoustic and language\nmodeling to advance the state of the art on the Switchboard recognition task.\nInspired by machine learning ensemble techniques, the system uses a range of\nconvolutional and recurrent neural networks. I-vector modeling and lattice-free\nMMI training provide significant gains for all acoustic model architectures.\nLanguage model rescoring with multiple forward and backward running RNNLMs, and\nword posterior-based system combination provide a 20% boost. The best single\nsystem uses a ResNet architecture acoustic model with RNNLM rescoring, and\nachieves a word error rate of 6.9% on the NIST 2000 Switchboard task. The\ncombined system has an error rate of 6.2%, representing an improvement over\npreviously reported results on this benchmark task.",
    "published": "2016-09-12T18:59:29Z",
    "pdf_url": "http://arxiv.org/pdf/1609.03528v2",
    "categories": [
      "cs.CL",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "1710.01073v1",
    "title": "Resolution limits on visual speech recognition",
    "authors": [
      "Helen L. Bear",
      "Richard Harvey",
      "Barry-John Theobald",
      "Yuxuan Lan"
    ],
    "abstract": "Visual-only speech recognition is dependent upon a number of factors that can\nbe difficult to control, such as: lighting; identity; motion; emotion and\nexpression. But some factors, such as video resolution are controllable, so it\nis surprising that there is not yet a systematic study of the effect of\nresolution on lip-reading. Here we use a new data set, the Rosetta Raven data,\nto train and test recognizers so we can measure the affect of video resolution\non recognition accuracy. We conclude that, contrary to common practice,\nresolution need not be that great for automatic lip-reading. However it is\nhighly unlikely that automatic lip-reading can work reliably when the distance\nbetween the bottom of the lower lip and the top of the upper lip is less than\nfour pixels at rest.",
    "published": "2017-10-03T11:07:06Z",
    "pdf_url": "http://arxiv.org/pdf/1710.01073v1",
    "categories": [
      "cs.CV",
      "eess.IV"
    ]
  },
  {
    "arxiv_id": "1804.09713v1",
    "title": "End-to-End Multimodal Speech Recognition",
    "authors": [
      "Shruti Palaskar",
      "Ramon Sanabria",
      "Florian Metze"
    ],
    "abstract": "Transcription or sub-titling of open-domain videos is still a challenging\ndomain for Automatic Speech Recognition (ASR) due to the data's challenging\nacoustics, variable signal processing and the essentially unrestricted domain\nof the data. In previous work, we have shown that the visual channel --\nspecifically object and scene features -- can help to adapt the acoustic model\n(AM) and language model (LM) of a recognizer, and we are now expanding this\nwork to end-to-end approaches. In the case of a Connectionist Temporal\nClassification (CTC)-based approach, we retain the separation of AM and LM,\nwhile for a sequence-to-sequence (S2S) approach, both information sources are\nadapted together, in a single model. This paper also analyzes the behavior of\nCTC and S2S models on noisy video data (How-To corpus), and compares it to\nresults on the clean Wall Street Journal (WSJ) corpus, providing insight into\nthe robustness of both approaches.",
    "published": "2018-04-25T22:54:06Z",
    "pdf_url": "http://arxiv.org/pdf/1804.09713v1",
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2004.14840v1",
    "title": "Multiresolution and Multimodal Speech Recognition with Transformers",
    "authors": [
      "Georgios Paraskevopoulos",
      "Srinivas Parthasarathy",
      "Aparna Khare",
      "Shiva Sundaram"
    ],
    "abstract": "This paper presents an audio visual automatic speech recognition (AV-ASR)\nsystem using a Transformer-based architecture. We particularly focus on the\nscene context provided by the visual information, to ground the ASR. We extract\nrepresentations for audio features in the encoder layers of the transformer and\nfuse video features using an additional crossmodal multihead attention layer.\nAdditionally, we incorporate a multitask training criterion for multiresolution\nASR, where we train the model to generate both character and subword level\ntranscriptions.\n  Experimental results on the How2 dataset, indicate that multiresolution\ntraining can speed up convergence by around 50% and relatively improves word\nerror rate (WER) performance by upto 18% over subword prediction models.\nFurther, incorporating visual information improves performance with relative\ngains upto 3.76% over audio only models.\n  Our results are comparable to state-of-the-art Listen, Attend and Spell-based\narchitectures.",
    "published": "2020-04-29T09:32:11Z",
    "pdf_url": "http://arxiv.org/pdf/2004.14840v1",
    "categories": [
      "eess.AS",
      "cs.CV",
      "cs.LG",
      "cs.SD",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "2103.15122v2",
    "title": "Quantifying Bias in Automatic Speech Recognition",
    "authors": [
      "Siyuan Feng",
      "Olya Kudina",
      "Bence Mark Halpern",
      "Odette Scharenborg"
    ],
    "abstract": "Automatic speech recognition (ASR) systems promise to deliver objective\ninterpretation of human speech. Practice and recent evidence suggests that the\nstate-of-the-art (SotA) ASRs struggle with the large variation in speech due to\ne.g., gender, age, speech impairment, race, and accents. Many factors can cause\nthe bias of an ASR system. Our overarching goal is to uncover bias in ASR\nsystems to work towards proactive bias mitigation in ASR. This paper is a first\nstep towards this goal and systematically quantifies the bias of a Dutch SotA\nASR system against gender, age, regional accents and non-native accents. Word\nerror rates are compared, and an in-depth phoneme-level error analysis is\nconducted to understand where bias is occurring. We primarily focus on bias due\nto articulation differences in the dataset. Based on our findings, we suggest\nbias mitigation strategies for ASR development.",
    "published": "2021-03-28T12:52:03Z",
    "pdf_url": "http://arxiv.org/pdf/2103.15122v2",
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "2005.09267v2",
    "title": "Iterative Pseudo-Labeling for Speech Recognition",
    "authors": [
      "Qiantong Xu",
      "Tatiana Likhomanenko",
      "Jacob Kahn",
      "Awni Hannun",
      "Gabriel Synnaeve",
      "Ronan Collobert"
    ],
    "abstract": "Pseudo-labeling has recently shown promise in end-to-end automatic speech\nrecognition (ASR). We study Iterative Pseudo-Labeling (IPL), a semi-supervised\nalgorithm which efficiently performs multiple iterations of pseudo-labeling on\nunlabeled data as the acoustic model evolves. In particular, IPL fine-tunes an\nexisting model at each iteration using both labeled data and a subset of\nunlabeled data. We study the main components of IPL: decoding with a language\nmodel and data augmentation. We then demonstrate the effectiveness of IPL by\nachieving state-of-the-art word-error rate on the Librispeech test sets in both\nstandard and low-resource setting. We also study the effect of language models\ntrained on different corpora to show IPL can effectively utilize additional\ntext. Finally, we release a new large in-domain text corpus which does not\noverlap with the Librispeech training transcriptions to foster research in\nlow-resource, semi-supervised ASR",
    "published": "2020-05-19T07:56:21Z",
    "pdf_url": "http://arxiv.org/pdf/2005.09267v2",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2104.00766v1",
    "title": "Configurable Privacy-Preserving Automatic Speech Recognition",
    "authors": [
      "Ranya Aloufi",
      "Hamed Haddadi",
      "David Boyle"
    ],
    "abstract": "Voice assistive technologies have given rise to far-reaching privacy and\nsecurity concerns. In this paper we investigate whether modular automatic\nspeech recognition (ASR) can improve privacy in voice assistive systems by\ncombining independently trained separation, recognition, and discretization\nmodules to design configurable privacy-preserving ASR systems. We evaluate\nprivacy concerns and the effects of applying various state-of-the-art\ntechniques at each stage of the system, and report results using task-specific\nmetrics (i.e. WER, ABX, and accuracy). We show that overlapping speech inputs\nto ASR systems present further privacy concerns, and how these may be mitigated\nusing speech separation and optimization techniques. Our discretization module\nis shown to minimize paralinguistics privacy leakage from ASR acoustic models\nto levels commensurate with random guessing. We show that voice privacy can be\nconfigurable, and argue this presents new opportunities for privacy-preserving\napplications incorporating ASR.",
    "published": "2021-04-01T21:03:49Z",
    "pdf_url": "http://arxiv.org/pdf/2104.00766v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "1904.05862v4",
    "title": "wav2vec: Unsupervised Pre-training for Speech Recognition",
    "authors": [
      "Steffen Schneider",
      "Alexei Baevski",
      "Ronan Collobert",
      "Michael Auli"
    ],
    "abstract": "We explore unsupervised pre-training for speech recognition by learning\nrepresentations of raw audio. wav2vec is trained on large amounts of unlabeled\naudio data and the resulting representations are then used to improve acoustic\nmodel training. We pre-train a simple multi-layer convolutional neural network\noptimized via a noise contrastive binary classification task. Our experiments\non WSJ reduce WER of a strong character-based log-mel filterbank baseline by up\nto 36% when only a few hours of transcribed data is available. Our approach\nachieves 2.43% WER on the nov92 test set. This outperforms Deep Speech 2, the\nbest reported character-based system in the literature while using two orders\nof magnitude less labeled training data.",
    "published": "2019-04-11T17:29:30Z",
    "pdf_url": "http://arxiv.org/pdf/1904.05862v4",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2010.08642v1",
    "title": "Multimodal Speech Recognition with Unstructured Audio Masking",
    "authors": [
      "Tejas Srinivasan",
      "Ramon Sanabria",
      "Florian Metze",
      "Desmond Elliott"
    ],
    "abstract": "Visual context has been shown to be useful for automatic speech recognition\n(ASR) systems when the speech signal is noisy or corrupted. Previous work,\nhowever, has only demonstrated the utility of visual context in an unrealistic\nsetting, where a fixed set of words are systematically masked in the audio. In\nthis paper, we simulate a more realistic masking scenario during model\ntraining, called RandWordMask, where the masking can occur for any word\nsegment. Our experiments on the Flickr 8K Audio Captions Corpus show that\nmultimodal ASR can generalize to recover different types of masked words in\nthis unstructured masking setting. Moreover, our analysis shows that our models\nare capable of attending to the visual signal when the audio signal is\ncorrupted. These results show that multimodal ASR systems can leverage the\nvisual signal in more generalized noisy scenarios.",
    "published": "2020-10-16T21:49:20Z",
    "pdf_url": "http://arxiv.org/pdf/2010.08642v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2209.00260v1",
    "title": "Deep Sparse Conformer for Speech Recognition",
    "authors": [
      "Xianchao Wu"
    ],
    "abstract": "Conformer has achieved impressive results in Automatic Speech Recognition\n(ASR) by leveraging transformer's capturing of content-based global\ninteractions and convolutional neural network's exploiting of local features.\nIn Conformer, two macaron-like feed-forward layers with half-step residual\nconnections sandwich the multi-head self-attention and convolution modules\nfollowed by a post layer normalization. We improve Conformer's long-sequence\nrepresentation ability in two directions, \\emph{sparser} and \\emph{deeper}. We\nadapt a sparse self-attention mechanism with $\\mathcal{O}(L\\text{log}L)$ in\ntime complexity and memory usage. A deep normalization strategy is utilized\nwhen performing residual connections to ensure our training of hundred-level\nConformer blocks. On the Japanese CSJ-500h dataset, this deep sparse Conformer\nachieves respectively CERs of 5.52\\%, 4.03\\% and 4.50\\% on the three evaluation\nsets and 4.16\\%, 2.84\\% and 3.20\\% when ensembling five deep sparse Conformer\nvariants from 12 to 16, 17, 50, and finally 100 encoder layers.",
    "published": "2022-09-01T06:56:11Z",
    "pdf_url": "http://arxiv.org/pdf/2209.00260v1",
    "categories": [
      "cs.CL",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2305.15055v1",
    "title": "Iteratively Improving Speech Recognition and Voice Conversion",
    "authors": [
      "Mayank Kumar Singh",
      "Naoya Takahashi",
      "Onoe Naoyuki"
    ],
    "abstract": "Many existing works on voice conversion (VC) tasks use automatic speech\nrecognition (ASR) models for ensuring linguistic consistency between source and\nconverted samples. However, for the low-data resource domains, training a\nhigh-quality ASR remains to be a challenging task. In this work, we propose a\nnovel iterative way of improving both the ASR and VC models. We first train an\nASR model which is used to ensure content preservation while training a VC\nmodel. In the next iteration, the VC model is used as a data augmentation\nmethod to further fine-tune the ASR model and generalize it to diverse\nspeakers. By iteratively leveraging the improved ASR model to train VC model\nand vice-versa, we experimentally show improvement in both the models. Our\nproposed framework outperforms the ASR and one-shot VC baseline models on\nEnglish singing and Hindi speech domains in subjective and objective\nevaluations in low-data resource settings.",
    "published": "2023-05-24T11:45:42Z",
    "pdf_url": "http://arxiv.org/pdf/2305.15055v1",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2305.16619v1",
    "title": "2-bit Conformer quantization for automatic speech recognition",
    "authors": [
      "Oleg Rybakov",
      "Phoenix Meadowlark",
      "Shaojin Ding",
      "David Qiu",
      "Jian Li",
      "David Rim",
      "Yanzhang He"
    ],
    "abstract": "Large speech models are rapidly gaining traction in research community. As a\nresult, model compression has become an important topic, so that these models\ncan fit in memory and be served with reduced cost. Practical approaches for\ncompressing automatic speech recognition (ASR) model use int8 or int4 weight\nquantization. In this study, we propose to develop 2-bit ASR models. We explore\nthe impact of symmetric and asymmetric quantization combined with sub-channel\nquantization and clipping on both LibriSpeech dataset and large-scale training\ndata. We obtain a lossless 2-bit Conformer model with 32% model size reduction\nwhen compared to state of the art 4-bit Conformer model for LibriSpeech. With\nthe large-scale training data, we obtain a 2-bit Conformer model with over 40%\nmodel size reduction against the 4-bit version at the cost of 17% relative word\nerror rate degradation",
    "published": "2023-05-26T04:26:42Z",
    "pdf_url": "http://arxiv.org/pdf/2305.16619v1",
    "categories": [
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "1603.03185v2",
    "title": "Personalized Speech recognition on mobile devices",
    "authors": [
      "Ian McGraw",
      "Rohit Prabhavalkar",
      "Raziel Alvarez",
      "Montse Gonzalez Arenas",
      "Kanishka Rao",
      "David Rybach",
      "Ouais Alsharif",
      "Hasim Sak",
      "Alexander Gruenstein",
      "Francoise Beaufays",
      "Carolina Parada"
    ],
    "abstract": "We describe a large vocabulary speech recognition system that is accurate,\nhas low latency, and yet has a small enough memory and computational footprint\nto run faster than real-time on a Nexus 5 Android smartphone. We employ a\nquantized Long Short-Term Memory (LSTM) acoustic model trained with\nconnectionist temporal classification (CTC) to directly predict phoneme\ntargets, and further reduce its memory footprint using an SVD-based compression\nscheme. Additionally, we minimize our memory footprint by using a single\nlanguage model for both dictation and voice command domains, constructed using\nBayesian interpolation. Finally, in order to properly handle device-specific\ninformation, such as proper names and other context-dependent information, we\ninject vocabulary items into the decoder graph and bias the language model\non-the-fly. Our system achieves 13.5% word error rate on an open-ended\ndictation task, running with a median speed that is seven times faster than\nreal-time.",
    "published": "2016-03-10T08:51:51Z",
    "pdf_url": "http://arxiv.org/pdf/1603.03185v2",
    "categories": [
      "cs.CL",
      "cs.LG",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "2008.05760v1",
    "title": "MASRI-HEADSET: A Maltese Corpus for Speech Recognition",
    "authors": [
      "Carlos Mena",
      "Albert Gatt",
      "Andrea DeMarco",
      "Claudia Borg",
      "Lonneke van der Plas",
      "Amanda Muscat",
      "Ian Padovani"
    ],
    "abstract": "Maltese, the national language of Malta, is spoken by approximately 500,000\npeople. Speech processing for Maltese is still in its early stages of\ndevelopment. In this paper, we present the first spoken Maltese corpus designed\npurposely for Automatic Speech Recognition (ASR). The MASRI-HEADSET corpus was\ndeveloped by the MASRI project at the University of Malta. It consists of 8\nhours of speech paired with text, recorded by using short text snippets in a\nlaboratory environment. The speakers were recruited from different geographical\nlocations all over the Maltese islands, and were roughly evenly distributed by\ngender. This paper also presents some initial results achieved in baseline\nexperiments for Maltese ASR using Sphinx and Kaldi. The MASRI-HEADSET Corpus is\npublicly available for research/academic purposes.",
    "published": "2020-08-13T08:57:16Z",
    "pdf_url": "http://arxiv.org/pdf/2008.05760v1",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2102.04429v1",
    "title": "Federated Acoustic Modeling For Automatic Speech Recognition",
    "authors": [
      "Xiaodong Cui",
      "Songtao Lu",
      "Brian Kingsbury"
    ],
    "abstract": "Data privacy and protection is a crucial issue for any automatic speech\nrecognition (ASR) service provider when dealing with clients. In this paper, we\ninvestigate federated acoustic modeling using data from multiple clients. A\nclient's data is stored on a local data server and the clients communicate only\nmodel parameters with a central server, and not their data. The communication\nhappens infrequently to reduce the communication cost. To mitigate the non-iid\nissue, client adaptive federated training (CAFT) is proposed to canonicalize\ndata across clients. The experiments are carried out on 1,150 hours of speech\ndata from multiple domains. Hybrid LSTM acoustic models are trained via\nfederated learning and their performance is compared to traditional centralized\nacoustic model training. The experimental results demonstrate the effectiveness\nof the proposed federated acoustic modeling strategy. We also show that CAFT\ncan further improve the performance of the federated acoustic model.",
    "published": "2021-02-08T18:39:36Z",
    "pdf_url": "http://arxiv.org/pdf/2102.04429v1",
    "categories": [
      "cs.SD",
      "cs.DC",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2102.11531v1",
    "title": "Memory-efficient Speech Recognition on Smart Devices",
    "authors": [
      "Ganesh Venkatesh",
      "Alagappan Valliappan",
      "Jay Mahadeokar",
      "Yuan Shangguan",
      "Christian Fuegen",
      "Michael L. Seltzer",
      "Vikas Chandra"
    ],
    "abstract": "Recurrent transducer models have emerged as a promising solution for speech\nrecognition on the current and next generation smart devices. The transducer\nmodels provide competitive accuracy within a reasonable memory footprint\nalleviating the memory capacity constraints in these devices. However, these\nmodels access parameters from off-chip memory for every input time step which\nadversely effects device battery life and limits their usability on low-power\ndevices.\n  We address transducer model's memory access concerns by optimizing their\nmodel architecture and designing novel recurrent cell designs. We demonstrate\nthat i) model's energy cost is dominated by accessing model weights from\noff-chip memory, ii) transducer model architecture is pivotal in determining\nthe number of accesses to off-chip memory and just model size is not a good\nproxy, iii) our transducer model optimizations and novel recurrent cell reduces\noff-chip memory accesses by 4.5x and model size by 2x with minimal accuracy\nimpact.",
    "published": "2021-02-23T07:43:45Z",
    "pdf_url": "http://arxiv.org/pdf/2102.11531v1",
    "categories": [
      "cs.SD",
      "cs.CL",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2105.03010v1",
    "title": "Efficient Weight factorization for Multilingual Speech Recognition",
    "authors": [
      "Ngoc-Quan Pham",
      "Tuan-Nam Nguyen",
      "Sebastian Stueker",
      "Alexander Waibel"
    ],
    "abstract": "End-to-end multilingual speech recognition involves using a single model\ntraining on a compositional speech corpus including many languages, resulting\nin a single neural network to handle transcribing different languages. Due to\nthe fact that each language in the training data has different characteristics,\nthe shared network may struggle to optimize for all various languages\nsimultaneously. In this paper we propose a novel multilingual architecture that\ntargets the core operation in neural networks: linear transformation functions.\nThe key idea of the method is to assign fast weight matrices for each language\nby decomposing each weight matrix into a shared component and a language\ndependent component. The latter is then factorized into vectors using rank-1\nassumptions to reduce the number of parameters per language. This efficient\nfactorization scheme is proved to be effective in two multilingual settings\nwith $7$ and $27$ languages, reducing the word error rates by $26\\%$ and $27\\%$\nrel. for two popular architectures LSTM and Transformer, respectively.",
    "published": "2021-05-07T00:12:02Z",
    "pdf_url": "http://arxiv.org/pdf/2105.03010v1",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2110.02791v1",
    "title": "Spell my name: keyword boosted speech recognition",
    "authors": [
      "Namkyu Jung",
      "Geonmin Kim",
      "Joon Son Chung"
    ],
    "abstract": "Recognition of uncommon words such as names and technical terminology is\nimportant to understanding conversations in context. However, the ability to\nrecognise such words remains a challenge in modern automatic speech recognition\n(ASR) systems.\n  In this paper, we propose a simple but powerful ASR decoding method that can\nbetter recognise these uncommon keywords, which in turn enables better\nreadability of the results. The method boosts the probabilities of given\nkeywords in a beam search based on acoustic model predictions. The method does\nnot require any training in advance.\n  We demonstrate the effectiveness of our method on the LibriSpeeech test sets\nand also internal data of real-world conversations. Our method significantly\nboosts keyword accuracy on the test sets, while maintaining the accuracy of the\nother words, and as well as providing significant qualitative improvements.\nThis method is applicable to other tasks such as machine translation, or\nwherever unseen and difficult keywords need to be recognised in beam search.",
    "published": "2021-10-06T14:16:57Z",
    "pdf_url": "http://arxiv.org/pdf/2110.02791v1",
    "categories": [
      "cs.SD",
      "cs.CL",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2110.10026v3",
    "title": "Private Language Model Adaptation for Speech Recognition",
    "authors": [
      "Zhe Liu",
      "Ke Li",
      "Shreyan Bakshi",
      "Fuchun Peng"
    ],
    "abstract": "Speech model adaptation is crucial to handle the discrepancy between\nserver-side proxy training data and actual data received on local devices of\nusers. With the use of federated learning (FL), we introduce an efficient\napproach on continuously adapting neural network language models (NNLMs) on\nprivate devices with applications on automatic speech recognition (ASR). To\naddress the potential speech transcription errors in the on-device training\ncorpus, we perform empirical studies on comparing various strategies of\nleveraging token-level confidence scores to improve the NNLM quality in the FL\nsettings. Experiments show that compared with no model adaptation, the proposed\nmethod achieves relative 2.6% and 10.8% word error rate (WER) reductions on two\nspeech evaluation datasets, respectively. We also provide analysis in\nevaluating privacy guarantees of our presented procedure.",
    "published": "2021-09-28T00:15:43Z",
    "pdf_url": "http://arxiv.org/pdf/2110.10026v3",
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.LG",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "2205.12304v1",
    "title": "Adaptive multilingual speech recognition with pretrained models",
    "authors": [
      "Ngoc-Quan Pham",
      "Alex Waibel",
      "Jan Niehues"
    ],
    "abstract": "Multilingual speech recognition with supervised learning has achieved great\nresults as reflected in recent research. With the development of pretraining\nmethods on audio and text data, it is imperative to transfer the knowledge from\nunsupervised multilingual models to facilitate recognition, especially in many\nlanguages with limited data. Our work investigated the effectiveness of using\ntwo pretrained models for two modalities: wav2vec 2.0 for audio and MBART50 for\ntext, together with the adaptive weight techniques to massively improve the\nrecognition quality on the public datasets containing CommonVoice and Europarl.\nOverall, we noticed an 44% improvement over purely supervised learning, and\nmore importantly, each technique provides a different reinforcement in\ndifferent languages. We also explore other possibilities to potentially obtain\nthe best model by slightly adding either depth or relative attention to the\narchitecture.",
    "published": "2022-05-24T18:29:07Z",
    "pdf_url": "http://arxiv.org/pdf/2205.12304v1",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2210.00117v1",
    "title": "Blind Signal Dereverberation for Machine Speech Recognition",
    "authors": [
      "Samik Sadhu",
      "Hynek Hermansky"
    ],
    "abstract": "We present a method to remove unknown convolutive noise introduced to speech\nby reverberations of recording environments, utilizing some amount of training\nspeech data from the reverberant environment, and any available non-reverberant\nspeech data. Using Fourier transform computed over long temporal windows, which\nideally cover the entire room impulse response, we convert room induced\nconvolution to additions in the log spectral domain. Next, we compute a\nspectral normalization vector from statistics gathered over reverberated as\nwell as over clean speech in the log spectral domain. During operation, this\nnormalization vectors are used to alleviate reverberations from complex speech\nspectra recorded under the same reverberant conditions . Such dereverberated\ncomplex speech spectra are used to compute complex FDLP-spectrograms for use in\nautomatic speech recognition.",
    "published": "2022-09-30T22:15:31Z",
    "pdf_url": "http://arxiv.org/pdf/2210.00117v1",
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "2210.14742v1",
    "title": "Monotonic segmental attention for automatic speech recognition",
    "authors": [
      "Albert Zeyer",
      "Robin Schmitt",
      "Wei Zhou",
      "Ralf Schlüter",
      "Hermann Ney"
    ],
    "abstract": "We introduce a novel segmental-attention model for automatic speech\nrecognition. We restrict the decoder attention to segments to avoid quadratic\nruntime of global attention, better generalize to long sequences, and\neventually enable streaming. We directly compare global-attention and different\nsegmental-attention modeling variants. We develop and compare two separate\ntime-synchronous decoders, one specifically taking the segmental nature into\naccount, yielding further improvements. Using time-synchronous decoding for\nsegmental models is novel and a step towards streaming applications. Our\nexperiments show the importance of a length model to predict the segment\nboundaries. The final best segmental-attention model using segmental decoding\nperforms better than global-attention, in contrast to other monotonic attention\napproaches in the literature. Further, we observe that the segmental model\ngeneralizes much better to long sequences of up to several minutes.",
    "published": "2022-10-26T14:21:23Z",
    "pdf_url": "http://arxiv.org/pdf/2210.14742v1",
    "categories": [
      "cs.CL",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2211.03541v2",
    "title": "Multi-blank Transducers for Speech Recognition",
    "authors": [
      "Hainan Xu",
      "Fei Jia",
      "Somshubra Majumdar",
      "Shinji Watanabe",
      "Boris Ginsburg"
    ],
    "abstract": "This paper proposes a modification to RNN-Transducer (RNN-T) models for\nautomatic speech recognition (ASR). In standard RNN-T, the emission of a blank\nsymbol consumes exactly one input frame; in our proposed method, we introduce\nadditional blank symbols, which consume two or more input frames when emitted.\nWe refer to the added symbols as big blanks, and the method multi-blank RNN-T.\nFor training multi-blank RNN-Ts, we propose a novel logit under-normalization\nmethod in order to prioritize emissions of big blanks. With experiments on\nmultiple languages and datasets, we show that multi-blank RNN-T methods could\nbring relative speedups of over +90%/+139% to model inference for English\nLibrispeech and German Multilingual Librispeech datasets, respectively. The\nmulti-blank RNN-T method also improves ASR accuracy consistently. We will\nrelease our implementation of the method in the NeMo\n(https://github.com/NVIDIA/NeMo) toolkit.",
    "published": "2022-11-04T16:24:46Z",
    "pdf_url": "http://arxiv.org/pdf/2211.03541v2",
    "categories": [
      "eess.AS",
      "cs.LG",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "2306.09452v1",
    "title": "Distillation Strategies for Discriminative Speech Recognition Rescoring",
    "authors": [
      "Prashanth Gurunath Shivakumar",
      "Jari Kolehmainen",
      "Yile Gu",
      "Ankur Gandhe",
      "Ariya Rastrow",
      "Ivan Bulyko"
    ],
    "abstract": "Second-pass rescoring is employed in most state-of-the-art speech recognition\nsystems. Recently, BERT based models have gained popularity for re-ranking the\nn-best hypothesis by exploiting the knowledge from masked language model\npre-training. Further, fine-tuning with discriminative loss such as minimum\nword error rate (MWER) has shown to perform better than likelihood-based loss.\nStreaming applications with low latency requirements impose significant\nconstraints on the size of the models, thereby limiting the word error rate\n(WER) performance gains. In this paper, we propose effective strategies for\ndistilling from large models discriminatively trained with the MWER objective.\nWe experiment on Librispeech and production scale internal dataset for\nvoice-assistant. Our results demonstrate relative improvements of upto 7% WER\nover student models trained with MWER. We also show that the proposed\ndistillation can reduce the WER gap between the student and the teacher by 62%\nupto 100%.",
    "published": "2023-06-15T19:15:14Z",
    "pdf_url": "http://arxiv.org/pdf/2306.09452v1",
    "categories": [
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2308.02013v2",
    "title": "Federated Representation Learning for Automatic Speech Recognition",
    "authors": [
      "Guruprasad V Ramesh",
      "Gopinath Chennupati",
      "Milind Rao",
      "Anit Kumar Sahu",
      "Ariya Rastrow",
      "Jasha Droppo"
    ],
    "abstract": "Federated Learning (FL) is a privacy-preserving paradigm, allowing edge\ndevices to learn collaboratively without sharing data. Edge devices like Alexa\nand Siri are prospective sources of unlabeled audio data that can be tapped to\nlearn robust audio representations. In this work, we bring Self-supervised\nLearning (SSL) and FL together to learn representations for Automatic Speech\nRecognition respecting data privacy constraints. We use the speaker and chapter\ninformation in the unlabeled speech dataset, Libri-Light, to simulate non-IID\nspeaker-siloed data distributions and pre-train an LSTM encoder with the\nContrastive Predictive Coding framework with FedSGD. We show that the\npre-trained ASR encoder in FL performs as well as a centrally pre-trained model\nand produces an improvement of 12-15% (WER) compared to no pre-training. We\nfurther adapt the federated pre-trained models to a new language, French, and\nshow a 20% (WER) improvement over no pre-training.",
    "published": "2023-08-03T20:08:23Z",
    "pdf_url": "http://arxiv.org/pdf/2308.02013v2",
    "categories": [
      "cs.SD",
      "cs.CL",
      "cs.LG",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2309.08150v2",
    "title": "Unimodal Aggregation for CTC-based Speech Recognition",
    "authors": [
      "Ying Fang",
      "Xiaofei Li"
    ],
    "abstract": "This paper works on non-autoregressive automatic speech recognition. A\nunimodal aggregation (UMA) is proposed to segment and integrate the feature\nframes that belong to the same text token, and thus to learn better feature\nrepresentations for text tokens. The frame-wise features and weights are both\nderived from an encoder. Then, the feature frames with unimodal weights are\nintegrated and further processed by a decoder. Connectionist temporal\nclassification (CTC) loss is applied for training. Compared to the regular CTC,\nthe proposed method learns better feature representations and shortens the\nsequence length, resulting in lower recognition error and computational\ncomplexity. Experiments on three Mandarin datasets show that UMA demonstrates\nsuperior or comparable performance to other advanced non-autoregressive\nmethods, such as self-conditioned CTC. Moreover, by integrating\nself-conditioned CTC into the proposed framework, the performance can be\nfurther noticeably improved.",
    "published": "2023-09-15T04:34:40Z",
    "pdf_url": "http://arxiv.org/pdf/2309.08150v2",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2401.08916v1",
    "title": "Two-pass Endpoint Detection for Speech Recognition",
    "authors": [
      "Anirudh Raju",
      "Aparna Khare",
      "Di He",
      "Ilya Sklyar",
      "Long Chen",
      "Sam Alptekin",
      "Viet Anh Trinh",
      "Zhe Zhang",
      "Colin Vaz",
      "Venkatesh Ravichandran",
      "Roland Maas",
      "Ariya Rastrow"
    ],
    "abstract": "Endpoint (EP) detection is a key component of far-field speech recognition\nsystems that assist the user through voice commands. The endpoint detector has\nto trade-off between accuracy and latency, since waiting longer reduces the\ncases of users being cut-off early. We propose a novel two-pass solution for\nendpointing, where the utterance endpoint detected from a first pass endpointer\nis verified by a 2nd-pass model termed EP Arbitrator. Our method improves the\ntrade-off between early cut-offs and latency over a baseline endpointer, as\ntested on datasets including voice-assistant transactional queries,\nconversational speech, and the public SLURP corpus. We demonstrate that our\nmethod shows improvements regardless of the first-pass EP model used.",
    "published": "2024-01-17T02:00:07Z",
    "pdf_url": "http://arxiv.org/pdf/2401.08916v1",
    "categories": [
      "eess.AS",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "2406.02649v1",
    "title": "Keyword-Guided Adaptation of Automatic Speech Recognition",
    "authors": [
      "Aviv Shamsian",
      "Aviv Navon",
      "Neta Glazer",
      "Gill Hetz",
      "Joseph Keshet"
    ],
    "abstract": "Automatic Speech Recognition (ASR) technology has made significant progress\nin recent years, providing accurate transcription across various domains.\nHowever, some challenges remain, especially in noisy environments and\nspecialized jargon. In this paper, we propose a novel approach for improved\njargon word recognition by contextual biasing Whisper-based models. We employ a\nkeyword spotting model that leverages the Whisper encoder representation to\ndynamically generate prompts for guiding the decoder during the transcription\nprocess. We introduce two approaches to effectively steer the decoder towards\nthese prompts: KG-Whisper, which is aimed at fine-tuning the Whisper decoder,\nand KG-Whisper-PT, which learns a prompt prefix. Our results show a significant\nimprovement in the recognition accuracy of specified keywords and in reducing\nthe overall word error rates. Specifically, in unseen language generalization,\nwe demonstrate an average WER improvement of 5.1% over Whisper.",
    "published": "2024-06-04T14:20:38Z",
    "pdf_url": "http://arxiv.org/pdf/2406.02649v1",
    "categories": [
      "eess.AS",
      "cs.LG",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "2406.08380v2",
    "title": "Towards Unsupervised Speech Recognition Without Pronunciation Models",
    "authors": [
      "Junrui Ni",
      "Liming Wang",
      "Yang Zhang",
      "Kaizhi Qian",
      "Heting Gao",
      "Mark Hasegawa-Johnson",
      "Chang D. Yoo"
    ],
    "abstract": "Recent advancements in supervised automatic speech recognition (ASR) have\nachieved remarkable performance, largely due to the growing availability of\nlarge transcribed speech corpora. However, most languages lack sufficient\npaired speech and text data to effectively train these systems. In this\narticle, we tackle the challenge of developing ASR systems without paired\nspeech and text corpora by proposing the removal of reliance on a phoneme\nlexicon. We explore a new research direction: word-level unsupervised ASR, and\nexperimentally demonstrate that an unsupervised speech recognizer can emerge\nfrom joint speech-to-speech and text-to-text masked token-infilling. Using a\ncurated speech corpus containing a fixed number of English words, our system\niteratively refines the word segmentation structure and achieves a word error\nrate of between 20-23%, depending on the vocabulary size, without parallel\ntranscripts, oracle word boundaries, or a pronunciation lexicon. This\ninnovative model surpasses the performance of previous unsupervised ASR models\nunder the lexicon-free setting.",
    "published": "2024-06-12T16:30:58Z",
    "pdf_url": "http://arxiv.org/pdf/2406.08380v2",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2406.18373v1",
    "title": "Dynamic Data Pruning for Automatic Speech Recognition",
    "authors": [
      "Qiao Xiao",
      "Pingchuan Ma",
      "Adriana Fernandez-Lopez",
      "Boqian Wu",
      "Lu Yin",
      "Stavros Petridis",
      "Mykola Pechenizkiy",
      "Maja Pantic",
      "Decebal Constantin Mocanu",
      "Shiwei Liu"
    ],
    "abstract": "The recent success of Automatic Speech Recognition (ASR) is largely\nattributed to the ever-growing amount of training data. However, this trend has\nmade model training prohibitively costly and imposed computational demands.\nWhile data pruning has been proposed to mitigate this issue by identifying a\nsmall subset of relevant data, its application in ASR has been barely explored,\nand existing works often entail significant overhead to achieve meaningful\nresults. To fill this gap, this paper presents the first investigation of\ndynamic data pruning for ASR, finding that we can reach the full-data\nperformance by dynamically selecting 70% of data. Furthermore, we introduce\nDynamic Data Pruning for ASR (DDP-ASR), which offers several fine-grained\npruning granularities specifically tailored for speech-related datasets, going\nbeyond the conventional pruning of entire time sequences. Our intensive\nexperiments show that DDP-ASR can save up to 1.6x training time with negligible\nperformance loss.",
    "published": "2024-06-26T14:17:36Z",
    "pdf_url": "http://arxiv.org/pdf/2406.18373v1",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2408.00004v2",
    "title": "Handling Numeric Expressions in Automatic Speech Recognition",
    "authors": [
      "Christian Huber",
      "Alexander Waibel"
    ],
    "abstract": "This paper addresses the problem of correctly formatting numeric expressions\nin automatic speech recognition (ASR) transcripts. This is challenging since\nthe expected transcript format depends on the context, e.g., 1945 (year) vs.\n19:45 (timestamp). We compare cascaded and end-to-end approaches to recognize\nand format numeric expressions such as years, timestamps, currency amounts, and\nquantities. For the end-to-end approach, we employed a data generation strategy\nusing a large language model (LLM) together with a text to speech (TTS) model\nto generate adaptation data. The results on our test data set show that while\napproaches based on LLMs perform well in recognizing formatted numeric\nexpressions, adapted end-to-end models offer competitive performance with the\nadvantage of lower latency and inference cost.",
    "published": "2024-07-18T09:46:19Z",
    "pdf_url": "http://arxiv.org/pdf/2408.00004v2",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2410.00940v1",
    "title": "Automatic Speech Recognition for the Ika Language",
    "authors": [
      "Uchenna Nzenwata",
      "Daniel Ogbuigwe"
    ],
    "abstract": "We present a cost-effective approach for developing Automatic Speech\nRecognition (ASR) models for low-resource languages like Ika. We fine-tune the\npretrained wav2vec 2.0 Massively Multilingual Speech Models on a high-quality\nspeech dataset compiled from New Testament Bible translations in Ika. Our\nresults show that fine-tuning multilingual pretrained models achieves a Word\nError Rate (WER) of 0.5377 and Character Error Rate (CER) of 0.2651 with just\nover 1 hour of training data. The larger 1 billion parameter model outperforms\nthe smaller 300 million parameter model due to its greater complexity and\nability to store richer speech representations. However, we observe overfitting\nto the small training dataset, reducing generalizability. Our findings\ndemonstrate the potential of leveraging multilingual pretrained models for\nlow-resource languages. Future work should focus on expanding the dataset and\nexploring techniques to mitigate overfitting.",
    "published": "2024-10-01T11:56:42Z",
    "pdf_url": "http://arxiv.org/pdf/2410.00940v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2502.04834v1",
    "title": "Lightweight Operations for Visual Speech Recognition",
    "authors": [
      "Iason Ioannis Panagos",
      "Giorgos Sfikas",
      "Christophoros Nikou"
    ],
    "abstract": "Visual speech recognition (VSR), which decodes spoken words from video data,\noffers significant benefits, particularly when audio is unavailable. However,\nthe high dimensionality of video data leads to prohibitive computational costs\nthat demand powerful hardware, limiting VSR deployment on resource-constrained\ndevices. This work addresses this limitation by developing lightweight VSR\narchitectures. Leveraging efficient operation design paradigms, we create\ncompact yet powerful models with reduced resource requirements and minimal\naccuracy loss. We train and evaluate our models on a large-scale public dataset\nfor recognition of words from video sequences, demonstrating their\neffectiveness for practical applications. We also conduct an extensive array of\nablative experiments to thoroughly analyze the size and complexity of each\nmodel. Code and trained models will be made publicly available.",
    "published": "2025-02-07T11:08:32Z",
    "pdf_url": "http://arxiv.org/pdf/2502.04834v1",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2509.23550v1",
    "title": "Automatic Speech Recognition for Greek Medical Dictation",
    "authors": [
      "Vardis Georgilas",
      "Themos Stafylakis"
    ],
    "abstract": "Medical dictation systems are essential tools in modern healthcare, enabling\naccurate and efficient conversion of speech into written medical documentation.\nThe main objective of this paper is to create a domain-specific system for\nGreek medical speech transcriptions. The ultimate goal is to assist healthcare\nprofessionals by reducing the overload of manual documentation and improving\nworkflow efficiency. Towards this goal, we develop a system that combines\nautomatic speech recognition techniques with text correction model, allowing\nbetter handling of domain-specific terminology and linguistic variations in\nGreek. Our approach leverages both acoustic and textual modeling to create more\nrealistic and reliable transcriptions. We focused on adapting existing language\nand speech technologies to the Greek medical context, addressing challenges\nsuch as complex medical terminology and linguistic inconsistencies. Through\ndomain-specific fine-tuning, our system achieves more accurate and coherent\ntranscriptions, contributing to the development of practical language\ntechnologies for the Greek healthcare sector.",
    "published": "2025-09-28T01:15:47Z",
    "pdf_url": "http://arxiv.org/pdf/2509.23550v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1507.04019v1",
    "title": "Feature Normalisation for Robust Speech Recognition",
    "authors": [
      "D. S. Pavan Kumar"
    ],
    "abstract": "Speech recognition system performance degrades in noisy environments. If the\nacoustic models are built using features of clean utterances, the features of a\nnoisy test utterance would be acoustically mismatched with the trained model.\nThis gives poor likelihoods and poor recognition accuracy. Model adaptation and\nfeature normalisation are two broad areas that address this problem. While the\nformer often gives better performance, the latter involves estimation of lesser\nnumber of parameters, making the system feasible for practical implementations.\n  This research focuses on the efficacies of various subspace, statistical and\nstereo based feature normalisation techniques. A subspace projection based\nmethod has been investigated as a standalone and adjunct technique involving\nreconstruction of noisy speech features from a precomputed set of clean speech\nbuilding-blocks. The building blocks are learned using non-negative matrix\nfactorisation (NMF) on log-Mel filter bank coefficients, which form a basis for\nthe clean speech subspace. The work provides a detailed study on how the method\ncan be incorporated into the extraction process of Mel-frequency cepstral\ncoefficients. Experimental results show that the new features are robust to\nnoise, and achieve better results when combined with the existing techniques.\n  The work also proposes a modification to the training process of SPLICE\nalgorithm for noise robust speech recognition. It is based on feature\ncorrelations, and enables this stereo-based algorithm to improve the\nperformance in all noise conditions, especially in unseen cases. Further, the\nmodified framework is extended to work for non-stereo datasets where clean and\nnoisy training utterances, but not stereo counterparts, are required. An\nMLLR-based computationally efficient run-time noise adaptation method in SPLICE\nframework has been proposed.",
    "published": "2015-07-14T20:34:16Z",
    "pdf_url": "http://arxiv.org/pdf/1507.04019v1",
    "categories": [
      "cs.CL",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "1701.03577v1",
    "title": "Kernel Approximation Methods for Speech Recognition",
    "authors": [
      "Avner May",
      "Alireza Bagheri Garakani",
      "Zhiyun Lu",
      "Dong Guo",
      "Kuan Liu",
      "Aurélien Bellet",
      "Linxi Fan",
      "Michael Collins",
      "Daniel Hsu",
      "Brian Kingsbury",
      "Michael Picheny",
      "Fei Sha"
    ],
    "abstract": "We study large-scale kernel methods for acoustic modeling in speech\nrecognition and compare their performance to deep neural networks (DNNs). We\nperform experiments on four speech recognition datasets, including the TIMIT\nand Broadcast News benchmark tasks, and compare these two types of models on\nframe-level performance metrics (accuracy, cross-entropy), as well as on\nrecognition metrics (word/character error rate). In order to scale kernel\nmethods to these large datasets, we use the random Fourier feature method of\nRahimi and Recht (2007). We propose two novel techniques for improving the\nperformance of kernel acoustic models. First, in order to reduce the number of\nrandom features required by kernel models, we propose a simple but effective\nmethod for feature selection. The method is able to explore a large number of\nnon-linear features while maintaining a compact model more efficiently than\nexisting approaches. Second, we present a number of frame-level metrics which\ncorrelate very strongly with recognition performance when computed on the\nheldout set; we take advantage of these correlations by monitoring these\nmetrics during training in order to decide when to stop learning. This\ntechnique can noticeably improve the recognition performance of both DNN and\nkernel models, while narrowing the gap between them. Additionally, we show that\nthe linear bottleneck method of Sainath et al. (2013) improves the performance\nof our kernel models significantly, in addition to speeding up training and\nmaking the models more compact. Together, these three methods dramatically\nimprove the performance of kernel acoustic models, making their performance\ncomparable to DNNs on the tasks we explored.",
    "published": "2017-01-13T07:24:18Z",
    "pdf_url": "http://arxiv.org/pdf/1701.03577v1",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2507.05727v2",
    "title": "ContextASR-Bench: A Massive Contextual Speech Recognition Benchmark",
    "authors": [
      "He Wang",
      "Linhan Ma",
      "Dake Guo",
      "Xiong Wang",
      "Lei Xie",
      "Jin Xu",
      "Junyang Lin"
    ],
    "abstract": "Automatic Speech Recognition (ASR) has been extensively investigated, yet\nprior benchmarks have largely focused on assessing the acoustic robustness of\nASR models, leaving evaluations of their linguistic capabilities relatively\nunderexplored. This largely stems from the limited parameter sizes and training\ncorpora of conventional ASR models, leaving them with insufficient world\nknowledge, which is crucial for accurately recognizing named entities across\ndiverse domains. For instance, drug and treatment names in medicine or\nspecialized technical terms in engineering. Recent breakthroughs in Large\nLanguage Models (LLMs) and corresponding Large Audio Language Models (LALMs)\nhave markedly enhanced the visibility of advanced context modeling and general\nartificial intelligence capabilities. Leveraging LLMs, we envision a unified\nsystem capable of robust speech recognition across diverse real-world domains,\nyet existing benchmarks are inadequate for evaluating this objective. To\naddress this gap, we propose ContextASR-Bench: a comprehensive, large-scale\nbenchmark designed to assess the linguistic competence of ASR systems using\ncorpora that feature numerous named entities across multiple domains. It\nencompasses up to 40,000 data entries with more than 300,000 named entities\nacross over 10 domains. Beyond the audio and its transcription, each sample\nprovides the domain it belongs to and a list of named entities it contains,\nwhich are referred to as the context. Based on this, we introduce three\nevaluation modes to assess how effectively models can exploit such context to\nimprove ASR accuracy. Extensive evaluation on ContextASR-Bench highlights that\nLALMs outperform conventional ASR models by a large margin thanks to the strong\nworld knowledge and context modeling of LLMs, yet there remains ample room for\nfurther improvement. The dataset and evaluation code have been released.",
    "published": "2025-07-08T07:21:20Z",
    "pdf_url": "http://arxiv.org/pdf/2507.05727v2",
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "2004.09249v2",
    "title": "CHiME-6 Challenge:Tackling Multispeaker Speech Recognition for\n  Unsegmented Recordings",
    "authors": [
      "Shinji Watanabe",
      "Michael Mandel",
      "Jon Barker",
      "Emmanuel Vincent",
      "Ashish Arora",
      "Xuankai Chang",
      "Sanjeev Khudanpur",
      "Vimal Manohar",
      "Daniel Povey",
      "Desh Raj",
      "David Snyder",
      "Aswin Shanmugam Subramanian",
      "Jan Trmal",
      "Bar Ben Yair",
      "Christoph Boeddeker",
      "Zhaoheng Ni",
      "Yusuke Fujita",
      "Shota Horiguchi",
      "Naoyuki Kanda",
      "Takuya Yoshioka",
      "Neville Ryant"
    ],
    "abstract": "Following the success of the 1st, 2nd, 3rd, 4th and 5th CHiME challenges we\norganize the 6th CHiME Speech Separation and Recognition Challenge (CHiME-6).\nThe new challenge revisits the previous CHiME-5 challenge and further considers\nthe problem of distant multi-microphone conversational speech diarization and\nrecognition in everyday home environments. Speech material is the same as the\nprevious CHiME-5 recordings except for accurate array synchronization. The\nmaterial was elicited using a dinner party scenario with efforts taken to\ncapture data that is representative of natural conversational speech. This\npaper provides a baseline description of the CHiME-6 challenge for both\nsegmented multispeaker speech recognition (Track 1) and unsegmented\nmultispeaker speech recognition (Track 2). Of note, Track 2 is the first\nchallenge activity in the community to tackle an unsegmented multispeaker\nspeech recognition scenario with a complete set of reproducible open source\nbaselines providing speech enhancement, speaker diarization, and speech\nrecognition modules.",
    "published": "2020-04-20T12:59:07Z",
    "pdf_url": "http://arxiv.org/pdf/2004.09249v2",
    "categories": [
      "cs.SD",
      "cs.CL",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2207.05071v1",
    "title": "Online Continual Learning of End-to-End Speech Recognition Models",
    "authors": [
      "Muqiao Yang",
      "Ian Lane",
      "Shinji Watanabe"
    ],
    "abstract": "Continual Learning, also known as Lifelong Learning, aims to continually\nlearn from new data as it becomes available. While prior research on continual\nlearning in automatic speech recognition has focused on the adaptation of\nmodels across multiple different speech recognition tasks, in this paper we\npropose an experimental setting for \\textit{online continual learning} for\nautomatic speech recognition of a single task. Specifically focusing on the\ncase where additional training data for the same task becomes available\nincrementally over time, we demonstrate the effectiveness of performing\nincremental model updates to end-to-end speech recognition models with an\nonline Gradient Episodic Memory (GEM) method. Moreover, we show that with\nonline continual learning and a selective sampling strategy, we can maintain an\naccuracy that is similar to retraining a model from scratch while requiring\nsignificantly lower computation costs. We have also verified our method with\nself-supervised learning (SSL) features.",
    "published": "2022-07-11T05:35:06Z",
    "pdf_url": "http://arxiv.org/pdf/2207.05071v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2404.17394v2",
    "title": "Child Speech Recognition in Human-Robot Interaction: Problem Solved?",
    "authors": [
      "Ruben Janssens",
      "Eva Verhelst",
      "Giulio Antonio Abbo",
      "Qiaoqiao Ren",
      "Maria Jose Pinto Bernal",
      "Tony Belpaeme"
    ],
    "abstract": "Automated Speech Recognition shows superhuman performance for adult English\nspeech on a range of benchmarks, but disappoints when fed children's speech.\nThis has long sat in the way of child-robot interaction. Recent evolutions in\ndata-driven speech recognition, including the availability of Transformer\narchitectures and unprecedented volumes of training data, might mean a\nbreakthrough for child speech recognition and social robot applications aimed\nat children. We revisit a study on child speech recognition from 2017 and show\nthat indeed performance has increased, with newcomer OpenAI Whisper doing\nmarkedly better than leading commercial cloud services. Performance improves\neven more in highly structured interactions when priming models with specific\nphrases. While transcription is not perfect yet, the best model recognises\n60.3% of sentences correctly barring small grammatical differences, with\nsub-second transcription time running on a local GPU, showing potential for\nusable autonomous child-robot speech interactions.",
    "published": "2024-04-26T13:14:28Z",
    "pdf_url": "http://arxiv.org/pdf/2404.17394v2",
    "categories": [
      "cs.CL",
      "cs.HC",
      "cs.RO"
    ]
  },
  {
    "arxiv_id": "2409.12370v1",
    "title": "Robust Audiovisual Speech Recognition Models with Mixture-of-Experts",
    "authors": [
      "Yihan Wu",
      "Yifan Peng",
      "Yichen Lu",
      "Xuankai Chang",
      "Ruihua Song",
      "Shinji Watanabe"
    ],
    "abstract": "Visual signals can enhance audiovisual speech recognition accuracy by\nproviding additional contextual information. Given the complexity of visual\nsignals, an audiovisual speech recognition model requires robust generalization\ncapabilities across diverse video scenarios, presenting a significant\nchallenge. In this paper, we introduce EVA, leveraging the mixture-of-Experts\nfor audioVisual ASR to perform robust speech recognition for ``in-the-wild''\nvideos. Specifically, we first encode visual information into visual tokens\nsequence and map them into speech space by a lightweight projection. Then, we\nbuild EVA upon a robust pretrained speech recognition model, ensuring its\ngeneralization ability. Moreover, to incorporate visual information\neffectively, we inject visual information into the ASR model through a\nmixture-of-experts module. Experiments show our model achieves state-of-the-art\nresults on three benchmarks, which demonstrates the generalization ability of\nEVA across diverse video domains.",
    "published": "2024-09-19T00:08:28Z",
    "pdf_url": "http://arxiv.org/pdf/2409.12370v1",
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.CV",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "2502.15264v1",
    "title": "Retrieval-Augmented Speech Recognition Approach for Domain Challenges",
    "authors": [
      "Peng Shen",
      "Xugang Lu",
      "Hisashi Kawai"
    ],
    "abstract": "Speech recognition systems often face challenges due to domain mismatch,\nparticularly in real-world applications where domain-specific data is\nunavailable because of data accessibility and confidentiality constraints.\nInspired by Retrieval-Augmented Generation (RAG) techniques for large language\nmodels (LLMs), this paper introduces a LLM-based retrieval-augmented speech\nrecognition method that incorporates domain-specific textual data at the\ninference stage to enhance recognition performance. Rather than relying on\ndomain-specific textual data during the training phase, our model is trained to\nlearn how to utilize textual information provided in prompts for LLM decoder to\nimprove speech recognition performance. Benefiting from the advantages of the\nRAG retrieval mechanism, our approach efficiently accesses locally available\ndomain-specific documents, ensuring a convenient and effective process for\nsolving domain mismatch problems. Experiments conducted on the CSJ database\ndemonstrate that the proposed method significantly improves speech recognition\naccuracy and achieves state-of-the-art results on the CSJ dataset, even without\nrelying on the full training data.",
    "published": "2025-02-21T07:47:50Z",
    "pdf_url": "http://arxiv.org/pdf/2502.15264v1",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2509.22744v1",
    "title": "Index-MSR: A high-efficiency multimodal fusion framework for speech\n  recognition",
    "authors": [
      "Jinming Chen",
      "Lu Wang",
      "Zheshu Song",
      "Wei Deng"
    ],
    "abstract": "Driven by large scale datasets and LLM based architectures, automatic speech\nrecognition (ASR) systems have achieved remarkable improvements in accuracy.\nHowever, challenges persist for domain-specific terminology, and short\nutterances lacking semantic coherence, where recognition performance often\ndegrades significantly. In this work, we present Index-MSR, an efficient\nmultimodal speech recognition framework. At its core is a novel Multimodal\nFusion Decoder (MFD), which effectively incorporates text-related information\nfrom videos (e.g., subtitles and presentation slides) into the speech\nrecognition. This cross-modal integration not only enhances overall ASR\naccuracy but also yields substantial reductions in substitution errors.\nExtensive evaluations on both an in-house subtitle dataset and a public AVSR\ndataset demonstrate that Index-MSR achieves sota accuracy, with substitution\nerrors reduced by 20,50%. These results demonstrate that our approach\nefficiently exploits text-related cues from video to improve speech recognition\naccuracy, showing strong potential in applications requiring strict audio text\nsynchronization, such as audio translation.",
    "published": "2025-09-26T03:47:15Z",
    "pdf_url": "http://arxiv.org/pdf/2509.22744v1",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.MM",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "1805.10387v2",
    "title": "Mixed-Precision Training for NLP and Speech Recognition with OpenSeq2Seq",
    "authors": [
      "Oleksii Kuchaiev",
      "Boris Ginsburg",
      "Igor Gitman",
      "Vitaly Lavrukhin",
      "Jason Li",
      "Huyen Nguyen",
      "Carl Case",
      "Paulius Micikevicius"
    ],
    "abstract": "We present OpenSeq2Seq - a TensorFlow-based toolkit for training\nsequence-to-sequence models that features distributed and mixed-precision\ntraining. Benchmarks on machine translation and speech recognition tasks show\nthat models built using OpenSeq2Seq give state-of-the-art performance at 1.5-3x\nless training time. OpenSeq2Seq currently provides building blocks for models\nthat solve a wide range of tasks including neural machine translation,\nautomatic speech recognition, and speech synthesis.",
    "published": "2018-05-25T22:54:38Z",
    "pdf_url": "http://arxiv.org/pdf/1805.10387v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2008.06580v2",
    "title": "Adaptation Algorithms for Neural Network-Based Speech Recognition: An\n  Overview",
    "authors": [
      "Peter Bell",
      "Joachim Fainberg",
      "Ondrej Klejch",
      "Jinyu Li",
      "Steve Renals",
      "Pawel Swietojanski"
    ],
    "abstract": "We present a structured overview of adaptation algorithms for neural\nnetwork-based speech recognition, considering both hybrid hidden Markov model /\nneural network systems and end-to-end neural network systems, with a focus on\nspeaker adaptation, domain adaptation, and accent adaptation. The overview\ncharacterizes adaptation algorithms as based on embeddings, model parameter\nadaptation, or data augmentation. We present a meta-analysis of the performance\nof speech recognition adaptation algorithms, based on relative error rate\nreductions as reported in the literature.",
    "published": "2020-08-14T21:50:03Z",
    "pdf_url": "http://arxiv.org/pdf/2008.06580v2",
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "2008.07621v1",
    "title": "Speech Recognition using EEG signals recorded using dry electrodes",
    "authors": [
      "Gautam Krishna",
      "Co Tran",
      "Mason Carnahan",
      "Morgan M Hagood",
      "Ahmed H Tewfik"
    ],
    "abstract": "In this paper, we demonstrate speech recognition using electroencephalography\n(EEG) signals obtained using dry electrodes on a limited English vocabulary\nconsisting of three vowels and one word using a deep learning model. We\ndemonstrate a test accuracy of 79.07 percent on a subset vocabulary consisting\nof two English vowels. Our results demonstrate the feasibility of using EEG\nsignals recorded using dry electrodes for performing the task of speech\nrecognition.",
    "published": "2020-08-13T09:56:45Z",
    "pdf_url": "http://arxiv.org/pdf/2008.07621v1",
    "categories": [
      "eess.AS",
      "cs.LG",
      "cs.SD",
      "eess.SP"
    ]
  },
  {
    "arxiv_id": "2006.02902v1",
    "title": "Constrained Variational Autoencoder for improving EEG based Speech\n  Recognition Systems",
    "authors": [
      "Gautam Krishna",
      "Co Tran",
      "Mason Carnahan",
      "Ahmed Tewfik"
    ],
    "abstract": "In this paper we introduce a recurrent neural network (RNN) based variational\nautoencoder (VAE) model with a new constrained loss function that can generate\nmore meaningful electroencephalography (EEG) features from raw EEG features to\nimprove the performance of EEG based speech recognition systems. We demonstrate\nthat both continuous and isolated speech recognition systems trained and tested\nusing EEG features generated from raw EEG features using our VAE model results\nin improved performance and we demonstrate our results for a limited English\nvocabulary consisting of 30 unique sentences for continuous speech recognition\nand for an English vocabulary consisting of 2 unique sentences for isolated\nspeech recognition. We compare our method with another recently introduced\nmethod described by authors in [1] to improve the performance of EEG based\ncontinuous speech recognition systems and we demonstrate that our method\noutperforms their method as vocabulary size increases when trained and tested\nusing the same data set. Even though we demonstrate results only for automatic\nspeech recognition (ASR) experiments in this paper, the proposed VAE model with\nconstrained loss function can be extended to a variety of other EEG based brain\ncomputer interface (BCI) applications.",
    "published": "2020-06-01T06:03:50Z",
    "pdf_url": "http://arxiv.org/pdf/2006.02902v1",
    "categories": [
      "eess.AS",
      "cs.LG",
      "cs.SD",
      "eess.SP"
    ]
  },
  {
    "arxiv_id": "1312.6849v2",
    "title": "Speech Recognition Front End Without Information Loss",
    "authors": [
      "Matthew Ager",
      "Zoran Cvetkovic",
      "Peter Sollich"
    ],
    "abstract": "Speech representation and modelling in high-dimensional spaces of acoustic\nwaveforms, or a linear transformation thereof, is investigated with the aim of\nimproving the robustness of automatic speech recognition to additive noise. The\nmotivation behind this approach is twofold: (i) the information in acoustic\nwaveforms that is usually removed in the process of extracting low-dimensional\nfeatures might aid robust recognition by virtue of structured redundancy\nanalogous to channel coding, (ii) linear feature domains allow for exact noise\nadaptation, as opposed to representations that involve non-linear processing\nwhich makes noise adaptation challenging. Thus, we develop a generative\nframework for phoneme modelling in high-dimensional linear feature domains, and\nuse it in phoneme classification and recognition tasks. Results show that\nclassification and recognition in this framework perform better than analogous\nPLP and MFCC classifiers below 18 dB SNR. A combination of the high-dimensional\nand MFCC features at the likelihood level performs uniformly better than either\nof the individual representations across all noise levels.",
    "published": "2013-12-24T16:36:16Z",
    "pdf_url": "http://arxiv.org/pdf/1312.6849v2",
    "categories": [
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1506.00799v1",
    "title": "Learning Speech Rate in Speech Recognition",
    "authors": [
      "Xiangyu Zeng",
      "Shi Yin",
      "Dong Wang"
    ],
    "abstract": "A significant performance reduction is often observed in speech recognition\nwhen the rate of speech (ROS) is too low or too high. Most of present\napproaches to addressing the ROS variation focus on the change of speech\nsignals in dynamic properties caused by ROS, and accordingly modify the dynamic\nmodel, e.g., the transition probabilities of the hidden Markov model (HMM).\nHowever, an abnormal ROS changes not only the dynamic but also the static\nproperty of speech signals, and thus can not be compensated for purely by\nmodifying the dynamic model. This paper proposes an ROS learning approach based\non deep neural networks (DNN), which involves an ROS feature as the input of\nthe DNN model and so the spectrum distortion caused by ROS can be learned and\ncompensated for. The experimental results show that this approach can deliver\nbetter performance for too slow and too fast utterances, demonstrating our\nconjecture that ROS impacts both the dynamic and the static property of speech.\nIn addition, the proposed approach can be combined with the conventional HMM\ntransition adaptation method, offering additional performance gains.",
    "published": "2015-06-02T08:59:47Z",
    "pdf_url": "http://arxiv.org/pdf/1506.00799v1",
    "categories": [
      "cs.CL",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "1506.07503v1",
    "title": "Attention-Based Models for Speech Recognition",
    "authors": [
      "Jan Chorowski",
      "Dzmitry Bahdanau",
      "Dmitriy Serdyuk",
      "Kyunghyun Cho",
      "Yoshua Bengio"
    ],
    "abstract": "Recurrent sequence generators conditioned on input data through an attention\nmechanism have recently shown very good performance on a range of tasks in-\ncluding machine translation, handwriting synthesis and image caption gen-\neration. We extend the attention-mechanism with features needed for speech\nrecognition. We show that while an adaptation of the model used for machine\ntranslation in reaches a competitive 18.7% phoneme error rate (PER) on the\nTIMIT phoneme recognition task, it can only be applied to utterances which are\nroughly as long as the ones it was trained on. We offer a qualitative\nexplanation of this failure and propose a novel and generic method of adding\nlocation-awareness to the attention mechanism to alleviate this issue. The new\nmethod yields a model that is robust to long inputs and achieves 18% PER in\nsingle utterances and 20% in 10-times longer (repeated) utterances. Finally, we\npropose a change to the at- tention mechanism that prevents it from\nconcentrating too much on single frames, which further reduces PER to 17.6%\nlevel.",
    "published": "2015-06-24T19:10:33Z",
    "pdf_url": "http://arxiv.org/pdf/1506.07503v1",
    "categories": [
      "cs.CL",
      "cs.LG",
      "cs.NE",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1612.01928v1",
    "title": "Invariant Representations for Noisy Speech Recognition",
    "authors": [
      "Dmitriy Serdyuk",
      "Kartik Audhkhasi",
      "Philémon Brakel",
      "Bhuvana Ramabhadran",
      "Samuel Thomas",
      "Yoshua Bengio"
    ],
    "abstract": "Modern automatic speech recognition (ASR) systems need to be robust under\nacoustic variability arising from environmental, speaker, channel, and\nrecording conditions. Ensuring such robustness to variability is a challenge in\nmodern day neural network-based ASR systems, especially when all types of\nvariability are not seen during training. We attempt to address this problem by\nencouraging the neural network acoustic model to learn invariant feature\nrepresentations. We use ideas from recent research on image generation using\nGenerative Adversarial Networks and domain adaptation ideas extending\nadversarial gradient-based training. A recent work from Ganin et al. proposes\nto use adversarial training for image domain adaptation by using an\nintermediate representation from the main target classification network to\ndeteriorate the domain classifier performance through a separate neural\nnetwork. Our work focuses on investigating neural architectures which produce\nrepresentations invariant to noise conditions for ASR. We evaluate the proposed\narchitecture on the Aurora-4 task, a popular benchmark for noise robust ASR. We\nshow that our method generalizes better than the standard multi-condition\ntraining especially when only a few noise categories are seen during training.",
    "published": "2016-11-27T22:20:51Z",
    "pdf_url": "http://arxiv.org/pdf/1612.01928v1",
    "categories": [
      "cs.CL",
      "cs.CV",
      "cs.LG",
      "cs.SD",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1712.00489v1",
    "title": "Visual Features for Context-Aware Speech Recognition",
    "authors": [
      "Abhinav Gupta",
      "Yajie Miao",
      "Leonardo Neves",
      "Florian Metze"
    ],
    "abstract": "Automatic transcriptions of consumer-generated multi-media content such as\n\"Youtube\" videos still exhibit high word error rates. Such data typically\noccupies a very broad domain, has been recorded in challenging conditions, with\ncheap hardware and a focus on the visual modality, and may have been\npost-processed or edited. In this paper, we extend our earlier work on adapting\nthe acoustic model of a DNN-based speech recognition system to an RNN language\nmodel and show how both can be adapted to the objects and scenes that can be\nautomatically detected in the video. We are working on a corpus of \"how-to\"\nvideos from the web, and the idea is that an object that can be seen (\"car\"),\nor a scene that is being detected (\"kitchen\") can be used to condition both\nmodels on the \"context\" of the recording, thereby reducing perplexity and\nimproving transcription. We achieve good improvements in both cases and compare\nand analyze the respective reductions in word error rate. We expect that our\nresults can be used for any type of speech processing in which \"context\"\ninformation is available, for example in robotics, man-machine interaction, or\nwhen indexing large audio-visual archives, and should ultimately help to bring\ntogether the \"video-to-text\" and \"speech-to-text\" communities.",
    "published": "2017-12-01T20:56:31Z",
    "pdf_url": "http://arxiv.org/pdf/1712.00489v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "1712.06086v1",
    "title": "Deep Learning for Distant Speech Recognition",
    "authors": [
      "Mirco Ravanelli"
    ],
    "abstract": "Deep learning is an emerging technology that is considered one of the most\npromising directions for reaching higher levels of artificial intelligence.\nAmong the other achievements, building computers that understand speech\nrepresents a crucial leap towards intelligent machines. Despite the great\nefforts of the past decades, however, a natural and robust human-machine speech\ninteraction still appears to be out of reach, especially when users interact\nwith a distant microphone in noisy and reverberant environments. The latter\ndisturbances severely hamper the intelligibility of a speech signal, making\nDistant Speech Recognition (DSR) one of the major open challenges in the field.\n  This thesis addresses the latter scenario and proposes some novel techniques,\narchitectures, and algorithms to improve the robustness of distant-talking\nacoustic models. We first elaborate on methodologies for realistic data\ncontamination, with a particular emphasis on DNN training with simulated data.\nWe then investigate on approaches for better exploiting speech contexts,\nproposing some original methodologies for both feed-forward and recurrent\nneural networks. Lastly, inspired by the idea that cooperation across different\nDNNs could be the key for counteracting the harmful effects of noise and\nreverberation, we propose a novel deep learning paradigm called network of deep\nneural networks. The analysis of the original concepts were based on extensive\nexperimental validations conducted on both real and simulated data, considering\ndifferent corpora, microphone configurations, environments, noisy conditions,\nand ASR tasks.",
    "published": "2017-12-17T10:29:15Z",
    "pdf_url": "http://arxiv.org/pdf/1712.06086v1",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "1712.09444v2",
    "title": "Letter-Based Speech Recognition with Gated ConvNets",
    "authors": [
      "Vitaliy Liptchinsky",
      "Gabriel Synnaeve",
      "Ronan Collobert"
    ],
    "abstract": "In the recent literature, \"end-to-end\" speech systems often refer to\nletter-based acoustic models trained in a sequence-to-sequence manner, either\nvia a recurrent model or via a structured output learning approach (such as\nCTC). In contrast to traditional phone (or senone)-based approaches, these\n\"end-to-end'' approaches alleviate the need of word pronunciation modeling, and\ndo not require a \"forced alignment\" step at training time. Phone-based\napproaches remain however state of the art on classical benchmarks. In this\npaper, we propose a letter-based speech recognition system, leveraging a\nConvNet acoustic model. Key ingredients of the ConvNet are Gated Linear Units\nand high dropout. The ConvNet is trained to map audio sequences to their\ncorresponding letter transcriptions, either via a classical CTC approach, or\nvia a recent variant called ASG. Coupled with a simple decoder at inference\ntime, our system matches the best existing letter-based systems on WSJ (in word\nerror rate), and shows near state of the art performance on LibriSpeech.",
    "published": "2017-12-22T17:42:15Z",
    "pdf_url": "http://arxiv.org/pdf/1712.09444v2",
    "categories": [
      "cs.CL",
      "cs.AI"
    ]
  },
  {
    "arxiv_id": "1804.05374v2",
    "title": "Twin Regularization for online speech recognition",
    "authors": [
      "Mirco Ravanelli",
      "Dmitriy Serdyuk",
      "Yoshua Bengio"
    ],
    "abstract": "Online speech recognition is crucial for developing natural human-machine\ninterfaces. This modality, however, is significantly more challenging than\noff-line ASR, since real-time/low-latency constraints inevitably hinder the use\nof future information, that is known to be very helpful to perform robust\npredictions. A popular solution to mitigate this issue consists of feeding\nneural acoustic models with context windows that gather some future frames.\nThis introduces a latency which depends on the number of employed look-ahead\nfeatures. This paper explores a different approach, based on estimating the\nfuture rather than waiting for it. Our technique encourages the hidden\nrepresentations of a unidirectional recurrent network to embed some useful\ninformation about the future. Inspired by a recently proposed technique called\nTwin Networks, we add a regularization term that forces forward hidden states\nto be as close as possible to cotemporal backward ones, computed by a \"twin\"\nneural network running backwards in time. The experiments, conducted on a\nnumber of datasets, recurrent architectures, input features, and acoustic\nconditions, have shown the effectiveness of this approach. One important\nadvantage is that our method does not introduce any additional computation at\ntest time if compared to standard unidirectional recurrent networks.",
    "published": "2018-04-15T15:52:16Z",
    "pdf_url": "http://arxiv.org/pdf/1804.05374v2",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "1811.07453v2",
    "title": "The PyTorch-Kaldi Speech Recognition Toolkit",
    "authors": [
      "Mirco Ravanelli",
      "Titouan Parcollet",
      "Yoshua Bengio"
    ],
    "abstract": "The availability of open-source software is playing a remarkable role in the\npopularization of speech recognition and deep learning. Kaldi, for instance, is\nnowadays an established framework used to develop state-of-the-art speech\nrecognizers. PyTorch is used to build neural networks with the Python language\nand has recently spawn tremendous interest within the machine learning\ncommunity thanks to its simplicity and flexibility.\n  The PyTorch-Kaldi project aims to bridge the gap between these popular\ntoolkits, trying to inherit the efficiency of Kaldi and the flexibility of\nPyTorch. PyTorch-Kaldi is not only a simple interface between these software,\nbut it embeds several useful features for developing modern speech recognizers.\nFor instance, the code is specifically designed to naturally plug-in\nuser-defined acoustic models. As an alternative, users can exploit several\npre-implemented neural networks that can be customized using intuitive\nconfiguration files. PyTorch-Kaldi supports multiple feature and label streams\nas well as combinations of neural networks, enabling the use of complex neural\narchitectures. The toolkit is publicly-released along with a rich documentation\nand is designed to properly work locally or on HPC clusters.\n  Experiments, that are conducted on several datasets and tasks, show that\nPyTorch-Kaldi can effectively be used to develop modern state-of-the-art speech\nrecognizers.",
    "published": "2018-11-19T01:57:05Z",
    "pdf_url": "http://arxiv.org/pdf/1811.07453v2",
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.LG",
      "cs.NE"
    ]
  },
  {
    "arxiv_id": "1905.05605v1",
    "title": "Encrypted Speech Recognition using Deep Polynomial Networks",
    "authors": [
      "Shi-Xiong Zhang",
      "Yifan Gong",
      "Dong Yu"
    ],
    "abstract": "The cloud-based speech recognition/API provides developers or enterprises an\neasy way to create speech-enabled features in their applications. However,\nsending audios about personal or company internal information to the cloud,\nraises concerns about the privacy and security issues. The recognition results\ngenerated in cloud may also reveal some sensitive information. This paper\nproposes a deep polynomial network (DPN) that can be applied to the encrypted\nspeech as an acoustic model. It allows clients to send their data in an\nencrypted form to the cloud to ensure that their data remains confidential, at\nmean while the DPN can still make frame-level predictions over the encrypted\nspeech and return them in encrypted form. One good property of the DPN is that\nit can be trained on unencrypted speech features in the traditional way. To\nkeep the cloud away from the raw audio and recognition results, a cloud-local\njoint decoding framework is also proposed. We demonstrate the effectiveness of\nmodel and framework on the Switchboard and Cortana voice assistant tasks with\nsmall performance degradation and latency increased comparing with the\ntraditional cloud-based DNNs.",
    "published": "2019-05-11T00:14:09Z",
    "pdf_url": "http://arxiv.org/pdf/1905.05605v1",
    "categories": [
      "cs.CR",
      "cs.CL",
      "cs.SD",
      "eess.AS",
      "stat.ML"
    ]
  },
  {
    "arxiv_id": "1908.01060v1",
    "title": "Multilingual Speech Recognition with Corpus Relatedness Sampling",
    "authors": [
      "Xinjian Li",
      "Siddharth Dalmia",
      "Alan W. Black",
      "Florian Metze"
    ],
    "abstract": "Multilingual acoustic models have been successfully applied to low-resource\nspeech recognition. Most existing works have combined many small corpora\ntogether and pretrained a multilingual model by sampling from each corpus\nuniformly. The model is eventually fine-tuned on each target corpus. This\napproach, however, fails to exploit the relatedness and similarity among\ncorpora in the training set. For example, the target corpus might benefit more\nfrom a corpus in the same domain or a corpus from a close language. In this\nwork, we propose a simple but useful sampling strategy to take advantage of\nthis relatedness. We first compute the corpus-level embeddings and estimate the\nsimilarity between each corpus. Next, we start training the multilingual model\nwith uniform-sampling from each corpus at first, then we gradually increase the\nprobability to sample from related corpora based on its similarity with the\ntarget corpus. Finally, the model would be fine-tuned automatically on the\ntarget corpus. Our sampling strategy outperforms the baseline multilingual\nmodel on 16 low-resource tasks. Additionally, we demonstrate that our corpus\nembeddings capture the language and domain information of each corpus.",
    "published": "2019-08-02T21:08:13Z",
    "pdf_url": "http://arxiv.org/pdf/1908.01060v1",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2004.04438v1",
    "title": "Improving Readability for Automatic Speech Recognition Transcription",
    "authors": [
      "Junwei Liao",
      "Sefik Emre Eskimez",
      "Liyang Lu",
      "Yu Shi",
      "Ming Gong",
      "Linjun Shou",
      "Hong Qu",
      "Michael Zeng"
    ],
    "abstract": "Modern Automatic Speech Recognition (ASR) systems can achieve high\nperformance in terms of recognition accuracy. However, a perfectly accurate\ntranscript still can be challenging to read due to grammatical errors,\ndisfluency, and other errata common in spoken communication. Many downstream\ntasks and human readers rely on the output of the ASR system; therefore, errors\nintroduced by the speaker and ASR system alike will be propagated to the next\ntask in the pipeline. In this work, we propose a novel NLP task called ASR\npost-processing for readability (APR) that aims to transform the noisy ASR\noutput into a readable text for humans and downstream tasks while maintaining\nthe semantic meaning of the speaker. In addition, we describe a method to\naddress the lack of task-specific data by synthesizing examples for the APR\ntask using the datasets collected for Grammatical Error Correction (GEC)\nfollowed by text-to-speech (TTS) and ASR. Furthermore, we propose metrics\nborrowed from similar tasks to evaluate performance on the APR task. We compare\nfine-tuned models based on several open-sourced and adapted pre-trained models\nwith the traditional pipeline method. Our results suggest that finetuned models\nimprove the performance on the APR task significantly, hinting at the potential\nbenefits of using APR systems. We hope that the read, understand, and rewrite\napproach of our work can serve as a basis that many NLP tasks and human readers\ncan benefit from.",
    "published": "2020-04-09T09:26:42Z",
    "pdf_url": "http://arxiv.org/pdf/2004.04438v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2009.09615v2",
    "title": "End-to-End Bengali Speech Recognition",
    "authors": [
      "Sayan Mandal",
      "Sarthak Yadav",
      "Atul Rai"
    ],
    "abstract": "Bengali is a prominent language of the Indian subcontinent. However, while\nmany state-of-the-art acoustic models exist for prominent languages spoken in\nthe region, research and resources for Bengali are few and far between. In this\nwork, we apply CTC based CNN-RNN networks, a prominent deep learning based\nend-to-end automatic speech recognition technique, to the Bengali ASR task. We\nalso propose and evaluate the applicability and efficacy of small 7x3 and 3x3\nconvolution kernels which are prominently used in the computer vision domain\nprimarily because of their FLOPs and parameter efficient nature. We propose two\nCNN blocks, 2-layer Block A and 4-layer Block B, with the first layer\ncomprising of 7x3 kernel and the subsequent layers comprising solely of 3x3\nkernels. Using the publicly available Large Bengali ASR Training data set, we\nbenchmark and evaluate the performance of seven deep neural network\nconfigurations of varying complexities and depth on the Bengali ASR task. Our\nbest model, with Block B, has a WER of 13.67, having an absolute reduction of\n1.39% over comparable model with larger convolution kernels of size 41x11 and\n21x11.",
    "published": "2020-09-21T05:08:07Z",
    "pdf_url": "http://arxiv.org/pdf/2009.09615v2",
    "categories": [
      "eess.AS",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "2108.00899v1",
    "title": "Adversarial Data Augmentation for Disordered Speech Recognition",
    "authors": [
      "Zengrui Jin",
      "Mengzhe Geng",
      "Xurong Xie",
      "Jianwei Yu",
      "Shansong Liu",
      "Xunying Liu",
      "Helen Meng"
    ],
    "abstract": "Automatic recognition of disordered speech remains a highly challenging task\nto date. The underlying neuro-motor conditions, often compounded with\nco-occurring physical disabilities, lead to the difficulty in collecting large\nquantities of impaired speech required for ASR system development. To this end,\ndata augmentation techniques play a vital role in current disordered speech\nrecognition systems. In contrast to existing data augmentation techniques only\nmodifying the speaking rate or overall shape of spectral contour, fine-grained\nspectro-temporal differences between disordered and normal speech are modelled\nusing deep convolutional generative adversarial networks (DCGAN) during data\naugmentation to modify normal speech spectra into those closer to disordered\nspeech. Experiments conducted on the UASpeech corpus suggest the proposed\nadversarial data augmentation approach consistently outperformed the baseline\naugmentation methods using tempo or speed perturbation on a state-of-the-art\nhybrid DNN system. An overall word error rate (WER) reduction up to 3.05\\%\n(9.7\\% relative) was obtained over the baseline system using no data\naugmentation. The final learning hidden unit contribution (LHUC) speaker\nadapted system using the best adversarial augmentation approach gives an\noverall WER of 25.89% on the UASpeech test set of 16 dysarthric speakers.",
    "published": "2021-08-02T13:44:36Z",
    "pdf_url": "http://arxiv.org/pdf/2108.00899v1",
    "categories": [
      "eess.AS",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "2005.08497v1",
    "title": "Attention-based Transducer for Online Speech Recognition",
    "authors": [
      "Bin Wang",
      "Yan Yin",
      "Hui Lin"
    ],
    "abstract": "Recent studies reveal the potential of recurrent neural network transducer\n(RNN-T) for end-to-end (E2E) speech recognition. Among some most popular E2E\nsystems including RNN-T, Attention Encoder-Decoder (AED), and Connectionist\nTemporal Classification (CTC), RNN-T has some clear advantages given that it\nsupports streaming recognition and does not have frame-independency assumption.\nAlthough significant progresses have been made for RNN-T research, it is still\nfacing performance challenges in terms of training speed and accuracy. We\npropose attention-based transducer with modification over RNN-T in two aspects.\nFirst, we introduce chunk-wise attention in the joint network. Second,\nself-attention is introduced in the encoder. Our proposed model outperforms\nRNN-T for both training speed and accuracy. For training, we achieves over 1.7x\nspeedup. With 500 hours LAIX non-native English training data, attention-based\ntransducer yields ~10.6% WER reduction over baseline RNN-T. Trained with full\nset of over 10K hours data, our final system achieves ~5.5% WER reduction over\nthat trained with the best Kaldi TDNN-f recipe. After 8-bit weight quantization\nwithout WER degradation, RTF and latency drop to 0.34~0.36 and 268~409\nmilliseconds respectively on a single CPU core of a production server.",
    "published": "2020-05-18T07:26:33Z",
    "pdf_url": "http://arxiv.org/pdf/2005.08497v1",
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "2104.04627v1",
    "title": "Accented Speech Recognition Inspired by Human Perception",
    "authors": [
      "Xiangyun Chu",
      "Elizabeth Combs",
      "Amber Wang",
      "Michael Picheny"
    ],
    "abstract": "While improvements have been made in automatic speech recognition performance\nover the last several years, machines continue to have significantly lower\nperformance on accented speech than humans. In addition, the most significant\nimprovements on accented speech primarily arise by overwhelming the problem\nwith hundreds or even thousands of hours of data. Humans typically require much\nless data to adapt to a new accent. This paper explores methods that are\ninspired by human perception to evaluate possible performance improvements for\nrecognition of accented speech, with a specific focus on recognizing speech\nwith a novel accent relative to that of the training data. Our experiments are\nrun on small, accessible datasets that are available to the research community.\nWe explore four methodologies: pre-exposure to multiple accents, grapheme and\nphoneme-based pronunciations, dropout (to improve generalization to a novel\naccent), and the identification of the layers in the neural network that can\nspecifically be associated with accent modeling. Our results indicate that\nmethods based on human perception are promising in reducing WER and\nunderstanding how accented speech is modeled in neural networks for novel\naccents.",
    "published": "2021-04-09T22:35:09Z",
    "pdf_url": "http://arxiv.org/pdf/2104.04627v1",
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.LG",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "2202.01094v3",
    "title": "RescoreBERT: Discriminative Speech Recognition Rescoring with BERT",
    "authors": [
      "Liyan Xu",
      "Yile Gu",
      "Jari Kolehmainen",
      "Haidar Khan",
      "Ankur Gandhe",
      "Ariya Rastrow",
      "Andreas Stolcke",
      "Ivan Bulyko"
    ],
    "abstract": "Second-pass rescoring is an important component in automatic speech\nrecognition (ASR) systems that is used to improve the outputs from a first-pass\ndecoder by implementing a lattice rescoring or $n$-best re-ranking. While\npretraining with a masked language model (MLM) objective has received great\nsuccess in various natural language understanding (NLU) tasks, it has not\ngained traction as a rescoring model for ASR. Specifically, training a\nbidirectional model like BERT on a discriminative objective such as minimum WER\n(MWER) has not been explored. Here we show how to train a BERT-based rescoring\nmodel with MWER loss, to incorporate the improvements of a discriminative loss\ninto fine-tuning of deep bidirectional pretrained models for ASR. Specifically,\nwe propose a fusion strategy that incorporates the MLM into the discriminative\ntraining process to effectively distill knowledge from a pretrained model. We\nfurther propose an alternative discriminative loss. This approach, which we\ncall RescoreBERT, reduces WER by 6.6%/3.4% relative on the LibriSpeech\nclean/other test sets over a BERT baseline without discriminative objective. We\nalso evaluate our method on an internal dataset from a conversational agent and\nfind that it reduces both latency and WER (by 3 to 8% relative) over an LSTM\nrescoring model.",
    "published": "2022-02-02T15:45:26Z",
    "pdf_url": "http://arxiv.org/pdf/2202.01094v3",
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.LG",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "1802.06424v2",
    "title": "End-to-end Audiovisual Speech Recognition",
    "authors": [
      "Stavros Petridis",
      "Themos Stafylakis",
      "Pingchuan Ma",
      "Feipeng Cai",
      "Georgios Tzimiropoulos",
      "Maja Pantic"
    ],
    "abstract": "Several end-to-end deep learning approaches have been recently presented\nwhich extract either audio or visual features from the input images or audio\nsignals and perform speech recognition. However, research on end-to-end\naudiovisual models is very limited. In this work, we present an end-to-end\naudiovisual model based on residual networks and Bidirectional Gated Recurrent\nUnits (BGRUs). To the best of our knowledge, this is the first audiovisual\nfusion model which simultaneously learns to extract features directly from the\nimage pixels and audio waveforms and performs within-context word recognition\non a large publicly available dataset (LRW). The model consists of two streams,\none for each modality, which extract features directly from mouth regions and\nraw waveforms. The temporal dynamics in each stream/modality are modeled by a\n2-layer BGRU and the fusion of multiple streams/modalities takes place via\nanother 2-layer BGRU. A slight improvement in the classification rate over an\nend-to-end audio-only and MFCC-based model is reported in clean audio\nconditions and low levels of noise. In presence of high levels of noise, the\nend-to-end audiovisual model significantly outperforms both audio-only models.",
    "published": "2018-02-18T19:07:31Z",
    "pdf_url": "http://arxiv.org/pdf/1802.06424v2",
    "categories": [
      "cs.CV"
    ]
  },
  {
    "arxiv_id": "1807.10311v1",
    "title": "Open Source Automatic Speech Recognition for German",
    "authors": [
      "Benjamin Milde",
      "Arne Köhn"
    ],
    "abstract": "High quality Automatic Speech Recognition (ASR) is a prerequisite for\nspeech-based applications and research. While state-of-the-art ASR software is\nfreely available, the language dependent acoustic models are lacking for\nlanguages other than English, due to the limited amount of freely available\ntraining data. We train acoustic models for German with Kaldi on two datasets,\nwhich are both distributed under a Creative Commons license. The resulting\nmodel is freely redistributable, lowering the cost of entry for German ASR. The\nmodels are trained on a total of 412 hours of German read speech data and we\nachieve a relative word error reduction of 26% by adding data from the Spoken\nWikipedia Corpus to the previously best freely available German acoustic model\nrecipe and dataset. Our best model achieves a word error rate of 14.38 on the\nTuda-De test set. Due to the large amount of speakers and the diversity of\ntopics included in the training data, our model is robust against speaker\nvariation and topic shift.",
    "published": "2018-07-26T18:31:08Z",
    "pdf_url": "http://arxiv.org/pdf/1807.10311v1",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "2209.00261v1",
    "title": "Attention Enhanced Citrinet for Speech Recognition",
    "authors": [
      "Xianchao Wu"
    ],
    "abstract": "Citrinet is an end-to-end convolutional Connectionist Temporal Classification\n(CTC) based automatic speech recognition (ASR) model. To capture local and\nglobal contextual information, 1D time-channel separable convolutions combined\nwith sub-word encoding and squeeze-and-excitation (SE) are used in Citrinet,\nmaking the whole architecture to be as deep as including 23 blocks with 235\nconvolution layers and 46 linear layers. This pure convolutional and deep\narchitecture makes Critrinet relatively slow at convergence. In this paper, we\npropose to introduce multi-head attentions together with feed-forward networks\nin the convolution module in Citrinet blocks while keeping the SE module and\nresidual module unchanged. For speeding up, we remove 8 convolution layers in\neach attention-enhanced Citrinet block and reduce 23 blocks to 13. Experiments\non the Japanese CSJ-500h and Magic-1600h dataset show that the\nattention-enhanced Citrinet with less layers and blocks and converges faster\nwith lower character error rates than (1) Citrinet with 80\\% training time and\n(2) Conformer with 40\\% training time and 29.8\\% model size.",
    "published": "2022-09-01T06:59:50Z",
    "pdf_url": "http://arxiv.org/pdf/2209.00261v1",
    "categories": [
      "cs.CL",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2305.02081v1",
    "title": "Considerations for Ethical Speech Recognition Datasets",
    "authors": [
      "Orestis Papakyriakopoulos",
      "Alice Xiang"
    ],
    "abstract": "Speech AI Technologies are largely trained on publicly available datasets or\nby the massive web-crawling of speech. In both cases, data acquisition focuses\non minimizing collection effort, without necessarily taking the data subjects'\nprotection or user needs into consideration. This results to models that are\nnot robust when used on users who deviate from the dominant demographics in the\ntraining set, discriminating individuals having different dialects, accents,\nspeaking styles, and disfluencies. In this talk, we use automatic speech\nrecognition as a case study and examine the properties that ethical speech\ndatasets should possess towards responsible AI applications. We showcase\ndiversity issues, inclusion practices, and necessary considerations that can\nimprove trained models, while facilitating model explainability and protecting\nusers and data subjects. We argue for the legal & privacy protection of data\nsubjects, targeted data sampling corresponding to user demographics & needs,\nappropriate meta data that ensure explainability & accountability in cases of\nmodel failure, and the sociotechnical \\& situated model design. We hope this\ntalk can inspire researchers \\& practitioners to design and use more\nhuman-centric datasets in speech technologies and other domains, in ways that\nempower and respect users, while improving machine learning models' robustness\nand utility.",
    "published": "2023-05-03T12:38:14Z",
    "pdf_url": "http://arxiv.org/pdf/2305.02081v1",
    "categories": [
      "cs.CY",
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "1801.00059v2",
    "title": "The CAPIO 2017 Conversational Speech Recognition System",
    "authors": [
      "Kyu J. Han",
      "Akshay Chandrashekaran",
      "Jungsuk Kim",
      "Ian Lane"
    ],
    "abstract": "In this paper we show how we have achieved the state-of-the-art performance\non the industry-standard NIST 2000 Hub5 English evaluation set. We explore\ndensely connected LSTMs, inspired by the densely connected convolutional\nnetworks recently introduced for image classification tasks. We also propose an\nacoustic model adaptation scheme that simply averages the parameters of a seed\nneural network acoustic model and its adapted version. This method was applied\nwith the CallHome training corpus and improved individual system performances\nby on average 6.1% (relative) against the CallHome portion of the evaluation\nset with no performance loss on the Switchboard portion. With RNN-LM rescoring\nand lattice combination on the 5 systems trained across three different phone\nsets, our 2017 speech recognition system has obtained 5.0% and 9.1% on\nSwitchboard and CallHome, respectively, both of which are the best word error\nrates reported thus far. According to IBM in their latest work to compare human\nand machine transcriptions, our reported Switchboard word error rate can be\nconsidered to surpass the human parity (5.1%) of transcribing conversational\ntelephone speech.",
    "published": "2017-12-29T23:31:05Z",
    "pdf_url": "http://arxiv.org/pdf/1801.00059v2",
    "categories": [
      "cs.CL"
    ]
  },
  {
    "arxiv_id": "1902.02383v1",
    "title": "End-to-end Anchored Speech Recognition",
    "authors": [
      "Yiming Wang",
      "Xing Fan",
      "I-Fan Chen",
      "Yuzong Liu",
      "Tongfei Chen",
      "Björn Hoffmeister"
    ],
    "abstract": "Voice-controlled house-hold devices, like Amazon Echo or Google Home, face\nthe problem of performing speech recognition of device-directed speech in the\npresence of interfering background speech, i.e., background noise and\ninterfering speech from another person or media device in proximity need to be\nignored. We propose two end-to-end models to tackle this problem with\ninformation extracted from the \"anchored segment\". The anchored segment refers\nto the wake-up word part of an audio stream, which contains valuable speaker\ninformation that can be used to suppress interfering speech and background\nnoise. The first method is called \"Multi-source Attention\" where the attention\nmechanism takes both the speaker information and decoder state into\nconsideration. The second method directly learns a frame-level mask on top of\nthe encoder output. We also explore a multi-task learning setup where we use\nthe ground truth of the mask to guide the learner. Given that audio data with\ninterfering speech is rare in our training data set, we also propose a way to\nsynthesize \"noisy\" speech from \"clean\" speech to mitigate the mismatch between\ntraining and test data. Our proposed methods show up to 15% relative reduction\nin WER for Amazon Alexa live data with interfering background speech without\nsignificantly degrading on clean speech.",
    "published": "2019-02-06T19:50:23Z",
    "pdf_url": "http://arxiv.org/pdf/1902.02383v1",
    "categories": [
      "cs.CL",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "1906.08041v2",
    "title": "Multi-Stream End-to-End Speech Recognition",
    "authors": [
      "Ruizhi Li",
      "Xiaofei Wang",
      "Sri Harish Mallidi",
      "Shinji Watanabe",
      "Takaaki Hori",
      "Hynek Hermansky"
    ],
    "abstract": "Attention-based methods and Connectionist Temporal Classification (CTC)\nnetwork have been promising research directions for end-to-end (E2E) Automatic\nSpeech Recognition (ASR). The joint CTC/Attention model has achieved great\nsuccess by utilizing both architectures during multi-task training and joint\ndecoding. In this work, we present a multi-stream framework based on joint\nCTC/Attention E2E ASR with parallel streams represented by separate encoders\naiming to capture diverse information. On top of the regular attention\nnetworks, the Hierarchical Attention Network (HAN) is introduced to steer the\ndecoder toward the most informative encoders. A separate CTC network is\nassigned to each stream to force monotonic alignments. Two representative\nframework have been proposed and discussed, which are Multi-Encoder\nMulti-Resolution (MEM-Res) framework and Multi-Encoder Multi-Array (MEM-Array)\nframework, respectively. In MEM-Res framework, two heterogeneous encoders with\ndifferent architectures, temporal resolutions and separate CTC networks work in\nparallel to extract complimentary information from same acoustics. Experiments\nare conducted on Wall Street Journal (WSJ) and CHiME-4, resulting in relative\nWord Error Rate (WER) reduction of 18.0-32.1% and the best WER of 3.6% in the\nWSJ eval92 test set. The MEM-Array framework aims at improving the far-field\nASR robustness using multiple microphone arrays which are activated by separate\nencoders. Compared with the best single-array results, the proposed framework\nhas achieved relative WER reduction of 3.7% and 9.7% in AMI and DIRHA\nmulti-array corpora, respectively, which also outperforms conventional fusion\nstrategies.",
    "published": "2019-06-17T23:00:15Z",
    "pdf_url": "http://arxiv.org/pdf/1906.08041v2",
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "2008.04481v1",
    "title": "Transformer with Bidirectional Decoder for Speech Recognition",
    "authors": [
      "Xi Chen",
      "Songyang Zhang",
      "Dandan Song",
      "Peng Ouyang",
      "Shouyi Yin"
    ],
    "abstract": "Attention-based models have made tremendous progress on end-to-end automatic\nspeech recognition(ASR) recently. However, the conventional transformer-based\napproaches usually generate the sequence results token by token from left to\nright, leaving the right-to-left contexts unexploited. In this work, we\nintroduce a bidirectional speech transformer to utilize the different\ndirectional contexts simultaneously. Specifically, the outputs of our proposed\ntransformer include a left-to-right target, and a right-to-left target. In\ninference stage, we use the introduced bidirectional beam search method, which\ncan not only generate left-to-right candidates but also generate right-to-left\ncandidates, and determine the best hypothesis by the score.\n  To demonstrate our proposed speech transformer with a bidirectional\ndecoder(STBD), we conduct extensive experiments on the AISHELL-1 dataset. The\nresults of experiments show that STBD achieves a 3.6\\% relative CER\nreduction(CERR) over the unidirectional speech transformer baseline. Besides,\nthe strongest model in this paper called STBD-Big can achieve 6.64\\% CER on the\ntest set, without language model rescoring and any extra data augmentation\nstrategies.",
    "published": "2020-08-11T02:12:42Z",
    "pdf_url": "http://arxiv.org/pdf/2008.04481v1",
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.LG",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "2008.12048v1",
    "title": "End-to-end Music-mixed Speech Recognition",
    "authors": [
      "Jeongwoo Woo",
      "Masato Mimura",
      "Kazuyoshi Yoshii",
      "Tatsuya Kawahara"
    ],
    "abstract": "Automatic speech recognition (ASR) in multimedia content is one of the\npromising applications, but speech data in this kind of content are frequently\nmixed with background music, which is harmful for the performance of ASR. In\nthis study, we propose a method for improving ASR with background music based\non time-domain source separation. We utilize Conv-TasNet as a separation\nnetwork, which has achieved state-of-the-art performance for multi-speaker\nsource separation, to extract the speech signal from a speech-music mixture in\nthe waveform domain. We also propose joint fine-tuning of a pre-trained\nConv-TasNet front-end with an attention-based ASR back-end using both\nseparation and ASR objectives. We evaluated our method through ASR experiments\nusing speech data mixed with background music from a wide variety of Japanese\nanimations. We show that time-domain speech-music separation drastically\nimproves ASR performance of the back-end model trained with mixture data, and\nthe joint optimization yielded a further significant WER reduction. The\ntime-domain separation method outperformed a frequency-domain separation\nmethod, which reuses the phase information of the input mixture signal, both in\nsimple cascading and joint training settings. We also demonstrate that our\nmethod works robustly for music interference from classical, jazz and popular\ngenres.",
    "published": "2020-08-27T10:51:26Z",
    "pdf_url": "http://arxiv.org/pdf/2008.12048v1",
    "categories": [
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2106.07803v1",
    "title": "SynthASR: Unlocking Synthetic Data for Speech Recognition",
    "authors": [
      "Amin Fazel",
      "Wei Yang",
      "Yulan Liu",
      "Roberto Barra-Chicote",
      "Yixiong Meng",
      "Roland Maas",
      "Jasha Droppo"
    ],
    "abstract": "End-to-end (E2E) automatic speech recognition (ASR) models have recently\ndemonstrated superior performance over the traditional hybrid ASR models.\nTraining an E2E ASR model requires a large amount of data which is not only\nexpensive but may also raise dependency on production data. At the same time,\nsynthetic speech generated by the state-of-the-art text-to-speech (TTS) engines\nhas advanced to near-human naturalness. In this work, we propose to utilize\nsynthetic speech for ASR training (SynthASR) in applications where data is\nsparse or hard to get for ASR model training. In addition, we apply continual\nlearning with a novel multi-stage training strategy to address catastrophic\nforgetting, achieved by a mix of weighted multi-style training, data\naugmentation, encoder freezing, and parameter regularization. In our\nexperiments conducted on in-house datasets for a new application of recognizing\nmedication names, training ASR RNN-T models with synthetic audio via the\nproposed multi-stage training improved the recognition performance on new\napplication by more than 65% relative, without degradation on existing general\napplications. Our observations show that SynthASR holds great promise in\ntraining the state-of-the-art large-scale E2E ASR models for new applications\nwhile reducing the costs and dependency on production data.",
    "published": "2021-06-14T23:26:44Z",
    "pdf_url": "http://arxiv.org/pdf/2106.07803v1",
    "categories": [
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2110.03509v5",
    "title": "Analyzing the Robustness of Unsupervised Speech Recognition",
    "authors": [
      "Guan-Ting Lin",
      "Chan-Jan Hsu",
      "Da-Rong Liu",
      "Hung-Yi Lee",
      "Yu Tsao"
    ],
    "abstract": "Unsupervised speech recognition (unsupervised ASR) aims to learn the ASR\nsystem with non-parallel speech and text corpus only. Wav2vec-U has shown\npromising results in unsupervised ASR by self-supervised speech representations\ncoupled with Generative Adversarial Network (GAN) training, but the robustness\nof the unsupervised ASR framework is unknown. In this work, we further analyze\nthe training robustness of unsupervised ASR on the domain mismatch scenarios in\nwhich the domains of unpaired speech and text are different. Three domain\nmismatch scenarios include: (1) using speech and text from different datasets,\n(2) utilizing noisy/spontaneous speech, and (3) adjusting the amount of speech\nand text data. We also quantify the degree of the domain mismatch by\ncalculating the JS-divergence of phoneme n-gram between the transcription of\nspeech and text. This metric correlates with the performance highly.\nExperimental results show that domain mismatch leads to inferior performance,\nbut a self-supervised model pre-trained on the targeted speech domain can\nextract better representation to alleviate the performance drop.",
    "published": "2021-10-07T14:46:10Z",
    "pdf_url": "http://arxiv.org/pdf/2110.03509v5",
    "categories": [
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2111.03250v1",
    "title": "Context-Aware Transformer Transducer for Speech Recognition",
    "authors": [
      "Feng-Ju Chang",
      "Jing Liu",
      "Martin Radfar",
      "Athanasios Mouchtaris",
      "Maurizio Omologo",
      "Ariya Rastrow",
      "Siegfried Kunzmann"
    ],
    "abstract": "End-to-end (E2E) automatic speech recognition (ASR) systems often have\ndifficulty recognizing uncommon words, that appear infrequently in the training\ndata. One promising method, to improve the recognition accuracy on such rare\nwords, is to latch onto personalized/contextual information at inference. In\nthis work, we present a novel context-aware transformer transducer (CATT)\nnetwork that improves the state-of-the-art transformer-based ASR system by\ntaking advantage of such contextual signals. Specifically, we propose a\nmulti-head attention-based context-biasing network, which is jointly trained\nwith the rest of the ASR sub-networks. We explore different techniques to\nencode contextual data and to create the final attention context vectors. We\nalso leverage both BLSTM and pretrained BERT based models to encode contextual\ndata and guide the network training. Using an in-house far-field dataset, we\nshow that CATT, using a BERT based context encoder, improves the word error\nrate of the baseline transformer transducer and outperforms an existing deep\ncontextual model by 24.2% and 19.4% respectively.",
    "published": "2021-11-05T04:14:35Z",
    "pdf_url": "http://arxiv.org/pdf/2111.03250v1",
    "categories": [
      "cs.CL",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2211.01458v2",
    "title": "Towards Zero-Shot Code-Switched Speech Recognition",
    "authors": [
      "Brian Yan",
      "Matthew Wiesner",
      "Ondrej Klejch",
      "Preethi Jyothi",
      "Shinji Watanabe"
    ],
    "abstract": "In this work, we seek to build effective code-switched (CS) automatic speech\nrecognition systems (ASR) under the zero-shot setting where no transcribed CS\nspeech data is available for training. Previously proposed frameworks which\nconditionally factorize the bilingual task into its constituent monolingual\nparts are a promising starting point for leveraging monolingual data\nefficiently. However, these methods require the monolingual modules to perform\nlanguage segmentation. That is, each monolingual module has to simultaneously\ndetect CS points and transcribe speech segments of one language while ignoring\nthose of other languages -- not a trivial task. We propose to simplify each\nmonolingual module by allowing them to transcribe all speech segments\nindiscriminately with a monolingual script (i.e. transliteration). This simple\nmodification passes the responsibility of CS point detection to subsequent\nbilingual modules which determine the final output by considering multiple\nmonolingual transliterations along with external language model information. We\napply this transliteration-based approach in an end-to-end differentiable\nneural network and demonstrate its efficacy for zero-shot CS ASR on\nMandarin-English SEAME test sets.",
    "published": "2022-11-02T19:52:54Z",
    "pdf_url": "http://arxiv.org/pdf/2211.01458v2",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2303.03329v1",
    "title": "End-to-End Speech Recognition: A Survey",
    "authors": [
      "Rohit Prabhavalkar",
      "Takaaki Hori",
      "Tara N. Sainath",
      "Ralf Schlüter",
      "Shinji Watanabe"
    ],
    "abstract": "In the last decade of automatic speech recognition (ASR) research, the\nintroduction of deep learning brought considerable reductions in word error\nrate of more than 50% relative, compared to modeling without deep learning. In\nthe wake of this transition, a number of all-neural ASR architectures were\nintroduced. These so-called end-to-end (E2E) models provide highly integrated,\ncompletely neural ASR models, which rely strongly on general machine learning\nknowledge, learn more consistently from data, while depending less on ASR\ndomain-specific experience. The success and enthusiastic adoption of deep\nlearning accompanied by more generic model architectures lead to E2E models now\nbecoming the prominent ASR approach. The goal of this survey is to provide a\ntaxonomy of E2E ASR models and corresponding improvements, and to discuss their\nproperties and their relation to the classical hidden Markov model (HMM) based\nASR architecture. All relevant aspects of E2E ASR are covered in this work:\nmodeling, training, decoding, and external language model integration,\naccompanied by discussions of performance and deployment opportunities, as well\nas an outlook into potential future developments.",
    "published": "2023-03-03T01:46:41Z",
    "pdf_url": "http://arxiv.org/pdf/2303.03329v1",
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "2308.11589v1",
    "title": "Indonesian Automatic Speech Recognition with XLSR-53",
    "authors": [
      "Panji Arisaputra",
      "Amalia Zahra"
    ],
    "abstract": "This study focuses on the development of Indonesian Automatic Speech\nRecognition (ASR) using the XLSR-53 pre-trained model, the XLSR stands for\ncross-lingual speech representations. The use of this XLSR-53 pre-trained model\nis to significantly reduce the amount of training data in non-English languages\nrequired to achieve a competitive Word Error Rate (WER). The total amount of\ndata used in this study is 24 hours, 18 minutes, and 1 second: (1) TITML-IDN 14\nhours and 31 minutes; (2) Magic Data 3 hours and 33 minutes; and (3) Common\nVoice 6 hours, 14 minutes, and 1 second. With a WER of 20%, the model built in\nthis study can compete with similar models using the Common Voice dataset split\ntest. WER can be decreased by around 8% using a language model, resulted in WER\nfrom 20% to 12%. Thus, the results of this study have succeeded in perfecting\nprevious research in contributing to the creation of a better Indonesian ASR\nwith a smaller amount of data.",
    "published": "2023-08-20T09:59:40Z",
    "pdf_url": "http://arxiv.org/pdf/2308.11589v1",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2310.15970v3",
    "title": "Accented Speech Recognition With Accent-specific Codebooks",
    "authors": [
      "Darshan Prabhu",
      "Preethi Jyothi",
      "Sriram Ganapathy",
      "Vinit Unni"
    ],
    "abstract": "Speech accents pose a significant challenge to state-of-the-art automatic\nspeech recognition (ASR) systems. Degradation in performance across\nunderrepresented accents is a severe deterrent to the inclusive adoption of\nASR. In this work, we propose a novel accent adaptation approach for end-to-end\nASR systems using cross-attention with a trainable set of codebooks. These\nlearnable codebooks capture accent-specific information and are integrated\nwithin the ASR encoder layers. The model is trained on accented English speech,\nwhile the test data also contained accents which were not seen during training.\nOn the Mozilla Common Voice multi-accented dataset, we show that our proposed\napproach yields significant performance gains not only on the seen English\naccents (up to $37\\%$ relative improvement in word error rate) but also on the\nunseen accents (up to $5\\%$ relative improvement in WER). Further, we\nillustrate benefits for a zero-shot transfer setup on the L2Artic dataset. We\nalso compare the performance with other approaches based on accent adversarial\ntraining.",
    "published": "2023-10-24T16:10:58Z",
    "pdf_url": "http://arxiv.org/pdf/2310.15970v3",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ]
  },
  {
    "arxiv_id": "2312.14020v1",
    "title": "BANSpEmo: A Bangla Emotional Speech Recognition Dataset",
    "authors": [
      "Md Gulzar Hussain",
      "Mahmuda Rahman",
      "Babe Sultana",
      "Ye Shiren"
    ],
    "abstract": "In the field of audio and speech analysis, the ability to identify emotions\nfrom acoustic signals is essential. Human-computer interaction (HCI) and\nbehavioural analysis are only a few of the many areas where the capacity to\ndistinguish emotions from speech signals has an extensive range of\napplications. Here, we are introducing BanSpEmo, a corpus of emotional speech\nthat only consists of audio recordings and has been created specifically for\nthe Bangla language. This corpus contains 792 audio recordings over a duration\nof more than 1 hour and 23 minutes. 22 native speakers took part in the\nrecording of two sets of sentences that represent the six desired emotions. The\ndata set consists of 12 Bangla sentences which are uttered in 6 emotions as\nDisgust, Happy, Sad, Surprised, Anger, and Fear. This corpus is not also gender\nbalanced. Ten individuals who either have experience in related field or have\nacting experience took part in the assessment of this corpus. It has a balanced\nnumber of audio recordings in each emotion class. BanSpEmo can be considered as\na useful resource to promote emotion and speech recognition research and\nrelated applications in the Bangla language. The dataset can be found here:\nhttps://data.mendeley.com/datasets/rdwn4bs5ky and might be employed for\nacademic research.",
    "published": "2023-12-21T16:52:41Z",
    "pdf_url": "http://arxiv.org/pdf/2312.14020v1",
    "categories": [
      "cs.HC",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ]
  },
  {
    "arxiv_id": "2405.13344v2",
    "title": "Contextualized Automatic Speech Recognition with Dynamic Vocabulary",
    "authors": [
      "Yui Sudo",
      "Yosuke Fukumoto",
      "Muhammad Shakeel",
      "Yifan Peng",
      "Shinji Watanabe"
    ],
    "abstract": "Deep biasing (DB) enhances the performance of end-to-end automatic speech\nrecognition (E2E-ASR) models for rare words or contextual phrases using a bias\nlist. However, most existing methods treat bias phrases as sequences of\nsubwords in a predefined static vocabulary. This naive sequence decomposition\nproduces unnatural token patterns, significantly lowering their occurrence\nprobability. More advanced techniques address this problem by expanding the\nvocabulary with additional modules, including the external language model\nshallow fusion or rescoring. However, they result in increasing the workload\ndue to the additional modules. This paper proposes a dynamic vocabulary where\nbias tokens can be added during inference. Each entry in a bias list is\nrepresented as a single token, unlike a sequence of existing subword tokens.\nThis approach eliminates the need to learn subword dependencies within the bias\nphrases. This method is easily applied to various architectures because it only\nexpands the embedding and output layers in common E2E-ASR architectures.\nExperimental results demonstrate that the proposed method improves the bias\nphrase WER on English and Japanese datasets by 3.1 -- 4.9 points compared with\nthe conventional DB method.",
    "published": "2024-05-22T05:03:39Z",
    "pdf_url": "http://arxiv.org/pdf/2405.13344v2",
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "2011.00721v1",
    "title": "Robust Raw Waveform Speech Recognition Using Relevance Weighted\n  Representations",
    "authors": [
      "Purvi Agrawal",
      "Sriram Ganapathy"
    ],
    "abstract": "Speech recognition in noisy and channel distorted scenarios is often\nchallenging as the current acoustic modeling schemes are not adaptive to the\nchanges in the signal distribution in the presence of noise. In this work, we\ndevelop a novel acoustic modeling framework for noise robust speech recognition\nbased on relevance weighting mechanism. The relevance weighting is achieved\nusing a sub-network approach that performs feature selection. A relevance\nsub-network is applied on the output of first layer of a convolutional network\nmodel operating on raw speech signals while a second relevance sub-network is\napplied on the second convolutional layer output. The relevance weights for the\nfirst layer correspond to an acoustic filterbank selection while the relevance\nweights in the second layer perform modulation filter selection. The model is\ntrained for a speech recognition task on noisy and reverberant speech. The\nspeech recognition experiments on multiple datasets (Aurora-4, CHiME-3, VOiCES)\nreveal that the incorporation of relevance weighting in the neural network\narchitecture improves the speech recognition word error rates significantly\n(average relative improvements of 10% over the baseline systems)",
    "published": "2020-10-29T19:32:50Z",
    "pdf_url": "http://arxiv.org/pdf/2011.00721v1",
    "categories": [
      "eess.AS",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "2201.05845v2",
    "title": "Recent Progress in the CUHK Dysarthric Speech Recognition System",
    "authors": [
      "Shansong Liu",
      "Mengzhe Geng",
      "Shoukang Hu",
      "Xurong Xie",
      "Mingyu Cui",
      "Jianwei Yu",
      "Xunying Liu",
      "Helen Meng"
    ],
    "abstract": "Despite the rapid progress of automatic speech recognition (ASR) technologies\nin the past few decades, recognition of disordered speech remains a highly\nchallenging task to date. Disordered speech presents a wide spectrum of\nchallenges to current data intensive deep neural networks (DNNs) based ASR\ntechnologies that predominantly target normal speech. This paper presents\nrecent research efforts at the Chinese University of Hong Kong (CUHK) to\nimprove the performance of disordered speech recognition systems on the largest\npublicly available UASpeech dysarthric speech corpus. A set of novel modelling\ntechniques including neural architectural search, data augmentation using\nspectra-temporal perturbation, model based speaker adaptation and cross-domain\ngeneration of visual features within an audio-visual speech recognition (AVSR)\nsystem framework were employed to address the above challenges. The combination\nof these techniques produced the lowest published word error rate (WER) of\n25.21% on the UASpeech test set 16 dysarthric speakers, and an overall WER\nreduction of 5.4% absolute (17.6% relative) over the CUHK 2018 dysarthric\nspeech recognition system featuring a 6-way DNN system combination and cross\nadaptation of out-of-domain normal speech data trained systems. Bayesian model\nadaptation further allows rapid adaptation to individual dysarthric speakers to\nbe performed using as little as 3.06 seconds of speech. The efficacy of these\ntechniques were further demonstrated on a CUDYS Cantonese dysarthric speech\nrecognition task.",
    "published": "2022-01-15T13:02:40Z",
    "pdf_url": "http://arxiv.org/pdf/2201.05845v2",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.LG",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "2407.21211v2",
    "title": "Leveraging Self-Supervised Models for Automatic Whispered Speech\n  Recognition",
    "authors": [
      "Aref Farhadipour",
      "Homa Asadi",
      "Volker Dellwo"
    ],
    "abstract": "In automatic speech recognition, any factor that alters the acoustic\nproperties of speech can pose a challenge to the system's performance. This\npaper presents a novel approach for automatic whispered speech recognition in\nthe Irish dialect using the self-supervised WavLM model. Conventional automatic\nspeech recognition systems often fail to accurately recognise whispered speech\ndue to its distinct acoustic properties and the scarcity of relevant training\ndata. To address this challenge, we utilized a pre-trained WavLM model,\nfine-tuned with a combination of whispered and normal speech data from the\nwTIMIT and CHAINS datasets, which include the English language in Singaporean\nand Irish dialects, respectively. Our baseline evaluation with the OpenAI\nWhisper model highlighted its limitations, achieving a Word Error Rate (WER) of\n18.8% and a Character Error Rate (CER) of 4.24% on whispered speech. In\ncontrast, the proposed WavLM-based system significantly improved performance,\nachieving a WER of 9.22% and a CER of 2.59%. These results demonstrate the\nefficacy of our approach in recognising whispered speech and underscore the\nimportance of tailored acoustic modeling for robust automatic speech\nrecognition systems. This study provides valuable insights into developing\neffective automatic speech recognition solutions for challenging speech\naffected by whisper and dialect. The source codes for this paper are freely\navailable.",
    "published": "2024-07-30T21:45:37Z",
    "pdf_url": "http://arxiv.org/pdf/2407.21211v2",
    "categories": [
      "eess.AS",
      "cs.SD"
    ]
  },
  {
    "arxiv_id": "2412.19005v1",
    "title": "Enhancing Audiovisual Speech Recognition through Bifocal Preference\n  Optimization",
    "authors": [
      "Yihan Wu",
      "Yichen Lu",
      "Yifan Peng",
      "Xihua Wang",
      "Ruihua Song",
      "Shinji Watanabe"
    ],
    "abstract": "Audiovisual Automatic Speech Recognition (AV-ASR) aims to improve speech\nrecognition accuracy by leveraging visual signals. It is particularly\nchallenging in unconstrained real-world scenarios across various domains due to\nnoisy acoustic environments, spontaneous speech, and the uncertain use of\nvisual information. Most previous works fine-tune audio-only ASR models on\naudiovisual datasets, optimizing them for conventional ASR objectives. However,\nthey often neglect visual features and common errors in unconstrained video\nscenarios. In this paper, we propose using a preference optimization strategy\nto improve speech recognition accuracy for real-world videos. First, we create\npreference data via simulating common errors that occurred in AV-ASR from two\nfocals: manipulating the audio or vision input and rewriting the output\ntranscript. Second, we propose BPO-AVASR, a Bifocal Preference Optimization\nmethod to improve AV-ASR models by leveraging both input-side and output-side\npreference. Extensive experiments demonstrate that our approach significantly\nimproves speech recognition accuracy across various domains, outperforming\nprevious state-of-the-art models on real-world video speech recognition.",
    "published": "2024-12-26T00:26:45Z",
    "pdf_url": "http://arxiv.org/pdf/2412.19005v1",
    "categories": [
      "eess.AS",
      "cs.AI"
    ]
  }
]