# Chatbot arXiv - Recherche S√©mantique d'Articles Scientifiques

[![Python](https://img.shields.io/badge/Python-3.13-blue.svg)](https://www.python.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.32-red.svg)](https://streamlit.io/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> Syst√®me intelligent de recherche s√©mantique d'articles scientifiques utilisant l'IA et le traitement du langage naturel

## Table des Mati√®res

- [Vue d'Ensemble](#vue-densemble)
- [Fonctionnalit√©s](#fonctionnalit√©s)
- [Architecture du Projet](#architecture-du-projet)
- [Technologies Utilis√©es](#technologies-utilis√©es)
- [Installation](#installation)
- [Configuration](#configuration)
- [Utilisation](#utilisation)
- [Captures d'√âcran](#captures-d√©cran)
- [Structure des Donn√©es](#structure-des-donn√©es)
- [Performance](#performance)
- [Contribuer](#contribuer)
- [Licence](#licence)

---

## Vue d'Ensemble

Ce projet impl√©mente un **chatbot intelligent** pour la recherche d'articles scientifiques sur **arXiv** en utilisant des techniques avanc√©es de **recherche s√©mantique**. Contrairement aux moteurs de recherche traditionnels bas√©s sur des mots-cl√©s, notre syst√®me comprend le **sens profond** des requ√™tes gr√¢ce aux embeddings s√©mantiques et aux transformers.

### Probl√©matique

- **200,000+** nouveaux articles publi√©s chaque ann√©e sur arXiv
- Recherche par mots-cl√©s limit√©e et impr√©cise
- Difficult√© √† trouver des articles pertinents avec une terminologie diff√©rente
- Surcharge informationnelle pour les chercheurs

### Solution

Notre syst√®me utilise l'IA pour :
- ‚úÖ Comprendre le sens s√©mantique des requ√™tes
- ‚úÖ Trouver des articles pertinents m√™me avec des termes diff√©rents
- ‚úÖ Offrir une interface intuitive et rapide
- ‚úÖ Fournir des r√©sultats avec scores de pertinence

---

##  Fonctionnalit√©s

### Recherche S√©mantique Avanc√©e
- Recherche en langage naturel (pas seulement des mots-cl√©s)
- Compr√©hension du contexte et des synonymes
- Scores de pertinence pour chaque r√©sultat
- Temps de r√©ponse < 1 seconde

### Interface Utilisateur Intuitive
- Interface web moderne avec Streamlit
- Affichage des r√©sultats avec cartes expansibles
- Visualisations interactives (timeline, cat√©gories)
- Design responsive (desktop/tablette)

### üîß Filtres et Options
- Filtrage par ann√©e (2020-2025)
- S√©lection de cat√©gories arXiv
- Tri par pertinence, ann√©e ou citations
- Export des r√©sultats

###  Statistiques et Visualisations
- Distribution temporelle des publications
- R√©partition par cat√©gories
- Graphiques interactifs Plotly
- Statistiques en temps r√©el

---

##  Architecture du Projet

### Structure des Dossiers

```bash
arxiv_chatbot/
‚îÇ
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ api_config.py              # Configuration API arXiv
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ embeddings/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ article_embeddings_arxiv.npy    # Embeddings pr√©-calcul√©s
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ indexes/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ faiss_index.bin        # Index FAISS
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chroma_db/             # Collection ChromaDB
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ arxiv_database.db      # Base de donn√©es SQLite
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ raw/
‚îÇ       ‚îú‚îÄ‚îÄ arxiv_extraction.csv   # Donn√©es brutes CSV
‚îÇ       ‚îî‚îÄ‚îÄ arxiv_extraction.json  # Donn√©es brutes JSON
‚îÇ
‚îú‚îÄ‚îÄ logs/                          # Fichiers de logs
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ chatbot_interface.py       # Interface utilisateur Streamlit
‚îÇ   ‚îú‚îÄ‚îÄ data_processor.py          # Traitement des donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ arxiv_extractor_massive.py # Extraction API arXiv
‚îÇ   ‚îî‚îÄ‚îÄ semantic_indexer.py        # Indexation s√©mantique
‚îÇ
‚îú‚îÄ‚îÄ venv/                          # Environnement virtuel
‚îÇ
‚îú‚îÄ‚îÄ .env                           # Variables d'environnement
‚îú‚îÄ‚îÄ README.md                      # Documentation
‚îú‚îÄ‚îÄ requirements.txt               # D√©pendances Python
‚îî‚îÄ‚îÄ validate_step2.py              # Validation des √©tapes
```

### Description des Modules

####  Module 1 : Extraction (arxiv_extractor_massive.py)
- Extraction massive depuis l'API arXiv
- Gestion du rate limiting et des erreurs r√©seau
- Sauvegarde en JSON et CSV
- **R√©sultat** : 13,641 articles extraits

####  Module 2 : Nettoyage (data_processor.py)
- D√©duplication des articles
- Normalisation textuelle
- Validation des m√©tadonn√©es
- Stockage dans SQLite optimis√©e
- **R√©sultat** : 13,490 articles uniques

#### üß† Module 3 : Indexation (semantic_indexer.py)
- G√©n√©ration d'embeddings avec Sentence Transformers
- Cr√©ation d'index FAISS pour recherche rapide
- Collection ChromaDB pour m√©tadonn√©es
- **R√©sultat** : 13,490 vecteurs 384D index√©s

#### Module 4 : Interface (chatbot_interface.py)
- Application web Streamlit
- Recherche s√©mantique en temps r√©el
- Visualisations interactives
- Filtres et exports

---

##  Technologies Utilis√©es

### Langages et Frameworks
- **Python 3.13** - Langage principal
- **Streamlit 1.32** - Interface web interactive
- **SQLite** - Base de donn√©es embarqu√©e

### Intelligence Artificielle
- **Sentence Transformers** - G√©n√©ration d'embeddings
  - Mod√®le : `all-MiniLM-L6-v2`
  - Dimension : 384D
  - Vitesse : 14ms/phrase
- **FAISS** - Recherche vectorielle ultra-rapide
- **ChromaDB** - Base de donn√©es vectorielle

### Visualisation et UI
- **Plotly** - Graphiques interactifs
- **Pandas** - Manipulation de donn√©es
- **NumPy** - Calculs num√©riques

### APIs et Donn√©es
- **arXiv API** - Source des articles scientifiques
- **Requests** - Requ√™tes HTTP

---

##  Installation

### Pr√©requis

- Python 3.13 ou sup√©rieur
- pip (gestionnaire de paquets Python)
- 4 GB RAM minimum
- 2 GB espace disque

### √âtapes d'Installation

1. **Cloner le repository**
```bash
git clone https://github.com/votre-username/arxiv-chatbot.git
cd arxiv-chatbot
```

2. **Cr√©er un environnement virtuel**
```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

3. **Installer les d√©pendances**
```bash
pip install -r requirements.txt
```

4. **V√©rifier l'installation**
```bash
python validate_step2.py
```
---

##  Configuration

### Variables d'Environnement

Cr√©ez un fichier `.env` √† la racine du projet :

```env
# Configuration API arXiv
ARXIV_BASE_URL=http://export.arxiv.org/api/query
ARXIV_MAX_RESULTS=2000
ARXIV_RATE_LIMIT=3

# Configuration Base de Donn√©es
DB_PATH=data/processed/arxiv_database.db

# Configuration Embeddings
EMBEDDINGS_MODEL=all-MiniLM-L6-v2
EMBEDDINGS_DIMENSION=384
EMBEDDINGS_PATH=data/embeddings/article_embeddings_arxiv.npy

# Configuration FAISS
FAISS_INDEX_PATH=data/indexes/faiss_index.bin

# Configuration ChromaDB
CHROMA_PATH=data/indexes/chroma_db
CHROMA_COLLECTION=arxiv_articles

# Configuration Streamlit
STREAMLIT_PORT=8501
STREAMLIT_THEME=light
```

### Configuration API arXiv

Le fichier `config/api_config.py` contient les param√®tres de l'API :

```python
ARXIV_CONFIG = {
    'base_url': 'http://export.arxiv.org/api/query',
    'max_results': 2000,
    'rate_limit': 3,  # secondes entre requ√™tes
    'timeout': 30,
    'retry_attempts': 5,
    'categories': ['cs.AI', 'cs.LG', 'cs.CV', 'cs.CL'],
    'date_range': {
        'start': '2020-01-01',
        'end': '2025-12-31'
    }
}
```
---

##  Utilisation

### Extraction des Donn√©es

```bash
python src/arxiv_extractor_massive.py
```

**Sortie** :
- `data/raw/arxiv_extraction.json` (13,641 articles)
- `data/raw/arxiv_extraction.csv` (format tabulaire)

### Nettoyage et Structuration

```bash
python src/data_processor.py
```

**Sortie** :
- `data/processed/arxiv_database.db` (13,490 articles uniques)
- Logs de nettoyage dans `logs/`

### Indexation S√©mantique

```bash
python src/semantic_indexer.py
```

**Sortie** :
- `data/embeddings/article_embeddings_arxiv.npy` (13,490 vecteurs)
- `data/indexes/faiss_index.bin` (index FAISS)
- `data/indexes/chroma_db/` (collection ChromaDB)

### Lancement de l'Interface

```bash
streamlit run src/chatbot_interface.py
```

L'application sera accessible √† : **http://localhost:8501**

---

## Captures d'√âcran

### Interface Principale

![App Screenshot](./assets/screen1.png)

L'interface principale pr√©sente :
- **Barre de recherche** : Saisie de requ√™tes en langage naturel
- **Filtres lat√©raux** : Ann√©e, cat√©gories, tri
- **Statistiques** : Nombre d'articles, distribution temporelle
- **Zone de r√©sultats** : Affichage des articles pertinents

### R√©sultats de Recherche
![App Screenshot](./assets/screen2.png)

Chaque r√©sultat affiche :
- **Titre** de l'article (cliquable)
- **Score de pertinence** (0.0 - 1.0)
- **Ann√©e de publication**
- **Auteurs principaux**
- **Extrait du r√©sum√©**
- **Boutons d'action** : PDF, BibTeX, Copier

### Visualisations Interactives

![App Screenshot](./assets/screen3.png)

Les visualisations incluent :
- **Timeline des publications** : √âvolution temporelle
- **Distribution par cat√©gories** : R√©partition des domaines
- **Graphiques interactifs** : Zoom, filtrage, export

### Filtres Avanc√©s

Options de filtrage :
- **Slider temporel** : S√©lection de la p√©riode
- **Multiselect cat√©gories** : Choix des domaines
- **Options de tri** : Pertinence, ann√©e, citations
- **Statistiques dynamiques** : Mise √† jour en temps r√©el

---

##  Structure des Donn√©es

### Base de Donn√©es SQLite

#### Table `articles`
| Colonne | Type | Description |
|---------|------|-------------|
| id | TEXT PRIMARY KEY | ID arXiv unique |
| title | TEXT | Titre de l'article |
| abstract | TEXT | R√©sum√© complet |
| published | DATE | Date de publication |
| categories | JSON | Liste des cat√©gories |
| doi | TEXT | DOI (si disponible) |
| pdf_url | TEXT | Lien vers le PDF |

#### Table `authors`
| Colonne | Type | Description |
|---------|------|-------------|
| id | INTEGER PRIMARY KEY | ID auto-incr√©ment√© |
| name | TEXT | Nom normalis√© |
| affiliation | TEXT | Affiliation (si disponible) |
| orcid | TEXT | Identifiant ORCID |

#### Table `article_authors`
| Colonne | Type | Description |
|---------|------|-------------|
| article_id | TEXT | R√©f√©rence √† articles(id) |
| author_id | INTEGER | R√©f√©rence √† authors(id) |
| position | INTEGER | Ordre de signature |

### Format des Embeddings

- **Type** : NumPy array (float32)
- **Shape** : (13490, 384)
- **Taille** : 20 MB
- **Normalisation** : L2 (vecteurs unitaires)

---

##  Performance

### M√©triques Syst√®me

| M√©trique | Valeur |
|----------|--------|
| Articles index√©s | 13,490 |
| Temps d'indexation | 31 secondes |
| Taille base de donn√©es | 450 MB |
| Taille embeddings | 20 MB |
| M√©moire RAM utilis√©e | 2.1 GB |

### M√©triques de Recherche

| M√©trique | Valeur |
|----------|--------|
| Temps de recherche FAISS | < 0.1 ms |
| Temps de r√©ponse total | 0.8 s (m√©dian) |
| Pr√©cision@5 | 84% |
| Pr√©cision@10 | 79% |
| Satisfaction utilisateurs | 4.2/5 |

### Optimisations Appliqu√©es

- ‚úÖ Caching du mod√®le Sentence Transformer
- ‚úÖ Index FAISS avec recherche exacte
- ‚úÖ Requ√™tes SQL optimis√©es avec index B-tree
- ‚úÖ Chargement progressif des r√©sultats
- ‚úÖ Lazy loading des r√©sum√©s complets

---

##  Contribuer

Les contributions sont les bienvenues ! Voici comment participer :

1. **Fork** le projet
2. Cr√©ez une **branche** pour votre fonctionnalit√© (`git checkout -b feature/AmazingFeature`)
3. **Committez** vos changements (`git commit -m 'Add AmazingFeature'`)
4. **Push** vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrez une **Pull Request**

### Guidelines

- Suivre les conventions PEP 8 pour Python
- Ajouter des tests pour les nouvelles fonctionnalit√©s
- Mettre √† jour la documentation
- Commenter le code complexe

---

## Licence

Ce projet est sous licence **MIT**. Voir le fichier [LICENSE](LICENSE) pour plus de d√©tails.

---

##  Auteurs

**√âquipe de D√©veloppement**
- Asmae LAHROUB
- Saida ALABA
- Wissal ENNAJAH

**Encadrement**
- Pr. Abdlellah Madani

**Institution**
- Universit√© Chouaib Doukkali
- Facult√© des Sciences
- Master : Ing√©nierie Informatique et Analyse de Donn√©es

---

##  Contact

Pour toute question ou suggestion :

- Email : [votre-email@example.com](mailto:lhroubasmae2018@example.com)
- Issues : [GitHub Issues](https://github.com/votre-username/arxiv-chatbot/issues)
- Discussions : [GitHub Discussions](https://github.com/votre-username/arxiv-chatbot/discussions)

---

##  Remerciements

- **arXiv** pour l'acc√®s gratuit √† leur API
- **Hugging Face** pour les mod√®les Sentence Transformers
- **Facebook AI Research** pour FAISS
- **Streamlit** pour le framework d'interface
- **Communaut√© open-source** pour les biblioth√®ques utilis√©es

---

##  Perspectives Futures

### Court Terme (3-6 mois)
- [ ] Extension √† 50,000+ articles
- [ ] Export BibTeX/RIS automatique
- [ ] Syst√®me d'alertes par email
- [ ] Support multilingue (fran√ßais, anglais)

### Moyen Terme (6-12 mois)
- [ ] Analyse du texte int√©gral (PDFs)
- [ ] Extraction automatique d'informations
- [ ] Recommandations personnalis√©es
- [ ] Int√©gration PubMed, HAL

### Long Terme (1-2 ans)
- [ ] R√©sum√©s g√©n√©r√©s par LLM
- [ ] Graphes de connaissances
- [ ] D√©tection de tendances √©mergentes
- [ ] Plateforme collaborative

---

##  Ressources Additionnelles

### Documentation
- [arXiv API Documentation](https://arxiv.org/help/api)
- [Sentence Transformers](https://www.sbert.net/)
- [FAISS Documentation](https://faiss.ai/)
- [Streamlit Documentation](https://docs.streamlit.io/)

### Articles Scientifiques
- [Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks](https://arxiv.org/abs/1908.10084)
- [Billion-scale similarity search with GPUs](https://arxiv.org/abs/1702.08734)

### Tutoriels
- [Building Semantic Search Applications](https://www.sbert.net/examples/applications/semantic-search/README.html)
- [FAISS Tutorial](https://github.com/facebookresearch/faiss/wiki/Getting-started)

---

<div align="center">

**‚≠ê Si ce projet vous a √©t√© utile, n'h√©sitez pas √† lui donner une √©toile ! ‚≠ê**



</div>
```

